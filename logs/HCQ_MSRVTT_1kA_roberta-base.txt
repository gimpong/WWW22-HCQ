Experiment directory: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_MSRVTT_1kA_roberta-base
Preparing the dataloaders ...
Loading dataset MSRVTT_jsfusion_trainval in ram ...
Finish loading dataset MSRVTT_jsfusion_trainval in ram, taking 303.1627972126007 s.
Loading dataset MSRVTT_jsfusion_test in ram ...
Finish loading dataset MSRVTT_jsfusion_test in ram, taking 30.62748885154724 s.
Loading dataset MSRVTT_jsfusion_test in ram ...
Finish loading dataset MSRVTT_jsfusion_test in ram, taking 14.081108331680298 s.
Training ...
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_MSRVTT_1kA_roberta-base/checkpoint-epoch0.pth ...
Done in 8.467s
Updating 'best' checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_MSRVTT_1kA_roberta-base/checkpoint-epoch0.pth ...
Done in 10.155s
 epoch          : 0
 loss           : 0
 learning_rate  : 0.0001
 n_samples      : 0
 n_steps        : 0
 MSRVTT_jsfusion_test/t2v_metrics/R1: 0.0
 MSRVTT_jsfusion_test/t2v_metrics/R5: 0.6
 MSRVTT_jsfusion_test/t2v_metrics/R10: 0.9
 MSRVTT_jsfusion_test/t2v_metrics/R50: 5.1
 MSRVTT_jsfusion_test/t2v_metrics/MedR: 494.0
 MSRVTT_jsfusion_test/t2v_metrics/MeanR: 500.367
 MSRVTT_jsfusion_test/t2v_metrics/geometric_mean_R1-R5-R10: 0.0
 MSRVTT_jsfusion_test/v2t_metrics/R1: 0.0
 MSRVTT_jsfusion_test/v2t_metrics/R5: 0.4
 MSRVTT_jsfusion_test/v2t_metrics/R10: 0.5
 MSRVTT_jsfusion_test/v2t_metrics/R50: 4.8
 MSRVTT_jsfusion_test/v2t_metrics/MedR: 517.0
 MSRVTT_jsfusion_test/v2t_metrics/MeanR: 511.0715
 MSRVTT_jsfusion_test/v2t_metrics/geometric_mean_R1-R5-R10: 0.0
 mnt_best       : 0.0
 not_improved_count: 0
Train Epoch: 1 [1/250 128/32000 (0%)] Loss: 9.79148 (QuantReg: 22.29398) QuantErr: 22.29398 batch_time=17.60762 
Train Epoch: 1 [12/250 1536/32000 (5%)] Loss: 9.15695 (QuantReg: 22.36269) QuantErr: 22.36269 batch_time=0.48463 
Train Epoch: 1 [23/250 2944/32000 (9%)] Loss: 7.71432 (QuantReg: 22.55618) QuantErr: 22.55618 batch_time=0.49085 
Train Epoch: 1 [34/250 4352/32000 (14%)] Loss: 7.11308 (QuantReg: 22.62117) QuantErr: 22.62117 batch_time=0.50021 
Train Epoch: 1 [45/250 5760/32000 (18%)] Loss: 7.44017 (QuantReg: 22.59572) QuantErr: 22.59572 batch_time=0.48779 
Train Epoch: 1 [56/250 7168/32000 (22%)] Loss: 6.58747 (QuantReg: 22.62014) QuantErr: 22.62014 batch_time=0.48433 
Train Epoch: 1 [67/250 8576/32000 (27%)] Loss: 5.96107 (QuantReg: 22.64347) QuantErr: 22.64347 batch_time=0.49536 
Train Epoch: 1 [78/250 9984/32000 (31%)] Loss: 5.63668 (QuantReg: 22.60108) QuantErr: 22.60108 batch_time=0.48929 
Train Epoch: 1 [89/250 11392/32000 (36%)] Loss: 5.72397 (QuantReg: 22.61637) QuantErr: 22.61637 batch_time=0.49659 
Train Epoch: 1 [100/250 12800/32000 (40%)] Loss: 5.23563 (QuantReg: 22.62866) QuantErr: 22.62866 batch_time=0.48468 
Train Epoch: 1 [111/250 14208/32000 (44%)] Loss: 5.45254 (QuantReg: 22.62077) QuantErr: 22.62077 batch_time=0.82563 
Train Epoch: 1 [122/250 15616/32000 (49%)] Loss: 5.08708 (QuantReg: 22.61661) QuantErr: 22.61661 batch_time=0.49912 
Train Epoch: 1 [133/250 17024/32000 (53%)] Loss: 4.94262 (QuantReg: 22.62331) QuantErr: 22.62331 batch_time=0.52268 
Train Epoch: 1 [144/250 18432/32000 (58%)] Loss: 4.81687 (QuantReg: 22.61462) QuantErr: 22.61462 batch_time=0.50104 
Train Epoch: 1 [155/250 19840/32000 (62%)] Loss: 4.77283 (QuantReg: 22.62066) QuantErr: 22.62066 batch_time=0.49504 
Train Epoch: 1 [166/250 21248/32000 (66%)] Loss: 4.68481 (QuantReg: 22.57771) QuantErr: 22.57771 batch_time=0.49749 
Train Epoch: 1 [177/250 22656/32000 (71%)] Loss: 4.67921 (QuantReg: 22.61409) QuantErr: 22.61409 batch_time=0.49539 
Train Epoch: 1 [188/250 24064/32000 (75%)] Loss: 4.72821 (QuantReg: 22.64111) QuantErr: 22.64111 batch_time=0.85462 
Train Epoch: 1 [199/250 25472/32000 (80%)] Loss: 4.48433 (QuantReg: 22.66157) QuantErr: 22.66157 batch_time=0.49805 
Train Epoch: 1 [210/250 26880/32000 (84%)] Loss: 4.36722 (QuantReg: 22.65427) QuantErr: 22.65427 batch_time=0.49232 
Train Epoch: 1 [221/250 28288/32000 (88%)] Loss: 4.99173 (QuantReg: 22.66599) QuantErr: 22.66599 batch_time=0.52043 
Train Epoch: 1 [232/250 29696/32000 (93%)] Loss: 4.20352 (QuantReg: 22.67728) QuantErr: 22.67728 batch_time=0.61435 
Train Epoch: 1 [243/250 31104/32000 (97%)] Loss: 3.95817 (QuantReg: 22.63443) QuantErr: 22.63443 batch_time=0.49045 
Train Epoch: 1 codebook_update_time=2.23457
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_MSRVTT_1kA_roberta-base/checkpoint-epoch1.pth ...
Done in 3.955s
Updating 'best' checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_MSRVTT_1kA_roberta-base/checkpoint-epoch1.pth ...
Done in 8.698s
 epoch          : 1
 loss           : 5.616883320808411
 quant_reg      : 22.600959770202635
 quant_err      : 22.600959770202635
 learning_rate  : 0.0001
 n_samples      : 32000
 n_steps        : 250
 MSRVTT_jsfusion_test/t2v_metrics/R1: 8.5
 MSRVTT_jsfusion_test/t2v_metrics/R5: 28.6
 MSRVTT_jsfusion_test/t2v_metrics/R10: 43.9
 MSRVTT_jsfusion_test/t2v_metrics/R50: 77.7
 MSRVTT_jsfusion_test/t2v_metrics/MedR: 14.0
 MSRVTT_jsfusion_test/t2v_metrics/MeanR: 44.858
 MSRVTT_jsfusion_test/t2v_metrics/geometric_mean_R1-R5-R10: 22.016578413053768
 MSRVTT_jsfusion_test/v2t_metrics/R1: 10.9
 MSRVTT_jsfusion_test/v2t_metrics/R5: 32.2
 MSRVTT_jsfusion_test/v2t_metrics/R10: 45.9
 MSRVTT_jsfusion_test/v2t_metrics/R50: 79.3
 MSRVTT_jsfusion_test/v2t_metrics/MedR: 13.0
 MSRVTT_jsfusion_test/v2t_metrics/MeanR: 43.66
 MSRVTT_jsfusion_test/v2t_metrics/geometric_mean_R1-R5-R10: 25.25602614068817
 mnt_best       : 22.016578413053768
 not_improved_count: 0
Train Epoch: 2 [1/250 128/32000 (0%)] Loss: 4.04907 (QuantReg: 10.60452) QuantErr: 10.60452 batch_time=23.30103 
Train Epoch: 2 [12/250 1536/32000 (5%)] Loss: 4.34646 (QuantReg: 10.80864) QuantErr: 10.80864 batch_time=0.49790 
Train Epoch: 2 [23/250 2944/32000 (9%)] Loss: 4.60635 (QuantReg: 11.76969) QuantErr: 11.76969 batch_time=0.49703 
Train Epoch: 2 [34/250 4352/32000 (14%)] Loss: 3.81537 (QuantReg: 11.45857) QuantErr: 11.45857 batch_time=0.49729 
Train Epoch: 2 [45/250 5760/32000 (18%)] Loss: 4.11797 (QuantReg: 12.05406) QuantErr: 12.05406 batch_time=1.79420 
Train Epoch: 2 [56/250 7168/32000 (22%)] Loss: 3.83013 (QuantReg: 12.03797) QuantErr: 12.03797 batch_time=0.50672 
Train Epoch: 2 [67/250 8576/32000 (27%)] Loss: 3.92122 (QuantReg: 12.43412) QuantErr: 12.43412 batch_time=0.49214 
Train Epoch: 2 [78/250 9984/32000 (31%)] Loss: 3.64327 (QuantReg: 12.09956) QuantErr: 12.09956 batch_time=0.50409 
Train Epoch: 2 [89/250 11392/32000 (36%)] Loss: 3.49058 (QuantReg: 12.25521) QuantErr: 12.25521 batch_time=0.72971 
Train Epoch: 2 [100/250 12800/32000 (40%)] Loss: 4.10961 (QuantReg: 12.64125) QuantErr: 12.64125 batch_time=0.48888 
Train Epoch: 2 [111/250 14208/32000 (44%)] Loss: 4.15006 (QuantReg: 12.49328) QuantErr: 12.49328 batch_time=0.50195 
Train Epoch: 2 [122/250 15616/32000 (49%)] Loss: 3.51093 (QuantReg: 12.68871) QuantErr: 12.68871 batch_time=0.49796 
Train Epoch: 2 [133/250 17024/32000 (53%)] Loss: 3.98043 (QuantReg: 13.36201) QuantErr: 13.36201 batch_time=0.51262 
Train Epoch: 2 [144/250 18432/32000 (58%)] Loss: 3.86710 (QuantReg: 13.21151) QuantErr: 13.21151 batch_time=0.88571 
Train Epoch: 2 [155/250 19840/32000 (62%)] Loss: 3.82423 (QuantReg: 13.16813) QuantErr: 13.16813 batch_time=0.48950 
Train Epoch: 2 [166/250 21248/32000 (66%)] Loss: 3.73893 (QuantReg: 13.30185) QuantErr: 13.30185 batch_time=0.81079 
Train Epoch: 2 [177/250 22656/32000 (71%)] Loss: 3.79339 (QuantReg: 13.35253) QuantErr: 13.35253 batch_time=0.49659 
Train Epoch: 2 [188/250 24064/32000 (75%)] Loss: 3.67709 (QuantReg: 13.89095) QuantErr: 13.89095 batch_time=0.50372 
Train Epoch: 2 [199/250 25472/32000 (80%)] Loss: 3.82995 (QuantReg: 13.43280) QuantErr: 13.43280 batch_time=0.49974 
Train Epoch: 2 [210/250 26880/32000 (84%)] Loss: 3.38052 (QuantReg: 14.48529) QuantErr: 14.48529 batch_time=0.49899 
Train Epoch: 2 [221/250 28288/32000 (88%)] Loss: 3.40227 (QuantReg: 14.10329) QuantErr: 14.10329 batch_time=0.49885 
Train Epoch: 2 [232/250 29696/32000 (93%)] Loss: 3.53674 (QuantReg: 14.06636) QuantErr: 14.06636 batch_time=0.49845 
Train Epoch: 2 [243/250 31104/32000 (97%)] Loss: 3.54245 (QuantReg: 13.86805) QuantErr: 13.86805 batch_time=0.49654 
Train Epoch: 2 codebook_update_time=1.63846
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_MSRVTT_1kA_roberta-base/checkpoint-epoch2.pth ...
Done in 4.008s
Updating 'best' checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_MSRVTT_1kA_roberta-base/checkpoint-epoch2.pth ...
Done in 7.965s
removing stale ckpt [epoch 1] [took 0.01s]
removing stale ckpt [epoch 0] [took 0.00s]
 epoch          : 2
 loss           : 3.765118082046509
 quant_reg      : 12.80198962020874
 quant_err      : 12.80198962020874
 learning_rate  : 9.5e-05
 n_samples      : 64000
 n_steps        : 500
 MSRVTT_jsfusion_test/t2v_metrics/R1: 12.6
 MSRVTT_jsfusion_test/t2v_metrics/R5: 38.1
 MSRVTT_jsfusion_test/t2v_metrics/R10: 53.5
 MSRVTT_jsfusion_test/t2v_metrics/R50: 83.0
 MSRVTT_jsfusion_test/t2v_metrics/MedR: 9.0
 MSRVTT_jsfusion_test/t2v_metrics/MeanR: 38.109
 MSRVTT_jsfusion_test/t2v_metrics/geometric_mean_R1-R5-R10: 29.504149564706317
 MSRVTT_jsfusion_test/v2t_metrics/R1: 14.4
 MSRVTT_jsfusion_test/v2t_metrics/R5: 41.0
 MSRVTT_jsfusion_test/v2t_metrics/R10: 54.3
 MSRVTT_jsfusion_test/v2t_metrics/R50: 82.3
 MSRVTT_jsfusion_test/v2t_metrics/MedR: 8.0
 MSRVTT_jsfusion_test/v2t_metrics/MeanR: 36.9775
 MSRVTT_jsfusion_test/v2t_metrics/geometric_mean_R1-R5-R10: 31.767428379579528
 mnt_best       : 29.504149564706317
 not_improved_count: 0
Train Epoch: 3 [1/250 128/32000 (0%)] Loss: 3.25211 (QuantReg: 11.03418) QuantErr: 11.03418 batch_time=31.24523 
Train Epoch: 3 [12/250 1536/32000 (5%)] Loss: 3.13154 (QuantReg: 10.90020) QuantErr: 10.90020 batch_time=1.01906 
Train Epoch: 3 [23/250 2944/32000 (9%)] Loss: 3.63055 (QuantReg: 10.98746) QuantErr: 10.98746 batch_time=0.60388 
Train Epoch: 3 [34/250 4352/32000 (14%)] Loss: 3.78538 (QuantReg: 11.46998) QuantErr: 11.46998 batch_time=0.49342 
Train Epoch: 3 [45/250 5760/32000 (18%)] Loss: 3.29590 (QuantReg: 11.61458) QuantErr: 11.61458 batch_time=0.50218 
Train Epoch: 3 [56/250 7168/32000 (22%)] Loss: 3.24607 (QuantReg: 11.64419) QuantErr: 11.64419 batch_time=0.49858 
Train Epoch: 3 [67/250 8576/32000 (27%)] Loss: 3.02486 (QuantReg: 11.87529) QuantErr: 11.87529 batch_time=0.49025 
Train Epoch: 3 [78/250 9984/32000 (31%)] Loss: 3.30610 (QuantReg: 11.80598) QuantErr: 11.80598 batch_time=0.49721 
Train Epoch: 3 [89/250 11392/32000 (36%)] Loss: 2.99747 (QuantReg: 11.75561) QuantErr: 11.75561 batch_time=0.50923 
Train Epoch: 3 [100/250 12800/32000 (40%)] Loss: 3.42340 (QuantReg: 11.71822) QuantErr: 11.71822 batch_time=0.47473 
Train Epoch: 3 [111/250 14208/32000 (44%)] Loss: 3.41941 (QuantReg: 11.96877) QuantErr: 11.96877 batch_time=0.51663 
Train Epoch: 3 [122/250 15616/32000 (49%)] Loss: 2.89199 (QuantReg: 12.10991) QuantErr: 12.10991 batch_time=0.49706 
Train Epoch: 3 [133/250 17024/32000 (53%)] Loss: 3.01953 (QuantReg: 11.85675) QuantErr: 11.85675 batch_time=0.49092 
Train Epoch: 3 [144/250 18432/32000 (58%)] Loss: 2.88530 (QuantReg: 12.20796) QuantErr: 12.20796 batch_time=0.49438 
Train Epoch: 3 [155/250 19840/32000 (62%)] Loss: 3.54684 (QuantReg: 12.28975) QuantErr: 12.28975 batch_time=0.97184 
Train Epoch: 3 [166/250 21248/32000 (66%)] Loss: 3.25400 (QuantReg: 12.45780) QuantErr: 12.45780 batch_time=0.49434 
Train Epoch: 3 [177/250 22656/32000 (71%)] Loss: 3.31546 (QuantReg: 12.38459) QuantErr: 12.38459 batch_time=0.48706 
Train Epoch: 3 [188/250 24064/32000 (75%)] Loss: 3.49139 (QuantReg: 12.67160) QuantErr: 12.67160 batch_time=0.50433 
Train Epoch: 3 [199/250 25472/32000 (80%)] Loss: 3.25192 (QuantReg: 12.82726) QuantErr: 12.82726 batch_time=0.50374 
Train Epoch: 3 [210/250 26880/32000 (84%)] Loss: 2.56871 (QuantReg: 12.84011) QuantErr: 12.84011 batch_time=0.53537 
Experiment directory: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_MSRVTT_1kA_roberta-base
Preparing the dataloaders ...
Loading dataset MSRVTT_jsfusion_trainval in ram ...
Finish loading dataset MSRVTT_jsfusion_trainval in ram, taking 328.4512679576874 s.
Loading dataset MSRVTT_jsfusion_test in ram ...
Finish loading dataset MSRVTT_jsfusion_test in ram, taking 29.23418879508972 s.
Loading dataset MSRVTT_jsfusion_test in ram ...
Finish loading dataset MSRVTT_jsfusion_test in ram, taking 35.05871081352234 s.
Training ...
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_MSRVTT_1kA_roberta-base/checkpoint-epoch0.pth ...
Done in 1.778s
Updating 'best' checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_MSRVTT_1kA_roberta-base/checkpoint-epoch0.pth ...
Done in 3.466s
 epoch          : 0
 loss           : 0
 learning_rate  : 0.0001
 n_samples      : 0
 n_steps        : 0
 MSRVTT_jsfusion_test/t2v_metrics/R1: 0.0
 MSRVTT_jsfusion_test/t2v_metrics/R5: 0.6
 MSRVTT_jsfusion_test/t2v_metrics/R10: 0.9
 MSRVTT_jsfusion_test/t2v_metrics/R50: 5.1
 MSRVTT_jsfusion_test/t2v_metrics/MedR: 494.0
 MSRVTT_jsfusion_test/t2v_metrics/MeanR: 500.367
 MSRVTT_jsfusion_test/t2v_metrics/geometric_mean_R1-R5-R10: 0.0
 MSRVTT_jsfusion_test/v2t_metrics/R1: 0.0
 MSRVTT_jsfusion_test/v2t_metrics/R5: 0.4
 MSRVTT_jsfusion_test/v2t_metrics/R10: 0.5
 MSRVTT_jsfusion_test/v2t_metrics/R50: 4.8
 MSRVTT_jsfusion_test/v2t_metrics/MedR: 517.0
 MSRVTT_jsfusion_test/v2t_metrics/MeanR: 511.0715
 MSRVTT_jsfusion_test/v2t_metrics/geometric_mean_R1-R5-R10: 0.0
 mnt_best       : 0.0
 not_improved_count: 0
Train Epoch: 1 [1/250 128/32000 (0%)] Loss: 9.78876 (QuantReg: 22.29451) QuantErr: 22.29451 batch_time=18.99975 
Train Epoch: 1 [12/250 1536/32000 (5%)] Loss: 9.30404 (QuantReg: 22.39879) QuantErr: 22.39879 batch_time=0.48281 
Train Epoch: 1 [23/250 2944/32000 (9%)] Loss: 7.64905 (QuantReg: 22.55591) QuantErr: 22.55591 batch_time=1.85077 
Train Epoch: 1 [34/250 4352/32000 (14%)] Loss: 6.89103 (QuantReg: 22.61416) QuantErr: 22.61416 batch_time=0.51771 
Train Epoch: 1 [45/250 5760/32000 (18%)] Loss: 7.13362 (QuantReg: 22.61382) QuantErr: 22.61382 batch_time=0.47768 
Train Epoch: 1 [56/250 7168/32000 (22%)] Loss: 6.50737 (QuantReg: 22.62199) QuantErr: 22.62199 batch_time=0.47708 
Train Epoch: 1 [67/250 8576/32000 (27%)] Loss: 5.75723 (QuantReg: 22.60867) QuantErr: 22.60867 batch_time=3.18233 
Train Epoch: 1 [78/250 9984/32000 (31%)] Loss: 5.54827 (QuantReg: 22.61583) QuantErr: 22.61583 batch_time=0.47735 
Train Epoch: 1 [89/250 11392/32000 (36%)] Loss: 5.77014 (QuantReg: 22.61644) QuantErr: 22.61644 batch_time=0.46949 
Train Epoch: 1 [100/250 12800/32000 (40%)] Loss: 5.39464 (QuantReg: 22.65991) QuantErr: 22.65991 batch_time=0.95060 
Train Epoch: 1 [111/250 14208/32000 (44%)] Loss: 5.26279 (QuantReg: 22.58437) QuantErr: 22.58437 batch_time=0.48064 
Train Epoch: 1 [122/250 15616/32000 (49%)] Loss: 5.28473 (QuantReg: 22.60606) QuantErr: 22.60606 batch_time=0.47193 
Train Epoch: 1 [133/250 17024/32000 (53%)] Loss: 5.04621 (QuantReg: 22.61851) QuantErr: 22.61851 batch_time=0.47749 
Train Epoch: 1 [144/250 18432/32000 (58%)] Loss: 4.88421 (QuantReg: 22.65601) QuantErr: 22.65601 batch_time=1.93702 
Train Epoch: 1 [155/250 19840/32000 (62%)] Loss: 4.91598 (QuantReg: 22.61003) QuantErr: 22.61003 batch_time=0.48354 
Train Epoch: 1 [166/250 21248/32000 (66%)] Loss: 4.64491 (QuantReg: 22.57845) QuantErr: 22.57845 batch_time=0.48431 
Train Epoch: 1 [177/250 22656/32000 (71%)] Loss: 4.66547 (QuantReg: 22.62090) QuantErr: 22.62090 batch_time=0.48655 
Train Epoch: 1 [188/250 24064/32000 (75%)] Loss: 4.60874 (QuantReg: 22.63664) QuantErr: 22.63664 batch_time=0.47929 
Train Epoch: 1 [199/250 25472/32000 (80%)] Loss: 4.60505 (QuantReg: 22.66799) QuantErr: 22.66799 batch_time=0.53260 
Train Epoch: 1 [210/250 26880/32000 (84%)] Loss: 4.38503 (QuantReg: 22.64332) QuantErr: 22.64332 batch_time=0.52277 
Train Epoch: 1 [221/250 28288/32000 (88%)] Loss: 4.85373 (QuantReg: 22.64572) QuantErr: 22.64572 batch_time=0.49509 
Train Epoch: 1 [232/250 29696/32000 (93%)] Loss: 4.29711 (QuantReg: 22.63468) QuantErr: 22.63468 batch_time=0.49191 
Train Epoch: 1 [243/250 31104/32000 (97%)] Loss: 3.94186 (QuantReg: 22.62863) QuantErr: 22.62863 batch_time=0.49433 
Train Epoch: 1 codebook_update_time=1.93285
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_MSRVTT_1kA_roberta-base/checkpoint-epoch1.pth ...
Done in 4.030s
Updating 'best' checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_MSRVTT_1kA_roberta-base/checkpoint-epoch1.pth ...
Done in 7.815s
 epoch          : 1
 loss           : 5.564510670661926
 quant_reg      : 22.60241316986084
 quant_err      : 22.60241316986084
 learning_rate  : 0.0001
 n_samples      : 32000
 n_steps        : 250
 MSRVTT_jsfusion_test/t2v_metrics/R1: 8.8
 MSRVTT_jsfusion_test/t2v_metrics/R5: 31.5
 MSRVTT_jsfusion_test/t2v_metrics/R10: 43.6
 MSRVTT_jsfusion_test/t2v_metrics/R50: 77.8
 MSRVTT_jsfusion_test/t2v_metrics/MedR: 14.0
 MSRVTT_jsfusion_test/t2v_metrics/MeanR: 45.846
 MSRVTT_jsfusion_test/t2v_metrics/geometric_mean_R1-R5-R10: 22.948795983939718
 MSRVTT_jsfusion_test/v2t_metrics/R1: 10.5
 MSRVTT_jsfusion_test/v2t_metrics/R5: 32.2
 MSRVTT_jsfusion_test/v2t_metrics/R10: 45.3
 MSRVTT_jsfusion_test/v2t_metrics/R50: 78.8
 MSRVTT_jsfusion_test/v2t_metrics/MedR: 13.0
 MSRVTT_jsfusion_test/v2t_metrics/MeanR: 44.232
 MSRVTT_jsfusion_test/v2t_metrics/geometric_mean_R1-R5-R10: 24.834063709381603
 mnt_best       : 22.948795983939718
 not_improved_count: 0
Train Epoch: 2 [1/250 128/32000 (0%)] Loss: 4.01795 (QuantReg: 10.23188) QuantErr: 10.23188 batch_time=30.37116 
Train Epoch: 2 [12/250 1536/32000 (5%)] Loss: 4.32586 (QuantReg: 10.71046) QuantErr: 10.71046 batch_time=0.49735 
Train Epoch: 2 [23/250 2944/32000 (9%)] Loss: 4.59775 (QuantReg: 11.60484) QuantErr: 11.60484 batch_time=0.48314 
Train Epoch: 2 [34/250 4352/32000 (14%)] Loss: 3.92952 (QuantReg: 11.18868) QuantErr: 11.18868 batch_time=0.51841 
Train Epoch: 2 [45/250 5760/32000 (18%)] Loss: 4.20868 (QuantReg: 12.33174) QuantErr: 12.33174 batch_time=0.48483 
Train Epoch: 2 [56/250 7168/32000 (22%)] Loss: 3.93033 (QuantReg: 12.05905) QuantErr: 12.05905 batch_time=0.51162 
Train Epoch: 2 [67/250 8576/32000 (27%)] Loss: 3.93864 (QuantReg: 12.12665) QuantErr: 12.12665 batch_time=1.28985 
Train Epoch: 2 [78/250 9984/32000 (31%)] Loss: 3.40910 (QuantReg: 12.18132) QuantErr: 12.18132 batch_time=0.56978 
Train Epoch: 2 [89/250 11392/32000 (36%)] Loss: 3.36989 (QuantReg: 12.34477) QuantErr: 12.34477 batch_time=0.49137 
Train Epoch: 2 [100/250 12800/32000 (40%)] Loss: 4.22926 (QuantReg: 12.52924) QuantErr: 12.52924 batch_time=0.48766 
Train Epoch: 2 [111/250 14208/32000 (44%)] Loss: 4.18998 (QuantReg: 12.50600) QuantErr: 12.50600 batch_time=0.60203 
Train Epoch: 2 [122/250 15616/32000 (49%)] Loss: 3.45194 (QuantReg: 12.72742) QuantErr: 12.72742 batch_time=0.47668 
Train Epoch: 2 [133/250 17024/32000 (53%)] Loss: 3.94796 (QuantReg: 13.37875) QuantErr: 13.37875 batch_time=0.47666 
Train Epoch: 2 [144/250 18432/32000 (58%)] Loss: 3.75051 (QuantReg: 12.89451) QuantErr: 12.89451 batch_time=1.44926 
Train Epoch: 2 [155/250 19840/32000 (62%)] Loss: 3.77229 (QuantReg: 13.22000) QuantErr: 13.22000 batch_time=0.49122 
Train Epoch: 2 [166/250 21248/32000 (66%)] Loss: 3.86418 (QuantReg: 13.10659) QuantErr: 13.10659 batch_time=0.48962 
Train Epoch: 2 [177/250 22656/32000 (71%)] Loss: 3.75562 (QuantReg: 13.26286) QuantErr: 13.26286 batch_time=0.48977 
Train Epoch: 2 [188/250 24064/32000 (75%)] Loss: 3.66688 (QuantReg: 13.56225) QuantErr: 13.56225 batch_time=0.49005 
Train Epoch: 2 [199/250 25472/32000 (80%)] Loss: 3.76441 (QuantReg: 13.37771) QuantErr: 13.37771 batch_time=0.47702 
Train Epoch: 2 [210/250 26880/32000 (84%)] Loss: 3.21566 (QuantReg: 14.14134) QuantErr: 14.14134 batch_time=0.48356 
Train Epoch: 2 [221/250 28288/32000 (88%)] Loss: 3.39800 (QuantReg: 14.33235) QuantErr: 14.33235 batch_time=0.48234 
Train Epoch: 2 [232/250 29696/32000 (93%)] Loss: 3.57317 (QuantReg: 13.53979) QuantErr: 13.53979 batch_time=0.48461 
Train Epoch: 2 [243/250 31104/32000 (97%)] Loss: 3.50857 (QuantReg: 14.14395) QuantErr: 14.14395 batch_time=0.51660 
Train Epoch: 2 codebook_update_time=1.56825
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_MSRVTT_1kA_roberta-base/checkpoint-epoch2.pth ...
Done in 3.901s
Updating 'best' checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_MSRVTT_1kA_roberta-base/checkpoint-epoch2.pth ...
Done in 7.683s
removing stale ckpt [epoch 1] [took 0.00s]
removing stale ckpt [epoch 0] [took 0.00s]
 epoch          : 2
 loss           : 3.7399247140884397
 quant_reg      : 12.718965816497803
 quant_err      : 12.718965816497803
 learning_rate  : 9.5e-05
 n_samples      : 64000
 n_steps        : 500
 MSRVTT_jsfusion_test/t2v_metrics/R1: 12.4
 MSRVTT_jsfusion_test/t2v_metrics/R5: 38.6
 MSRVTT_jsfusion_test/t2v_metrics/R10: 52.9
 MSRVTT_jsfusion_test/t2v_metrics/R50: 82.6
 MSRVTT_jsfusion_test/t2v_metrics/MedR: 9.0
 MSRVTT_jsfusion_test/t2v_metrics/MeanR: 38.477
 MSRVTT_jsfusion_test/t2v_metrics/geometric_mean_R1-R5-R10: 29.36442857266928
 MSRVTT_jsfusion_test/v2t_metrics/R1: 14.7
 MSRVTT_jsfusion_test/v2t_metrics/R5: 41.7
 MSRVTT_jsfusion_test/v2t_metrics/R10: 53.9
 MSRVTT_jsfusion_test/v2t_metrics/R50: 83.0
 MSRVTT_jsfusion_test/v2t_metrics/MedR: 8.0
 MSRVTT_jsfusion_test/v2t_metrics/MeanR: 36.805
 MSRVTT_jsfusion_test/v2t_metrics/geometric_mean_R1-R5-R10: 32.08834992262977
 mnt_best       : 29.36442857266928
 not_improved_count: 0
Train Epoch: 3 [1/250 128/32000 (0%)] Loss: 3.15178 (QuantReg: 11.03813) QuantErr: 11.03813 batch_time=26.70025 
Train Epoch: 3 [12/250 1536/32000 (5%)] Loss: 3.06007 (QuantReg: 11.13581) QuantErr: 11.13581 batch_time=0.49942 
Train Epoch: 3 [23/250 2944/32000 (9%)] Loss: 3.58578 (QuantReg: 11.22079) QuantErr: 11.22079 batch_time=0.47661 
Train Epoch: 3 [34/250 4352/32000 (14%)] Loss: 3.71836 (QuantReg: 11.38439) QuantErr: 11.38439 batch_time=0.48815 
Train Epoch: 3 [45/250 5760/32000 (18%)] Loss: 3.29878 (QuantReg: 11.44952) QuantErr: 11.44952 batch_time=2.08895 
Train Epoch: 3 [56/250 7168/32000 (22%)] Loss: 3.19271 (QuantReg: 11.47770) QuantErr: 11.47770 batch_time=0.48750 
Train Epoch: 3 [67/250 8576/32000 (27%)] Loss: 2.96248 (QuantReg: 11.93103) QuantErr: 11.93103 batch_time=0.48299 
Train Epoch: 3 [78/250 9984/32000 (31%)] Loss: 3.37287 (QuantReg: 11.95112) QuantErr: 11.95112 batch_time=0.59302 
Train Epoch: 3 [89/250 11392/32000 (36%)] Loss: 3.06161 (QuantReg: 11.85408) QuantErr: 11.85408 batch_time=0.48702 
Train Epoch: 3 [100/250 12800/32000 (40%)] Loss: 3.31058 (QuantReg: 11.99900) QuantErr: 11.99900 batch_time=0.70888 
Train Epoch: 3 [111/250 14208/32000 (44%)] Loss: 3.29464 (QuantReg: 12.22749) QuantErr: 12.22749 batch_time=0.48338 
Train Epoch: 3 [122/250 15616/32000 (49%)] Loss: 2.86962 (QuantReg: 12.16106) QuantErr: 12.16106 batch_time=0.48513 
Train Epoch: 3 [133/250 17024/32000 (53%)] Loss: 3.11707 (QuantReg: 11.89912) QuantErr: 11.89912 batch_time=0.52716 
Train Epoch: 3 [144/250 18432/32000 (58%)] Loss: 2.84270 (QuantReg: 12.55656) QuantErr: 12.55656 batch_time=1.18250 
Train Epoch: 3 [155/250 19840/32000 (62%)] Loss: 3.33766 (QuantReg: 12.45936) QuantErr: 12.45936 batch_time=0.49124 
Train Epoch: 3 [166/250 21248/32000 (66%)] Loss: 3.36388 (QuantReg: 12.49098) QuantErr: 12.49098 batch_time=0.48499 
Train Epoch: 3 [177/250 22656/32000 (71%)] Loss: 3.31371 (QuantReg: 12.46542) QuantErr: 12.46542 batch_time=0.71517 
Train Epoch: 3 [188/250 24064/32000 (75%)] Loss: 3.52455 (QuantReg: 12.81858) QuantErr: 12.81858 batch_time=0.47951 
Train Epoch: 3 [199/250 25472/32000 (80%)] Loss: 3.35949 (QuantReg: 12.90587) QuantErr: 12.90587 batch_time=1.15812 
Train Epoch: 3 [210/250 26880/32000 (84%)] Loss: 2.76305 (QuantReg: 12.78317) QuantErr: 12.78317 batch_time=0.49799 
Train Epoch: 3 [221/250 28288/32000 (88%)] Loss: 3.44795 (QuantReg: 12.55824) QuantErr: 12.55824 batch_time=0.48738 
Train Epoch: 3 [232/250 29696/32000 (93%)] Loss: 2.73534 (QuantReg: 13.00282) QuantErr: 13.00282 batch_time=0.47939 
Train Epoch: 3 [243/250 31104/32000 (97%)] Loss: 2.87192 (QuantReg: 12.93090) QuantErr: 12.93090 batch_time=0.47764 
Train Epoch: 3 codebook_update_time=1.58670
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_MSRVTT_1kA_roberta-base/checkpoint-epoch3.pth ...
Done in 4.054s
Updating 'best' checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_MSRVTT_1kA_roberta-base/checkpoint-epoch3.pth ...
Done in 7.970s
removing stale ckpt [epoch 2] [took 0.00s]
 epoch          : 3
 loss           : 3.1283362617492676
 quant_reg      : 12.163154209136962
 quant_err      : 12.163154209136962
 learning_rate  : 9.025e-05
 n_samples      : 96000
 n_steps        : 750
 MSRVTT_jsfusion_test/t2v_metrics/R1: 15.7
 MSRVTT_jsfusion_test/t2v_metrics/R5: 41.4
 MSRVTT_jsfusion_test/t2v_metrics/R10: 56.5
 MSRVTT_jsfusion_test/t2v_metrics/R50: 84.2
 MSRVTT_jsfusion_test/t2v_metrics/MedR: 8.0
 MSRVTT_jsfusion_test/t2v_metrics/MeanR: 34.576
 MSRVTT_jsfusion_test/t2v_metrics/geometric_mean_R1-R5-R10: 33.239117172571916
 MSRVTT_jsfusion_test/v2t_metrics/R1: 16.2
 MSRVTT_jsfusion_test/v2t_metrics/R5: 43.7
 MSRVTT_jsfusion_test/v2t_metrics/R10: 55.9
 MSRVTT_jsfusion_test/v2t_metrics/R50: 83.3
 MSRVTT_jsfusion_test/v2t_metrics/MedR: 8.0
 MSRVTT_jsfusion_test/v2t_metrics/MeanR: 34.732
 MSRVTT_jsfusion_test/v2t_metrics/geometric_mean_R1-R5-R10: 34.07763286970777
 mnt_best       : 33.239117172571916
 not_improved_count: 0
Train Epoch: 4 [1/250 128/32000 (0%)] Loss: 3.06300 (QuantReg: 11.84448) QuantErr: 11.84448 batch_time=27.18164 
Train Epoch: 4 [12/250 1536/32000 (5%)] Loss: 3.54424 (QuantReg: 10.76435) QuantErr: 10.76435 batch_time=0.49415 
Train Epoch: 4 [23/250 2944/32000 (9%)] Loss: 3.38015 (QuantReg: 11.40240) QuantErr: 11.40240 batch_time=0.48159 
Train Epoch: 4 [34/250 4352/32000 (14%)] Loss: 2.64742 (QuantReg: 11.34886) QuantErr: 11.34886 batch_time=0.48140 
Train Epoch: 4 [45/250 5760/32000 (18%)] Loss: 3.01379 (QuantReg: 12.18349) QuantErr: 12.18349 batch_time=0.49461 
Train Epoch: 4 [56/250 7168/32000 (22%)] Loss: 2.55050 (QuantReg: 11.48080) QuantErr: 11.48080 batch_time=0.47714 
Train Epoch: 4 [67/250 8576/32000 (27%)] Loss: 3.40061 (QuantReg: 11.57647) QuantErr: 11.57647 batch_time=0.49128 
Train Epoch: 4 [78/250 9984/32000 (31%)] Loss: 3.15815 (QuantReg: 11.91097) QuantErr: 11.91097 batch_time=0.48135 
Train Epoch: 4 [89/250 11392/32000 (36%)] Loss: 2.73815 (QuantReg: 12.43271) QuantErr: 12.43271 batch_time=0.51588 
Train Epoch: 4 [100/250 12800/32000 (40%)] Loss: 2.57571 (QuantReg: 11.91706) QuantErr: 11.91706 batch_time=0.49455 
Train Epoch: 4 [111/250 14208/32000 (44%)] Loss: 2.63150 (QuantReg: 12.01877) QuantErr: 12.01877 batch_time=0.49695 
Train Epoch: 4 [122/250 15616/32000 (49%)] Loss: 2.42360 (QuantReg: 12.67567) QuantErr: 12.67567 batch_time=1.24645 
Train Epoch: 4 [133/250 17024/32000 (53%)] Loss: 2.85849 (QuantReg: 12.16191) QuantErr: 12.16191 batch_time=0.50880 
Train Epoch: 4 [144/250 18432/32000 (58%)] Loss: 2.68433 (QuantReg: 12.28422) QuantErr: 12.28422 batch_time=1.52101 
Train Epoch: 4 [155/250 19840/32000 (62%)] Loss: 2.68495 (QuantReg: 12.33066) QuantErr: 12.33066 batch_time=0.49722 
Train Epoch: 4 [166/250 21248/32000 (66%)] Loss: 2.86905 (QuantReg: 12.80900) QuantErr: 12.80900 batch_time=0.49390 
Train Epoch: 4 [177/250 22656/32000 (71%)] Loss: 3.10884 (QuantReg: 12.38535) QuantErr: 12.38535 batch_time=0.48715 
Train Epoch: 4 [188/250 24064/32000 (75%)] Loss: 2.65596 (QuantReg: 12.40719) QuantErr: 12.40719 batch_time=0.48579 
Train Epoch: 4 [199/250 25472/32000 (80%)] Loss: 2.63663 (QuantReg: 12.31523) QuantErr: 12.31523 batch_time=0.80468 
Train Epoch: 4 [210/250 26880/32000 (84%)] Loss: 2.64818 (QuantReg: 12.21047) QuantErr: 12.21047 batch_time=0.49285 
Train Epoch: 4 [221/250 28288/32000 (88%)] Loss: 2.51407 (QuantReg: 12.81056) QuantErr: 12.81056 batch_time=0.49143 
Train Epoch: 4 [232/250 29696/32000 (93%)] Loss: 3.15287 (QuantReg: 12.52741) QuantErr: 12.52741 batch_time=0.53050 
Train Epoch: 4 [243/250 31104/32000 (97%)] Loss: 2.86564 (QuantReg: 12.79766) QuantErr: 12.79766 batch_time=0.49037 
Train Epoch: 4 codebook_update_time=1.62475
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_MSRVTT_1kA_roberta-base/checkpoint-epoch4.pth ...
Done in 3.957s
Updating 'best' checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_MSRVTT_1kA_roberta-base/checkpoint-epoch4.pth ...
Done in 7.853s
removing stale ckpt [epoch 3] [took 0.00s]
 epoch          : 4
 loss           : 2.808939471244812
 quant_reg      : 12.140612907409668
 quant_err      : 12.140612907409668
 learning_rate  : 8.573749999999999e-05
 n_samples      : 128000
 n_steps        : 1000
 MSRVTT_jsfusion_test/t2v_metrics/R1: 16.4
 MSRVTT_jsfusion_test/t2v_metrics/R5: 42.9
 MSRVTT_jsfusion_test/t2v_metrics/R10: 58.2
 MSRVTT_jsfusion_test/t2v_metrics/R50: 85.5
 MSRVTT_jsfusion_test/t2v_metrics/MedR: 7.0
 MSRVTT_jsfusion_test/t2v_metrics/MeanR: 31.338
 MSRVTT_jsfusion_test/t2v_metrics/geometric_mean_R1-R5-R10: 34.46736169725739
 MSRVTT_jsfusion_test/v2t_metrics/R1: 16.3
 MSRVTT_jsfusion_test/v2t_metrics/R5: 45.6
 MSRVTT_jsfusion_test/v2t_metrics/R10: 58.5
 MSRVTT_jsfusion_test/v2t_metrics/R50: 85.7
 MSRVTT_jsfusion_test/v2t_metrics/MedR: 7.0
 MSRVTT_jsfusion_test/v2t_metrics/MeanR: 32.195499999999996
 MSRVTT_jsfusion_test/v2t_metrics/geometric_mean_R1-R5-R10: 35.16436433145058
 mnt_best       : 34.46736169725739
 not_improved_count: 0
Train Epoch: 5 [1/250 128/32000 (0%)] Loss: 2.89774 (QuantReg: 11.58838) QuantErr: 11.58838 batch_time=30.39497 
Train Epoch: 5 [12/250 1536/32000 (5%)] Loss: 2.70143 (QuantReg: 11.85547) QuantErr: 11.85547 batch_time=0.47623 
Train Epoch: 5 [23/250 2944/32000 (9%)] Loss: 2.77560 (QuantReg: 12.05634) QuantErr: 12.05634 batch_time=0.49081 
Train Epoch: 5 [34/250 4352/32000 (14%)] Loss: 2.44685 (QuantReg: 11.72468) QuantErr: 11.72468 batch_time=0.48791 
Train Epoch: 5 [45/250 5760/32000 (18%)] Loss: 2.87022 (QuantReg: 12.22706) QuantErr: 12.22706 batch_time=0.49004 
Train Epoch: 5 [56/250 7168/32000 (22%)] Loss: 2.72972 (QuantReg: 11.92283) QuantErr: 11.92283 batch_time=0.49194 
Train Epoch: 5 [67/250 8576/32000 (27%)] Loss: 3.25264 (QuantReg: 11.76211) QuantErr: 11.76211 batch_time=0.54063 
Train Epoch: 5 [78/250 9984/32000 (31%)] Loss: 2.64480 (QuantReg: 12.14319) QuantErr: 12.14319 batch_time=0.49814 
Train Epoch: 5 [89/250 11392/32000 (36%)] Loss: 2.02798 (QuantReg: 12.34831) QuantErr: 12.34831 batch_time=0.54747 
Train Epoch: 5 [100/250 12800/32000 (40%)] Loss: 2.58624 (QuantReg: 11.93959) QuantErr: 11.93959 batch_time=0.49801 
Train Epoch: 5 [111/250 14208/32000 (44%)] Loss: 2.09420 (QuantReg: 11.93083) QuantErr: 11.93083 batch_time=0.49596 
Train Epoch: 5 [122/250 15616/32000 (49%)] Loss: 2.34979 (QuantReg: 12.13651) QuantErr: 12.13651 batch_time=0.82641 
Train Epoch: 5 [133/250 17024/32000 (53%)] Loss: 2.36777 (QuantReg: 12.43271) QuantErr: 12.43271 batch_time=0.47940 
Train Epoch: 5 [144/250 18432/32000 (58%)] Loss: 2.13230 (QuantReg: 12.36703) QuantErr: 12.36703 batch_time=0.49224 
Train Epoch: 5 [155/250 19840/32000 (62%)] Loss: 2.32208 (QuantReg: 12.62380) QuantErr: 12.62380 batch_time=0.48984 
Train Epoch: 5 [166/250 21248/32000 (66%)] Loss: 2.28415 (QuantReg: 12.31069) QuantErr: 12.31069 batch_time=0.53337 
Train Epoch: 5 [177/250 22656/32000 (71%)] Loss: 2.24140 (QuantReg: 12.27098) QuantErr: 12.27098 batch_time=0.48510 
Train Epoch: 5 [188/250 24064/32000 (75%)] Loss: 2.20690 (QuantReg: 12.69590) QuantErr: 12.69590 batch_time=0.49392 
Train Epoch: 5 [199/250 25472/32000 (80%)] Loss: 2.07039 (QuantReg: 12.45418) QuantErr: 12.45418 batch_time=0.48761 
Train Epoch: 5 [210/250 26880/32000 (84%)] Loss: 2.27886 (QuantReg: 12.48251) QuantErr: 12.48251 batch_time=0.49248 
Train Epoch: 5 [221/250 28288/32000 (88%)] Loss: 2.28371 (QuantReg: 12.45471) QuantErr: 12.45471 batch_time=0.49063 
Train Epoch: 5 [232/250 29696/32000 (93%)] Loss: 2.24813 (QuantReg: 12.66427) QuantErr: 12.66427 batch_time=0.49366 
Train Epoch: 5 [243/250 31104/32000 (97%)] Loss: 2.61138 (QuantReg: 12.59312) QuantErr: 12.59312 batch_time=1.25534 
Train Epoch: 5 codebook_update_time=1.58527
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_MSRVTT_1kA_roberta-base/checkpoint-epoch5.pth ...
Done in 9.594s
Updating 'best' checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_MSRVTT_1kA_roberta-base/checkpoint-epoch5.pth ...
Done in 13.734s
removing stale ckpt [epoch 4] [took 0.00s]
 epoch          : 5
 loss           : 2.4375512285232546
 quant_reg      : 12.257071594238282
 quant_err      : 12.257071594238282
 learning_rate  : 8.145062499999998e-05
 n_samples      : 160000
 n_steps        : 1250
 MSRVTT_jsfusion_test/t2v_metrics/R1: 18.1
 MSRVTT_jsfusion_test/t2v_metrics/R5: 46.1
 MSRVTT_jsfusion_test/t2v_metrics/R10: 59.9
 MSRVTT_jsfusion_test/t2v_metrics/R50: 86.7
 MSRVTT_jsfusion_test/t2v_metrics/MedR: 7.0
 MSRVTT_jsfusion_test/t2v_metrics/MeanR: 28.272
 MSRVTT_jsfusion_test/t2v_metrics/geometric_mean_R1-R5-R10: 36.83568701588683
 MSRVTT_jsfusion_test/v2t_metrics/R1: 17.2
 MSRVTT_jsfusion_test/v2t_metrics/R5: 47.4
 MSRVTT_jsfusion_test/v2t_metrics/R10: 60.3
 MSRVTT_jsfusion_test/v2t_metrics/R50: 86.9
 MSRVTT_jsfusion_test/v2t_metrics/MedR: 6.0
 MSRVTT_jsfusion_test/v2t_metrics/MeanR: 26.862
 MSRVTT_jsfusion_test/v2t_metrics/geometric_mean_R1-R5-R10: 36.63318677622725
 mnt_best       : 36.83568701588683
 not_improved_count: 0
Train Epoch: 6 [1/250 128/32000 (0%)] Loss: 2.41294 (QuantReg: 11.91495) QuantErr: 11.91495 batch_time=29.25734 
Train Epoch: 6 [12/250 1536/32000 (5%)] Loss: 2.84078 (QuantReg: 11.70439) QuantErr: 11.70439 batch_time=0.48424 
Train Epoch: 6 [23/250 2944/32000 (9%)] Loss: 2.47814 (QuantReg: 12.13412) QuantErr: 12.13412 batch_time=0.48945 
Train Epoch: 6 [34/250 4352/32000 (14%)] Loss: 2.60994 (QuantReg: 12.03449) QuantErr: 12.03449 batch_time=0.47681 
Train Epoch: 6 [45/250 5760/32000 (18%)] Loss: 2.35396 (QuantReg: 12.17746) QuantErr: 12.17746 batch_time=0.49132 
Train Epoch: 6 [56/250 7168/32000 (22%)] Loss: 2.24814 (QuantReg: 12.35949) QuantErr: 12.35949 batch_time=0.49446 
Train Epoch: 6 [67/250 8576/32000 (27%)] Loss: 2.37996 (QuantReg: 12.07577) QuantErr: 12.07577 batch_time=0.48553 
Train Epoch: 6 [78/250 9984/32000 (31%)] Loss: 2.35173 (QuantReg: 12.36160) QuantErr: 12.36160 batch_time=0.47510 
Train Epoch: 6 [89/250 11392/32000 (36%)] Loss: 2.21855 (QuantReg: 12.10989) QuantErr: 12.10989 batch_time=0.49193 
Train Epoch: 6 [100/250 12800/32000 (40%)] Loss: 2.13394 (QuantReg: 12.20411) QuantErr: 12.20411 batch_time=0.60585 
Train Epoch: 6 [111/250 14208/32000 (44%)] Loss: 2.04014 (QuantReg: 12.29963) QuantErr: 12.29963 batch_time=0.71555 
Train Epoch: 6 [122/250 15616/32000 (49%)] Loss: 2.31610 (QuantReg: 12.24338) QuantErr: 12.24338 batch_time=0.48990 
Train Epoch: 6 [133/250 17024/32000 (53%)] Loss: 2.25748 (QuantReg: 12.47534) QuantErr: 12.47534 batch_time=1.40772 
Train Epoch: 6 [144/250 18432/32000 (58%)] Loss: 2.42721 (QuantReg: 12.47520) QuantErr: 12.47520 batch_time=0.49137 
Train Epoch: 6 [155/250 19840/32000 (62%)] Loss: 2.36910 (QuantReg: 12.50132) QuantErr: 12.50132 batch_time=0.49583 
Train Epoch: 6 [166/250 21248/32000 (66%)] Loss: 2.15343 (QuantReg: 12.51692) QuantErr: 12.51692 batch_time=0.48633 
Train Epoch: 6 [177/250 22656/32000 (71%)] Loss: 1.92438 (QuantReg: 12.09575) QuantErr: 12.09575 batch_time=0.48350 
Train Epoch: 6 [188/250 24064/32000 (75%)] Loss: 2.13901 (QuantReg: 12.64707) QuantErr: 12.64707 batch_time=0.49306 
Train Epoch: 6 [199/250 25472/32000 (80%)] Loss: 2.24646 (QuantReg: 12.57708) QuantErr: 12.57708 batch_time=0.48378 
Train Epoch: 6 [210/250 26880/32000 (84%)] Loss: 2.13720 (QuantReg: 12.76378) QuantErr: 12.76378 batch_time=1.34892 
Train Epoch: 6 [221/250 28288/32000 (88%)] Loss: 2.14121 (QuantReg: 12.80715) QuantErr: 12.80715 batch_time=0.47698 
Train Epoch: 6 [232/250 29696/32000 (93%)] Loss: 2.01622 (QuantReg: 12.83145) QuantErr: 12.83145 batch_time=0.48412 
Train Epoch: 6 [243/250 31104/32000 (97%)] Loss: 2.24617 (QuantReg: 12.48486) QuantErr: 12.48486 batch_time=0.48058 
Train Epoch: 6 codebook_update_time=1.66467
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_MSRVTT_1kA_roberta-base/checkpoint-epoch6.pth ...
Done in 3.668s
Updating 'best' checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_MSRVTT_1kA_roberta-base/checkpoint-epoch6.pth ...
Done in 7.747s
removing stale ckpt [epoch 5] [took 0.00s]
 epoch          : 6
 loss           : 2.255416241645813
 quant_reg      : 12.342533512115478
 quant_err      : 12.342533512115478
 learning_rate  : 7.737809374999998e-05
 n_samples      : 192000
 n_steps        : 1500
 MSRVTT_jsfusion_test/t2v_metrics/R1: 19.2
 MSRVTT_jsfusion_test/t2v_metrics/R5: 48.6
 MSRVTT_jsfusion_test/t2v_metrics/R10: 62.5
 MSRVTT_jsfusion_test/t2v_metrics/R50: 88.2
 MSRVTT_jsfusion_test/t2v_metrics/MedR: 6.0
 MSRVTT_jsfusion_test/t2v_metrics/MeanR: 27.762
 MSRVTT_jsfusion_test/t2v_metrics/geometric_mean_R1-R5-R10: 38.7798244205739
 MSRVTT_jsfusion_test/v2t_metrics/R1: 19.7
 MSRVTT_jsfusion_test/v2t_metrics/R5: 48.2
 MSRVTT_jsfusion_test/v2t_metrics/R10: 62.8
 MSRVTT_jsfusion_test/v2t_metrics/R50: 87.1
 MSRVTT_jsfusion_test/v2t_metrics/MedR: 6.0
 MSRVTT_jsfusion_test/v2t_metrics/MeanR: 27.5135
 MSRVTT_jsfusion_test/v2t_metrics/geometric_mean_R1-R5-R10: 39.068280997847424
 mnt_best       : 38.7798244205739
 not_improved_count: 0
Train Epoch: 7 [1/250 128/32000 (0%)] Loss: 2.05536 (QuantReg: 11.59041) QuantErr: 11.59041 batch_time=25.86617 
Train Epoch: 7 [12/250 1536/32000 (5%)] Loss: 2.14430 (QuantReg: 12.11360) QuantErr: 12.11360 batch_time=0.47282 
Train Epoch: 7 [23/250 2944/32000 (9%)] Loss: 1.88668 (QuantReg: 12.34693) QuantErr: 12.34693 batch_time=0.48341 
Train Epoch: 7 [34/250 4352/32000 (14%)] Loss: 2.42834 (QuantReg: 12.24511) QuantErr: 12.24511 batch_time=0.48752 
Train Epoch: 7 [45/250 5760/32000 (18%)] Loss: 2.20325 (QuantReg: 12.18710) QuantErr: 12.18710 batch_time=0.48853 
Train Epoch: 7 [56/250 7168/32000 (22%)] Loss: 1.81228 (QuantReg: 12.42776) QuantErr: 12.42776 batch_time=0.49744 
Train Epoch: 7 [67/250 8576/32000 (27%)] Loss: 1.89141 (QuantReg: 12.69475) QuantErr: 12.69475 batch_time=0.47473 
Train Epoch: 7 [78/250 9984/32000 (31%)] Loss: 1.72835 (QuantReg: 12.67097) QuantErr: 12.67097 batch_time=0.47686 
Train Epoch: 7 [89/250 11392/32000 (36%)] Loss: 1.86961 (QuantReg: 12.55931) QuantErr: 12.55931 batch_time=0.48042 
Train Epoch: 7 [100/250 12800/32000 (40%)] Loss: 1.45854 (QuantReg: 12.90419) QuantErr: 12.90419 batch_time=0.47996 
Train Epoch: 7 [111/250 14208/32000 (44%)] Loss: 2.68176 (QuantReg: 12.23573) QuantErr: 12.23573 batch_time=0.48077 
Train Epoch: 7 [122/250 15616/32000 (49%)] Loss: 2.04609 (QuantReg: 12.78741) QuantErr: 12.78741 batch_time=0.49053 
Train Epoch: 7 [133/250 17024/32000 (53%)] Loss: 2.17915 (QuantReg: 12.63390) QuantErr: 12.63390 batch_time=0.48608 
Train Epoch: 7 [144/250 18432/32000 (58%)] Loss: 2.15453 (QuantReg: 12.76260) QuantErr: 12.76260 batch_time=0.47464 
Train Epoch: 7 [155/250 19840/32000 (62%)] Loss: 2.63151 (QuantReg: 12.25673) QuantErr: 12.25673 batch_time=0.49662 
Train Epoch: 7 [166/250 21248/32000 (66%)] Loss: 2.66394 (QuantReg: 12.29717) QuantErr: 12.29717 batch_time=0.49343 
Train Epoch: 7 [177/250 22656/32000 (71%)] Loss: 1.92588 (QuantReg: 12.81239) QuantErr: 12.81239 batch_time=0.48698 
Train Epoch: 7 [188/250 24064/32000 (75%)] Loss: 2.16696 (QuantReg: 12.20279) QuantErr: 12.20279 batch_time=0.49073 
Train Epoch: 7 [199/250 25472/32000 (80%)] Loss: 1.91448 (QuantReg: 12.55758) QuantErr: 12.55758 batch_time=0.48205 
Train Epoch: 7 [210/250 26880/32000 (84%)] Loss: 2.30352 (QuantReg: 12.69962) QuantErr: 12.69962 batch_time=0.52325 
Train Epoch: 7 [221/250 28288/32000 (88%)] Loss: 2.08887 (QuantReg: 12.73307) QuantErr: 12.73307 batch_time=0.49789 
Train Epoch: 7 [232/250 29696/32000 (93%)] Loss: 2.37808 (QuantReg: 12.68667) QuantErr: 12.68667 batch_time=0.47273 
Train Epoch: 7 [243/250 31104/32000 (97%)] Loss: 1.97285 (QuantReg: 12.78296) QuantErr: 12.78296 batch_time=0.54664 
Train Epoch: 7 codebook_update_time=1.60531
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_MSRVTT_1kA_roberta-base/checkpoint-epoch7.pth ...
Done in 4.333s
removing stale ckpt [epoch 6] [took 0.00s]
 epoch          : 7
 loss           : 2.0865332236289977
 quant_reg      : 12.498834690093995
 quant_err      : 12.498834690093995
 learning_rate  : 7.350918906249998e-05
 n_samples      : 224000
 n_steps        : 1750
 MSRVTT_jsfusion_test/t2v_metrics/R1: 19.1
 MSRVTT_jsfusion_test/t2v_metrics/R5: 47.1
 MSRVTT_jsfusion_test/t2v_metrics/R10: 61.5
 MSRVTT_jsfusion_test/t2v_metrics/R50: 87.2
 MSRVTT_jsfusion_test/t2v_metrics/MedR: 6.0
 MSRVTT_jsfusion_test/t2v_metrics/MeanR: 27.79
 MSRVTT_jsfusion_test/t2v_metrics/geometric_mean_R1-R5-R10: 38.10451720677924
 MSRVTT_jsfusion_test/v2t_metrics/R1: 19.4
 MSRVTT_jsfusion_test/v2t_metrics/R5: 47.2
 MSRVTT_jsfusion_test/v2t_metrics/R10: 61.8
 MSRVTT_jsfusion_test/v2t_metrics/R50: 87.4
 MSRVTT_jsfusion_test/v2t_metrics/MedR: 6.0
 MSRVTT_jsfusion_test/v2t_metrics/MeanR: 26.828
 MSRVTT_jsfusion_test/v2t_metrics/geometric_mean_R1-R5-R10: 38.3922944608152
 mnt_best       : 38.7798244205739
 not_improved_count: 1
Train Epoch: 8 [1/250 128/32000 (0%)] Loss: 1.98904 (QuantReg: 11.93523) QuantErr: 11.93523 batch_time=31.93371 
Train Epoch: 8 [12/250 1536/32000 (5%)] Loss: 2.16851 (QuantReg: 12.43986) QuantErr: 12.43986 batch_time=0.47591 
Train Epoch: 8 [23/250 2944/32000 (9%)] Loss: 2.23057 (QuantReg: 12.47167) QuantErr: 12.47167 batch_time=0.47465 
Train Epoch: 8 [34/250 4352/32000 (14%)] Loss: 2.33309 (QuantReg: 12.39509) QuantErr: 12.39509 batch_time=0.49286 
Train Epoch: 8 [45/250 5760/32000 (18%)] Loss: 1.54938 (QuantReg: 12.51083) QuantErr: 12.51083 batch_time=0.47784 
Train Epoch: 8 [56/250 7168/32000 (22%)] Loss: 1.78841 (QuantReg: 12.09640) QuantErr: 12.09640 batch_time=0.48859 
Train Epoch: 8 [67/250 8576/32000 (27%)] Loss: 1.76342 (QuantReg: 12.19335) QuantErr: 12.19335 batch_time=0.47674 
Train Epoch: 8 [78/250 9984/32000 (31%)] Loss: 1.83692 (QuantReg: 12.48532) QuantErr: 12.48532 batch_time=0.47886 
Train Epoch: 8 [89/250 11392/32000 (36%)] Loss: 2.42906 (QuantReg: 12.11625) QuantErr: 12.11625 batch_time=0.59653 
Train Epoch: 8 [100/250 12800/32000 (40%)] Loss: 2.16212 (QuantReg: 12.23075) QuantErr: 12.23075 batch_time=0.49976 
Train Epoch: 8 [111/250 14208/32000 (44%)] Loss: 1.87364 (QuantReg: 12.70621) QuantErr: 12.70621 batch_time=0.49121 
Train Epoch: 8 [122/250 15616/32000 (49%)] Loss: 1.94881 (QuantReg: 12.63151) QuantErr: 12.63151 batch_time=0.48696 
Train Epoch: 8 [133/250 17024/32000 (53%)] Loss: 2.02373 (QuantReg: 12.21127) QuantErr: 12.21127 batch_time=0.50310 
Train Epoch: 8 [144/250 18432/32000 (58%)] Loss: 2.09444 (QuantReg: 12.79032) QuantErr: 12.79032 batch_time=0.48789 
Train Epoch: 8 [155/250 19840/32000 (62%)] Loss: 1.91097 (QuantReg: 12.51278) QuantErr: 12.51278 batch_time=0.69265 
Train Epoch: 8 [166/250 21248/32000 (66%)] Loss: 2.16385 (QuantReg: 12.50268) QuantErr: 12.50268 batch_time=0.48912 
Train Epoch: 8 [177/250 22656/32000 (71%)] Loss: 1.47028 (QuantReg: 12.65635) QuantErr: 12.65635 batch_time=0.48614 
Train Epoch: 8 [188/250 24064/32000 (75%)] Loss: 2.29269 (QuantReg: 12.41413) QuantErr: 12.41413 batch_time=0.49007 
Train Epoch: 8 [199/250 25472/32000 (80%)] Loss: 1.90664 (QuantReg: 12.65866) QuantErr: 12.65866 batch_time=0.60781 
Train Epoch: 8 [210/250 26880/32000 (84%)] Loss: 1.84593 (QuantReg: 12.76096) QuantErr: 12.76096 batch_time=0.84388 
Train Epoch: 8 [221/250 28288/32000 (88%)] Loss: 1.79270 (QuantReg: 12.65623) QuantErr: 12.65623 batch_time=0.51617 
Train Epoch: 8 [232/250 29696/32000 (93%)] Loss: 1.70496 (QuantReg: 12.45304) QuantErr: 12.45304 batch_time=0.47928 
Train Epoch: 8 [243/250 31104/32000 (97%)] Loss: 1.61879 (QuantReg: 12.82245) QuantErr: 12.82245 batch_time=0.49176 
Train Epoch: 8 codebook_update_time=1.59266
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_MSRVTT_1kA_roberta-base/checkpoint-epoch8.pth ...
Done in 4.144s
Updating 'best' checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_MSRVTT_1kA_roberta-base/checkpoint-epoch8.pth ...
Done in 7.929s
removing stale ckpt [epoch 7] [took 0.00s]
 epoch          : 8
 loss           : 1.9299684081077575
 quant_reg      : 12.55632773590088
 quant_err      : 12.55632773590088
 learning_rate  : 6.983372960937497e-05
 n_samples      : 256000
 n_steps        : 2000
 MSRVTT_jsfusion_test/t2v_metrics/R1: 20.8
 MSRVTT_jsfusion_test/t2v_metrics/R5: 48.7
 MSRVTT_jsfusion_test/t2v_metrics/R10: 63.1
 MSRVTT_jsfusion_test/t2v_metrics/R50: 88.1
 MSRVTT_jsfusion_test/t2v_metrics/MedR: 6.0
 MSRVTT_jsfusion_test/t2v_metrics/MeanR: 26.056
 MSRVTT_jsfusion_test/t2v_metrics/geometric_mean_R1-R5-R10: 39.982862658837
 MSRVTT_jsfusion_test/v2t_metrics/R1: 19.6
 MSRVTT_jsfusion_test/v2t_metrics/R5: 50.1
 MSRVTT_jsfusion_test/v2t_metrics/R10: 62.7
 MSRVTT_jsfusion_test/v2t_metrics/R50: 88.0
 MSRVTT_jsfusion_test/v2t_metrics/MedR: 5.0
 MSRVTT_jsfusion_test/v2t_metrics/MeanR: 25.8405
 MSRVTT_jsfusion_test/v2t_metrics/geometric_mean_R1-R5-R10: 39.48696723273632
 mnt_best       : 39.982862658837
 not_improved_count: 0
Train Epoch: 9 [1/250 128/32000 (0%)] Loss: 1.80150 (QuantReg: 12.49873) QuantErr: 12.49873 batch_time=34.05183 
Train Epoch: 9 [12/250 1536/32000 (5%)] Loss: 1.88849 (QuantReg: 12.22593) QuantErr: 12.22593 batch_time=0.48113 
Train Epoch: 9 [23/250 2944/32000 (9%)] Loss: 1.59646 (QuantReg: 12.61866) QuantErr: 12.61866 batch_time=0.48088 
Train Epoch: 9 [34/250 4352/32000 (14%)] Loss: 2.25994 (QuantReg: 12.38442) QuantErr: 12.38442 batch_time=0.47885 
Train Epoch: 9 [45/250 5760/32000 (18%)] Loss: 1.61608 (QuantReg: 12.48756) QuantErr: 12.48756 batch_time=0.61046 
Train Epoch: 9 [56/250 7168/32000 (22%)] Loss: 1.87112 (QuantReg: 12.41489) QuantErr: 12.41489 batch_time=0.72507 
Train Epoch: 9 [67/250 8576/32000 (27%)] Loss: 1.92773 (QuantReg: 12.45654) QuantErr: 12.45654 batch_time=0.53497 
Train Epoch: 9 [78/250 9984/32000 (31%)] Loss: 1.65231 (QuantReg: 12.47909) QuantErr: 12.47909 batch_time=0.53008 
Train Epoch: 9 [89/250 11392/32000 (36%)] Loss: 1.67191 (QuantReg: 12.44047) QuantErr: 12.44047 batch_time=0.52046 
Train Epoch: 9 [100/250 12800/32000 (40%)] Loss: 1.95157 (QuantReg: 12.62650) QuantErr: 12.62650 batch_time=0.79599 
Train Epoch: 9 [111/250 14208/32000 (44%)] Loss: 1.90296 (QuantReg: 12.66943) QuantErr: 12.66943 batch_time=0.49319 
Train Epoch: 9 [122/250 15616/32000 (49%)] Loss: 1.95108 (QuantReg: 12.62761) QuantErr: 12.62761 batch_time=0.49755 
Train Epoch: 9 [133/250 17024/32000 (53%)] Loss: 1.79747 (QuantReg: 12.50569) QuantErr: 12.50569 batch_time=0.62007 
Train Epoch: 9 [144/250 18432/32000 (58%)] Loss: 1.65645 (QuantReg: 12.39413) QuantErr: 12.39413 batch_time=1.53003 
Train Epoch: 9 [155/250 19840/32000 (62%)] Loss: 1.54549 (QuantReg: 12.94353) QuantErr: 12.94353 batch_time=0.49245 
Train Epoch: 9 [166/250 21248/32000 (66%)] Loss: 1.96887 (QuantReg: 12.67731) QuantErr: 12.67731 batch_time=0.47942 
Train Epoch: 9 [177/250 22656/32000 (71%)] Loss: 1.55461 (QuantReg: 12.54632) QuantErr: 12.54632 batch_time=0.48314 
Train Epoch: 9 [188/250 24064/32000 (75%)] Loss: 1.84935 (QuantReg: 12.60620) QuantErr: 12.60620 batch_time=0.48375 
Train Epoch: 9 [199/250 25472/32000 (80%)] Loss: 1.96604 (QuantReg: 12.69258) QuantErr: 12.69258 batch_time=0.49453 
Train Epoch: 9 [210/250 26880/32000 (84%)] Loss: 2.05535 (QuantReg: 12.74539) QuantErr: 12.74539 batch_time=0.47697 
Train Epoch: 9 [221/250 28288/32000 (88%)] Loss: 2.34000 (QuantReg: 12.55416) QuantErr: 12.55416 batch_time=0.50054 
Train Epoch: 9 [232/250 29696/32000 (93%)] Loss: 2.02732 (QuantReg: 12.71974) QuantErr: 12.71974 batch_time=0.52520 
Train Epoch: 9 [243/250 31104/32000 (97%)] Loss: 1.54750 (QuantReg: 12.92064) QuantErr: 12.92064 batch_time=0.50388 
Train Epoch: 9 codebook_update_time=1.60541
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_MSRVTT_1kA_roberta-base/checkpoint-epoch9.pth ...
Done in 4.207s
removing stale ckpt [epoch 8] [took 0.00s]
 epoch          : 9
 loss           : 1.7930238671302796
 quant_reg      : 12.590286758422852
 quant_err      : 12.590286758422852
 learning_rate  : 6.634204312890622e-05
 n_samples      : 288000
 n_steps        : 2250
 MSRVTT_jsfusion_test/t2v_metrics/R1: 19.4
 MSRVTT_jsfusion_test/t2v_metrics/R5: 48.3
 MSRVTT_jsfusion_test/t2v_metrics/R10: 62.7
 MSRVTT_jsfusion_test/t2v_metrics/R50: 88.1
 MSRVTT_jsfusion_test/t2v_metrics/MedR: 6.0
 MSRVTT_jsfusion_test/t2v_metrics/MeanR: 25.134
 MSRVTT_jsfusion_test/t2v_metrics/geometric_mean_R1-R5-R10: 38.87515501914658
 MSRVTT_jsfusion_test/v2t_metrics/R1: 20.0
 MSRVTT_jsfusion_test/v2t_metrics/R5: 48.4
 MSRVTT_jsfusion_test/v2t_metrics/R10: 63.3
 MSRVTT_jsfusion_test/v2t_metrics/R50: 88.9
 MSRVTT_jsfusion_test/v2t_metrics/MedR: 6.0
 MSRVTT_jsfusion_test/v2t_metrics/MeanR: 24.8895
 MSRVTT_jsfusion_test/v2t_metrics/geometric_mean_R1-R5-R10: 39.423909491713985
 mnt_best       : 39.982862658837
 not_improved_count: 1
Train Epoch: 10 [1/250 128/32000 (0%)] Loss: 1.73845 (QuantReg: 12.38152) QuantErr: 12.38152 batch_time=28.96621 
Train Epoch: 10 [12/250 1536/32000 (5%)] Loss: 1.92685 (QuantReg: 12.32197) QuantErr: 12.32197 batch_time=0.49426 
Train Epoch: 10 [23/250 2944/32000 (9%)] Loss: 1.72292 (QuantReg: 12.61821) QuantErr: 12.61821 batch_time=0.48332 
Train Epoch: 10 [34/250 4352/32000 (14%)] Loss: 1.36728 (QuantReg: 12.62850) QuantErr: 12.62850 batch_time=0.48250 
Train Epoch: 10 [45/250 5760/32000 (18%)] Loss: 1.45317 (QuantReg: 12.76411) QuantErr: 12.76411 batch_time=0.48403 
Train Epoch: 10 [56/250 7168/32000 (22%)] Loss: 2.12765 (QuantReg: 12.60278) QuantErr: 12.60278 batch_time=0.48790 
Train Epoch: 10 [67/250 8576/32000 (27%)] Loss: 1.73666 (QuantReg: 12.60190) QuantErr: 12.60190 batch_time=0.48665 
Train Epoch: 10 [78/250 9984/32000 (31%)] Loss: 1.69921 (QuantReg: 12.57515) QuantErr: 12.57515 batch_time=0.49923 
Train Epoch: 10 [89/250 11392/32000 (36%)] Loss: 1.80952 (QuantReg: 12.15483) QuantErr: 12.15483 batch_time=0.53507 
Train Epoch: 10 [100/250 12800/32000 (40%)] Loss: 1.98236 (QuantReg: 12.51050) QuantErr: 12.51050 batch_time=0.48429 
Train Epoch: 10 [111/250 14208/32000 (44%)] Loss: 1.77192 (QuantReg: 12.67617) QuantErr: 12.67617 batch_time=0.48683 
Train Epoch: 10 [122/250 15616/32000 (49%)] Loss: 1.50730 (QuantReg: 12.52141) QuantErr: 12.52141 batch_time=0.47932 
Train Epoch: 10 [133/250 17024/32000 (53%)] Loss: 1.50456 (QuantReg: 12.97289) QuantErr: 12.97289 batch_time=0.48291 
Train Epoch: 10 [144/250 18432/32000 (58%)] Loss: 2.16583 (QuantReg: 12.59621) QuantErr: 12.59621 batch_time=0.65308 
Train Epoch: 10 [155/250 19840/32000 (62%)] Loss: 1.47780 (QuantReg: 12.90536) QuantErr: 12.90536 batch_time=0.47514 
Train Epoch: 10 [166/250 21248/32000 (66%)] Loss: 1.95613 (QuantReg: 12.71877) QuantErr: 12.71877 batch_time=0.49153 
Train Epoch: 10 [177/250 22656/32000 (71%)] Loss: 1.45937 (QuantReg: 12.67209) QuantErr: 12.67209 batch_time=0.47908 
Train Epoch: 10 [188/250 24064/32000 (75%)] Loss: 2.35043 (QuantReg: 12.68090) QuantErr: 12.68090 batch_time=0.47930 
Train Epoch: 10 [199/250 25472/32000 (80%)] Loss: 1.97876 (QuantReg: 12.86640) QuantErr: 12.86640 batch_time=0.51616 
Train Epoch: 10 [210/250 26880/32000 (84%)] Loss: 2.11996 (QuantReg: 12.92795) QuantErr: 12.92795 batch_time=1.00739 
Train Epoch: 10 [221/250 28288/32000 (88%)] Loss: 1.72061 (QuantReg: 12.67925) QuantErr: 12.67925 batch_time=0.48515 
Train Epoch: 10 [232/250 29696/32000 (93%)] Loss: 1.84988 (QuantReg: 12.56503) QuantErr: 12.56503 batch_time=0.55129 
Train Epoch: 10 [243/250 31104/32000 (97%)] Loss: 1.50238 (QuantReg: 12.82526) QuantErr: 12.82526 batch_time=0.60645 
Train Epoch: 10 codebook_update_time=1.58768
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_MSRVTT_1kA_roberta-base/checkpoint-epoch10.pth ...
Done in 3.904s
removing stale ckpt [epoch 9] [took 0.03s]
 epoch          : 10
 loss           : 1.714939702987671
 quant_reg      : 12.675204723358155
 quant_err      : 12.675204723358155
 learning_rate  : 6.30249409724609e-05
 n_samples      : 320000
 n_steps        : 2500
 MSRVTT_jsfusion_test/t2v_metrics/R1: 19.7
 MSRVTT_jsfusion_test/t2v_metrics/R5: 48.5
 MSRVTT_jsfusion_test/t2v_metrics/R10: 63.9
 MSRVTT_jsfusion_test/t2v_metrics/R50: 88.9
 MSRVTT_jsfusion_test/t2v_metrics/MedR: 6.0
 MSRVTT_jsfusion_test/t2v_metrics/MeanR: 25.126
 MSRVTT_jsfusion_test/t2v_metrics/geometric_mean_R1-R5-R10: 39.37642413594324
 MSRVTT_jsfusion_test/v2t_metrics/R1: 21.4
 MSRVTT_jsfusion_test/v2t_metrics/R5: 50.3
 MSRVTT_jsfusion_test/v2t_metrics/R10: 63.2
 MSRVTT_jsfusion_test/v2t_metrics/R50: 89.2
 MSRVTT_jsfusion_test/v2t_metrics/MedR: 5.5
 MSRVTT_jsfusion_test/v2t_metrics/MeanR: 23.319
 MSRVTT_jsfusion_test/v2t_metrics/geometric_mean_R1-R5-R10: 40.82250136487754
 mnt_best       : 39.982862658837
 not_improved_count: 2
Train Epoch: 11 [1/250 128/32000 (0%)] Loss: 1.51887 (QuantReg: 12.37076) QuantErr: 12.37076 batch_time=23.32701 
Train Epoch: 11 [12/250 1536/32000 (5%)] Loss: 1.61270 (QuantReg: 12.80917) QuantErr: 12.80917 batch_time=0.52350 
Train Epoch: 11 [23/250 2944/32000 (9%)] Loss: 1.74465 (QuantReg: 12.44467) QuantErr: 12.44467 batch_time=0.47342 
Train Epoch: 11 [34/250 4352/32000 (14%)] Loss: 1.77197 (QuantReg: 12.40222) QuantErr: 12.40222 batch_time=0.49851 
Train Epoch: 11 [45/250 5760/32000 (18%)] Loss: 1.65589 (QuantReg: 12.82126) QuantErr: 12.82126 batch_time=0.49599 
Train Epoch: 11 [56/250 7168/32000 (22%)] Loss: 1.55550 (QuantReg: 12.52989) QuantErr: 12.52989 batch_time=0.49188 
Train Epoch: 11 [67/250 8576/32000 (27%)] Loss: 1.74116 (QuantReg: 13.02409) QuantErr: 13.02409 batch_time=0.48006 
Train Epoch: 11 [78/250 9984/32000 (31%)] Loss: 1.50774 (QuantReg: 12.81854) QuantErr: 12.81854 batch_time=0.47540 
Train Epoch: 11 [89/250 11392/32000 (36%)] Loss: 2.22177 (QuantReg: 12.42133) QuantErr: 12.42133 batch_time=0.48838 
Train Epoch: 11 [100/250 12800/32000 (40%)] Loss: 1.53107 (QuantReg: 12.66232) QuantErr: 12.66232 batch_time=0.59382 
Train Epoch: 11 [111/250 14208/32000 (44%)] Loss: 1.32439 (QuantReg: 12.70685) QuantErr: 12.70685 batch_time=0.48678 
Train Epoch: 11 [122/250 15616/32000 (49%)] Loss: 1.77809 (QuantReg: 12.79892) QuantErr: 12.79892 batch_time=0.49113 
Train Epoch: 11 [133/250 17024/32000 (53%)] Loss: 1.85601 (QuantReg: 12.91447) QuantErr: 12.91447 batch_time=0.70629 
Train Epoch: 11 [144/250 18432/32000 (58%)] Loss: 1.54449 (QuantReg: 13.16202) QuantErr: 13.16202 batch_time=2.01950 
Train Epoch: 11 [155/250 19840/32000 (62%)] Loss: 1.86760 (QuantReg: 12.73079) QuantErr: 12.73079 batch_time=0.48729 
Train Epoch: 11 [166/250 21248/32000 (66%)] Loss: 1.82189 (QuantReg: 12.73665) QuantErr: 12.73665 batch_time=0.49188 
Train Epoch: 11 [177/250 22656/32000 (71%)] Loss: 1.62684 (QuantReg: 12.93566) QuantErr: 12.93566 batch_time=0.49608 
Train Epoch: 11 [188/250 24064/32000 (75%)] Loss: 1.65344 (QuantReg: 12.89565) QuantErr: 12.89565 batch_time=0.48521 
Train Epoch: 11 [199/250 25472/32000 (80%)] Loss: 1.54493 (QuantReg: 12.94157) QuantErr: 12.94157 batch_time=0.49839 
Train Epoch: 11 [210/250 26880/32000 (84%)] Loss: 1.60680 (QuantReg: 12.66587) QuantErr: 12.66587 batch_time=0.49567 
Train Epoch: 11 [221/250 28288/32000 (88%)] Loss: 1.73722 (QuantReg: 12.67920) QuantErr: 12.67920 batch_time=0.48154 
Train Epoch: 11 [232/250 29696/32000 (93%)] Loss: 1.43002 (QuantReg: 12.82396) QuantErr: 12.82396 batch_time=0.48741 
Train Epoch: 11 [243/250 31104/32000 (97%)] Loss: 1.44807 (QuantReg: 13.34846) QuantErr: 13.34846 batch_time=0.48009 
Train Epoch: 11 codebook_update_time=1.64598
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_MSRVTT_1kA_roberta-base/checkpoint-epoch11.pth ...
Done in 4.182s
Updating 'best' checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_MSRVTT_1kA_roberta-base/checkpoint-epoch11.pth ...
Done in 8.037s
removing stale ckpt [epoch 10] [took 0.00s]
 epoch          : 11
 loss           : 1.6231155576705933
 quant_reg      : 12.763282180786133
 quant_err      : 12.763282180786133
 learning_rate  : 5.987369392383786e-05
 n_samples      : 352000
 n_steps        : 2750
 MSRVTT_jsfusion_test/t2v_metrics/R1: 20.9
 MSRVTT_jsfusion_test/t2v_metrics/R5: 49.1
 MSRVTT_jsfusion_test/t2v_metrics/R10: 63.1
 MSRVTT_jsfusion_test/t2v_metrics/R50: 88.6
 MSRVTT_jsfusion_test/t2v_metrics/MedR: 6.0
 MSRVTT_jsfusion_test/t2v_metrics/MeanR: 24.343
 MSRVTT_jsfusion_test/t2v_metrics/geometric_mean_R1-R5-R10: 40.15617878602743
 MSRVTT_jsfusion_test/v2t_metrics/R1: 21.3
 MSRVTT_jsfusion_test/v2t_metrics/R5: 50.8
 MSRVTT_jsfusion_test/v2t_metrics/R10: 64.1
 MSRVTT_jsfusion_test/v2t_metrics/R50: 89.1
 MSRVTT_jsfusion_test/v2t_metrics/MedR: 5.0
 MSRVTT_jsfusion_test/v2t_metrics/MeanR: 22.242
 MSRVTT_jsfusion_test/v2t_metrics/geometric_mean_R1-R5-R10: 41.08662312343042
 mnt_best       : 40.15617878602743
 not_improved_count: 0
Train Epoch: 12 [1/250 128/32000 (0%)] Loss: 1.55471 (QuantReg: 12.50087) QuantErr: 12.50087 batch_time=24.00727 
Train Epoch: 12 [12/250 1536/32000 (5%)] Loss: 1.80777 (QuantReg: 12.42166) QuantErr: 12.42166 batch_time=0.49604 
Train Epoch: 12 [23/250 2944/32000 (9%)] Loss: 1.91452 (QuantReg: 12.39489) QuantErr: 12.39489 batch_time=0.50502 
Train Epoch: 12 [34/250 4352/32000 (14%)] Loss: 1.26912 (QuantReg: 13.17751) QuantErr: 13.17751 batch_time=0.48685 
Train Epoch: 12 [45/250 5760/32000 (18%)] Loss: 1.70683 (QuantReg: 12.41596) QuantErr: 12.41596 batch_time=0.47925 
Train Epoch: 12 [56/250 7168/32000 (22%)] Loss: 1.69104 (QuantReg: 12.90051) QuantErr: 12.90051 batch_time=0.47528 
Train Epoch: 12 [67/250 8576/32000 (27%)] Loss: 1.49341 (QuantReg: 12.77176) QuantErr: 12.77176 batch_time=0.48690 
Train Epoch: 12 [78/250 9984/32000 (31%)] Loss: 1.65041 (QuantReg: 12.62924) QuantErr: 12.62924 batch_time=0.47114 
Train Epoch: 12 [89/250 11392/32000 (36%)] Loss: 1.53382 (QuantReg: 12.67207) QuantErr: 12.67207 batch_time=0.69009 
Train Epoch: 12 [100/250 12800/32000 (40%)] Loss: 2.18497 (QuantReg: 11.97397) QuantErr: 11.97397 batch_time=0.80179 
Train Epoch: 12 [111/250 14208/32000 (44%)] Loss: 1.25403 (QuantReg: 12.64635) QuantErr: 12.64635 batch_time=0.49931 
Train Epoch: 12 [122/250 15616/32000 (49%)] Loss: 1.60028 (QuantReg: 12.61513) QuantErr: 12.61513 batch_time=0.48735 
Train Epoch: 12 [133/250 17024/32000 (53%)] Loss: 1.76922 (QuantReg: 12.77681) QuantErr: 12.77681 batch_time=0.48190 
Train Epoch: 12 [144/250 18432/32000 (58%)] Loss: 1.70009 (QuantReg: 12.51700) QuantErr: 12.51700 batch_time=0.49164 
Train Epoch: 12 [155/250 19840/32000 (62%)] Loss: 1.68556 (QuantReg: 13.03814) QuantErr: 13.03814 batch_time=0.48211 
Train Epoch: 12 [166/250 21248/32000 (66%)] Loss: 1.29456 (QuantReg: 12.93789) QuantErr: 12.93789 batch_time=0.48580 
Train Epoch: 12 [177/250 22656/32000 (71%)] Loss: 1.63271 (QuantReg: 12.81011) QuantErr: 12.81011 batch_time=0.48535 
Train Epoch: 12 [188/250 24064/32000 (75%)] Loss: 1.47576 (QuantReg: 12.61897) QuantErr: 12.61897 batch_time=0.48128 
Train Epoch: 12 [199/250 25472/32000 (80%)] Loss: 1.51913 (QuantReg: 12.60090) QuantErr: 12.60090 batch_time=0.48011 
Train Epoch: 12 [210/250 26880/32000 (84%)] Loss: 1.25844 (QuantReg: 13.15169) QuantErr: 13.15169 batch_time=0.51891 
Train Epoch: 12 [221/250 28288/32000 (88%)] Loss: 1.32345 (QuantReg: 13.05747) QuantErr: 13.05747 batch_time=0.53454 
Train Epoch: 12 [232/250 29696/32000 (93%)] Loss: 1.66706 (QuantReg: 12.89366) QuantErr: 12.89366 batch_time=0.49283 
Train Epoch: 12 [243/250 31104/32000 (97%)] Loss: 1.50077 (QuantReg: 12.99018) QuantErr: 12.99018 batch_time=0.71309 
Train Epoch: 12 codebook_update_time=1.89660
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_MSRVTT_1kA_roberta-base/checkpoint-epoch12.pth ...
Done in 4.032s
Updating 'best' checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_MSRVTT_1kA_roberta-base/checkpoint-epoch12.pth ...
Done in 8.078s
removing stale ckpt [epoch 11] [took 0.00s]
 epoch          : 12
 loss           : 1.5383011283874513
 quant_reg      : 12.778900856018067
 quant_err      : 12.778900856018067
 learning_rate  : 5.688000922764596e-05
 n_samples      : 384000
 n_steps        : 3000
 MSRVTT_jsfusion_test/t2v_metrics/R1: 22.5
 MSRVTT_jsfusion_test/t2v_metrics/R5: 49.1
 MSRVTT_jsfusion_test/t2v_metrics/R10: 64.0
 MSRVTT_jsfusion_test/t2v_metrics/R50: 88.9
 MSRVTT_jsfusion_test/t2v_metrics/MedR: 6.0
 MSRVTT_jsfusion_test/t2v_metrics/MeanR: 26.239
 MSRVTT_jsfusion_test/t2v_metrics/geometric_mean_R1-R5-R10: 41.3505535831905
 MSRVTT_jsfusion_test/v2t_metrics/R1: 21.4
 MSRVTT_jsfusion_test/v2t_metrics/R5: 51.2
 MSRVTT_jsfusion_test/v2t_metrics/R10: 64.2
 MSRVTT_jsfusion_test/v2t_metrics/R50: 89.4
 MSRVTT_jsfusion_test/v2t_metrics/MedR: 5.0
 MSRVTT_jsfusion_test/v2t_metrics/MeanR: 24.7165
 MSRVTT_jsfusion_test/v2t_metrics/geometric_mean_R1-R5-R10: 41.27999038519095
 mnt_best       : 41.3505535831905
 not_improved_count: 0
Train Epoch: 13 [1/250 128/32000 (0%)] Loss: 1.53680 (QuantReg: 12.75366) QuantErr: 12.75366 batch_time=25.45378 
Train Epoch: 13 [12/250 1536/32000 (5%)] Loss: 1.38285 (QuantReg: 12.58187) QuantErr: 12.58187 batch_time=0.48077 
Train Epoch: 13 [23/250 2944/32000 (9%)] Loss: 1.60631 (QuantReg: 12.24889) QuantErr: 12.24889 batch_time=1.08944 
Train Epoch: 13 [34/250 4352/32000 (14%)] Loss: 1.58489 (QuantReg: 12.76478) QuantErr: 12.76478 batch_time=0.49764 
Train Epoch: 13 [45/250 5760/32000 (18%)] Loss: 1.37290 (QuantReg: 12.69887) QuantErr: 12.69887 batch_time=0.48106 
Train Epoch: 13 [56/250 7168/32000 (22%)] Loss: 1.24582 (QuantReg: 12.66505) QuantErr: 12.66505 batch_time=0.49970 
Train Epoch: 13 [67/250 8576/32000 (27%)] Loss: 1.35255 (QuantReg: 12.82354) QuantErr: 12.82354 batch_time=0.48558 
Train Epoch: 13 [78/250 9984/32000 (31%)] Loss: 1.30705 (QuantReg: 12.56483) QuantErr: 12.56483 batch_time=0.48837 
Train Epoch: 13 [89/250 11392/32000 (36%)] Loss: 1.49875 (QuantReg: 12.81720) QuantErr: 12.81720 batch_time=0.49789 
Train Epoch: 13 [100/250 12800/32000 (40%)] Loss: 1.64584 (QuantReg: 12.65969) QuantErr: 12.65969 batch_time=0.53811 
Train Epoch: 13 [111/250 14208/32000 (44%)] Loss: 1.46295 (QuantReg: 12.72056) QuantErr: 12.72056 batch_time=0.49238 
Train Epoch: 13 [122/250 15616/32000 (49%)] Loss: 1.64694 (QuantReg: 12.69824) QuantErr: 12.69824 batch_time=0.49567 
Train Epoch: 13 [133/250 17024/32000 (53%)] Loss: 1.20366 (QuantReg: 13.04296) QuantErr: 13.04296 batch_time=0.49286 
Train Epoch: 13 [144/250 18432/32000 (58%)] Loss: 1.23679 (QuantReg: 12.88866) QuantErr: 12.88866 batch_time=3.02000 
Train Epoch: 13 [155/250 19840/32000 (62%)] Loss: 1.56723 (QuantReg: 12.92328) QuantErr: 12.92328 batch_time=0.52421 
Train Epoch: 13 [166/250 21248/32000 (66%)] Loss: 1.34051 (QuantReg: 12.84668) QuantErr: 12.84668 batch_time=0.74578 
Train Epoch: 13 [177/250 22656/32000 (71%)] Loss: 1.21430 (QuantReg: 13.09309) QuantErr: 13.09309 batch_time=0.49402 
Train Epoch: 13 [188/250 24064/32000 (75%)] Loss: 1.41553 (QuantReg: 13.05190) QuantErr: 13.05190 batch_time=0.52735 
Train Epoch: 13 [199/250 25472/32000 (80%)] Loss: 1.77948 (QuantReg: 12.94874) QuantErr: 12.94874 batch_time=0.71578 
Train Epoch: 13 [210/250 26880/32000 (84%)] Loss: 1.32693 (QuantReg: 12.90221) QuantErr: 12.90221 batch_time=0.47487 
Train Epoch: 13 [221/250 28288/32000 (88%)] Loss: 1.11811 (QuantReg: 12.99386) QuantErr: 12.99386 batch_time=0.47915 
Train Epoch: 13 [232/250 29696/32000 (93%)] Loss: 1.66525 (QuantReg: 12.83367) QuantErr: 12.83367 batch_time=0.49576 
Train Epoch: 13 [243/250 31104/32000 (97%)] Loss: 1.24226 (QuantReg: 13.13151) QuantErr: 13.13151 batch_time=0.49318 
Train Epoch: 13 codebook_update_time=1.65551
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_MSRVTT_1kA_roberta-base/checkpoint-epoch13.pth ...
Done in 13.685s
removing stale ckpt [epoch 12] [took 0.00s]
 epoch          : 13
 loss           : 1.4744682831764222
 quant_reg      : 12.833291820526123
 quant_err      : 12.833291820526123
 learning_rate  : 5.4036008766263664e-05
 n_samples      : 416000
 n_steps        : 3250
 MSRVTT_jsfusion_test/t2v_metrics/R1: 20.3
 MSRVTT_jsfusion_test/t2v_metrics/R5: 51.3
 MSRVTT_jsfusion_test/t2v_metrics/R10: 63.8
 MSRVTT_jsfusion_test/t2v_metrics/R50: 90.2
 MSRVTT_jsfusion_test/t2v_metrics/MedR: 5.0
 MSRVTT_jsfusion_test/t2v_metrics/MeanR: 24.791
 MSRVTT_jsfusion_test/t2v_metrics/geometric_mean_R1-R5-R10: 40.50214529102553
 MSRVTT_jsfusion_test/v2t_metrics/R1: 22.3
 MSRVTT_jsfusion_test/v2t_metrics/R5: 51.2
 MSRVTT_jsfusion_test/v2t_metrics/R10: 65.1
 MSRVTT_jsfusion_test/v2t_metrics/R50: 89.6
 MSRVTT_jsfusion_test/v2t_metrics/MedR: 5.0
 MSRVTT_jsfusion_test/v2t_metrics/MeanR: 22.616
 MSRVTT_jsfusion_test/v2t_metrics/geometric_mean_R1-R5-R10: 42.045411200309466
 mnt_best       : 41.3505535831905
 not_improved_count: 1
Train Epoch: 14 [1/250 128/32000 (0%)] Loss: 1.45016 (QuantReg: 12.87608) QuantErr: 12.87608 batch_time=25.36863 
Train Epoch: 14 [12/250 1536/32000 (5%)] Loss: 1.56168 (QuantReg: 13.07539) QuantErr: 13.07539 batch_time=0.49168 
Train Epoch: 14 [23/250 2944/32000 (9%)] Loss: 1.36316 (QuantReg: 12.67556) QuantErr: 12.67556 batch_time=0.48579 
Train Epoch: 14 [34/250 4352/32000 (14%)] Loss: 1.10013 (QuantReg: 12.72080) QuantErr: 12.72080 batch_time=0.48316 
Train Epoch: 14 [45/250 5760/32000 (18%)] Loss: 1.13192 (QuantReg: 13.02445) QuantErr: 13.02445 batch_time=0.48452 
Train Epoch: 14 [56/250 7168/32000 (22%)] Loss: 1.46095 (QuantReg: 12.80134) QuantErr: 12.80134 batch_time=0.48775 
Train Epoch: 14 [67/250 8576/32000 (27%)] Loss: 1.28055 (QuantReg: 12.88980) QuantErr: 12.88980 batch_time=1.27152 
Train Epoch: 14 [78/250 9984/32000 (31%)] Loss: 1.09143 (QuantReg: 12.88371) QuantErr: 12.88371 batch_time=0.48670 
Train Epoch: 14 [89/250 11392/32000 (36%)] Loss: 1.73628 (QuantReg: 12.92683) QuantErr: 12.92683 batch_time=0.50258 
Train Epoch: 14 [100/250 12800/32000 (40%)] Loss: 1.75223 (QuantReg: 12.68729) QuantErr: 12.68729 batch_time=0.48256 
Train Epoch: 14 [111/250 14208/32000 (44%)] Loss: 1.65696 (QuantReg: 12.66437) QuantErr: 12.66437 batch_time=0.48719 
Train Epoch: 14 [122/250 15616/32000 (49%)] Loss: 1.16409 (QuantReg: 13.20796) QuantErr: 13.20796 batch_time=0.48464 
Train Epoch: 14 [133/250 17024/32000 (53%)] Loss: 1.81849 (QuantReg: 12.89984) QuantErr: 12.89984 batch_time=0.49376 
Train Epoch: 14 [144/250 18432/32000 (58%)] Loss: 1.42182 (QuantReg: 12.99421) QuantErr: 12.99421 batch_time=0.49505 
Train Epoch: 14 [155/250 19840/32000 (62%)] Loss: 1.41244 (QuantReg: 12.77862) QuantErr: 12.77862 batch_time=0.71101 
Train Epoch: 14 [166/250 21248/32000 (66%)] Loss: 1.38422 (QuantReg: 12.66807) QuantErr: 12.66807 batch_time=0.49529 
Train Epoch: 14 [177/250 22656/32000 (71%)] Loss: 1.35911 (QuantReg: 12.98553) QuantErr: 12.98553 batch_time=1.05544 
Train Epoch: 14 [188/250 24064/32000 (75%)] Loss: 1.34188 (QuantReg: 12.73097) QuantErr: 12.73097 batch_time=0.48437 
Train Epoch: 14 [199/250 25472/32000 (80%)] Loss: 1.58856 (QuantReg: 12.83863) QuantErr: 12.83863 batch_time=0.50045 
Train Epoch: 14 [210/250 26880/32000 (84%)] Loss: 1.13729 (QuantReg: 13.36257) QuantErr: 13.36257 batch_time=0.49254 
Train Epoch: 14 [221/250 28288/32000 (88%)] Loss: 1.48462 (QuantReg: 13.36749) QuantErr: 13.36749 batch_time=0.48819 
Train Epoch: 14 [232/250 29696/32000 (93%)] Loss: 1.34147 (QuantReg: 13.12947) QuantErr: 13.12947 batch_time=0.49781 
Train Epoch: 14 [243/250 31104/32000 (97%)] Loss: 1.23828 (QuantReg: 13.15486) QuantErr: 13.15486 batch_time=0.49129 
Train Epoch: 14 codebook_update_time=1.75678
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_MSRVTT_1kA_roberta-base/checkpoint-epoch14.pth ...
Done in 4.020s
Updating 'best' checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_MSRVTT_1kA_roberta-base/checkpoint-epoch14.pth ...
Done in 24.385s
removing stale ckpt [epoch 13] [took 0.01s]
 epoch          : 14
 loss           : 1.3964751441478729
 quant_reg      : 12.953193359375
 quant_err      : 12.953193359375
 learning_rate  : 5.133420832795048e-05
 n_samples      : 448000
 n_steps        : 3500
 MSRVTT_jsfusion_test/t2v_metrics/R1: 21.2
 MSRVTT_jsfusion_test/t2v_metrics/R5: 51.2
 MSRVTT_jsfusion_test/t2v_metrics/R10: 65.9
 MSRVTT_jsfusion_test/t2v_metrics/R50: 89.4
 MSRVTT_jsfusion_test/t2v_metrics/MedR: 5.0
 MSRVTT_jsfusion_test/t2v_metrics/MeanR: 25.681
 MSRVTT_jsfusion_test/t2v_metrics/geometric_mean_R1-R5-R10: 41.51105255525371
 MSRVTT_jsfusion_test/v2t_metrics/R1: 20.5
 MSRVTT_jsfusion_test/v2t_metrics/R5: 52.3
 MSRVTT_jsfusion_test/v2t_metrics/R10: 65.6
 MSRVTT_jsfusion_test/v2t_metrics/R50: 89.9
 MSRVTT_jsfusion_test/v2t_metrics/MedR: 5.0
 MSRVTT_jsfusion_test/v2t_metrics/MeanR: 23.4765
 MSRVTT_jsfusion_test/v2t_metrics/geometric_mean_R1-R5-R10: 41.27810927682134
 mnt_best       : 41.51105255525371
 not_improved_count: 0
Train Epoch: 15 [1/250 128/32000 (0%)] Loss: 1.39598 (QuantReg: 13.07109) QuantErr: 13.07109 batch_time=26.23247 
Train Epoch: 15 [12/250 1536/32000 (5%)] Loss: 1.57174 (QuantReg: 12.90043) QuantErr: 12.90043 batch_time=0.82421 
Train Epoch: 15 [23/250 2944/32000 (9%)] Loss: 1.51437 (QuantReg: 12.81585) QuantErr: 12.81585 batch_time=1.43528 
Train Epoch: 15 [34/250 4352/32000 (14%)] Loss: 1.46503 (QuantReg: 12.66467) QuantErr: 12.66467 batch_time=0.48290 
Train Epoch: 15 [45/250 5760/32000 (18%)] Loss: 1.61961 (QuantReg: 12.59982) QuantErr: 12.59982 batch_time=0.49238 
Train Epoch: 15 [56/250 7168/32000 (22%)] Loss: 1.30888 (QuantReg: 13.08152) QuantErr: 13.08152 batch_time=0.48681 
Train Epoch: 15 [67/250 8576/32000 (27%)] Loss: 1.34714 (QuantReg: 13.20964) QuantErr: 13.20964 batch_time=0.49229 
Train Epoch: 15 [78/250 9984/32000 (31%)] Loss: 1.50099 (QuantReg: 13.22906) QuantErr: 13.22906 batch_time=0.49208 
Train Epoch: 15 [89/250 11392/32000 (36%)] Loss: 1.44051 (QuantReg: 12.78274) QuantErr: 12.78274 batch_time=0.59959 
Train Epoch: 15 [100/250 12800/32000 (40%)] Loss: 1.05045 (QuantReg: 12.86462) QuantErr: 12.86462 batch_time=0.48111 
Train Epoch: 15 [111/250 14208/32000 (44%)] Loss: 1.02284 (QuantReg: 13.10267) QuantErr: 13.10267 batch_time=0.47382 
Train Epoch: 15 [122/250 15616/32000 (49%)] Loss: 1.29459 (QuantReg: 13.07288) QuantErr: 13.07288 batch_time=0.72568 
Train Epoch: 15 [133/250 17024/32000 (53%)] Loss: 1.35649 (QuantReg: 13.26511) QuantErr: 13.26511 batch_time=0.48126 
Train Epoch: 15 [144/250 18432/32000 (58%)] Loss: 1.60983 (QuantReg: 13.04230) QuantErr: 13.04230 batch_time=0.48440 
Train Epoch: 15 [155/250 19840/32000 (62%)] Loss: 1.32180 (QuantReg: 13.07542) QuantErr: 13.07542 batch_time=0.48611 
Train Epoch: 15 [166/250 21248/32000 (66%)] Loss: 1.31836 (QuantReg: 12.88226) QuantErr: 12.88226 batch_time=0.48295 
Train Epoch: 15 [177/250 22656/32000 (71%)] Loss: 1.33392 (QuantReg: 13.01900) QuantErr: 13.01900 batch_time=0.48539 
Train Epoch: 15 [188/250 24064/32000 (75%)] Loss: 1.36416 (QuantReg: 12.84391) QuantErr: 12.84391 batch_time=0.48244 
Train Epoch: 15 [199/250 25472/32000 (80%)] Loss: 1.46462 (QuantReg: 13.50912) QuantErr: 13.50912 batch_time=0.50018 
Train Epoch: 15 [210/250 26880/32000 (84%)] Loss: 1.56603 (QuantReg: 12.99232) QuantErr: 12.99232 batch_time=0.48289 
Train Epoch: 15 [221/250 28288/32000 (88%)] Loss: 1.51479 (QuantReg: 13.34737) QuantErr: 13.34737 batch_time=0.48733 
Train Epoch: 15 [232/250 29696/32000 (93%)] Loss: 1.37176 (QuantReg: 13.39953) QuantErr: 13.39953 batch_time=0.47346 
Train Epoch: 15 [243/250 31104/32000 (97%)] Loss: 1.36372 (QuantReg: 13.00748) QuantErr: 13.00748 batch_time=0.83591 
Train Epoch: 15 codebook_update_time=1.61014
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_MSRVTT_1kA_roberta-base/checkpoint-epoch15.pth ...
Done in 4.021s
Updating 'best' checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_MSRVTT_1kA_roberta-base/checkpoint-epoch15.pth ...
Done in 7.993s
removing stale ckpt [epoch 14] [took 0.00s]
 epoch          : 15
 loss           : 1.337243925333023
 quant_reg      : 12.992572593688966
 quant_err      : 12.992572593688966
 learning_rate  : 4.876749791155295e-05
 n_samples      : 480000
 n_steps        : 3750
 MSRVTT_jsfusion_test/t2v_metrics/R1: 23.2
 MSRVTT_jsfusion_test/t2v_metrics/R5: 50.1
 MSRVTT_jsfusion_test/t2v_metrics/R10: 64.8
 MSRVTT_jsfusion_test/t2v_metrics/R50: 89.5
 MSRVTT_jsfusion_test/t2v_metrics/MedR: 5.0
 MSRVTT_jsfusion_test/t2v_metrics/MeanR: 25.639
 MSRVTT_jsfusion_test/t2v_metrics/geometric_mean_R1-R5-R10: 42.231214598490844
 MSRVTT_jsfusion_test/v2t_metrics/R1: 20.7
 MSRVTT_jsfusion_test/v2t_metrics/R5: 51.6
 MSRVTT_jsfusion_test/v2t_metrics/R10: 65.7
 MSRVTT_jsfusion_test/v2t_metrics/R50: 89.4
 MSRVTT_jsfusion_test/v2t_metrics/MedR: 5.0
 MSRVTT_jsfusion_test/v2t_metrics/MeanR: 23.605
 MSRVTT_jsfusion_test/v2t_metrics/geometric_mean_R1-R5-R10: 41.24726328951273
 mnt_best       : 42.231214598490844
 not_improved_count: 0
Train Epoch: 16 [1/250 128/32000 (0%)] Loss: 1.47112 (QuantReg: 12.66747) QuantErr: 12.66747 batch_time=28.65316 
Train Epoch: 16 [12/250 1536/32000 (5%)] Loss: 1.04482 (QuantReg: 12.91136) QuantErr: 12.91136 batch_time=0.48054 
Train Epoch: 16 [23/250 2944/32000 (9%)] Loss: 1.20600 (QuantReg: 12.95227) QuantErr: 12.95227 batch_time=0.69958 
Train Epoch: 16 [34/250 4352/32000 (14%)] Loss: 1.17886 (QuantReg: 12.99290) QuantErr: 12.99290 batch_time=0.47500 
Train Epoch: 16 [45/250 5760/32000 (18%)] Loss: 1.25344 (QuantReg: 13.00930) QuantErr: 13.00930 batch_time=0.48857 
Train Epoch: 16 [56/250 7168/32000 (22%)] Loss: 1.24100 (QuantReg: 13.24392) QuantErr: 13.24392 batch_time=0.47398 
Train Epoch: 16 [67/250 8576/32000 (27%)] Loss: 1.27682 (QuantReg: 12.95119) QuantErr: 12.95119 batch_time=0.47895 
Train Epoch: 16 [78/250 9984/32000 (31%)] Loss: 1.37431 (QuantReg: 12.90666) QuantErr: 12.90666 batch_time=0.48050 
Train Epoch: 16 [89/250 11392/32000 (36%)] Loss: 1.24280 (QuantReg: 12.86123) QuantErr: 12.86123 batch_time=0.47159 
Train Epoch: 16 [100/250 12800/32000 (40%)] Loss: 1.27380 (QuantReg: 12.85417) QuantErr: 12.85417 batch_time=0.48251 
Train Epoch: 16 [111/250 14208/32000 (44%)] Loss: 1.62249 (QuantReg: 12.98039) QuantErr: 12.98039 batch_time=0.48345 
Train Epoch: 16 [122/250 15616/32000 (49%)] Loss: 1.37555 (QuantReg: 13.17805) QuantErr: 13.17805 batch_time=0.46962 
Train Epoch: 16 [133/250 17024/32000 (53%)] Loss: 1.37282 (QuantReg: 13.12674) QuantErr: 13.12674 batch_time=0.48009 
Train Epoch: 16 [144/250 18432/32000 (58%)] Loss: 1.59639 (QuantReg: 12.76551) QuantErr: 12.76551 batch_time=0.52187 
Train Epoch: 16 [155/250 19840/32000 (62%)] Loss: 1.44740 (QuantReg: 13.49054) QuantErr: 13.49054 batch_time=0.47413 
Train Epoch: 16 [166/250 21248/32000 (66%)] Loss: 1.40160 (QuantReg: 13.34806) QuantErr: 13.34806 batch_time=0.47119 
Train Epoch: 16 [177/250 22656/32000 (71%)] Loss: 1.29097 (QuantReg: 13.08693) QuantErr: 13.08693 batch_time=0.47195 
Train Epoch: 16 [188/250 24064/32000 (75%)] Loss: 1.52462 (QuantReg: 13.10785) QuantErr: 13.10785 batch_time=0.46922 
Train Epoch: 16 [199/250 25472/32000 (80%)] Loss: 1.48923 (QuantReg: 12.76772) QuantErr: 12.76772 batch_time=0.48477 
Train Epoch: 16 [210/250 26880/32000 (84%)] Loss: 1.26484 (QuantReg: 12.82559) QuantErr: 12.82559 batch_time=0.48541 
Train Epoch: 16 [221/250 28288/32000 (88%)] Loss: 1.35573 (QuantReg: 12.91451) QuantErr: 12.91451 batch_time=0.58657 
Train Epoch: 16 [232/250 29696/32000 (93%)] Loss: 1.05985 (QuantReg: 13.11012) QuantErr: 13.11012 batch_time=0.58155 
Train Epoch: 16 [243/250 31104/32000 (97%)] Loss: 1.11124 (QuantReg: 13.10870) QuantErr: 13.10870 batch_time=0.48303 
Train Epoch: 16 codebook_update_time=1.73951
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_MSRVTT_1kA_roberta-base/checkpoint-epoch16.pth ...
Done in 12.521s
removing stale ckpt [epoch 15] [took 0.00s]
 epoch          : 16
 loss           : 1.2834236388206481
 quant_reg      : 12.99853598022461
 quant_err      : 12.99853598022461
 learning_rate  : 4.6329123015975305e-05
 n_samples      : 512000
 n_steps        : 4000
 MSRVTT_jsfusion_test/t2v_metrics/R1: 20.8
 MSRVTT_jsfusion_test/t2v_metrics/R5: 50.6
 MSRVTT_jsfusion_test/t2v_metrics/R10: 63.8
 MSRVTT_jsfusion_test/t2v_metrics/R50: 88.9
 MSRVTT_jsfusion_test/t2v_metrics/MedR: 5.0
 MSRVTT_jsfusion_test/t2v_metrics/MeanR: 24.804
 MSRVTT_jsfusion_test/t2v_metrics/geometric_mean_R1-R5-R10: 40.6454101339078
 MSRVTT_jsfusion_test/v2t_metrics/R1: 20.4
 MSRVTT_jsfusion_test/v2t_metrics/R5: 51.4
 MSRVTT_jsfusion_test/v2t_metrics/R10: 65.3
 MSRVTT_jsfusion_test/v2t_metrics/R50: 89.8
 MSRVTT_jsfusion_test/v2t_metrics/MedR: 5.0
 MSRVTT_jsfusion_test/v2t_metrics/MeanR: 22.918
 MSRVTT_jsfusion_test/v2t_metrics/geometric_mean_R1-R5-R10: 40.9105661133571
 mnt_best       : 42.231214598490844
 not_improved_count: 1
Train Epoch: 17 [1/250 128/32000 (0%)] Loss: 1.40223 (QuantReg: 12.53526) QuantErr: 12.53526 batch_time=32.64507 
Train Epoch: 17 [12/250 1536/32000 (5%)] Loss: 1.15314 (QuantReg: 12.91318) QuantErr: 12.91318 batch_time=0.48590 
Train Epoch: 17 [23/250 2944/32000 (9%)] Loss: 1.08835 (QuantReg: 12.81096) QuantErr: 12.81096 batch_time=0.49181 
Train Epoch: 17 [34/250 4352/32000 (14%)] Loss: 1.16976 (QuantReg: 13.06904) QuantErr: 13.06904 batch_time=0.55145 
Train Epoch: 17 [45/250 5760/32000 (18%)] Loss: 1.29629 (QuantReg: 13.14529) QuantErr: 13.14529 batch_time=1.01213 
Train Epoch: 17 [56/250 7168/32000 (22%)] Loss: 1.01750 (QuantReg: 13.08680) QuantErr: 13.08680 batch_time=0.80108 
Train Epoch: 17 [67/250 8576/32000 (27%)] Loss: 1.15419 (QuantReg: 13.06940) QuantErr: 13.06940 batch_time=1.36325 
Train Epoch: 17 [78/250 9984/32000 (31%)] Loss: 1.20654 (QuantReg: 12.87917) QuantErr: 12.87917 batch_time=0.49006 
Train Epoch: 17 [89/250 11392/32000 (36%)] Loss: 1.11894 (QuantReg: 12.64294) QuantErr: 12.64294 batch_time=0.49153 
Train Epoch: 17 [100/250 12800/32000 (40%)] Loss: 1.48266 (QuantReg: 13.10894) QuantErr: 13.10894 batch_time=0.48523 
Train Epoch: 17 [111/250 14208/32000 (44%)] Loss: 1.32512 (QuantReg: 12.56067) QuantErr: 12.56067 batch_time=0.48647 
Train Epoch: 17 [122/250 15616/32000 (49%)] Loss: 1.27327 (QuantReg: 12.58043) QuantErr: 12.58043 batch_time=0.49205 
Train Epoch: 17 [133/250 17024/32000 (53%)] Loss: 1.13362 (QuantReg: 13.30151) QuantErr: 13.30151 batch_time=0.81866 
Train Epoch: 17 [144/250 18432/32000 (58%)] Loss: 1.39549 (QuantReg: 13.13209) QuantErr: 13.13209 batch_time=0.49520 
Train Epoch: 17 [155/250 19840/32000 (62%)] Loss: 1.41550 (QuantReg: 12.98653) QuantErr: 12.98653 batch_time=0.48872 
Train Epoch: 17 [166/250 21248/32000 (66%)] Loss: 1.26579 (QuantReg: 12.83585) QuantErr: 12.83585 batch_time=0.50589 
Train Epoch: 17 [177/250 22656/32000 (71%)] Loss: 1.28867 (QuantReg: 13.07468) QuantErr: 13.07468 batch_time=0.58962 
Train Epoch: 17 [188/250 24064/32000 (75%)] Loss: 1.96228 (QuantReg: 12.95880) QuantErr: 12.95880 batch_time=0.48843 
Train Epoch: 17 [199/250 25472/32000 (80%)] Loss: 1.19000 (QuantReg: 12.97893) QuantErr: 12.97893 batch_time=0.53797 
Train Epoch: 17 [210/250 26880/32000 (84%)] Loss: 1.06718 (QuantReg: 12.96606) QuantErr: 12.96606 batch_time=0.55253 
Train Epoch: 17 [221/250 28288/32000 (88%)] Loss: 1.12142 (QuantReg: 13.05395) QuantErr: 13.05395 batch_time=1.63742 
Train Epoch: 17 [232/250 29696/32000 (93%)] Loss: 1.09594 (QuantReg: 13.04986) QuantErr: 13.04986 batch_time=0.49163 
Train Epoch: 17 [243/250 31104/32000 (97%)] Loss: 1.37286 (QuantReg: 12.89277) QuantErr: 12.89277 batch_time=0.49310 
Train Epoch: 17 codebook_update_time=1.64085
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_MSRVTT_1kA_roberta-base/checkpoint-epoch17.pth ...
Done in 4.073s
Updating 'best' checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_MSRVTT_1kA_roberta-base/checkpoint-epoch17.pth ...
Done in 7.991s
removing stale ckpt [epoch 16] [took 0.00s]
 epoch          : 17
 loss           : 1.2462474904060363
 quant_reg      : 13.016258354187011
 quant_err      : 13.016258354187011
 learning_rate  : 4.4012666865176535e-05
 n_samples      : 544000
 n_steps        : 4250
 MSRVTT_jsfusion_test/t2v_metrics/R1: 21.6
 MSRVTT_jsfusion_test/t2v_metrics/R5: 53.1
 MSRVTT_jsfusion_test/t2v_metrics/R10: 66.5
 MSRVTT_jsfusion_test/t2v_metrics/R50: 89.2
 MSRVTT_jsfusion_test/t2v_metrics/MedR: 5.0
 MSRVTT_jsfusion_test/t2v_metrics/MeanR: 25.609
 MSRVTT_jsfusion_test/t2v_metrics/geometric_mean_R1-R5-R10: 42.408863994665296
 MSRVTT_jsfusion_test/v2t_metrics/R1: 20.6
 MSRVTT_jsfusion_test/v2t_metrics/R5: 54.0
 MSRVTT_jsfusion_test/v2t_metrics/R10: 68.0
 MSRVTT_jsfusion_test/v2t_metrics/R50: 89.4
 MSRVTT_jsfusion_test/v2t_metrics/MedR: 5.0
 MSRVTT_jsfusion_test/v2t_metrics/MeanR: 22.9855
 MSRVTT_jsfusion_test/v2t_metrics/geometric_mean_R1-R5-R10: 42.29184491446412
 mnt_best       : 42.408863994665296
 not_improved_count: 0
Train Epoch: 18 [1/250 128/32000 (0%)] Loss: 1.26207 (QuantReg: 12.71729) QuantErr: 12.71729 batch_time=30.90942 
Train Epoch: 18 [12/250 1536/32000 (5%)] Loss: 1.26519 (QuantReg: 12.39459) QuantErr: 12.39459 batch_time=1.10416 
Train Epoch: 18 [23/250 2944/32000 (9%)] Loss: 1.28018 (QuantReg: 12.77549) QuantErr: 12.77549 batch_time=0.49641 
Train Epoch: 18 [34/250 4352/32000 (14%)] Loss: 1.38148 (QuantReg: 12.85350) QuantErr: 12.85350 batch_time=0.47967 
Train Epoch: 18 [45/250 5760/32000 (18%)] Loss: 1.23841 (QuantReg: 12.99766) QuantErr: 12.99766 batch_time=0.48151 
Train Epoch: 18 [56/250 7168/32000 (22%)] Loss: 1.03023 (QuantReg: 13.03217) QuantErr: 13.03217 batch_time=0.46916 
Train Epoch: 18 [67/250 8576/32000 (27%)] Loss: 1.20115 (QuantReg: 13.03832) QuantErr: 13.03832 batch_time=0.69327 
Train Epoch: 18 [78/250 9984/32000 (31%)] Loss: 1.31808 (QuantReg: 13.01620) QuantErr: 13.01620 batch_time=0.53124 
Train Epoch: 18 [89/250 11392/32000 (36%)] Loss: 1.56839 (QuantReg: 12.52544) QuantErr: 12.52544 batch_time=0.49137 
Train Epoch: 18 [100/250 12800/32000 (40%)] Loss: 1.47991 (QuantReg: 12.79534) QuantErr: 12.79534 batch_time=0.76605 
Train Epoch: 18 [111/250 14208/32000 (44%)] Loss: 1.27167 (QuantReg: 13.34227) QuantErr: 13.34227 batch_time=0.49726 
Train Epoch: 18 [122/250 15616/32000 (49%)] Loss: 1.09933 (QuantReg: 13.26171) QuantErr: 13.26171 batch_time=0.49564 
Train Epoch: 18 [133/250 17024/32000 (53%)] Loss: 1.06786 (QuantReg: 12.99521) QuantErr: 12.99521 batch_time=0.48929 
Train Epoch: 18 [144/250 18432/32000 (58%)] Loss: 1.57348 (QuantReg: 12.87085) QuantErr: 12.87085 batch_time=0.66990 
Train Epoch: 18 [155/250 19840/32000 (62%)] Loss: 1.18042 (QuantReg: 12.79677) QuantErr: 12.79677 batch_time=0.49150 
Train Epoch: 18 [166/250 21248/32000 (66%)] Loss: 1.38533 (QuantReg: 13.20260) QuantErr: 13.20260 batch_time=0.49754 
Train Epoch: 18 [177/250 22656/32000 (71%)] Loss: 1.11753 (QuantReg: 13.16217) QuantErr: 13.16217 batch_time=0.48725 
Train Epoch: 18 [188/250 24064/32000 (75%)] Loss: 1.12127 (QuantReg: 12.87485) QuantErr: 12.87485 batch_time=0.49037 
Train Epoch: 18 [199/250 25472/32000 (80%)] Loss: 1.33184 (QuantReg: 12.97066) QuantErr: 12.97066 batch_time=0.58106 
Train Epoch: 18 [210/250 26880/32000 (84%)] Loss: 1.22051 (QuantReg: 12.94233) QuantErr: 12.94233 batch_time=0.48373 
Train Epoch: 18 [221/250 28288/32000 (88%)] Loss: 1.21051 (QuantReg: 13.07589) QuantErr: 13.07589 batch_time=0.47906 
Train Epoch: 18 [232/250 29696/32000 (93%)] Loss: 1.43237 (QuantReg: 13.00898) QuantErr: 13.00898 batch_time=0.47942 
Train Epoch: 18 [243/250 31104/32000 (97%)] Loss: 1.39292 (QuantReg: 13.25722) QuantErr: 13.25722 batch_time=0.47421 
Train Epoch: 18 codebook_update_time=1.62325
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_MSRVTT_1kA_roberta-base/checkpoint-epoch18.pth ...
Done in 4.038s
removing stale ckpt [epoch 17] [took 0.00s]
 epoch          : 18
 loss           : 1.2149391906261444
 quant_reg      : 13.033641311645507
 quant_err      : 13.033641311645507
 learning_rate  : 4.181203352191771e-05
 n_samples      : 576000
 n_steps        : 4500
 MSRVTT_jsfusion_test/t2v_metrics/R1: 21.9
 MSRVTT_jsfusion_test/t2v_metrics/R5: 52.4
 MSRVTT_jsfusion_test/t2v_metrics/R10: 65.9
 MSRVTT_jsfusion_test/t2v_metrics/R50: 89.5
 MSRVTT_jsfusion_test/t2v_metrics/MedR: 5.0
 MSRVTT_jsfusion_test/t2v_metrics/MeanR: 24.318
 MSRVTT_jsfusion_test/t2v_metrics/geometric_mean_R1-R5-R10: 42.288304419328234
 MSRVTT_jsfusion_test/v2t_metrics/R1: 23.3
 MSRVTT_jsfusion_test/v2t_metrics/R5: 51.4
 MSRVTT_jsfusion_test/v2t_metrics/R10: 66.8
 MSRVTT_jsfusion_test/v2t_metrics/R50: 89.8
 MSRVTT_jsfusion_test/v2t_metrics/MedR: 5.0
 MSRVTT_jsfusion_test/v2t_metrics/MeanR: 22.786
 MSRVTT_jsfusion_test/v2t_metrics/geometric_mean_R1-R5-R10: 43.08887620866924
 mnt_best       : 42.408863994665296
 not_improved_count: 1
Train Epoch: 19 [1/250 128/32000 (0%)] Loss: 0.96580 (QuantReg: 13.18199) QuantErr: 13.18199 batch_time=30.11154 
Train Epoch: 19 [12/250 1536/32000 (5%)] Loss: 1.13810 (QuantReg: 12.72930) QuantErr: 12.72930 batch_time=0.48214 
Train Epoch: 19 [23/250 2944/32000 (9%)] Loss: 1.49391 (QuantReg: 12.88334) QuantErr: 12.88334 batch_time=0.51658 
Train Epoch: 19 [34/250 4352/32000 (14%)] Loss: 1.06911 (QuantReg: 13.02507) QuantErr: 13.02507 batch_time=0.60001 
Train Epoch: 19 [45/250 5760/32000 (18%)] Loss: 1.19659 (QuantReg: 13.24097) QuantErr: 13.24097 batch_time=0.48529 
Train Epoch: 19 [56/250 7168/32000 (22%)] Loss: 1.09437 (QuantReg: 13.31794) QuantErr: 13.31794 batch_time=0.48335 
Train Epoch: 19 [67/250 8576/32000 (27%)] Loss: 1.09890 (QuantReg: 13.15706) QuantErr: 13.15706 batch_time=0.48371 
Train Epoch: 19 [78/250 9984/32000 (31%)] Loss: 1.12779 (QuantReg: 13.15859) QuantErr: 13.15859 batch_time=0.48612 
Train Epoch: 19 [89/250 11392/32000 (36%)] Loss: 1.55094 (QuantReg: 12.70433) QuantErr: 12.70433 batch_time=3.05168 
Train Epoch: 19 [100/250 12800/32000 (40%)] Loss: 1.31486 (QuantReg: 13.06879) QuantErr: 13.06879 batch_time=0.48700 
Train Epoch: 19 [111/250 14208/32000 (44%)] Loss: 1.31089 (QuantReg: 13.09834) QuantErr: 13.09834 batch_time=0.48420 
Train Epoch: 19 [122/250 15616/32000 (49%)] Loss: 1.45132 (QuantReg: 13.07703) QuantErr: 13.07703 batch_time=0.49465 
Train Epoch: 19 [133/250 17024/32000 (53%)] Loss: 1.23800 (QuantReg: 13.18706) QuantErr: 13.18706 batch_time=0.48302 
Train Epoch: 19 [144/250 18432/32000 (58%)] Loss: 1.24791 (QuantReg: 13.06767) QuantErr: 13.06767 batch_time=0.47556 
Train Epoch: 19 [155/250 19840/32000 (62%)] Loss: 0.98255 (QuantReg: 13.18479) QuantErr: 13.18479 batch_time=0.48894 
Train Epoch: 19 [166/250 21248/32000 (66%)] Loss: 1.35720 (QuantReg: 13.10086) QuantErr: 13.10086 batch_time=0.49123 
Train Epoch: 19 [177/250 22656/32000 (71%)] Loss: 1.16038 (QuantReg: 13.10558) QuantErr: 13.10558 batch_time=0.48417 
Train Epoch: 19 [188/250 24064/32000 (75%)] Loss: 1.21110 (QuantReg: 13.03137) QuantErr: 13.03137 batch_time=0.48973 
Train Epoch: 19 [199/250 25472/32000 (80%)] Loss: 1.19026 (QuantReg: 13.32264) QuantErr: 13.32264 batch_time=0.48538 
Train Epoch: 19 [210/250 26880/32000 (84%)] Loss: 1.07248 (QuantReg: 12.95377) QuantErr: 12.95377 batch_time=1.50504 
Train Epoch: 19 [221/250 28288/32000 (88%)] Loss: 1.19681 (QuantReg: 13.43178) QuantErr: 13.43178 batch_time=0.48336 
Train Epoch: 19 [232/250 29696/32000 (93%)] Loss: 1.08174 (QuantReg: 12.83413) QuantErr: 12.83413 batch_time=0.49165 
Train Epoch: 19 [243/250 31104/32000 (97%)] Loss: 1.17044 (QuantReg: 13.41363) QuantErr: 13.41363 batch_time=0.48541 
Train Epoch: 19 codebook_update_time=1.61682
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_MSRVTT_1kA_roberta-base/checkpoint-epoch19.pth ...
Done in 5.475s
removing stale ckpt [epoch 18] [took 0.00s]
 epoch          : 19
 loss           : 1.1806748452186584
 quant_reg      : 13.112760314941406
 quant_err      : 13.112760314941406
 learning_rate  : 3.972143184582182e-05
 n_samples      : 608000
 n_steps        : 4750
 MSRVTT_jsfusion_test/t2v_metrics/R1: 21.0
 MSRVTT_jsfusion_test/t2v_metrics/R5: 50.9
 MSRVTT_jsfusion_test/t2v_metrics/R10: 65.5
 MSRVTT_jsfusion_test/t2v_metrics/R50: 89.4
 MSRVTT_jsfusion_test/t2v_metrics/MedR: 5.0
 MSRVTT_jsfusion_test/t2v_metrics/MeanR: 24.827
 MSRVTT_jsfusion_test/t2v_metrics/geometric_mean_R1-R5-R10: 41.21539430064656
 MSRVTT_jsfusion_test/v2t_metrics/R1: 21.7
 MSRVTT_jsfusion_test/v2t_metrics/R5: 52.5
 MSRVTT_jsfusion_test/v2t_metrics/R10: 66.9
 MSRVTT_jsfusion_test/v2t_metrics/R50: 89.1
 MSRVTT_jsfusion_test/v2t_metrics/MedR: 5.0
 MSRVTT_jsfusion_test/v2t_metrics/MeanR: 23.404
 MSRVTT_jsfusion_test/v2t_metrics/geometric_mean_R1-R5-R10: 42.39829429028783
 mnt_best       : 42.408863994665296
 not_improved_count: 2
Train Epoch: 20 [1/250 128/32000 (0%)] Loss: 1.05645 (QuantReg: 13.25249) QuantErr: 13.25249 batch_time=32.21712 
Train Epoch: 20 [12/250 1536/32000 (5%)] Loss: 1.14982 (QuantReg: 12.87963) QuantErr: 12.87963 batch_time=0.51861 
Train Epoch: 20 [23/250 2944/32000 (9%)] Loss: 1.00203 (QuantReg: 13.07004) QuantErr: 13.07004 batch_time=0.48888 
Train Epoch: 20 [34/250 4352/32000 (14%)] Loss: 0.92877 (QuantReg: 13.14923) QuantErr: 13.14923 batch_time=0.49163 
Train Epoch: 20 [45/250 5760/32000 (18%)] Loss: 0.87738 (QuantReg: 13.28940) QuantErr: 13.28940 batch_time=0.90276 
Train Epoch: 20 [56/250 7168/32000 (22%)] Loss: 1.15403 (QuantReg: 13.21803) QuantErr: 13.21803 batch_time=0.49850 
Train Epoch: 20 [67/250 8576/32000 (27%)] Loss: 1.26656 (QuantReg: 12.91308) QuantErr: 12.91308 batch_time=0.49955 
Train Epoch: 20 [78/250 9984/32000 (31%)] Loss: 1.07099 (QuantReg: 13.14820) QuantErr: 13.14820 batch_time=0.49491 
Train Epoch: 20 [89/250 11392/32000 (36%)] Loss: 1.12294 (QuantReg: 13.14804) QuantErr: 13.14804 batch_time=0.51924 
Train Epoch: 20 [100/250 12800/32000 (40%)] Loss: 1.42419 (QuantReg: 13.23054) QuantErr: 13.23054 batch_time=0.50008 
Train Epoch: 20 [111/250 14208/32000 (44%)] Loss: 1.14638 (QuantReg: 12.90687) QuantErr: 12.90687 batch_time=0.49690 
Train Epoch: 20 [122/250 15616/32000 (49%)] Loss: 1.12720 (QuantReg: 12.95242) QuantErr: 12.95242 batch_time=0.53902 
Train Epoch: 20 [133/250 17024/32000 (53%)] Loss: 1.03727 (QuantReg: 13.30045) QuantErr: 13.30045 batch_time=0.53316 
Train Epoch: 20 [144/250 18432/32000 (58%)] Loss: 1.15821 (QuantReg: 13.11387) QuantErr: 13.11387 batch_time=1.96752 
Train Epoch: 20 [155/250 19840/32000 (62%)] Loss: 1.20666 (QuantReg: 13.29103) QuantErr: 13.29103 batch_time=0.50383 
Train Epoch: 20 [166/250 21248/32000 (66%)] Loss: 1.08787 (QuantReg: 13.46806) QuantErr: 13.46806 batch_time=0.49786 
Train Epoch: 20 [177/250 22656/32000 (71%)] Loss: 1.14979 (QuantReg: 13.23932) QuantErr: 13.23932 batch_time=0.48499 
Train Epoch: 20 [188/250 24064/32000 (75%)] Loss: 0.90243 (QuantReg: 13.49814) QuantErr: 13.49814 batch_time=0.48382 
Train Epoch: 20 [199/250 25472/32000 (80%)] Loss: 1.50322 (QuantReg: 13.35745) QuantErr: 13.35745 batch_time=0.48971 
Train Epoch: 20 [210/250 26880/32000 (84%)] Loss: 1.08095 (QuantReg: 13.42635) QuantErr: 13.42635 batch_time=0.48493 
Train Epoch: 20 [221/250 28288/32000 (88%)] Loss: 1.19476 (QuantReg: 13.52245) QuantErr: 13.52245 batch_time=0.59517 
Train Epoch: 20 [232/250 29696/32000 (93%)] Loss: 1.20061 (QuantReg: 13.33238) QuantErr: 13.33238 batch_time=0.48934 
Train Epoch: 20 [243/250 31104/32000 (97%)] Loss: 1.16941 (QuantReg: 13.41476) QuantErr: 13.41476 batch_time=0.48576 
Train Epoch: 20 codebook_update_time=1.63736
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_MSRVTT_1kA_roberta-base/checkpoint-epoch20.pth ...
Done in 4.101s
Updating 'best' checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_MSRVTT_1kA_roberta-base/checkpoint-epoch20.pth ...
Done in 8.009s
removing stale ckpt [epoch 19] [took 0.08s]
 epoch          : 20
 loss           : 1.1286647977828979
 quant_reg      : 13.187817665100098
 quant_err      : 13.187817665100098
 learning_rate  : 3.7735360253530726e-05
 n_samples      : 640000
 n_steps        : 5000
 MSRVTT_jsfusion_test/t2v_metrics/R1: 22.5
 MSRVTT_jsfusion_test/t2v_metrics/R5: 52.3
 MSRVTT_jsfusion_test/t2v_metrics/R10: 65.9
 MSRVTT_jsfusion_test/t2v_metrics/R50: 90.5
 MSRVTT_jsfusion_test/t2v_metrics/MedR: 5.0
 MSRVTT_jsfusion_test/t2v_metrics/MeanR: 23.564
 MSRVTT_jsfusion_test/t2v_metrics/geometric_mean_R1-R5-R10: 42.64386310622815
 MSRVTT_jsfusion_test/v2t_metrics/R1: 22.5
 MSRVTT_jsfusion_test/v2t_metrics/R5: 52.1
 MSRVTT_jsfusion_test/v2t_metrics/R10: 65.4
 MSRVTT_jsfusion_test/v2t_metrics/R50: 90.3
 MSRVTT_jsfusion_test/v2t_metrics/MedR: 5.0
 MSRVTT_jsfusion_test/v2t_metrics/MeanR: 22.758
 MSRVTT_jsfusion_test/v2t_metrics/geometric_mean_R1-R5-R10: 42.48144980528598
 mnt_best       : 42.64386310622815
 not_improved_count: 0
Train Epoch: 21 [1/250 128/32000 (0%)] Loss: 1.20003 (QuantReg: 13.07227) QuantErr: 13.07227 batch_time=31.14250 
Train Epoch: 21 [12/250 1536/32000 (5%)] Loss: 0.99222 (QuantReg: 12.93650) QuantErr: 12.93650 batch_time=0.47999 
Train Epoch: 21 [23/250 2944/32000 (9%)] Loss: 0.99568 (QuantReg: 12.76929) QuantErr: 12.76929 batch_time=0.48356 
Train Epoch: 21 [34/250 4352/32000 (14%)] Loss: 1.37043 (QuantReg: 13.01119) QuantErr: 13.01119 batch_time=0.47995 
Train Epoch: 21 [45/250 5760/32000 (18%)] Loss: 0.92449 (QuantReg: 13.32140) QuantErr: 13.32140 batch_time=0.47300 
Train Epoch: 21 [56/250 7168/32000 (22%)] Loss: 1.18646 (QuantReg: 13.52093) QuantErr: 13.52093 batch_time=0.47690 
Train Epoch: 21 [67/250 8576/32000 (27%)] Loss: 1.03604 (QuantReg: 13.17662) QuantErr: 13.17662 batch_time=0.48801 
Train Epoch: 21 [78/250 9984/32000 (31%)] Loss: 1.08228 (QuantReg: 13.25543) QuantErr: 13.25543 batch_time=0.48456 
Train Epoch: 21 [89/250 11392/32000 (36%)] Loss: 1.21248 (QuantReg: 13.00887) QuantErr: 13.00887 batch_time=0.49240 
Train Epoch: 21 [100/250 12800/32000 (40%)] Loss: 1.02166 (QuantReg: 13.29054) QuantErr: 13.29054 batch_time=0.52137 
Train Epoch: 21 [111/250 14208/32000 (44%)] Loss: 0.96906 (QuantReg: 13.10602) QuantErr: 13.10602 batch_time=0.47944 
Train Epoch: 21 [122/250 15616/32000 (49%)] Loss: 1.07802 (QuantReg: 12.88636) QuantErr: 12.88636 batch_time=0.47754 
Train Epoch: 21 [133/250 17024/32000 (53%)] Loss: 1.08949 (QuantReg: 13.03567) QuantErr: 13.03567 batch_time=0.55158 
Train Epoch: 21 [144/250 18432/32000 (58%)] Loss: 0.96032 (QuantReg: 12.95413) QuantErr: 12.95413 batch_time=0.48419 
Train Epoch: 21 [155/250 19840/32000 (62%)] Loss: 1.16799 (QuantReg: 13.22547) QuantErr: 13.22547 batch_time=1.23036 
Train Epoch: 21 [166/250 21248/32000 (66%)] Loss: 1.14573 (QuantReg: 13.24907) QuantErr: 13.24907 batch_time=0.47794 
Train Epoch: 21 [177/250 22656/32000 (71%)] Loss: 0.98275 (QuantReg: 13.18660) QuantErr: 13.18660 batch_time=0.49663 
Train Epoch: 21 [188/250 24064/32000 (75%)] Loss: 1.06048 (QuantReg: 13.40302) QuantErr: 13.40302 batch_time=0.48492 
Train Epoch: 21 [199/250 25472/32000 (80%)] Loss: 1.07407 (QuantReg: 13.35163) QuantErr: 13.35163 batch_time=0.48103 
Train Epoch: 21 [210/250 26880/32000 (84%)] Loss: 1.08314 (QuantReg: 13.62918) QuantErr: 13.62918 batch_time=1.02260 
Train Epoch: 21 [221/250 28288/32000 (88%)] Loss: 0.90967 (QuantReg: 13.36172) QuantErr: 13.36172 batch_time=0.48325 
Train Epoch: 21 [232/250 29696/32000 (93%)] Loss: 1.05925 (QuantReg: 13.48204) QuantErr: 13.48204 batch_time=0.49619 
Train Epoch: 21 [243/250 31104/32000 (97%)] Loss: 1.13594 (QuantReg: 13.26313) QuantErr: 13.26313 batch_time=0.49600 
Train Epoch: 21 codebook_update_time=1.71861
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_MSRVTT_1kA_roberta-base/checkpoint-epoch21.pth ...
Done in 4.050s
removing stale ckpt [epoch 20] [took 0.00s]
 epoch          : 21
 loss           : 1.1029776327610017
 quant_reg      : 13.20656460571289
 quant_err      : 13.20656460571289
 learning_rate  : 3.584859224085419e-05
 n_samples      : 672000
 n_steps        : 5250
 MSRVTT_jsfusion_test/t2v_metrics/R1: 21.3
 MSRVTT_jsfusion_test/t2v_metrics/R5: 51.7
 MSRVTT_jsfusion_test/t2v_metrics/R10: 65.2
 MSRVTT_jsfusion_test/t2v_metrics/R50: 89.4
 MSRVTT_jsfusion_test/t2v_metrics/MedR: 5.0
 MSRVTT_jsfusion_test/t2v_metrics/MeanR: 25.281
 MSRVTT_jsfusion_test/t2v_metrics/geometric_mean_R1-R5-R10: 41.56290686996879
 MSRVTT_jsfusion_test/v2t_metrics/R1: 22.9
 MSRVTT_jsfusion_test/v2t_metrics/R5: 53.0
 MSRVTT_jsfusion_test/v2t_metrics/R10: 67.3
 MSRVTT_jsfusion_test/v2t_metrics/R50: 89.7
 MSRVTT_jsfusion_test/v2t_metrics/MedR: 5.0
 MSRVTT_jsfusion_test/v2t_metrics/MeanR: 23.389
 MSRVTT_jsfusion_test/v2t_metrics/geometric_mean_R1-R5-R10: 43.388583503523435
 mnt_best       : 42.64386310622815
 not_improved_count: 1
Train Epoch: 22 [1/250 128/32000 (0%)] Loss: 1.42250 (QuantReg: 12.94548) QuantErr: 12.94548 batch_time=25.44970 
Train Epoch: 22 [12/250 1536/32000 (5%)] Loss: 1.57540 (QuantReg: 13.25845) QuantErr: 13.25845 batch_time=0.52090 
Train Epoch: 22 [23/250 2944/32000 (9%)] Loss: 1.19406 (QuantReg: 13.00664) QuantErr: 13.00664 batch_time=0.50859 
Train Epoch: 22 [34/250 4352/32000 (14%)] Loss: 1.48445 (QuantReg: 13.27386) QuantErr: 13.27386 batch_time=0.50567 
Train Epoch: 22 [45/250 5760/32000 (18%)] Loss: 1.21743 (QuantReg: 13.15061) QuantErr: 13.15061 batch_time=0.50344 
Train Epoch: 22 [56/250 7168/32000 (22%)] Loss: 1.37191 (QuantReg: 13.05761) QuantErr: 13.05761 batch_time=0.49236 
Train Epoch: 22 [67/250 8576/32000 (27%)] Loss: 1.09315 (QuantReg: 13.52298) QuantErr: 13.52298 batch_time=0.49313 
Train Epoch: 22 [78/250 9984/32000 (31%)] Loss: 1.13058 (QuantReg: 13.07622) QuantErr: 13.07622 batch_time=0.48179 
Train Epoch: 22 [89/250 11392/32000 (36%)] Loss: 0.75276 (QuantReg: 13.59550) QuantErr: 13.59550 batch_time=0.49381 
Train Epoch: 22 [100/250 12800/32000 (40%)] Loss: 0.93433 (QuantReg: 13.24658) QuantErr: 13.24658 batch_time=0.48571 
Train Epoch: 22 [111/250 14208/32000 (44%)] Loss: 1.26415 (QuantReg: 13.43913) QuantErr: 13.43913 batch_time=0.48636 
Train Epoch: 22 [122/250 15616/32000 (49%)] Loss: 0.95044 (QuantReg: 13.22533) QuantErr: 13.22533 batch_time=0.48000 
Train Epoch: 22 [133/250 17024/32000 (53%)] Loss: 1.21187 (QuantReg: 13.07278) QuantErr: 13.07278 batch_time=0.47310 
Train Epoch: 22 [144/250 18432/32000 (58%)] Loss: 1.25007 (QuantReg: 13.15672) QuantErr: 13.15672 batch_time=0.47368 
Train Epoch: 22 [155/250 19840/32000 (62%)] Loss: 1.06510 (QuantReg: 13.45590) QuantErr: 13.45590 batch_time=0.50228 
Train Epoch: 22 [166/250 21248/32000 (66%)] Loss: 0.80245 (QuantReg: 13.39066) QuantErr: 13.39066 batch_time=0.48171 
Train Epoch: 22 [177/250 22656/32000 (71%)] Loss: 1.10459 (QuantReg: 13.67616) QuantErr: 13.67616 batch_time=0.48903 
Train Epoch: 22 [188/250 24064/32000 (75%)] Loss: 1.32641 (QuantReg: 13.51841) QuantErr: 13.51841 batch_time=0.48891 
Train Epoch: 22 [199/250 25472/32000 (80%)] Loss: 1.25127 (QuantReg: 13.16652) QuantErr: 13.16652 batch_time=0.84062 
Train Epoch: 22 [210/250 26880/32000 (84%)] Loss: 0.87356 (QuantReg: 12.97433) QuantErr: 12.97433 batch_time=4.34506 
Train Epoch: 22 [221/250 28288/32000 (88%)] Loss: 1.14339 (QuantReg: 13.08659) QuantErr: 13.08659 batch_time=0.50501 
Train Epoch: 22 [232/250 29696/32000 (93%)] Loss: 1.13510 (QuantReg: 13.13188) QuantErr: 13.13188 batch_time=0.49485 
Train Epoch: 22 [243/250 31104/32000 (97%)] Loss: 1.12954 (QuantReg: 13.51597) QuantErr: 13.51597 batch_time=0.49115 
Train Epoch: 22 codebook_update_time=1.62574
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_MSRVTT_1kA_roberta-base/checkpoint-epoch22.pth ...
Done in 12.664s
Updating 'best' checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_MSRVTT_1kA_roberta-base/checkpoint-epoch22.pth ...
Done in 16.601s
removing stale ckpt [epoch 21] [took 0.00s]
 epoch          : 22
 loss           : 1.0662442932128906
 quant_reg      : 13.260471683502198
 quant_err      : 13.260471683502198
 learning_rate  : 3.405616262881148e-05
 n_samples      : 704000
 n_steps        : 5500
 MSRVTT_jsfusion_test/t2v_metrics/R1: 22.9
 MSRVTT_jsfusion_test/t2v_metrics/R5: 53.3
 MSRVTT_jsfusion_test/t2v_metrics/R10: 66.9
 MSRVTT_jsfusion_test/t2v_metrics/R50: 89.4
 MSRVTT_jsfusion_test/t2v_metrics/MedR: 5.0
 MSRVTT_jsfusion_test/t2v_metrics/MeanR: 23.896
 MSRVTT_jsfusion_test/t2v_metrics/geometric_mean_R1-R5-R10: 43.384001160520526
 MSRVTT_jsfusion_test/v2t_metrics/R1: 23.8
 MSRVTT_jsfusion_test/v2t_metrics/R5: 54.0
 MSRVTT_jsfusion_test/v2t_metrics/R10: 69.4
 MSRVTT_jsfusion_test/v2t_metrics/R50: 89.9
 MSRVTT_jsfusion_test/v2t_metrics/MedR: 5.0
 MSRVTT_jsfusion_test/v2t_metrics/MeanR: 21.5665
 MSRVTT_jsfusion_test/v2t_metrics/geometric_mean_R1-R5-R10: 44.67968086904884
 mnt_best       : 43.384001160520526
 not_improved_count: 0
Train Epoch: 23 [1/250 128/32000 (0%)] Loss: 1.15277 (QuantReg: 13.04650) QuantErr: 13.04650 batch_time=27.83075 
Train Epoch: 23 [12/250 1536/32000 (5%)] Loss: 1.29943 (QuantReg: 13.06130) QuantErr: 13.06130 batch_time=0.48720 
Train Epoch: 23 [23/250 2944/32000 (9%)] Loss: 1.09741 (QuantReg: 13.24754) QuantErr: 13.24754 batch_time=0.48117 
Train Epoch: 23 [34/250 4352/32000 (14%)] Loss: 1.03686 (QuantReg: 12.96593) QuantErr: 12.96593 batch_time=0.47934 
Train Epoch: 23 [45/250 5760/32000 (18%)] Loss: 1.37603 (QuantReg: 13.27438) QuantErr: 13.27438 batch_time=0.51657 
Train Epoch: 23 [56/250 7168/32000 (22%)] Loss: 0.73047 (QuantReg: 13.63094) QuantErr: 13.63094 batch_time=0.50663 
Train Epoch: 23 [67/250 8576/32000 (27%)] Loss: 0.88533 (QuantReg: 13.50966) QuantErr: 13.50966 batch_time=0.48829 
Train Epoch: 23 [78/250 9984/32000 (31%)] Loss: 0.96755 (QuantReg: 13.13040) QuantErr: 13.13040 batch_time=0.48029 
Train Epoch: 23 [89/250 11392/32000 (36%)] Loss: 1.24965 (QuantReg: 13.35209) QuantErr: 13.35209 batch_time=0.49148 
Train Epoch: 23 [100/250 12800/32000 (40%)] Loss: 0.69026 (QuantReg: 13.44733) QuantErr: 13.44733 batch_time=0.48550 
Train Epoch: 23 [111/250 14208/32000 (44%)] Loss: 1.01747 (QuantReg: 13.08113) QuantErr: 13.08113 batch_time=0.50095 
Train Epoch: 23 [122/250 15616/32000 (49%)] Loss: 1.32158 (QuantReg: 13.47630) QuantErr: 13.47630 batch_time=0.51750 
Train Epoch: 23 [133/250 17024/32000 (53%)] Loss: 1.31684 (QuantReg: 13.07840) QuantErr: 13.07840 batch_time=0.60645 
Train Epoch: 23 [144/250 18432/32000 (58%)] Loss: 0.82686 (QuantReg: 13.18178) QuantErr: 13.18178 batch_time=0.68672 
Train Epoch: 23 [155/250 19840/32000 (62%)] Loss: 1.35563 (QuantReg: 13.48839) QuantErr: 13.48839 batch_time=0.47680 
Train Epoch: 23 [166/250 21248/32000 (66%)] Loss: 0.92686 (QuantReg: 13.31433) QuantErr: 13.31433 batch_time=0.48327 
Train Epoch: 23 [177/250 22656/32000 (71%)] Loss: 1.43231 (QuantReg: 13.30979) QuantErr: 13.30979 batch_time=0.49648 
Train Epoch: 23 [188/250 24064/32000 (75%)] Loss: 0.84061 (QuantReg: 13.64183) QuantErr: 13.64183 batch_time=0.49604 
Train Epoch: 23 [199/250 25472/32000 (80%)] Loss: 0.98196 (QuantReg: 13.48004) QuantErr: 13.48004 batch_time=0.49397 
Train Epoch: 23 [210/250 26880/32000 (84%)] Loss: 0.96886 (QuantReg: 13.20247) QuantErr: 13.20247 batch_time=0.48414 
Train Epoch: 23 [221/250 28288/32000 (88%)] Loss: 1.13427 (QuantReg: 13.49242) QuantErr: 13.49242 batch_time=0.48307 
Train Epoch: 23 [232/250 29696/32000 (93%)] Loss: 1.02399 (QuantReg: 13.14499) QuantErr: 13.14499 batch_time=0.48161 
Train Epoch: 23 [243/250 31104/32000 (97%)] Loss: 1.15370 (QuantReg: 12.87689) QuantErr: 12.87689 batch_time=0.48800 
Train Epoch: 23 codebook_update_time=1.63029
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_MSRVTT_1kA_roberta-base/checkpoint-epoch23.pth ...
Done in 4.244s
Updating 'best' checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_MSRVTT_1kA_roberta-base/checkpoint-epoch23.pth ...
Done in 8.184s
removing stale ckpt [epoch 22] [took 0.00s]
 epoch          : 23
 loss           : 1.0388291110992431
 quant_reg      : 13.25239246749878
 quant_err      : 13.25239246749878
 learning_rate  : 3.2353354497370904e-05
 n_samples      : 736000
 n_steps        : 5750
 MSRVTT_jsfusion_test/t2v_metrics/R1: 23.1
 MSRVTT_jsfusion_test/t2v_metrics/R5: 54.3
 MSRVTT_jsfusion_test/t2v_metrics/R10: 66.8
 MSRVTT_jsfusion_test/t2v_metrics/R50: 90.2
 MSRVTT_jsfusion_test/t2v_metrics/MedR: 5.0
 MSRVTT_jsfusion_test/t2v_metrics/MeanR: 24.023
 MSRVTT_jsfusion_test/t2v_metrics/geometric_mean_R1-R5-R10: 43.7585333450047
 MSRVTT_jsfusion_test/v2t_metrics/R1: 23.1
 MSRVTT_jsfusion_test/v2t_metrics/R5: 54.6
 MSRVTT_jsfusion_test/v2t_metrics/R10: 69.1
 MSRVTT_jsfusion_test/v2t_metrics/R50: 90.0
 MSRVTT_jsfusion_test/v2t_metrics/MedR: 4.0
 MSRVTT_jsfusion_test/v2t_metrics/MeanR: 22.5485
 MSRVTT_jsfusion_test/v2t_metrics/geometric_mean_R1-R5-R10: 44.33644730358441
 mnt_best       : 43.7585333450047
 not_improved_count: 0
Train Epoch: 24 [1/250 128/32000 (0%)] Loss: 0.82468 (QuantReg: 13.19801) QuantErr: 13.19801 batch_time=33.89242 
Train Epoch: 24 [12/250 1536/32000 (5%)] Loss: 0.94658 (QuantReg: 13.45876) QuantErr: 13.45876 batch_time=0.51361 
Train Epoch: 24 [23/250 2944/32000 (9%)] Loss: 1.30140 (QuantReg: 12.78446) QuantErr: 12.78446 batch_time=0.47831 
Train Epoch: 24 [34/250 4352/32000 (14%)] Loss: 1.08130 (QuantReg: 13.21490) QuantErr: 13.21490 batch_time=3.05874 
Train Epoch: 24 [45/250 5760/32000 (18%)] Loss: 1.02089 (QuantReg: 13.32579) QuantErr: 13.32579 batch_time=0.49863 
Train Epoch: 24 [56/250 7168/32000 (22%)] Loss: 1.16317 (QuantReg: 12.72989) QuantErr: 12.72989 batch_time=0.48533 
Train Epoch: 24 [67/250 8576/32000 (27%)] Loss: 0.81853 (QuantReg: 13.36761) QuantErr: 13.36761 batch_time=0.74340 
Train Epoch: 24 [78/250 9984/32000 (31%)] Loss: 0.88755 (QuantReg: 13.25585) QuantErr: 13.25585 batch_time=0.48574 
Train Epoch: 24 [89/250 11392/32000 (36%)] Loss: 1.08430 (QuantReg: 13.09027) QuantErr: 13.09027 batch_time=0.48126 
Train Epoch: 24 [100/250 12800/32000 (40%)] Loss: 1.18005 (QuantReg: 12.79085) QuantErr: 12.79085 batch_time=1.18516 
Train Epoch: 24 [111/250 14208/32000 (44%)] Loss: 0.95446 (QuantReg: 13.32781) QuantErr: 13.32781 batch_time=0.49744 
Train Epoch: 24 [122/250 15616/32000 (49%)] Loss: 0.98680 (QuantReg: 13.43203) QuantErr: 13.43203 batch_time=0.48136 
Train Epoch: 24 [133/250 17024/32000 (53%)] Loss: 0.84488 (QuantReg: 13.18234) QuantErr: 13.18234 batch_time=0.49334 
Train Epoch: 24 [144/250 18432/32000 (58%)] Loss: 0.86141 (QuantReg: 13.54273) QuantErr: 13.54273 batch_time=0.48572 
Train Epoch: 24 [155/250 19840/32000 (62%)] Loss: 0.99290 (QuantReg: 13.24569) QuantErr: 13.24569 batch_time=0.49235 
Train Epoch: 24 [166/250 21248/32000 (66%)] Loss: 0.83006 (QuantReg: 13.32632) QuantErr: 13.32632 batch_time=0.49202 
Train Epoch: 24 [177/250 22656/32000 (71%)] Loss: 1.05367 (QuantReg: 13.16662) QuantErr: 13.16662 batch_time=0.50513 
Train Epoch: 24 [188/250 24064/32000 (75%)] Loss: 0.87882 (QuantReg: 13.45014) QuantErr: 13.45014 batch_time=0.48630 
Train Epoch: 24 [199/250 25472/32000 (80%)] Loss: 0.91704 (QuantReg: 13.64253) QuantErr: 13.64253 batch_time=0.48179 
Train Epoch: 24 [210/250 26880/32000 (84%)] Loss: 0.73510 (QuantReg: 13.13080) QuantErr: 13.13080 batch_time=0.49589 
Train Epoch: 24 [221/250 28288/32000 (88%)] Loss: 1.27520 (QuantReg: 13.52516) QuantErr: 13.52516 batch_time=0.48736 
Train Epoch: 24 [232/250 29696/32000 (93%)] Loss: 0.98502 (QuantReg: 13.41431) QuantErr: 13.41431 batch_time=0.48361 
Train Epoch: 24 [243/250 31104/32000 (97%)] Loss: 0.96711 (QuantReg: 13.32376) QuantErr: 13.32376 batch_time=0.48472 
Train Epoch: 24 codebook_update_time=1.60309
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_MSRVTT_1kA_roberta-base/checkpoint-epoch24.pth ...
Done in 4.085s
removing stale ckpt [epoch 23] [took 0.00s]
 epoch          : 24
 loss           : 1.007991623401642
 quant_reg      : 13.277650772094727
 quant_err      : 13.277650772094727
 learning_rate  : 3.0735686772502355e-05
 n_samples      : 768000
 n_steps        : 6000
 MSRVTT_jsfusion_test/t2v_metrics/R1: 22.5
 MSRVTT_jsfusion_test/t2v_metrics/R5: 54.6
 MSRVTT_jsfusion_test/t2v_metrics/R10: 67.1
 MSRVTT_jsfusion_test/t2v_metrics/R50: 89.2
 MSRVTT_jsfusion_test/t2v_metrics/MedR: 4.0
 MSRVTT_jsfusion_test/t2v_metrics/MeanR: 24.938
 MSRVTT_jsfusion_test/t2v_metrics/geometric_mean_R1-R5-R10: 43.52103619881346
 MSRVTT_jsfusion_test/v2t_metrics/R1: 23.5
 MSRVTT_jsfusion_test/v2t_metrics/R5: 53.0
 MSRVTT_jsfusion_test/v2t_metrics/R10: 69.4
 MSRVTT_jsfusion_test/v2t_metrics/R50: 89.5
 MSRVTT_jsfusion_test/v2t_metrics/MedR: 5.0
 MSRVTT_jsfusion_test/v2t_metrics/MeanR: 22.4475
 MSRVTT_jsfusion_test/v2t_metrics/geometric_mean_R1-R5-R10: 44.21480704810501
 mnt_best       : 43.7585333450047
 not_improved_count: 1
Train Epoch: 25 [1/250 128/32000 (0%)] Loss: 0.99945 (QuantReg: 13.27877) QuantErr: 13.27877 batch_time=30.68703 
Train Epoch: 25 [12/250 1536/32000 (5%)] Loss: 0.86738 (QuantReg: 13.16814) QuantErr: 13.16814 batch_time=0.47433 
Train Epoch: 25 [23/250 2944/32000 (9%)] Loss: 1.64058 (QuantReg: 13.41315) QuantErr: 13.41315 batch_time=0.48322 
Train Epoch: 25 [34/250 4352/32000 (14%)] Loss: 0.99126 (QuantReg: 13.34959) QuantErr: 13.34959 batch_time=0.47040 
Train Epoch: 25 [45/250 5760/32000 (18%)] Loss: 1.09878 (QuantReg: 13.16562) QuantErr: 13.16562 batch_time=0.49051 
Train Epoch: 25 [56/250 7168/32000 (22%)] Loss: 1.18398 (QuantReg: 13.49984) QuantErr: 13.49984 batch_time=0.48007 
Train Epoch: 25 [67/250 8576/32000 (27%)] Loss: 0.88422 (QuantReg: 13.36930) QuantErr: 13.36930 batch_time=0.48698 
Train Epoch: 25 [78/250 9984/32000 (31%)] Loss: 1.01771 (QuantReg: 13.50779) QuantErr: 13.50779 batch_time=0.49379 
Train Epoch: 25 [89/250 11392/32000 (36%)] Loss: 0.90846 (QuantReg: 13.28292) QuantErr: 13.28292 batch_time=0.48534 
Train Epoch: 25 [100/250 12800/32000 (40%)] Loss: 0.91764 (QuantReg: 13.32541) QuantErr: 13.32541 batch_time=0.49281 
Train Epoch: 25 [111/250 14208/32000 (44%)] Loss: 0.95533 (QuantReg: 13.29041) QuantErr: 13.29041 batch_time=0.47687 
Train Epoch: 25 [122/250 15616/32000 (49%)] Loss: 0.88970 (QuantReg: 13.49531) QuantErr: 13.49531 batch_time=0.49314 
Train Epoch: 25 [133/250 17024/32000 (53%)] Loss: 0.88162 (QuantReg: 13.58132) QuantErr: 13.58132 batch_time=0.49644 
Train Epoch: 25 [144/250 18432/32000 (58%)] Loss: 0.86808 (QuantReg: 13.51274) QuantErr: 13.51274 batch_time=0.80923 
Train Epoch: 25 [155/250 19840/32000 (62%)] Loss: 0.97708 (QuantReg: 13.03055) QuantErr: 13.03055 batch_time=0.49181 
Train Epoch: 25 [166/250 21248/32000 (66%)] Loss: 0.96721 (QuantReg: 13.37438) QuantErr: 13.37438 batch_time=0.49098 
Train Epoch: 25 [177/250 22656/32000 (71%)] Loss: 0.90003 (QuantReg: 13.77248) QuantErr: 13.77248 batch_time=0.49772 
Train Epoch: 25 [188/250 24064/32000 (75%)] Loss: 0.91160 (QuantReg: 13.33647) QuantErr: 13.33647 batch_time=0.79962 
Train Epoch: 25 [199/250 25472/32000 (80%)] Loss: 0.78366 (QuantReg: 13.41288) QuantErr: 13.41288 batch_time=0.48191 
Train Epoch: 25 [210/250 26880/32000 (84%)] Loss: 0.80251 (QuantReg: 13.53143) QuantErr: 13.53143 batch_time=0.48040 
Train Epoch: 25 [221/250 28288/32000 (88%)] Loss: 1.33320 (QuantReg: 13.11409) QuantErr: 13.11409 batch_time=0.49840 
Train Epoch: 25 [232/250 29696/32000 (93%)] Loss: 0.81856 (QuantReg: 13.79943) QuantErr: 13.79943 batch_time=0.49616 
Train Epoch: 25 [243/250 31104/32000 (97%)] Loss: 1.14014 (QuantReg: 13.50928) QuantErr: 13.50928 batch_time=0.82581 
Train Epoch: 25 codebook_update_time=1.85887
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_MSRVTT_1kA_roberta-base/checkpoint-epoch25.pth ...
Done in 3.823s
removing stale ckpt [epoch 24] [took 0.00s]
 epoch          : 25
 loss           : 0.9815811302661895
 quant_reg      : 13.365996131896972
 quant_err      : 13.365996131896972
 learning_rate  : 2.9198902433877236e-05
 n_samples      : 800000
 n_steps        : 6250
 MSRVTT_jsfusion_test/t2v_metrics/R1: 22.9
 MSRVTT_jsfusion_test/t2v_metrics/R5: 54.3
 MSRVTT_jsfusion_test/t2v_metrics/R10: 67.1
 MSRVTT_jsfusion_test/t2v_metrics/R50: 89.7
 MSRVTT_jsfusion_test/t2v_metrics/MedR: 4.5
 MSRVTT_jsfusion_test/t2v_metrics/MeanR: 25.223
 MSRVTT_jsfusion_test/t2v_metrics/geometric_mean_R1-R5-R10: 43.69709951128224
 MSRVTT_jsfusion_test/v2t_metrics/R1: 22.4
 MSRVTT_jsfusion_test/v2t_metrics/R5: 53.7
 MSRVTT_jsfusion_test/v2t_metrics/R10: 69.3
 MSRVTT_jsfusion_test/v2t_metrics/R50: 90.1
 MSRVTT_jsfusion_test/v2t_metrics/MedR: 5.0
 MSRVTT_jsfusion_test/v2t_metrics/MeanR: 22.2855
 MSRVTT_jsfusion_test/v2t_metrics/geometric_mean_R1-R5-R10: 43.68360916923076
 mnt_best       : 43.7585333450047
 not_improved_count: 2
Train Epoch: 26 [1/250 128/32000 (0%)] Loss: 0.97872 (QuantReg: 13.36069) QuantErr: 13.36069 batch_time=23.56761 
Train Epoch: 26 [12/250 1536/32000 (5%)] Loss: 1.03532 (QuantReg: 13.05002) QuantErr: 13.05002 batch_time=0.48446 
Train Epoch: 26 [23/250 2944/32000 (9%)] Loss: 0.73548 (QuantReg: 13.57146) QuantErr: 13.57146 batch_time=0.47987 
Train Epoch: 26 [34/250 4352/32000 (14%)] Loss: 1.01196 (QuantReg: 13.41024) QuantErr: 13.41024 batch_time=0.47283 
Train Epoch: 26 [45/250 5760/32000 (18%)] Loss: 0.95553 (QuantReg: 13.04234) QuantErr: 13.04234 batch_time=0.47712 
Train Epoch: 26 [56/250 7168/32000 (22%)] Loss: 0.79635 (QuantReg: 13.49634) QuantErr: 13.49634 batch_time=0.47736 
Train Epoch: 26 [67/250 8576/32000 (27%)] Loss: 0.97711 (QuantReg: 13.40609) QuantErr: 13.40609 batch_time=3.48523 
Train Epoch: 26 [78/250 9984/32000 (31%)] Loss: 0.94742 (QuantReg: 13.27924) QuantErr: 13.27924 batch_time=0.49742 
Train Epoch: 26 [89/250 11392/32000 (36%)] Loss: 0.86711 (QuantReg: 13.37822) QuantErr: 13.37822 batch_time=0.48907 
Train Epoch: 26 [100/250 12800/32000 (40%)] Loss: 1.00655 (QuantReg: 13.44381) QuantErr: 13.44381 batch_time=0.92553 
Train Epoch: 26 [111/250 14208/32000 (44%)] Loss: 1.09913 (QuantReg: 13.38885) QuantErr: 13.38885 batch_time=0.49421 
Train Epoch: 26 [122/250 15616/32000 (49%)] Loss: 1.14711 (QuantReg: 13.19078) QuantErr: 13.19078 batch_time=0.71352 
Train Epoch: 26 [133/250 17024/32000 (53%)] Loss: 1.29887 (QuantReg: 13.12589) QuantErr: 13.12589 batch_time=0.48121 
Train Epoch: 26 [144/250 18432/32000 (58%)] Loss: 1.19337 (QuantReg: 13.18583) QuantErr: 13.18583 batch_time=0.47662 
Train Epoch: 26 [155/250 19840/32000 (62%)] Loss: 0.90947 (QuantReg: 13.39964) QuantErr: 13.39964 batch_time=0.47508 
Train Epoch: 26 [166/250 21248/32000 (66%)] Loss: 1.01786 (QuantReg: 13.35320) QuantErr: 13.35320 batch_time=0.70231 
Train Epoch: 26 [177/250 22656/32000 (71%)] Loss: 1.14127 (QuantReg: 13.36214) QuantErr: 13.36214 batch_time=0.47518 
Train Epoch: 26 [188/250 24064/32000 (75%)] Loss: 0.87714 (QuantReg: 13.64693) QuantErr: 13.64693 batch_time=0.58776 
Train Epoch: 26 [199/250 25472/32000 (80%)] Loss: 1.39318 (QuantReg: 13.44540) QuantErr: 13.44540 batch_time=0.47055 
Train Epoch: 26 [210/250 26880/32000 (84%)] Loss: 0.66679 (QuantReg: 13.87070) QuantErr: 13.87070 batch_time=0.50271 
Train Epoch: 26 [221/250 28288/32000 (88%)] Loss: 0.91685 (QuantReg: 13.43698) QuantErr: 13.43698 batch_time=0.49174 
Train Epoch: 26 [232/250 29696/32000 (93%)] Loss: 0.84232 (QuantReg: 13.64831) QuantErr: 13.64831 batch_time=0.49411 
Train Epoch: 26 [243/250 31104/32000 (97%)] Loss: 0.84811 (QuantReg: 13.32251) QuantErr: 13.32251 batch_time=0.50391 
Train Epoch: 26 codebook_update_time=1.90982
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_MSRVTT_1kA_roberta-base/checkpoint-epoch26.pth ...
Done in 4.245s
removing stale ckpt [epoch 25] [took 0.00s]
 epoch          : 26
 loss           : 0.9635830934047699
 quant_reg      : 13.375402130126954
 quant_err      : 13.375402130126954
 learning_rate  : 2.7738957312183373e-05
 n_samples      : 832000
 n_steps        : 6500
 MSRVTT_jsfusion_test/t2v_metrics/R1: 22.7
 MSRVTT_jsfusion_test/t2v_metrics/R5: 55.4
 MSRVTT_jsfusion_test/t2v_metrics/R10: 66.6
 MSRVTT_jsfusion_test/t2v_metrics/R50: 90.1
 MSRVTT_jsfusion_test/t2v_metrics/MedR: 4.0
 MSRVTT_jsfusion_test/t2v_metrics/MeanR: 24.36
 MSRVTT_jsfusion_test/t2v_metrics/geometric_mean_R1-R5-R10: 43.75254132720776
 MSRVTT_jsfusion_test/v2t_metrics/R1: 23.6
 MSRVTT_jsfusion_test/v2t_metrics/R5: 53.5
 MSRVTT_jsfusion_test/v2t_metrics/R10: 68.1
 MSRVTT_jsfusion_test/v2t_metrics/R50: 90.0
 MSRVTT_jsfusion_test/v2t_metrics/MedR: 5.0
 MSRVTT_jsfusion_test/v2t_metrics/MeanR: 22.3335
 MSRVTT_jsfusion_test/v2t_metrics/geometric_mean_R1-R5-R10: 44.137151246353966
 mnt_best       : 43.7585333450047
 not_improved_count: 3
Train Epoch: 27 [1/250 128/32000 (0%)] Loss: 0.83866 (QuantReg: 12.93821) QuantErr: 12.93821 batch_time=29.85310 
Train Epoch: 27 [12/250 1536/32000 (5%)] Loss: 1.36129 (QuantReg: 12.95082) QuantErr: 12.95082 batch_time=0.54223 
Train Epoch: 27 [23/250 2944/32000 (9%)] Loss: 0.90475 (QuantReg: 13.14935) QuantErr: 13.14935 batch_time=0.50285 
Train Epoch: 27 [34/250 4352/32000 (14%)] Loss: 0.91875 (QuantReg: 13.29463) QuantErr: 13.29463 batch_time=0.49204 
Train Epoch: 27 [45/250 5760/32000 (18%)] Loss: 0.90018 (QuantReg: 13.19043) QuantErr: 13.19043 batch_time=0.60469 
Train Epoch: 27 [56/250 7168/32000 (22%)] Loss: 0.95953 (QuantReg: 13.17672) QuantErr: 13.17672 batch_time=0.48794 
Train Epoch: 27 [67/250 8576/32000 (27%)] Loss: 0.80878 (QuantReg: 13.10896) QuantErr: 13.10896 batch_time=0.48486 
Train Epoch: 27 [78/250 9984/32000 (31%)] Loss: 0.85543 (QuantReg: 13.61594) QuantErr: 13.61594 batch_time=0.49165 
Train Epoch: 27 [89/250 11392/32000 (36%)] Loss: 1.20258 (QuantReg: 13.16438) QuantErr: 13.16438 batch_time=1.23362 
Train Epoch: 27 [100/250 12800/32000 (40%)] Loss: 0.92944 (QuantReg: 13.21978) QuantErr: 13.21978 batch_time=0.48176 
Train Epoch: 27 [111/250 14208/32000 (44%)] Loss: 1.03365 (QuantReg: 13.45206) QuantErr: 13.45206 batch_time=0.60526 
Train Epoch: 27 [122/250 15616/32000 (49%)] Loss: 0.72232 (QuantReg: 13.38801) QuantErr: 13.38801 batch_time=0.47984 
Train Epoch: 27 [133/250 17024/32000 (53%)] Loss: 1.04666 (QuantReg: 13.30898) QuantErr: 13.30898 batch_time=0.48763 
Train Epoch: 27 [144/250 18432/32000 (58%)] Loss: 0.75658 (QuantReg: 13.52631) QuantErr: 13.52631 batch_time=0.81680 
Train Epoch: 27 [155/250 19840/32000 (62%)] Loss: 0.82051 (QuantReg: 13.21235) QuantErr: 13.21235 batch_time=0.49117 
Train Epoch: 27 [166/250 21248/32000 (66%)] Loss: 0.88876 (QuantReg: 13.55849) QuantErr: 13.55849 batch_time=0.48066 
Train Epoch: 27 [177/250 22656/32000 (71%)] Loss: 0.86983 (QuantReg: 13.43667) QuantErr: 13.43667 batch_time=0.60471 
Train Epoch: 27 [188/250 24064/32000 (75%)] Loss: 1.00830 (QuantReg: 13.07330) QuantErr: 13.07330 batch_time=0.49365 
Train Epoch: 27 [199/250 25472/32000 (80%)] Loss: 0.82834 (QuantReg: 13.53814) QuantErr: 13.53814 batch_time=0.48256 
Train Epoch: 27 [210/250 26880/32000 (84%)] Loss: 1.11827 (QuantReg: 13.37026) QuantErr: 13.37026 batch_time=0.48039 
Train Epoch: 27 [221/250 28288/32000 (88%)] Loss: 1.10340 (QuantReg: 13.39078) QuantErr: 13.39078 batch_time=0.48464 
Train Epoch: 27 [232/250 29696/32000 (93%)] Loss: 0.65587 (QuantReg: 13.46951) QuantErr: 13.46951 batch_time=0.48529 
Train Epoch: 27 [243/250 31104/32000 (97%)] Loss: 1.03758 (QuantReg: 13.22472) QuantErr: 13.22472 batch_time=0.47936 
Train Epoch: 27 codebook_update_time=1.62357
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_MSRVTT_1kA_roberta-base/checkpoint-epoch27.pth ...
Done in 4.116s
removing stale ckpt [epoch 26] [took 0.00s]
 epoch          : 27
 loss           : 0.9506648080348968
 quant_reg      : 13.375730159759522
 quant_err      : 13.375730159759522
 learning_rate  : 2.6352009446574204e-05
 n_samples      : 864000
 n_steps        : 6750
 MSRVTT_jsfusion_test/t2v_metrics/R1: 23.2
 MSRVTT_jsfusion_test/t2v_metrics/R5: 53.6
 MSRVTT_jsfusion_test/t2v_metrics/R10: 66.6
 MSRVTT_jsfusion_test/t2v_metrics/R50: 90.0
 MSRVTT_jsfusion_test/t2v_metrics/MedR: 5.0
 MSRVTT_jsfusion_test/t2v_metrics/MeanR: 24.8
 MSRVTT_jsfusion_test/t2v_metrics/geometric_mean_R1-R5-R10: 43.58887576365895
 MSRVTT_jsfusion_test/v2t_metrics/R1: 23.8
 MSRVTT_jsfusion_test/v2t_metrics/R5: 54.5
 MSRVTT_jsfusion_test/v2t_metrics/R10: 68.3
 MSRVTT_jsfusion_test/v2t_metrics/R50: 89.7
 MSRVTT_jsfusion_test/v2t_metrics/MedR: 5.0
 MSRVTT_jsfusion_test/v2t_metrics/MeanR: 22.5525
 MSRVTT_jsfusion_test/v2t_metrics/geometric_mean_R1-R5-R10: 44.57910937554264
 mnt_best       : 43.7585333450047
 not_improved_count: 4
Train Epoch: 28 [1/250 128/32000 (0%)] Loss: 0.97901 (QuantReg: 12.92075) QuantErr: 12.92075 batch_time=25.88027 
Train Epoch: 28 [12/250 1536/32000 (5%)] Loss: 0.99459 (QuantReg: 13.16217) QuantErr: 13.16217 batch_time=0.49737 
Train Epoch: 28 [23/250 2944/32000 (9%)] Loss: 0.74092 (QuantReg: 13.40668) QuantErr: 13.40668 batch_time=0.48097 
Train Epoch: 28 [34/250 4352/32000 (14%)] Loss: 1.01880 (QuantReg: 13.21777) QuantErr: 13.21777 batch_time=0.49646 
Train Epoch: 28 [45/250 5760/32000 (18%)] Loss: 0.58763 (QuantReg: 13.63238) QuantErr: 13.63238 batch_time=0.48227 
Train Epoch: 28 [56/250 7168/32000 (22%)] Loss: 1.18703 (QuantReg: 13.29038) QuantErr: 13.29038 batch_time=0.58571 
Train Epoch: 28 [67/250 8576/32000 (27%)] Loss: 0.84096 (QuantReg: 13.33112) QuantErr: 13.33112 batch_time=0.54164 
Train Epoch: 28 [78/250 9984/32000 (31%)] Loss: 0.85857 (QuantReg: 13.29003) QuantErr: 13.29003 batch_time=0.85186 
Train Epoch: 28 [89/250 11392/32000 (36%)] Loss: 0.86663 (QuantReg: 13.32353) QuantErr: 13.32353 batch_time=0.47992 
Train Epoch: 28 [100/250 12800/32000 (40%)] Loss: 1.05148 (QuantReg: 13.57808) QuantErr: 13.57808 batch_time=0.47579 
Train Epoch: 28 [111/250 14208/32000 (44%)] Loss: 1.10215 (QuantReg: 13.31897) QuantErr: 13.31897 batch_time=0.49529 
Train Epoch: 28 [122/250 15616/32000 (49%)] Loss: 0.65369 (QuantReg: 13.41740) QuantErr: 13.41740 batch_time=0.48606 
Train Epoch: 28 [133/250 17024/32000 (53%)] Loss: 1.10940 (QuantReg: 13.37956) QuantErr: 13.37956 batch_time=0.74196 
Train Epoch: 28 [144/250 18432/32000 (58%)] Loss: 0.99744 (QuantReg: 13.58941) QuantErr: 13.58941 batch_time=0.49149 
Train Epoch: 28 [155/250 19840/32000 (62%)] Loss: 1.21053 (QuantReg: 13.55433) QuantErr: 13.55433 batch_time=0.89774 
Train Epoch: 28 [166/250 21248/32000 (66%)] Loss: 1.28875 (QuantReg: 13.73476) QuantErr: 13.73476 batch_time=0.47610 
Train Epoch: 28 [177/250 22656/32000 (71%)] Loss: 1.25545 (QuantReg: 13.29589) QuantErr: 13.29589 batch_time=0.48722 
Train Epoch: 28 [188/250 24064/32000 (75%)] Loss: 0.91646 (QuantReg: 13.42123) QuantErr: 13.42123 batch_time=0.49123 
Train Epoch: 28 [199/250 25472/32000 (80%)] Loss: 0.82303 (QuantReg: 13.66983) QuantErr: 13.66983 batch_time=0.61658 
Train Epoch: 28 [210/250 26880/32000 (84%)] Loss: 0.90906 (QuantReg: 13.64206) QuantErr: 13.64206 batch_time=0.47019 
Train Epoch: 28 [221/250 28288/32000 (88%)] Loss: 0.72353 (QuantReg: 13.50406) QuantErr: 13.50406 batch_time=0.47196 
Train Epoch: 28 [232/250 29696/32000 (93%)] Loss: 0.84654 (QuantReg: 13.48187) QuantErr: 13.48187 batch_time=0.50059 
Train Epoch: 28 [243/250 31104/32000 (97%)] Loss: 0.97719 (QuantReg: 13.45512) QuantErr: 13.45512 batch_time=0.68618 
Train Epoch: 28 codebook_update_time=1.58254
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_MSRVTT_1kA_roberta-base/checkpoint-epoch28.pth ...
Done in 4.055s
removing stale ckpt [epoch 27] [took 0.00s]
 epoch          : 28
 loss           : 0.9170336532592773
 quant_reg      : 13.416763927459717
 quant_err      : 13.416763927459717
 learning_rate  : 2.5034408974245492e-05
 n_samples      : 896000
 n_steps        : 7000
 MSRVTT_jsfusion_test/t2v_metrics/R1: 21.5
 MSRVTT_jsfusion_test/t2v_metrics/R5: 53.9
 MSRVTT_jsfusion_test/t2v_metrics/R10: 66.8
 MSRVTT_jsfusion_test/t2v_metrics/R50: 89.6
 MSRVTT_jsfusion_test/t2v_metrics/MedR: 5.0
 MSRVTT_jsfusion_test/t2v_metrics/MeanR: 25.236
 MSRVTT_jsfusion_test/t2v_metrics/geometric_mean_R1-R5-R10: 42.61880116711732
 MSRVTT_jsfusion_test/v2t_metrics/R1: 22.7
 MSRVTT_jsfusion_test/v2t_metrics/R5: 54.3
 MSRVTT_jsfusion_test/v2t_metrics/R10: 68.2
 MSRVTT_jsfusion_test/v2t_metrics/R50: 90.1
 MSRVTT_jsfusion_test/v2t_metrics/MedR: 5.0
 MSRVTT_jsfusion_test/v2t_metrics/MeanR: 23.12
 MSRVTT_jsfusion_test/v2t_metrics/geometric_mean_R1-R5-R10: 43.80631151098585
 mnt_best       : 43.7585333450047
 not_improved_count: 5
Train Epoch: 29 [1/250 128/32000 (0%)] Loss: 0.97197 (QuantReg: 13.33347) QuantErr: 13.33347 batch_time=29.20421 
Train Epoch: 29 [12/250 1536/32000 (5%)] Loss: 0.79949 (QuantReg: 13.18721) QuantErr: 13.18721 batch_time=0.49301 
Train Epoch: 29 [23/250 2944/32000 (9%)] Loss: 0.72830 (QuantReg: 13.39422) QuantErr: 13.39422 batch_time=0.48591 
Train Epoch: 29 [34/250 4352/32000 (14%)] Loss: 0.91747 (QuantReg: 13.11250) QuantErr: 13.11250 batch_time=0.49566 
Train Epoch: 29 [45/250 5760/32000 (18%)] Loss: 1.02197 (QuantReg: 13.55443) QuantErr: 13.55443 batch_time=0.51104 
Train Epoch: 29 [56/250 7168/32000 (22%)] Loss: 0.98679 (QuantReg: 13.33686) QuantErr: 13.33686 batch_time=0.49518 
Train Epoch: 29 [67/250 8576/32000 (27%)] Loss: 1.34922 (QuantReg: 13.41505) QuantErr: 13.41505 batch_time=0.49533 
Train Epoch: 29 [78/250 9984/32000 (31%)] Loss: 0.82359 (QuantReg: 13.50238) QuantErr: 13.50238 batch_time=0.49984 
Train Epoch: 29 [89/250 11392/32000 (36%)] Loss: 0.82370 (QuantReg: 13.62453) QuantErr: 13.62453 batch_time=0.48160 
Train Epoch: 29 [100/250 12800/32000 (40%)] Loss: 0.91351 (QuantReg: 13.19056) QuantErr: 13.19056 batch_time=0.48873 
Train Epoch: 29 [111/250 14208/32000 (44%)] Loss: 1.11180 (QuantReg: 13.58554) QuantErr: 13.58554 batch_time=0.48972 
Train Epoch: 29 [122/250 15616/32000 (49%)] Loss: 1.04848 (QuantReg: 13.82458) QuantErr: 13.82458 batch_time=0.48810 
Train Epoch: 29 [133/250 17024/32000 (53%)] Loss: 0.77216 (QuantReg: 13.53194) QuantErr: 13.53194 batch_time=0.81387 
Train Epoch: 29 [144/250 18432/32000 (58%)] Loss: 0.88641 (QuantReg: 13.52895) QuantErr: 13.52895 batch_time=0.49653 
Train Epoch: 29 [155/250 19840/32000 (62%)] Loss: 0.79840 (QuantReg: 13.53330) QuantErr: 13.53330 batch_time=0.48732 
Train Epoch: 29 [166/250 21248/32000 (66%)] Loss: 0.97441 (QuantReg: 13.59164) QuantErr: 13.59164 batch_time=0.48949 
Train Epoch: 29 [177/250 22656/32000 (71%)] Loss: 0.91478 (QuantReg: 13.52576) QuantErr: 13.52576 batch_time=0.48453 
Train Epoch: 29 [188/250 24064/32000 (75%)] Loss: 1.00937 (QuantReg: 13.48476) QuantErr: 13.48476 batch_time=0.48985 
Train Epoch: 29 [199/250 25472/32000 (80%)] Loss: 0.92614 (QuantReg: 13.19295) QuantErr: 13.19295 batch_time=0.49922 
Train Epoch: 29 [210/250 26880/32000 (84%)] Loss: 1.06061 (QuantReg: 13.38875) QuantErr: 13.38875 batch_time=0.49069 
Train Epoch: 29 [221/250 28288/32000 (88%)] Loss: 0.91668 (QuantReg: 13.47514) QuantErr: 13.47514 batch_time=0.52529 
Train Epoch: 29 [232/250 29696/32000 (93%)] Loss: 0.74439 (QuantReg: 13.80180) QuantErr: 13.80180 batch_time=0.52834 
Train Epoch: 29 [243/250 31104/32000 (97%)] Loss: 0.77331 (QuantReg: 13.57602) QuantErr: 13.57602 batch_time=0.49512 
Train Epoch: 29 codebook_update_time=2.09617
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_MSRVTT_1kA_roberta-base/checkpoint-epoch29.pth ...
Done in 3.795s
removing stale ckpt [epoch 28] [took 0.00s]
 epoch          : 29
 loss           : 0.9166005065441132
 quant_reg      : 13.454935050964355
 quant_err      : 13.454935050964355
 learning_rate  : 2.3782688525533216e-05
 n_samples      : 928000
 n_steps        : 7250
 MSRVTT_jsfusion_test/t2v_metrics/R1: 23.6
 MSRVTT_jsfusion_test/t2v_metrics/R5: 52.7
 MSRVTT_jsfusion_test/t2v_metrics/R10: 66.7
 MSRVTT_jsfusion_test/t2v_metrics/R50: 90.2
 MSRVTT_jsfusion_test/t2v_metrics/MedR: 5.0
 MSRVTT_jsfusion_test/t2v_metrics/MeanR: 25.289
 MSRVTT_jsfusion_test/t2v_metrics/geometric_mean_R1-R5-R10: 43.61301900582007
 MSRVTT_jsfusion_test/v2t_metrics/R1: 23.6
 MSRVTT_jsfusion_test/v2t_metrics/R5: 54.0
 MSRVTT_jsfusion_test/v2t_metrics/R10: 68.1
 MSRVTT_jsfusion_test/v2t_metrics/R50: 90.8
 MSRVTT_jsfusion_test/v2t_metrics/MedR: 5.0
 MSRVTT_jsfusion_test/v2t_metrics/MeanR: 23.107
 MSRVTT_jsfusion_test/v2t_metrics/geometric_mean_R1-R5-R10: 44.27422402462267
 mnt_best       : 43.7585333450047
 not_improved_count: 6
Train Epoch: 30 [1/250 128/32000 (0%)] Loss: 0.92729 (QuantReg: 13.23133) QuantErr: 13.23133 batch_time=23.80867 
Train Epoch: 30 [12/250 1536/32000 (5%)] Loss: 0.90838 (QuantReg: 13.24885) QuantErr: 13.24885 batch_time=0.48285 
Train Epoch: 30 [23/250 2944/32000 (9%)] Loss: 0.66556 (QuantReg: 13.48246) QuantErr: 13.48246 batch_time=0.48634 
Train Epoch: 30 [34/250 4352/32000 (14%)] Loss: 0.80719 (QuantReg: 13.48693) QuantErr: 13.48693 batch_time=0.48533 
Train Epoch: 30 [45/250 5760/32000 (18%)] Loss: 0.95544 (QuantReg: 13.25919) QuantErr: 13.25919 batch_time=0.48591 
Train Epoch: 30 [56/250 7168/32000 (22%)] Loss: 0.74399 (QuantReg: 13.43115) QuantErr: 13.43115 batch_time=0.49020 
Train Epoch: 30 [67/250 8576/32000 (27%)] Loss: 0.71378 (QuantReg: 13.18858) QuantErr: 13.18858 batch_time=2.46094 
Train Epoch: 30 [78/250 9984/32000 (31%)] Loss: 0.80245 (QuantReg: 13.55127) QuantErr: 13.55127 batch_time=0.48801 
Train Epoch: 30 [89/250 11392/32000 (36%)] Loss: 0.88920 (QuantReg: 13.56984) QuantErr: 13.56984 batch_time=0.49209 
Train Epoch: 30 [100/250 12800/32000 (40%)] Loss: 0.85448 (QuantReg: 13.65634) QuantErr: 13.65634 batch_time=0.48652 
Train Epoch: 30 [111/250 14208/32000 (44%)] Loss: 0.89319 (QuantReg: 13.63187) QuantErr: 13.63187 batch_time=1.25806 
Train Epoch: 30 [122/250 15616/32000 (49%)] Loss: 0.98208 (QuantReg: 13.62611) QuantErr: 13.62611 batch_time=0.52050 
Train Epoch: 30 [133/250 17024/32000 (53%)] Loss: 0.80166 (QuantReg: 13.39488) QuantErr: 13.39488 batch_time=0.48180 
Train Epoch: 30 [144/250 18432/32000 (58%)] Loss: 0.78137 (QuantReg: 13.65673) QuantErr: 13.65673 batch_time=0.53496 
Train Epoch: 30 [155/250 19840/32000 (62%)] Loss: 0.99924 (QuantReg: 13.21906) QuantErr: 13.21906 batch_time=0.52420 
Train Epoch: 30 [166/250 21248/32000 (66%)] Loss: 1.02634 (QuantReg: 13.48086) QuantErr: 13.48086 batch_time=0.51750 
Train Epoch: 30 [177/250 22656/32000 (71%)] Loss: 0.82848 (QuantReg: 13.56749) QuantErr: 13.56749 batch_time=0.48615 
Train Epoch: 30 [188/250 24064/32000 (75%)] Loss: 1.04011 (QuantReg: 13.43966) QuantErr: 13.43966 batch_time=0.49074 
Train Epoch: 30 [199/250 25472/32000 (80%)] Loss: 0.79808 (QuantReg: 13.77515) QuantErr: 13.77515 batch_time=0.53410 
Train Epoch: 30 [210/250 26880/32000 (84%)] Loss: 1.13375 (QuantReg: 13.54546) QuantErr: 13.54546 batch_time=0.48626 
Train Epoch: 30 [221/250 28288/32000 (88%)] Loss: 0.91523 (QuantReg: 13.35204) QuantErr: 13.35204 batch_time=0.48336 
Train Epoch: 30 [232/250 29696/32000 (93%)] Loss: 0.89889 (QuantReg: 13.17829) QuantErr: 13.17829 batch_time=0.48877 
Train Epoch: 30 [243/250 31104/32000 (97%)] Loss: 0.67301 (QuantReg: 13.71017) QuantErr: 13.71017 batch_time=0.48130 
Train Epoch: 30 codebook_update_time=1.67155
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_MSRVTT_1kA_roberta-base/checkpoint-epoch30.pth ...
Done in 4.119s
Updating 'best' checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_MSRVTT_1kA_roberta-base/checkpoint-epoch30.pth ...
Done in 8.008s
removing stale ckpt [epoch 29] [took 0.00s]
 epoch          : 30
 loss           : 0.9065579133033752
 quant_reg      : 13.464303276062012
 quant_err      : 13.464303276062012
 learning_rate  : 2.2593554099256555e-05
 n_samples      : 960000
 n_steps        : 7500
 MSRVTT_jsfusion_test/t2v_metrics/R1: 23.5
 MSRVTT_jsfusion_test/t2v_metrics/R5: 54.1
 MSRVTT_jsfusion_test/t2v_metrics/R10: 66.9
 MSRVTT_jsfusion_test/t2v_metrics/R50: 89.1
 MSRVTT_jsfusion_test/t2v_metrics/MedR: 5.0
 MSRVTT_jsfusion_test/t2v_metrics/MeanR: 26.401
 MSRVTT_jsfusion_test/t2v_metrics/geometric_mean_R1-R5-R10: 43.97748762273903
 MSRVTT_jsfusion_test/v2t_metrics/R1: 23.2
 MSRVTT_jsfusion_test/v2t_metrics/R5: 53.1
 MSRVTT_jsfusion_test/v2t_metrics/R10: 67.0
 MSRVTT_jsfusion_test/v2t_metrics/R50: 89.4
 MSRVTT_jsfusion_test/v2t_metrics/MedR: 5.0
 MSRVTT_jsfusion_test/v2t_metrics/MeanR: 23.1105
 MSRVTT_jsfusion_test/v2t_metrics/geometric_mean_R1-R5-R10: 43.539733810198435
 mnt_best       : 43.97748762273903
 not_improved_count: 0
Train Epoch: 31 [1/250 128/32000 (0%)] Loss: 0.97058 (QuantReg: 13.65611) QuantErr: 13.65611 batch_time=24.40781 
Train Epoch: 31 [12/250 1536/32000 (5%)] Loss: 0.77374 (QuantReg: 13.48545) QuantErr: 13.48545 batch_time=0.50552 
Train Epoch: 31 [23/250 2944/32000 (9%)] Loss: 0.78078 (QuantReg: 13.58938) QuantErr: 13.58938 batch_time=0.48835 
Train Epoch: 31 [34/250 4352/32000 (14%)] Loss: 0.98345 (QuantReg: 13.68046) QuantErr: 13.68046 batch_time=0.49126 
Train Epoch: 31 [45/250 5760/32000 (18%)] Loss: 0.86738 (QuantReg: 13.50197) QuantErr: 13.50197 batch_time=0.48679 
Train Epoch: 31 [56/250 7168/32000 (22%)] Loss: 0.73864 (QuantReg: 13.41591) QuantErr: 13.41591 batch_time=0.54839 
Train Epoch: 31 [67/250 8576/32000 (27%)] Loss: 0.88613 (QuantReg: 13.43973) QuantErr: 13.43973 batch_time=0.49755 
Train Epoch: 31 [78/250 9984/32000 (31%)] Loss: 0.79246 (QuantReg: 13.77775) QuantErr: 13.77775 batch_time=0.50899 
Train Epoch: 31 [89/250 11392/32000 (36%)] Loss: 1.01178 (QuantReg: 13.15929) QuantErr: 13.15929 batch_time=0.49351 
Train Epoch: 31 [100/250 12800/32000 (40%)] Loss: 0.87095 (QuantReg: 13.92109) QuantErr: 13.92109 batch_time=0.50155 
Train Epoch: 31 [111/250 14208/32000 (44%)] Loss: 0.55467 (QuantReg: 13.50543) QuantErr: 13.50543 batch_time=0.50718 
Train Epoch: 31 [122/250 15616/32000 (49%)] Loss: 0.97427 (QuantReg: 13.48664) QuantErr: 13.48664 batch_time=0.54869 
Train Epoch: 31 [133/250 17024/32000 (53%)] Loss: 0.81070 (QuantReg: 13.51523) QuantErr: 13.51523 batch_time=0.50710 
Train Epoch: 31 [144/250 18432/32000 (58%)] Loss: 0.68498 (QuantReg: 13.86923) QuantErr: 13.86923 batch_time=0.82714 
Train Epoch: 31 [155/250 19840/32000 (62%)] Loss: 0.93765 (QuantReg: 13.32941) QuantErr: 13.32941 batch_time=0.47741 
Train Epoch: 31 [166/250 21248/32000 (66%)] Loss: 0.58877 (QuantReg: 13.50713) QuantErr: 13.50713 batch_time=0.47297 
Train Epoch: 31 [177/250 22656/32000 (71%)] Loss: 0.91615 (QuantReg: 13.88861) QuantErr: 13.88861 batch_time=0.49075 
Train Epoch: 31 [188/250 24064/32000 (75%)] Loss: 0.99950 (QuantReg: 13.60506) QuantErr: 13.60506 batch_time=0.84918 
Train Epoch: 31 [199/250 25472/32000 (80%)] Loss: 0.67400 (QuantReg: 13.52166) QuantErr: 13.52166 batch_time=2.53241 
Train Epoch: 31 [210/250 26880/32000 (84%)] Loss: 1.01643 (QuantReg: 13.15256) QuantErr: 13.15256 batch_time=2.39787 
Train Epoch: 31 [221/250 28288/32000 (88%)] Loss: 0.71197 (QuantReg: 13.88385) QuantErr: 13.88385 batch_time=0.49374 
Train Epoch: 31 [232/250 29696/32000 (93%)] Loss: 0.74130 (QuantReg: 13.44869) QuantErr: 13.44869 batch_time=0.48485 
Train Epoch: 31 [243/250 31104/32000 (97%)] Loss: 0.93150 (QuantReg: 13.67078) QuantErr: 13.67078 batch_time=0.59279 
Train Epoch: 31 codebook_update_time=1.59501
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_MSRVTT_1kA_roberta-base/checkpoint-epoch31.pth ...
Done in 13.986s
removing stale ckpt [epoch 30] [took 0.00s]
 epoch          : 31
 loss           : 0.8778289895057678
 quant_reg      : 13.499969509124757
 quant_err      : 13.499969509124757
 learning_rate  : 2.1463876394293726e-05
 n_samples      : 992000
 n_steps        : 7750
 MSRVTT_jsfusion_test/t2v_metrics/R1: 22.8
 MSRVTT_jsfusion_test/t2v_metrics/R5: 53.5
 MSRVTT_jsfusion_test/t2v_metrics/R10: 67.0
 MSRVTT_jsfusion_test/t2v_metrics/R50: 89.3
 MSRVTT_jsfusion_test/t2v_metrics/MedR: 5.0
 MSRVTT_jsfusion_test/t2v_metrics/MeanR: 25.772
 MSRVTT_jsfusion_test/t2v_metrics/geometric_mean_R1-R5-R10: 43.396477306154914
 MSRVTT_jsfusion_test/v2t_metrics/R1: 22.8
 MSRVTT_jsfusion_test/v2t_metrics/R5: 54.3
 MSRVTT_jsfusion_test/v2t_metrics/R10: 67.5
 MSRVTT_jsfusion_test/v2t_metrics/R50: 89.5
 MSRVTT_jsfusion_test/v2t_metrics/MedR: 5.0
 MSRVTT_jsfusion_test/v2t_metrics/MeanR: 22.8325
 MSRVTT_jsfusion_test/v2t_metrics/geometric_mean_R1-R5-R10: 43.719932537960794
 mnt_best       : 43.97748762273903
 not_improved_count: 1
Train Epoch: 32 [1/250 128/32000 (0%)] Loss: 0.89511 (QuantReg: 13.68603) QuantErr: 13.68603 batch_time=23.76826 
Train Epoch: 32 [12/250 1536/32000 (5%)] Loss: 0.62282 (QuantReg: 13.64398) QuantErr: 13.64398 batch_time=0.50292 
Train Epoch: 32 [23/250 2944/32000 (9%)] Loss: 0.99331 (QuantReg: 13.34854) QuantErr: 13.34854 batch_time=0.48512 
Train Epoch: 32 [34/250 4352/32000 (14%)] Loss: 0.81708 (QuantReg: 13.67477) QuantErr: 13.67477 batch_time=0.48294 
Train Epoch: 32 [45/250 5760/32000 (18%)] Loss: 0.76369 (QuantReg: 13.27561) QuantErr: 13.27561 batch_time=0.51149 
Train Epoch: 32 [56/250 7168/32000 (22%)] Loss: 0.89946 (QuantReg: 13.59418) QuantErr: 13.59418 batch_time=0.48350 
Train Epoch: 32 [67/250 8576/32000 (27%)] Loss: 0.70917 (QuantReg: 13.69357) QuantErr: 13.69357 batch_time=0.70499 
Train Epoch: 32 [78/250 9984/32000 (31%)] Loss: 0.73271 (QuantReg: 13.62496) QuantErr: 13.62496 batch_time=0.48963 
Train Epoch: 32 [89/250 11392/32000 (36%)] Loss: 1.01846 (QuantReg: 13.33553) QuantErr: 13.33553 batch_time=0.51218 
Train Epoch: 32 [100/250 12800/32000 (40%)] Loss: 0.86518 (QuantReg: 13.44987) QuantErr: 13.44987 batch_time=0.48349 
Train Epoch: 32 [111/250 14208/32000 (44%)] Loss: 0.92633 (QuantReg: 13.40396) QuantErr: 13.40396 batch_time=0.50156 
Train Epoch: 32 [122/250 15616/32000 (49%)] Loss: 0.75523 (QuantReg: 13.37200) QuantErr: 13.37200 batch_time=0.50682 
Train Epoch: 32 [133/250 17024/32000 (53%)] Loss: 0.89754 (QuantReg: 13.44431) QuantErr: 13.44431 batch_time=0.59880 
Train Epoch: 32 [144/250 18432/32000 (58%)] Loss: 1.08322 (QuantReg: 13.66823) QuantErr: 13.66823 batch_time=0.49126 
Train Epoch: 32 [155/250 19840/32000 (62%)] Loss: 0.82032 (QuantReg: 13.54642) QuantErr: 13.54642 batch_time=0.81901 
Train Epoch: 32 [166/250 21248/32000 (66%)] Loss: 0.85920 (QuantReg: 13.74119) QuantErr: 13.74119 batch_time=0.48133 
Train Epoch: 32 [177/250 22656/32000 (71%)] Loss: 0.92879 (QuantReg: 13.24858) QuantErr: 13.24858 batch_time=0.48795 
Train Epoch: 32 [188/250 24064/32000 (75%)] Loss: 0.72603 (QuantReg: 13.47529) QuantErr: 13.47529 batch_time=0.48935 
Train Epoch: 32 [199/250 25472/32000 (80%)] Loss: 0.88596 (QuantReg: 13.46224) QuantErr: 13.46224 batch_time=0.49082 
Train Epoch: 32 [210/250 26880/32000 (84%)] Loss: 0.93954 (QuantReg: 13.71399) QuantErr: 13.71399 batch_time=1.13528 
Train Epoch: 32 [221/250 28288/32000 (88%)] Loss: 0.76985 (QuantReg: 13.66759) QuantErr: 13.66759 batch_time=0.49426 
Train Epoch: 32 [232/250 29696/32000 (93%)] Loss: 0.92306 (QuantReg: 13.36966) QuantErr: 13.36966 batch_time=1.28692 
Train Epoch: 32 [243/250 31104/32000 (97%)] Loss: 0.76764 (QuantReg: 13.51225) QuantErr: 13.51225 batch_time=0.71601 
Train Epoch: 32 codebook_update_time=1.60075
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_MSRVTT_1kA_roberta-base/checkpoint-epoch32.pth ...
Done in 3.818s
Updating 'best' checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_MSRVTT_1kA_roberta-base/checkpoint-epoch32.pth ...
Done in 23.627s
removing stale ckpt [epoch 31] [took 0.00s]
 epoch          : 32
 loss           : 0.8631286942958831
 quant_reg      : 13.510049816131591
 quant_err      : 13.510049816131591
 learning_rate  : 2.039068257457904e-05
 n_samples      : 1024000
 n_steps        : 8000
 MSRVTT_jsfusion_test/t2v_metrics/R1: 23.3
 MSRVTT_jsfusion_test/t2v_metrics/R5: 55.0
 MSRVTT_jsfusion_test/t2v_metrics/R10: 67.3
 MSRVTT_jsfusion_test/t2v_metrics/R50: 89.5
 MSRVTT_jsfusion_test/t2v_metrics/MedR: 4.0
 MSRVTT_jsfusion_test/t2v_metrics/MeanR: 25.883
 MSRVTT_jsfusion_test/t2v_metrics/geometric_mean_R1-R5-R10: 44.181917283933615
 MSRVTT_jsfusion_test/v2t_metrics/R1: 23.0
 MSRVTT_jsfusion_test/v2t_metrics/R5: 53.4
 MSRVTT_jsfusion_test/v2t_metrics/R10: 69.4
 MSRVTT_jsfusion_test/v2t_metrics/R50: 90.1
 MSRVTT_jsfusion_test/v2t_metrics/MedR: 5.0
 MSRVTT_jsfusion_test/v2t_metrics/MeanR: 23.1325
 MSRVTT_jsfusion_test/v2t_metrics/geometric_mean_R1-R5-R10: 44.00913722085311
 mnt_best       : 44.181917283933615
 not_improved_count: 0
Train Epoch: 33 [1/250 128/32000 (0%)] Loss: 0.72170 (QuantReg: 13.67982) QuantErr: 13.67982 batch_time=28.42191 
Train Epoch: 33 [12/250 1536/32000 (5%)] Loss: 0.94657 (QuantReg: 13.34549) QuantErr: 13.34549 batch_time=0.52084 
Train Epoch: 33 [23/250 2944/32000 (9%)] Loss: 0.74251 (QuantReg: 13.51268) QuantErr: 13.51268 batch_time=0.53503 
Train Epoch: 33 [34/250 4352/32000 (14%)] Loss: 0.91570 (QuantReg: 13.61069) QuantErr: 13.61069 batch_time=0.48802 
Train Epoch: 33 [45/250 5760/32000 (18%)] Loss: 0.83072 (QuantReg: 13.22895) QuantErr: 13.22895 batch_time=0.58505 
Train Epoch: 33 [56/250 7168/32000 (22%)] Loss: 0.89258 (QuantReg: 13.28287) QuantErr: 13.28287 batch_time=0.48914 
Train Epoch: 33 [67/250 8576/32000 (27%)] Loss: 1.07141 (QuantReg: 13.38283) QuantErr: 13.38283 batch_time=0.49504 
Train Epoch: 33 [78/250 9984/32000 (31%)] Loss: 1.14201 (QuantReg: 13.45962) QuantErr: 13.45962 batch_time=0.70830 
Train Epoch: 33 [89/250 11392/32000 (36%)] Loss: 0.88339 (QuantReg: 13.39873) QuantErr: 13.39873 batch_time=0.48450 
Train Epoch: 33 [100/250 12800/32000 (40%)] Loss: 0.59789 (QuantReg: 13.55524) QuantErr: 13.55524 batch_time=0.49121 
Train Epoch: 33 [111/250 14208/32000 (44%)] Loss: 0.94110 (QuantReg: 13.17887) QuantErr: 13.17887 batch_time=0.51767 
Train Epoch: 33 [122/250 15616/32000 (49%)] Loss: 1.35055 (QuantReg: 13.23271) QuantErr: 13.23271 batch_time=0.49705 
Train Epoch: 33 [133/250 17024/32000 (53%)] Loss: 1.14690 (QuantReg: 13.78189) QuantErr: 13.78189 batch_time=0.49813 
Train Epoch: 33 [144/250 18432/32000 (58%)] Loss: 0.91859 (QuantReg: 13.64933) QuantErr: 13.64933 batch_time=0.47822 
Train Epoch: 33 [155/250 19840/32000 (62%)] Loss: 0.98708 (QuantReg: 13.15808) QuantErr: 13.15808 batch_time=0.48630 
Train Epoch: 33 [166/250 21248/32000 (66%)] Loss: 1.07290 (QuantReg: 13.39004) QuantErr: 13.39004 batch_time=0.52170 
Train Epoch: 33 [177/250 22656/32000 (71%)] Loss: 0.71306 (QuantReg: 13.57154) QuantErr: 13.57154 batch_time=0.47846 
Train Epoch: 33 [188/250 24064/32000 (75%)] Loss: 0.85486 (QuantReg: 13.43712) QuantErr: 13.43712 batch_time=0.49235 
Train Epoch: 33 [199/250 25472/32000 (80%)] Loss: 1.09906 (QuantReg: 13.28254) QuantErr: 13.28254 batch_time=0.50641 
Train Epoch: 33 [210/250 26880/32000 (84%)] Loss: 0.86561 (QuantReg: 13.68076) QuantErr: 13.68076 batch_time=0.48784 
Train Epoch: 33 [221/250 28288/32000 (88%)] Loss: 0.96079 (QuantReg: 13.44398) QuantErr: 13.44398 batch_time=0.49187 
Train Epoch: 33 [232/250 29696/32000 (93%)] Loss: 0.95064 (QuantReg: 13.44690) QuantErr: 13.44690 batch_time=0.50394 
Train Epoch: 33 [243/250 31104/32000 (97%)] Loss: 0.68613 (QuantReg: 13.46790) QuantErr: 13.46790 batch_time=0.49444 
Train Epoch: 33 codebook_update_time=1.63214
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_MSRVTT_1kA_roberta-base/checkpoint-epoch33.pth ...
Done in 3.996s
Updating 'best' checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_MSRVTT_1kA_roberta-base/checkpoint-epoch33.pth ...
Done in 7.861s
removing stale ckpt [epoch 32] [took 0.00s]
 epoch          : 33
 loss           : 0.8641658632755279
 quant_reg      : 13.5185341796875
 quant_err      : 13.5185341796875
 learning_rate  : 1.9371148445850086e-05
 n_samples      : 1056000
 n_steps        : 8250
 MSRVTT_jsfusion_test/t2v_metrics/R1: 23.8
 MSRVTT_jsfusion_test/t2v_metrics/R5: 54.3
 MSRVTT_jsfusion_test/t2v_metrics/R10: 67.7
 MSRVTT_jsfusion_test/t2v_metrics/R50: 89.6
 MSRVTT_jsfusion_test/t2v_metrics/MedR: 5.0
 MSRVTT_jsfusion_test/t2v_metrics/MeanR: 25.447
 MSRVTT_jsfusion_test/t2v_metrics/geometric_mean_R1-R5-R10: 44.3937486126006
 MSRVTT_jsfusion_test/v2t_metrics/R1: 23.7
 MSRVTT_jsfusion_test/v2t_metrics/R5: 53.1
 MSRVTT_jsfusion_test/v2t_metrics/R10: 67.6
 MSRVTT_jsfusion_test/v2t_metrics/R50: 90.4
 MSRVTT_jsfusion_test/v2t_metrics/MedR: 5.0
 MSRVTT_jsfusion_test/v2t_metrics/MeanR: 22.8035
 MSRVTT_jsfusion_test/v2t_metrics/geometric_mean_R1-R5-R10: 43.98080636688326
 mnt_best       : 44.3937486126006
 not_improved_count: 0
Train Epoch: 34 [1/250 128/32000 (0%)] Loss: 0.85653 (QuantReg: 13.22184) QuantErr: 13.22184 batch_time=30.08378 
Train Epoch: 34 [12/250 1536/32000 (5%)] Loss: 0.77029 (QuantReg: 13.52802) QuantErr: 13.52802 batch_time=0.48247 
Train Epoch: 34 [23/250 2944/32000 (9%)] Loss: 0.84923 (QuantReg: 13.21123) QuantErr: 13.21123 batch_time=0.47896 
Train Epoch: 34 [34/250 4352/32000 (14%)] Loss: 0.77920 (QuantReg: 13.48270) QuantErr: 13.48270 batch_time=0.50418 
Train Epoch: 34 [45/250 5760/32000 (18%)] Loss: 0.62838 (QuantReg: 13.78126) QuantErr: 13.78126 batch_time=0.48970 
Train Epoch: 34 [56/250 7168/32000 (22%)] Loss: 0.99027 (QuantReg: 13.51006) QuantErr: 13.51006 batch_time=0.81150 
Train Epoch: 34 [67/250 8576/32000 (27%)] Loss: 0.64078 (QuantReg: 13.59617) QuantErr: 13.59617 batch_time=0.47510 
Train Epoch: 34 [78/250 9984/32000 (31%)] Loss: 1.01843 (QuantReg: 13.28539) QuantErr: 13.28539 batch_time=0.48199 
Train Epoch: 34 [89/250 11392/32000 (36%)] Loss: 0.88193 (QuantReg: 13.63388) QuantErr: 13.63388 batch_time=0.48634 
Train Epoch: 34 [100/250 12800/32000 (40%)] Loss: 0.65044 (QuantReg: 13.48960) QuantErr: 13.48960 batch_time=0.50978 
Train Epoch: 34 [111/250 14208/32000 (44%)] Loss: 0.99866 (QuantReg: 13.66961) QuantErr: 13.66961 batch_time=0.48438 
Train Epoch: 34 [122/250 15616/32000 (49%)] Loss: 0.74758 (QuantReg: 13.69140) QuantErr: 13.69140 batch_time=0.48393 
Train Epoch: 34 [133/250 17024/32000 (53%)] Loss: 0.84635 (QuantReg: 13.47827) QuantErr: 13.47827 batch_time=0.70392 
Train Epoch: 34 [144/250 18432/32000 (58%)] Loss: 0.71448 (QuantReg: 13.43673) QuantErr: 13.43673 batch_time=0.48472 
Train Epoch: 34 [155/250 19840/32000 (62%)] Loss: 0.63432 (QuantReg: 13.66648) QuantErr: 13.66648 batch_time=0.58511 
Train Epoch: 34 [166/250 21248/32000 (66%)] Loss: 0.84522 (QuantReg: 13.46769) QuantErr: 13.46769 batch_time=0.47127 
Train Epoch: 34 [177/250 22656/32000 (71%)] Loss: 0.94898 (QuantReg: 13.57171) QuantErr: 13.57171 batch_time=0.48723 
Train Epoch: 34 [188/250 24064/32000 (75%)] Loss: 0.73347 (QuantReg: 13.74567) QuantErr: 13.74567 batch_time=0.49324 
Train Epoch: 34 [199/250 25472/32000 (80%)] Loss: 0.74213 (QuantReg: 13.75396) QuantErr: 13.75396 batch_time=0.49107 
Train Epoch: 34 [210/250 26880/32000 (84%)] Loss: 0.92884 (QuantReg: 13.62071) QuantErr: 13.62071 batch_time=0.49187 
Train Epoch: 34 [221/250 28288/32000 (88%)] Loss: 0.72022 (QuantReg: 13.64822) QuantErr: 13.64822 batch_time=0.94952 
Train Epoch: 34 [232/250 29696/32000 (93%)] Loss: 0.73662 (QuantReg: 13.73945) QuantErr: 13.73945 batch_time=0.49023 
Train Epoch: 34 [243/250 31104/32000 (97%)] Loss: 0.73030 (QuantReg: 13.92954) QuantErr: 13.92954 batch_time=0.48499 
Train Epoch: 34 codebook_update_time=1.62052
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_MSRVTT_1kA_roberta-base/checkpoint-epoch34.pth ...
Done in 19.939s
removing stale ckpt [epoch 33] [took 0.00s]
 epoch          : 34
 loss           : 0.8376554822921753
 quant_reg      : 13.552899806976319
 quant_err      : 13.552899806976319
 learning_rate  : 1.840259102355758e-05
 n_samples      : 1088000
 n_steps        : 8500
 MSRVTT_jsfusion_test/t2v_metrics/R1: 23.1
 MSRVTT_jsfusion_test/t2v_metrics/R5: 53.5
 MSRVTT_jsfusion_test/t2v_metrics/R10: 66.9
 MSRVTT_jsfusion_test/t2v_metrics/R50: 89.9
 MSRVTT_jsfusion_test/t2v_metrics/MedR: 5.0
 MSRVTT_jsfusion_test/t2v_metrics/MeanR: 25.308
 MSRVTT_jsfusion_test/t2v_metrics/geometric_mean_R1-R5-R10: 43.56428861134619
 MSRVTT_jsfusion_test/v2t_metrics/R1: 23.7
 MSRVTT_jsfusion_test/v2t_metrics/R5: 53.8
 MSRVTT_jsfusion_test/v2t_metrics/R10: 67.2
 MSRVTT_jsfusion_test/v2t_metrics/R50: 89.9
 MSRVTT_jsfusion_test/v2t_metrics/MedR: 5.0
 MSRVTT_jsfusion_test/v2t_metrics/MeanR: 23.276
 MSRVTT_jsfusion_test/v2t_metrics/geometric_mean_R1-R5-R10: 44.08592575388191
 mnt_best       : 44.3937486126006
 not_improved_count: 1
Train Epoch: 35 [1/250 128/32000 (0%)] Loss: 0.78581 (QuantReg: 13.37173) QuantErr: 13.37173 batch_time=23.90467 
Train Epoch: 35 [12/250 1536/32000 (5%)] Loss: 0.70760 (QuantReg: 13.75984) QuantErr: 13.75984 batch_time=0.50798 
Train Epoch: 35 [23/250 2944/32000 (9%)] Loss: 0.82512 (QuantReg: 13.85418) QuantErr: 13.85418 batch_time=0.48656 
Train Epoch: 35 [34/250 4352/32000 (14%)] Loss: 0.89213 (QuantReg: 13.28878) QuantErr: 13.28878 batch_time=0.48373 
Train Epoch: 35 [45/250 5760/32000 (18%)] Loss: 0.91407 (QuantReg: 13.41366) QuantErr: 13.41366 batch_time=0.47932 
Train Epoch: 35 [56/250 7168/32000 (22%)] Loss: 0.94391 (QuantReg: 13.69179) QuantErr: 13.69179 batch_time=0.47752 
Train Epoch: 35 [67/250 8576/32000 (27%)] Loss: 0.77431 (QuantReg: 13.57240) QuantErr: 13.57240 batch_time=0.61210 
Train Epoch: 35 [78/250 9984/32000 (31%)] Loss: 1.03414 (QuantReg: 13.67210) QuantErr: 13.67210 batch_time=0.48699 
Train Epoch: 35 [89/250 11392/32000 (36%)] Loss: 0.97240 (QuantReg: 13.43920) QuantErr: 13.43920 batch_time=0.47535 
Train Epoch: 35 [100/250 12800/32000 (40%)] Loss: 0.68174 (QuantReg: 13.30767) QuantErr: 13.30767 batch_time=0.48140 
Train Epoch: 35 [111/250 14208/32000 (44%)] Loss: 0.63540 (QuantReg: 13.64171) QuantErr: 13.64171 batch_time=0.49212 
Train Epoch: 35 [122/250 15616/32000 (49%)] Loss: 0.75176 (QuantReg: 13.46947) QuantErr: 13.46947 batch_time=0.48693 
Train Epoch: 35 [133/250 17024/32000 (53%)] Loss: 0.85403 (QuantReg: 13.50592) QuantErr: 13.50592 batch_time=0.47012 
Train Epoch: 35 [144/250 18432/32000 (58%)] Loss: 1.14024 (QuantReg: 13.62619) QuantErr: 13.62619 batch_time=1.48437 
Train Epoch: 35 [155/250 19840/32000 (62%)] Loss: 0.65844 (QuantReg: 13.52175) QuantErr: 13.52175 batch_time=0.47756 
Train Epoch: 35 [166/250 21248/32000 (66%)] Loss: 0.72743 (QuantReg: 13.52143) QuantErr: 13.52143 batch_time=0.48349 
Train Epoch: 35 [177/250 22656/32000 (71%)] Loss: 0.71935 (QuantReg: 13.61254) QuantErr: 13.61254 batch_time=0.49865 
Train Epoch: 35 [188/250 24064/32000 (75%)] Loss: 0.97122 (QuantReg: 13.40021) QuantErr: 13.40021 batch_time=0.59891 
Train Epoch: 35 [199/250 25472/32000 (80%)] Loss: 0.99700 (QuantReg: 13.88470) QuantErr: 13.88470 batch_time=1.15629 
Train Epoch: 35 [210/250 26880/32000 (84%)] Loss: 0.68187 (QuantReg: 13.74735) QuantErr: 13.74735 batch_time=0.47896 
Train Epoch: 35 [221/250 28288/32000 (88%)] Loss: 0.79790 (QuantReg: 13.69251) QuantErr: 13.69251 batch_time=0.47294 
Train Epoch: 35 [232/250 29696/32000 (93%)] Loss: 0.63059 (QuantReg: 13.72590) QuantErr: 13.72590 batch_time=0.49223 
Train Epoch: 35 [243/250 31104/32000 (97%)] Loss: 0.78297 (QuantReg: 13.69114) QuantErr: 13.69114 batch_time=0.48703 
Train Epoch: 35 codebook_update_time=1.58384
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_MSRVTT_1kA_roberta-base/checkpoint-epoch35.pth ...
Done in 4.140s
removing stale ckpt [epoch 34] [took 0.00s]
 epoch          : 35
 loss           : 0.8332806828022004
 quant_reg      : 13.58620040512085
 quant_err      : 13.58620040512085
 learning_rate  : 1.74824614723797e-05
 n_samples      : 1120000
 n_steps        : 8750
 MSRVTT_jsfusion_test/t2v_metrics/R1: 23.4
 MSRVTT_jsfusion_test/t2v_metrics/R5: 53.8
 MSRVTT_jsfusion_test/t2v_metrics/R10: 66.3
 MSRVTT_jsfusion_test/t2v_metrics/R50: 89.4
 MSRVTT_jsfusion_test/t2v_metrics/MedR: 5.0
 MSRVTT_jsfusion_test/t2v_metrics/MeanR: 25.825
 MSRVTT_jsfusion_test/t2v_metrics/geometric_mean_R1-R5-R10: 43.70225906315285
 MSRVTT_jsfusion_test/v2t_metrics/R1: 23.1
 MSRVTT_jsfusion_test/v2t_metrics/R5: 53.8
 MSRVTT_jsfusion_test/v2t_metrics/R10: 67.7
 MSRVTT_jsfusion_test/v2t_metrics/R50: 89.5
 MSRVTT_jsfusion_test/v2t_metrics/MedR: 5.0
 MSRVTT_jsfusion_test/v2t_metrics/MeanR: 22.969
 MSRVTT_jsfusion_test/v2t_metrics/geometric_mean_R1-R5-R10: 43.81884991700495
 mnt_best       : 44.3937486126006
 not_improved_count: 2
Train Epoch: 36 [1/250 128/32000 (0%)] Loss: 0.73094 (QuantReg: 13.61367) QuantErr: 13.61367 batch_time=28.14930 
Train Epoch: 36 [12/250 1536/32000 (5%)] Loss: 0.77932 (QuantReg: 13.70795) QuantErr: 13.70795 batch_time=0.47637 
Train Epoch: 36 [23/250 2944/32000 (9%)] Loss: 0.80637 (QuantReg: 13.56748) QuantErr: 13.56748 batch_time=0.47012 
Train Epoch: 36 [34/250 4352/32000 (14%)] Loss: 0.78885 (QuantReg: 13.55156) QuantErr: 13.55156 batch_time=0.49963 
Train Epoch: 36 [45/250 5760/32000 (18%)] Loss: 0.87254 (QuantReg: 13.86853) QuantErr: 13.86853 batch_time=0.49330 
Train Epoch: 36 [56/250 7168/32000 (22%)] Loss: 0.98175 (QuantReg: 13.77703) QuantErr: 13.77703 batch_time=0.48542 
Train Epoch: 36 [67/250 8576/32000 (27%)] Loss: 0.90186 (QuantReg: 13.55017) QuantErr: 13.55017 batch_time=0.52736 
Train Epoch: 36 [78/250 9984/32000 (31%)] Loss: 0.64232 (QuantReg: 13.57861) QuantErr: 13.57861 batch_time=0.49685 
Train Epoch: 36 [89/250 11392/32000 (36%)] Loss: 0.76610 (QuantReg: 13.80132) QuantErr: 13.80132 batch_time=0.48556 
Train Epoch: 36 [100/250 12800/32000 (40%)] Loss: 0.64474 (QuantReg: 13.64827) QuantErr: 13.64827 batch_time=0.48703 
Train Epoch: 36 [111/250 14208/32000 (44%)] Loss: 0.78243 (QuantReg: 13.38548) QuantErr: 13.38548 batch_time=0.60717 
Train Epoch: 36 [122/250 15616/32000 (49%)] Loss: 0.60749 (QuantReg: 13.68087) QuantErr: 13.68087 batch_time=0.48841 
Train Epoch: 36 [133/250 17024/32000 (53%)] Loss: 0.97621 (QuantReg: 13.64754) QuantErr: 13.64754 batch_time=0.49250 
Train Epoch: 36 [144/250 18432/32000 (58%)] Loss: 0.88812 (QuantReg: 13.41109) QuantErr: 13.41109 batch_time=2.02642 
Train Epoch: 36 [155/250 19840/32000 (62%)] Loss: 0.87888 (QuantReg: 13.64863) QuantErr: 13.64863 batch_time=0.48623 
Train Epoch: 36 [166/250 21248/32000 (66%)] Loss: 1.14289 (QuantReg: 13.51024) QuantErr: 13.51024 batch_time=0.59732 
Train Epoch: 36 [177/250 22656/32000 (71%)] Loss: 0.77535 (QuantReg: 13.41715) QuantErr: 13.41715 batch_time=0.48726 
Train Epoch: 36 [188/250 24064/32000 (75%)] Loss: 0.72638 (QuantReg: 13.51136) QuantErr: 13.51136 batch_time=0.49572 
Train Epoch: 36 [199/250 25472/32000 (80%)] Loss: 0.75467 (QuantReg: 13.92709) QuantErr: 13.92709 batch_time=0.48255 
Train Epoch: 36 [210/250 26880/32000 (84%)] Loss: 1.13270 (QuantReg: 13.59239) QuantErr: 13.59239 batch_time=0.48448 
Train Epoch: 36 [221/250 28288/32000 (88%)] Loss: 0.74586 (QuantReg: 13.71007) QuantErr: 13.71007 batch_time=0.48606 
Train Epoch: 36 [232/250 29696/32000 (93%)] Loss: 1.03526 (QuantReg: 13.49264) QuantErr: 13.49264 batch_time=0.48878 
Train Epoch: 36 [243/250 31104/32000 (97%)] Loss: 0.65099 (QuantReg: 13.75096) QuantErr: 13.75096 batch_time=0.49498 
Train Epoch: 36 codebook_update_time=1.61066
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_MSRVTT_1kA_roberta-base/checkpoint-epoch36.pth ...
Done in 3.961s
removing stale ckpt [epoch 35] [took 0.00s]
 epoch          : 36
 loss           : 0.8255536062717438
 quant_reg      : 13.617491661071778
 quant_err      : 13.617491661071778
 learning_rate  : 1.6608338398760715e-05
 n_samples      : 1152000
 n_steps        : 9000
 MSRVTT_jsfusion_test/t2v_metrics/R1: 23.3
 MSRVTT_jsfusion_test/t2v_metrics/R5: 53.8
 MSRVTT_jsfusion_test/t2v_metrics/R10: 68.3
 MSRVTT_jsfusion_test/t2v_metrics/R50: 89.2
 MSRVTT_jsfusion_test/t2v_metrics/MedR: 5.0
 MSRVTT_jsfusion_test/t2v_metrics/MeanR: 25.994
 MSRVTT_jsfusion_test/t2v_metrics/geometric_mean_R1-R5-R10: 44.074388969949055
 MSRVTT_jsfusion_test/v2t_metrics/R1: 23.3
 MSRVTT_jsfusion_test/v2t_metrics/R5: 54.0
 MSRVTT_jsfusion_test/v2t_metrics/R10: 67.7
 MSRVTT_jsfusion_test/v2t_metrics/R50: 89.9
 MSRVTT_jsfusion_test/v2t_metrics/MedR: 4.0
 MSRVTT_jsfusion_test/v2t_metrics/MeanR: 23.239
 MSRVTT_jsfusion_test/v2t_metrics/geometric_mean_R1-R5-R10: 43.99933538941028
 mnt_best       : 44.3937486126006
 not_improved_count: 3
Train Epoch: 37 [1/250 128/32000 (0%)] Loss: 0.85811 (QuantReg: 13.31548) QuantErr: 13.31548 batch_time=25.19665 
Train Epoch: 37 [12/250 1536/32000 (5%)] Loss: 0.90843 (QuantReg: 13.69510) QuantErr: 13.69510 batch_time=0.48673 
Train Epoch: 37 [23/250 2944/32000 (9%)] Loss: 0.79870 (QuantReg: 13.61899) QuantErr: 13.61899 batch_time=0.69729 
Train Epoch: 37 [34/250 4352/32000 (14%)] Loss: 0.80184 (QuantReg: 13.43832) QuantErr: 13.43832 batch_time=0.53939 
Train Epoch: 37 [45/250 5760/32000 (18%)] Loss: 0.92177 (QuantReg: 13.36670) QuantErr: 13.36670 batch_time=0.48014 
Train Epoch: 37 [56/250 7168/32000 (22%)] Loss: 0.67388 (QuantReg: 13.75298) QuantErr: 13.75298 batch_time=0.48525 
Train Epoch: 37 [67/250 8576/32000 (27%)] Loss: 0.61526 (QuantReg: 13.95199) QuantErr: 13.95199 batch_time=0.48742 
Train Epoch: 37 [78/250 9984/32000 (31%)] Loss: 0.75549 (QuantReg: 13.67071) QuantErr: 13.67071 batch_time=0.52335 
Train Epoch: 37 [89/250 11392/32000 (36%)] Loss: 0.63667 (QuantReg: 13.85137) QuantErr: 13.85137 batch_time=0.48860 
Train Epoch: 37 [100/250 12800/32000 (40%)] Loss: 0.71125 (QuantReg: 13.73738) QuantErr: 13.73738 batch_time=0.48669 
Train Epoch: 37 [111/250 14208/32000 (44%)] Loss: 0.94345 (QuantReg: 13.73377) QuantErr: 13.73377 batch_time=0.48685 
Train Epoch: 37 [122/250 15616/32000 (49%)] Loss: 0.84141 (QuantReg: 13.65329) QuantErr: 13.65329 batch_time=0.50589 
Train Epoch: 37 [133/250 17024/32000 (53%)] Loss: 0.69311 (QuantReg: 13.89069) QuantErr: 13.89069 batch_time=0.48183 
Train Epoch: 37 [144/250 18432/32000 (58%)] Loss: 0.99284 (QuantReg: 13.67248) QuantErr: 13.67248 batch_time=0.48158 
Train Epoch: 37 [155/250 19840/32000 (62%)] Loss: 0.79122 (QuantReg: 13.82046) QuantErr: 13.82046 batch_time=0.50933 
Train Epoch: 37 [166/250 21248/32000 (66%)] Loss: 0.72184 (QuantReg: 13.93537) QuantErr: 13.93537 batch_time=0.48853 
Train Epoch: 37 [177/250 22656/32000 (71%)] Loss: 0.64087 (QuantReg: 13.89243) QuantErr: 13.89243 batch_time=0.49022 
Train Epoch: 37 [188/250 24064/32000 (75%)] Loss: 0.56715 (QuantReg: 13.56001) QuantErr: 13.56001 batch_time=0.50623 
Train Epoch: 37 [199/250 25472/32000 (80%)] Loss: 0.72516 (QuantReg: 13.93516) QuantErr: 13.93516 batch_time=0.52973 
Train Epoch: 37 [210/250 26880/32000 (84%)] Loss: 1.01455 (QuantReg: 13.50014) QuantErr: 13.50014 batch_time=0.49703 
Train Epoch: 37 [221/250 28288/32000 (88%)] Loss: 0.92826 (QuantReg: 13.54521) QuantErr: 13.54521 batch_time=0.49370 
Train Epoch: 37 [232/250 29696/32000 (93%)] Loss: 0.72464 (QuantReg: 13.47749) QuantErr: 13.47749 batch_time=0.82873 
Train Epoch: 37 [243/250 31104/32000 (97%)] Loss: 0.80073 (QuantReg: 13.63434) QuantErr: 13.63434 batch_time=0.48415 
Train Epoch: 37 codebook_update_time=1.59043
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_MSRVTT_1kA_roberta-base/checkpoint-epoch37.pth ...
Done in 4.093s
removing stale ckpt [epoch 36] [took 0.00s]
 epoch          : 37
 loss           : 0.8183878500461579
 quant_reg      : 13.638668487548829
 quant_err      : 13.638668487548829
 learning_rate  : 1.5777921478822678e-05
 n_samples      : 1184000
 n_steps        : 9250
 MSRVTT_jsfusion_test/t2v_metrics/R1: 24.2
 MSRVTT_jsfusion_test/t2v_metrics/R5: 52.8
 MSRVTT_jsfusion_test/t2v_metrics/R10: 67.0
 MSRVTT_jsfusion_test/t2v_metrics/R50: 88.8
 MSRVTT_jsfusion_test/t2v_metrics/MedR: 5.0
 MSRVTT_jsfusion_test/t2v_metrics/MeanR: 25.701
 MSRVTT_jsfusion_test/t2v_metrics/geometric_mean_R1-R5-R10: 44.073211449489705
 MSRVTT_jsfusion_test/v2t_metrics/R1: 23.2
 MSRVTT_jsfusion_test/v2t_metrics/R5: 55.2
 MSRVTT_jsfusion_test/v2t_metrics/R10: 68.9
 MSRVTT_jsfusion_test/v2t_metrics/R50: 90.9
 MSRVTT_jsfusion_test/v2t_metrics/MedR: 4.0
 MSRVTT_jsfusion_test/v2t_metrics/MeanR: 22.5375
 MSRVTT_jsfusion_test/v2t_metrics/geometric_mean_R1-R5-R10: 44.51934453319823
 mnt_best       : 44.3937486126006
 not_improved_count: 4
Train Epoch: 38 [1/250 128/32000 (0%)] Loss: 0.93875 (QuantReg: 13.34107) QuantErr: 13.34107 batch_time=30.26368 
Train Epoch: 38 [12/250 1536/32000 (5%)] Loss: 0.74928 (QuantReg: 13.65988) QuantErr: 13.65988 batch_time=0.47677 
Train Epoch: 38 [23/250 2944/32000 (9%)] Loss: 0.77763 (QuantReg: 13.78892) QuantErr: 13.78892 batch_time=0.48402 
Train Epoch: 38 [34/250 4352/32000 (14%)] Loss: 0.79237 (QuantReg: 13.47069) QuantErr: 13.47069 batch_time=0.51315 
Train Epoch: 38 [45/250 5760/32000 (18%)] Loss: 0.68314 (QuantReg: 13.52315) QuantErr: 13.52315 batch_time=0.48875 
Train Epoch: 38 [56/250 7168/32000 (22%)] Loss: 0.64596 (QuantReg: 13.63010) QuantErr: 13.63010 batch_time=0.48856 
Train Epoch: 38 [67/250 8576/32000 (27%)] Loss: 0.86469 (QuantReg: 13.81389) QuantErr: 13.81389 batch_time=0.48700 
Train Epoch: 38 [78/250 9984/32000 (31%)] Loss: 0.88099 (QuantReg: 13.53793) QuantErr: 13.53793 batch_time=0.54369 
Train Epoch: 38 [89/250 11392/32000 (36%)] Loss: 0.84759 (QuantReg: 13.76674) QuantErr: 13.76674 batch_time=0.48673 
Train Epoch: 38 [100/250 12800/32000 (40%)] Loss: 0.70927 (QuantReg: 13.66371) QuantErr: 13.66371 batch_time=1.14420 
Train Epoch: 38 [111/250 14208/32000 (44%)] Loss: 1.00414 (QuantReg: 13.81147) QuantErr: 13.81147 batch_time=0.60080 
Train Epoch: 38 [122/250 15616/32000 (49%)] Loss: 0.79951 (QuantReg: 13.93328) QuantErr: 13.93328 batch_time=0.47191 
Train Epoch: 38 [133/250 17024/32000 (53%)] Loss: 0.47913 (QuantReg: 13.87350) QuantErr: 13.87350 batch_time=0.49364 
Train Epoch: 38 [144/250 18432/32000 (58%)] Loss: 0.72652 (QuantReg: 13.57880) QuantErr: 13.57880 batch_time=0.50331 
Train Epoch: 38 [155/250 19840/32000 (62%)] Loss: 0.93783 (QuantReg: 13.82001) QuantErr: 13.82001 batch_time=0.49322 
Train Epoch: 38 [166/250 21248/32000 (66%)] Loss: 1.02454 (QuantReg: 13.62759) QuantErr: 13.62759 batch_time=0.50139 
Train Epoch: 38 [177/250 22656/32000 (71%)] Loss: 0.96429 (QuantReg: 13.46245) QuantErr: 13.46245 batch_time=0.49688 
Train Epoch: 38 [188/250 24064/32000 (75%)] Loss: 0.59380 (QuantReg: 13.57350) QuantErr: 13.57350 batch_time=0.49781 
Train Epoch: 38 [199/250 25472/32000 (80%)] Loss: 0.78981 (QuantReg: 13.90049) QuantErr: 13.90049 batch_time=0.48124 
Train Epoch: 38 [210/250 26880/32000 (84%)] Loss: 0.65521 (QuantReg: 13.64208) QuantErr: 13.64208 batch_time=0.47956 
Train Epoch: 38 [221/250 28288/32000 (88%)] Loss: 0.65071 (QuantReg: 13.63535) QuantErr: 13.63535 batch_time=0.49631 
Train Epoch: 38 [232/250 29696/32000 (93%)] Loss: 0.78965 (QuantReg: 13.84141) QuantErr: 13.84141 batch_time=0.49081 
Train Epoch: 38 [243/250 31104/32000 (97%)] Loss: 0.94699 (QuantReg: 13.48578) QuantErr: 13.48578 batch_time=0.49305 
Train Epoch: 38 codebook_update_time=1.66961
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_MSRVTT_1kA_roberta-base/checkpoint-epoch38.pth ...
Done in 4.022s
removing stale ckpt [epoch 37] [took 0.00s]
 epoch          : 38
 loss           : 0.8035135608911514
 quant_reg      : 13.635846019744873
 quant_err      : 13.635846019744873
 learning_rate  : 1.4989025404881544e-05
 n_samples      : 1216000
 n_steps        : 9500
 MSRVTT_jsfusion_test/t2v_metrics/R1: 23.5
 MSRVTT_jsfusion_test/t2v_metrics/R5: 53.5
 MSRVTT_jsfusion_test/t2v_metrics/R10: 68.5
 MSRVTT_jsfusion_test/t2v_metrics/R50: 90.1
 MSRVTT_jsfusion_test/t2v_metrics/MedR: 5.0
 MSRVTT_jsfusion_test/t2v_metrics/MeanR: 25.362
 MSRVTT_jsfusion_test/t2v_metrics/geometric_mean_R1-R5-R10: 44.16084809231387
 MSRVTT_jsfusion_test/v2t_metrics/R1: 23.7
 MSRVTT_jsfusion_test/v2t_metrics/R5: 54.6
 MSRVTT_jsfusion_test/v2t_metrics/R10: 68.6
 MSRVTT_jsfusion_test/v2t_metrics/R50: 90.4
 MSRVTT_jsfusion_test/v2t_metrics/MedR: 5.0
 MSRVTT_jsfusion_test/v2t_metrics/MeanR: 22.143
 MSRVTT_jsfusion_test/v2t_metrics/geometric_mean_R1-R5-R10: 44.608919234774596
 mnt_best       : 44.3937486126006
 not_improved_count: 5
Train Epoch: 39 [1/250 128/32000 (0%)] Loss: 0.94453 (QuantReg: 13.73013) QuantErr: 13.73013 batch_time=34.69589 
Train Epoch: 39 [12/250 1536/32000 (5%)] Loss: 0.76744 (QuantReg: 13.69786) QuantErr: 13.69786 batch_time=0.47733 
Train Epoch: 39 [23/250 2944/32000 (9%)] Loss: 0.73431 (QuantReg: 13.96419) QuantErr: 13.96419 batch_time=0.49179 
Train Epoch: 39 [34/250 4352/32000 (14%)] Loss: 1.27888 (QuantReg: 13.44384) QuantErr: 13.44384 batch_time=0.49700 
Train Epoch: 39 [45/250 5760/32000 (18%)] Loss: 0.74284 (QuantReg: 13.69282) QuantErr: 13.69282 batch_time=0.48590 
Train Epoch: 39 [56/250 7168/32000 (22%)] Loss: 0.58590 (QuantReg: 13.39798) QuantErr: 13.39798 batch_time=0.48672 
Train Epoch: 39 [67/250 8576/32000 (27%)] Loss: 0.75155 (QuantReg: 13.67756) QuantErr: 13.67756 batch_time=0.63698 
Train Epoch: 39 [78/250 9984/32000 (31%)] Loss: 0.79602 (QuantReg: 13.73127) QuantErr: 13.73127 batch_time=0.48024 
Train Epoch: 39 [89/250 11392/32000 (36%)] Loss: 0.83363 (QuantReg: 13.60443) QuantErr: 13.60443 batch_time=0.48102 
Train Epoch: 39 [100/250 12800/32000 (40%)] Loss: 0.85480 (QuantReg: 13.62463) QuantErr: 13.62463 batch_time=0.48591 
Train Epoch: 39 [111/250 14208/32000 (44%)] Loss: 1.26982 (QuantReg: 13.39353) QuantErr: 13.39353 batch_time=0.48923 
Train Epoch: 39 [122/250 15616/32000 (49%)] Loss: 0.54435 (QuantReg: 13.78309) QuantErr: 13.78309 batch_time=0.50406 
Train Epoch: 39 [133/250 17024/32000 (53%)] Loss: 0.48527 (QuantReg: 13.62781) QuantErr: 13.62781 batch_time=0.50364 
Train Epoch: 39 [144/250 18432/32000 (58%)] Loss: 0.84781 (QuantReg: 13.84199) QuantErr: 13.84199 batch_time=3.07314 
Train Epoch: 39 [155/250 19840/32000 (62%)] Loss: 0.65107 (QuantReg: 13.89783) QuantErr: 13.89783 batch_time=0.51457 
Train Epoch: 39 [166/250 21248/32000 (66%)] Loss: 0.54926 (QuantReg: 13.68319) QuantErr: 13.68319 batch_time=0.49563 
Train Epoch: 39 [177/250 22656/32000 (71%)] Loss: 0.77953 (QuantReg: 13.73333) QuantErr: 13.73333 batch_time=0.48477 
Train Epoch: 39 [188/250 24064/32000 (75%)] Loss: 0.63012 (QuantReg: 13.80961) QuantErr: 13.80961 batch_time=0.48631 
Train Epoch: 39 [199/250 25472/32000 (80%)] Loss: 0.76967 (QuantReg: 13.68370) QuantErr: 13.68370 batch_time=0.49840 
Train Epoch: 39 [210/250 26880/32000 (84%)] Loss: 0.88138 (QuantReg: 13.58927) QuantErr: 13.58927 batch_time=0.48567 
Train Epoch: 39 [221/250 28288/32000 (88%)] Loss: 0.76668 (QuantReg: 13.76816) QuantErr: 13.76816 batch_time=0.49013 
Train Epoch: 39 [232/250 29696/32000 (93%)] Loss: 0.96993 (QuantReg: 13.60762) QuantErr: 13.60762 batch_time=0.47820 
Train Epoch: 39 [243/250 31104/32000 (97%)] Loss: 0.85664 (QuantReg: 13.77119) QuantErr: 13.77119 batch_time=0.49597 
Train Epoch: 39 codebook_update_time=1.70141
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_MSRVTT_1kA_roberta-base/checkpoint-epoch39.pth ...
Done in 4.089s
Updating 'best' checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_MSRVTT_1kA_roberta-base/checkpoint-epoch39.pth ...
Done in 7.966s
removing stale ckpt [epoch 38] [took 0.00s]
 epoch          : 39
 loss           : 0.8020275042057038
 quant_reg      : 13.649314716339111
 quant_err      : 13.649314716339111
 learning_rate  : 1.4239574134637466e-05
 n_samples      : 1248000
 n_steps        : 9750
 MSRVTT_jsfusion_test/t2v_metrics/R1: 23.9
 MSRVTT_jsfusion_test/t2v_metrics/R5: 53.7
 MSRVTT_jsfusion_test/t2v_metrics/R10: 69.2
 MSRVTT_jsfusion_test/t2v_metrics/R50: 89.2
 MSRVTT_jsfusion_test/t2v_metrics/MedR: 5.0
 MSRVTT_jsfusion_test/t2v_metrics/MeanR: 25.784
 MSRVTT_jsfusion_test/t2v_metrics/geometric_mean_R1-R5-R10: 44.61621870540411
 MSRVTT_jsfusion_test/v2t_metrics/R1: 24.5
 MSRVTT_jsfusion_test/v2t_metrics/R5: 54.5
 MSRVTT_jsfusion_test/v2t_metrics/R10: 69.8
 MSRVTT_jsfusion_test/v2t_metrics/R50: 90.0
 MSRVTT_jsfusion_test/v2t_metrics/MedR: 4.0
 MSRVTT_jsfusion_test/v2t_metrics/MeanR: 22.8485
 MSRVTT_jsfusion_test/v2t_metrics/geometric_mean_R1-R5-R10: 45.33907649028125
 mnt_best       : 44.61621870540411
 not_improved_count: 0
Train Epoch: 40 [1/250 128/32000 (0%)] Loss: 1.02278 (QuantReg: 13.73519) QuantErr: 13.73519 batch_time=29.60853 
Train Epoch: 40 [12/250 1536/32000 (5%)] Loss: 0.65432 (QuantReg: 13.83181) QuantErr: 13.83181 batch_time=0.50968 
Train Epoch: 40 [23/250 2944/32000 (9%)] Loss: 0.86565 (QuantReg: 13.10292) QuantErr: 13.10292 batch_time=0.48936 
Train Epoch: 40 [34/250 4352/32000 (14%)] Loss: 0.85913 (QuantReg: 13.70785) QuantErr: 13.70785 batch_time=1.27064 
Train Epoch: 40 [45/250 5760/32000 (18%)] Loss: 0.81960 (QuantReg: 13.40557) QuantErr: 13.40557 batch_time=0.47979 
Train Epoch: 40 [56/250 7168/32000 (22%)] Loss: 0.86517 (QuantReg: 13.70564) QuantErr: 13.70564 batch_time=0.48291 
Train Epoch: 40 [67/250 8576/32000 (27%)] Loss: 0.71936 (QuantReg: 13.71745) QuantErr: 13.71745 batch_time=0.48035 
Train Epoch: 40 [78/250 9984/32000 (31%)] Loss: 0.87419 (QuantReg: 13.53813) QuantErr: 13.53813 batch_time=0.48847 
Train Epoch: 40 [89/250 11392/32000 (36%)] Loss: 0.90474 (QuantReg: 13.56722) QuantErr: 13.56722 batch_time=0.47708 
Train Epoch: 40 [100/250 12800/32000 (40%)] Loss: 0.74988 (QuantReg: 13.71149) QuantErr: 13.71149 batch_time=0.48372 
Train Epoch: 40 [111/250 14208/32000 (44%)] Loss: 0.68789 (QuantReg: 13.72978) QuantErr: 13.72978 batch_time=0.70906 
Train Epoch: 40 [122/250 15616/32000 (49%)] Loss: 0.72145 (QuantReg: 13.99800) QuantErr: 13.99800 batch_time=0.49126 
Train Epoch: 40 [133/250 17024/32000 (53%)] Loss: 0.84772 (QuantReg: 13.58292) QuantErr: 13.58292 batch_time=0.48708 
Train Epoch: 40 [144/250 18432/32000 (58%)] Loss: 0.70948 (QuantReg: 13.88330) QuantErr: 13.88330 batch_time=1.65048 
Train Epoch: 40 [155/250 19840/32000 (62%)] Loss: 0.99123 (QuantReg: 13.56958) QuantErr: 13.56958 batch_time=0.48716 
Train Epoch: 40 [166/250 21248/32000 (66%)] Loss: 0.71057 (QuantReg: 13.41502) QuantErr: 13.41502 batch_time=0.48267 
Train Epoch: 40 [177/250 22656/32000 (71%)] Loss: 0.93815 (QuantReg: 13.63950) QuantErr: 13.63950 batch_time=1.16193 
Train Epoch: 40 [188/250 24064/32000 (75%)] Loss: 0.97796 (QuantReg: 13.81265) QuantErr: 13.81265 batch_time=0.48809 
Train Epoch: 40 [199/250 25472/32000 (80%)] Loss: 0.65668 (QuantReg: 13.73885) QuantErr: 13.73885 batch_time=0.49749 
Train Epoch: 40 [210/250 26880/32000 (84%)] Loss: 0.62753 (QuantReg: 13.71966) QuantErr: 13.71966 batch_time=0.47570 
Train Epoch: 40 [221/250 28288/32000 (88%)] Loss: 0.84226 (QuantReg: 13.52457) QuantErr: 13.52457 batch_time=0.49318 
Train Epoch: 40 [232/250 29696/32000 (93%)] Loss: 0.79480 (QuantReg: 13.73900) QuantErr: 13.73900 batch_time=0.80474 
Train Epoch: 40 [243/250 31104/32000 (97%)] Loss: 0.83617 (QuantReg: 13.80657) QuantErr: 13.80657 batch_time=0.47903 
Train Epoch: 40 codebook_update_time=1.57199
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_MSRVTT_1kA_roberta-base/checkpoint-epoch40.pth ...
Done in 4.009s
Updating 'best' checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_MSRVTT_1kA_roberta-base/checkpoint-epoch40.pth ...
Done in 7.988s
removing stale ckpt [epoch 39] [took 0.00s]
 epoch          : 40
 loss           : 0.8010204273462296
 quant_reg      : 13.708213035583496
 quant_err      : 13.708213035583496
 learning_rate  : 1.3527595427905592e-05
 n_samples      : 1280000
 n_steps        : 10000
 MSRVTT_jsfusion_test/t2v_metrics/R1: 25.4
 MSRVTT_jsfusion_test/t2v_metrics/R5: 54.6
 MSRVTT_jsfusion_test/t2v_metrics/R10: 67.7
 MSRVTT_jsfusion_test/t2v_metrics/R50: 89.3
 MSRVTT_jsfusion_test/t2v_metrics/MedR: 4.5
 MSRVTT_jsfusion_test/t2v_metrics/MeanR: 26.49
 MSRVTT_jsfusion_test/t2v_metrics/geometric_mean_R1-R5-R10: 45.45046624096163
 MSRVTT_jsfusion_test/v2t_metrics/R1: 24.1
 MSRVTT_jsfusion_test/v2t_metrics/R5: 55.8
 MSRVTT_jsfusion_test/v2t_metrics/R10: 68.7
 MSRVTT_jsfusion_test/v2t_metrics/R50: 89.7
 MSRVTT_jsfusion_test/v2t_metrics/MedR: 4.0
 MSRVTT_jsfusion_test/v2t_metrics/MeanR: 23.442
 MSRVTT_jsfusion_test/v2t_metrics/geometric_mean_R1-R5-R10: 45.206684799809004
 mnt_best       : 45.45046624096163
 not_improved_count: 0
Train Epoch: 41 [1/250 128/32000 (0%)] Loss: 0.62617 (QuantReg: 13.60321) QuantErr: 13.60321 batch_time=28.22087 
Train Epoch: 41 [12/250 1536/32000 (5%)] Loss: 0.71328 (QuantReg: 13.67856) QuantErr: 13.67856 batch_time=0.47571 
Train Epoch: 41 [23/250 2944/32000 (9%)] Loss: 0.56110 (QuantReg: 13.77232) QuantErr: 13.77232 batch_time=0.48202 
Train Epoch: 41 [34/250 4352/32000 (14%)] Loss: 0.96417 (QuantReg: 13.70181) QuantErr: 13.70181 batch_time=0.48071 
Train Epoch: 41 [45/250 5760/32000 (18%)] Loss: 0.52821 (QuantReg: 14.05395) QuantErr: 14.05395 batch_time=0.47224 
Train Epoch: 41 [56/250 7168/32000 (22%)] Loss: 0.66567 (QuantReg: 13.55929) QuantErr: 13.55929 batch_time=0.62231 
Train Epoch: 41 [67/250 8576/32000 (27%)] Loss: 0.55951 (QuantReg: 13.95862) QuantErr: 13.95862 batch_time=0.49712 
Train Epoch: 41 [78/250 9984/32000 (31%)] Loss: 0.73124 (QuantReg: 13.91457) QuantErr: 13.91457 batch_time=0.49594 
Train Epoch: 41 [89/250 11392/32000 (36%)] Loss: 0.86240 (QuantReg: 13.84865) QuantErr: 13.84865 batch_time=0.59995 
Train Epoch: 41 [100/250 12800/32000 (40%)] Loss: 0.90496 (QuantReg: 13.64133) QuantErr: 13.64133 batch_time=0.49026 
Train Epoch: 41 [111/250 14208/32000 (44%)] Loss: 0.75686 (QuantReg: 13.88951) QuantErr: 13.88951 batch_time=0.48798 
Train Epoch: 41 [122/250 15616/32000 (49%)] Loss: 0.61666 (QuantReg: 13.81840) QuantErr: 13.81840 batch_time=0.60947 
Train Epoch: 41 [133/250 17024/32000 (53%)] Loss: 0.94035 (QuantReg: 13.56085) QuantErr: 13.56085 batch_time=0.48644 
Train Epoch: 41 [144/250 18432/32000 (58%)] Loss: 0.77976 (QuantReg: 13.87397) QuantErr: 13.87397 batch_time=0.48878 
Train Epoch: 41 [155/250 19840/32000 (62%)] Loss: 0.75362 (QuantReg: 13.87440) QuantErr: 13.87440 batch_time=0.50896 
Train Epoch: 41 [166/250 21248/32000 (66%)] Loss: 0.51568 (QuantReg: 13.92766) QuantErr: 13.92766 batch_time=0.49323 
Train Epoch: 41 [177/250 22656/32000 (71%)] Loss: 0.68583 (QuantReg: 13.73904) QuantErr: 13.73904 batch_time=0.49205 
Train Epoch: 41 [188/250 24064/32000 (75%)] Loss: 0.53661 (QuantReg: 13.70765) QuantErr: 13.70765 batch_time=0.60563 
Train Epoch: 41 [199/250 25472/32000 (80%)] Loss: 0.77234 (QuantReg: 13.98493) QuantErr: 13.98493 batch_time=0.48040 
Train Epoch: 41 [210/250 26880/32000 (84%)] Loss: 0.84999 (QuantReg: 13.79677) QuantErr: 13.79677 batch_time=0.47688 
Train Epoch: 41 [221/250 28288/32000 (88%)] Loss: 0.83268 (QuantReg: 13.94626) QuantErr: 13.94626 batch_time=0.58726 
Train Epoch: 41 [232/250 29696/32000 (93%)] Loss: 0.90097 (QuantReg: 13.59979) QuantErr: 13.59979 batch_time=0.48571 
Train Epoch: 41 [243/250 31104/32000 (97%)] Loss: 0.73471 (QuantReg: 13.89042) QuantErr: 13.89042 batch_time=0.49164 
Train Epoch: 41 codebook_update_time=1.86132
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_MSRVTT_1kA_roberta-base/checkpoint-epoch41.pth ...
Done in 4.089s
removing stale ckpt [epoch 40] [took 0.00s]
 epoch          : 41
 loss           : 0.7825957357883453
 quant_reg      : 13.726843364715576
 quant_err      : 13.726843364715576
 learning_rate  : 1.2851215656510312e-05
 n_samples      : 1312000
 n_steps        : 10250
 MSRVTT_jsfusion_test/t2v_metrics/R1: 24.7
 MSRVTT_jsfusion_test/t2v_metrics/R5: 53.4
 MSRVTT_jsfusion_test/t2v_metrics/R10: 67.5
 MSRVTT_jsfusion_test/t2v_metrics/R50: 88.6
 MSRVTT_jsfusion_test/t2v_metrics/MedR: 5.0
 MSRVTT_jsfusion_test/t2v_metrics/MeanR: 26.731
 MSRVTT_jsfusion_test/t2v_metrics/geometric_mean_R1-R5-R10: 44.65265921754029
 MSRVTT_jsfusion_test/v2t_metrics/R1: 23.1
 MSRVTT_jsfusion_test/v2t_metrics/R5: 54.7
 MSRVTT_jsfusion_test/v2t_metrics/R10: 68.3
 MSRVTT_jsfusion_test/v2t_metrics/R50: 90.7
 MSRVTT_jsfusion_test/v2t_metrics/MedR: 5.0
 MSRVTT_jsfusion_test/v2t_metrics/MeanR: 24.13
 MSRVTT_jsfusion_test/v2t_metrics/geometric_mean_R1-R5-R10: 44.19162822681513
 mnt_best       : 45.45046624096163
 not_improved_count: 1
Train Epoch: 42 [1/250 128/32000 (0%)] Loss: 0.69850 (QuantReg: 13.87202) QuantErr: 13.87202 batch_time=28.91094 
Train Epoch: 42 [12/250 1536/32000 (5%)] Loss: 0.84651 (QuantReg: 13.63659) QuantErr: 13.63659 batch_time=0.48039 
Train Epoch: 42 [23/250 2944/32000 (9%)] Loss: 0.63239 (QuantReg: 14.04925) QuantErr: 14.04925 batch_time=0.47811 
Train Epoch: 42 [34/250 4352/32000 (14%)] Loss: 0.64188 (QuantReg: 13.89195) QuantErr: 13.89195 batch_time=0.53580 
Train Epoch: 42 [45/250 5760/32000 (18%)] Loss: 0.88454 (QuantReg: 13.76260) QuantErr: 13.76260 batch_time=0.47299 
Train Epoch: 42 [56/250 7168/32000 (22%)] Loss: 0.48324 (QuantReg: 13.84632) QuantErr: 13.84632 batch_time=0.49677 
Train Epoch: 42 [67/250 8576/32000 (27%)] Loss: 0.92164 (QuantReg: 13.43248) QuantErr: 13.43248 batch_time=0.48493 
Train Epoch: 42 [78/250 9984/32000 (31%)] Loss: 1.01498 (QuantReg: 13.38683) QuantErr: 13.38683 batch_time=0.49586 
Train Epoch: 42 [89/250 11392/32000 (36%)] Loss: 0.95817 (QuantReg: 13.90031) QuantErr: 13.90031 batch_time=0.48716 
Train Epoch: 42 [100/250 12800/32000 (40%)] Loss: 0.84062 (QuantReg: 13.69130) QuantErr: 13.69130 batch_time=0.51379 
Train Epoch: 42 [111/250 14208/32000 (44%)] Loss: 0.82853 (QuantReg: 13.63521) QuantErr: 13.63521 batch_time=0.48291 
Train Epoch: 42 [122/250 15616/32000 (49%)] Loss: 0.87517 (QuantReg: 14.00644) QuantErr: 14.00644 batch_time=0.48652 
Train Epoch: 42 [133/250 17024/32000 (53%)] Loss: 0.61257 (QuantReg: 13.80060) QuantErr: 13.80060 batch_time=0.48966 
Train Epoch: 42 [144/250 18432/32000 (58%)] Loss: 0.89004 (QuantReg: 13.53806) QuantErr: 13.53806 batch_time=0.49294 
Train Epoch: 42 [155/250 19840/32000 (62%)] Loss: 0.64762 (QuantReg: 13.76373) QuantErr: 13.76373 batch_time=0.48813 
Train Epoch: 42 [166/250 21248/32000 (66%)] Loss: 0.84353 (QuantReg: 13.65878) QuantErr: 13.65878 batch_time=0.48505 
Train Epoch: 42 [177/250 22656/32000 (71%)] Loss: 0.85479 (QuantReg: 13.79791) QuantErr: 13.79791 batch_time=0.72003 
Train Epoch: 42 [188/250 24064/32000 (75%)] Loss: 0.64139 (QuantReg: 13.74747) QuantErr: 13.74747 batch_time=0.48041 
Train Epoch: 42 [199/250 25472/32000 (80%)] Loss: 0.95788 (QuantReg: 13.91047) QuantErr: 13.91047 batch_time=0.50392 
Train Epoch: 42 [210/250 26880/32000 (84%)] Loss: 0.86477 (QuantReg: 13.91864) QuantErr: 13.91864 batch_time=0.48073 
Train Epoch: 42 [221/250 28288/32000 (88%)] Loss: 0.70614 (QuantReg: 13.75027) QuantErr: 13.75027 batch_time=1.22459 
Train Epoch: 42 [232/250 29696/32000 (93%)] Loss: 0.79053 (QuantReg: 13.65796) QuantErr: 13.65796 batch_time=0.60666 
Train Epoch: 42 [243/250 31104/32000 (97%)] Loss: 0.80606 (QuantReg: 13.84307) QuantErr: 13.84307 batch_time=0.49366 
Train Epoch: 42 codebook_update_time=1.60482
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_MSRVTT_1kA_roberta-base/checkpoint-epoch42.pth ...
Done in 4.052s
removing stale ckpt [epoch 41] [took 0.00s]
 epoch          : 42
 loss           : 0.7762019647359848
 quant_reg      : 13.730311828613281
 quant_err      : 13.730311828613281
 learning_rate  : 1.2208654873684796e-05
 n_samples      : 1344000
 n_steps        : 10500
 MSRVTT_jsfusion_test/t2v_metrics/R1: 23.7
 MSRVTT_jsfusion_test/t2v_metrics/R5: 53.5
 MSRVTT_jsfusion_test/t2v_metrics/R10: 68.2
 MSRVTT_jsfusion_test/t2v_metrics/R50: 89.4
 MSRVTT_jsfusion_test/t2v_metrics/MedR: 5.0
 MSRVTT_jsfusion_test/t2v_metrics/MeanR: 27.322
 MSRVTT_jsfusion_test/t2v_metrics/geometric_mean_R1-R5-R10: 44.221027988459944
 MSRVTT_jsfusion_test/v2t_metrics/R1: 24.1
 MSRVTT_jsfusion_test/v2t_metrics/R5: 53.7
 MSRVTT_jsfusion_test/v2t_metrics/R10: 68.1
 MSRVTT_jsfusion_test/v2t_metrics/R50: 89.8
 MSRVTT_jsfusion_test/v2t_metrics/MedR: 4.5
 MSRVTT_jsfusion_test/v2t_metrics/MeanR: 24.2895
 MSRVTT_jsfusion_test/v2t_metrics/geometric_mean_R1-R5-R10: 44.50199494486188
 mnt_best       : 45.45046624096163
 not_improved_count: 2
Train Epoch: 43 [1/250 128/32000 (0%)] Loss: 0.62696 (QuantReg: 14.02613) QuantErr: 14.02613 batch_time=26.78449 
Train Epoch: 43 [12/250 1536/32000 (5%)] Loss: 0.79193 (QuantReg: 13.71832) QuantErr: 13.71832 batch_time=0.49169 
Train Epoch: 43 [23/250 2944/32000 (9%)] Loss: 0.74953 (QuantReg: 13.61813) QuantErr: 13.61813 batch_time=0.52246 
Train Epoch: 43 [34/250 4352/32000 (14%)] Loss: 0.81310 (QuantReg: 13.82187) QuantErr: 13.82187 batch_time=0.48424 
Train Epoch: 43 [45/250 5760/32000 (18%)] Loss: 0.69533 (QuantReg: 13.84296) QuantErr: 13.84296 batch_time=0.49981 
Train Epoch: 43 [56/250 7168/32000 (22%)] Loss: 0.80889 (QuantReg: 13.64419) QuantErr: 13.64419 batch_time=0.48448 
Train Epoch: 43 [67/250 8576/32000 (27%)] Loss: 0.85982 (QuantReg: 13.70028) QuantErr: 13.70028 batch_time=0.48352 
Train Epoch: 43 [78/250 9984/32000 (31%)] Loss: 0.87449 (QuantReg: 14.04293) QuantErr: 14.04293 batch_time=0.49377 
Train Epoch: 43 [89/250 11392/32000 (36%)] Loss: 0.94664 (QuantReg: 13.86617) QuantErr: 13.86617 batch_time=0.69897 
Train Epoch: 43 [100/250 12800/32000 (40%)] Loss: 0.90044 (QuantReg: 13.82958) QuantErr: 13.82958 batch_time=0.49114 
Train Epoch: 43 [111/250 14208/32000 (44%)] Loss: 0.85623 (QuantReg: 13.96753) QuantErr: 13.96753 batch_time=0.48439 
Train Epoch: 43 [122/250 15616/32000 (49%)] Loss: 0.68362 (QuantReg: 13.91621) QuantErr: 13.91621 batch_time=0.48915 
Train Epoch: 43 [133/250 17024/32000 (53%)] Loss: 0.81208 (QuantReg: 13.46484) QuantErr: 13.46484 batch_time=0.47711 
Train Epoch: 43 [144/250 18432/32000 (58%)] Loss: 0.82472 (QuantReg: 13.63841) QuantErr: 13.63841 batch_time=2.20451 
Train Epoch: 43 [155/250 19840/32000 (62%)] Loss: 0.87567 (QuantReg: 13.70959) QuantErr: 13.70959 batch_time=0.48171 
Train Epoch: 43 [166/250 21248/32000 (66%)] Loss: 0.86938 (QuantReg: 13.81841) QuantErr: 13.81841 batch_time=0.51763 
Train Epoch: 43 [177/250 22656/32000 (71%)] Loss: 0.79768 (QuantReg: 13.78623) QuantErr: 13.78623 batch_time=0.48949 
Train Epoch: 43 [188/250 24064/32000 (75%)] Loss: 0.75738 (QuantReg: 13.52758) QuantErr: 13.52758 batch_time=0.48831 
Train Epoch: 43 [199/250 25472/32000 (80%)] Loss: 0.98351 (QuantReg: 13.83830) QuantErr: 13.83830 batch_time=0.49916 
Train Epoch: 43 [210/250 26880/32000 (84%)] Loss: 0.73311 (QuantReg: 13.77050) QuantErr: 13.77050 batch_time=0.50716 
Train Epoch: 43 [221/250 28288/32000 (88%)] Loss: 0.73000 (QuantReg: 14.00887) QuantErr: 14.00887 batch_time=0.49493 
Train Epoch: 43 [232/250 29696/32000 (93%)] Loss: 0.96374 (QuantReg: 14.06725) QuantErr: 14.06725 batch_time=0.49085 
Train Epoch: 43 [243/250 31104/32000 (97%)] Loss: 0.82759 (QuantReg: 13.57615) QuantErr: 13.57615 batch_time=0.61058 
Train Epoch: 43 codebook_update_time=1.61298
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_MSRVTT_1kA_roberta-base/checkpoint-epoch43.pth ...
Done in 3.987s
removing stale ckpt [epoch 42] [took 0.00s]
 epoch          : 43
 loss           : 0.7764584361314774
 quant_reg      : 13.779004959106445
 quant_err      : 13.779004959106445
 learning_rate  : 1.1598222130000555e-05
 n_samples      : 1376000
 n_steps        : 10750
 MSRVTT_jsfusion_test/t2v_metrics/R1: 25.1
 MSRVTT_jsfusion_test/t2v_metrics/R5: 53.9
 MSRVTT_jsfusion_test/t2v_metrics/R10: 66.7
 MSRVTT_jsfusion_test/t2v_metrics/R50: 89.6
 MSRVTT_jsfusion_test/t2v_metrics/MedR: 5.0
 MSRVTT_jsfusion_test/t2v_metrics/MeanR: 27.054
 MSRVTT_jsfusion_test/t2v_metrics/geometric_mean_R1-R5-R10: 44.85347618103172
 MSRVTT_jsfusion_test/v2t_metrics/R1: 24.1
 MSRVTT_jsfusion_test/v2t_metrics/R5: 54.8
 MSRVTT_jsfusion_test/v2t_metrics/R10: 68.6
 MSRVTT_jsfusion_test/v2t_metrics/R50: 90.2
 MSRVTT_jsfusion_test/v2t_metrics/MedR: 4.0
 MSRVTT_jsfusion_test/v2t_metrics/MeanR: 23.877
 MSRVTT_jsfusion_test/v2t_metrics/geometric_mean_R1-R5-R10: 44.91319033832874
 mnt_best       : 45.45046624096163
 not_improved_count: 3
Train Epoch: 44 [1/250 128/32000 (0%)] Loss: 0.81577 (QuantReg: 13.59031) QuantErr: 13.59031 batch_time=30.44403 
Train Epoch: 44 [12/250 1536/32000 (5%)] Loss: 0.74225 (QuantReg: 13.89880) QuantErr: 13.89880 batch_time=0.47928 
Train Epoch: 44 [23/250 2944/32000 (9%)] Loss: 1.03701 (QuantReg: 13.83868) QuantErr: 13.83868 batch_time=1.38198 
Train Epoch: 44 [34/250 4352/32000 (14%)] Loss: 0.54418 (QuantReg: 13.96148) QuantErr: 13.96148 batch_time=0.47715 
Train Epoch: 44 [45/250 5760/32000 (18%)] Loss: 0.67509 (QuantReg: 14.07450) QuantErr: 14.07450 batch_time=0.48167 
Train Epoch: 44 [56/250 7168/32000 (22%)] Loss: 0.69237 (QuantReg: 13.86323) QuantErr: 13.86323 batch_time=0.57521 
Train Epoch: 44 [67/250 8576/32000 (27%)] Loss: 1.03198 (QuantReg: 13.61710) QuantErr: 13.61710 batch_time=1.12021 
Train Epoch: 44 [78/250 9984/32000 (31%)] Loss: 0.81208 (QuantReg: 13.79980) QuantErr: 13.79980 batch_time=0.46929 
Train Epoch: 44 [89/250 11392/32000 (36%)] Loss: 0.73071 (QuantReg: 13.69877) QuantErr: 13.69877 batch_time=0.48711 
Train Epoch: 44 [100/250 12800/32000 (40%)] Loss: 0.66267 (QuantReg: 13.59295) QuantErr: 13.59295 batch_time=0.47937 
Train Epoch: 44 [111/250 14208/32000 (44%)] Loss: 0.72868 (QuantReg: 13.95536) QuantErr: 13.95536 batch_time=0.46939 
Train Epoch: 44 [122/250 15616/32000 (49%)] Loss: 0.82716 (QuantReg: 13.81001) QuantErr: 13.81001 batch_time=0.48788 
Train Epoch: 44 [133/250 17024/32000 (53%)] Loss: 0.78019 (QuantReg: 13.99398) QuantErr: 13.99398 batch_time=0.48678 
Train Epoch: 44 [144/250 18432/32000 (58%)] Loss: 0.81470 (QuantReg: 13.82957) QuantErr: 13.82957 batch_time=0.49383 
Train Epoch: 44 [155/250 19840/32000 (62%)] Loss: 0.59756 (QuantReg: 13.90764) QuantErr: 13.90764 batch_time=0.52818 
Train Epoch: 44 [166/250 21248/32000 (66%)] Loss: 0.89517 (QuantReg: 13.95312) QuantErr: 13.95312 batch_time=0.49410 
Train Epoch: 44 [177/250 22656/32000 (71%)] Loss: 0.46956 (QuantReg: 14.15370) QuantErr: 14.15370 batch_time=0.49588 
Train Epoch: 44 [188/250 24064/32000 (75%)] Loss: 1.01524 (QuantReg: 13.61704) QuantErr: 13.61704 batch_time=0.48712 
Train Epoch: 44 [199/250 25472/32000 (80%)] Loss: 0.81003 (QuantReg: 13.94085) QuantErr: 13.94085 batch_time=0.48834 
Train Epoch: 44 [210/250 26880/32000 (84%)] Loss: 0.90373 (QuantReg: 13.51059) QuantErr: 13.51059 batch_time=0.48307 
Train Epoch: 44 [221/250 28288/32000 (88%)] Loss: 0.65438 (QuantReg: 13.65227) QuantErr: 13.65227 batch_time=0.70299 
Train Epoch: 44 [232/250 29696/32000 (93%)] Loss: 0.61507 (QuantReg: 13.85343) QuantErr: 13.85343 batch_time=0.59060 
Train Epoch: 44 [243/250 31104/32000 (97%)] Loss: 0.56073 (QuantReg: 13.77119) QuantErr: 13.77119 batch_time=0.54119 
Train Epoch: 44 codebook_update_time=1.64054
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_MSRVTT_1kA_roberta-base/checkpoint-epoch44.pth ...
Done in 4.131s
Updating 'best' checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_MSRVTT_1kA_roberta-base/checkpoint-epoch44.pth ...
Done in 8.096s
removing stale ckpt [epoch 43] [took 0.00s]
 epoch          : 44
 loss           : 0.7702731961011886
 quant_reg      : 13.790441867828369
 quant_err      : 13.790441867828369
 learning_rate  : 1.1018311023500527e-05
 n_samples      : 1408000
 n_steps        : 11000
 MSRVTT_jsfusion_test/t2v_metrics/R1: 25.5
 MSRVTT_jsfusion_test/t2v_metrics/R5: 54.7
 MSRVTT_jsfusion_test/t2v_metrics/R10: 67.8
 MSRVTT_jsfusion_test/t2v_metrics/R50: 89.2
 MSRVTT_jsfusion_test/t2v_metrics/MedR: 5.0
 MSRVTT_jsfusion_test/t2v_metrics/MeanR: 27.035
 MSRVTT_jsfusion_test/t2v_metrics/geometric_mean_R1-R5-R10: 45.560211714800715
 MSRVTT_jsfusion_test/v2t_metrics/R1: 24.5
 MSRVTT_jsfusion_test/v2t_metrics/R5: 55.0
 MSRVTT_jsfusion_test/v2t_metrics/R10: 69.0
 MSRVTT_jsfusion_test/v2t_metrics/R50: 90.2
 MSRVTT_jsfusion_test/v2t_metrics/MedR: 4.0
 MSRVTT_jsfusion_test/v2t_metrics/MeanR: 23.8005
 MSRVTT_jsfusion_test/v2t_metrics/geometric_mean_R1-R5-R10: 45.30289491218929
 mnt_best       : 45.560211714800715
 not_improved_count: 0
Train Epoch: 45 [1/250 128/32000 (0%)] Loss: 0.72699 (QuantReg: 13.77554) QuantErr: 13.77554 batch_time=31.20414 
Train Epoch: 45 [12/250 1536/32000 (5%)] Loss: 0.57544 (QuantReg: 14.10861) QuantErr: 14.10861 batch_time=0.47666 
Train Epoch: 45 [23/250 2944/32000 (9%)] Loss: 0.98186 (QuantReg: 13.68263) QuantErr: 13.68263 batch_time=0.52319 
Train Epoch: 45 [34/250 4352/32000 (14%)] Loss: 0.69984 (QuantReg: 13.82173) QuantErr: 13.82173 batch_time=0.48728 
Train Epoch: 45 [45/250 5760/32000 (18%)] Loss: 0.85032 (QuantReg: 13.78329) QuantErr: 13.78329 batch_time=0.59730 
Train Epoch: 45 [56/250 7168/32000 (22%)] Loss: 0.88963 (QuantReg: 13.74977) QuantErr: 13.74977 batch_time=0.48731 
Train Epoch: 45 [67/250 8576/32000 (27%)] Loss: 0.64827 (QuantReg: 13.82822) QuantErr: 13.82822 batch_time=0.47597 
Train Epoch: 45 [78/250 9984/32000 (31%)] Loss: 0.80685 (QuantReg: 13.72235) QuantErr: 13.72235 batch_time=0.47460 
Train Epoch: 45 [89/250 11392/32000 (36%)] Loss: 1.00381 (QuantReg: 13.52509) QuantErr: 13.52509 batch_time=0.48936 
Train Epoch: 45 [100/250 12800/32000 (40%)] Loss: 0.47578 (QuantReg: 14.01428) QuantErr: 14.01428 batch_time=0.49523 
Train Epoch: 45 [111/250 14208/32000 (44%)] Loss: 0.77566 (QuantReg: 13.45622) QuantErr: 13.45622 batch_time=1.01559 
Train Epoch: 45 [122/250 15616/32000 (49%)] Loss: 0.78230 (QuantReg: 13.67070) QuantErr: 13.67070 batch_time=0.49572 
Train Epoch: 45 [133/250 17024/32000 (53%)] Loss: 0.71579 (QuantReg: 13.75348) QuantErr: 13.75348 batch_time=0.90868 
Train Epoch: 45 [144/250 18432/32000 (58%)] Loss: 0.74606 (QuantReg: 13.77494) QuantErr: 13.77494 batch_time=0.60491 
Train Epoch: 45 [155/250 19840/32000 (62%)] Loss: 0.76933 (QuantReg: 14.06128) QuantErr: 14.06128 batch_time=1.43239 
Train Epoch: 45 [166/250 21248/32000 (66%)] Loss: 0.65843 (QuantReg: 14.09388) QuantErr: 14.09388 batch_time=0.47806 
Train Epoch: 45 [177/250 22656/32000 (71%)] Loss: 0.81872 (QuantReg: 13.87277) QuantErr: 13.87277 batch_time=0.47545 
Train Epoch: 45 [188/250 24064/32000 (75%)] Loss: 0.61674 (QuantReg: 13.94786) QuantErr: 13.94786 batch_time=0.48630 
Train Epoch: 45 [199/250 25472/32000 (80%)] Loss: 0.81661 (QuantReg: 13.96774) QuantErr: 13.96774 batch_time=0.48508 
Train Epoch: 45 [210/250 26880/32000 (84%)] Loss: 0.97142 (QuantReg: 13.90958) QuantErr: 13.90958 batch_time=0.49755 
Train Epoch: 45 [221/250 28288/32000 (88%)] Loss: 0.70443 (QuantReg: 13.61618) QuantErr: 13.61618 batch_time=0.50561 
Train Epoch: 45 [232/250 29696/32000 (93%)] Loss: 0.76897 (QuantReg: 13.89317) QuantErr: 13.89317 batch_time=0.49016 
Train Epoch: 45 [243/250 31104/32000 (97%)] Loss: 0.69924 (QuantReg: 13.97155) QuantErr: 13.97155 batch_time=0.48572 
Train Epoch: 45 codebook_update_time=1.58630
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_MSRVTT_1kA_roberta-base/checkpoint-epoch45.pth ...
Done in 4.008s
removing stale ckpt [epoch 44] [took 0.00s]
 epoch          : 45
 loss           : 0.7550979577302933
 quant_reg      : 13.781465240478516
 quant_err      : 13.781465240478516
 learning_rate  : 1.04673954723255e-05
 n_samples      : 1440000
 n_steps        : 11250
 MSRVTT_jsfusion_test/t2v_metrics/R1: 25.4
 MSRVTT_jsfusion_test/t2v_metrics/R5: 54.5
 MSRVTT_jsfusion_test/t2v_metrics/R10: 68.2
 MSRVTT_jsfusion_test/t2v_metrics/R50: 89.0
 MSRVTT_jsfusion_test/t2v_metrics/MedR: 4.0
 MSRVTT_jsfusion_test/t2v_metrics/MeanR: 26.417
 MSRVTT_jsfusion_test/t2v_metrics/geometric_mean_R1-R5-R10: 45.53425106900006
 MSRVTT_jsfusion_test/v2t_metrics/R1: 23.4
 MSRVTT_jsfusion_test/v2t_metrics/R5: 55.4
 MSRVTT_jsfusion_test/v2t_metrics/R10: 69.7
 MSRVTT_jsfusion_test/v2t_metrics/R50: 89.7
 MSRVTT_jsfusion_test/v2t_metrics/MedR: 4.0
 MSRVTT_jsfusion_test/v2t_metrics/MeanR: 23.1185
 MSRVTT_jsfusion_test/v2t_metrics/geometric_mean_R1-R5-R10: 44.873106217104386
 mnt_best       : 45.560211714800715
 not_improved_count: 1
Train Epoch: 46 [1/250 128/32000 (0%)] Loss: 0.87544 (QuantReg: 13.50720) QuantErr: 13.50720 batch_time=29.00588 
Train Epoch: 46 [12/250 1536/32000 (5%)] Loss: 0.79090 (QuantReg: 13.64304) QuantErr: 13.64304 batch_time=0.50153 
Train Epoch: 46 [23/250 2944/32000 (9%)] Loss: 0.73221 (QuantReg: 13.51358) QuantErr: 13.51358 batch_time=0.48911 
Train Epoch: 46 [34/250 4352/32000 (14%)] Loss: 0.99483 (QuantReg: 13.87637) QuantErr: 13.87637 batch_time=0.48359 
Train Epoch: 46 [45/250 5760/32000 (18%)] Loss: 0.85318 (QuantReg: 13.68553) QuantErr: 13.68553 batch_time=0.48240 
Train Epoch: 46 [56/250 7168/32000 (22%)] Loss: 0.81456 (QuantReg: 13.65429) QuantErr: 13.65429 batch_time=0.50583 
Train Epoch: 46 [67/250 8576/32000 (27%)] Loss: 0.69646 (QuantReg: 13.78549) QuantErr: 13.78549 batch_time=3.96747 
Train Epoch: 46 [78/250 9984/32000 (31%)] Loss: 0.80805 (QuantReg: 13.80007) QuantErr: 13.80007 batch_time=0.48284 
Train Epoch: 46 [89/250 11392/32000 (36%)] Loss: 0.73331 (QuantReg: 13.75390) QuantErr: 13.75390 batch_time=0.48464 
Train Epoch: 46 [100/250 12800/32000 (40%)] Loss: 0.78070 (QuantReg: 13.57968) QuantErr: 13.57968 batch_time=0.50242 
Train Epoch: 46 [111/250 14208/32000 (44%)] Loss: 0.72799 (QuantReg: 13.85950) QuantErr: 13.85950 batch_time=0.47962 
Train Epoch: 46 [122/250 15616/32000 (49%)] Loss: 0.96617 (QuantReg: 13.74617) QuantErr: 13.74617 batch_time=0.50582 
Train Epoch: 46 [133/250 17024/32000 (53%)] Loss: 0.69933 (QuantReg: 13.70675) QuantErr: 13.70675 batch_time=0.49132 
Train Epoch: 46 [144/250 18432/32000 (58%)] Loss: 1.13451 (QuantReg: 13.66905) QuantErr: 13.66905 batch_time=0.48596 
Train Epoch: 46 [155/250 19840/32000 (62%)] Loss: 0.63445 (QuantReg: 13.97668) QuantErr: 13.97668 batch_time=0.48191 
Train Epoch: 46 [166/250 21248/32000 (66%)] Loss: 0.64984 (QuantReg: 13.68443) QuantErr: 13.68443 batch_time=0.50351 
Train Epoch: 46 [177/250 22656/32000 (71%)] Loss: 0.75474 (QuantReg: 13.84388) QuantErr: 13.84388 batch_time=0.49119 
Train Epoch: 46 [188/250 24064/32000 (75%)] Loss: 0.94392 (QuantReg: 13.73636) QuantErr: 13.73636 batch_time=0.48395 
Train Epoch: 46 [199/250 25472/32000 (80%)] Loss: 0.82537 (QuantReg: 14.01768) QuantErr: 14.01768 batch_time=0.72046 
Train Epoch: 46 [210/250 26880/32000 (84%)] Loss: 1.02456 (QuantReg: 14.10460) QuantErr: 14.10460 batch_time=0.48456 
Train Epoch: 46 [221/250 28288/32000 (88%)] Loss: 0.63214 (QuantReg: 13.72894) QuantErr: 13.72894 batch_time=0.48635 
Train Epoch: 46 [232/250 29696/32000 (93%)] Loss: 0.94724 (QuantReg: 13.49643) QuantErr: 13.49643 batch_time=1.54329 
Train Epoch: 46 [243/250 31104/32000 (97%)] Loss: 0.72155 (QuantReg: 14.09543) QuantErr: 14.09543 batch_time=0.49336 
Train Epoch: 46 codebook_update_time=1.62086
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_MSRVTT_1kA_roberta-base/checkpoint-epoch46.pth ...
Done in 4.003s
removing stale ckpt [epoch 45] [took 0.00s]
 epoch          : 46
 loss           : 0.7665483434200286
 quant_reg      : 13.785688201904296
 quant_err      : 13.785688201904296
 learning_rate  : 9.944025698709225e-06
 n_samples      : 1472000
 n_steps        : 11500
 MSRVTT_jsfusion_test/t2v_metrics/R1: 25.7
 MSRVTT_jsfusion_test/t2v_metrics/R5: 53.7
 MSRVTT_jsfusion_test/t2v_metrics/R10: 66.5
 MSRVTT_jsfusion_test/t2v_metrics/R50: 88.8
 MSRVTT_jsfusion_test/t2v_metrics/MedR: 5.0
 MSRVTT_jsfusion_test/t2v_metrics/MeanR: 27.256
 MSRVTT_jsfusion_test/t2v_metrics/geometric_mean_R1-R5-R10: 45.106903858360546
 MSRVTT_jsfusion_test/v2t_metrics/R1: 25.0
 MSRVTT_jsfusion_test/v2t_metrics/R5: 54.1
 MSRVTT_jsfusion_test/v2t_metrics/R10: 68.8
 MSRVTT_jsfusion_test/v2t_metrics/R50: 89.6
 MSRVTT_jsfusion_test/v2t_metrics/MedR: 5.0
 MSRVTT_jsfusion_test/v2t_metrics/MeanR: 23.851
 MSRVTT_jsfusion_test/v2t_metrics/geometric_mean_R1-R5-R10: 45.31499161883594
 mnt_best       : 45.560211714800715
 not_improved_count: 2
Train Epoch: 47 [1/250 128/32000 (0%)] Loss: 0.72665 (QuantReg: 13.79110) QuantErr: 13.79110 batch_time=28.33146 
Train Epoch: 47 [12/250 1536/32000 (5%)] Loss: 0.83967 (QuantReg: 13.80427) QuantErr: 13.80427 batch_time=0.48694 
Train Epoch: 47 [23/250 2944/32000 (9%)] Loss: 0.78541 (QuantReg: 13.98422) QuantErr: 13.98422 batch_time=0.48048 
Train Epoch: 47 [34/250 4352/32000 (14%)] Loss: 0.71324 (QuantReg: 13.76442) QuantErr: 13.76442 batch_time=0.48090 
Train Epoch: 47 [45/250 5760/32000 (18%)] Loss: 0.77413 (QuantReg: 13.80919) QuantErr: 13.80919 batch_time=0.79401 
Train Epoch: 47 [56/250 7168/32000 (22%)] Loss: 0.64521 (QuantReg: 13.91399) QuantErr: 13.91399 batch_time=0.49668 
Train Epoch: 47 [67/250 8576/32000 (27%)] Loss: 0.64678 (QuantReg: 13.79146) QuantErr: 13.79146 batch_time=1.79784 
Train Epoch: 47 [78/250 9984/32000 (31%)] Loss: 0.76438 (QuantReg: 13.64450) QuantErr: 13.64450 batch_time=0.51876 
Train Epoch: 47 [89/250 11392/32000 (36%)] Loss: 0.75666 (QuantReg: 13.81261) QuantErr: 13.81261 batch_time=0.47914 
Train Epoch: 47 [100/250 12800/32000 (40%)] Loss: 0.88348 (QuantReg: 13.65284) QuantErr: 13.65284 batch_time=0.47948 
Train Epoch: 47 [111/250 14208/32000 (44%)] Loss: 1.01178 (QuantReg: 13.50140) QuantErr: 13.50140 batch_time=0.48755 
Train Epoch: 47 [122/250 15616/32000 (49%)] Loss: 0.86666 (QuantReg: 13.85537) QuantErr: 13.85537 batch_time=0.88019 
Train Epoch: 47 [133/250 17024/32000 (53%)] Loss: 0.83118 (QuantReg: 13.63986) QuantErr: 13.63986 batch_time=0.48501 
Train Epoch: 47 [144/250 18432/32000 (58%)] Loss: 0.85081 (QuantReg: 13.59882) QuantErr: 13.59882 batch_time=0.51154 
Train Epoch: 47 [155/250 19840/32000 (62%)] Loss: 0.76089 (QuantReg: 13.78274) QuantErr: 13.78274 batch_time=0.48916 
Train Epoch: 47 [166/250 21248/32000 (66%)] Loss: 0.84171 (QuantReg: 13.77491) QuantErr: 13.77491 batch_time=0.49544 
Train Epoch: 47 [177/250 22656/32000 (71%)] Loss: 1.05017 (QuantReg: 13.86870) QuantErr: 13.86870 batch_time=0.49907 
Train Epoch: 47 [188/250 24064/32000 (75%)] Loss: 0.75684 (QuantReg: 13.90273) QuantErr: 13.90273 batch_time=0.49129 
Train Epoch: 47 [199/250 25472/32000 (80%)] Loss: 0.79718 (QuantReg: 13.99143) QuantErr: 13.99143 batch_time=2.17661 
Train Epoch: 47 [210/250 26880/32000 (84%)] Loss: 0.65097 (QuantReg: 14.02471) QuantErr: 14.02471 batch_time=0.48525 
Train Epoch: 47 [221/250 28288/32000 (88%)] Loss: 0.68920 (QuantReg: 13.84032) QuantErr: 13.84032 batch_time=0.49469 
Train Epoch: 47 [232/250 29696/32000 (93%)] Loss: 0.61311 (QuantReg: 13.85516) QuantErr: 13.85516 batch_time=0.49779 
Train Epoch: 47 [243/250 31104/32000 (97%)] Loss: 0.76739 (QuantReg: 13.90225) QuantErr: 13.90225 batch_time=0.49025 
Train Epoch: 47 codebook_update_time=1.92261
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_MSRVTT_1kA_roberta-base/checkpoint-epoch47.pth ...
Done in 4.313s
removing stale ckpt [epoch 46] [took 0.00s]
 epoch          : 47
 loss           : 0.7526967715024948
 quant_reg      : 13.808480987548828
 quant_err      : 13.808480987548828
 learning_rate  : 9.446824413773763e-06
 n_samples      : 1504000
 n_steps        : 11750
 MSRVTT_jsfusion_test/t2v_metrics/R1: 25.5
 MSRVTT_jsfusion_test/t2v_metrics/R5: 54.2
 MSRVTT_jsfusion_test/t2v_metrics/R10: 66.6
 MSRVTT_jsfusion_test/t2v_metrics/R50: 89.3
 MSRVTT_jsfusion_test/t2v_metrics/MedR: 5.0
 MSRVTT_jsfusion_test/t2v_metrics/MeanR: 27.181
 MSRVTT_jsfusion_test/t2v_metrics/geometric_mean_R1-R5-R10: 45.15140115517927
 MSRVTT_jsfusion_test/v2t_metrics/R1: 23.1
 MSRVTT_jsfusion_test/v2t_metrics/R5: 54.8
 MSRVTT_jsfusion_test/v2t_metrics/R10: 68.2
 MSRVTT_jsfusion_test/v2t_metrics/R50: 89.6
 MSRVTT_jsfusion_test/v2t_metrics/MedR: 4.0
 MSRVTT_jsfusion_test/v2t_metrics/MeanR: 23.99
 MSRVTT_jsfusion_test/v2t_metrics/geometric_mean_R1-R5-R10: 44.19695043898772
 mnt_best       : 45.560211714800715
 not_improved_count: 3
Train Epoch: 48 [1/250 128/32000 (0%)] Loss: 0.85753 (QuantReg: 13.90436) QuantErr: 13.90436 batch_time=31.33462 
Train Epoch: 48 [12/250 1536/32000 (5%)] Loss: 0.50675 (QuantReg: 13.89925) QuantErr: 13.89925 batch_time=0.52698 
Train Epoch: 48 [23/250 2944/32000 (9%)] Loss: 0.49614 (QuantReg: 13.76835) QuantErr: 13.76835 batch_time=0.47446 
Train Epoch: 48 [34/250 4352/32000 (14%)] Loss: 0.59867 (QuantReg: 14.26493) QuantErr: 14.26493 batch_time=0.49106 
Train Epoch: 48 [45/250 5760/32000 (18%)] Loss: 0.61250 (QuantReg: 13.88452) QuantErr: 13.88452 batch_time=0.48794 
Train Epoch: 48 [56/250 7168/32000 (22%)] Loss: 0.96490 (QuantReg: 13.79999) QuantErr: 13.79999 batch_time=0.49326 
Train Epoch: 48 [67/250 8576/32000 (27%)] Loss: 0.85982 (QuantReg: 13.73912) QuantErr: 13.73912 batch_time=1.99318 
Train Epoch: 48 [78/250 9984/32000 (31%)] Loss: 0.65475 (QuantReg: 13.95627) QuantErr: 13.95627 batch_time=0.52165 
Train Epoch: 48 [89/250 11392/32000 (36%)] Loss: 0.73693 (QuantReg: 13.95269) QuantErr: 13.95269 batch_time=0.47199 
Train Epoch: 48 [100/250 12800/32000 (40%)] Loss: 0.68629 (QuantReg: 13.72853) QuantErr: 13.72853 batch_time=0.48953 
Train Epoch: 48 [111/250 14208/32000 (44%)] Loss: 0.87137 (QuantReg: 13.68446) QuantErr: 13.68446 batch_time=0.48228 
Train Epoch: 48 [122/250 15616/32000 (49%)] Loss: 0.71400 (QuantReg: 13.77946) QuantErr: 13.77946 batch_time=0.48343 
Train Epoch: 48 [133/250 17024/32000 (53%)] Loss: 0.93630 (QuantReg: 13.96167) QuantErr: 13.96167 batch_time=0.50374 
Train Epoch: 48 [144/250 18432/32000 (58%)] Loss: 0.99577 (QuantReg: 13.88580) QuantErr: 13.88580 batch_time=0.48314 
Train Epoch: 48 [155/250 19840/32000 (62%)] Loss: 0.73595 (QuantReg: 13.79403) QuantErr: 13.79403 batch_time=0.47637 
Train Epoch: 48 [166/250 21248/32000 (66%)] Loss: 0.64900 (QuantReg: 13.86545) QuantErr: 13.86545 batch_time=0.48960 
Train Epoch: 48 [177/250 22656/32000 (71%)] Loss: 0.66138 (QuantReg: 13.87721) QuantErr: 13.87721 batch_time=0.49160 
Train Epoch: 48 [188/250 24064/32000 (75%)] Loss: 0.73141 (QuantReg: 13.73277) QuantErr: 13.73277 batch_time=0.49455 
Train Epoch: 48 [199/250 25472/32000 (80%)] Loss: 0.70580 (QuantReg: 13.65620) QuantErr: 13.65620 batch_time=0.48881 
Train Epoch: 48 [210/250 26880/32000 (84%)] Loss: 0.66987 (QuantReg: 13.96980) QuantErr: 13.96980 batch_time=2.70154 
Train Epoch: 48 [221/250 28288/32000 (88%)] Loss: 0.82721 (QuantReg: 13.98894) QuantErr: 13.98894 batch_time=0.47074 
Train Epoch: 48 [232/250 29696/32000 (93%)] Loss: 0.82650 (QuantReg: 13.82945) QuantErr: 13.82945 batch_time=0.49751 
Train Epoch: 48 [243/250 31104/32000 (97%)] Loss: 0.67846 (QuantReg: 13.86231) QuantErr: 13.86231 batch_time=0.47586 
Train Epoch: 48 codebook_update_time=1.57931
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_MSRVTT_1kA_roberta-base/checkpoint-epoch48.pth ...
Done in 4.245s
removing stale ckpt [epoch 47] [took 0.05s]
 epoch          : 48
 loss           : 0.7470782670974732
 quant_reg      : 13.843913955688476
 quant_err      : 13.843913955688476
 learning_rate  : 8.974483193085074e-06
 n_samples      : 1536000
 n_steps        : 12000
 MSRVTT_jsfusion_test/t2v_metrics/R1: 25.2
 MSRVTT_jsfusion_test/t2v_metrics/R5: 54.2
 MSRVTT_jsfusion_test/t2v_metrics/R10: 66.6
 MSRVTT_jsfusion_test/t2v_metrics/R50: 89.4
 MSRVTT_jsfusion_test/t2v_metrics/MedR: 5.0
 MSRVTT_jsfusion_test/t2v_metrics/MeanR: 27.856
 MSRVTT_jsfusion_test/t2v_metrics/geometric_mean_R1-R5-R10: 44.97363789277803
 MSRVTT_jsfusion_test/v2t_metrics/R1: 24.5
 MSRVTT_jsfusion_test/v2t_metrics/R5: 54.8
 MSRVTT_jsfusion_test/v2t_metrics/R10: 67.1
 MSRVTT_jsfusion_test/v2t_metrics/R50: 89.6
 MSRVTT_jsfusion_test/v2t_metrics/MedR: 5.0
 MSRVTT_jsfusion_test/v2t_metrics/MeanR: 24.3725
 MSRVTT_jsfusion_test/v2t_metrics/geometric_mean_R1-R5-R10: 44.82872506757752
 mnt_best       : 45.560211714800715
 not_improved_count: 4
Train Epoch: 49 [1/250 128/32000 (0%)] Loss: 0.83891 (QuantReg: 13.84257) QuantErr: 13.84257 batch_time=31.52726 
Train Epoch: 49 [12/250 1536/32000 (5%)] Loss: 0.85205 (QuantReg: 13.93216) QuantErr: 13.93216 batch_time=0.47489 
Train Epoch: 49 [23/250 2944/32000 (9%)] Loss: 0.79819 (QuantReg: 13.67541) QuantErr: 13.67541 batch_time=1.27918 
Train Epoch: 49 [34/250 4352/32000 (14%)] Loss: 0.72732 (QuantReg: 14.02989) QuantErr: 14.02989 batch_time=0.48349 
Train Epoch: 49 [45/250 5760/32000 (18%)] Loss: 0.62447 (QuantReg: 13.76965) QuantErr: 13.76965 batch_time=0.47546 
Train Epoch: 49 [56/250 7168/32000 (22%)] Loss: 0.87845 (QuantReg: 13.66003) QuantErr: 13.66003 batch_time=0.52395 
Train Epoch: 49 [67/250 8576/32000 (27%)] Loss: 0.73423 (QuantReg: 13.68295) QuantErr: 13.68295 batch_time=0.47081 
Train Epoch: 49 [78/250 9984/32000 (31%)] Loss: 0.56318 (QuantReg: 13.75289) QuantErr: 13.75289 batch_time=0.48180 
Train Epoch: 49 [89/250 11392/32000 (36%)] Loss: 0.70890 (QuantReg: 13.76761) QuantErr: 13.76761 batch_time=0.88953 
Train Epoch: 49 [100/250 12800/32000 (40%)] Loss: 0.64227 (QuantReg: 13.61461) QuantErr: 13.61461 batch_time=0.49347 
Train Epoch: 49 [111/250 14208/32000 (44%)] Loss: 0.62537 (QuantReg: 13.86207) QuantErr: 13.86207 batch_time=0.53537 
Train Epoch: 49 [122/250 15616/32000 (49%)] Loss: 0.73835 (QuantReg: 13.78441) QuantErr: 13.78441 batch_time=0.49100 
Train Epoch: 49 [133/250 17024/32000 (53%)] Loss: 1.03112 (QuantReg: 13.68163) QuantErr: 13.68163 batch_time=0.50125 
Train Epoch: 49 [144/250 18432/32000 (58%)] Loss: 0.61552 (QuantReg: 13.78127) QuantErr: 13.78127 batch_time=0.73660 
Train Epoch: 49 [155/250 19840/32000 (62%)] Loss: 0.67421 (QuantReg: 14.14138) QuantErr: 14.14138 batch_time=0.61042 
Train Epoch: 49 [166/250 21248/32000 (66%)] Loss: 0.66988 (QuantReg: 14.01689) QuantErr: 14.01689 batch_time=0.48378 
Train Epoch: 49 [177/250 22656/32000 (71%)] Loss: 0.77053 (QuantReg: 13.89802) QuantErr: 13.89802 batch_time=0.48407 
Train Epoch: 49 [188/250 24064/32000 (75%)] Loss: 0.56417 (QuantReg: 14.02065) QuantErr: 14.02065 batch_time=0.48588 
Train Epoch: 49 [199/250 25472/32000 (80%)] Loss: 0.84052 (QuantReg: 14.04515) QuantErr: 14.04515 batch_time=0.48851 
Train Epoch: 49 [210/250 26880/32000 (84%)] Loss: 0.83823 (QuantReg: 13.90349) QuantErr: 13.90349 batch_time=0.49407 
Train Epoch: 49 [221/250 28288/32000 (88%)] Loss: 0.87255 (QuantReg: 13.96410) QuantErr: 13.96410 batch_time=0.49061 
Train Epoch: 49 [232/250 29696/32000 (93%)] Loss: 0.81848 (QuantReg: 14.17745) QuantErr: 14.17745 batch_time=0.48695 
Train Epoch: 49 [243/250 31104/32000 (97%)] Loss: 0.67934 (QuantReg: 14.09910) QuantErr: 14.09910 batch_time=0.49052 
Train Epoch: 49 codebook_update_time=1.63301
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_MSRVTT_1kA_roberta-base/checkpoint-epoch49.pth ...
Done in 4.062s
removing stale ckpt [epoch 48] [took 0.00s]
 epoch          : 49
 loss           : 0.7386114770174026
 quant_reg      : 13.834927070617676
 quant_err      : 13.834927070617676
 learning_rate  : 8.52575903343082e-06
 n_samples      : 1568000
 n_steps        : 12250
 MSRVTT_jsfusion_test/t2v_metrics/R1: 25.1
 MSRVTT_jsfusion_test/t2v_metrics/R5: 53.9
 MSRVTT_jsfusion_test/t2v_metrics/R10: 67.3
 MSRVTT_jsfusion_test/t2v_metrics/R50: 88.5
 MSRVTT_jsfusion_test/t2v_metrics/MedR: 5.0
 MSRVTT_jsfusion_test/t2v_metrics/MeanR: 27.235
 MSRVTT_jsfusion_test/t2v_metrics/geometric_mean_R1-R5-R10: 44.98756808845169
 MSRVTT_jsfusion_test/v2t_metrics/R1: 24.3
 MSRVTT_jsfusion_test/v2t_metrics/R5: 53.2
 MSRVTT_jsfusion_test/v2t_metrics/R10: 67.9
 MSRVTT_jsfusion_test/v2t_metrics/R50: 89.3
 MSRVTT_jsfusion_test/v2t_metrics/MedR: 5.0
 MSRVTT_jsfusion_test/v2t_metrics/MeanR: 24.3485
 MSRVTT_jsfusion_test/v2t_metrics/geometric_mean_R1-R5-R10: 44.44223519481383
 mnt_best       : 45.560211714800715
 not_improved_count: 5
Train Epoch: 50 [1/250 128/32000 (0%)] Loss: 0.77107 (QuantReg: 13.92676) QuantErr: 13.92676 batch_time=24.91010 
Train Epoch: 50 [12/250 1536/32000 (5%)] Loss: 0.84403 (QuantReg: 13.88184) QuantErr: 13.88184 batch_time=0.47781 
Train Epoch: 50 [23/250 2944/32000 (9%)] Loss: 0.67043 (QuantReg: 13.98687) QuantErr: 13.98687 batch_time=0.49278 
Train Epoch: 50 [34/250 4352/32000 (14%)] Loss: 0.87335 (QuantReg: 13.64579) QuantErr: 13.64579 batch_time=0.49293 
Train Epoch: 50 [45/250 5760/32000 (18%)] Loss: 0.91588 (QuantReg: 13.57755) QuantErr: 13.57755 batch_time=0.48602 
Train Epoch: 50 [56/250 7168/32000 (22%)] Loss: 0.59398 (QuantReg: 14.01089) QuantErr: 14.01089 batch_time=0.51758 
Train Epoch: 50 [67/250 8576/32000 (27%)] Loss: 0.89561 (QuantReg: 13.85263) QuantErr: 13.85263 batch_time=1.40113 
Train Epoch: 50 [78/250 9984/32000 (31%)] Loss: 0.85282 (QuantReg: 13.87618) QuantErr: 13.87618 batch_time=0.48722 
Train Epoch: 50 [89/250 11392/32000 (36%)] Loss: 0.59847 (QuantReg: 13.73451) QuantErr: 13.73451 batch_time=0.49420 
Train Epoch: 50 [100/250 12800/32000 (40%)] Loss: 0.83057 (QuantReg: 13.87860) QuantErr: 13.87860 batch_time=0.48357 
Train Epoch: 50 [111/250 14208/32000 (44%)] Loss: 0.78781 (QuantReg: 13.78627) QuantErr: 13.78627 batch_time=0.58736 
Train Epoch: 50 [122/250 15616/32000 (49%)] Loss: 0.68063 (QuantReg: 13.98633) QuantErr: 13.98633 batch_time=0.48915 
Train Epoch: 50 [133/250 17024/32000 (53%)] Loss: 0.68626 (QuantReg: 13.86347) QuantErr: 13.86347 batch_time=0.48516 
Train Epoch: 50 [144/250 18432/32000 (58%)] Loss: 0.60505 (QuantReg: 13.75291) QuantErr: 13.75291 batch_time=0.48289 
Train Epoch: 50 [155/250 19840/32000 (62%)] Loss: 0.74362 (QuantReg: 13.85110) QuantErr: 13.85110 batch_time=0.73774 
Train Epoch: 50 [166/250 21248/32000 (66%)] Loss: 0.86403 (QuantReg: 13.93162) QuantErr: 13.93162 batch_time=0.81662 
Train Epoch: 50 [177/250 22656/32000 (71%)] Loss: 0.93147 (QuantReg: 13.76079) QuantErr: 13.76079 batch_time=0.48136 
Train Epoch: 50 [188/250 24064/32000 (75%)] Loss: 0.67836 (QuantReg: 14.00995) QuantErr: 14.00995 batch_time=0.48200 
Train Epoch: 50 [199/250 25472/32000 (80%)] Loss: 0.68019 (QuantReg: 13.85839) QuantErr: 13.85839 batch_time=0.48707 
Train Epoch: 50 [210/250 26880/32000 (84%)] Loss: 0.66574 (QuantReg: 13.80747) QuantErr: 13.80747 batch_time=1.49364 
Train Epoch: 50 [221/250 28288/32000 (88%)] Loss: 0.87047 (QuantReg: 13.71941) QuantErr: 13.71941 batch_time=0.50317 
Train Epoch: 50 [232/250 29696/32000 (93%)] Loss: 0.86832 (QuantReg: 13.62936) QuantErr: 13.62936 batch_time=0.53829 
Train Epoch: 50 [243/250 31104/32000 (97%)] Loss: 0.69644 (QuantReg: 14.01035) QuantErr: 14.01035 batch_time=0.49248 
Train Epoch: 50 codebook_update_time=1.66175
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_MSRVTT_1kA_roberta-base/checkpoint-epoch50.pth ...
Done in 3.928s
removing stale ckpt [epoch 49] [took 0.00s]
 epoch          : 50
 loss           : 0.7363379848003387
 quant_reg      : 13.846760375976562
 quant_err      : 13.846760375976562
 learning_rate  : 8.09947108175928e-06
 n_samples      : 1600000
 n_steps        : 12500
 MSRVTT_jsfusion_test/t2v_metrics/R1: 24.4
 MSRVTT_jsfusion_test/t2v_metrics/R5: 54.0
 MSRVTT_jsfusion_test/t2v_metrics/R10: 66.2
 MSRVTT_jsfusion_test/t2v_metrics/R50: 88.8
 MSRVTT_jsfusion_test/t2v_metrics/MedR: 5.0
 MSRVTT_jsfusion_test/t2v_metrics/MeanR: 26.819
 MSRVTT_jsfusion_test/t2v_metrics/geometric_mean_R1-R5-R10: 44.348662358233575
 MSRVTT_jsfusion_test/v2t_metrics/R1: 23.6
 MSRVTT_jsfusion_test/v2t_metrics/R5: 54.1
 MSRVTT_jsfusion_test/v2t_metrics/R10: 67.9
 MSRVTT_jsfusion_test/v2t_metrics/R50: 89.2
 MSRVTT_jsfusion_test/v2t_metrics/MedR: 5.0
 MSRVTT_jsfusion_test/v2t_metrics/MeanR: 24.522
 MSRVTT_jsfusion_test/v2t_metrics/geometric_mean_R1-R5-R10: 44.25812531268617
 mnt_best       : 45.560211714800715
 not_improved_count: 6
Final evaluation ...
Loading checkpoint from: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_MSRVTT_1kA_roberta-base/trained_model.pth ...
Ckpt loaded at epoch 44.
Saved similarity matrix (quantize videos) to /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_MSRVTT_1kA_roberta-base/MSRVTT-test-qv-sims.npy
Saved v2t similarity matrix (quantize texts) to /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_MSRVTT_1kA_roberta-base/MSRVTT-test-qt-sims.npy
MSRVTT_jsfusion_test:
 t2v_metrics/R1/final_eval: 25.5
 t2v_metrics/R5/final_eval: 54.7
 t2v_metrics/R10/final_eval: 67.8
 t2v_metrics/R50/final_eval: 89.2
 t2v_metrics/MedR/final_eval: 5.0
 t2v_metrics/MeanR/final_eval: 27.035
 t2v_metrics/geometric_mean_R1-R5-R10/final_eval: 45.560211714800715
 v2t_metrics/R1/final_eval: 24.5
 v2t_metrics/R5/final_eval: 55.0
 v2t_metrics/R10/final_eval: 69.0
 v2t_metrics/R50/final_eval: 90.2
 v2t_metrics/MedR/final_eval: 4.0
 v2t_metrics/MeanR/final_eval: 23.8005
 v2t_metrics/geometric_mean_R1-R5-R10/final_eval: 45.30289491218929
Best epoch for the monitored metric: 44
Script took 03h09m08s
The best performing ckpt can be found at /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_MSRVTT_1kA_roberta-base/trained_model.pth
