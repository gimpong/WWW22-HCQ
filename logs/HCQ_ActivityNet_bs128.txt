Experiment directory: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_ActivityNet_bs128
Preparing the dataloaders ...
Loading dataset ActivityNet_val1_trainval in ram ...
Finish loading dataset ActivityNet_val1_trainval in ram, taking 632.6719100475311 s.
Loading dataset ActivityNet_val1_test in ram ...
Finish loading dataset ActivityNet_val1_test in ram, taking 247.49860501289368 s.
Loading dataset ActivityNet_val1_test in ram ...
Finish loading dataset ActivityNet_val1_test in ram, taking 121.92634558677673 s.
Training ...
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_ActivityNet_bs128/checkpoint-epoch0.pth ...
Done in 4.065s
Updating 'best' checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_ActivityNet_bs128/checkpoint-epoch0.pth ...
Done in 5.472s
 epoch          : 0
 loss           : 0
 learning_rate  : 5e-05
 n_samples      : 0
 n_steps        : 0
 ActivityNet_val1_test/t2v_metrics/R1: 0.04067520846044336
 ActivityNet_val1_test/t2v_metrics/R5: 0.18303843807199513
 ActivityNet_val1_test/t2v_metrics/R10: 0.24405125076266015
 ActivityNet_val1_test/t2v_metrics/R50: 0.9558673988204189
 ActivityNet_val1_test/t2v_metrics/MedR: 2484.0
 ActivityNet_val1_test/t2v_metrics/MeanR: 2488.6077893024203
 ActivityNet_val1_test/t2v_metrics/geometric_mean_R1-R5-R10: 0.12202562538133006
 ActivityNet_val1_test/v2t_metrics/R1: 0.04067520846044336
 ActivityNet_val1_test/v2t_metrics/R5: 0.1016880211511084
 ActivityNet_val1_test/v2t_metrics/R10: 0.22371364653243847
 ActivityNet_val1_test/v2t_metrics/R50: 0.9151921903599756
 ActivityNet_val1_test/v2t_metrics/MedR: 2511.0
 ActivityNet_val1_test/v2t_metrics/MeanR: 2492.4876957494407
 ActivityNet_val1_test/v2t_metrics/geometric_mean_R1-R5-R10: 0.09744600075376822
 mnt_best       : 0.12202562538133006
 not_improved_count: 0
Train Epoch: 1 [1/250 128/32000 (0%)] Loss: 9.86133 (QuantReg: 22.40812) QuantErr: 22.40812 batch_time=25.64044 
Train Epoch: 1 [12/250 1536/32000 (5%)] Loss: 8.70169 (QuantReg: 22.50962) QuantErr: 22.50962 batch_time=0.67414 
Train Epoch: 1 [23/250 2944/32000 (9%)] Loss: 6.70137 (QuantReg: 22.63057) QuantErr: 22.63057 batch_time=0.66981 
Train Epoch: 1 [34/250 4352/32000 (14%)] Loss: 5.03630 (QuantReg: 22.70709) QuantErr: 22.70709 batch_time=0.64778 
Train Epoch: 1 [45/250 5760/32000 (18%)] Loss: 4.17119 (QuantReg: 22.67682) QuantErr: 22.67682 batch_time=0.64939 
Train Epoch: 1 [56/250 7168/32000 (22%)] Loss: 3.20043 (QuantReg: 22.70436) QuantErr: 22.70436 batch_time=0.64543 
Train Epoch: 1 [67/250 8576/32000 (27%)] Loss: 3.14136 (QuantReg: 22.69837) QuantErr: 22.69837 batch_time=0.64444 
Train Epoch: 1 [78/250 9984/32000 (31%)] Loss: 2.64793 (QuantReg: 22.67697) QuantErr: 22.67697 batch_time=0.64670 
Train Epoch: 1 [89/250 11392/32000 (36%)] Loss: 2.33770 (QuantReg: 22.68045) QuantErr: 22.68045 batch_time=0.64766 
Train Epoch: 1 [100/250 12800/32000 (40%)] Loss: 2.19518 (QuantReg: 22.68900) QuantErr: 22.68900 batch_time=0.65009 
Train Epoch: 1 [111/250 14208/32000 (44%)] Loss: 1.91724 (QuantReg: 22.69458) QuantErr: 22.69458 batch_time=0.66993 
Train Epoch: 1 [122/250 15616/32000 (49%)] Loss: 2.02643 (QuantReg: 22.70510) QuantErr: 22.70510 batch_time=0.65584 
Train Epoch: 1 [133/250 17024/32000 (53%)] Loss: 2.08646 (QuantReg: 22.69926) QuantErr: 22.69926 batch_time=0.65366 
Train Epoch: 1 [144/250 18432/32000 (58%)] Loss: 1.62319 (QuantReg: 22.69029) QuantErr: 22.69029 batch_time=0.65103 
Train Epoch: 1 [155/250 19840/32000 (62%)] Loss: 1.71684 (QuantReg: 22.68892) QuantErr: 22.68892 batch_time=0.66234 
Train Epoch: 1 [166/250 21248/32000 (66%)] Loss: 1.69842 (QuantReg: 22.66619) QuantErr: 22.66619 batch_time=0.65726 
Train Epoch: 1 [177/250 22656/32000 (71%)] Loss: 1.45012 (QuantReg: 22.66401) QuantErr: 22.66401 batch_time=0.65079 
Train Epoch: 1 [188/250 24064/32000 (75%)] Loss: 1.72999 (QuantReg: 22.65899) QuantErr: 22.65899 batch_time=0.64874 
Train Epoch: 1 [199/250 25472/32000 (80%)] Loss: 1.57557 (QuantReg: 22.64421) QuantErr: 22.64421 batch_time=0.95710 
Train Epoch: 1 [210/250 26880/32000 (84%)] Loss: 1.33979 (QuantReg: 22.68754) QuantErr: 22.68754 batch_time=0.64471 
Train Epoch: 1 [221/250 28288/32000 (88%)] Loss: 1.13284 (QuantReg: 22.69653) QuantErr: 22.69653 batch_time=0.65480 
Train Epoch: 1 [232/250 29696/32000 (93%)] Loss: 1.11405 (QuantReg: 22.66403) QuantErr: 22.66403 batch_time=0.64806 
Train Epoch: 1 [243/250 31104/32000 (97%)] Loss: 1.17348 (QuantReg: 22.66912) QuantErr: 22.66912 batch_time=0.65051 
Train Epoch: 1 codebook_update_time=2.26754
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_ActivityNet_bs128/checkpoint-epoch1.pth ...
Done in 6.425s
Updating 'best' checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_ActivityNet_bs128/checkpoint-epoch1.pth ...
Done in 10.262s
 epoch          : 1
 loss           : 2.8291447224617006
 quant_reg      : 22.663669891357422
 quant_err      : 22.663669891357422
 learning_rate  : 5e-05
 n_samples      : 32000
 n_steps        : 250
 ActivityNet_val1_test/t2v_metrics/R1: 10.51454138702461
 ActivityNet_val1_test/t2v_metrics/R5: 33.272320520642666
 ActivityNet_val1_test/t2v_metrics/R10: 49.25767744559691
 ActivityNet_val1_test/t2v_metrics/R50: 85.76367703884482
 ActivityNet_val1_test/t2v_metrics/MedR: 11.0
 ActivityNet_val1_test/t2v_metrics/MeanR: 34.624161073825505
 ActivityNet_val1_test/t2v_metrics/geometric_mean_R1-R5-R10: 25.829487281219194
 ActivityNet_val1_test/v2t_metrics/R1: 12.670327435428106
 ActivityNet_val1_test/v2t_metrics/R5: 35.81452104942038
 ActivityNet_val1_test/v2t_metrics/R10: 50.96603620093553
 ActivityNet_val1_test/v2t_metrics/R50: 87.12629652226968
 ActivityNet_val1_test/v2t_metrics/MedR: 10.0
 ActivityNet_val1_test/v2t_metrics/MeanR: 33.17144600366077
 ActivityNet_val1_test/v2t_metrics/geometric_mean_R1-R5-R10: 28.491104226739452
 mnt_best       : 25.829487281219194
 not_improved_count: 0
Train Epoch: 2 [1/250 128/32000 (0%)] Loss: 1.26277 (QuantReg: 12.07542) QuantErr: 12.07542 batch_time=28.18180 
Train Epoch: 2 [12/250 1536/32000 (5%)] Loss: 1.05394 (QuantReg: 11.82825) QuantErr: 11.82825 batch_time=0.68909 
Train Epoch: 2 [23/250 2944/32000 (9%)] Loss: 0.92753 (QuantReg: 12.15348) QuantErr: 12.15348 batch_time=0.69392 
Train Epoch: 2 [34/250 4352/32000 (14%)] Loss: 1.02575 (QuantReg: 11.85568) QuantErr: 11.85568 batch_time=0.63482 
Train Epoch: 2 [45/250 5760/32000 (18%)] Loss: 0.94570 (QuantReg: 12.05942) QuantErr: 12.05942 batch_time=0.64486 
Train Epoch: 2 [56/250 7168/32000 (22%)] Loss: 0.98588 (QuantReg: 12.44884) QuantErr: 12.44884 batch_time=0.64232 
Train Epoch: 2 [67/250 8576/32000 (27%)] Loss: 1.07973 (QuantReg: 12.22546) QuantErr: 12.22546 batch_time=0.64170 
Train Epoch: 2 [78/250 9984/32000 (31%)] Loss: 1.07099 (QuantReg: 12.24922) QuantErr: 12.24922 batch_time=0.63859 
Train Epoch: 2 [89/250 11392/32000 (36%)] Loss: 0.89759 (QuantReg: 12.14025) QuantErr: 12.14025 batch_time=0.67049 
Train Epoch: 2 [100/250 12800/32000 (40%)] Loss: 0.80837 (QuantReg: 12.60327) QuantErr: 12.60327 batch_time=0.64313 
Train Epoch: 2 [111/250 14208/32000 (44%)] Loss: 0.81544 (QuantReg: 12.60614) QuantErr: 12.60614 batch_time=0.64876 
Train Epoch: 2 [122/250 15616/32000 (49%)] Loss: 0.97419 (QuantReg: 12.44439) QuantErr: 12.44439 batch_time=0.67584 
Train Epoch: 2 [133/250 17024/32000 (53%)] Loss: 0.85251 (QuantReg: 12.67172) QuantErr: 12.67172 batch_time=0.65811 
Train Epoch: 2 [144/250 18432/32000 (58%)] Loss: 0.99064 (QuantReg: 12.92047) QuantErr: 12.92047 batch_time=0.66034 
Train Epoch: 2 [155/250 19840/32000 (62%)] Loss: 0.84417 (QuantReg: 12.89269) QuantErr: 12.89269 batch_time=0.64940 
Train Epoch: 2 [166/250 21248/32000 (66%)] Loss: 0.74639 (QuantReg: 12.88044) QuantErr: 12.88044 batch_time=0.66719 
Train Epoch: 2 [177/250 22656/32000 (71%)] Loss: 0.76289 (QuantReg: 13.00110) QuantErr: 13.00110 batch_time=0.64327 
Train Epoch: 2 [188/250 24064/32000 (75%)] Loss: 0.68438 (QuantReg: 12.89093) QuantErr: 12.89093 batch_time=0.65601 
Train Epoch: 2 [199/250 25472/32000 (80%)] Loss: 0.58440 (QuantReg: 12.89680) QuantErr: 12.89680 batch_time=1.24785 
Train Epoch: 2 [210/250 26880/32000 (84%)] Loss: 0.56219 (QuantReg: 13.12439) QuantErr: 13.12439 batch_time=0.67302 
Train Epoch: 2 [221/250 28288/32000 (88%)] Loss: 0.73104 (QuantReg: 12.83913) QuantErr: 12.83913 batch_time=0.64764 
Train Epoch: 2 [232/250 29696/32000 (93%)] Loss: 0.63786 (QuantReg: 13.16199) QuantErr: 13.16199 batch_time=0.65071 
Train Epoch: 2 [243/250 31104/32000 (97%)] Loss: 0.69660 (QuantReg: 13.38215) QuantErr: 13.38215 batch_time=0.67959 
Train Epoch: 2 codebook_update_time=1.78371
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_ActivityNet_bs128/checkpoint-epoch2.pth ...
Done in 3.997s
Updating 'best' checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_ActivityNet_bs128/checkpoint-epoch2.pth ...
Done in 7.959s
removing stale ckpt [epoch 1] [took 0.01s]
removing stale ckpt [epoch 0] [took 0.01s]
 epoch          : 2
 loss           : 0.8595910174846649
 quant_reg      : 12.590146812438965
 quant_err      : 12.590146812438965
 learning_rate  : 5e-05
 n_samples      : 64000
 n_steps        : 500
 ActivityNet_val1_test/t2v_metrics/R1: 12.466951393125889
 ActivityNet_val1_test/t2v_metrics/R5: 37.27882855399634
 ActivityNet_val1_test/t2v_metrics/R10: 53.65059995932479
 ActivityNet_val1_test/t2v_metrics/R50: 89.32275777913362
 ActivityNet_val1_test/t2v_metrics/MedR: 9.0
 ActivityNet_val1_test/t2v_metrics/MeanR: 29.076876143990237
 ActivityNet_val1_test/t2v_metrics/geometric_mean_R1-R5-R10: 29.214538842551203
 ActivityNet_val1_test/v2t_metrics/R1: 13.971934106162294
 ActivityNet_val1_test/v2t_metrics/R5: 39.35326418547895
 ActivityNet_val1_test/v2t_metrics/R10: 56.49786455155583
 ActivityNet_val1_test/v2t_metrics/R50: 90.35997559487492
 ActivityNet_val1_test/v2t_metrics/MedR: 8.0
 ActivityNet_val1_test/v2t_metrics/MeanR: 27.75859263778727
 ActivityNet_val1_test/v2t_metrics/geometric_mean_R1-R5-R10: 31.43569798235668
 mnt_best       : 29.214538842551203
 not_improved_count: 0
Train Epoch: 3 [1/250 128/32000 (0%)] Loss: 0.79840 (QuantReg: 10.64189) QuantErr: 10.64189 batch_time=26.46939 
Train Epoch: 3 [12/250 1536/32000 (5%)] Loss: 0.61587 (QuantReg: 11.22693) QuantErr: 11.22693 batch_time=0.64797 
Train Epoch: 3 [23/250 2944/32000 (9%)] Loss: 0.57006 (QuantReg: 10.84987) QuantErr: 10.84987 batch_time=0.65293 
Train Epoch: 3 [34/250 4352/32000 (14%)] Loss: 0.61525 (QuantReg: 10.83387) QuantErr: 10.83387 batch_time=0.69308 
Train Epoch: 3 [45/250 5760/32000 (18%)] Loss: 0.62599 (QuantReg: 10.76262) QuantErr: 10.76262 batch_time=0.66666 
Train Epoch: 3 [56/250 7168/32000 (22%)] Loss: 0.60638 (QuantReg: 10.41826) QuantErr: 10.41826 batch_time=0.64927 
Train Epoch: 3 [67/250 8576/32000 (27%)] Loss: 0.50063 (QuantReg: 10.83335) QuantErr: 10.83335 batch_time=0.64289 
Train Epoch: 3 [78/250 9984/32000 (31%)] Loss: 0.53655 (QuantReg: 10.74238) QuantErr: 10.74238 batch_time=0.64431 
Train Epoch: 3 [89/250 11392/32000 (36%)] Loss: 0.62439 (QuantReg: 10.76291) QuantErr: 10.76291 batch_time=0.64385 
Train Epoch: 3 [100/250 12800/32000 (40%)] Loss: 0.57050 (QuantReg: 11.11535) QuantErr: 11.11535 batch_time=0.66078 
Train Epoch: 3 [111/250 14208/32000 (44%)] Loss: 0.56590 (QuantReg: 10.83972) QuantErr: 10.83972 batch_time=0.65019 
Train Epoch: 3 [122/250 15616/32000 (49%)] Loss: 0.60695 (QuantReg: 11.02952) QuantErr: 11.02952 batch_time=0.64769 
Train Epoch: 3 [133/250 17024/32000 (53%)] Loss: 0.56641 (QuantReg: 11.14981) QuantErr: 11.14981 batch_time=6.35427 
Train Epoch: 3 [144/250 18432/32000 (58%)] Loss: 0.46224 (QuantReg: 11.58760) QuantErr: 11.58760 batch_time=0.65448 
Train Epoch: 3 [155/250 19840/32000 (62%)] Loss: 0.49089 (QuantReg: 11.30477) QuantErr: 11.30477 batch_time=0.66432 
Train Epoch: 3 [166/250 21248/32000 (66%)] Loss: 0.56007 (QuantReg: 11.07203) QuantErr: 11.07203 batch_time=0.64053 
Train Epoch: 3 [177/250 22656/32000 (71%)] Loss: 0.50887 (QuantReg: 11.19533) QuantErr: 11.19533 batch_time=0.64936 
Train Epoch: 3 [188/250 24064/32000 (75%)] Loss: 0.51533 (QuantReg: 10.79175) QuantErr: 10.79175 batch_time=0.64657 
Train Epoch: 3 [199/250 25472/32000 (80%)] Loss: 0.44646 (QuantReg: 11.37865) QuantErr: 11.37865 batch_time=0.65227 
Train Epoch: 3 [210/250 26880/32000 (84%)] Loss: 0.46518 (QuantReg: 11.29146) QuantErr: 11.29146 batch_time=0.63919 
Train Epoch: 3 [221/250 28288/32000 (88%)] Loss: 0.44970 (QuantReg: 11.39111) QuantErr: 11.39111 batch_time=0.66001 
Train Epoch: 3 [232/250 29696/32000 (93%)] Loss: 0.43778 (QuantReg: 11.46351) QuantErr: 11.46351 batch_time=0.64340 
Train Epoch: 3 [243/250 31104/32000 (97%)] Loss: 0.40081 (QuantReg: 11.12813) QuantErr: 11.12813 batch_time=0.64844 
Train Epoch: 3 codebook_update_time=1.80891
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_ActivityNet_bs128/checkpoint-epoch3.pth ...
Done in 3.773s
Updating 'best' checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_ActivityNet_bs128/checkpoint-epoch3.pth ...
Done in 7.530s
removing stale ckpt [epoch 2] [took 0.00s]
 epoch          : 3
 loss           : 0.5574689654111862
 quant_reg      : 11.020709091186523
 quant_err      : 11.020709091186523
 learning_rate  : 4.25e-05
 n_samples      : 96000
 n_steps        : 750
 ActivityNet_val1_test/t2v_metrics/R1: 13.91092129347163
 ActivityNet_val1_test/t2v_metrics/R5: 40.044742729306485
 ActivityNet_val1_test/t2v_metrics/R10: 57.189343095383364
 ActivityNet_val1_test/t2v_metrics/R50: 90.82774049217002
 ActivityNet_val1_test/t2v_metrics/MedR: 8.0
 ActivityNet_val1_test/t2v_metrics/MeanR: 26.956579214968478
 ActivityNet_val1_test/t2v_metrics/geometric_mean_R1-R5-R10: 31.700942161997556
 ActivityNet_val1_test/v2t_metrics/R1: 15.334553589587147
 ActivityNet_val1_test/v2t_metrics/R5: 40.98027252389669
 ActivityNet_val1_test/v2t_metrics/R10: 58.08419768151312
 ActivityNet_val1_test/v2t_metrics/R50: 90.78706528370958
 ActivityNet_val1_test/v2t_metrics/MedR: 8.0
 ActivityNet_val1_test/v2t_metrics/MeanR: 26.170225747406956
 ActivityNet_val1_test/v2t_metrics/geometric_mean_R1-R5-R10: 33.17172004951286
 mnt_best       : 31.700942161997556
 not_improved_count: 0
Train Epoch: 4 [1/250 128/32000 (0%)] Loss: 0.43232 (QuantReg: 10.62519) QuantErr: 10.62519 batch_time=25.25426 
Train Epoch: 4 [12/250 1536/32000 (5%)] Loss: 0.37508 (QuantReg: 10.44307) QuantErr: 10.44307 batch_time=0.65011 
Train Epoch: 4 [23/250 2944/32000 (9%)] Loss: 0.46402 (QuantReg: 10.42327) QuantErr: 10.42327 batch_time=0.65018 
Train Epoch: 4 [34/250 4352/32000 (14%)] Loss: 0.48230 (QuantReg: 10.39592) QuantErr: 10.39592 batch_time=0.84728 
Train Epoch: 4 [45/250 5760/32000 (18%)] Loss: 0.39609 (QuantReg: 10.34249) QuantErr: 10.34249 batch_time=0.64858 
Train Epoch: 4 [56/250 7168/32000 (22%)] Loss: 0.39161 (QuantReg: 10.40416) QuantErr: 10.40416 batch_time=0.64212 
Train Epoch: 4 [67/250 8576/32000 (27%)] Loss: 0.44245 (QuantReg: 10.44605) QuantErr: 10.44605 batch_time=0.64170 
Train Epoch: 4 [78/250 9984/32000 (31%)] Loss: 0.55722 (QuantReg: 10.60080) QuantErr: 10.60080 batch_time=0.77546 
Train Epoch: 4 [89/250 11392/32000 (36%)] Loss: 0.34728 (QuantReg: 10.74629) QuantErr: 10.74629 batch_time=0.65227 
Train Epoch: 4 [100/250 12800/32000 (40%)] Loss: 0.39124 (QuantReg: 10.87798) QuantErr: 10.87798 batch_time=0.64453 
Train Epoch: 4 [111/250 14208/32000 (44%)] Loss: 0.39272 (QuantReg: 10.92550) QuantErr: 10.92550 batch_time=0.65245 
Train Epoch: 4 [122/250 15616/32000 (49%)] Loss: 0.49167 (QuantReg: 10.75740) QuantErr: 10.75740 batch_time=0.64907 
Train Epoch: 4 [133/250 17024/32000 (53%)] Loss: 0.35767 (QuantReg: 11.17390) QuantErr: 11.17390 batch_time=0.64221 
Train Epoch: 4 [144/250 18432/32000 (58%)] Loss: 0.44120 (QuantReg: 10.73508) QuantErr: 10.73508 batch_time=5.38336 
Train Epoch: 4 [155/250 19840/32000 (62%)] Loss: 0.41551 (QuantReg: 10.78856) QuantErr: 10.78856 batch_time=0.65696 
Train Epoch: 4 [166/250 21248/32000 (66%)] Loss: 0.38478 (QuantReg: 11.26255) QuantErr: 11.26255 batch_time=0.64619 
Train Epoch: 4 [177/250 22656/32000 (71%)] Loss: 0.40578 (QuantReg: 11.01624) QuantErr: 11.01624 batch_time=0.65806 
Train Epoch: 4 [188/250 24064/32000 (75%)] Loss: 0.27030 (QuantReg: 11.08467) QuantErr: 11.08467 batch_time=0.65531 
Train Epoch: 4 [199/250 25472/32000 (80%)] Loss: 0.39522 (QuantReg: 10.67382) QuantErr: 10.67382 batch_time=0.63947 
Train Epoch: 4 [210/250 26880/32000 (84%)] Loss: 0.41277 (QuantReg: 11.10534) QuantErr: 11.10534 batch_time=0.83802 
Train Epoch: 4 [221/250 28288/32000 (88%)] Loss: 0.41477 (QuantReg: 10.81035) QuantErr: 10.81035 batch_time=0.64765 
Train Epoch: 4 [232/250 29696/32000 (93%)] Loss: 0.35054 (QuantReg: 11.08756) QuantErr: 11.08756 batch_time=0.64078 
Train Epoch: 4 [243/250 31104/32000 (97%)] Loss: 0.45928 (QuantReg: 10.78584) QuantErr: 10.78584 batch_time=0.64121 
Train Epoch: 4 codebook_update_time=2.18522
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_ActivityNet_bs128/checkpoint-epoch4.pth ...
Done in 4.064s
Updating 'best' checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_ActivityNet_bs128/checkpoint-epoch4.pth ...
Done in 7.971s
removing stale ckpt [epoch 3] [took 0.00s]
 epoch          : 4
 loss           : 0.41555819773674013
 quant_reg      : 10.778521152496339
 quant_err      : 10.778521152496339
 learning_rate  : 4.25e-05
 n_samples      : 128000
 n_steps        : 1000
 ActivityNet_val1_test/t2v_metrics/R1: 14.134634940004068
 ActivityNet_val1_test/t2v_metrics/R5: 41.04128533658735
 ActivityNet_val1_test/t2v_metrics/R10: 57.779133618059795
 ActivityNet_val1_test/t2v_metrics/R50: 91.21415497254424
 ActivityNet_val1_test/t2v_metrics/MedR: 8.0
 ActivityNet_val1_test/t2v_metrics/MeanR: 27.258490949766117
 ActivityNet_val1_test/t2v_metrics/geometric_mean_R1-R5-R10: 32.24226366217791
 ActivityNet_val1_test/v2t_metrics/R1: 15.659955257270694
 ActivityNet_val1_test/v2t_metrics/R5: 42.261541590400654
 ActivityNet_val1_test/v2t_metrics/R10: 59.99593247915396
 ActivityNet_val1_test/v2t_metrics/R50: 91.58023184868823
 ActivityNet_val1_test/v2t_metrics/MedR: 7.0
 ActivityNet_val1_test/v2t_metrics/MeanR: 25.550945698596706
 ActivityNet_val1_test/v2t_metrics/geometric_mean_R1-R5-R10: 34.11556382061522
 mnt_best       : 32.24226366217791
 not_improved_count: 0
Train Epoch: 5 [1/250 128/32000 (0%)] Loss: 0.30199 (QuantReg: 10.68278) QuantErr: 10.68278 batch_time=20.90157 
Train Epoch: 5 [12/250 1536/32000 (5%)] Loss: 0.30570 (QuantReg: 10.81147) QuantErr: 10.81147 batch_time=0.66451 
Train Epoch: 5 [23/250 2944/32000 (9%)] Loss: 0.30977 (QuantReg: 10.61954) QuantErr: 10.61954 batch_time=0.64131 
Train Epoch: 5 [34/250 4352/32000 (14%)] Loss: 0.44453 (QuantReg: 10.64198) QuantErr: 10.64198 batch_time=0.98888 
Train Epoch: 5 [45/250 5760/32000 (18%)] Loss: 0.36817 (QuantReg: 10.68812) QuantErr: 10.68812 batch_time=0.64454 
Train Epoch: 5 [56/250 7168/32000 (22%)] Loss: 0.32842 (QuantReg: 10.73813) QuantErr: 10.73813 batch_time=0.64652 
Train Epoch: 5 [67/250 8576/32000 (27%)] Loss: 0.33464 (QuantReg: 10.84562) QuantErr: 10.84562 batch_time=1.95640 
Train Epoch: 5 [78/250 9984/32000 (31%)] Loss: 0.37644 (QuantReg: 10.68724) QuantErr: 10.68724 batch_time=0.65009 
Train Epoch: 5 [89/250 11392/32000 (36%)] Loss: 0.32725 (QuantReg: 10.60026) QuantErr: 10.60026 batch_time=0.64105 
Train Epoch: 5 [100/250 12800/32000 (40%)] Loss: 0.34655 (QuantReg: 10.73516) QuantErr: 10.73516 batch_time=0.65553 
Train Epoch: 5 [111/250 14208/32000 (44%)] Loss: 0.39646 (QuantReg: 10.84473) QuantErr: 10.84473 batch_time=0.70335 
Train Epoch: 5 [122/250 15616/32000 (49%)] Loss: 0.29523 (QuantReg: 10.92056) QuantErr: 10.92056 batch_time=0.68025 
Train Epoch: 5 [133/250 17024/32000 (53%)] Loss: 0.26595 (QuantReg: 10.60654) QuantErr: 10.60654 batch_time=1.46403 
Train Epoch: 5 [144/250 18432/32000 (58%)] Loss: 0.28061 (QuantReg: 10.41490) QuantErr: 10.41490 batch_time=2.33779 
Train Epoch: 5 [155/250 19840/32000 (62%)] Loss: 0.30912 (QuantReg: 10.88607) QuantErr: 10.88607 batch_time=0.64181 
Train Epoch: 5 [166/250 21248/32000 (66%)] Loss: 0.33144 (QuantReg: 10.93570) QuantErr: 10.93570 batch_time=1.11199 
Train Epoch: 5 [177/250 22656/32000 (71%)] Loss: 0.30662 (QuantReg: 10.79770) QuantErr: 10.79770 batch_time=0.66175 
Train Epoch: 5 [188/250 24064/32000 (75%)] Loss: 0.30640 (QuantReg: 10.78586) QuantErr: 10.78586 batch_time=0.64394 
Train Epoch: 5 [199/250 25472/32000 (80%)] Loss: 0.28345 (QuantReg: 11.02093) QuantErr: 11.02093 batch_time=1.57414 
Train Epoch: 5 [210/250 26880/32000 (84%)] Loss: 0.24664 (QuantReg: 10.97987) QuantErr: 10.97987 batch_time=0.64367 
Train Epoch: 5 [221/250 28288/32000 (88%)] Loss: 0.30425 (QuantReg: 10.96988) QuantErr: 10.96988 batch_time=0.63877 
Train Epoch: 5 [232/250 29696/32000 (93%)] Loss: 0.24305 (QuantReg: 10.93338) QuantErr: 10.93338 batch_time=0.65091 
Train Epoch: 5 [243/250 31104/32000 (97%)] Loss: 0.26338 (QuantReg: 10.85322) QuantErr: 10.85322 batch_time=0.66906 
Train Epoch: 5 codebook_update_time=1.76750
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_ActivityNet_bs128/checkpoint-epoch5.pth ...
Done in 3.954s
Updating 'best' checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_ActivityNet_bs128/checkpoint-epoch5.pth ...
Done in 7.825s
removing stale ckpt [epoch 4] [took 0.01s]
 epoch          : 5
 loss           : 0.3285088377594948
 quant_reg      : 10.775203769683838
 quant_err      : 10.775203769683838
 learning_rate  : 3.6125000000000004e-05
 n_samples      : 160000
 n_steps        : 1250
 ActivityNet_val1_test/t2v_metrics/R1: 15.395566402277812
 ActivityNet_val1_test/t2v_metrics/R5: 41.976815131177545
 ActivityNet_val1_test/t2v_metrics/R10: 58.73500101688021
 ActivityNet_val1_test/t2v_metrics/R50: 90.94976611755135
 ActivityNet_val1_test/t2v_metrics/MedR: 8.0
 ActivityNet_val1_test/t2v_metrics/MeanR: 27.22106975798251
 ActivityNet_val1_test/t2v_metrics/geometric_mean_R1-R5-R10: 33.60733271058537
 ActivityNet_val1_test/v2t_metrics/R1: 15.151515151515152
 ActivityNet_val1_test/v2t_metrics/R5: 42.50559284116331
 ActivityNet_val1_test/v2t_metrics/R10: 60.52471018913972
 ActivityNet_val1_test/v2t_metrics/R50: 91.80394549522066
 ActivityNet_val1_test/v2t_metrics/MedR: 7.0
 ActivityNet_val1_test/v2t_metrics/MeanR: 25.453731950376245
 ActivityNet_val1_test/v2t_metrics/geometric_mean_R1-R5-R10: 33.906135007095614
 mnt_best       : 33.60733271058537
 not_improved_count: 0
Train Epoch: 6 [1/250 128/32000 (0%)] Loss: 0.38843 (QuantReg: 10.68040) QuantErr: 10.68040 batch_time=23.57521 
Train Epoch: 6 [12/250 1536/32000 (5%)] Loss: 0.25647 (QuantReg: 10.88374) QuantErr: 10.88374 batch_time=0.73616 
Train Epoch: 6 [23/250 2944/32000 (9%)] Loss: 0.30235 (QuantReg: 10.81501) QuantErr: 10.81501 batch_time=0.92176 
Train Epoch: 6 [34/250 4352/32000 (14%)] Loss: 0.32118 (QuantReg: 10.32021) QuantErr: 10.32021 batch_time=0.64599 
Train Epoch: 6 [45/250 5760/32000 (18%)] Loss: 0.27893 (QuantReg: 10.75209) QuantErr: 10.75209 batch_time=0.64730 
Train Epoch: 6 [56/250 7168/32000 (22%)] Loss: 0.33599 (QuantReg: 10.71778) QuantErr: 10.71778 batch_time=0.81387 
Train Epoch: 6 [67/250 8576/32000 (27%)] Loss: 0.27137 (QuantReg: 10.69643) QuantErr: 10.69643 batch_time=0.81934 
Train Epoch: 6 [78/250 9984/32000 (31%)] Loss: 0.35389 (QuantReg: 10.91389) QuantErr: 10.91389 batch_time=0.65705 
Train Epoch: 6 [89/250 11392/32000 (36%)] Loss: 0.31815 (QuantReg: 10.80056) QuantErr: 10.80056 batch_time=0.65238 
Train Epoch: 6 [100/250 12800/32000 (40%)] Loss: 0.26736 (QuantReg: 11.06353) QuantErr: 11.06353 batch_time=0.70854 
Train Epoch: 6 [111/250 14208/32000 (44%)] Loss: 0.22190 (QuantReg: 10.85609) QuantErr: 10.85609 batch_time=0.64976 
Train Epoch: 6 [122/250 15616/32000 (49%)] Loss: 0.28935 (QuantReg: 10.70486) QuantErr: 10.70486 batch_time=0.64283 
Train Epoch: 6 [133/250 17024/32000 (53%)] Loss: 0.28896 (QuantReg: 10.81706) QuantErr: 10.81706 batch_time=0.63972 
Train Epoch: 6 [144/250 18432/32000 (58%)] Loss: 0.25153 (QuantReg: 10.69076) QuantErr: 10.69076 batch_time=0.68715 
Train Epoch: 6 [155/250 19840/32000 (62%)] Loss: 0.21526 (QuantReg: 10.85252) QuantErr: 10.85252 batch_time=1.42898 
Train Epoch: 6 [166/250 21248/32000 (66%)] Loss: 0.31394 (QuantReg: 10.64979) QuantErr: 10.64979 batch_time=0.65426 
Train Epoch: 6 [177/250 22656/32000 (71%)] Loss: 0.25826 (QuantReg: 10.97348) QuantErr: 10.97348 batch_time=0.64921 
Train Epoch: 6 [188/250 24064/32000 (75%)] Loss: 0.27156 (QuantReg: 11.05665) QuantErr: 11.05665 batch_time=0.64686 
Train Epoch: 6 [199/250 25472/32000 (80%)] Loss: 0.24975 (QuantReg: 10.76671) QuantErr: 10.76671 batch_time=0.64324 
Train Epoch: 6 [210/250 26880/32000 (84%)] Loss: 0.31362 (QuantReg: 11.02974) QuantErr: 11.02974 batch_time=0.65757 
Train Epoch: 6 [221/250 28288/32000 (88%)] Loss: 0.21315 (QuantReg: 10.87427) QuantErr: 10.87427 batch_time=0.64795 
Train Epoch: 6 [232/250 29696/32000 (93%)] Loss: 0.21610 (QuantReg: 10.98182) QuantErr: 10.98182 batch_time=0.64364 
Train Epoch: 6 [243/250 31104/32000 (97%)] Loss: 0.25352 (QuantReg: 10.77214) QuantErr: 10.77214 batch_time=0.64421 
Train Epoch: 6 codebook_update_time=1.93863
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_ActivityNet_bs128/checkpoint-epoch6.pth ...
Done in 15.099s
Updating 'best' checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_ActivityNet_bs128/checkpoint-epoch6.pth ...
Done in 18.908s
removing stale ckpt [epoch 5] [took 0.01s]
 epoch          : 6
 loss           : 0.28429930919408797
 quant_reg      : 10.763820152282715
 quant_err      : 10.763820152282715
 learning_rate  : 3.6125000000000004e-05
 n_samples      : 192000
 n_steps        : 1500
 ActivityNet_val1_test/t2v_metrics/R1: 15.598942444580029
 ActivityNet_val1_test/t2v_metrics/R5: 43.74618669920683
 ActivityNet_val1_test/t2v_metrics/R10: 60.5043725849095
 ActivityNet_val1_test/t2v_metrics/R50: 91.31584299369534
 ActivityNet_val1_test/t2v_metrics/MedR: 7.0
 ActivityNet_val1_test/t2v_metrics/MeanR: 25.54403091315843
 ActivityNet_val1_test/t2v_metrics/geometric_mean_R1-R5-R10: 34.56267703528711
 ActivityNet_val1_test/v2t_metrics/R1: 16.67683546878178
 ActivityNet_val1_test/v2t_metrics/R5: 44.29530201342282
 ActivityNet_val1_test/v2t_metrics/R10: 62.21273134024812
 ActivityNet_val1_test/v2t_metrics/R50: 91.76327028676022
 ActivityNet_val1_test/v2t_metrics/MedR: 7.0
 ActivityNet_val1_test/v2t_metrics/MeanR: 24.98637380516575
 ActivityNet_val1_test/v2t_metrics/geometric_mean_R1-R5-R10: 35.81928066679331
 mnt_best       : 34.56267703528711
 not_improved_count: 0
Train Epoch: 7 [1/250 128/32000 (0%)] Loss: 0.30229 (QuantReg: 10.55149) QuantErr: 10.55149 batch_time=22.30147 
Train Epoch: 7 [12/250 1536/32000 (5%)] Loss: 0.30615 (QuantReg: 10.48997) QuantErr: 10.48997 batch_time=1.10413 
Train Epoch: 7 [23/250 2944/32000 (9%)] Loss: 0.27374 (QuantReg: 10.65777) QuantErr: 10.65777 batch_time=1.54219 
Train Epoch: 7 [34/250 4352/32000 (14%)] Loss: 0.24293 (QuantReg: 11.03754) QuantErr: 11.03754 batch_time=0.64909 
Train Epoch: 7 [45/250 5760/32000 (18%)] Loss: 0.22156 (QuantReg: 10.78556) QuantErr: 10.78556 batch_time=0.74545 
Train Epoch: 7 [56/250 7168/32000 (22%)] Loss: 0.20372 (QuantReg: 11.07190) QuantErr: 11.07190 batch_time=0.64967 
Train Epoch: 7 [67/250 8576/32000 (27%)] Loss: 0.23892 (QuantReg: 10.72866) QuantErr: 10.72866 batch_time=0.84757 
Train Epoch: 7 [78/250 9984/32000 (31%)] Loss: 0.24414 (QuantReg: 10.57635) QuantErr: 10.57635 batch_time=7.97332 
Train Epoch: 7 [89/250 11392/32000 (36%)] Loss: 0.23203 (QuantReg: 10.79638) QuantErr: 10.79638 batch_time=0.65295 
Train Epoch: 7 [100/250 12800/32000 (40%)] Loss: 0.29016 (QuantReg: 10.71004) QuantErr: 10.71004 batch_time=0.65517 
Train Epoch: 7 [111/250 14208/32000 (44%)] Loss: 0.19035 (QuantReg: 10.83233) QuantErr: 10.83233 batch_time=0.64876 
Train Epoch: 7 [122/250 15616/32000 (49%)] Loss: 0.21100 (QuantReg: 10.89036) QuantErr: 10.89036 batch_time=0.65237 
Train Epoch: 7 [133/250 17024/32000 (53%)] Loss: 0.22106 (QuantReg: 10.51180) QuantErr: 10.51180 batch_time=0.64304 
Train Epoch: 7 [144/250 18432/32000 (58%)] Loss: 0.24024 (QuantReg: 10.97250) QuantErr: 10.97250 batch_time=0.64126 
Train Epoch: 7 [155/250 19840/32000 (62%)] Loss: 0.31380 (QuantReg: 10.80200) QuantErr: 10.80200 batch_time=0.65788 
Train Epoch: 7 [166/250 21248/32000 (66%)] Loss: 0.23145 (QuantReg: 10.87861) QuantErr: 10.87861 batch_time=0.64654 
Train Epoch: 7 [177/250 22656/32000 (71%)] Loss: 0.25852 (QuantReg: 10.60952) QuantErr: 10.60952 batch_time=0.67915 
Train Epoch: 7 [188/250 24064/32000 (75%)] Loss: 0.23383 (QuantReg: 11.04639) QuantErr: 11.04639 batch_time=0.65489 
Train Epoch: 7 [199/250 25472/32000 (80%)] Loss: 0.29354 (QuantReg: 10.82287) QuantErr: 10.82287 batch_time=0.64388 
Train Epoch: 7 [210/250 26880/32000 (84%)] Loss: 0.15268 (QuantReg: 10.92702) QuantErr: 10.92702 batch_time=0.64072 
Train Epoch: 7 [221/250 28288/32000 (88%)] Loss: 0.19315 (QuantReg: 10.92085) QuantErr: 10.92085 batch_time=0.64300 
Train Epoch: 7 [232/250 29696/32000 (93%)] Loss: 0.19035 (QuantReg: 10.93960) QuantErr: 10.93960 batch_time=0.66746 
Train Epoch: 7 [243/250 31104/32000 (97%)] Loss: 0.21987 (QuantReg: 10.62396) QuantErr: 10.62396 batch_time=0.66054 
Train Epoch: 7 codebook_update_time=1.83978
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_ActivityNet_bs128/checkpoint-epoch7.pth ...
Done in 21.442s
Updating 'best' checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_ActivityNet_bs128/checkpoint-epoch7.pth ...
Done in 25.408s
removing stale ckpt [epoch 6] [took 0.00s]
 epoch          : 7
 loss           : 0.24280645179748536
 quant_reg      : 10.767874702453613
 quant_err      : 10.767874702453613
 learning_rate  : 3.0706250000000004e-05
 n_samples      : 224000
 n_steps        : 1750
 ActivityNet_val1_test/t2v_metrics/R1: 15.924344112263576
 ActivityNet_val1_test/t2v_metrics/R5: 44.25462680496238
 ActivityNet_val1_test/t2v_metrics/R10: 61.541590400650804
 ActivityNet_val1_test/t2v_metrics/R50: 90.99044132601179
 ActivityNet_val1_test/t2v_metrics/MedR: 7.0
 ActivityNet_val1_test/t2v_metrics/MeanR: 26.680496237543217
 ActivityNet_val1_test/t2v_metrics/geometric_mean_R1-R5-R10: 35.13416614052744
 ActivityNet_val1_test/v2t_metrics/R1: 17.388651616839535
 ActivityNet_val1_test/v2t_metrics/R5: 45.12914378686191
 ActivityNet_val1_test/v2t_metrics/R10: 63.412649989831195
 ActivityNet_val1_test/v2t_metrics/R50: 91.49888143176734
 ActivityNet_val1_test/v2t_metrics/MedR: 7.0
 ActivityNet_val1_test/v2t_metrics/MeanR: 25.06772422208664
 ActivityNet_val1_test/v2t_metrics/geometric_mean_R1-R5-R10: 36.78179907256159
 mnt_best       : 35.13416614052744
 not_improved_count: 0
Train Epoch: 8 [1/250 128/32000 (0%)] Loss: 0.25017 (QuantReg: 10.72681) QuantErr: 10.72681 batch_time=23.83086 
Train Epoch: 8 [12/250 1536/32000 (5%)] Loss: 0.18028 (QuantReg: 10.70438) QuantErr: 10.70438 batch_time=0.64441 
Train Epoch: 8 [23/250 2944/32000 (9%)] Loss: 0.20877 (QuantReg: 10.93380) QuantErr: 10.93380 batch_time=0.66160 
Train Epoch: 8 [34/250 4352/32000 (14%)] Loss: 0.21291 (QuantReg: 10.83552) QuantErr: 10.83552 batch_time=0.63939 
Train Epoch: 8 [45/250 5760/32000 (18%)] Loss: 0.23888 (QuantReg: 10.89232) QuantErr: 10.89232 batch_time=2.80453 
Train Epoch: 8 [56/250 7168/32000 (22%)] Loss: 0.27161 (QuantReg: 10.70914) QuantErr: 10.70914 batch_time=0.64833 
Train Epoch: 8 [67/250 8576/32000 (27%)] Loss: 0.24327 (QuantReg: 10.78460) QuantErr: 10.78460 batch_time=0.64174 
Train Epoch: 8 [78/250 9984/32000 (31%)] Loss: 0.24865 (QuantReg: 10.71569) QuantErr: 10.71569 batch_time=1.15614 
Train Epoch: 8 [89/250 11392/32000 (36%)] Loss: 0.25380 (QuantReg: 10.72511) QuantErr: 10.72511 batch_time=0.67281 
Train Epoch: 8 [100/250 12800/32000 (40%)] Loss: 0.21028 (QuantReg: 10.64086) QuantErr: 10.64086 batch_time=0.64134 
Train Epoch: 8 [111/250 14208/32000 (44%)] Loss: 0.17547 (QuantReg: 10.78639) QuantErr: 10.78639 batch_time=0.64515 
Train Epoch: 8 [122/250 15616/32000 (49%)] Loss: 0.20443 (QuantReg: 10.50945) QuantErr: 10.50945 batch_time=0.64169 
Train Epoch: 8 [133/250 17024/32000 (53%)] Loss: 0.16856 (QuantReg: 10.82636) QuantErr: 10.82636 batch_time=0.65094 
Train Epoch: 8 [144/250 18432/32000 (58%)] Loss: 0.17489 (QuantReg: 10.66352) QuantErr: 10.66352 batch_time=0.66192 
Train Epoch: 8 [155/250 19840/32000 (62%)] Loss: 0.21084 (QuantReg: 10.60990) QuantErr: 10.60990 batch_time=0.64037 
Train Epoch: 8 [166/250 21248/32000 (66%)] Loss: 0.16471 (QuantReg: 10.93224) QuantErr: 10.93224 batch_time=0.64321 
Train Epoch: 8 [177/250 22656/32000 (71%)] Loss: 0.17529 (QuantReg: 10.57649) QuantErr: 10.57649 batch_time=0.65876 
Train Epoch: 8 [188/250 24064/32000 (75%)] Loss: 0.17846 (QuantReg: 10.87887) QuantErr: 10.87887 batch_time=0.64393 
Train Epoch: 8 [199/250 25472/32000 (80%)] Loss: 0.17722 (QuantReg: 10.84530) QuantErr: 10.84530 batch_time=0.63767 
Train Epoch: 8 [210/250 26880/32000 (84%)] Loss: 0.19346 (QuantReg: 10.58539) QuantErr: 10.58539 batch_time=2.67068 
Train Epoch: 8 [221/250 28288/32000 (88%)] Loss: 0.18837 (QuantReg: 10.97056) QuantErr: 10.97056 batch_time=0.69199 
Train Epoch: 8 [232/250 29696/32000 (93%)] Loss: 0.25635 (QuantReg: 10.91460) QuantErr: 10.91460 batch_time=0.64546 
Train Epoch: 8 [243/250 31104/32000 (97%)] Loss: 0.14814 (QuantReg: 10.53818) QuantErr: 10.53818 batch_time=0.63462 
Train Epoch: 8 codebook_update_time=1.76113
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_ActivityNet_bs128/checkpoint-epoch8.pth ...
Done in 4.017s
Updating 'best' checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_ActivityNet_bs128/checkpoint-epoch8.pth ...
Done in 8.313s
removing stale ckpt [epoch 7] [took 0.01s]
 epoch          : 8
 loss           : 0.22032551497220992
 quant_reg      : 10.79703706741333
 quant_err      : 10.79703706741333
 learning_rate  : 3.0706250000000004e-05
 n_samples      : 256000
 n_steps        : 2000
 ActivityNet_val1_test/t2v_metrics/R1: 16.107382550335572
 ActivityNet_val1_test/t2v_metrics/R5: 44.86475493186902
 ActivityNet_val1_test/t2v_metrics/R10: 62.02969290217612
 ActivityNet_val1_test/t2v_metrics/R50: 91.25483018100468
 ActivityNet_val1_test/t2v_metrics/MedR: 7.0
 ActivityNet_val1_test/t2v_metrics/MeanR: 26.9538336383974
 ActivityNet_val1_test/t2v_metrics/geometric_mean_R1-R5-R10: 35.523027174004156
 ActivityNet_val1_test/v2t_metrics/R1: 16.900549115314217
 ActivityNet_val1_test/v2t_metrics/R5: 46.02399837299166
 ActivityNet_val1_test/v2t_metrics/R10: 64.44986780557251
 ActivityNet_val1_test/v2t_metrics/R50: 91.76327028676022
 ActivityNet_val1_test/v2t_metrics/MedR: 6.0
 ActivityNet_val1_test/v2t_metrics/MeanR: 25.474069554606466
 ActivityNet_val1_test/v2t_metrics/geometric_mean_R1-R5-R10: 36.872484128282494
 mnt_best       : 35.523027174004156
 not_improved_count: 0
Train Epoch: 9 [1/250 128/32000 (0%)] Loss: 0.17867 (QuantReg: 10.87741) QuantErr: 10.87741 batch_time=24.18010 
Train Epoch: 9 [12/250 1536/32000 (5%)] Loss: 0.17991 (QuantReg: 10.69508) QuantErr: 10.69508 batch_time=2.36209 
Train Epoch: 9 [23/250 2944/32000 (9%)] Loss: 0.15790 (QuantReg: 10.85445) QuantErr: 10.85445 batch_time=0.64729 
Train Epoch: 9 [34/250 4352/32000 (14%)] Loss: 0.19782 (QuantReg: 10.90718) QuantErr: 10.90718 batch_time=0.64366 
Train Epoch: 9 [45/250 5760/32000 (18%)] Loss: 0.24620 (QuantReg: 10.82522) QuantErr: 10.82522 batch_time=0.64966 
Train Epoch: 9 [56/250 7168/32000 (22%)] Loss: 0.13773 (QuantReg: 10.86765) QuantErr: 10.86765 batch_time=0.65037 
Train Epoch: 9 [67/250 8576/32000 (27%)] Loss: 0.27465 (QuantReg: 10.64122) QuantErr: 10.64122 batch_time=0.64110 
Train Epoch: 9 [78/250 9984/32000 (31%)] Loss: 0.23426 (QuantReg: 10.72536) QuantErr: 10.72536 batch_time=0.64462 
Train Epoch: 9 [89/250 11392/32000 (36%)] Loss: 0.25638 (QuantReg: 10.76872) QuantErr: 10.76872 batch_time=0.65816 
Train Epoch: 9 [100/250 12800/32000 (40%)] Loss: 0.21838 (QuantReg: 10.71451) QuantErr: 10.71451 batch_time=0.65108 
Train Epoch: 9 [111/250 14208/32000 (44%)] Loss: 0.14753 (QuantReg: 10.51871) QuantErr: 10.51871 batch_time=0.66018 
Train Epoch: 9 [122/250 15616/32000 (49%)] Loss: 0.22483 (QuantReg: 10.68111) QuantErr: 10.68111 batch_time=0.65718 
Train Epoch: 9 [133/250 17024/32000 (53%)] Loss: 0.23458 (QuantReg: 10.68837) QuantErr: 10.68837 batch_time=0.63352 
Train Epoch: 9 [144/250 18432/32000 (58%)] Loss: 0.26365 (QuantReg: 10.92529) QuantErr: 10.92529 batch_time=4.37017 
Train Epoch: 9 [155/250 19840/32000 (62%)] Loss: 0.17477 (QuantReg: 10.89073) QuantErr: 10.89073 batch_time=0.64321 
Train Epoch: 9 [166/250 21248/32000 (66%)] Loss: 0.17448 (QuantReg: 10.76244) QuantErr: 10.76244 batch_time=0.64624 
Train Epoch: 9 [177/250 22656/32000 (71%)] Loss: 0.16471 (QuantReg: 10.71885) QuantErr: 10.71885 batch_time=0.66330 
Train Epoch: 9 [188/250 24064/32000 (75%)] Loss: 0.15268 (QuantReg: 10.93667) QuantErr: 10.93667 batch_time=0.65269 
Train Epoch: 9 [199/250 25472/32000 (80%)] Loss: 0.16982 (QuantReg: 10.81541) QuantErr: 10.81541 batch_time=0.66269 
Train Epoch: 9 [210/250 26880/32000 (84%)] Loss: 0.15871 (QuantReg: 10.86596) QuantErr: 10.86596 batch_time=0.64536 
Train Epoch: 9 [221/250 28288/32000 (88%)] Loss: 0.20213 (QuantReg: 10.81937) QuantErr: 10.81937 batch_time=0.64731 
Train Epoch: 9 [232/250 29696/32000 (93%)] Loss: 0.22006 (QuantReg: 10.89966) QuantErr: 10.89966 batch_time=0.66651 
Train Epoch: 9 [243/250 31104/32000 (97%)] Loss: 0.16606 (QuantReg: 10.64421) QuantErr: 10.64421 batch_time=0.64853 
Train Epoch: 9 codebook_update_time=1.77928
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_ActivityNet_bs128/checkpoint-epoch9.pth ...
Done in 6.161s
Updating 'best' checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_ActivityNet_bs128/checkpoint-epoch9.pth ...
Done in 13.351s
removing stale ckpt [epoch 8] [took 0.34s]
 epoch          : 9
 loss           : 0.19809449735283852
 quant_reg      : 10.800171058654785
 quant_err      : 10.800171058654785
 learning_rate  : 2.6100312500000002e-05
 n_samples      : 288000
 n_steps        : 2250
 ActivityNet_val1_test/t2v_metrics/R1: 16.900549115314217
 ActivityNet_val1_test/t2v_metrics/R5: 45.27150701647346
 ActivityNet_val1_test/t2v_metrics/R10: 63.24994915598943
 ActivityNet_val1_test/t2v_metrics/R50: 91.05145413870247
 ActivityNet_val1_test/t2v_metrics/MedR: 7.0
 ActivityNet_val1_test/t2v_metrics/MeanR: 26.824079723408584
 ActivityNet_val1_test/t2v_metrics/geometric_mean_R1-R5-R10: 36.441422043083044
 ActivityNet_val1_test/v2t_metrics/R1: 17.53101484645109
 ActivityNet_val1_test/v2t_metrics/R5: 46.77648972950986
 ActivityNet_val1_test/v2t_metrics/R10: 64.2668293675005
 ActivityNet_val1_test/v2t_metrics/R50: 91.49888143176734
 ActivityNet_val1_test/v2t_metrics/MedR: 6.0
 ActivityNet_val1_test/v2t_metrics/MeanR: 25.83577384584096
 ActivityNet_val1_test/v2t_metrics/geometric_mean_R1-R5-R10: 37.492165018122236
 mnt_best       : 36.441422043083044
 not_improved_count: 0
Train Epoch: 10 [1/250 128/32000 (0%)] Loss: 0.14940 (QuantReg: 10.80495) QuantErr: 10.80495 batch_time=25.43971 
Train Epoch: 10 [12/250 1536/32000 (5%)] Loss: 0.18204 (QuantReg: 10.71825) QuantErr: 10.71825 batch_time=0.66463 
Train Epoch: 10 [23/250 2944/32000 (9%)] Loss: 0.17358 (QuantReg: 10.82188) QuantErr: 10.82188 batch_time=0.64894 
Train Epoch: 10 [34/250 4352/32000 (14%)] Loss: 0.19938 (QuantReg: 10.87071) QuantErr: 10.87071 batch_time=0.65078 
Train Epoch: 10 [45/250 5760/32000 (18%)] Loss: 0.15222 (QuantReg: 10.65945) QuantErr: 10.65945 batch_time=0.64230 
Train Epoch: 10 [56/250 7168/32000 (22%)] Loss: 0.16308 (QuantReg: 10.52228) QuantErr: 10.52228 batch_time=0.66845 
Train Epoch: 10 [67/250 8576/32000 (27%)] Loss: 0.20694 (QuantReg: 10.78585) QuantErr: 10.78585 batch_time=1.22941 
Train Epoch: 10 [78/250 9984/32000 (31%)] Loss: 0.18978 (QuantReg: 10.91699) QuantErr: 10.91699 batch_time=0.65420 
Train Epoch: 10 [89/250 11392/32000 (36%)] Loss: 0.13131 (QuantReg: 10.71752) QuantErr: 10.71752 batch_time=0.64081 
Train Epoch: 10 [100/250 12800/32000 (40%)] Loss: 0.15572 (QuantReg: 10.88466) QuantErr: 10.88466 batch_time=0.64601 
Train Epoch: 10 [111/250 14208/32000 (44%)] Loss: 0.20302 (QuantReg: 10.61178) QuantErr: 10.61178 batch_time=0.64519 
Train Epoch: 10 [122/250 15616/32000 (49%)] Loss: 0.19129 (QuantReg: 10.80009) QuantErr: 10.80009 batch_time=0.68255 
Train Epoch: 10 [133/250 17024/32000 (53%)] Loss: 0.15448 (QuantReg: 10.79744) QuantErr: 10.79744 batch_time=0.64975 
Train Epoch: 10 [144/250 18432/32000 (58%)] Loss: 0.18496 (QuantReg: 10.89967) QuantErr: 10.89967 batch_time=0.65231 
Train Epoch: 10 [155/250 19840/32000 (62%)] Loss: 0.22395 (QuantReg: 10.79202) QuantErr: 10.79202 batch_time=0.64631 
Train Epoch: 10 [166/250 21248/32000 (66%)] Loss: 0.17962 (QuantReg: 10.80112) QuantErr: 10.80112 batch_time=0.64188 
Train Epoch: 10 [177/250 22656/32000 (71%)] Loss: 0.19960 (QuantReg: 10.92002) QuantErr: 10.92002 batch_time=0.69988 
Train Epoch: 10 [188/250 24064/32000 (75%)] Loss: 0.13990 (QuantReg: 10.95731) QuantErr: 10.95731 batch_time=0.64376 
Train Epoch: 10 [199/250 25472/32000 (80%)] Loss: 0.17776 (QuantReg: 10.69244) QuantErr: 10.69244 batch_time=0.64492 
Train Epoch: 10 [210/250 26880/32000 (84%)] Loss: 0.19109 (QuantReg: 11.11222) QuantErr: 11.11222 batch_time=2.07713 
Train Epoch: 10 [221/250 28288/32000 (88%)] Loss: 0.13954 (QuantReg: 11.10796) QuantErr: 11.10796 batch_time=0.64183 
Train Epoch: 10 [232/250 29696/32000 (93%)] Loss: 0.13817 (QuantReg: 10.97757) QuantErr: 10.97757 batch_time=0.64123 
Train Epoch: 10 [243/250 31104/32000 (97%)] Loss: 0.21265 (QuantReg: 10.96767) QuantErr: 10.96767 batch_time=0.64942 
Train Epoch: 10 codebook_update_time=1.83364
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_ActivityNet_bs128/checkpoint-epoch10.pth ...
Done in 4.471s
Updating 'best' checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_ActivityNet_bs128/checkpoint-epoch10.pth ...
Done in 8.623s
removing stale ckpt [epoch 9] [took 0.04s]
 epoch          : 10
 loss           : 0.17955050987005233
 quant_reg      : 10.784574653625489
 quant_err      : 10.784574653625489
 learning_rate  : 2.6100312500000002e-05
 n_samples      : 320000
 n_steps        : 2500
 ActivityNet_val1_test/t2v_metrics/R1: 16.96156192800488
 ActivityNet_val1_test/t2v_metrics/R5: 46.34940004067521
 ActivityNet_val1_test/t2v_metrics/R10: 63.51433801098231
 ActivityNet_val1_test/t2v_metrics/R50: 91.45820622330689
 ActivityNet_val1_test/t2v_metrics/MedR: 6.0
 ActivityNet_val1_test/t2v_metrics/MeanR: 25.9816961561928
 ActivityNet_val1_test/t2v_metrics/geometric_mean_R1-R5-R10: 36.823684850155196
 ActivityNet_val1_test/v2t_metrics/R1: 17.67337807606264
 ActivityNet_val1_test/v2t_metrics/R5: 47.79336994102095
 ActivityNet_val1_test/v2t_metrics/R10: 65.36505999593248
 ActivityNet_val1_test/v2t_metrics/R50: 91.62090705714867
 ActivityNet_val1_test/v2t_metrics/MedR: 6.0
 ActivityNet_val1_test/v2t_metrics/MeanR: 25.39271913768558
 ActivityNet_val1_test/v2t_metrics/geometric_mean_R1-R5-R10: 38.07830680612879
 mnt_best       : 36.823684850155196
 not_improved_count: 0
Train Epoch: 11 [1/250 128/32000 (0%)] Loss: 0.19712 (QuantReg: 10.83497) QuantErr: 10.83497 batch_time=21.81338 
Train Epoch: 11 [12/250 1536/32000 (5%)] Loss: 0.14177 (QuantReg: 10.72243) QuantErr: 10.72243 batch_time=0.64480 
Train Epoch: 11 [23/250 2944/32000 (9%)] Loss: 0.18439 (QuantReg: 10.60823) QuantErr: 10.60823 batch_time=0.64955 
Train Epoch: 11 [34/250 4352/32000 (14%)] Loss: 0.20418 (QuantReg: 10.86818) QuantErr: 10.86818 batch_time=0.64532 
Train Epoch: 11 [45/250 5760/32000 (18%)] Loss: 0.15245 (QuantReg: 10.77436) QuantErr: 10.77436 batch_time=0.64278 
Train Epoch: 11 [56/250 7168/32000 (22%)] Loss: 0.18475 (QuantReg: 10.78029) QuantErr: 10.78029 batch_time=0.65816 
Train Epoch: 11 [67/250 8576/32000 (27%)] Loss: 0.17446 (QuantReg: 10.69382) QuantErr: 10.69382 batch_time=0.95000 
Train Epoch: 11 [78/250 9984/32000 (31%)] Loss: 0.17338 (QuantReg: 10.74846) QuantErr: 10.74846 batch_time=0.65402 
Train Epoch: 11 [89/250 11392/32000 (36%)] Loss: 0.17007 (QuantReg: 10.81282) QuantErr: 10.81282 batch_time=0.65286 
Train Epoch: 11 [100/250 12800/32000 (40%)] Loss: 0.18463 (QuantReg: 11.05151) QuantErr: 11.05151 batch_time=0.65503 
Train Epoch: 11 [111/250 14208/32000 (44%)] Loss: 0.16374 (QuantReg: 10.61991) QuantErr: 10.61991 batch_time=0.64872 
Train Epoch: 11 [122/250 15616/32000 (49%)] Loss: 0.20472 (QuantReg: 10.58018) QuantErr: 10.58018 batch_time=0.65801 
Train Epoch: 11 [133/250 17024/32000 (53%)] Loss: 0.13782 (QuantReg: 10.58796) QuantErr: 10.58796 batch_time=0.64962 
Train Epoch: 11 [144/250 18432/32000 (58%)] Loss: 0.14333 (QuantReg: 10.88811) QuantErr: 10.88811 batch_time=3.68035 
Train Epoch: 11 [155/250 19840/32000 (62%)] Loss: 0.14503 (QuantReg: 10.89856) QuantErr: 10.89856 batch_time=0.64791 
Train Epoch: 11 [166/250 21248/32000 (66%)] Loss: 0.16416 (QuantReg: 10.71110) QuantErr: 10.71110 batch_time=0.64193 
Train Epoch: 11 [177/250 22656/32000 (71%)] Loss: 0.17862 (QuantReg: 10.80689) QuantErr: 10.80689 batch_time=0.64701 
Train Epoch: 11 [188/250 24064/32000 (75%)] Loss: 0.17386 (QuantReg: 10.72978) QuantErr: 10.72978 batch_time=0.65208 
Train Epoch: 11 [199/250 25472/32000 (80%)] Loss: 0.16780 (QuantReg: 10.72107) QuantErr: 10.72107 batch_time=0.64614 
Train Epoch: 11 [210/250 26880/32000 (84%)] Loss: 0.17099 (QuantReg: 10.91318) QuantErr: 10.91318 batch_time=0.91264 
Train Epoch: 11 [221/250 28288/32000 (88%)] Loss: 0.11934 (QuantReg: 11.06623) QuantErr: 11.06623 batch_time=0.64860 
Train Epoch: 11 [232/250 29696/32000 (93%)] Loss: 0.11685 (QuantReg: 10.90019) QuantErr: 10.90019 batch_time=0.67117 
Train Epoch: 11 [243/250 31104/32000 (97%)] Loss: 0.17394 (QuantReg: 10.96733) QuantErr: 10.96733 batch_time=0.65547 
Train Epoch: 11 codebook_update_time=1.95715
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_ActivityNet_bs128/checkpoint-epoch11.pth ...
Done in 4.719s
removing stale ckpt [epoch 10] [took 0.01s]
 epoch          : 11
 loss           : 0.1643868734240532
 quant_reg      : 10.766478240966796
 quant_err      : 10.766478240966796
 learning_rate  : 2.2185265625e-05
 n_samples      : 352000
 n_steps        : 2750
 ActivityNet_val1_test/t2v_metrics/R1: 16.67683546878178
 ActivityNet_val1_test/t2v_metrics/R5: 46.308724832214764
 ActivityNet_val1_test/t2v_metrics/R10: 63.63636363636363
 ActivityNet_val1_test/t2v_metrics/R50: 90.92942851332113
 ActivityNet_val1_test/t2v_metrics/MedR: 6.0
 ActivityNet_val1_test/t2v_metrics/MeanR: 27.316249745779945
 ActivityNet_val1_test/t2v_metrics/geometric_mean_R1-R5-R10: 36.62918652202238
 ActivityNet_val1_test/v2t_metrics/R1: 17.714053284523082
 ActivityNet_val1_test/v2t_metrics/R5: 48.03742119178361
 ActivityNet_val1_test/v2t_metrics/R10: 65.05999593247915
 ActivityNet_val1_test/v2t_metrics/R50: 91.35651820215578
 ActivityNet_val1_test/v2t_metrics/MedR: 6.0
 ActivityNet_val1_test/v2t_metrics/MeanR: 26.739678665853162
 ActivityNet_val1_test/v2t_metrics/geometric_mean_R1-R5-R10: 38.112773551477055
 mnt_best       : 36.823684850155196
 not_improved_count: 1
Train Epoch: 12 [1/250 128/32000 (0%)] Loss: 0.13010 (QuantReg: 10.62824) QuantErr: 10.62824 batch_time=24.71962 
Train Epoch: 12 [12/250 1536/32000 (5%)] Loss: 0.18347 (QuantReg: 10.70307) QuantErr: 10.70307 batch_time=0.64383 
Train Epoch: 12 [23/250 2944/32000 (9%)] Loss: 0.21578 (QuantReg: 10.54397) QuantErr: 10.54397 batch_time=0.65648 
Train Epoch: 12 [34/250 4352/32000 (14%)] Loss: 0.17386 (QuantReg: 10.37536) QuantErr: 10.37536 batch_time=0.93400 
Train Epoch: 12 [45/250 5760/32000 (18%)] Loss: 0.19022 (QuantReg: 10.83144) QuantErr: 10.83144 batch_time=0.64069 
Train Epoch: 12 [56/250 7168/32000 (22%)] Loss: 0.17072 (QuantReg: 10.60056) QuantErr: 10.60056 batch_time=0.65018 
Train Epoch: 12 [67/250 8576/32000 (27%)] Loss: 0.18524 (QuantReg: 10.65392) QuantErr: 10.65392 batch_time=0.64846 
Train Epoch: 12 [78/250 9984/32000 (31%)] Loss: 0.10442 (QuantReg: 10.67848) QuantErr: 10.67848 batch_time=0.64588 
Train Epoch: 12 [89/250 11392/32000 (36%)] Loss: 0.12898 (QuantReg: 10.78828) QuantErr: 10.78828 batch_time=0.68414 
Train Epoch: 12 [100/250 12800/32000 (40%)] Loss: 0.16997 (QuantReg: 10.80818) QuantErr: 10.80818 batch_time=0.70378 
Train Epoch: 12 [111/250 14208/32000 (44%)] Loss: 0.12258 (QuantReg: 10.93220) QuantErr: 10.93220 batch_time=0.68760 
Train Epoch: 12 [122/250 15616/32000 (49%)] Loss: 0.16199 (QuantReg: 10.71958) QuantErr: 10.71958 batch_time=0.78279 
Train Epoch: 12 [133/250 17024/32000 (53%)] Loss: 0.16382 (QuantReg: 10.86508) QuantErr: 10.86508 batch_time=0.64598 
Train Epoch: 12 [144/250 18432/32000 (58%)] Loss: 0.09933 (QuantReg: 10.76197) QuantErr: 10.76197 batch_time=0.64718 
Train Epoch: 12 [155/250 19840/32000 (62%)] Loss: 0.19178 (QuantReg: 10.64205) QuantErr: 10.64205 batch_time=0.65317 
Train Epoch: 12 [166/250 21248/32000 (66%)] Loss: 0.17006 (QuantReg: 10.68346) QuantErr: 10.68346 batch_time=0.64155 
Train Epoch: 12 [177/250 22656/32000 (71%)] Loss: 0.16550 (QuantReg: 10.69671) QuantErr: 10.69671 batch_time=0.64111 
Train Epoch: 12 [188/250 24064/32000 (75%)] Loss: 0.15790 (QuantReg: 10.71448) QuantErr: 10.71448 batch_time=0.64706 
Train Epoch: 12 [199/250 25472/32000 (80%)] Loss: 0.14067 (QuantReg: 10.87011) QuantErr: 10.87011 batch_time=0.69874 
Train Epoch: 12 [210/250 26880/32000 (84%)] Loss: 0.14192 (QuantReg: 10.74851) QuantErr: 10.74851 batch_time=0.64353 
Train Epoch: 12 [221/250 28288/32000 (88%)] Loss: 0.13308 (QuantReg: 10.66002) QuantErr: 10.66002 batch_time=0.65121 
Train Epoch: 12 [232/250 29696/32000 (93%)] Loss: 0.17868 (QuantReg: 10.90090) QuantErr: 10.90090 batch_time=0.63893 
Train Epoch: 12 [243/250 31104/32000 (97%)] Loss: 0.13530 (QuantReg: 10.78760) QuantErr: 10.78760 batch_time=0.64302 
Train Epoch: 12 codebook_update_time=2.21119
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_ActivityNet_bs128/checkpoint-epoch12.pth ...
Done in 5.007s
Updating 'best' checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_ActivityNet_bs128/checkpoint-epoch12.pth ...
Done in 9.752s
removing stale ckpt [epoch 11] [took 0.02s]
 epoch          : 12
 loss           : 0.15271886843442917
 quant_reg      : 10.733918270111085
 quant_err      : 10.733918270111085
 learning_rate  : 2.2185265625e-05
 n_samples      : 384000
 n_steps        : 3000
 ActivityNet_val1_test/t2v_metrics/R1: 17.164937970307097
 ActivityNet_val1_test/t2v_metrics/R5: 46.75615212527964
 ActivityNet_val1_test/t2v_metrics/R10: 64.20581655480984
 ActivityNet_val1_test/t2v_metrics/R50: 90.8074028879398
 ActivityNet_val1_test/t2v_metrics/MedR: 6.0
 ActivityNet_val1_test/t2v_metrics/MeanR: 27.70002033760423
 ActivityNet_val1_test/t2v_metrics/geometric_mean_R1-R5-R10: 37.212181023506474
 ActivityNet_val1_test/v2t_metrics/R1: 17.69371568029286
 ActivityNet_val1_test/v2t_metrics/R5: 47.915395566402275
 ActivityNet_val1_test/v2t_metrics/R10: 65.73113687207648
 ActivityNet_val1_test/v2t_metrics/R50: 91.29550538946512
 ActivityNet_val1_test/v2t_metrics/MedR: 6.0
 ActivityNet_val1_test/v2t_metrics/MeanR: 26.335163717714053
 ActivityNet_val1_test/v2t_metrics/geometric_mean_R1-R5-R10: 38.19634042369397
 mnt_best       : 37.212181023506474
 not_improved_count: 0
Train Epoch: 13 [1/250 128/32000 (0%)] Loss: 0.14196 (QuantReg: 10.74568) QuantErr: 10.74568 batch_time=22.46467 
Train Epoch: 13 [12/250 1536/32000 (5%)] Loss: 0.11550 (QuantReg: 10.60409) QuantErr: 10.60409 batch_time=0.64170 
Train Epoch: 13 [23/250 2944/32000 (9%)] Loss: 0.18206 (QuantReg: 10.77544) QuantErr: 10.77544 batch_time=0.64326 
Train Epoch: 13 [34/250 4352/32000 (14%)] Loss: 0.14428 (QuantReg: 10.63940) QuantErr: 10.63940 batch_time=0.64640 
Train Epoch: 13 [45/250 5760/32000 (18%)] Loss: 0.13867 (QuantReg: 10.77318) QuantErr: 10.77318 batch_time=0.64240 
Train Epoch: 13 [56/250 7168/32000 (22%)] Loss: 0.12037 (QuantReg: 10.67719) QuantErr: 10.67719 batch_time=0.63940 
Train Epoch: 13 [67/250 8576/32000 (27%)] Loss: 0.11743 (QuantReg: 10.78879) QuantErr: 10.78879 batch_time=3.09935 
Train Epoch: 13 [78/250 9984/32000 (31%)] Loss: 0.16336 (QuantReg: 10.81190) QuantErr: 10.81190 batch_time=0.63814 
Train Epoch: 13 [89/250 11392/32000 (36%)] Loss: 0.15762 (QuantReg: 10.94040) QuantErr: 10.94040 batch_time=0.64778 
Train Epoch: 13 [100/250 12800/32000 (40%)] Loss: 0.10443 (QuantReg: 10.72621) QuantErr: 10.72621 batch_time=0.65025 
Train Epoch: 13 [111/250 14208/32000 (44%)] Loss: 0.09639 (QuantReg: 10.78716) QuantErr: 10.78716 batch_time=0.65185 
Train Epoch: 13 [122/250 15616/32000 (49%)] Loss: 0.16600 (QuantReg: 10.42938) QuantErr: 10.42938 batch_time=0.64663 
Train Epoch: 13 [133/250 17024/32000 (53%)] Loss: 0.15648 (QuantReg: 10.60687) QuantErr: 10.60687 batch_time=0.66268 
Train Epoch: 13 [144/250 18432/32000 (58%)] Loss: 0.12020 (QuantReg: 10.90066) QuantErr: 10.90066 batch_time=0.65793 
Train Epoch: 13 [155/250 19840/32000 (62%)] Loss: 0.19901 (QuantReg: 10.74312) QuantErr: 10.74312 batch_time=0.64654 
Train Epoch: 13 [166/250 21248/32000 (66%)] Loss: 0.14252 (QuantReg: 10.83706) QuantErr: 10.83706 batch_time=0.66097 
Train Epoch: 13 [177/250 22656/32000 (71%)] Loss: 0.15323 (QuantReg: 10.78911) QuantErr: 10.78911 batch_time=0.66426 
Train Epoch: 13 [188/250 24064/32000 (75%)] Loss: 0.12081 (QuantReg: 10.49823) QuantErr: 10.49823 batch_time=0.65972 
Train Epoch: 13 [199/250 25472/32000 (80%)] Loss: 0.23265 (QuantReg: 10.82727) QuantErr: 10.82727 batch_time=4.36063 
Train Epoch: 13 [210/250 26880/32000 (84%)] Loss: 0.12964 (QuantReg: 10.64284) QuantErr: 10.64284 batch_time=0.66151 
Train Epoch: 13 [221/250 28288/32000 (88%)] Loss: 0.15838 (QuantReg: 10.67105) QuantErr: 10.67105 batch_time=0.64530 
Train Epoch: 13 [232/250 29696/32000 (93%)] Loss: 0.10975 (QuantReg: 10.69004) QuantErr: 10.69004 batch_time=0.67688 
Train Epoch: 13 [243/250 31104/32000 (97%)] Loss: 0.10430 (QuantReg: 10.79563) QuantErr: 10.79563 batch_time=0.65269 
Train Epoch: 13 codebook_update_time=1.75459
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_ActivityNet_bs128/checkpoint-epoch13.pth ...
Done in 4.305s
Updating 'best' checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_ActivityNet_bs128/checkpoint-epoch13.pth ...
Done in 9.526s
removing stale ckpt [epoch 12] [took 0.01s]
 epoch          : 13
 loss           : 0.14238685286045075
 quant_reg      : 10.695345520019531
 quant_err      : 10.695345520019531
 learning_rate  : 1.885747578125e-05
 n_samples      : 416000
 n_steps        : 3250
 ActivityNet_val1_test/t2v_metrics/R1: 17.225950782997764
 ActivityNet_val1_test/t2v_metrics/R5: 47.122229001423634
 ActivityNet_val1_test/t2v_metrics/R10: 64.93797030709783
 ActivityNet_val1_test/t2v_metrics/R50: 90.58368924140736
 ActivityNet_val1_test/t2v_metrics/MedR: 6.0
 ActivityNet_val1_test/t2v_metrics/MeanR: 27.93207240187106
 ActivityNet_val1_test/t2v_metrics/geometric_mean_R1-R5-R10: 37.494644989867005
 ActivityNet_val1_test/v2t_metrics/R1: 18.934309538336382
 ActivityNet_val1_test/v2t_metrics/R5: 48.95261338214358
 ActivityNet_val1_test/v2t_metrics/R10: 66.34126499898312
 ActivityNet_val1_test/v2t_metrics/R50: 91.2751677852349
 ActivityNet_val1_test/v2t_metrics/MedR: 6.0
 ActivityNet_val1_test/v2t_metrics/MeanR: 26.86983933292658
 ActivityNet_val1_test/v2t_metrics/geometric_mean_R1-R5-R10: 39.4702339912904
 mnt_best       : 37.494644989867005
 not_improved_count: 0
Train Epoch: 14 [1/250 128/32000 (0%)] Loss: 0.08956 (QuantReg: 10.75674) QuantErr: 10.75674 batch_time=22.86858 
Train Epoch: 14 [12/250 1536/32000 (5%)] Loss: 0.12829 (QuantReg: 10.84736) QuantErr: 10.84736 batch_time=0.63816 
Train Epoch: 14 [23/250 2944/32000 (9%)] Loss: 0.12392 (QuantReg: 10.51743) QuantErr: 10.51743 batch_time=0.64589 
Train Epoch: 14 [34/250 4352/32000 (14%)] Loss: 0.15534 (QuantReg: 10.52043) QuantErr: 10.52043 batch_time=0.64430 
Train Epoch: 14 [45/250 5760/32000 (18%)] Loss: 0.16283 (QuantReg: 10.54947) QuantErr: 10.54947 batch_time=0.63827 
Train Epoch: 14 [56/250 7168/32000 (22%)] Loss: 0.14608 (QuantReg: 10.49591) QuantErr: 10.49591 batch_time=0.65163 
Train Epoch: 14 [67/250 8576/32000 (27%)] Loss: 0.15769 (QuantReg: 10.70887) QuantErr: 10.70887 batch_time=2.33579 
Train Epoch: 14 [78/250 9984/32000 (31%)] Loss: 0.09575 (QuantReg: 10.64832) QuantErr: 10.64832 batch_time=0.63266 
Train Epoch: 14 [89/250 11392/32000 (36%)] Loss: 0.16930 (QuantReg: 10.66771) QuantErr: 10.66771 batch_time=0.63968 
Train Epoch: 14 [100/250 12800/32000 (40%)] Loss: 0.14935 (QuantReg: 10.49588) QuantErr: 10.49588 batch_time=0.64947 
Train Epoch: 14 [111/250 14208/32000 (44%)] Loss: 0.12124 (QuantReg: 10.61825) QuantErr: 10.61825 batch_time=0.65126 
Train Epoch: 14 [122/250 15616/32000 (49%)] Loss: 0.12946 (QuantReg: 10.94359) QuantErr: 10.94359 batch_time=0.64137 
Train Epoch: 14 [133/250 17024/32000 (53%)] Loss: 0.12726 (QuantReg: 10.56032) QuantErr: 10.56032 batch_time=0.65852 
Train Epoch: 14 [144/250 18432/32000 (58%)] Loss: 0.14425 (QuantReg: 10.74134) QuantErr: 10.74134 batch_time=1.42686 
Train Epoch: 14 [155/250 19840/32000 (62%)] Loss: 0.12219 (QuantReg: 10.83475) QuantErr: 10.83475 batch_time=0.65321 
Train Epoch: 14 [166/250 21248/32000 (66%)] Loss: 0.11768 (QuantReg: 10.63499) QuantErr: 10.63499 batch_time=0.64871 
Train Epoch: 14 [177/250 22656/32000 (71%)] Loss: 0.16459 (QuantReg: 10.77607) QuantErr: 10.77607 batch_time=0.64581 
Train Epoch: 14 [188/250 24064/32000 (75%)] Loss: 0.08750 (QuantReg: 10.52369) QuantErr: 10.52369 batch_time=0.63782 
Train Epoch: 14 [199/250 25472/32000 (80%)] Loss: 0.17201 (QuantReg: 10.48234) QuantErr: 10.48234 batch_time=0.64389 
Train Epoch: 14 [210/250 26880/32000 (84%)] Loss: 0.13147 (QuantReg: 10.70988) QuantErr: 10.70988 batch_time=4.95450 
Train Epoch: 14 [221/250 28288/32000 (88%)] Loss: 0.12183 (QuantReg: 10.72118) QuantErr: 10.72118 batch_time=0.65012 
Train Epoch: 14 [232/250 29696/32000 (93%)] Loss: 0.14064 (QuantReg: 10.63638) QuantErr: 10.63638 batch_time=0.64910 
Train Epoch: 14 [243/250 31104/32000 (97%)] Loss: 0.10073 (QuantReg: 10.63356) QuantErr: 10.63356 batch_time=0.64088 
Train Epoch: 14 codebook_update_time=1.75636
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_ActivityNet_bs128/checkpoint-epoch14.pth ...
Done in 4.015s
Updating 'best' checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_ActivityNet_bs128/checkpoint-epoch14.pth ...
Done in 8.496s
removing stale ckpt [epoch 13] [took 0.01s]
 epoch          : 14
 loss           : 0.13446473085880278
 quant_reg      : 10.651949718475342
 quant_err      : 10.651949718475342
 learning_rate  : 1.885747578125e-05
 n_samples      : 448000
 n_steps        : 3500
 ActivityNet_val1_test/t2v_metrics/R1: 17.836078909904412
 ActivityNet_val1_test/t2v_metrics/R5: 47.427293064876956
 ActivityNet_val1_test/t2v_metrics/R10: 64.87695749440716
 ActivityNet_val1_test/t2v_metrics/R50: 90.3396379906447
 ActivityNet_val1_test/t2v_metrics/MedR: 6.0
 ActivityNet_val1_test/t2v_metrics/MeanR: 28.537929631889362
 ActivityNet_val1_test/t2v_metrics/geometric_mean_R1-R5-R10: 38.00196607168883
 ActivityNet_val1_test/v2t_metrics/R1: 18.52755745373195
 ActivityNet_val1_test/v2t_metrics/R5: 48.89160056945292
 ActivityNet_val1_test/v2t_metrics/R10: 66.25991458206224
 ActivityNet_val1_test/v2t_metrics/R50: 91.11246695139313
 ActivityNet_val1_test/v2t_metrics/MedR: 6.0
 ActivityNet_val1_test/v2t_metrics/MeanR: 27.04474272930649
 ActivityNet_val1_test/v2t_metrics/geometric_mean_R1-R5-R10: 39.15324528445985
 mnt_best       : 38.00196607168883
 not_improved_count: 0
Train Epoch: 15 [1/250 128/32000 (0%)] Loss: 0.09400 (QuantReg: 10.74126) QuantErr: 10.74126 batch_time=21.81631 
Train Epoch: 15 [12/250 1536/32000 (5%)] Loss: 0.13460 (QuantReg: 10.60012) QuantErr: 10.60012 batch_time=0.64589 
Train Epoch: 15 [23/250 2944/32000 (9%)] Loss: 0.12912 (QuantReg: 10.55435) QuantErr: 10.55435 batch_time=0.65431 
Train Epoch: 15 [34/250 4352/32000 (14%)] Loss: 0.09798 (QuantReg: 10.42793) QuantErr: 10.42793 batch_time=0.65182 
Train Epoch: 15 [45/250 5760/32000 (18%)] Loss: 0.10553 (QuantReg: 10.47609) QuantErr: 10.47609 batch_time=0.65011 
Train Epoch: 15 [56/250 7168/32000 (22%)] Loss: 0.14913 (QuantReg: 10.53494) QuantErr: 10.53494 batch_time=0.64973 
Train Epoch: 15 [67/250 8576/32000 (27%)] Loss: 0.17091 (QuantReg: 10.73915) QuantErr: 10.73915 batch_time=0.64263 
Train Epoch: 15 [78/250 9984/32000 (31%)] Loss: 0.12606 (QuantReg: 10.65842) QuantErr: 10.65842 batch_time=0.64360 
Train Epoch: 15 [89/250 11392/32000 (36%)] Loss: 0.11260 (QuantReg: 10.61797) QuantErr: 10.61797 batch_time=0.64594 
Train Epoch: 15 [100/250 12800/32000 (40%)] Loss: 0.13208 (QuantReg: 10.31634) QuantErr: 10.31634 batch_time=0.66168 
Train Epoch: 15 [111/250 14208/32000 (44%)] Loss: 0.15677 (QuantReg: 10.44209) QuantErr: 10.44209 batch_time=0.66358 
Train Epoch: 15 [122/250 15616/32000 (49%)] Loss: 0.18374 (QuantReg: 10.46926) QuantErr: 10.46926 batch_time=0.65534 
Train Epoch: 15 [133/250 17024/32000 (53%)] Loss: 0.11717 (QuantReg: 10.77343) QuantErr: 10.77343 batch_time=1.63035 
Train Epoch: 15 [144/250 18432/32000 (58%)] Loss: 0.09925 (QuantReg: 10.45994) QuantErr: 10.45994 batch_time=0.67734 
Train Epoch: 15 [155/250 19840/32000 (62%)] Loss: 0.09488 (QuantReg: 10.49052) QuantErr: 10.49052 batch_time=0.67004 
Train Epoch: 15 [166/250 21248/32000 (66%)] Loss: 0.14676 (QuantReg: 10.68024) QuantErr: 10.68024 batch_time=0.65029 
Train Epoch: 15 [177/250 22656/32000 (71%)] Loss: 0.17554 (QuantReg: 10.47120) QuantErr: 10.47120 batch_time=0.71788 
Train Epoch: 15 [188/250 24064/32000 (75%)] Loss: 0.08354 (QuantReg: 10.67948) QuantErr: 10.67948 batch_time=0.65136 
Train Epoch: 15 [199/250 25472/32000 (80%)] Loss: 0.11912 (QuantReg: 10.36714) QuantErr: 10.36714 batch_time=0.66615 
Train Epoch: 15 [210/250 26880/32000 (84%)] Loss: 0.10687 (QuantReg: 10.41367) QuantErr: 10.41367 batch_time=0.66130 
Train Epoch: 15 [221/250 28288/32000 (88%)] Loss: 0.14848 (QuantReg: 10.48195) QuantErr: 10.48195 batch_time=0.69512 
Train Epoch: 15 [232/250 29696/32000 (93%)] Loss: 0.12383 (QuantReg: 10.52368) QuantErr: 10.52368 batch_time=0.64728 
Train Epoch: 15 [243/250 31104/32000 (97%)] Loss: 0.13091 (QuantReg: 10.45149) QuantErr: 10.45149 batch_time=0.64229 
Train Epoch: 15 codebook_update_time=2.24740
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_ActivityNet_bs128/checkpoint-epoch15.pth ...
Done in 4.633s
Updating 'best' checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_ActivityNet_bs128/checkpoint-epoch15.pth ...
Done in 9.518s
removing stale ckpt [epoch 14] [took 0.11s]
 epoch          : 15
 loss           : 0.12723694437742233
 quant_reg      : 10.585981769561768
 quant_err      : 10.585981769561768
 learning_rate  : 1.6028854414062497e-05
 n_samples      : 480000
 n_steps        : 3750
 ActivityNet_val1_test/t2v_metrics/R1: 17.81574130567419
 ActivityNet_val1_test/t2v_metrics/R5: 47.87472035794183
 ActivityNet_val1_test/t2v_metrics/R10: 64.85661989017694
 ActivityNet_val1_test/t2v_metrics/R50: 90.46166361602603
 ActivityNet_val1_test/t2v_metrics/MedR: 6.0
 ActivityNet_val1_test/t2v_metrics/MeanR: 28.783201138905838
 ActivityNet_val1_test/t2v_metrics/geometric_mean_R1-R5-R10: 38.1026182596942
 ActivityNet_val1_test/v2t_metrics/R1: 18.568232662192393
 ActivityNet_val1_test/v2t_metrics/R5: 48.830587756762256
 ActivityNet_val1_test/v2t_metrics/R10: 66.64632906243645
 ActivityNet_val1_test/v2t_metrics/R50: 91.1734797640838
 ActivityNet_val1_test/v2t_metrics/MedR: 6.0
 ActivityNet_val1_test/v2t_metrics/MeanR: 27.76428716697173
 ActivityNet_val1_test/v2t_metrics/geometric_mean_R1-R5-R10: 39.241558868111596
 mnt_best       : 38.1026182596942
 not_improved_count: 0
Train Epoch: 16 [1/250 128/32000 (0%)] Loss: 0.11937 (QuantReg: 10.56717) QuantErr: 10.56717 batch_time=22.35816 
Train Epoch: 16 [12/250 1536/32000 (5%)] Loss: 0.09494 (QuantReg: 10.64229) QuantErr: 10.64229 batch_time=0.68825 
Train Epoch: 16 [23/250 2944/32000 (9%)] Loss: 0.08349 (QuantReg: 10.54766) QuantErr: 10.54766 batch_time=1.20460 
Train Epoch: 16 [34/250 4352/32000 (14%)] Loss: 0.15114 (QuantReg: 10.55434) QuantErr: 10.55434 batch_time=0.64986 
Train Epoch: 16 [45/250 5760/32000 (18%)] Loss: 0.09151 (QuantReg: 10.76358) QuantErr: 10.76358 batch_time=0.66915 
Train Epoch: 16 [56/250 7168/32000 (22%)] Loss: 0.08387 (QuantReg: 10.55905) QuantErr: 10.55905 batch_time=0.66163 
Train Epoch: 16 [67/250 8576/32000 (27%)] Loss: 0.12246 (QuantReg: 10.61885) QuantErr: 10.61885 batch_time=0.63415 
Train Epoch: 16 [78/250 9984/32000 (31%)] Loss: 0.12277 (QuantReg: 10.40690) QuantErr: 10.40690 batch_time=0.65036 
Train Epoch: 16 [89/250 11392/32000 (36%)] Loss: 0.13384 (QuantReg: 10.55587) QuantErr: 10.55587 batch_time=0.65897 
Train Epoch: 16 [100/250 12800/32000 (40%)] Loss: 0.17178 (QuantReg: 10.33397) QuantErr: 10.33397 batch_time=0.65324 
Train Epoch: 16 [111/250 14208/32000 (44%)] Loss: 0.12512 (QuantReg: 10.45475) QuantErr: 10.45475 batch_time=0.64614 
Train Epoch: 16 [122/250 15616/32000 (49%)] Loss: 0.13899 (QuantReg: 10.56851) QuantErr: 10.56851 batch_time=0.66849 
Train Epoch: 16 [133/250 17024/32000 (53%)] Loss: 0.10341 (QuantReg: 10.32651) QuantErr: 10.32651 batch_time=0.66194 
Train Epoch: 16 [144/250 18432/32000 (58%)] Loss: 0.10165 (QuantReg: 10.67988) QuantErr: 10.67988 batch_time=0.64283 
Train Epoch: 16 [155/250 19840/32000 (62%)] Loss: 0.10439 (QuantReg: 10.51468) QuantErr: 10.51468 batch_time=0.66376 
Train Epoch: 16 [166/250 21248/32000 (66%)] Loss: 0.16959 (QuantReg: 10.39988) QuantErr: 10.39988 batch_time=0.65380 
Train Epoch: 16 [177/250 22656/32000 (71%)] Loss: 0.09180 (QuantReg: 10.39494) QuantErr: 10.39494 batch_time=0.67310 
Train Epoch: 16 [188/250 24064/32000 (75%)] Loss: 0.10603 (QuantReg: 10.57636) QuantErr: 10.57636 batch_time=0.64795 
Train Epoch: 16 [199/250 25472/32000 (80%)] Loss: 0.11025 (QuantReg: 10.56029) QuantErr: 10.56029 batch_time=0.66087 
Train Epoch: 16 [210/250 26880/32000 (84%)] Loss: 0.16243 (QuantReg: 10.50099) QuantErr: 10.50099 batch_time=0.66076 
Train Epoch: 16 [221/250 28288/32000 (88%)] Loss: 0.08698 (QuantReg: 10.43562) QuantErr: 10.43562 batch_time=0.66679 
Train Epoch: 16 [232/250 29696/32000 (93%)] Loss: 0.09379 (QuantReg: 10.70445) QuantErr: 10.70445 batch_time=0.65475 
Train Epoch: 16 [243/250 31104/32000 (97%)] Loss: 0.09670 (QuantReg: 10.60090) QuantErr: 10.60090 batch_time=0.66198 
Train Epoch: 16 codebook_update_time=1.88869
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_ActivityNet_bs128/checkpoint-epoch16.pth ...
Done in 6.099s
Updating 'best' checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_ActivityNet_bs128/checkpoint-epoch16.pth ...
Done in 11.814s
removing stale ckpt [epoch 15] [took 0.08s]
 epoch          : 16
 loss           : 0.12433208328485489
 quant_reg      : 10.54029502105713
 quant_err      : 10.54029502105713
 learning_rate  : 1.6028854414062497e-05
 n_samples      : 512000
 n_steps        : 4000
 ActivityNet_val1_test/t2v_metrics/R1: 18.303843807199513
 ActivityNet_val1_test/t2v_metrics/R5: 48.38316046369738
 ActivityNet_val1_test/t2v_metrics/R10: 64.93797030709783
 ActivityNet_val1_test/t2v_metrics/R50: 90.03457392719137
 ActivityNet_val1_test/t2v_metrics/MedR: 6.0
 ActivityNet_val1_test/t2v_metrics/MeanR: 29.68964815944682
 ActivityNet_val1_test/t2v_metrics/geometric_mean_R1-R5-R10: 38.59920990028789
 ActivityNet_val1_test/v2t_metrics/R1: 18.486882245271506
 ActivityNet_val1_test/v2t_metrics/R5: 49.76611755135245
 ActivityNet_val1_test/v2t_metrics/R10: 66.91071791742932
 ActivityNet_val1_test/v2t_metrics/R50: 90.86841570063046
 ActivityNet_val1_test/v2t_metrics/MedR: 6.0
 ActivityNet_val1_test/v2t_metrics/MeanR: 28.33109619686801
 ActivityNet_val1_test/v2t_metrics/geometric_mean_R1-R5-R10: 39.48489994855078
 mnt_best       : 38.59920990028789
 not_improved_count: 0
Train Epoch: 17 [1/250 128/32000 (0%)] Loss: 0.11109 (QuantReg: 10.59993) QuantErr: 10.59993 batch_time=23.02203 
Train Epoch: 17 [12/250 1536/32000 (5%)] Loss: 0.13267 (QuantReg: 10.57943) QuantErr: 10.57943 batch_time=0.64465 
Train Epoch: 17 [23/250 2944/32000 (9%)] Loss: 0.10759 (QuantReg: 10.51055) QuantErr: 10.51055 batch_time=4.67424 
Train Epoch: 17 [34/250 4352/32000 (14%)] Loss: 0.12218 (QuantReg: 10.55581) QuantErr: 10.55581 batch_time=0.68130 
Train Epoch: 17 [45/250 5760/32000 (18%)] Loss: 0.10600 (QuantReg: 10.16763) QuantErr: 10.16763 batch_time=0.65665 
Train Epoch: 17 [56/250 7168/32000 (22%)] Loss: 0.09400 (QuantReg: 10.46909) QuantErr: 10.46909 batch_time=0.65255 
Train Epoch: 17 [67/250 8576/32000 (27%)] Loss: 0.11227 (QuantReg: 10.28705) QuantErr: 10.28705 batch_time=0.64528 
Train Epoch: 17 [78/250 9984/32000 (31%)] Loss: 0.13798 (QuantReg: 10.44706) QuantErr: 10.44706 batch_time=0.64231 
Train Epoch: 17 [89/250 11392/32000 (36%)] Loss: 0.09692 (QuantReg: 10.43073) QuantErr: 10.43073 batch_time=0.65394 
Train Epoch: 17 [100/250 12800/32000 (40%)] Loss: 0.12683 (QuantReg: 10.41608) QuantErr: 10.41608 batch_time=0.67993 
Train Epoch: 17 [111/250 14208/32000 (44%)] Loss: 0.09871 (QuantReg: 10.38634) QuantErr: 10.38634 batch_time=0.68282 
Train Epoch: 17 [122/250 15616/32000 (49%)] Loss: 0.15572 (QuantReg: 10.31833) QuantErr: 10.31833 batch_time=0.65696 
Train Epoch: 17 [133/250 17024/32000 (53%)] Loss: 0.10148 (QuantReg: 10.45290) QuantErr: 10.45290 batch_time=0.66576 
Train Epoch: 17 [144/250 18432/32000 (58%)] Loss: 0.11193 (QuantReg: 10.60916) QuantErr: 10.60916 batch_time=1.08527 
Train Epoch: 17 [155/250 19840/32000 (62%)] Loss: 0.08147 (QuantReg: 10.62315) QuantErr: 10.62315 batch_time=0.63900 
Train Epoch: 17 [166/250 21248/32000 (66%)] Loss: 0.09474 (QuantReg: 10.60581) QuantErr: 10.60581 batch_time=0.64149 
Train Epoch: 17 [177/250 22656/32000 (71%)] Loss: 0.17566 (QuantReg: 10.34274) QuantErr: 10.34274 batch_time=0.65383 
Train Epoch: 17 [188/250 24064/32000 (75%)] Loss: 0.09833 (QuantReg: 10.27898) QuantErr: 10.27898 batch_time=0.64256 
Train Epoch: 17 [199/250 25472/32000 (80%)] Loss: 0.12595 (QuantReg: 10.40472) QuantErr: 10.40472 batch_time=1.42611 
Train Epoch: 17 [210/250 26880/32000 (84%)] Loss: 0.12424 (QuantReg: 10.44755) QuantErr: 10.44755 batch_time=0.70554 
Train Epoch: 17 [221/250 28288/32000 (88%)] Loss: 0.12133 (QuantReg: 10.62668) QuantErr: 10.62668 batch_time=0.65315 
Train Epoch: 17 [232/250 29696/32000 (93%)] Loss: 0.10771 (QuantReg: 10.43473) QuantErr: 10.43473 batch_time=0.96554 
Train Epoch: 17 [243/250 31104/32000 (97%)] Loss: 0.13022 (QuantReg: 10.36958) QuantErr: 10.36958 batch_time=0.67845 
Train Epoch: 17 codebook_update_time=1.87759
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_ActivityNet_bs128/checkpoint-epoch17.pth ...
Done in 5.014s
Updating 'best' checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_ActivityNet_bs128/checkpoint-epoch17.pth ...
Done in 10.417s
removing stale ckpt [epoch 16] [took 0.07s]
 epoch          : 17
 loss           : 0.11971532887220383
 quant_reg      : 10.46480778503418
 quant_err      : 10.46480778503418
 learning_rate  : 1.3624526251953122e-05
 n_samples      : 544000
 n_steps        : 4250
 ActivityNet_val1_test/t2v_metrics/R1: 18.446207036811064
 ActivityNet_val1_test/t2v_metrics/R5: 48.240797234085825
 ActivityNet_val1_test/t2v_metrics/R10: 65.16168395363026
 ActivityNet_val1_test/t2v_metrics/R50: 90.29896278218426
 ActivityNet_val1_test/t2v_metrics/MedR: 6.0
 ActivityNet_val1_test/t2v_metrics/MeanR: 30.402481187716088
 ActivityNet_val1_test/t2v_metrics/geometric_mean_R1-R5-R10: 38.7053754684394
 ActivityNet_val1_test/v2t_metrics/R1: 19.178360789099045
 ActivityNet_val1_test/v2t_metrics/R5: 49.50172869635957
 ActivityNet_val1_test/v2t_metrics/R10: 66.46329062436445
 ActivityNet_val1_test/v2t_metrics/R50: 90.74639007524914
 ActivityNet_val1_test/v2t_metrics/MedR: 6.0
 ActivityNet_val1_test/v2t_metrics/MeanR: 28.88427903193004
 ActivityNet_val1_test/v2t_metrics/geometric_mean_R1-R5-R10: 39.81113535562355
 mnt_best       : 38.7053754684394
 not_improved_count: 0
Train Epoch: 18 [1/250 128/32000 (0%)] Loss: 0.08343 (QuantReg: 10.31499) QuantErr: 10.31499 batch_time=24.63652 
Train Epoch: 18 [12/250 1536/32000 (5%)] Loss: 0.13665 (QuantReg: 10.22870) QuantErr: 10.22870 batch_time=0.63906 
Train Epoch: 18 [23/250 2944/32000 (9%)] Loss: 0.11111 (QuantReg: 10.17742) QuantErr: 10.17742 batch_time=2.27750 
Train Epoch: 18 [34/250 4352/32000 (14%)] Loss: 0.11123 (QuantReg: 10.43421) QuantErr: 10.43421 batch_time=0.64327 
Train Epoch: 18 [45/250 5760/32000 (18%)] Loss: 0.10897 (QuantReg: 10.62097) QuantErr: 10.62097 batch_time=0.64173 
Train Epoch: 18 [56/250 7168/32000 (22%)] Loss: 0.11511 (QuantReg: 10.30744) QuantErr: 10.30744 batch_time=0.66012 
Train Epoch: 18 [67/250 8576/32000 (27%)] Loss: 0.11727 (QuantReg: 10.52980) QuantErr: 10.52980 batch_time=1.41768 
Train Epoch: 18 [78/250 9984/32000 (31%)] Loss: 0.09312 (QuantReg: 10.52608) QuantErr: 10.52608 batch_time=0.64254 
Train Epoch: 18 [89/250 11392/32000 (36%)] Loss: 0.08157 (QuantReg: 10.25451) QuantErr: 10.25451 batch_time=0.65308 
Train Epoch: 18 [100/250 12800/32000 (40%)] Loss: 0.07537 (QuantReg: 10.51247) QuantErr: 10.51247 batch_time=0.66148 
Train Epoch: 18 [111/250 14208/32000 (44%)] Loss: 0.11316 (QuantReg: 10.22009) QuantErr: 10.22009 batch_time=0.68328 
Train Epoch: 18 [122/250 15616/32000 (49%)] Loss: 0.11599 (QuantReg: 10.35986) QuantErr: 10.35986 batch_time=0.65247 
Train Epoch: 18 [133/250 17024/32000 (53%)] Loss: 0.17772 (QuantReg: 10.43071) QuantErr: 10.43071 batch_time=0.66208 
Train Epoch: 18 [144/250 18432/32000 (58%)] Loss: 0.13594 (QuantReg: 10.34782) QuantErr: 10.34782 batch_time=0.88538 
Train Epoch: 18 [155/250 19840/32000 (62%)] Loss: 0.10070 (QuantReg: 10.27641) QuantErr: 10.27641 batch_time=0.65881 
Train Epoch: 18 [166/250 21248/32000 (66%)] Loss: 0.12114 (QuantReg: 10.29175) QuantErr: 10.29175 batch_time=0.64477 
Train Epoch: 18 [177/250 22656/32000 (71%)] Loss: 0.13449 (QuantReg: 10.42731) QuantErr: 10.42731 batch_time=0.64999 
Train Epoch: 18 [188/250 24064/32000 (75%)] Loss: 0.13059 (QuantReg: 10.47486) QuantErr: 10.47486 batch_time=0.64651 
Train Epoch: 18 [199/250 25472/32000 (80%)] Loss: 0.08842 (QuantReg: 10.43710) QuantErr: 10.43710 batch_time=0.63586 
Train Epoch: 18 [210/250 26880/32000 (84%)] Loss: 0.13959 (QuantReg: 10.46580) QuantErr: 10.46580 batch_time=1.72910 
Train Epoch: 18 [221/250 28288/32000 (88%)] Loss: 0.12818 (QuantReg: 10.28916) QuantErr: 10.28916 batch_time=2.44964 
Train Epoch: 18 [232/250 29696/32000 (93%)] Loss: 0.10675 (QuantReg: 10.29477) QuantErr: 10.29477 batch_time=0.65000 
Train Epoch: 18 [243/250 31104/32000 (97%)] Loss: 0.08286 (QuantReg: 10.29215) QuantErr: 10.29215 batch_time=0.65075 
Train Epoch: 18 codebook_update_time=1.74497
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_ActivityNet_bs128/checkpoint-epoch18.pth ...
Done in 4.591s
removing stale ckpt [epoch 17] [took 0.01s]
 epoch          : 18
 loss           : 0.11488990464806556
 quant_reg      : 10.397148376464843
 quant_err      : 10.397148376464843
 learning_rate  : 1.3624526251953122e-05
 n_samples      : 576000
 n_steps        : 4500
 ActivityNet_val1_test/t2v_metrics/R1: 18.425869432580843
 ActivityNet_val1_test/t2v_metrics/R5: 48.505186089078705
 ActivityNet_val1_test/t2v_metrics/R10: 64.75493186902582
 ActivityNet_val1_test/t2v_metrics/R50: 90.2379499694936
 ActivityNet_val1_test/t2v_metrics/MedR: 6.0
 ActivityNet_val1_test/t2v_metrics/MeanR: 30.149074639007527
 ActivityNet_val1_test/t2v_metrics/geometric_mean_R1-R5-R10: 38.68087933923349
 ActivityNet_val1_test/v2t_metrics/R1: 19.402074435631484
 ActivityNet_val1_test/v2t_metrics/R5: 49.847467968273335
 ActivityNet_val1_test/v2t_metrics/R10: 65.81248728899736
 ActivityNet_val1_test/v2t_metrics/R50: 90.68537726255848
 ActivityNet_val1_test/v2t_metrics/MedR: 6.0
 ActivityNet_val1_test/v2t_metrics/MeanR: 29.25218629245475
 ActivityNet_val1_test/v2t_metrics/geometric_mean_R1-R5-R10: 39.926985740282795
 mnt_best       : 38.7053754684394
 not_improved_count: 1
Train Epoch: 19 [1/250 128/32000 (0%)] Loss: 0.12944 (QuantReg: 10.35297) QuantErr: 10.35297 batch_time=21.23902 
Train Epoch: 19 [12/250 1536/32000 (5%)] Loss: 0.14680 (QuantReg: 10.33442) QuantErr: 10.33442 batch_time=0.64920 
Train Epoch: 19 [23/250 2944/32000 (9%)] Loss: 0.12708 (QuantReg: 10.31906) QuantErr: 10.31906 batch_time=0.65747 
Train Epoch: 19 [34/250 4352/32000 (14%)] Loss: 0.13086 (QuantReg: 10.25302) QuantErr: 10.25302 batch_time=0.66904 
Train Epoch: 19 [45/250 5760/32000 (18%)] Loss: 0.12901 (QuantReg: 10.30415) QuantErr: 10.30415 batch_time=0.64575 
Train Epoch: 19 [56/250 7168/32000 (22%)] Loss: 0.12903 (QuantReg: 10.48188) QuantErr: 10.48188 batch_time=0.64089 
Train Epoch: 19 [67/250 8576/32000 (27%)] Loss: 0.09831 (QuantReg: 10.46824) QuantErr: 10.46824 batch_time=0.66213 
Train Epoch: 19 [78/250 9984/32000 (31%)] Loss: 0.09321 (QuantReg: 10.46529) QuantErr: 10.46529 batch_time=0.63914 
Train Epoch: 19 [89/250 11392/32000 (36%)] Loss: 0.08569 (QuantReg: 10.35979) QuantErr: 10.35979 batch_time=0.65360 
Train Epoch: 19 [100/250 12800/32000 (40%)] Loss: 0.13623 (QuantReg: 10.34992) QuantErr: 10.34992 batch_time=0.65480 
Train Epoch: 19 [111/250 14208/32000 (44%)] Loss: 0.09203 (QuantReg: 10.17803) QuantErr: 10.17803 batch_time=0.64270 
Train Epoch: 19 [122/250 15616/32000 (49%)] Loss: 0.08775 (QuantReg: 10.28996) QuantErr: 10.28996 batch_time=0.64603 
Train Epoch: 19 [133/250 17024/32000 (53%)] Loss: 0.14226 (QuantReg: 10.29826) QuantErr: 10.29826 batch_time=0.64548 
Train Epoch: 19 [144/250 18432/32000 (58%)] Loss: 0.12823 (QuantReg: 10.36983) QuantErr: 10.36983 batch_time=0.66819 
Train Epoch: 19 [155/250 19840/32000 (62%)] Loss: 0.09691 (QuantReg: 10.39418) QuantErr: 10.39418 batch_time=0.64715 
Train Epoch: 19 [166/250 21248/32000 (66%)] Loss: 0.07929 (QuantReg: 10.46517) QuantErr: 10.46517 batch_time=0.63900 
Train Epoch: 19 [177/250 22656/32000 (71%)] Loss: 0.11586 (QuantReg: 10.29710) QuantErr: 10.29710 batch_time=1.56641 
Train Epoch: 19 [188/250 24064/32000 (75%)] Loss: 0.11213 (QuantReg: 10.42791) QuantErr: 10.42791 batch_time=0.64159 
Train Epoch: 19 [199/250 25472/32000 (80%)] Loss: 0.11417 (QuantReg: 10.34027) QuantErr: 10.34027 batch_time=0.63984 
Train Epoch: 19 [210/250 26880/32000 (84%)] Loss: 0.14986 (QuantReg: 10.16006) QuantErr: 10.16006 batch_time=0.65157 
Train Epoch: 19 [221/250 28288/32000 (88%)] Loss: 0.12525 (QuantReg: 10.37715) QuantErr: 10.37715 batch_time=0.68427 
Train Epoch: 19 [232/250 29696/32000 (93%)] Loss: 0.09619 (QuantReg: 10.37251) QuantErr: 10.37251 batch_time=0.65898 
Train Epoch: 19 [243/250 31104/32000 (97%)] Loss: 0.07971 (QuantReg: 10.30872) QuantErr: 10.30872 batch_time=0.67765 
Train Epoch: 19 codebook_update_time=1.79053
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_ActivityNet_bs128/checkpoint-epoch19.pth ...
Done in 4.323s
removing stale ckpt [epoch 18] [took 0.02s]
 epoch          : 19
 loss           : 0.11110387647151947
 quant_reg      : 10.327787311553955
 quant_err      : 10.327787311553955
 learning_rate  : 1.1580847314160154e-05
 n_samples      : 608000
 n_steps        : 4750
 ActivityNet_val1_test/t2v_metrics/R1: 18.385194224120397
 ActivityNet_val1_test/t2v_metrics/R5: 48.11877160870449
 ActivityNet_val1_test/t2v_metrics/R10: 65.18202155786048
 ActivityNet_val1_test/t2v_metrics/R50: 89.44478340451495
 ActivityNet_val1_test/t2v_metrics/MedR: 6.0
 ActivityNet_val1_test/t2v_metrics/MeanR: 32.001830384380725
 ActivityNet_val1_test/t2v_metrics/geometric_mean_R1-R5-R10: 38.634046060273356
 ActivityNet_val1_test/v2t_metrics/R1: 19.056335163717716
 ActivityNet_val1_test/v2t_metrics/R5: 49.42037827943868
 ActivityNet_val1_test/v2t_metrics/R10: 65.99552572706935
 ActivityNet_val1_test/v2t_metrics/R50: 90.3396379906447
 ActivityNet_val1_test/v2t_metrics/MedR: 6.0
 ActivityNet_val1_test/v2t_metrics/MeanR: 30.01464307504576
 ActivityNet_val1_test/v2t_metrics/geometric_mean_R1-R5-R10: 39.6113806773283
 mnt_best       : 38.7053754684394
 not_improved_count: 2
Train Epoch: 20 [1/250 128/32000 (0%)] Loss: 0.10755 (QuantReg: 10.12301) QuantErr: 10.12301 batch_time=21.15674 
Train Epoch: 20 [12/250 1536/32000 (5%)] Loss: 0.09604 (QuantReg: 10.28484) QuantErr: 10.28484 batch_time=0.64244 
Train Epoch: 20 [23/250 2944/32000 (9%)] Loss: 0.08679 (QuantReg: 10.29968) QuantErr: 10.29968 batch_time=0.64798 
Train Epoch: 20 [34/250 4352/32000 (14%)] Loss: 0.07810 (QuantReg: 10.18374) QuantErr: 10.18374 batch_time=0.64483 
Train Epoch: 20 [45/250 5760/32000 (18%)] Loss: 0.11974 (QuantReg: 10.31605) QuantErr: 10.31605 batch_time=0.65669 
Train Epoch: 20 [56/250 7168/32000 (22%)] Loss: 0.14159 (QuantReg: 10.16703) QuantErr: 10.16703 batch_time=0.63912 
Train Epoch: 20 [67/250 8576/32000 (27%)] Loss: 0.07338 (QuantReg: 10.26547) QuantErr: 10.26547 batch_time=0.76930 
Train Epoch: 20 [78/250 9984/32000 (31%)] Loss: 0.09360 (QuantReg: 10.32840) QuantErr: 10.32840 batch_time=0.65445 
Train Epoch: 20 [89/250 11392/32000 (36%)] Loss: 0.08442 (QuantReg: 10.33978) QuantErr: 10.33978 batch_time=0.66511 
Train Epoch: 20 [100/250 12800/32000 (40%)] Loss: 0.12729 (QuantReg: 10.25944) QuantErr: 10.25944 batch_time=0.65368 
Train Epoch: 20 [111/250 14208/32000 (44%)] Loss: 0.13973 (QuantReg: 10.15591) QuantErr: 10.15591 batch_time=0.64365 
Train Epoch: 20 [122/250 15616/32000 (49%)] Loss: 0.10686 (QuantReg: 10.25356) QuantErr: 10.25356 batch_time=0.64853 
Train Epoch: 20 [133/250 17024/32000 (53%)] Loss: 0.11247 (QuantReg: 10.32759) QuantErr: 10.32759 batch_time=0.64676 
Train Epoch: 20 [144/250 18432/32000 (58%)] Loss: 0.09960 (QuantReg: 10.27739) QuantErr: 10.27739 batch_time=0.65731 
Train Epoch: 20 [155/250 19840/32000 (62%)] Loss: 0.09851 (QuantReg: 10.12737) QuantErr: 10.12737 batch_time=0.64634 
Train Epoch: 20 [166/250 21248/32000 (66%)] Loss: 0.11024 (QuantReg: 10.21363) QuantErr: 10.21363 batch_time=0.65083 
Train Epoch: 20 [177/250 22656/32000 (71%)] Loss: 0.11154 (QuantReg: 10.17082) QuantErr: 10.17082 batch_time=0.66515 
Train Epoch: 20 [188/250 24064/32000 (75%)] Loss: 0.07956 (QuantReg: 10.08311) QuantErr: 10.08311 batch_time=0.70735 
Train Epoch: 20 [199/250 25472/32000 (80%)] Loss: 0.13300 (QuantReg: 10.09925) QuantErr: 10.09925 batch_time=0.64116 
Train Epoch: 20 [210/250 26880/32000 (84%)] Loss: 0.10290 (QuantReg: 10.14127) QuantErr: 10.14127 batch_time=0.82358 
Train Epoch: 20 [221/250 28288/32000 (88%)] Loss: 0.11486 (QuantReg: 10.31466) QuantErr: 10.31466 batch_time=0.64463 
Train Epoch: 20 [232/250 29696/32000 (93%)] Loss: 0.08704 (QuantReg: 10.23205) QuantErr: 10.23205 batch_time=2.25997 
Train Epoch: 20 [243/250 31104/32000 (97%)] Loss: 0.16980 (QuantReg: 10.22361) QuantErr: 10.22361 batch_time=0.69767 
Train Epoch: 20 codebook_update_time=2.30293
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_ActivityNet_bs128/checkpoint-epoch20.pth ...
Done in 4.427s
removing stale ckpt [epoch 19] [took 0.06s]
 epoch          : 20
 loss           : 0.10688324847817421
 quant_reg      : 10.247306949615478
 quant_err      : 10.247306949615478
 learning_rate  : 1.1580847314160154e-05
 n_samples      : 640000
 n_steps        : 5000
 ActivityNet_val1_test/t2v_metrics/R1: 18.486882245271506
 ActivityNet_val1_test/t2v_metrics/R5: 48.240797234085825
 ActivityNet_val1_test/t2v_metrics/R10: 64.5312182224934
 ActivityNet_val1_test/t2v_metrics/R50: 89.7701850721985
 ActivityNet_val1_test/t2v_metrics/MedR: 6.0
 ActivityNet_val1_test/t2v_metrics/MeanR: 31.215171852755745
 ActivityNet_val1_test/t2v_metrics/geometric_mean_R1-R5-R10: 38.60847713295036
 ActivityNet_val1_test/v2t_metrics/R1: 19.585112873703476
 ActivityNet_val1_test/v2t_metrics/R5: 50.05084401057555
 ActivityNet_val1_test/v2t_metrics/R10: 66.01586333129957
 ActivityNet_val1_test/v2t_metrics/R50: 90.58368924140736
 ActivityNet_val1_test/v2t_metrics/MedR: 5.0
 ActivityNet_val1_test/v2t_metrics/MeanR: 29.39271913768558
 ActivityNet_val1_test/v2t_metrics/geometric_mean_R1-R5-R10: 40.1478164991343
 mnt_best       : 38.7053754684394
 not_improved_count: 3
Train Epoch: 21 [1/250 128/32000 (0%)] Loss: 0.09130 (QuantReg: 10.19548) QuantErr: 10.19548 batch_time=22.97376 
Train Epoch: 21 [12/250 1536/32000 (5%)] Loss: 0.07806 (QuantReg: 10.03920) QuantErr: 10.03920 batch_time=0.71023 
Train Epoch: 21 [23/250 2944/32000 (9%)] Loss: 0.10901 (QuantReg: 10.21644) QuantErr: 10.21644 batch_time=0.69913 
Train Epoch: 21 [34/250 4352/32000 (14%)] Loss: 0.14325 (QuantReg: 10.15640) QuantErr: 10.15640 batch_time=0.71396 
Train Epoch: 21 [45/250 5760/32000 (18%)] Loss: 0.09033 (QuantReg: 10.27629) QuantErr: 10.27629 batch_time=0.68681 
Train Epoch: 21 [56/250 7168/32000 (22%)] Loss: 0.08784 (QuantReg: 10.20440) QuantErr: 10.20440 batch_time=0.64237 
Train Epoch: 21 [67/250 8576/32000 (27%)] Loss: 0.08333 (QuantReg: 10.11528) QuantErr: 10.11528 batch_time=0.65872 
Train Epoch: 21 [78/250 9984/32000 (31%)] Loss: 0.11352 (QuantReg: 10.16617) QuantErr: 10.16617 batch_time=0.67697 
Train Epoch: 21 [89/250 11392/32000 (36%)] Loss: 0.10930 (QuantReg: 10.19153) QuantErr: 10.19153 batch_time=0.65340 
Train Epoch: 21 [100/250 12800/32000 (40%)] Loss: 0.14162 (QuantReg: 10.29164) QuantErr: 10.29164 batch_time=0.64343 
Train Epoch: 21 [111/250 14208/32000 (44%)] Loss: 0.09924 (QuantReg: 10.14175) QuantErr: 10.14175 batch_time=0.64926 
Train Epoch: 21 [122/250 15616/32000 (49%)] Loss: 0.10893 (QuantReg: 10.17494) QuantErr: 10.17494 batch_time=0.81915 
Train Epoch: 21 [133/250 17024/32000 (53%)] Loss: 0.08904 (QuantReg: 10.00638) QuantErr: 10.00638 batch_time=4.00357 
Train Epoch: 21 [144/250 18432/32000 (58%)] Loss: 0.09754 (QuantReg: 10.25696) QuantErr: 10.25696 batch_time=0.63627 
Train Epoch: 21 [155/250 19840/32000 (62%)] Loss: 0.12171 (QuantReg: 10.13589) QuantErr: 10.13589 batch_time=1.25981 
Train Epoch: 21 [166/250 21248/32000 (66%)] Loss: 0.12028 (QuantReg: 10.12179) QuantErr: 10.12179 batch_time=0.65180 
Train Epoch: 21 [177/250 22656/32000 (71%)] Loss: 0.12453 (QuantReg: 10.10311) QuantErr: 10.10311 batch_time=0.76347 
Train Epoch: 21 [188/250 24064/32000 (75%)] Loss: 0.11229 (QuantReg: 10.27791) QuantErr: 10.27791 batch_time=0.69819 
Train Epoch: 21 [199/250 25472/32000 (80%)] Loss: 0.17025 (QuantReg: 10.13514) QuantErr: 10.13514 batch_time=0.65773 
Train Epoch: 21 [210/250 26880/32000 (84%)] Loss: 0.06850 (QuantReg: 10.18349) QuantErr: 10.18349 batch_time=4.02883 
Train Epoch: 21 [221/250 28288/32000 (88%)] Loss: 0.11603 (QuantReg: 10.23652) QuantErr: 10.23652 batch_time=0.67554 
Train Epoch: 21 [232/250 29696/32000 (93%)] Loss: 0.10269 (QuantReg: 10.11562) QuantErr: 10.11562 batch_time=0.66756 
Train Epoch: 21 [243/250 31104/32000 (97%)] Loss: 0.13636 (QuantReg: 10.19824) QuantErr: 10.19824 batch_time=0.64698 
Train Epoch: 21 codebook_update_time=1.68890
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_ActivityNet_bs128/checkpoint-epoch21.pth ...
Done in 5.059s
removing stale ckpt [epoch 20] [took 0.32s]
 epoch          : 21
 loss           : 0.10211598910391331
 quant_reg      : 10.174899841308594
 quant_err      : 10.174899841308594
 learning_rate  : 9.843720217036131e-06
 n_samples      : 672000
 n_steps        : 5250
 ActivityNet_val1_test/t2v_metrics/R1: 18.303843807199513
 ActivityNet_val1_test/t2v_metrics/R5: 48.240797234085825
 ActivityNet_val1_test/t2v_metrics/R10: 64.93797030709783
 ActivityNet_val1_test/t2v_metrics/R50: 89.48545861297539
 ActivityNet_val1_test/t2v_metrics/MedR: 6.0
 ActivityNet_val1_test/t2v_metrics/MeanR: 32.500711816148055
 ActivityNet_val1_test/t2v_metrics/geometric_mean_R1-R5-R10: 38.56131443843538
 ActivityNet_val1_test/v2t_metrics/R1: 19.402074435631484
 ActivityNet_val1_test/v2t_metrics/R5: 49.74577994712223
 ActivityNet_val1_test/v2t_metrics/R10: 65.64978645515558
 ActivityNet_val1_test/v2t_metrics/R50: 89.91254830181005
 ActivityNet_val1_test/v2t_metrics/MedR: 6.0
 ActivityNet_val1_test/v2t_metrics/MeanR: 31.079113280455562
 ActivityNet_val1_test/v2t_metrics/geometric_mean_R1-R5-R10: 39.866910043687845
 mnt_best       : 38.7053754684394
 not_improved_count: 4
Train Epoch: 22 [1/250 128/32000 (0%)] Loss: 0.14427 (QuantReg: 10.05605) QuantErr: 10.05605 batch_time=22.86311 
Train Epoch: 22 [12/250 1536/32000 (5%)] Loss: 0.11441 (QuantReg: 10.14585) QuantErr: 10.14585 batch_time=0.65057 
Train Epoch: 22 [23/250 2944/32000 (9%)] Loss: 0.08534 (QuantReg: 10.03412) QuantErr: 10.03412 batch_time=0.66267 
Train Epoch: 22 [34/250 4352/32000 (14%)] Loss: 0.10985 (QuantReg: 10.14683) QuantErr: 10.14683 batch_time=0.69116 
Train Epoch: 22 [45/250 5760/32000 (18%)] Loss: 0.09456 (QuantReg: 10.10018) QuantErr: 10.10018 batch_time=0.65703 
Train Epoch: 22 [56/250 7168/32000 (22%)] Loss: 0.09370 (QuantReg: 9.96409) QuantErr: 9.96409 batch_time=0.67694 
Train Epoch: 22 [67/250 8576/32000 (27%)] Loss: 0.08075 (QuantReg: 10.20208) QuantErr: 10.20208 batch_time=1.69005 
Train Epoch: 22 [78/250 9984/32000 (31%)] Loss: 0.07769 (QuantReg: 10.14632) QuantErr: 10.14632 batch_time=0.65575 
Train Epoch: 22 [89/250 11392/32000 (36%)] Loss: 0.10773 (QuantReg: 10.02390) QuantErr: 10.02390 batch_time=0.64787 
Train Epoch: 22 [100/250 12800/32000 (40%)] Loss: 0.13928 (QuantReg: 10.11124) QuantErr: 10.11124 batch_time=0.65114 
Train Epoch: 22 [111/250 14208/32000 (44%)] Loss: 0.09900 (QuantReg: 10.29277) QuantErr: 10.29277 batch_time=0.95252 
Train Epoch: 22 [122/250 15616/32000 (49%)] Loss: 0.07330 (QuantReg: 10.12113) QuantErr: 10.12113 batch_time=0.69136 
Train Epoch: 22 [133/250 17024/32000 (53%)] Loss: 0.10324 (QuantReg: 10.18222) QuantErr: 10.18222 batch_time=0.65276 
Train Epoch: 22 [144/250 18432/32000 (58%)] Loss: 0.16522 (QuantReg: 10.07362) QuantErr: 10.07362 batch_time=0.65023 
Train Epoch: 22 [155/250 19840/32000 (62%)] Loss: 0.09496 (QuantReg: 9.98901) QuantErr: 9.98901 batch_time=0.69852 
Train Epoch: 22 [166/250 21248/32000 (66%)] Loss: 0.09880 (QuantReg: 10.22016) QuantErr: 10.22016 batch_time=0.66147 
Train Epoch: 22 [177/250 22656/32000 (71%)] Loss: 0.11785 (QuantReg: 10.20996) QuantErr: 10.20996 batch_time=0.64809 
Train Epoch: 22 [188/250 24064/32000 (75%)] Loss: 0.08461 (QuantReg: 10.01182) QuantErr: 10.01182 batch_time=0.65128 
Train Epoch: 22 [199/250 25472/32000 (80%)] Loss: 0.07112 (QuantReg: 10.06055) QuantErr: 10.06055 batch_time=0.68473 
Train Epoch: 22 [210/250 26880/32000 (84%)] Loss: 0.10196 (QuantReg: 10.02701) QuantErr: 10.02701 batch_time=0.63845 
Train Epoch: 22 [221/250 28288/32000 (88%)] Loss: 0.08276 (QuantReg: 9.98932) QuantErr: 9.98932 batch_time=0.64944 
Train Epoch: 22 [232/250 29696/32000 (93%)] Loss: 0.11523 (QuantReg: 10.21549) QuantErr: 10.21549 batch_time=0.64194 
Train Epoch: 22 [243/250 31104/32000 (97%)] Loss: 0.10057 (QuantReg: 10.03502) QuantErr: 10.03502 batch_time=0.64402 
Train Epoch: 22 codebook_update_time=1.73804
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_ActivityNet_bs128/checkpoint-epoch22.pth ...
Done in 4.403s
Updating 'best' checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_ActivityNet_bs128/checkpoint-epoch22.pth ...
Done in 8.957s
removing stale ckpt [epoch 21] [took 0.01s]
 epoch          : 22
 loss           : 0.09878736801445484
 quant_reg      : 10.099211345672607
 quant_err      : 10.099211345672607
 learning_rate  : 9.843720217036131e-06
 n_samples      : 704000
 n_steps        : 5500
 ActivityNet_val1_test/t2v_metrics/R1: 18.79194630872483
 ActivityNet_val1_test/t2v_metrics/R5: 48.34248525523693
 ActivityNet_val1_test/t2v_metrics/R10: 65.2023591620907
 ActivityNet_val1_test/t2v_metrics/R50: 89.81086028065894
 ActivityNet_val1_test/t2v_metrics/MedR: 6.0
 ActivityNet_val1_test/t2v_metrics/MeanR: 32.09436648362823
 ActivityNet_val1_test/t2v_metrics/geometric_mean_R1-R5-R10: 38.98115311901852
 ActivityNet_val1_test/v2t_metrics/R1: 19.890176937156802
 ActivityNet_val1_test/v2t_metrics/R5: 50.091519219035995
 ActivityNet_val1_test/v2t_metrics/R10: 65.93451291437869
 ActivityNet_val1_test/v2t_metrics/R50: 90.03457392719137
 ActivityNet_val1_test/v2t_metrics/MedR: 5.0
 ActivityNet_val1_test/v2t_metrics/MeanR: 30.886922920479968
 ActivityNet_val1_test/v2t_metrics/geometric_mean_R1-R5-R10: 40.34953654298608
 mnt_best       : 38.98115311901852
 not_improved_count: 0
Train Epoch: 23 [1/250 128/32000 (0%)] Loss: 0.11088 (QuantReg: 9.98666) QuantErr: 9.98666 batch_time=25.72250 
Train Epoch: 23 [12/250 1536/32000 (5%)] Loss: 0.07448 (QuantReg: 10.00754) QuantErr: 10.00754 batch_time=0.69155 
Train Epoch: 23 [23/250 2944/32000 (9%)] Loss: 0.15060 (QuantReg: 9.93591) QuantErr: 9.93591 batch_time=0.64950 
Train Epoch: 23 [34/250 4352/32000 (14%)] Loss: 0.12753 (QuantReg: 9.76359) QuantErr: 9.76359 batch_time=0.66792 
Train Epoch: 23 [45/250 5760/32000 (18%)] Loss: 0.09908 (QuantReg: 9.89335) QuantErr: 9.89335 batch_time=0.64853 
Train Epoch: 23 [56/250 7168/32000 (22%)] Loss: 0.07803 (QuantReg: 9.94381) QuantErr: 9.94381 batch_time=0.70924 
Train Epoch: 23 [67/250 8576/32000 (27%)] Loss: 0.07402 (QuantReg: 10.20560) QuantErr: 10.20560 batch_time=0.64977 
Train Epoch: 23 [78/250 9984/32000 (31%)] Loss: 0.09892 (QuantReg: 10.00605) QuantErr: 10.00605 batch_time=0.64581 
Train Epoch: 23 [89/250 11392/32000 (36%)] Loss: 0.07179 (QuantReg: 9.95391) QuantErr: 9.95391 batch_time=0.97911 
Train Epoch: 23 [100/250 12800/32000 (40%)] Loss: 0.07357 (QuantReg: 9.82643) QuantErr: 9.82643 batch_time=0.65505 
Train Epoch: 23 [111/250 14208/32000 (44%)] Loss: 0.09842 (QuantReg: 10.00902) QuantErr: 10.00902 batch_time=0.65031 
Train Epoch: 23 [122/250 15616/32000 (49%)] Loss: 0.07864 (QuantReg: 10.10477) QuantErr: 10.10477 batch_time=0.64567 
Train Epoch: 23 [133/250 17024/32000 (53%)] Loss: 0.08062 (QuantReg: 9.92269) QuantErr: 9.92269 batch_time=0.65283 
Train Epoch: 23 [144/250 18432/32000 (58%)] Loss: 0.06783 (QuantReg: 9.94991) QuantErr: 9.94991 batch_time=3.24152 
Train Epoch: 23 [155/250 19840/32000 (62%)] Loss: 0.09855 (QuantReg: 10.06427) QuantErr: 10.06427 batch_time=0.65377 
Train Epoch: 23 [166/250 21248/32000 (66%)] Loss: 0.06005 (QuantReg: 9.89289) QuantErr: 9.89289 batch_time=0.64667 
Train Epoch: 23 [177/250 22656/32000 (71%)] Loss: 0.10303 (QuantReg: 10.10592) QuantErr: 10.10592 batch_time=0.64715 
Train Epoch: 23 [188/250 24064/32000 (75%)] Loss: 0.08639 (QuantReg: 9.94547) QuantErr: 9.94547 batch_time=0.66788 
Train Epoch: 23 [199/250 25472/32000 (80%)] Loss: 0.11974 (QuantReg: 10.07245) QuantErr: 10.07245 batch_time=0.77146 
Train Epoch: 23 [210/250 26880/32000 (84%)] Loss: 0.12629 (QuantReg: 9.95946) QuantErr: 9.95946 batch_time=0.65414 
Train Epoch: 23 [221/250 28288/32000 (88%)] Loss: 0.16618 (QuantReg: 10.06092) QuantErr: 10.06092 batch_time=0.64400 
Train Epoch: 23 [232/250 29696/32000 (93%)] Loss: 0.14916 (QuantReg: 10.12642) QuantErr: 10.12642 batch_time=0.69193 
Train Epoch: 23 [243/250 31104/32000 (97%)] Loss: 0.07659 (QuantReg: 9.94170) QuantErr: 9.94170 batch_time=0.89798 
Train Epoch: 23 codebook_update_time=2.07678
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_ActivityNet_bs128/checkpoint-epoch23.pth ...
Done in 5.399s
Updating 'best' checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_ActivityNet_bs128/checkpoint-epoch23.pth ...
Done in 10.238s
removing stale ckpt [epoch 22] [took 0.27s]
 epoch          : 23
 loss           : 0.10194099417328835
 quant_reg      : 10.012777496337891
 quant_err      : 10.012777496337891
 learning_rate  : 8.36716218448071e-06
 n_samples      : 736000
 n_steps        : 5750
 ActivityNet_val1_test/t2v_metrics/R1: 19.056335163717716
 ActivityNet_val1_test/t2v_metrics/R5: 48.36282285946716
 ActivityNet_val1_test/t2v_metrics/R10: 65.12100874516982
 ActivityNet_val1_test/t2v_metrics/R50: 89.34309538336385
 ActivityNet_val1_test/t2v_metrics/MedR: 6.0
 ActivityNet_val1_test/t2v_metrics/MeanR: 33.13077079520033
 ActivityNet_val1_test/t2v_metrics/geometric_mean_R1-R5-R10: 39.15230915419983
 ActivityNet_val1_test/v2t_metrics/R1: 20.032540166768353
 ActivityNet_val1_test/v2t_metrics/R5: 49.562741509050234
 ActivityNet_val1_test/v2t_metrics/R10: 65.48708562131381
 ActivityNet_val1_test/v2t_metrics/R50: 89.79052267642872
 ActivityNet_val1_test/v2t_metrics/MedR: 6.0
 ActivityNet_val1_test/v2t_metrics/MeanR: 31.918852959121416
 ActivityNet_val1_test/v2t_metrics/geometric_mean_R1-R5-R10: 40.21138226042343
 mnt_best       : 39.15230915419983
 not_improved_count: 0
Train Epoch: 24 [1/250 128/32000 (0%)] Loss: 0.14884 (QuantReg: 9.96876) QuantErr: 9.96876 batch_time=23.80366 
Train Epoch: 24 [12/250 1536/32000 (5%)] Loss: 0.07892 (QuantReg: 9.95699) QuantErr: 9.95699 batch_time=1.34703 
Train Epoch: 24 [23/250 2944/32000 (9%)] Loss: 0.12695 (QuantReg: 9.88099) QuantErr: 9.88099 batch_time=0.66944 
Train Epoch: 24 [34/250 4352/32000 (14%)] Loss: 0.08160 (QuantReg: 10.01110) QuantErr: 10.01110 batch_time=0.64794 
Train Epoch: 24 [45/250 5760/32000 (18%)] Loss: 0.07968 (QuantReg: 10.07421) QuantErr: 10.07421 batch_time=0.65554 
Train Epoch: 24 [56/250 7168/32000 (22%)] Loss: 0.09934 (QuantReg: 9.93718) QuantErr: 9.93718 batch_time=0.80041 
Train Epoch: 24 [67/250 8576/32000 (27%)] Loss: 0.07021 (QuantReg: 10.05114) QuantErr: 10.05114 batch_time=0.64558 
Train Epoch: 24 [78/250 9984/32000 (31%)] Loss: 0.08349 (QuantReg: 9.98561) QuantErr: 9.98561 batch_time=0.65565 
Train Epoch: 24 [89/250 11392/32000 (36%)] Loss: 0.10584 (QuantReg: 10.10694) QuantErr: 10.10694 batch_time=0.64860 
Train Epoch: 24 [100/250 12800/32000 (40%)] Loss: 0.14484 (QuantReg: 9.96327) QuantErr: 9.96327 batch_time=0.64968 
Train Epoch: 24 [111/250 14208/32000 (44%)] Loss: 0.07212 (QuantReg: 9.91677) QuantErr: 9.91677 batch_time=0.63811 
Train Epoch: 24 [122/250 15616/32000 (49%)] Loss: 0.13061 (QuantReg: 9.83324) QuantErr: 9.83324 batch_time=0.66293 
Train Epoch: 24 [133/250 17024/32000 (53%)] Loss: 0.10326 (QuantReg: 9.96005) QuantErr: 9.96005 batch_time=0.63917 
Train Epoch: 24 [144/250 18432/32000 (58%)] Loss: 0.14360 (QuantReg: 9.97320) QuantErr: 9.97320 batch_time=0.65465 
Train Epoch: 24 [155/250 19840/32000 (62%)] Loss: 0.08421 (QuantReg: 9.96836) QuantErr: 9.96836 batch_time=0.64953 
Train Epoch: 24 [166/250 21248/32000 (66%)] Loss: 0.07312 (QuantReg: 9.93250) QuantErr: 9.93250 batch_time=0.65166 
Train Epoch: 24 [177/250 22656/32000 (71%)] Loss: 0.05348 (QuantReg: 9.84000) QuantErr: 9.84000 batch_time=0.65668 
Train Epoch: 24 [188/250 24064/32000 (75%)] Loss: 0.08102 (QuantReg: 9.83642) QuantErr: 9.83642 batch_time=0.64414 
Train Epoch: 24 [199/250 25472/32000 (80%)] Loss: 0.12163 (QuantReg: 9.93244) QuantErr: 9.93244 batch_time=0.68465 
Train Epoch: 24 [210/250 26880/32000 (84%)] Loss: 0.05858 (QuantReg: 10.05855) QuantErr: 10.05855 batch_time=0.65147 
Train Epoch: 24 [221/250 28288/32000 (88%)] Loss: 0.09918 (QuantReg: 9.90154) QuantErr: 9.90154 batch_time=0.65473 
Train Epoch: 24 [232/250 29696/32000 (93%)] Loss: 0.10331 (QuantReg: 9.82825) QuantErr: 9.82825 batch_time=0.66273 
Train Epoch: 24 [243/250 31104/32000 (97%)] Loss: 0.09614 (QuantReg: 9.91093) QuantErr: 9.91093 batch_time=0.66848 
Train Epoch: 24 codebook_update_time=1.79646
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_ActivityNet_bs128/checkpoint-epoch24.pth ...
Done in 4.548s
removing stale ckpt [epoch 23] [took 0.02s]
 epoch          : 24
 loss           : 0.09588405083119869
 quant_reg      : 9.952922584533692
 quant_err      : 9.952922584533692
 learning_rate  : 8.36716218448071e-06
 n_samples      : 768000
 n_steps        : 6000
 ActivityNet_val1_test/t2v_metrics/R1: 18.64958307911328
 ActivityNet_val1_test/t2v_metrics/R5: 48.728899735611144
 ActivityNet_val1_test/t2v_metrics/R10: 65.28370957901159
 ActivityNet_val1_test/t2v_metrics/R50: 89.24140736221273
 ActivityNet_val1_test/t2v_metrics/MedR: 6.0
 ActivityNet_val1_test/t2v_metrics/MeanR: 34.220663005897904
 ActivityNet_val1_test/t2v_metrics/geometric_mean_R1-R5-R10: 39.00199769558217
 ActivityNet_val1_test/v2t_metrics/R1: 19.82916412446614
 ActivityNet_val1_test/v2t_metrics/R5: 49.318690258287575
 ActivityNet_val1_test/v2t_metrics/R10: 65.50742322554403
 ActivityNet_val1_test/v2t_metrics/R50: 89.3024201749034
 ActivityNet_val1_test/v2t_metrics/MedR: 6.0
 ActivityNet_val1_test/v2t_metrics/MeanR: 32.56680902989628
 ActivityNet_val1_test/v2t_metrics/geometric_mean_R1-R5-R10: 40.01309570441436
 mnt_best       : 39.15230915419983
 not_improved_count: 1
Train Epoch: 25 [1/250 128/32000 (0%)] Loss: 0.11902 (QuantReg: 10.02437) QuantErr: 10.02437 batch_time=25.67269 
Train Epoch: 25 [12/250 1536/32000 (5%)] Loss: 0.08274 (QuantReg: 9.95497) QuantErr: 9.95497 batch_time=0.65206 
Train Epoch: 25 [23/250 2944/32000 (9%)] Loss: 0.13021 (QuantReg: 9.83530) QuantErr: 9.83530 batch_time=0.64561 
Train Epoch: 25 [34/250 4352/32000 (14%)] Loss: 0.12406 (QuantReg: 9.98193) QuantErr: 9.98193 batch_time=0.64933 
Train Epoch: 25 [45/250 5760/32000 (18%)] Loss: 0.09063 (QuantReg: 9.88445) QuantErr: 9.88445 batch_time=0.66123 
Train Epoch: 25 [56/250 7168/32000 (22%)] Loss: 0.10964 (QuantReg: 9.85380) QuantErr: 9.85380 batch_time=0.64142 
Train Epoch: 25 [67/250 8576/32000 (27%)] Loss: 0.14716 (QuantReg: 9.91155) QuantErr: 9.91155 batch_time=0.63851 
Train Epoch: 25 [78/250 9984/32000 (31%)] Loss: 0.10930 (QuantReg: 9.88559) QuantErr: 9.88559 batch_time=0.64091 
Train Epoch: 25 [89/250 11392/32000 (36%)] Loss: 0.08897 (QuantReg: 9.81824) QuantErr: 9.81824 batch_time=0.64975 
Train Epoch: 25 [100/250 12800/32000 (40%)] Loss: 0.10460 (QuantReg: 9.90170) QuantErr: 9.90170 batch_time=0.64726 
Train Epoch: 25 [111/250 14208/32000 (44%)] Loss: 0.07554 (QuantReg: 9.81094) QuantErr: 9.81094 batch_time=0.65044 
Train Epoch: 25 [122/250 15616/32000 (49%)] Loss: 0.07991 (QuantReg: 9.90308) QuantErr: 9.90308 batch_time=0.64854 
Train Epoch: 25 [133/250 17024/32000 (53%)] Loss: 0.11667 (QuantReg: 9.88783) QuantErr: 9.88783 batch_time=0.65131 
Train Epoch: 25 [144/250 18432/32000 (58%)] Loss: 0.11677 (QuantReg: 9.84414) QuantErr: 9.84414 batch_time=2.51484 
Train Epoch: 25 [155/250 19840/32000 (62%)] Loss: 0.06709 (QuantReg: 9.83297) QuantErr: 9.83297 batch_time=0.65386 
Train Epoch: 25 [166/250 21248/32000 (66%)] Loss: 0.10204 (QuantReg: 9.91416) QuantErr: 9.91416 batch_time=0.64424 
Train Epoch: 25 [177/250 22656/32000 (71%)] Loss: 0.06293 (QuantReg: 9.87402) QuantErr: 9.87402 batch_time=0.68490 
Train Epoch: 25 [188/250 24064/32000 (75%)] Loss: 0.09407 (QuantReg: 9.94955) QuantErr: 9.94955 batch_time=0.64344 
Train Epoch: 25 [199/250 25472/32000 (80%)] Loss: 0.09569 (QuantReg: 9.89906) QuantErr: 9.89906 batch_time=0.64173 
Train Epoch: 25 [210/250 26880/32000 (84%)] Loss: 0.06366 (QuantReg: 9.92289) QuantErr: 9.92289 batch_time=0.64268 
Train Epoch: 25 [221/250 28288/32000 (88%)] Loss: 0.07322 (QuantReg: 9.95329) QuantErr: 9.95329 batch_time=0.64379 
Train Epoch: 25 [232/250 29696/32000 (93%)] Loss: 0.15646 (QuantReg: 9.75721) QuantErr: 9.75721 batch_time=0.64495 
Train Epoch: 25 [243/250 31104/32000 (97%)] Loss: 0.06401 (QuantReg: 9.81047) QuantErr: 9.81047 batch_time=0.64929 
Train Epoch: 25 codebook_update_time=1.89377
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_ActivityNet_bs128/checkpoint-epoch25.pth ...
Done in 5.240s
removing stale ckpt [epoch 24] [took 0.01s]
 epoch          : 25
 loss           : 0.09294814296066761
 quant_reg      : 9.874606147766114
 quant_err      : 9.874606147766114
 learning_rate  : 7.112087856808604e-06
 n_samples      : 800000
 n_steps        : 6250
 ActivityNet_val1_test/t2v_metrics/R1: 18.832621517185277
 ActivityNet_val1_test/t2v_metrics/R5: 48.89160056945292
 ActivityNet_val1_test/t2v_metrics/R10: 64.7345942647956
 ActivityNet_val1_test/t2v_metrics/R50: 89.34309538336385
 ActivityNet_val1_test/t2v_metrics/MedR: 6.0
 ActivityNet_val1_test/t2v_metrics/MeanR: 33.801301606670734
 ActivityNet_val1_test/t2v_metrics/geometric_mean_R1-R5-R10: 39.06254076593229
 ActivityNet_val1_test/v2t_metrics/R1: 19.82916412446614
 ActivityNet_val1_test/v2t_metrics/R5: 49.76611755135245
 ActivityNet_val1_test/v2t_metrics/R10: 65.54809843400447
 ActivityNet_val1_test/v2t_metrics/R50: 89.64815944681716
 ActivityNet_val1_test/v2t_metrics/MedR: 6.0
 ActivityNet_val1_test/v2t_metrics/MeanR: 32.235306080943666
 ActivityNet_val1_test/v2t_metrics/geometric_mean_R1-R5-R10: 40.14203838610703
 mnt_best       : 39.15230915419983
 not_improved_count: 2
Train Epoch: 26 [1/250 128/32000 (0%)] Loss: 0.05748 (QuantReg: 9.90616) QuantErr: 9.90616 batch_time=25.29286 
Train Epoch: 26 [12/250 1536/32000 (5%)] Loss: 0.09544 (QuantReg: 9.86254) QuantErr: 9.86254 batch_time=0.68273 
Train Epoch: 26 [23/250 2944/32000 (9%)] Loss: 0.07840 (QuantReg: 9.79789) QuantErr: 9.79789 batch_time=0.66946 
Train Epoch: 26 [34/250 4352/32000 (14%)] Loss: 0.08787 (QuantReg: 9.82366) QuantErr: 9.82366 batch_time=0.64983 
Train Epoch: 26 [45/250 5760/32000 (18%)] Loss: 0.09565 (QuantReg: 9.84087) QuantErr: 9.84087 batch_time=0.64185 
Train Epoch: 26 [56/250 7168/32000 (22%)] Loss: 0.08209 (QuantReg: 9.86534) QuantErr: 9.86534 batch_time=0.64239 
Train Epoch: 26 [67/250 8576/32000 (27%)] Loss: 0.11374 (QuantReg: 9.83733) QuantErr: 9.83733 batch_time=0.64442 
Train Epoch: 26 [78/250 9984/32000 (31%)] Loss: 0.13541 (QuantReg: 9.85660) QuantErr: 9.85660 batch_time=0.65118 
Train Epoch: 26 [89/250 11392/32000 (36%)] Loss: 0.10253 (QuantReg: 9.78200) QuantErr: 9.78200 batch_time=0.65040 
Train Epoch: 26 [100/250 12800/32000 (40%)] Loss: 0.09288 (QuantReg: 9.84577) QuantErr: 9.84577 batch_time=0.63879 
Train Epoch: 26 [111/250 14208/32000 (44%)] Loss: 0.08875 (QuantReg: 9.72258) QuantErr: 9.72258 batch_time=0.64298 
Train Epoch: 26 [122/250 15616/32000 (49%)] Loss: 0.12285 (QuantReg: 9.85382) QuantErr: 9.85382 batch_time=0.85037 
Train Epoch: 26 [133/250 17024/32000 (53%)] Loss: 0.08609 (QuantReg: 9.83817) QuantErr: 9.83817 batch_time=0.65378 
Train Epoch: 26 [144/250 18432/32000 (58%)] Loss: 0.10540 (QuantReg: 9.84557) QuantErr: 9.84557 batch_time=1.91903 
Train Epoch: 26 [155/250 19840/32000 (62%)] Loss: 0.10546 (QuantReg: 9.75060) QuantErr: 9.75060 batch_time=1.54031 
Train Epoch: 26 [166/250 21248/32000 (66%)] Loss: 0.05592 (QuantReg: 9.87738) QuantErr: 9.87738 batch_time=0.65719 
Train Epoch: 26 [177/250 22656/32000 (71%)] Loss: 0.09118 (QuantReg: 9.86679) QuantErr: 9.86679 batch_time=0.64504 
Train Epoch: 26 [188/250 24064/32000 (75%)] Loss: 0.07850 (QuantReg: 9.93148) QuantErr: 9.93148 batch_time=0.64127 
Train Epoch: 26 [199/250 25472/32000 (80%)] Loss: 0.06860 (QuantReg: 9.72867) QuantErr: 9.72867 batch_time=0.64081 
Train Epoch: 26 [210/250 26880/32000 (84%)] Loss: 0.09407 (QuantReg: 9.79518) QuantErr: 9.79518 batch_time=0.64227 
Train Epoch: 26 [221/250 28288/32000 (88%)] Loss: 0.08859 (QuantReg: 9.71997) QuantErr: 9.71997 batch_time=0.64981 
Train Epoch: 26 [232/250 29696/32000 (93%)] Loss: 0.06664 (QuantReg: 9.79961) QuantErr: 9.79961 batch_time=0.64389 
Train Epoch: 26 [243/250 31104/32000 (97%)] Loss: 0.12686 (QuantReg: 9.60230) QuantErr: 9.60230 batch_time=0.64841 
Train Epoch: 26 codebook_update_time=2.06684
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_ActivityNet_bs128/checkpoint-epoch26.pth ...
Done in 11.071s
Updating 'best' checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_ActivityNet_bs128/checkpoint-epoch26.pth ...
Done in 25.719s
removing stale ckpt [epoch 25] [took 0.01s]
 epoch          : 26
 loss           : 0.0938209947347641
 quant_reg      : 9.804403354644775
 quant_err      : 9.804403354644775
 learning_rate  : 7.112087856808604e-06
 n_samples      : 832000
 n_steps        : 6500
 ActivityNet_val1_test/t2v_metrics/R1: 18.89363432987594
 ActivityNet_val1_test/t2v_metrics/R5: 49.19666463290624
 ActivityNet_val1_test/t2v_metrics/R10: 64.83628228594671
 ActivityNet_val1_test/t2v_metrics/R50: 89.0176937156803
 ActivityNet_val1_test/t2v_metrics/MedR: 6.0
 ActivityNet_val1_test/t2v_metrics/MeanR: 34.65344722391702
 ActivityNet_val1_test/t2v_metrics/geometric_mean_R1-R5-R10: 39.20635097548293
 ActivityNet_val1_test/v2t_metrics/R1: 19.74781370754525
 ActivityNet_val1_test/v2t_metrics/R5: 49.74577994712223
 ActivityNet_val1_test/v2t_metrics/R10: 65.77181208053692
 ActivityNet_val1_test/v2t_metrics/R50: 89.34309538336385
 ActivityNet_val1_test/v2t_metrics/MedR: 6.0
 ActivityNet_val1_test/v2t_metrics/MeanR: 33.045759609518
 ActivityNet_val1_test/v2t_metrics/geometric_mean_R1-R5-R10: 40.1271539150235
 mnt_best       : 39.20635097548293
 not_improved_count: 0
Train Epoch: 27 [1/250 128/32000 (0%)] Loss: 0.07012 (QuantReg: 9.79964) QuantErr: 9.79964 batch_time=23.98179 
Train Epoch: 27 [12/250 1536/32000 (5%)] Loss: 0.12586 (QuantReg: 9.53259) QuantErr: 9.53259 batch_time=0.65069 
Train Epoch: 27 [23/250 2944/32000 (9%)] Loss: 0.10919 (QuantReg: 9.59028) QuantErr: 9.59028 batch_time=0.66355 
Train Epoch: 27 [34/250 4352/32000 (14%)] Loss: 0.09103 (QuantReg: 9.78969) QuantErr: 9.78969 batch_time=0.63947 
Train Epoch: 27 [45/250 5760/32000 (18%)] Loss: 0.07661 (QuantReg: 9.70465) QuantErr: 9.70465 batch_time=1.04955 
Train Epoch: 27 [56/250 7168/32000 (22%)] Loss: 0.10410 (QuantReg: 9.93609) QuantErr: 9.93609 batch_time=0.63525 
Train Epoch: 27 [67/250 8576/32000 (27%)] Loss: 0.10569 (QuantReg: 9.69936) QuantErr: 9.69936 batch_time=0.64211 
Train Epoch: 27 [78/250 9984/32000 (31%)] Loss: 0.06953 (QuantReg: 9.82677) QuantErr: 9.82677 batch_time=2.10869 
Train Epoch: 27 [89/250 11392/32000 (36%)] Loss: 0.09617 (QuantReg: 9.77197) QuantErr: 9.77197 batch_time=0.65192 
Train Epoch: 27 [100/250 12800/32000 (40%)] Loss: 0.07401 (QuantReg: 9.73298) QuantErr: 9.73298 batch_time=0.64955 
Train Epoch: 27 [111/250 14208/32000 (44%)] Loss: 0.07239 (QuantReg: 9.94442) QuantErr: 9.94442 batch_time=0.63338 
Train Epoch: 27 [122/250 15616/32000 (49%)] Loss: 0.09577 (QuantReg: 9.71602) QuantErr: 9.71602 batch_time=0.63270 
Train Epoch: 27 [133/250 17024/32000 (53%)] Loss: 0.09049 (QuantReg: 9.71856) QuantErr: 9.71856 batch_time=0.63675 
Train Epoch: 27 [144/250 18432/32000 (58%)] Loss: 0.08426 (QuantReg: 9.70825) QuantErr: 9.70825 batch_time=1.84603 
Train Epoch: 27 [155/250 19840/32000 (62%)] Loss: 0.10977 (QuantReg: 9.61328) QuantErr: 9.61328 batch_time=0.63750 
Train Epoch: 27 [166/250 21248/32000 (66%)] Loss: 0.11642 (QuantReg: 9.77680) QuantErr: 9.77680 batch_time=1.21257 
Train Epoch: 27 [177/250 22656/32000 (71%)] Loss: 0.07805 (QuantReg: 9.73569) QuantErr: 9.73569 batch_time=0.64311 
Train Epoch: 27 [188/250 24064/32000 (75%)] Loss: 0.11190 (QuantReg: 9.68402) QuantErr: 9.68402 batch_time=0.63816 
Train Epoch: 27 [199/250 25472/32000 (80%)] Loss: 0.08964 (QuantReg: 9.75492) QuantErr: 9.75492 batch_time=0.64206 
Train Epoch: 27 [210/250 26880/32000 (84%)] Loss: 0.13907 (QuantReg: 9.74049) QuantErr: 9.74049 batch_time=0.64977 
Train Epoch: 27 [221/250 28288/32000 (88%)] Loss: 0.08014 (QuantReg: 9.76710) QuantErr: 9.76710 batch_time=0.65267 
Train Epoch: 27 [232/250 29696/32000 (93%)] Loss: 0.09189 (QuantReg: 9.64598) QuantErr: 9.64598 batch_time=0.63419 
Train Epoch: 27 [243/250 31104/32000 (97%)] Loss: 0.09884 (QuantReg: 9.78964) QuantErr: 9.78964 batch_time=0.64485 
Train Epoch: 27 codebook_update_time=2.16934
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_ActivityNet_bs128/checkpoint-epoch27.pth ...
Done in 4.668s
removing stale ckpt [epoch 26] [took 0.01s]
 epoch          : 27
 loss           : 0.09232253323495387
 quant_reg      : 9.72440926361084
 quant_err      : 9.72440926361084
 learning_rate  : 6.045274678287313e-06
 n_samples      : 864000
 n_steps        : 6750
 ActivityNet_val1_test/t2v_metrics/R1: 18.974984746796828
 ActivityNet_val1_test/t2v_metrics/R5: 48.505186089078705
 ActivityNet_val1_test/t2v_metrics/R10: 64.77526947325605
 ActivityNet_val1_test/t2v_metrics/R50: 89.18039454952206
 ActivityNet_val1_test/t2v_metrics/MedR: 6.0
 ActivityNet_val1_test/t2v_metrics/MeanR: 34.68883465527761
 ActivityNet_val1_test/t2v_metrics/geometric_mean_R1-R5-R10: 39.065460338921675
 ActivityNet_val1_test/v2t_metrics/R1: 19.341061622940817
 ActivityNet_val1_test/v2t_metrics/R5: 49.64409192597112
 ActivityNet_val1_test/v2t_metrics/R10: 65.71079926784624
 ActivityNet_val1_test/v2t_metrics/R50: 89.40410819605451
 ActivityNet_val1_test/v2t_metrics/MedR: 6.0
 ActivityNet_val1_test/v2t_metrics/MeanR: 33.06141956477527
 ActivityNet_val1_test/v2t_metrics/geometric_mean_R1-R5-R10: 39.810247399411644
 mnt_best       : 39.20635097548293
 not_improved_count: 1
Train Epoch: 28 [1/250 128/32000 (0%)] Loss: 0.08039 (QuantReg: 9.72912) QuantErr: 9.72912 batch_time=25.69941 
Train Epoch: 28 [12/250 1536/32000 (5%)] Loss: 0.09236 (QuantReg: 9.73282) QuantErr: 9.73282 batch_time=0.64331 
Train Epoch: 28 [23/250 2944/32000 (9%)] Loss: 0.08726 (QuantReg: 9.72687) QuantErr: 9.72687 batch_time=0.65470 
Train Epoch: 28 [34/250 4352/32000 (14%)] Loss: 0.09268 (QuantReg: 9.68134) QuantErr: 9.68134 batch_time=1.19273 
Train Epoch: 28 [45/250 5760/32000 (18%)] Loss: 0.12900 (QuantReg: 9.58304) QuantErr: 9.58304 batch_time=0.64692 
Train Epoch: 28 [56/250 7168/32000 (22%)] Loss: 0.11297 (QuantReg: 9.77959) QuantErr: 9.77959 batch_time=0.64599 
Train Epoch: 28 [67/250 8576/32000 (27%)] Loss: 0.09047 (QuantReg: 9.69351) QuantErr: 9.69351 batch_time=0.63412 
Train Epoch: 28 [78/250 9984/32000 (31%)] Loss: 0.08794 (QuantReg: 9.62343) QuantErr: 9.62343 batch_time=0.63662 
Train Epoch: 28 [89/250 11392/32000 (36%)] Loss: 0.07186 (QuantReg: 9.76613) QuantErr: 9.76613 batch_time=0.65711 
Train Epoch: 28 [100/250 12800/32000 (40%)] Loss: 0.08608 (QuantReg: 9.57981) QuantErr: 9.57981 batch_time=0.65315 
Train Epoch: 28 [111/250 14208/32000 (44%)] Loss: 0.08569 (QuantReg: 9.80399) QuantErr: 9.80399 batch_time=0.64683 
Train Epoch: 28 [122/250 15616/32000 (49%)] Loss: 0.10505 (QuantReg: 9.68569) QuantErr: 9.68569 batch_time=0.63855 
Train Epoch: 28 [133/250 17024/32000 (53%)] Loss: 0.09845 (QuantReg: 9.64105) QuantErr: 9.64105 batch_time=0.65351 
Train Epoch: 28 [144/250 18432/32000 (58%)] Loss: 0.10144 (QuantReg: 9.78926) QuantErr: 9.78926 batch_time=0.65399 
Train Epoch: 28 [155/250 19840/32000 (62%)] Loss: 0.09855 (QuantReg: 9.69121) QuantErr: 9.69121 batch_time=0.64989 
Train Epoch: 28 [166/250 21248/32000 (66%)] Loss: 0.09207 (QuantReg: 9.65318) QuantErr: 9.65318 batch_time=0.64179 
Train Epoch: 28 [177/250 22656/32000 (71%)] Loss: 0.11071 (QuantReg: 9.59997) QuantErr: 9.59997 batch_time=0.64814 
Train Epoch: 28 [188/250 24064/32000 (75%)] Loss: 0.08275 (QuantReg: 9.53279) QuantErr: 9.53279 batch_time=0.65726 
Train Epoch: 28 [199/250 25472/32000 (80%)] Loss: 0.07894 (QuantReg: 9.62963) QuantErr: 9.62963 batch_time=0.64828 
Train Epoch: 28 [210/250 26880/32000 (84%)] Loss: 0.11817 (QuantReg: 9.78173) QuantErr: 9.78173 batch_time=0.65706 
Train Epoch: 28 [221/250 28288/32000 (88%)] Loss: 0.10921 (QuantReg: 9.71295) QuantErr: 9.71295 batch_time=0.65948 
Train Epoch: 28 [232/250 29696/32000 (93%)] Loss: 0.09024 (QuantReg: 9.65541) QuantErr: 9.65541 batch_time=0.64974 
Train Epoch: 28 [243/250 31104/32000 (97%)] Loss: 0.10406 (QuantReg: 9.62736) QuantErr: 9.62736 batch_time=0.67279 
Train Epoch: 28 codebook_update_time=1.86845
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_ActivityNet_bs128/checkpoint-epoch28.pth ...
Done in 4.124s
removing stale ckpt [epoch 27] [took 0.01s]
 epoch          : 28
 loss           : 0.09159653070569039
 quant_reg      : 9.67401121520996
 quant_err      : 9.67401121520996
 learning_rate  : 6.045274678287313e-06
 n_samples      : 896000
 n_steps        : 7000
 ActivityNet_val1_test/t2v_metrics/R1: 18.99532235102705
 ActivityNet_val1_test/t2v_metrics/R5: 48.484848484848484
 ActivityNet_val1_test/t2v_metrics/R10: 64.65324384787472
 ActivityNet_val1_test/t2v_metrics/R50: 89.03803131991052
 ActivityNet_val1_test/t2v_metrics/MedR: 6.0
 ActivityNet_val1_test/t2v_metrics/MeanR: 33.63249949155989
 ActivityNet_val1_test/t2v_metrics/geometric_mean_R1-R5-R10: 39.04939803842766
 ActivityNet_val1_test/v2t_metrics/R1: 19.768151311775473
 ActivityNet_val1_test/v2t_metrics/R5: 50.01016880211511
 ActivityNet_val1_test/v2t_metrics/R10: 65.26337197478136
 ActivityNet_val1_test/v2t_metrics/R50: 89.52613382143583
 ActivityNet_val1_test/v2t_metrics/MedR: 5.0
 ActivityNet_val1_test/v2t_metrics/MeanR: 32.188529591214156
 ActivityNet_val1_test/v2t_metrics/geometric_mean_R1-R5-R10: 40.108026692282714
 mnt_best       : 39.20635097548293
 not_improved_count: 2
Train Epoch: 29 [1/250 128/32000 (0%)] Loss: 0.08501 (QuantReg: 9.65722) QuantErr: 9.65722 batch_time=21.65643 
Train Epoch: 29 [12/250 1536/32000 (5%)] Loss: 0.11454 (QuantReg: 9.55625) QuantErr: 9.55625 batch_time=0.64758 
Train Epoch: 29 [23/250 2944/32000 (9%)] Loss: 0.13145 (QuantReg: 9.44501) QuantErr: 9.44501 batch_time=0.64503 
Train Epoch: 29 [34/250 4352/32000 (14%)] Loss: 0.09100 (QuantReg: 9.59112) QuantErr: 9.59112 batch_time=0.65292 
Train Epoch: 29 [45/250 5760/32000 (18%)] Loss: 0.06290 (QuantReg: 9.58319) QuantErr: 9.58319 batch_time=0.64993 
Train Epoch: 29 [56/250 7168/32000 (22%)] Loss: 0.08610 (QuantReg: 9.57957) QuantErr: 9.57957 batch_time=0.65523 
Train Epoch: 29 [67/250 8576/32000 (27%)] Loss: 0.06140 (QuantReg: 9.48089) QuantErr: 9.48089 batch_time=4.68848 
Train Epoch: 29 [78/250 9984/32000 (31%)] Loss: 0.11963 (QuantReg: 9.71420) QuantErr: 9.71420 batch_time=0.64213 
Train Epoch: 29 [89/250 11392/32000 (36%)] Loss: 0.10204 (QuantReg: 9.70055) QuantErr: 9.70055 batch_time=0.64155 
Train Epoch: 29 [100/250 12800/32000 (40%)] Loss: 0.11559 (QuantReg: 9.56027) QuantErr: 9.56027 batch_time=0.63988 
Train Epoch: 29 [111/250 14208/32000 (44%)] Loss: 0.10113 (QuantReg: 9.61978) QuantErr: 9.61978 batch_time=0.64488 
Train Epoch: 29 [122/250 15616/32000 (49%)] Loss: 0.08028 (QuantReg: 9.71491) QuantErr: 9.71491 batch_time=0.65413 
Train Epoch: 29 [133/250 17024/32000 (53%)] Loss: 0.05798 (QuantReg: 9.72260) QuantErr: 9.72260 batch_time=2.39637 
Train Epoch: 29 [144/250 18432/32000 (58%)] Loss: 0.06752 (QuantReg: 9.57857) QuantErr: 9.57857 batch_time=0.64902 
Train Epoch: 29 [155/250 19840/32000 (62%)] Loss: 0.07906 (QuantReg: 9.68566) QuantErr: 9.68566 batch_time=0.64789 
Train Epoch: 29 [166/250 21248/32000 (66%)] Loss: 0.07541 (QuantReg: 9.52069) QuantErr: 9.52069 batch_time=0.64341 
Train Epoch: 29 [177/250 22656/32000 (71%)] Loss: 0.10262 (QuantReg: 9.72269) QuantErr: 9.72269 batch_time=0.64985 
Train Epoch: 29 [188/250 24064/32000 (75%)] Loss: 0.06731 (QuantReg: 9.56228) QuantErr: 9.56228 batch_time=0.71159 
Train Epoch: 29 [199/250 25472/32000 (80%)] Loss: 0.07831 (QuantReg: 9.62333) QuantErr: 9.62333 batch_time=0.64818 
Train Epoch: 29 [210/250 26880/32000 (84%)] Loss: 0.05660 (QuantReg: 9.64183) QuantErr: 9.64183 batch_time=0.66144 
Train Epoch: 29 [221/250 28288/32000 (88%)] Loss: 0.08409 (QuantReg: 9.60989) QuantErr: 9.60989 batch_time=0.64051 
Train Epoch: 29 [232/250 29696/32000 (93%)] Loss: 0.08894 (QuantReg: 9.49916) QuantErr: 9.49916 batch_time=0.64022 
Train Epoch: 29 [243/250 31104/32000 (97%)] Loss: 0.06913 (QuantReg: 9.69096) QuantErr: 9.69096 batch_time=0.65081 
Train Epoch: 29 codebook_update_time=2.22022
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_ActivityNet_bs128/checkpoint-epoch29.pth ...
Done in 5.383s
removing stale ckpt [epoch 28] [took 0.00s]
 epoch          : 29
 loss           : 0.09045121316611766
 quant_reg      : 9.606603187561035
 quant_err      : 9.606603187561035
 learning_rate  : 5.138483476544216e-06
 n_samples      : 928000
 n_steps        : 7250
 ActivityNet_val1_test/t2v_metrics/R1: 19.11734797640838
 ActivityNet_val1_test/t2v_metrics/R5: 48.56619890176937
 ActivityNet_val1_test/t2v_metrics/R10: 64.89729509863739
 ActivityNet_val1_test/t2v_metrics/R50: 88.69229204799674
 ActivityNet_val1_test/t2v_metrics/MedR: 6.0
 ActivityNet_val1_test/t2v_metrics/MeanR: 35.074842383567216
 ActivityNet_val1_test/t2v_metrics/geometric_mean_R1-R5-R10: 39.20391616315163
 ActivityNet_val1_test/v2t_metrics/R1: 19.97152735407769
 ActivityNet_val1_test/v2t_metrics/R5: 49.6237543217409
 ActivityNet_val1_test/v2t_metrics/R10: 65.12100874516982
 ActivityNet_val1_test/v2t_metrics/R50: 89.1193817368314
 ActivityNet_val1_test/v2t_metrics/MedR: 6.0
 ActivityNet_val1_test/v2t_metrics/MeanR: 33.38804148871263
 ActivityNet_val1_test/v2t_metrics/geometric_mean_R1-R5-R10: 40.11197127552649
 mnt_best       : 39.20635097548293
 not_improved_count: 3
Train Epoch: 30 [1/250 128/32000 (0%)] Loss: 0.07584 (QuantReg: 9.53179) QuantErr: 9.53179 batch_time=27.33462 
Train Epoch: 30 [12/250 1536/32000 (5%)] Loss: 0.07782 (QuantReg: 9.40259) QuantErr: 9.40259 batch_time=0.65782 
Train Epoch: 30 [23/250 2944/32000 (9%)] Loss: 0.11136 (QuantReg: 9.59633) QuantErr: 9.59633 batch_time=0.64756 
Train Epoch: 30 [34/250 4352/32000 (14%)] Loss: 0.08927 (QuantReg: 9.65002) QuantErr: 9.65002 batch_time=0.65101 
Train Epoch: 30 [45/250 5760/32000 (18%)] Loss: 0.08189 (QuantReg: 9.51748) QuantErr: 9.51748 batch_time=0.64498 
Train Epoch: 30 [56/250 7168/32000 (22%)] Loss: 0.07944 (QuantReg: 9.54729) QuantErr: 9.54729 batch_time=0.65120 
Train Epoch: 30 [67/250 8576/32000 (27%)] Loss: 0.07511 (QuantReg: 9.56691) QuantErr: 9.56691 batch_time=5.95442 
Train Epoch: 30 [78/250 9984/32000 (31%)] Loss: 0.09562 (QuantReg: 9.47299) QuantErr: 9.47299 batch_time=0.64144 
Train Epoch: 30 [89/250 11392/32000 (36%)] Loss: 0.07740 (QuantReg: 9.66842) QuantErr: 9.66842 batch_time=0.64683 
Train Epoch: 30 [100/250 12800/32000 (40%)] Loss: 0.06200 (QuantReg: 9.49887) QuantErr: 9.49887 batch_time=0.65757 
Train Epoch: 30 [111/250 14208/32000 (44%)] Loss: 0.12065 (QuantReg: 9.50604) QuantErr: 9.50604 batch_time=0.64831 
Train Epoch: 30 [122/250 15616/32000 (49%)] Loss: 0.07916 (QuantReg: 9.66206) QuantErr: 9.66206 batch_time=0.64016 
Train Epoch: 30 [133/250 17024/32000 (53%)] Loss: 0.12620 (QuantReg: 9.58399) QuantErr: 9.58399 batch_time=0.67356 
Train Epoch: 30 [144/250 18432/32000 (58%)] Loss: 0.06474 (QuantReg: 9.68370) QuantErr: 9.68370 batch_time=0.64303 
Train Epoch: 30 [155/250 19840/32000 (62%)] Loss: 0.11195 (QuantReg: 9.58642) QuantErr: 9.58642 batch_time=1.01157 
Train Epoch: 30 [166/250 21248/32000 (66%)] Loss: 0.08445 (QuantReg: 9.58719) QuantErr: 9.58719 batch_time=0.64775 
Train Epoch: 30 [177/250 22656/32000 (71%)] Loss: 0.08803 (QuantReg: 9.67780) QuantErr: 9.67780 batch_time=0.65249 
Train Epoch: 30 [188/250 24064/32000 (75%)] Loss: 0.11652 (QuantReg: 9.33193) QuantErr: 9.33193 batch_time=0.67810 
Train Epoch: 30 [199/250 25472/32000 (80%)] Loss: 0.11575 (QuantReg: 9.41891) QuantErr: 9.41891 batch_time=0.64729 
Train Epoch: 30 [210/250 26880/32000 (84%)] Loss: 0.10820 (QuantReg: 9.55599) QuantErr: 9.55599 batch_time=0.64596 
Train Epoch: 30 [221/250 28288/32000 (88%)] Loss: 0.10484 (QuantReg: 9.54092) QuantErr: 9.54092 batch_time=0.67682 
Train Epoch: 30 [232/250 29696/32000 (93%)] Loss: 0.10324 (QuantReg: 9.58164) QuantErr: 9.58164 batch_time=0.67399 
Train Epoch: 30 [243/250 31104/32000 (97%)] Loss: 0.06830 (QuantReg: 9.49201) QuantErr: 9.49201 batch_time=0.67469 
Train Epoch: 30 codebook_update_time=1.83657
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_ActivityNet_bs128/checkpoint-epoch30.pth ...
Done in 4.434s
Updating 'best' checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_ActivityNet_bs128/checkpoint-epoch30.pth ...
Done in 8.269s
removing stale ckpt [epoch 29] [took 0.00s]
 epoch          : 30
 loss           : 0.09141907131671906
 quant_reg      : 9.563310111999511
 quant_err      : 9.563310111999511
 learning_rate  : 5.138483476544216e-06
 n_samples      : 960000
 n_steps        : 7500
 ActivityNet_val1_test/t2v_metrics/R1: 19.361399227171038
 ActivityNet_val1_test/t2v_metrics/R5: 48.60687411022982
 ActivityNet_val1_test/t2v_metrics/R10: 64.85661989017694
 ActivityNet_val1_test/t2v_metrics/R50: 88.40756558877364
 ActivityNet_val1_test/t2v_metrics/MedR: 6.0
 ActivityNet_val1_test/t2v_metrics/MeanR: 35.37929631889364
 ActivityNet_val1_test/t2v_metrics/geometric_mean_R1-R5-R10: 39.37279520634257
 ActivityNet_val1_test/v2t_metrics/R1: 19.219035997559487
 ActivityNet_val1_test/v2t_metrics/R5: 49.68476713443157
 ActivityNet_val1_test/v2t_metrics/R10: 66.03620093552979
 ActivityNet_val1_test/v2t_metrics/R50: 89.1193817368314
 ActivityNet_val1_test/v2t_metrics/MedR: 6.0
 ActivityNet_val1_test/v2t_metrics/MeanR: 33.153752287980474
 ActivityNet_val1_test/v2t_metrics/geometric_mean_R1-R5-R10: 39.80267982038903
 mnt_best       : 39.37279520634257
 not_improved_count: 0
Train Epoch: 31 [1/250 128/32000 (0%)] Loss: 0.08937 (QuantReg: 9.70560) QuantErr: 9.70560 batch_time=21.81050 
Train Epoch: 31 [12/250 1536/32000 (5%)] Loss: 0.06252 (QuantReg: 9.52602) QuantErr: 9.52602 batch_time=0.66711 
Train Epoch: 31 [23/250 2944/32000 (9%)] Loss: 0.10018 (QuantReg: 9.39970) QuantErr: 9.39970 batch_time=0.65309 
Train Epoch: 31 [34/250 4352/32000 (14%)] Loss: 0.07390 (QuantReg: 9.48623) QuantErr: 9.48623 batch_time=0.64877 
Train Epoch: 31 [45/250 5760/32000 (18%)] Loss: 0.19359 (QuantReg: 9.40235) QuantErr: 9.40235 batch_time=0.64988 
Train Epoch: 31 [56/250 7168/32000 (22%)] Loss: 0.11116 (QuantReg: 9.52928) QuantErr: 9.52928 batch_time=0.64689 
Train Epoch: 31 [67/250 8576/32000 (27%)] Loss: 0.09970 (QuantReg: 9.47008) QuantErr: 9.47008 batch_time=0.63406 
Train Epoch: 31 [78/250 9984/32000 (31%)] Loss: 0.08097 (QuantReg: 9.43869) QuantErr: 9.43869 batch_time=0.63770 
Train Epoch: 31 [89/250 11392/32000 (36%)] Loss: 0.08884 (QuantReg: 9.47440) QuantErr: 9.47440 batch_time=0.64630 
Train Epoch: 31 [100/250 12800/32000 (40%)] Loss: 0.06161 (QuantReg: 9.47599) QuantErr: 9.47599 batch_time=0.64539 
Train Epoch: 31 [111/250 14208/32000 (44%)] Loss: 0.06712 (QuantReg: 9.53852) QuantErr: 9.53852 batch_time=0.65234 
Train Epoch: 31 [122/250 15616/32000 (49%)] Loss: 0.07208 (QuantReg: 9.53306) QuantErr: 9.53306 batch_time=0.67352 
Train Epoch: 31 [133/250 17024/32000 (53%)] Loss: 0.08622 (QuantReg: 9.60571) QuantErr: 9.60571 batch_time=5.54849 
Train Epoch: 31 [144/250 18432/32000 (58%)] Loss: 0.12546 (QuantReg: 9.55602) QuantErr: 9.55602 batch_time=3.64201 
Train Epoch: 31 [155/250 19840/32000 (62%)] Loss: 0.09250 (QuantReg: 9.40971) QuantErr: 9.40971 batch_time=0.65294 
Train Epoch: 31 [166/250 21248/32000 (66%)] Loss: 0.11371 (QuantReg: 9.46747) QuantErr: 9.46747 batch_time=0.65188 
Train Epoch: 31 [177/250 22656/32000 (71%)] Loss: 0.06167 (QuantReg: 9.49156) QuantErr: 9.49156 batch_time=0.65237 
Train Epoch: 31 [188/250 24064/32000 (75%)] Loss: 0.10151 (QuantReg: 9.43784) QuantErr: 9.43784 batch_time=0.67960 
Train Epoch: 31 [199/250 25472/32000 (80%)] Loss: 0.06621 (QuantReg: 9.48762) QuantErr: 9.48762 batch_time=0.65126 
Train Epoch: 31 [210/250 26880/32000 (84%)] Loss: 0.08010 (QuantReg: 9.44550) QuantErr: 9.44550 batch_time=0.64885 
Train Epoch: 31 [221/250 28288/32000 (88%)] Loss: 0.09081 (QuantReg: 9.30897) QuantErr: 9.30897 batch_time=0.68203 
Train Epoch: 31 [232/250 29696/32000 (93%)] Loss: 0.05318 (QuantReg: 9.39593) QuantErr: 9.39593 batch_time=0.68704 
Train Epoch: 31 [243/250 31104/32000 (97%)] Loss: 0.08777 (QuantReg: 9.53863) QuantErr: 9.53863 batch_time=0.74835 
Train Epoch: 31 codebook_update_time=2.10665
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_ActivityNet_bs128/checkpoint-epoch31.pth ...
Done in 19.778s
removing stale ckpt [epoch 30] [took 0.01s]
 epoch          : 31
 loss           : 0.08706919334828854
 quant_reg      : 9.48543627166748
 quant_err      : 9.48543627166748
 learning_rate  : 4.367710955062584e-06
 n_samples      : 992000
 n_steps        : 7750
 ActivityNet_val1_test/t2v_metrics/R1: 19.23937360178971
 ActivityNet_val1_test/t2v_metrics/R5: 48.46451088061826
 ActivityNet_val1_test/t2v_metrics/R10: 64.59223103518406
 ActivityNet_val1_test/t2v_metrics/R50: 88.83465527760829
 ActivityNet_val1_test/t2v_metrics/MedR: 6.0
 ActivityNet_val1_test/t2v_metrics/MeanR: 35.636872076469395
 ActivityNet_val1_test/t2v_metrics/geometric_mean_R1-R5-R10: 39.19809994177975
 ActivityNet_val1_test/v2t_metrics/R1: 19.524100061012813
 ActivityNet_val1_test/v2t_metrics/R5: 49.88814317673378
 ActivityNet_val1_test/v2t_metrics/R10: 65.83282489322758
 ActivityNet_val1_test/v2t_metrics/R50: 89.03803131991052
 ActivityNet_val1_test/v2t_metrics/MedR: 6.0
 ActivityNet_val1_test/v2t_metrics/MeanR: 33.6880211511084
 ActivityNet_val1_test/v2t_metrics/geometric_mean_R1-R5-R10: 40.02551714937848
 mnt_best       : 39.37279520634257
 not_improved_count: 1
Train Epoch: 32 [1/250 128/32000 (0%)] Loss: 0.14123 (QuantReg: 9.36055) QuantErr: 9.36055 batch_time=23.91295 
Train Epoch: 32 [12/250 1536/32000 (5%)] Loss: 0.08464 (QuantReg: 9.54775) QuantErr: 9.54775 batch_time=0.64411 
Train Epoch: 32 [23/250 2944/32000 (9%)] Loss: 0.09060 (QuantReg: 9.30238) QuantErr: 9.30238 batch_time=2.36646 
Train Epoch: 32 [34/250 4352/32000 (14%)] Loss: 0.08983 (QuantReg: 9.60110) QuantErr: 9.60110 batch_time=0.65020 
Train Epoch: 32 [45/250 5760/32000 (18%)] Loss: 0.09569 (QuantReg: 9.44258) QuantErr: 9.44258 batch_time=0.64914 
Train Epoch: 32 [56/250 7168/32000 (22%)] Loss: 0.12936 (QuantReg: 9.42657) QuantErr: 9.42657 batch_time=0.64308 
Train Epoch: 32 [67/250 8576/32000 (27%)] Loss: 0.07220 (QuantReg: 9.35507) QuantErr: 9.35507 batch_time=0.66209 
Train Epoch: 32 [78/250 9984/32000 (31%)] Loss: 0.10510 (QuantReg: 9.54813) QuantErr: 9.54813 batch_time=2.71469 
Train Epoch: 32 [89/250 11392/32000 (36%)] Loss: 0.07651 (QuantReg: 9.31867) QuantErr: 9.31867 batch_time=0.65404 
Train Epoch: 32 [100/250 12800/32000 (40%)] Loss: 0.12870 (QuantReg: 9.36671) QuantErr: 9.36671 batch_time=0.64325 
Train Epoch: 32 [111/250 14208/32000 (44%)] Loss: 0.07323 (QuantReg: 9.33413) QuantErr: 9.33413 batch_time=0.65899 
Train Epoch: 32 [122/250 15616/32000 (49%)] Loss: 0.05822 (QuantReg: 9.37727) QuantErr: 9.37727 batch_time=0.66555 
Train Epoch: 32 [133/250 17024/32000 (53%)] Loss: 0.09105 (QuantReg: 9.38810) QuantErr: 9.38810 batch_time=0.65791 
Train Epoch: 32 [144/250 18432/32000 (58%)] Loss: 0.07062 (QuantReg: 9.26938) QuantErr: 9.26938 batch_time=0.79755 
Train Epoch: 32 [155/250 19840/32000 (62%)] Loss: 0.08655 (QuantReg: 9.35291) QuantErr: 9.35291 batch_time=2.88150 
Train Epoch: 32 [166/250 21248/32000 (66%)] Loss: 0.11390 (QuantReg: 9.60742) QuantErr: 9.60742 batch_time=0.64156 
Train Epoch: 32 [177/250 22656/32000 (71%)] Loss: 0.06713 (QuantReg: 9.37278) QuantErr: 9.37278 batch_time=0.64835 
Train Epoch: 32 [188/250 24064/32000 (75%)] Loss: 0.06175 (QuantReg: 9.48827) QuantErr: 9.48827 batch_time=0.64730 
Train Epoch: 32 [199/250 25472/32000 (80%)] Loss: 0.05120 (QuantReg: 9.47295) QuantErr: 9.47295 batch_time=0.64662 
Train Epoch: 32 [210/250 26880/32000 (84%)] Loss: 0.09868 (QuantReg: 9.36451) QuantErr: 9.36451 batch_time=0.64889 
Train Epoch: 32 [221/250 28288/32000 (88%)] Loss: 0.05932 (QuantReg: 9.35588) QuantErr: 9.35588 batch_time=0.64353 
Train Epoch: 32 [232/250 29696/32000 (93%)] Loss: 0.12269 (QuantReg: 9.25789) QuantErr: 9.25789 batch_time=0.65401 
Train Epoch: 32 [243/250 31104/32000 (97%)] Loss: 0.08506 (QuantReg: 9.34158) QuantErr: 9.34158 batch_time=0.64188 
Train Epoch: 32 codebook_update_time=2.02852
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_ActivityNet_bs128/checkpoint-epoch32.pth ...
Done in 4.750s
removing stale ckpt [epoch 31] [took 0.00s]
 epoch          : 32
 loss           : 0.08901591232419014
 quant_reg      : 9.425250221252442
 quant_err      : 9.425250221252442
 learning_rate  : 4.367710955062584e-06
 n_samples      : 1024000
 n_steps        : 8000
 ActivityNet_val1_test/t2v_metrics/R1: 18.99532235102705
 ActivityNet_val1_test/t2v_metrics/R5: 48.30181004677649
 ActivityNet_val1_test/t2v_metrics/R10: 64.71425666056538
 ActivityNet_val1_test/t2v_metrics/R50: 88.40756558877364
 ActivityNet_val1_test/t2v_metrics/MedR: 6.0
 ActivityNet_val1_test/t2v_metrics/MeanR: 36.686597518812285
 ActivityNet_val1_test/t2v_metrics/geometric_mean_R1-R5-R10: 39.01246094243513
 ActivityNet_val1_test/v2t_metrics/R1: 19.84950172869636
 ActivityNet_val1_test/v2t_metrics/R5: 49.80679275981289
 ActivityNet_val1_test/v2t_metrics/R10: 64.55155582672361
 ActivityNet_val1_test/v2t_metrics/R50: 88.44824079723409
 ActivityNet_val1_test/v2t_metrics/MedR: 6.0
 ActivityNet_val1_test/v2t_metrics/MeanR: 34.51657514744763
 ActivityNet_val1_test/v2t_metrics/geometric_mean_R1-R5-R10: 39.962099804503595
 mnt_best       : 39.37279520634257
 not_improved_count: 2
Train Epoch: 33 [1/250 128/32000 (0%)] Loss: 0.08139 (QuantReg: 9.36256) QuantErr: 9.36256 batch_time=25.75773 
Train Epoch: 33 [12/250 1536/32000 (5%)] Loss: 0.07893 (QuantReg: 9.36548) QuantErr: 9.36548 batch_time=0.65185 
Train Epoch: 33 [23/250 2944/32000 (9%)] Loss: 0.08251 (QuantReg: 9.36976) QuantErr: 9.36976 batch_time=0.65854 
Train Epoch: 33 [34/250 4352/32000 (14%)] Loss: 0.05809 (QuantReg: 9.44487) QuantErr: 9.44487 batch_time=3.01390 
Train Epoch: 33 [45/250 5760/32000 (18%)] Loss: 0.10254 (QuantReg: 9.35197) QuantErr: 9.35197 batch_time=0.65025 
Train Epoch: 33 [56/250 7168/32000 (22%)] Loss: 0.06722 (QuantReg: 9.36928) QuantErr: 9.36928 batch_time=0.64756 
Train Epoch: 33 [67/250 8576/32000 (27%)] Loss: 0.07965 (QuantReg: 9.25900) QuantErr: 9.25900 batch_time=0.65558 
Train Epoch: 33 [78/250 9984/32000 (31%)] Loss: 0.08891 (QuantReg: 9.35474) QuantErr: 9.35474 batch_time=0.66414 
Train Epoch: 33 [89/250 11392/32000 (36%)] Loss: 0.08349 (QuantReg: 9.45925) QuantErr: 9.45925 batch_time=0.64824 
Train Epoch: 33 [100/250 12800/32000 (40%)] Loss: 0.10498 (QuantReg: 9.40685) QuantErr: 9.40685 batch_time=0.63577 
Train Epoch: 33 [111/250 14208/32000 (44%)] Loss: 0.10270 (QuantReg: 9.24912) QuantErr: 9.24912 batch_time=0.64086 
Train Epoch: 33 [122/250 15616/32000 (49%)] Loss: 0.07302 (QuantReg: 9.55718) QuantErr: 9.55718 batch_time=0.64860 
Train Epoch: 33 [133/250 17024/32000 (53%)] Loss: 0.09252 (QuantReg: 9.30029) QuantErr: 9.30029 batch_time=0.64120 
Train Epoch: 33 [144/250 18432/32000 (58%)] Loss: 0.10160 (QuantReg: 9.32940) QuantErr: 9.32940 batch_time=2.32716 
Train Epoch: 33 [155/250 19840/32000 (62%)] Loss: 0.11068 (QuantReg: 9.44687) QuantErr: 9.44687 batch_time=0.64062 
Train Epoch: 33 [166/250 21248/32000 (66%)] Loss: 0.08365 (QuantReg: 9.34892) QuantErr: 9.34892 batch_time=0.64689 
Train Epoch: 33 [177/250 22656/32000 (71%)] Loss: 0.11353 (QuantReg: 9.32006) QuantErr: 9.32006 batch_time=0.64816 
Train Epoch: 33 [188/250 24064/32000 (75%)] Loss: 0.06921 (QuantReg: 9.47467) QuantErr: 9.47467 batch_time=0.64129 
Train Epoch: 33 [199/250 25472/32000 (80%)] Loss: 0.12726 (QuantReg: 9.36367) QuantErr: 9.36367 batch_time=0.64199 
Train Epoch: 33 [210/250 26880/32000 (84%)] Loss: 0.06147 (QuantReg: 9.41123) QuantErr: 9.41123 batch_time=0.65669 
Train Epoch: 33 [221/250 28288/32000 (88%)] Loss: 0.10106 (QuantReg: 9.36320) QuantErr: 9.36320 batch_time=0.64396 
Train Epoch: 33 [232/250 29696/32000 (93%)] Loss: 0.11063 (QuantReg: 9.46995) QuantErr: 9.46995 batch_time=0.65213 
Train Epoch: 33 [243/250 31104/32000 (97%)] Loss: 0.09074 (QuantReg: 9.24131) QuantErr: 9.24131 batch_time=0.66053 
Train Epoch: 33 codebook_update_time=2.17846
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_ActivityNet_bs128/checkpoint-epoch33.pth ...
Done in 4.362s
removing stale ckpt [epoch 32] [took 0.01s]
 epoch          : 33
 loss           : 0.08751598767936229
 quant_reg      : 9.363407012939453
 quant_err      : 9.363407012939453
 learning_rate  : 3.712554311803196e-06
 n_samples      : 1056000
 n_steps        : 8250
 ActivityNet_val1_test/t2v_metrics/R1: 18.64958307911328
 ActivityNet_val1_test/t2v_metrics/R5: 48.220459629855604
 ActivityNet_val1_test/t2v_metrics/R10: 64.0634533251983
 ActivityNet_val1_test/t2v_metrics/R50: 88.30587756762253
 ActivityNet_val1_test/t2v_metrics/MedR: 6.0
 ActivityNet_val1_test/t2v_metrics/MeanR: 36.96522269676632
 ActivityNet_val1_test/t2v_metrics/geometric_mean_R1-R5-R10: 38.62219386972305
 ActivityNet_val1_test/v2t_metrics/R1: 19.768151311775473
 ActivityNet_val1_test/v2t_metrics/R5: 49.908480780964005
 ActivityNet_val1_test/v2t_metrics/R10: 64.87695749440716
 ActivityNet_val1_test/v2t_metrics/R50: 88.63127923530608
 ActivityNet_val1_test/v2t_metrics/MedR: 6.0
 ActivityNet_val1_test/v2t_metrics/MeanR: 34.45027455765711
 ActivityNet_val1_test/v2t_metrics/geometric_mean_R1-R5-R10: 40.00156294915877
 mnt_best       : 39.37279520634257
 not_improved_count: 3
Train Epoch: 34 [1/250 128/32000 (0%)] Loss: 0.08510 (QuantReg: 9.41726) QuantErr: 9.41726 batch_time=23.26703 
Train Epoch: 34 [12/250 1536/32000 (5%)] Loss: 0.08402 (QuantReg: 9.23152) QuantErr: 9.23152 batch_time=0.64378 
Train Epoch: 34 [23/250 2944/32000 (9%)] Loss: 0.08468 (QuantReg: 9.22590) QuantErr: 9.22590 batch_time=0.64177 
Train Epoch: 34 [34/250 4352/32000 (14%)] Loss: 0.06112 (QuantReg: 9.15424) QuantErr: 9.15424 batch_time=0.64927 
Train Epoch: 34 [45/250 5760/32000 (18%)] Loss: 0.08430 (QuantReg: 9.35114) QuantErr: 9.35114 batch_time=0.65631 
Train Epoch: 34 [56/250 7168/32000 (22%)] Loss: 0.12211 (QuantReg: 9.27558) QuantErr: 9.27558 batch_time=0.63977 
Train Epoch: 34 [67/250 8576/32000 (27%)] Loss: 0.09996 (QuantReg: 9.30196) QuantErr: 9.30196 batch_time=1.06767 
Train Epoch: 34 [78/250 9984/32000 (31%)] Loss: 0.06662 (QuantReg: 9.36525) QuantErr: 9.36525 batch_time=0.64898 
Train Epoch: 34 [89/250 11392/32000 (36%)] Loss: 0.06620 (QuantReg: 9.46231) QuantErr: 9.46231 batch_time=0.66817 
Train Epoch: 34 [100/250 12800/32000 (40%)] Loss: 0.14193 (QuantReg: 9.38748) QuantErr: 9.38748 batch_time=0.66686 
Train Epoch: 34 [111/250 14208/32000 (44%)] Loss: 0.07667 (QuantReg: 9.46890) QuantErr: 9.46890 batch_time=0.64035 
Train Epoch: 34 [122/250 15616/32000 (49%)] Loss: 0.06083 (QuantReg: 9.14783) QuantErr: 9.14783 batch_time=0.64449 
Train Epoch: 34 [133/250 17024/32000 (53%)] Loss: 0.10784 (QuantReg: 9.22849) QuantErr: 9.22849 batch_time=3.44357 
Train Epoch: 34 [144/250 18432/32000 (58%)] Loss: 0.11716 (QuantReg: 9.27216) QuantErr: 9.27216 batch_time=0.64589 
Train Epoch: 34 [155/250 19840/32000 (62%)] Loss: 0.07459 (QuantReg: 9.43275) QuantErr: 9.43275 batch_time=0.63510 
Train Epoch: 34 [166/250 21248/32000 (66%)] Loss: 0.07735 (QuantReg: 9.18232) QuantErr: 9.18232 batch_time=0.64860 
Train Epoch: 34 [177/250 22656/32000 (71%)] Loss: 0.10969 (QuantReg: 9.27662) QuantErr: 9.27662 batch_time=0.64453 
Train Epoch: 34 [188/250 24064/32000 (75%)] Loss: 0.08700 (QuantReg: 9.28734) QuantErr: 9.28734 batch_time=0.64606 
Train Epoch: 34 [199/250 25472/32000 (80%)] Loss: 0.06043 (QuantReg: 9.35595) QuantErr: 9.35595 batch_time=0.63954 
Train Epoch: 34 [210/250 26880/32000 (84%)] Loss: 0.12198 (QuantReg: 9.31099) QuantErr: 9.31099 batch_time=0.65228 
Train Epoch: 34 [221/250 28288/32000 (88%)] Loss: 0.10715 (QuantReg: 9.30127) QuantErr: 9.30127 batch_time=0.64456 
Train Epoch: 34 [232/250 29696/32000 (93%)] Loss: 0.12380 (QuantReg: 9.18116) QuantErr: 9.18116 batch_time=0.64824 
Train Epoch: 34 [243/250 31104/32000 (97%)] Loss: 0.07838 (QuantReg: 9.31370) QuantErr: 9.31370 batch_time=0.65994 
Train Epoch: 34 codebook_update_time=2.07039
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_ActivityNet_bs128/checkpoint-epoch34.pth ...
Done in 4.201s
removing stale ckpt [epoch 33] [took 0.02s]
 epoch          : 34
 loss           : 0.08700257322192192
 quant_reg      : 9.312853008270263
 quant_err      : 9.312853008270263
 learning_rate  : 3.712554311803196e-06
 n_samples      : 1088000
 n_steps        : 8500
 ActivityNet_val1_test/t2v_metrics/R1: 18.690258287573723
 ActivityNet_val1_test/t2v_metrics/R5: 48.505186089078705
 ActivityNet_val1_test/t2v_metrics/R10: 64.22615415904006
 ActivityNet_val1_test/t2v_metrics/R50: 88.5499288183852
 ActivityNet_val1_test/t2v_metrics/MedR: 6.0
 ActivityNet_val1_test/t2v_metrics/MeanR: 37.297742525930445
 ActivityNet_val1_test/t2v_metrics/geometric_mean_R1-R5-R10: 38.75893172651755
 ActivityNet_val1_test/v2t_metrics/R1: 19.564775269473255
 ActivityNet_val1_test/v2t_metrics/R5: 49.96949359365467
 ActivityNet_val1_test/v2t_metrics/R10: 65.36505999593248
 ActivityNet_val1_test/v2t_metrics/R50: 88.97701850721985
 ActivityNet_val1_test/v2t_metrics/MedR: 6.0
 ActivityNet_val1_test/v2t_metrics/MeanR: 34.62558470612162
 ActivityNet_val1_test/v2t_metrics/geometric_mean_R1-R5-R10: 39.979911217792434
 mnt_best       : 39.37279520634257
 not_improved_count: 4
Train Epoch: 35 [1/250 128/32000 (0%)] Loss: 0.05535 (QuantReg: 9.25093) QuantErr: 9.25093 batch_time=25.35037 
Train Epoch: 35 [12/250 1536/32000 (5%)] Loss: 0.08956 (QuantReg: 9.29498) QuantErr: 9.29498 batch_time=0.65334 
Train Epoch: 35 [23/250 2944/32000 (9%)] Loss: 0.05283 (QuantReg: 9.27420) QuantErr: 9.27420 batch_time=0.65438 
Train Epoch: 35 [34/250 4352/32000 (14%)] Loss: 0.09407 (QuantReg: 9.20470) QuantErr: 9.20470 batch_time=0.97023 
Train Epoch: 35 [45/250 5760/32000 (18%)] Loss: 0.09462 (QuantReg: 9.23575) QuantErr: 9.23575 batch_time=0.64656 
Train Epoch: 35 [56/250 7168/32000 (22%)] Loss: 0.07668 (QuantReg: 9.25348) QuantErr: 9.25348 batch_time=0.66431 
Train Epoch: 35 [67/250 8576/32000 (27%)] Loss: 0.06240 (QuantReg: 9.30185) QuantErr: 9.30185 batch_time=2.83136 
Train Epoch: 35 [78/250 9984/32000 (31%)] Loss: 0.08296 (QuantReg: 9.14347) QuantErr: 9.14347 batch_time=0.65254 
Train Epoch: 35 [89/250 11392/32000 (36%)] Loss: 0.07867 (QuantReg: 9.27884) QuantErr: 9.27884 batch_time=0.67893 
Train Epoch: 35 [100/250 12800/32000 (40%)] Loss: 0.11667 (QuantReg: 9.36367) QuantErr: 9.36367 batch_time=0.64951 
Train Epoch: 35 [111/250 14208/32000 (44%)] Loss: 0.05999 (QuantReg: 9.33631) QuantErr: 9.33631 batch_time=0.68633 
Train Epoch: 35 [122/250 15616/32000 (49%)] Loss: 0.08937 (QuantReg: 9.24681) QuantErr: 9.24681 batch_time=0.65180 
Train Epoch: 35 [133/250 17024/32000 (53%)] Loss: 0.13454 (QuantReg: 9.26876) QuantErr: 9.26876 batch_time=0.66779 
Train Epoch: 35 [144/250 18432/32000 (58%)] Loss: 0.09095 (QuantReg: 9.38026) QuantErr: 9.38026 batch_time=1.41562 
Train Epoch: 35 [155/250 19840/32000 (62%)] Loss: 0.06693 (QuantReg: 9.26319) QuantErr: 9.26319 batch_time=0.64773 
Train Epoch: 35 [166/250 21248/32000 (66%)] Loss: 0.09075 (QuantReg: 9.21691) QuantErr: 9.21691 batch_time=0.64865 
Train Epoch: 35 [177/250 22656/32000 (71%)] Loss: 0.06647 (QuantReg: 9.44499) QuantErr: 9.44499 batch_time=0.65404 
Train Epoch: 35 [188/250 24064/32000 (75%)] Loss: 0.05872 (QuantReg: 9.29830) QuantErr: 9.29830 batch_time=0.64076 
Train Epoch: 35 [199/250 25472/32000 (80%)] Loss: 0.06207 (QuantReg: 9.19268) QuantErr: 9.19268 batch_time=0.65336 
Train Epoch: 35 [210/250 26880/32000 (84%)] Loss: 0.07514 (QuantReg: 9.30969) QuantErr: 9.30969 batch_time=0.65092 
Train Epoch: 35 [221/250 28288/32000 (88%)] Loss: 0.05211 (QuantReg: 9.22436) QuantErr: 9.22436 batch_time=0.64964 
Train Epoch: 35 [232/250 29696/32000 (93%)] Loss: 0.06655 (QuantReg: 9.22410) QuantErr: 9.22410 batch_time=0.64368 
Train Epoch: 35 [243/250 31104/32000 (97%)] Loss: 0.14795 (QuantReg: 9.10048) QuantErr: 9.10048 batch_time=0.64362 
Train Epoch: 35 codebook_update_time=2.21436
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_ActivityNet_bs128/checkpoint-epoch35.pth ...
Done in 5.142s
removing stale ckpt [epoch 34] [took 0.00s]
 epoch          : 35
 loss           : 0.08550502416491508
 quant_reg      : 9.271390216827392
 quant_err      : 9.271390216827392
 learning_rate  : 3.1556711650327163e-06
 n_samples      : 1120000
 n_steps        : 8750
 ActivityNet_val1_test/t2v_metrics/R1: 19.01565995525727
 ActivityNet_val1_test/t2v_metrics/R5: 48.810250152532035
 ActivityNet_val1_test/t2v_metrics/R10: 64.67358145210494
 ActivityNet_val1_test/t2v_metrics/R50: 88.28553996339231
 ActivityNet_val1_test/t2v_metrics/MedR: 6.0
 ActivityNet_val1_test/t2v_metrics/MeanR: 37.62070368110636
 ActivityNet_val1_test/t2v_metrics/geometric_mean_R1-R5-R10: 39.15462923677865
 ActivityNet_val1_test/v2t_metrics/R1: 19.84950172869636
 ActivityNet_val1_test/v2t_metrics/R5: 49.908480780964005
 ActivityNet_val1_test/v2t_metrics/R10: 64.97864551555827
 ActivityNet_val1_test/v2t_metrics/R50: 88.75330486068741
 ActivityNet_val1_test/v2t_metrics/MedR: 6.0
 ActivityNet_val1_test/v2t_metrics/MeanR: 34.277811673784825
 ActivityNet_val1_test/v2t_metrics/geometric_mean_R1-R5-R10: 40.077276842140726
 mnt_best       : 39.37279520634257
 not_improved_count: 5
Train Epoch: 36 [1/250 128/32000 (0%)] Loss: 0.12812 (QuantReg: 9.24421) QuantErr: 9.24421 batch_time=26.09615 
Train Epoch: 36 [12/250 1536/32000 (5%)] Loss: 0.05035 (QuantReg: 9.28477) QuantErr: 9.28477 batch_time=0.65953 
Train Epoch: 36 [23/250 2944/32000 (9%)] Loss: 0.07902 (QuantReg: 9.31839) QuantErr: 9.31839 batch_time=0.65655 
Train Epoch: 36 [34/250 4352/32000 (14%)] Loss: 0.06224 (QuantReg: 9.14723) QuantErr: 9.14723 batch_time=1.39901 
Train Epoch: 36 [45/250 5760/32000 (18%)] Loss: 0.06839 (QuantReg: 9.31799) QuantErr: 9.31799 batch_time=0.64613 
Train Epoch: 36 [56/250 7168/32000 (22%)] Loss: 0.10923 (QuantReg: 9.08393) QuantErr: 9.08393 batch_time=0.64862 
Train Epoch: 36 [67/250 8576/32000 (27%)] Loss: 0.08696 (QuantReg: 9.20700) QuantErr: 9.20700 batch_time=0.63979 
Train Epoch: 36 [78/250 9984/32000 (31%)] Loss: 0.08564 (QuantReg: 9.15499) QuantErr: 9.15499 batch_time=4.73457 
Train Epoch: 36 [89/250 11392/32000 (36%)] Loss: 0.11381 (QuantReg: 9.19752) QuantErr: 9.19752 batch_time=0.65194 
Train Epoch: 36 [100/250 12800/32000 (40%)] Loss: 0.08850 (QuantReg: 9.27572) QuantErr: 9.27572 batch_time=0.63918 
Train Epoch: 36 [111/250 14208/32000 (44%)] Loss: 0.07831 (QuantReg: 9.10624) QuantErr: 9.10624 batch_time=0.65208 
Train Epoch: 36 [122/250 15616/32000 (49%)] Loss: 0.09157 (QuantReg: 9.28069) QuantErr: 9.28069 batch_time=0.66533 
Train Epoch: 36 [133/250 17024/32000 (53%)] Loss: 0.05922 (QuantReg: 9.17615) QuantErr: 9.17615 batch_time=0.65904 
Train Epoch: 36 [144/250 18432/32000 (58%)] Loss: 0.05800 (QuantReg: 9.28907) QuantErr: 9.28907 batch_time=0.65963 
Train Epoch: 36 [155/250 19840/32000 (62%)] Loss: 0.09415 (QuantReg: 9.22730) QuantErr: 9.22730 batch_time=0.67057 
Train Epoch: 36 [166/250 21248/32000 (66%)] Loss: 0.09961 (QuantReg: 9.06239) QuantErr: 9.06239 batch_time=0.64379 
Train Epoch: 36 [177/250 22656/32000 (71%)] Loss: 0.06416 (QuantReg: 9.23524) QuantErr: 9.23524 batch_time=0.65546 
Train Epoch: 36 [188/250 24064/32000 (75%)] Loss: 0.09333 (QuantReg: 9.22457) QuantErr: 9.22457 batch_time=0.64847 
Train Epoch: 36 [199/250 25472/32000 (80%)] Loss: 0.09300 (QuantReg: 9.26307) QuantErr: 9.26307 batch_time=0.65593 
Train Epoch: 36 [210/250 26880/32000 (84%)] Loss: 0.09215 (QuantReg: 9.34710) QuantErr: 9.34710 batch_time=0.64200 
Train Epoch: 36 [221/250 28288/32000 (88%)] Loss: 0.09388 (QuantReg: 9.30800) QuantErr: 9.30800 batch_time=0.67827 
Train Epoch: 36 [232/250 29696/32000 (93%)] Loss: 0.11070 (QuantReg: 9.20932) QuantErr: 9.20932 batch_time=0.66517 
Train Epoch: 36 [243/250 31104/32000 (97%)] Loss: 0.09905 (QuantReg: 9.14499) QuantErr: 9.14499 batch_time=0.65024 
Train Epoch: 36 codebook_update_time=1.81587
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_ActivityNet_bs128/checkpoint-epoch36.pth ...
Done in 13.806s
removing stale ckpt [epoch 35] [took 0.05s]
 epoch          : 36
 loss           : 0.0878603936880827
 quant_reg      : 9.225257934570312
 quant_err      : 9.225257934570312
 learning_rate  : 3.1556711650327163e-06
 n_samples      : 1152000
 n_steps        : 9000
 ActivityNet_val1_test/t2v_metrics/R1: 18.89363432987594
 ActivityNet_val1_test/t2v_metrics/R5: 48.5865365059996
 ActivityNet_val1_test/t2v_metrics/R10: 64.42953020134229
 ActivityNet_val1_test/t2v_metrics/R50: 88.67195444376652
 ActivityNet_val1_test/t2v_metrics/MedR: 6.0
 ActivityNet_val1_test/t2v_metrics/MeanR: 37.17551352450681
 ActivityNet_val1_test/t2v_metrics/geometric_mean_R1-R5-R10: 38.96178127217182
 ActivityNet_val1_test/v2t_metrics/R1: 19.82916412446614
 ActivityNet_val1_test/v2t_metrics/R5: 49.88814317673378
 ActivityNet_val1_test/v2t_metrics/R10: 65.1006711409396
 ActivityNet_val1_test/v2t_metrics/R50: 88.99735611145007
 ActivityNet_val1_test/v2t_metrics/MedR: 6.0
 ActivityNet_val1_test/v2t_metrics/MeanR: 34.11287370347773
 ActivityNet_val1_test/v2t_metrics/geometric_mean_R1-R5-R10: 40.08320172662328
 mnt_best       : 39.37279520634257
 not_improved_count: 6
Train Epoch: 37 [1/250 128/32000 (0%)] Loss: 0.06744 (QuantReg: 9.14609) QuantErr: 9.14609 batch_time=25.80169 
Train Epoch: 37 [12/250 1536/32000 (5%)] Loss: 0.10538 (QuantReg: 9.13936) QuantErr: 9.13936 batch_time=0.80313 
Train Epoch: 37 [23/250 2944/32000 (9%)] Loss: 0.07858 (QuantReg: 9.15618) QuantErr: 9.15618 batch_time=0.65789 
Train Epoch: 37 [34/250 4352/32000 (14%)] Loss: 0.06787 (QuantReg: 9.16346) QuantErr: 9.16346 batch_time=0.66513 
Train Epoch: 37 [45/250 5760/32000 (18%)] Loss: 0.10916 (QuantReg: 8.95032) QuantErr: 8.95032 batch_time=1.78234 
Train Epoch: 37 [56/250 7168/32000 (22%)] Loss: 0.09971 (QuantReg: 9.31592) QuantErr: 9.31592 batch_time=0.68327 
Train Epoch: 37 [67/250 8576/32000 (27%)] Loss: 0.13005 (QuantReg: 9.20271) QuantErr: 9.20271 batch_time=0.69187 
Train Epoch: 37 [78/250 9984/32000 (31%)] Loss: 0.05855 (QuantReg: 9.16492) QuantErr: 9.16492 batch_time=0.64766 
Train Epoch: 37 [89/250 11392/32000 (36%)] Loss: 0.08570 (QuantReg: 9.21215) QuantErr: 9.21215 batch_time=0.63813 
Train Epoch: 37 [100/250 12800/32000 (40%)] Loss: 0.11126 (QuantReg: 9.19409) QuantErr: 9.19409 batch_time=0.64489 
Train Epoch: 37 [111/250 14208/32000 (44%)] Loss: 0.08282 (QuantReg: 9.29517) QuantErr: 9.29517 batch_time=0.64523 
Train Epoch: 37 [122/250 15616/32000 (49%)] Loss: 0.06813 (QuantReg: 9.27395) QuantErr: 9.27395 batch_time=0.65356 
Train Epoch: 37 [133/250 17024/32000 (53%)] Loss: 0.08467 (QuantReg: 9.27440) QuantErr: 9.27440 batch_time=0.64942 
Train Epoch: 37 [144/250 18432/32000 (58%)] Loss: 0.12550 (QuantReg: 9.24133) QuantErr: 9.24133 batch_time=3.20779 
Train Epoch: 37 [155/250 19840/32000 (62%)] Loss: 0.08429 (QuantReg: 8.98385) QuantErr: 8.98385 batch_time=0.64924 
Train Epoch: 37 [166/250 21248/32000 (66%)] Loss: 0.10760 (QuantReg: 9.18568) QuantErr: 9.18568 batch_time=0.64584 
Train Epoch: 37 [177/250 22656/32000 (71%)] Loss: 0.12488 (QuantReg: 9.21902) QuantErr: 9.21902 batch_time=0.64729 
Train Epoch: 37 [188/250 24064/32000 (75%)] Loss: 0.08849 (QuantReg: 9.07084) QuantErr: 9.07084 batch_time=0.65486 
Train Epoch: 37 [199/250 25472/32000 (80%)] Loss: 0.07539 (QuantReg: 9.17863) QuantErr: 9.17863 batch_time=0.68637 
Train Epoch: 37 [210/250 26880/32000 (84%)] Loss: 0.07960 (QuantReg: 9.20525) QuantErr: 9.20525 batch_time=0.64345 
Train Epoch: 37 [221/250 28288/32000 (88%)] Loss: 0.06353 (QuantReg: 9.17251) QuantErr: 9.17251 batch_time=0.64594 
Train Epoch: 37 [232/250 29696/32000 (93%)] Loss: 0.05020 (QuantReg: 9.21949) QuantErr: 9.21949 batch_time=0.67397 
Train Epoch: 37 [243/250 31104/32000 (97%)] Loss: 0.08105 (QuantReg: 9.15810) QuantErr: 9.15810 batch_time=0.65748 
Train Epoch: 37 codebook_update_time=1.87580
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_ActivityNet_bs128/checkpoint-epoch37.pth ...
Done in 5.421s
removing stale ckpt [epoch 36] [took 0.01s]
 epoch          : 37
 loss           : 0.08971312500536442
 quant_reg      : 9.174611492156982
 quant_err      : 9.174611492156982
 learning_rate  : 2.6823204902778087e-06
 n_samples      : 1184000
 n_steps        : 9250
 ActivityNet_val1_test/t2v_metrics/R1: 18.91397193410616
 ActivityNet_val1_test/t2v_metrics/R5: 48.52552369330893
 ActivityNet_val1_test/t2v_metrics/R10: 64.69391905633516
 ActivityNet_val1_test/t2v_metrics/R50: 88.24486475493187
 ActivityNet_val1_test/t2v_metrics/MedR: 6.0
 ActivityNet_val1_test/t2v_metrics/MeanR: 37.8071995118975
 ActivityNet_val1_test/t2v_metrics/geometric_mean_R1-R5-R10: 39.01265232450051
 ActivityNet_val1_test/v2t_metrics/R1: 19.86983933292658
 ActivityNet_val1_test/v2t_metrics/R5: 49.70510473866179
 ActivityNet_val1_test/v2t_metrics/R10: 65.16168395363026
 ActivityNet_val1_test/v2t_metrics/R50: 88.67195444376652
 ActivityNet_val1_test/v2t_metrics/MedR: 6.0
 ActivityNet_val1_test/v2t_metrics/MeanR: 34.70286760219646
 ActivityNet_val1_test/v2t_metrics/geometric_mean_R1-R5-R10: 40.073986659852686
 mnt_best       : 39.37279520634257
 not_improved_count: 7
Train Epoch: 38 [1/250 128/32000 (0%)] Loss: 0.10798 (QuantReg: 9.03336) QuantErr: 9.03336 batch_time=22.06689 
Train Epoch: 38 [12/250 1536/32000 (5%)] Loss: 0.08937 (QuantReg: 9.16915) QuantErr: 9.16915 batch_time=0.79378 
Train Epoch: 38 [23/250 2944/32000 (9%)] Loss: 0.09748 (QuantReg: 8.98857) QuantErr: 8.98857 batch_time=0.65664 
Train Epoch: 38 [34/250 4352/32000 (14%)] Loss: 0.07366 (QuantReg: 9.22139) QuantErr: 9.22139 batch_time=0.64926 
Train Epoch: 38 [45/250 5760/32000 (18%)] Loss: 0.05945 (QuantReg: 9.23571) QuantErr: 9.23571 batch_time=0.64300 
Train Epoch: 38 [56/250 7168/32000 (22%)] Loss: 0.06487 (QuantReg: 9.12710) QuantErr: 9.12710 batch_time=0.64303 
Train Epoch: 38 [67/250 8576/32000 (27%)] Loss: 0.05565 (QuantReg: 9.01205) QuantErr: 9.01205 batch_time=0.64034 
Train Epoch: 38 [78/250 9984/32000 (31%)] Loss: 0.07011 (QuantReg: 9.27383) QuantErr: 9.27383 batch_time=0.64795 
Train Epoch: 38 [89/250 11392/32000 (36%)] Loss: 0.12759 (QuantReg: 9.26796) QuantErr: 9.26796 batch_time=0.65732 
Train Epoch: 38 [100/250 12800/32000 (40%)] Loss: 0.09579 (QuantReg: 9.07823) QuantErr: 9.07823 batch_time=0.64852 
Train Epoch: 38 [111/250 14208/32000 (44%)] Loss: 0.06091 (QuantReg: 9.16525) QuantErr: 9.16525 batch_time=0.65098 
Train Epoch: 38 [122/250 15616/32000 (49%)] Loss: 0.06823 (QuantReg: 9.11117) QuantErr: 9.11117 batch_time=0.64977 
Train Epoch: 38 [133/250 17024/32000 (53%)] Loss: 0.08170 (QuantReg: 9.10366) QuantErr: 9.10366 batch_time=0.64305 
Train Epoch: 38 [144/250 18432/32000 (58%)] Loss: 0.09714 (QuantReg: 9.08908) QuantErr: 9.08908 batch_time=0.63949 
Train Epoch: 38 [155/250 19840/32000 (62%)] Loss: 0.15469 (QuantReg: 9.21927) QuantErr: 9.21927 batch_time=1.08752 
Train Epoch: 38 [166/250 21248/32000 (66%)] Loss: 0.07292 (QuantReg: 9.04284) QuantErr: 9.04284 batch_time=0.65663 
Train Epoch: 38 [177/250 22656/32000 (71%)] Loss: 0.10957 (QuantReg: 8.98330) QuantErr: 8.98330 batch_time=0.64085 
Train Epoch: 38 [188/250 24064/32000 (75%)] Loss: 0.08079 (QuantReg: 9.12175) QuantErr: 9.12175 batch_time=0.63506 
Train Epoch: 38 [199/250 25472/32000 (80%)] Loss: 0.06800 (QuantReg: 9.04582) QuantErr: 9.04582 batch_time=0.63574 
Train Epoch: 38 [210/250 26880/32000 (84%)] Loss: 0.05322 (QuantReg: 9.26960) QuantErr: 9.26960 batch_time=0.64099 
Train Epoch: 38 [221/250 28288/32000 (88%)] Loss: 0.06785 (QuantReg: 9.14686) QuantErr: 9.14686 batch_time=0.69946 
Train Epoch: 38 [232/250 29696/32000 (93%)] Loss: 0.08284 (QuantReg: 8.99756) QuantErr: 8.99756 batch_time=0.65628 
Train Epoch: 38 [243/250 31104/32000 (97%)] Loss: 0.07615 (QuantReg: 9.14175) QuantErr: 9.14175 batch_time=0.64586 
Train Epoch: 38 codebook_update_time=1.87870
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_ActivityNet_bs128/checkpoint-epoch38.pth ...
Done in 3.992s
removing stale ckpt [epoch 37] [took 0.01s]
 epoch          : 38
 loss           : 0.08598776036500931
 quant_reg      : 9.131751094818116
 quant_err      : 9.131751094818116
 learning_rate  : 2.6823204902778087e-06
 n_samples      : 1216000
 n_steps        : 9500
 ActivityNet_val1_test/t2v_metrics/R1: 19.097010372178158
 ActivityNet_val1_test/t2v_metrics/R5: 48.52552369330893
 ActivityNet_val1_test/t2v_metrics/R10: 64.85661989017694
 ActivityNet_val1_test/t2v_metrics/R50: 88.26520235916209
 ActivityNet_val1_test/t2v_metrics/MedR: 6.0
 ActivityNet_val1_test/t2v_metrics/MeanR: 37.415395566402275
 ActivityNet_val1_test/t2v_metrics/geometric_mean_R1-R5-R10: 39.17087822176254
 ActivityNet_val1_test/v2t_metrics/R1: 19.72747610331503
 ActivityNet_val1_test/v2t_metrics/R5: 50.05084401057555
 ActivityNet_val1_test/v2t_metrics/R10: 65.64978645515558
 ActivityNet_val1_test/v2t_metrics/R50: 88.97701850721985
 ActivityNet_val1_test/v2t_metrics/MedR: 5.0
 ActivityNet_val1_test/v2t_metrics/MeanR: 34.03843807199512
 ActivityNet_val1_test/v2t_metrics/geometric_mean_R1-R5-R10: 40.1703315631184
 mnt_best       : 39.37279520634257
 not_improved_count: 8
Train Epoch: 39 [1/250 128/32000 (0%)] Loss: 0.06032 (QuantReg: 9.23988) QuantErr: 9.23988 batch_time=23.12100 
Train Epoch: 39 [12/250 1536/32000 (5%)] Loss: 0.07855 (QuantReg: 9.06980) QuantErr: 9.06980 batch_time=0.67859 
Train Epoch: 39 [23/250 2944/32000 (9%)] Loss: 0.09877 (QuantReg: 9.17885) QuantErr: 9.17885 batch_time=0.64917 
Train Epoch: 39 [34/250 4352/32000 (14%)] Loss: 0.06872 (QuantReg: 8.95157) QuantErr: 8.95157 batch_time=0.65710 
Train Epoch: 39 [45/250 5760/32000 (18%)] Loss: 0.10056 (QuantReg: 9.23114) QuantErr: 9.23114 batch_time=0.64902 
Train Epoch: 39 [56/250 7168/32000 (22%)] Loss: 0.06019 (QuantReg: 9.04095) QuantErr: 9.04095 batch_time=0.64378 
Train Epoch: 39 [67/250 8576/32000 (27%)] Loss: 0.08335 (QuantReg: 9.16005) QuantErr: 9.16005 batch_time=4.42946 
Train Epoch: 39 [78/250 9984/32000 (31%)] Loss: 0.06151 (QuantReg: 9.10321) QuantErr: 9.10321 batch_time=0.66500 
Train Epoch: 39 [89/250 11392/32000 (36%)] Loss: 0.05713 (QuantReg: 9.31681) QuantErr: 9.31681 batch_time=0.65169 
Train Epoch: 39 [100/250 12800/32000 (40%)] Loss: 0.08685 (QuantReg: 9.08558) QuantErr: 9.08558 batch_time=0.80860 
Train Epoch: 39 [111/250 14208/32000 (44%)] Loss: 0.08208 (QuantReg: 9.15377) QuantErr: 9.15377 batch_time=0.64858 
Train Epoch: 39 [122/250 15616/32000 (49%)] Loss: 0.07633 (QuantReg: 9.08810) QuantErr: 9.08810 batch_time=0.64035 
Train Epoch: 39 [133/250 17024/32000 (53%)] Loss: 0.12062 (QuantReg: 9.09516) QuantErr: 9.09516 batch_time=0.66343 
Train Epoch: 39 [144/250 18432/32000 (58%)] Loss: 0.06689 (QuantReg: 9.10878) QuantErr: 9.10878 batch_time=0.66764 
Train Epoch: 39 [155/250 19840/32000 (62%)] Loss: 0.10004 (QuantReg: 8.99575) QuantErr: 8.99575 batch_time=0.64517 
Train Epoch: 39 [166/250 21248/32000 (66%)] Loss: 0.10072 (QuantReg: 9.01350) QuantErr: 9.01350 batch_time=0.65208 
Train Epoch: 39 [177/250 22656/32000 (71%)] Loss: 0.11258 (QuantReg: 9.08850) QuantErr: 9.08850 batch_time=0.63593 
Train Epoch: 39 [188/250 24064/32000 (75%)] Loss: 0.07003 (QuantReg: 9.06758) QuantErr: 9.06758 batch_time=0.65886 
Train Epoch: 39 [199/250 25472/32000 (80%)] Loss: 0.08402 (QuantReg: 9.01654) QuantErr: 9.01654 batch_time=2.98015 
Train Epoch: 39 [210/250 26880/32000 (84%)] Loss: 0.07223 (QuantReg: 9.08362) QuantErr: 9.08362 batch_time=0.66305 
Train Epoch: 39 [221/250 28288/32000 (88%)] Loss: 0.07495 (QuantReg: 9.11007) QuantErr: 9.11007 batch_time=0.64416 
Train Epoch: 39 [232/250 29696/32000 (93%)] Loss: 0.06740 (QuantReg: 9.13320) QuantErr: 9.13320 batch_time=0.65724 
Train Epoch: 39 [243/250 31104/32000 (97%)] Loss: 0.10794 (QuantReg: 9.14652) QuantErr: 9.14652 batch_time=0.65635 
Train Epoch: 39 codebook_update_time=2.34481
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_ActivityNet_bs128/checkpoint-epoch39.pth ...
Done in 3.911s
removing stale ckpt [epoch 38] [took 0.03s]
 epoch          : 39
 loss           : 0.08710288810729981
 quant_reg      : 9.094595886230469
 quant_err      : 9.094595886230469
 learning_rate  : 2.2799724167361374e-06
 n_samples      : 1248000
 n_steps        : 9750
 ActivityNet_val1_test/t2v_metrics/R1: 18.812283912955053
 ActivityNet_val1_test/t2v_metrics/R5: 48.810250152532035
 ActivityNet_val1_test/t2v_metrics/R10: 64.42953020134229
 ActivityNet_val1_test/t2v_metrics/R50: 87.8991254830181
 ActivityNet_val1_test/t2v_metrics/MedR: 6.0
 ActivityNet_val1_test/t2v_metrics/MeanR: 37.64490543014033
 ActivityNet_val1_test/t2v_metrics/geometric_mean_R1-R5-R10: 38.96540316806576
 ActivityNet_val1_test/v2t_metrics/R1: 19.666463290624364
 ActivityNet_val1_test/v2t_metrics/R5: 50.23388244864755
 ActivityNet_val1_test/v2t_metrics/R10: 65.48708562131381
 ActivityNet_val1_test/v2t_metrics/R50: 88.46857840146431
 ActivityNet_val1_test/v2t_metrics/MedR: 5.0
 ActivityNet_val1_test/v2t_metrics/MeanR: 34.878381126703275
 ActivityNet_val1_test/v2t_metrics/geometric_mean_R1-R5-R10: 40.14451586000405
 mnt_best       : 39.37279520634257
 not_improved_count: 9
Train Epoch: 40 [1/250 128/32000 (0%)] Loss: 0.08776 (QuantReg: 8.94518) QuantErr: 8.94518 batch_time=25.83189 
Train Epoch: 40 [12/250 1536/32000 (5%)] Loss: 0.11409 (QuantReg: 9.04218) QuantErr: 9.04218 batch_time=0.63737 
Train Epoch: 40 [23/250 2944/32000 (9%)] Loss: 0.10685 (QuantReg: 8.98052) QuantErr: 8.98052 batch_time=0.64029 
Train Epoch: 40 [34/250 4352/32000 (14%)] Loss: 0.08705 (QuantReg: 9.15299) QuantErr: 9.15299 batch_time=0.66008 
Train Epoch: 40 [45/250 5760/32000 (18%)] Loss: 0.07958 (QuantReg: 9.03015) QuantErr: 9.03015 batch_time=2.55355 
Train Epoch: 40 [56/250 7168/32000 (22%)] Loss: 0.08935 (QuantReg: 9.13149) QuantErr: 9.13149 batch_time=0.65731 
Train Epoch: 40 [67/250 8576/32000 (27%)] Loss: 0.06251 (QuantReg: 9.08323) QuantErr: 9.08323 batch_time=0.68409 
Train Epoch: 40 [78/250 9984/32000 (31%)] Loss: 0.10387 (QuantReg: 8.96008) QuantErr: 8.96008 batch_time=0.66666 
Train Epoch: 40 [89/250 11392/32000 (36%)] Loss: 0.06487 (QuantReg: 9.03051) QuantErr: 9.03051 batch_time=0.64697 
Train Epoch: 40 [100/250 12800/32000 (40%)] Loss: 0.11915 (QuantReg: 8.87385) QuantErr: 8.87385 batch_time=0.64859 
Train Epoch: 40 [111/250 14208/32000 (44%)] Loss: 0.08196 (QuantReg: 9.06461) QuantErr: 9.06461 batch_time=0.66356 
Train Epoch: 40 [122/250 15616/32000 (49%)] Loss: 0.12186 (QuantReg: 9.17875) QuantErr: 9.17875 batch_time=0.65668 
Train Epoch: 40 [133/250 17024/32000 (53%)] Loss: 0.14197 (QuantReg: 8.96900) QuantErr: 8.96900 batch_time=0.65367 
Train Epoch: 40 [144/250 18432/32000 (58%)] Loss: 0.11066 (QuantReg: 9.02206) QuantErr: 9.02206 batch_time=0.65512 
Train Epoch: 40 [155/250 19840/32000 (62%)] Loss: 0.11350 (QuantReg: 9.00321) QuantErr: 9.00321 batch_time=0.65000 
Train Epoch: 40 [166/250 21248/32000 (66%)] Loss: 0.10452 (QuantReg: 9.12638) QuantErr: 9.12638 batch_time=0.67152 
Train Epoch: 40 [177/250 22656/32000 (71%)] Loss: 0.09064 (QuantReg: 9.01135) QuantErr: 9.01135 batch_time=0.69494 
Train Epoch: 40 [188/250 24064/32000 (75%)] Loss: 0.09589 (QuantReg: 9.11928) QuantErr: 9.11928 batch_time=0.66547 
Train Epoch: 40 [199/250 25472/32000 (80%)] Loss: 0.10896 (QuantReg: 9.16173) QuantErr: 9.16173 batch_time=0.64443 
Train Epoch: 40 [210/250 26880/32000 (84%)] Loss: 0.10948 (QuantReg: 9.19663) QuantErr: 9.19663 batch_time=0.71557 
Train Epoch: 40 [221/250 28288/32000 (88%)] Loss: 0.05520 (QuantReg: 9.17320) QuantErr: 9.17320 batch_time=0.64341 
Train Epoch: 40 [232/250 29696/32000 (93%)] Loss: 0.10684 (QuantReg: 8.97784) QuantErr: 8.97784 batch_time=0.64749 
Train Epoch: 40 [243/250 31104/32000 (97%)] Loss: 0.07074 (QuantReg: 9.04363) QuantErr: 9.04363 batch_time=0.65263 
Train Epoch: 40 codebook_update_time=1.99349
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_ActivityNet_bs128/checkpoint-epoch40.pth ...
Done in 6.567s
removing stale ckpt [epoch 39] [took 0.15s]
 epoch          : 40
 loss           : 0.08874559389054776
 quant_reg      : 9.056332992553711
 quant_err      : 9.056332992553711
 learning_rate  : 2.2799724167361374e-06
 n_samples      : 1280000
 n_steps        : 10000
 ActivityNet_val1_test/t2v_metrics/R1: 18.934309538336382
 ActivityNet_val1_test/t2v_metrics/R5: 48.13910921293471
 ActivityNet_val1_test/t2v_metrics/R10: 64.5312182224934
 ActivityNet_val1_test/t2v_metrics/R50: 88.1838519422412
 ActivityNet_val1_test/t2v_metrics/MedR: 6.0
 ActivityNet_val1_test/t2v_metrics/MeanR: 38.11978848891601
 ActivityNet_val1_test/t2v_metrics/geometric_mean_R1-R5-R10: 38.89010616465612
 ActivityNet_val1_test/v2t_metrics/R1: 19.808826520235915
 ActivityNet_val1_test/v2t_metrics/R5: 50.27455765710799
 ActivityNet_val1_test/v2t_metrics/R10: 65.42607280862315
 ActivityNet_val1_test/v2t_metrics/R50: 88.6516168395363
 ActivityNet_val1_test/v2t_metrics/MedR: 5.0
 ActivityNet_val1_test/v2t_metrics/MeanR: 34.540980272523896
 ActivityNet_val1_test/v2t_metrics/geometric_mean_R1-R5-R10: 40.23950408278955
 mnt_best       : 39.37279520634257
 not_improved_count: 10
Train Epoch: 41 [1/250 128/32000 (0%)] Loss: 0.11533 (QuantReg: 9.01019) QuantErr: 9.01019 batch_time=22.70467 
Train Epoch: 41 [12/250 1536/32000 (5%)] Loss: 0.11157 (QuantReg: 8.94367) QuantErr: 8.94367 batch_time=1.39049 
Train Epoch: 41 [23/250 2944/32000 (9%)] Loss: 0.11171 (QuantReg: 8.99761) QuantErr: 8.99761 batch_time=0.64724 
Train Epoch: 41 [34/250 4352/32000 (14%)] Loss: 0.08614 (QuantReg: 9.03659) QuantErr: 9.03659 batch_time=0.79935 
Train Epoch: 41 [45/250 5760/32000 (18%)] Loss: 0.05690 (QuantReg: 9.06716) QuantErr: 9.06716 batch_time=0.65852 
Train Epoch: 41 [56/250 7168/32000 (22%)] Loss: 0.09370 (QuantReg: 8.88567) QuantErr: 8.88567 batch_time=0.79064 
Train Epoch: 41 [67/250 8576/32000 (27%)] Loss: 0.10622 (QuantReg: 9.11111) QuantErr: 9.11111 batch_time=0.63500 
Train Epoch: 41 [78/250 9984/32000 (31%)] Loss: 0.09475 (QuantReg: 9.08118) QuantErr: 9.08118 batch_time=0.64273 
Train Epoch: 41 [89/250 11392/32000 (36%)] Loss: 0.10550 (QuantReg: 9.00237) QuantErr: 9.00237 batch_time=0.64745 
Train Epoch: 41 [100/250 12800/32000 (40%)] Loss: 0.10018 (QuantReg: 9.12658) QuantErr: 9.12658 batch_time=0.68029 
Train Epoch: 41 [111/250 14208/32000 (44%)] Loss: 0.10651 (QuantReg: 8.90971) QuantErr: 8.90971 batch_time=0.64690 
Train Epoch: 41 [122/250 15616/32000 (49%)] Loss: 0.08669 (QuantReg: 8.96793) QuantErr: 8.96793 batch_time=0.64508 
Train Epoch: 41 [133/250 17024/32000 (53%)] Loss: 0.08535 (QuantReg: 9.09462) QuantErr: 9.09462 batch_time=0.77071 
Train Epoch: 41 [144/250 18432/32000 (58%)] Loss: 0.07274 (QuantReg: 9.01699) QuantErr: 9.01699 batch_time=0.65196 
Train Epoch: 41 [155/250 19840/32000 (62%)] Loss: 0.09273 (QuantReg: 9.03209) QuantErr: 9.03209 batch_time=0.69709 
Train Epoch: 41 [166/250 21248/32000 (66%)] Loss: 0.09555 (QuantReg: 9.01240) QuantErr: 9.01240 batch_time=0.68478 
Train Epoch: 41 [177/250 22656/32000 (71%)] Loss: 0.14050 (QuantReg: 9.00036) QuantErr: 9.00036 batch_time=0.69119 
Train Epoch: 41 [188/250 24064/32000 (75%)] Loss: 0.09111 (QuantReg: 9.02797) QuantErr: 9.02797 batch_time=0.68662 
Train Epoch: 41 [199/250 25472/32000 (80%)] Loss: 0.11625 (QuantReg: 8.98882) QuantErr: 8.98882 batch_time=0.64796 
Train Epoch: 41 [210/250 26880/32000 (84%)] Loss: 0.06127 (QuantReg: 9.06964) QuantErr: 9.06964 batch_time=0.64662 
Train Epoch: 41 [221/250 28288/32000 (88%)] Loss: 0.10261 (QuantReg: 9.05318) QuantErr: 9.05318 batch_time=0.65202 
Train Epoch: 41 [232/250 29696/32000 (93%)] Loss: 0.06199 (QuantReg: 8.92687) QuantErr: 8.92687 batch_time=0.65451 
Train Epoch: 41 [243/250 31104/32000 (97%)] Loss: 0.08276 (QuantReg: 9.10831) QuantErr: 9.10831 batch_time=0.64386 
Train Epoch: 41 codebook_update_time=1.81160
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_ActivityNet_bs128/checkpoint-epoch41.pth ...
Done in 4.798s
removing stale ckpt [epoch 40] [took 0.01s]
 epoch          : 41
 loss           : 0.08723485074937344
 quant_reg      : 9.027112884521484
 quant_err      : 9.027112884521484
 learning_rate  : 1.9379765542257167e-06
 n_samples      : 1312000
 n_steps        : 10250
 ActivityNet_val1_test/t2v_metrics/R1: 18.89363432987594
 ActivityNet_val1_test/t2v_metrics/R5: 48.52552369330893
 ActivityNet_val1_test/t2v_metrics/R10: 64.67358145210494
 ActivityNet_val1_test/t2v_metrics/R50: 88.38722798454342
 ActivityNet_val1_test/t2v_metrics/MedR: 6.0
 ActivityNet_val1_test/t2v_metrics/MeanR: 37.63371974781371
 ActivityNet_val1_test/t2v_metrics/geometric_mean_R1-R5-R10: 38.99457722665168
 ActivityNet_val1_test/v2t_metrics/R1: 19.74781370754525
 ActivityNet_val1_test/v2t_metrics/R5: 50.152532031726665
 ActivityNet_val1_test/v2t_metrics/R10: 65.89383770591824
 ActivityNet_val1_test/v2t_metrics/R50: 88.67195444376652
 ActivityNet_val1_test/v2t_metrics/MedR: 5.0
 ActivityNet_val1_test/v2t_metrics/MeanR: 34.956274150905024
 ActivityNet_val1_test/v2t_metrics/geometric_mean_R1-R5-R10: 40.26109315295831
 mnt_best       : 39.37279520634257
 not_improved_count: 11
Train Epoch: 42 [1/250 128/32000 (0%)] Loss: 0.08582 (QuantReg: 8.90387) QuantErr: 8.90387 batch_time=24.00791 
Train Epoch: 42 [12/250 1536/32000 (5%)] Loss: 0.09035 (QuantReg: 9.07928) QuantErr: 9.07928 batch_time=0.64607 
Train Epoch: 42 [23/250 2944/32000 (9%)] Loss: 0.07702 (QuantReg: 9.09234) QuantErr: 9.09234 batch_time=0.64021 
Train Epoch: 42 [34/250 4352/32000 (14%)] Loss: 0.10858 (QuantReg: 8.95469) QuantErr: 8.95469 batch_time=0.65025 
Train Epoch: 42 [45/250 5760/32000 (18%)] Loss: 0.11261 (QuantReg: 8.95614) QuantErr: 8.95614 batch_time=0.65381 
Train Epoch: 42 [56/250 7168/32000 (22%)] Loss: 0.06933 (QuantReg: 9.02245) QuantErr: 9.02245 batch_time=0.64466 
Train Epoch: 42 [67/250 8576/32000 (27%)] Loss: 0.08266 (QuantReg: 8.99923) QuantErr: 8.99923 batch_time=0.64570 
Train Epoch: 42 [78/250 9984/32000 (31%)] Loss: 0.12628 (QuantReg: 8.98316) QuantErr: 8.98316 batch_time=0.64439 
Train Epoch: 42 [89/250 11392/32000 (36%)] Loss: 0.07415 (QuantReg: 9.04063) QuantErr: 9.04063 batch_time=0.64571 
Train Epoch: 42 [100/250 12800/32000 (40%)] Loss: 0.05574 (QuantReg: 9.00113) QuantErr: 9.00113 batch_time=0.64134 
Train Epoch: 42 [111/250 14208/32000 (44%)] Loss: 0.08541 (QuantReg: 8.97871) QuantErr: 8.97871 batch_time=0.64505 
Train Epoch: 42 [122/250 15616/32000 (49%)] Loss: 0.08492 (QuantReg: 9.01777) QuantErr: 9.01777 batch_time=0.65126 
Train Epoch: 42 [133/250 17024/32000 (53%)] Loss: 0.09256 (QuantReg: 9.21098) QuantErr: 9.21098 batch_time=6.95509 
Train Epoch: 42 [144/250 18432/32000 (58%)] Loss: 0.08301 (QuantReg: 8.99067) QuantErr: 8.99067 batch_time=0.64763 
Train Epoch: 42 [155/250 19840/32000 (62%)] Loss: 0.09903 (QuantReg: 9.08096) QuantErr: 9.08096 batch_time=0.65573 
Train Epoch: 42 [166/250 21248/32000 (66%)] Loss: 0.05436 (QuantReg: 9.06405) QuantErr: 9.06405 batch_time=0.64192 
Train Epoch: 42 [177/250 22656/32000 (71%)] Loss: 0.08401 (QuantReg: 8.85300) QuantErr: 8.85300 batch_time=0.64032 
Train Epoch: 42 [188/250 24064/32000 (75%)] Loss: 0.07652 (QuantReg: 9.03332) QuantErr: 9.03332 batch_time=0.63981 
Train Epoch: 42 [199/250 25472/32000 (80%)] Loss: 0.08481 (QuantReg: 9.09072) QuantErr: 9.09072 batch_time=0.65051 
Train Epoch: 42 [210/250 26880/32000 (84%)] Loss: 0.12005 (QuantReg: 8.95742) QuantErr: 8.95742 batch_time=0.64526 
Train Epoch: 42 [221/250 28288/32000 (88%)] Loss: 0.07194 (QuantReg: 8.93716) QuantErr: 8.93716 batch_time=0.63852 
Train Epoch: 42 [232/250 29696/32000 (93%)] Loss: 0.08094 (QuantReg: 9.00352) QuantErr: 9.00352 batch_time=0.65108 
Train Epoch: 42 [243/250 31104/32000 (97%)] Loss: 0.10192 (QuantReg: 8.98880) QuantErr: 8.98880 batch_time=0.65072 
Train Epoch: 42 codebook_update_time=1.71633
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_ActivityNet_bs128/checkpoint-epoch42.pth ...
Done in 4.261s
removing stale ckpt [epoch 41] [took 0.01s]
 epoch          : 42
 loss           : 0.08746256902813912
 quant_reg      : 8.990806060791016
 quant_err      : 8.990806060791016
 learning_rate  : 1.9379765542257167e-06
 n_samples      : 1344000
 n_steps        : 10500
 ActivityNet_val1_test/t2v_metrics/R1: 18.79194630872483
 ActivityNet_val1_test/t2v_metrics/R5: 48.78991254830181
 ActivityNet_val1_test/t2v_metrics/R10: 64.61256863941428
 ActivityNet_val1_test/t2v_metrics/R50: 88.02115110839944
 ActivityNet_val1_test/t2v_metrics/MedR: 6.0
 ActivityNet_val1_test/t2v_metrics/MeanR: 37.769371568029285
 ActivityNet_val1_test/t2v_metrics/geometric_mean_R1-R5-R10: 38.98279161681112
 ActivityNet_val1_test/v2t_metrics/R1: 19.82916412446614
 ActivityNet_val1_test/v2t_metrics/R5: 50.23388244864755
 ActivityNet_val1_test/v2t_metrics/R10: 65.46674801708359
 ActivityNet_val1_test/v2t_metrics/R50: 88.85499288183851
 ActivityNet_val1_test/v2t_metrics/MedR: 5.0
 ActivityNet_val1_test/v2t_metrics/MeanR: 34.696766320927395
 ActivityNet_val1_test/v2t_metrics/geometric_mean_R1-R5-R10: 40.25074967736483
 mnt_best       : 39.37279520634257
 not_improved_count: 12
Train Epoch: 43 [1/250 128/32000 (0%)] Loss: 0.11260 (QuantReg: 9.11242) QuantErr: 9.11242 batch_time=23.94380 
Train Epoch: 43 [12/250 1536/32000 (5%)] Loss: 0.06347 (QuantReg: 8.93692) QuantErr: 8.93692 batch_time=0.65981 
Train Epoch: 43 [23/250 2944/32000 (9%)] Loss: 0.09192 (QuantReg: 9.03625) QuantErr: 9.03625 batch_time=0.65331 
Train Epoch: 43 [34/250 4352/32000 (14%)] Loss: 0.08053 (QuantReg: 8.90900) QuantErr: 8.90900 batch_time=0.65316 
Train Epoch: 43 [45/250 5760/32000 (18%)] Loss: 0.07382 (QuantReg: 9.02675) QuantErr: 9.02675 batch_time=0.69398 
Train Epoch: 43 [56/250 7168/32000 (22%)] Loss: 0.06882 (QuantReg: 8.81519) QuantErr: 8.81519 batch_time=0.65955 
Train Epoch: 43 [67/250 8576/32000 (27%)] Loss: 0.13240 (QuantReg: 9.11193) QuantErr: 9.11193 batch_time=1.89267 
Train Epoch: 43 [78/250 9984/32000 (31%)] Loss: 0.07145 (QuantReg: 8.99155) QuantErr: 8.99155 batch_time=0.64096 
Train Epoch: 43 [89/250 11392/32000 (36%)] Loss: 0.09736 (QuantReg: 8.94945) QuantErr: 8.94945 batch_time=0.64359 
Train Epoch: 43 [100/250 12800/32000 (40%)] Loss: 0.06774 (QuantReg: 8.86250) QuantErr: 8.86250 batch_time=0.64544 
Train Epoch: 43 [111/250 14208/32000 (44%)] Loss: 0.05397 (QuantReg: 8.87304) QuantErr: 8.87304 batch_time=0.64221 
Train Epoch: 43 [122/250 15616/32000 (49%)] Loss: 0.04914 (QuantReg: 8.82908) QuantErr: 8.82908 batch_time=0.68043 
Train Epoch: 43 [133/250 17024/32000 (53%)] Loss: 0.05413 (QuantReg: 9.04986) QuantErr: 9.04986 batch_time=0.64978 
Train Epoch: 43 [144/250 18432/32000 (58%)] Loss: 0.10061 (QuantReg: 9.02839) QuantErr: 9.02839 batch_time=0.66225 
Train Epoch: 43 [155/250 19840/32000 (62%)] Loss: 0.06864 (QuantReg: 8.96160) QuantErr: 8.96160 batch_time=0.64975 
Train Epoch: 43 [166/250 21248/32000 (66%)] Loss: 0.08299 (QuantReg: 8.91011) QuantErr: 8.91011 batch_time=0.66259 
Train Epoch: 43 [177/250 22656/32000 (71%)] Loss: 0.09180 (QuantReg: 8.96842) QuantErr: 8.96842 batch_time=0.66139 
Train Epoch: 43 [188/250 24064/32000 (75%)] Loss: 0.06216 (QuantReg: 8.99391) QuantErr: 8.99391 batch_time=0.64821 
Train Epoch: 43 [199/250 25472/32000 (80%)] Loss: 0.06092 (QuantReg: 8.86057) QuantErr: 8.86057 batch_time=0.64191 
Train Epoch: 43 [210/250 26880/32000 (84%)] Loss: 0.07399 (QuantReg: 9.02731) QuantErr: 9.02731 batch_time=0.64819 
Train Epoch: 43 [221/250 28288/32000 (88%)] Loss: 0.11254 (QuantReg: 9.06165) QuantErr: 9.06165 batch_time=0.64848 
Train Epoch: 43 [232/250 29696/32000 (93%)] Loss: 0.09219 (QuantReg: 9.03738) QuantErr: 9.03738 batch_time=0.64416 
Train Epoch: 43 [243/250 31104/32000 (97%)] Loss: 0.08121 (QuantReg: 8.91964) QuantErr: 8.91964 batch_time=0.64716 
Train Epoch: 43 codebook_update_time=2.03750
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_ActivityNet_bs128/checkpoint-epoch43.pth ...
Done in 5.562s
removing stale ckpt [epoch 42] [took 0.59s]
 epoch          : 43
 loss           : 0.08817622052133084
 quant_reg      : 8.94800532913208
 quant_err      : 8.94800532913208
 learning_rate  : 1.6472800710918591e-06
 n_samples      : 1376000
 n_steps        : 10750
 ActivityNet_val1_test/t2v_metrics/R1: 19.03599755948749
 ActivityNet_val1_test/t2v_metrics/R5: 48.30181004677649
 ActivityNet_val1_test/t2v_metrics/R10: 64.67358145210494
 ActivityNet_val1_test/t2v_metrics/R50: 88.02115110839944
 ActivityNet_val1_test/t2v_metrics/MedR: 6.0
 ActivityNet_val1_test/t2v_metrics/MeanR: 38.14093959731544
 ActivityNet_val1_test/t2v_metrics/geometric_mean_R1-R5-R10: 39.03210612696054
 ActivityNet_val1_test/v2t_metrics/R1: 19.890176937156802
 ActivityNet_val1_test/v2t_metrics/R5: 49.74577994712223
 ActivityNet_val1_test/v2t_metrics/R10: 65.32438478747204
 ActivityNet_val1_test/v2t_metrics/R50: 88.57026642261542
 ActivityNet_val1_test/v2t_metrics/MedR: 6.0
 ActivityNet_val1_test/v2t_metrics/MeanR: 34.763677038844826
 ActivityNet_val1_test/v2t_metrics/geometric_mean_R1-R5-R10: 40.131932496520385
 mnt_best       : 39.37279520634257
 not_improved_count: 13
Train Epoch: 44 [1/250 128/32000 (0%)] Loss: 0.09984 (QuantReg: 9.00652) QuantErr: 9.00652 batch_time=23.12731 
Train Epoch: 44 [12/250 1536/32000 (5%)] Loss: 0.11969 (QuantReg: 8.98293) QuantErr: 8.98293 batch_time=0.64800 
Train Epoch: 44 [23/250 2944/32000 (9%)] Loss: 0.08912 (QuantReg: 9.05038) QuantErr: 9.05038 batch_time=0.66039 
Train Epoch: 44 [34/250 4352/32000 (14%)] Loss: 0.10062 (QuantReg: 8.76494) QuantErr: 8.76494 batch_time=0.65303 
Train Epoch: 44 [45/250 5760/32000 (18%)] Loss: 0.09044 (QuantReg: 9.01370) QuantErr: 9.01370 batch_time=0.66062 
Train Epoch: 44 [56/250 7168/32000 (22%)] Loss: 0.06709 (QuantReg: 8.89303) QuantErr: 8.89303 batch_time=0.64293 
Train Epoch: 44 [67/250 8576/32000 (27%)] Loss: 0.06388 (QuantReg: 8.91371) QuantErr: 8.91371 batch_time=1.29077 
Train Epoch: 44 [78/250 9984/32000 (31%)] Loss: 0.09245 (QuantReg: 8.97250) QuantErr: 8.97250 batch_time=0.65232 
Train Epoch: 44 [89/250 11392/32000 (36%)] Loss: 0.06147 (QuantReg: 9.02578) QuantErr: 9.02578 batch_time=0.65890 
Train Epoch: 44 [100/250 12800/32000 (40%)] Loss: 0.08189 (QuantReg: 8.94018) QuantErr: 8.94018 batch_time=0.65310 
Train Epoch: 44 [111/250 14208/32000 (44%)] Loss: 0.11040 (QuantReg: 8.73473) QuantErr: 8.73473 batch_time=0.65212 
Train Epoch: 44 [122/250 15616/32000 (49%)] Loss: 0.07942 (QuantReg: 9.00322) QuantErr: 9.00322 batch_time=0.65162 
Train Epoch: 44 [133/250 17024/32000 (53%)] Loss: 0.08901 (QuantReg: 8.86342) QuantErr: 8.86342 batch_time=0.64975 
Train Epoch: 44 [144/250 18432/32000 (58%)] Loss: 0.08828 (QuantReg: 8.84764) QuantErr: 8.84764 batch_time=1.88274 
Train Epoch: 44 [155/250 19840/32000 (62%)] Loss: 0.06047 (QuantReg: 8.88074) QuantErr: 8.88074 batch_time=0.65075 
Train Epoch: 44 [166/250 21248/32000 (66%)] Loss: 0.06451 (QuantReg: 8.99563) QuantErr: 8.99563 batch_time=0.67027 
Train Epoch: 44 [177/250 22656/32000 (71%)] Loss: 0.07341 (QuantReg: 8.95295) QuantErr: 8.95295 batch_time=0.64182 
Train Epoch: 44 [188/250 24064/32000 (75%)] Loss: 0.08177 (QuantReg: 8.88762) QuantErr: 8.88762 batch_time=0.73708 
Train Epoch: 44 [199/250 25472/32000 (80%)] Loss: 0.10300 (QuantReg: 8.90122) QuantErr: 8.90122 batch_time=0.64794 
Train Epoch: 44 [210/250 26880/32000 (84%)] Loss: 0.07838 (QuantReg: 8.84917) QuantErr: 8.84917 batch_time=1.16752 
Train Epoch: 44 [221/250 28288/32000 (88%)] Loss: 0.11674 (QuantReg: 8.76453) QuantErr: 8.76453 batch_time=0.65572 
Train Epoch: 44 [232/250 29696/32000 (93%)] Loss: 0.06102 (QuantReg: 9.01272) QuantErr: 9.01272 batch_time=0.64309 
Train Epoch: 44 [243/250 31104/32000 (97%)] Loss: 0.07145 (QuantReg: 8.90232) QuantErr: 8.90232 batch_time=0.65522 
Train Epoch: 44 codebook_update_time=1.92939
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_ActivityNet_bs128/checkpoint-epoch44.pth ...
Done in 4.655s
removing stale ckpt [epoch 43] [took 0.00s]
 epoch          : 44
 loss           : 0.08739278008043766
 quant_reg      : 8.918422012329101
 quant_err      : 8.918422012329101
 learning_rate  : 1.6472800710918591e-06
 n_samples      : 1408000
 n_steps        : 11000
 ActivityNet_val1_test/t2v_metrics/R1: 18.87329672564572
 ActivityNet_val1_test/t2v_metrics/R5: 48.52552369330893
 ActivityNet_val1_test/t2v_metrics/R10: 64.7345942647956
 ActivityNet_val1_test/t2v_metrics/R50: 88.02115110839944
 ActivityNet_val1_test/t2v_metrics/MedR: 6.0
 ActivityNet_val1_test/t2v_metrics/MeanR: 38.706935123042506
 ActivityNet_val1_test/t2v_metrics/geometric_mean_R1-R5-R10: 38.992834799140816
 ActivityNet_val1_test/v2t_metrics/R1: 19.910514541387023
 ActivityNet_val1_test/v2t_metrics/R5: 49.88814317673378
 ActivityNet_val1_test/v2t_metrics/R10: 65.16168395363026
 ActivityNet_val1_test/v2t_metrics/R50: 88.79398006914785
 ActivityNet_val1_test/v2t_metrics/MedR: 6.0
 ActivityNet_val1_test/v2t_metrics/MeanR: 35.06558877364247
 ActivityNet_val1_test/v2t_metrics/geometric_mean_R1-R5-R10: 40.15047684467324
 mnt_best       : 39.37279520634257
 not_improved_count: 14
Train Epoch: 45 [1/250 128/32000 (0%)] Loss: 0.14121 (QuantReg: 8.92763) QuantErr: 8.92763 batch_time=22.25698 
Train Epoch: 45 [12/250 1536/32000 (5%)] Loss: 0.09783 (QuantReg: 8.76718) QuantErr: 8.76718 batch_time=0.64780 
Train Epoch: 45 [23/250 2944/32000 (9%)] Loss: 0.07922 (QuantReg: 9.05981) QuantErr: 9.05981 batch_time=0.64737 
Train Epoch: 45 [34/250 4352/32000 (14%)] Loss: 0.06444 (QuantReg: 8.81839) QuantErr: 8.81839 batch_time=0.67665 
Train Epoch: 45 [45/250 5760/32000 (18%)] Loss: 0.11567 (QuantReg: 8.94887) QuantErr: 8.94887 batch_time=0.64925 
Train Epoch: 45 [56/250 7168/32000 (22%)] Loss: 0.06572 (QuantReg: 8.85440) QuantErr: 8.85440 batch_time=0.64286 
Train Epoch: 45 [67/250 8576/32000 (27%)] Loss: 0.06504 (QuantReg: 8.88759) QuantErr: 8.88759 batch_time=0.64365 
Train Epoch: 45 [78/250 9984/32000 (31%)] Loss: 0.06193 (QuantReg: 8.90325) QuantErr: 8.90325 batch_time=0.64640 
Train Epoch: 45 [89/250 11392/32000 (36%)] Loss: 0.05828 (QuantReg: 8.87004) QuantErr: 8.87004 batch_time=0.67742 
Train Epoch: 45 [100/250 12800/32000 (40%)] Loss: 0.10759 (QuantReg: 9.07658) QuantErr: 9.07658 batch_time=0.65050 
Train Epoch: 45 [111/250 14208/32000 (44%)] Loss: 0.08399 (QuantReg: 8.95563) QuantErr: 8.95563 batch_time=0.65291 
Train Epoch: 45 [122/250 15616/32000 (49%)] Loss: 0.07737 (QuantReg: 8.76682) QuantErr: 8.76682 batch_time=0.64951 
Train Epoch: 45 [133/250 17024/32000 (53%)] Loss: 0.10104 (QuantReg: 8.81740) QuantErr: 8.81740 batch_time=0.63905 
Train Epoch: 45 [144/250 18432/32000 (58%)] Loss: 0.12585 (QuantReg: 9.08211) QuantErr: 9.08211 batch_time=3.01162 
Train Epoch: 45 [155/250 19840/32000 (62%)] Loss: 0.09527 (QuantReg: 8.94420) QuantErr: 8.94420 batch_time=0.64755 
Train Epoch: 45 [166/250 21248/32000 (66%)] Loss: 0.08309 (QuantReg: 8.84277) QuantErr: 8.84277 batch_time=0.64730 
Train Epoch: 45 [177/250 22656/32000 (71%)] Loss: 0.10215 (QuantReg: 8.86786) QuantErr: 8.86786 batch_time=0.65527 
Train Epoch: 45 [188/250 24064/32000 (75%)] Loss: 0.06458 (QuantReg: 8.95836) QuantErr: 8.95836 batch_time=0.65662 
Train Epoch: 45 [199/250 25472/32000 (80%)] Loss: 0.12815 (QuantReg: 9.01765) QuantErr: 9.01765 batch_time=0.67262 
Train Epoch: 45 [210/250 26880/32000 (84%)] Loss: 0.12519 (QuantReg: 8.75760) QuantErr: 8.75760 batch_time=0.69410 
Train Epoch: 45 [221/250 28288/32000 (88%)] Loss: 0.07592 (QuantReg: 8.85503) QuantErr: 8.85503 batch_time=1.28543 
Train Epoch: 45 [232/250 29696/32000 (93%)] Loss: 0.11209 (QuantReg: 8.86109) QuantErr: 8.86109 batch_time=0.64832 
Train Epoch: 45 [243/250 31104/32000 (97%)] Loss: 0.08755 (QuantReg: 8.87704) QuantErr: 8.87704 batch_time=0.67595 
Train Epoch: 45 codebook_update_time=1.78694
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_ActivityNet_bs128/checkpoint-epoch45.pth ...
Done in 6.087s
removing stale ckpt [epoch 44] [took 0.02s]
 epoch          : 45
 loss           : 0.09065921479463578
 quant_reg      : 8.902678066253662
 quant_err      : 8.902678066253662
 learning_rate  : 1.4001880604280803e-06
 n_samples      : 1440000
 n_steps        : 11250
 ActivityNet_val1_test/t2v_metrics/R1: 18.8529591214155
 ActivityNet_val1_test/t2v_metrics/R5: 48.728899735611144
 ActivityNet_val1_test/t2v_metrics/R10: 64.55155582672361
 ActivityNet_val1_test/t2v_metrics/R50: 87.98047589993898
 ActivityNet_val1_test/t2v_metrics/MedR: 6.0
 ActivityNet_val1_test/t2v_metrics/MeanR: 38.30384380719951
 ActivityNet_val1_test/t2v_metrics/geometric_mean_R1-R5-R10: 38.996378930066705
 ActivityNet_val1_test/v2t_metrics/R1: 19.97152735407769
 ActivityNet_val1_test/v2t_metrics/R5: 49.603416717510676
 ActivityNet_val1_test/v2t_metrics/R10: 65.30404718324182
 ActivityNet_val1_test/v2t_metrics/R50: 88.6516168395363
 ActivityNet_val1_test/v2t_metrics/MedR: 6.0
 ActivityNet_val1_test/v2t_metrics/MeanR: 35.06833435021355
 ActivityNet_val1_test/v2t_metrics/geometric_mean_R1-R5-R10: 40.14403194816225
 mnt_best       : 39.37279520634257
 not_improved_count: 15
Train Epoch: 46 [1/250 128/32000 (0%)] Loss: 0.08491 (QuantReg: 8.99424) QuantErr: 8.99424 batch_time=22.12143 
Train Epoch: 46 [12/250 1536/32000 (5%)] Loss: 0.07487 (QuantReg: 8.86399) QuantErr: 8.86399 batch_time=0.64269 
Train Epoch: 46 [23/250 2944/32000 (9%)] Loss: 0.09710 (QuantReg: 8.89871) QuantErr: 8.89871 batch_time=0.63940 
Train Epoch: 46 [34/250 4352/32000 (14%)] Loss: 0.07108 (QuantReg: 8.73546) QuantErr: 8.73546 batch_time=0.65080 
Train Epoch: 46 [45/250 5760/32000 (18%)] Loss: 0.07056 (QuantReg: 8.83196) QuantErr: 8.83196 batch_time=0.66099 
Train Epoch: 46 [56/250 7168/32000 (22%)] Loss: 0.06135 (QuantReg: 8.99926) QuantErr: 8.99926 batch_time=0.63785 
Train Epoch: 46 [67/250 8576/32000 (27%)] Loss: 0.08003 (QuantReg: 8.87879) QuantErr: 8.87879 batch_time=0.63795 
Train Epoch: 46 [78/250 9984/32000 (31%)] Loss: 0.05717 (QuantReg: 8.86500) QuantErr: 8.86500 batch_time=0.65105 
Train Epoch: 46 [89/250 11392/32000 (36%)] Loss: 0.09171 (QuantReg: 8.82840) QuantErr: 8.82840 batch_time=0.65871 
Train Epoch: 46 [100/250 12800/32000 (40%)] Loss: 0.07102 (QuantReg: 8.83486) QuantErr: 8.83486 batch_time=0.69055 
Train Epoch: 46 [111/250 14208/32000 (44%)] Loss: 0.07257 (QuantReg: 8.81811) QuantErr: 8.81811 batch_time=0.65787 
Train Epoch: 46 [122/250 15616/32000 (49%)] Loss: 0.09008 (QuantReg: 8.70208) QuantErr: 8.70208 batch_time=0.64998 
Train Epoch: 46 [133/250 17024/32000 (53%)] Loss: 0.14348 (QuantReg: 8.74097) QuantErr: 8.74097 batch_time=0.65198 
Train Epoch: 46 [144/250 18432/32000 (58%)] Loss: 0.05950 (QuantReg: 8.92442) QuantErr: 8.92442 batch_time=1.09591 
Train Epoch: 46 [155/250 19840/32000 (62%)] Loss: 0.09185 (QuantReg: 8.89982) QuantErr: 8.89982 batch_time=0.63903 
Train Epoch: 46 [166/250 21248/32000 (66%)] Loss: 0.08176 (QuantReg: 8.91104) QuantErr: 8.91104 batch_time=0.64208 
Train Epoch: 46 [177/250 22656/32000 (71%)] Loss: 0.09444 (QuantReg: 8.83223) QuantErr: 8.83223 batch_time=0.65195 
Train Epoch: 46 [188/250 24064/32000 (75%)] Loss: 0.06556 (QuantReg: 8.90226) QuantErr: 8.90226 batch_time=0.65898 
Train Epoch: 46 [199/250 25472/32000 (80%)] Loss: 0.07056 (QuantReg: 8.97790) QuantErr: 8.97790 batch_time=1.57088 
Train Epoch: 46 [210/250 26880/32000 (84%)] Loss: 0.10161 (QuantReg: 8.85090) QuantErr: 8.85090 batch_time=4.17862 
Train Epoch: 46 [221/250 28288/32000 (88%)] Loss: 0.09244 (QuantReg: 8.88793) QuantErr: 8.88793 batch_time=0.64081 
Train Epoch: 46 [232/250 29696/32000 (93%)] Loss: 0.13809 (QuantReg: 8.89958) QuantErr: 8.89958 batch_time=0.64174 
Train Epoch: 46 [243/250 31104/32000 (97%)] Loss: 0.07334 (QuantReg: 8.77563) QuantErr: 8.77563 batch_time=0.65514 
Train Epoch: 46 codebook_update_time=1.89836
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_ActivityNet_bs128/checkpoint-epoch46.pth ...
Done in 4.084s
removing stale ckpt [epoch 45] [took 0.18s]
 epoch          : 46
 loss           : 0.08762189193069934
 quant_reg      : 8.880967262268067
 quant_err      : 8.880967262268067
 learning_rate  : 1.4001880604280803e-06
 n_samples      : 1472000
 n_steps        : 11500
 ActivityNet_val1_test/t2v_metrics/R1: 19.11734797640838
 ActivityNet_val1_test/t2v_metrics/R5: 48.28147244254627
 ActivityNet_val1_test/t2v_metrics/R10: 64.36851738865161
 ActivityNet_val1_test/t2v_metrics/R50: 87.79743746186699
 ActivityNet_val1_test/t2v_metrics/MedR: 6.0
 ActivityNet_val1_test/t2v_metrics/MeanR: 39.02298149278015
 ActivityNet_val1_test/t2v_metrics/geometric_mean_R1-R5-R10: 39.02059486645692
 ActivityNet_val1_test/v2t_metrics/R1: 19.95118974984747
 ActivityNet_val1_test/v2t_metrics/R5: 49.603416717510676
 ActivityNet_val1_test/v2t_metrics/R10: 65.01932072401871
 ActivityNet_val1_test/v2t_metrics/R50: 88.46857840146431
 ActivityNet_val1_test/v2t_metrics/MedR: 6.0
 ActivityNet_val1_test/v2t_metrics/MeanR: 35.5865365059996
 ActivityNet_val1_test/v2t_metrics/geometric_mean_R1-R5-R10: 40.07199271228812
 mnt_best       : 39.37279520634257
 not_improved_count: 16
Train Epoch: 47 [1/250 128/32000 (0%)] Loss: 0.07716 (QuantReg: 8.92952) QuantErr: 8.92952 batch_time=24.86658 
Train Epoch: 47 [12/250 1536/32000 (5%)] Loss: 0.09320 (QuantReg: 8.96152) QuantErr: 8.96152 batch_time=0.66790 
Train Epoch: 47 [23/250 2944/32000 (9%)] Loss: 0.07696 (QuantReg: 8.84635) QuantErr: 8.84635 batch_time=0.64338 
Train Epoch: 47 [34/250 4352/32000 (14%)] Loss: 0.09901 (QuantReg: 8.82717) QuantErr: 8.82717 batch_time=0.64781 
Train Epoch: 47 [45/250 5760/32000 (18%)] Loss: 0.07414 (QuantReg: 8.85728) QuantErr: 8.85728 batch_time=0.67086 
Train Epoch: 47 [56/250 7168/32000 (22%)] Loss: 0.07234 (QuantReg: 8.91429) QuantErr: 8.91429 batch_time=0.65835 
Train Epoch: 47 [67/250 8576/32000 (27%)] Loss: 0.07755 (QuantReg: 8.90725) QuantErr: 8.90725 batch_time=0.65050 
Train Epoch: 47 [78/250 9984/32000 (31%)] Loss: 0.06073 (QuantReg: 8.82247) QuantErr: 8.82247 batch_time=0.68687 
Train Epoch: 47 [89/250 11392/32000 (36%)] Loss: 0.08679 (QuantReg: 8.74613) QuantErr: 8.74613 batch_time=0.67361 
Train Epoch: 47 [100/250 12800/32000 (40%)] Loss: 0.05438 (QuantReg: 8.95795) QuantErr: 8.95795 batch_time=0.64690 
Train Epoch: 47 [111/250 14208/32000 (44%)] Loss: 0.08058 (QuantReg: 8.72311) QuantErr: 8.72311 batch_time=0.67562 
Train Epoch: 47 [122/250 15616/32000 (49%)] Loss: 0.12839 (QuantReg: 8.93650) QuantErr: 8.93650 batch_time=0.64780 
Train Epoch: 47 [133/250 17024/32000 (53%)] Loss: 0.08672 (QuantReg: 8.90771) QuantErr: 8.90771 batch_time=1.85583 
Train Epoch: 47 [144/250 18432/32000 (58%)] Loss: 0.10779 (QuantReg: 8.90351) QuantErr: 8.90351 batch_time=0.64279 
Train Epoch: 47 [155/250 19840/32000 (62%)] Loss: 0.11498 (QuantReg: 8.81891) QuantErr: 8.81891 batch_time=0.63800 
Train Epoch: 47 [166/250 21248/32000 (66%)] Loss: 0.07364 (QuantReg: 8.74292) QuantErr: 8.74292 batch_time=0.64829 
Train Epoch: 47 [177/250 22656/32000 (71%)] Loss: 0.11025 (QuantReg: 8.85468) QuantErr: 8.85468 batch_time=0.66135 
Train Epoch: 47 [188/250 24064/32000 (75%)] Loss: 0.09163 (QuantReg: 8.91217) QuantErr: 8.91217 batch_time=0.64943 
Train Epoch: 47 [199/250 25472/32000 (80%)] Loss: 0.06536 (QuantReg: 8.75017) QuantErr: 8.75017 batch_time=0.64409 
Train Epoch: 47 [210/250 26880/32000 (84%)] Loss: 0.10971 (QuantReg: 8.87176) QuantErr: 8.87176 batch_time=0.95060 
Train Epoch: 47 [221/250 28288/32000 (88%)] Loss: 0.08454 (QuantReg: 8.84205) QuantErr: 8.84205 batch_time=0.66057 
Train Epoch: 47 [232/250 29696/32000 (93%)] Loss: 0.12276 (QuantReg: 8.66982) QuantErr: 8.66982 batch_time=0.64605 
Train Epoch: 47 [243/250 31104/32000 (97%)] Loss: 0.08858 (QuantReg: 8.86541) QuantErr: 8.86541 batch_time=1.08608 
Train Epoch: 47 codebook_update_time=1.81441
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_ActivityNet_bs128/checkpoint-epoch47.pth ...
Done in 4.038s
removing stale ckpt [epoch 46] [took 0.01s]
 epoch          : 47
 loss           : 0.08920167112350463
 quant_reg      : 8.867843082427978
 quant_err      : 8.867843082427978
 learning_rate  : 1.1901598513638682e-06
 n_samples      : 1504000
 n_steps        : 11750
 ActivityNet_val1_test/t2v_metrics/R1: 19.320724018710596
 ActivityNet_val1_test/t2v_metrics/R5: 48.56619890176937
 ActivityNet_val1_test/t2v_metrics/R10: 64.71425666056538
 ActivityNet_val1_test/t2v_metrics/R50: 88.0821639210901
 ActivityNet_val1_test/t2v_metrics/MedR: 6.0
 ActivityNet_val1_test/t2v_metrics/MeanR: 38.297945901972746
 ActivityNet_val1_test/t2v_metrics/geometric_mean_R1-R5-R10: 39.30542465346298
 ActivityNet_val1_test/v2t_metrics/R1: 19.890176937156802
 ActivityNet_val1_test/v2t_metrics/R5: 50.05084401057555
 ActivityNet_val1_test/v2t_metrics/R10: 64.97864551555827
 ActivityNet_val1_test/v2t_metrics/R50: 88.46857840146431
 ActivityNet_val1_test/v2t_metrics/MedR: 5.0
 ActivityNet_val1_test/v2t_metrics/MeanR: 35.094773235712836
 ActivityNet_val1_test/v2t_metrics/geometric_mean_R1-R5-R10: 40.14272978490286
 mnt_best       : 39.37279520634257
 not_improved_count: 17
Train Epoch: 48 [1/250 128/32000 (0%)] Loss: 0.10784 (QuantReg: 8.66697) QuantErr: 8.66697 batch_time=24.65139 
Train Epoch: 48 [12/250 1536/32000 (5%)] Loss: 0.08836 (QuantReg: 8.82222) QuantErr: 8.82222 batch_time=0.68075 
Train Epoch: 48 [23/250 2944/32000 (9%)] Loss: 0.07997 (QuantReg: 8.84107) QuantErr: 8.84107 batch_time=0.67112 
Train Epoch: 48 [34/250 4352/32000 (14%)] Loss: 0.13424 (QuantReg: 8.85260) QuantErr: 8.85260 batch_time=1.54778 
Train Epoch: 48 [45/250 5760/32000 (18%)] Loss: 0.07523 (QuantReg: 8.90218) QuantErr: 8.90218 batch_time=0.65637 
Train Epoch: 48 [56/250 7168/32000 (22%)] Loss: 0.06070 (QuantReg: 8.79387) QuantErr: 8.79387 batch_time=0.64298 
Train Epoch: 48 [67/250 8576/32000 (27%)] Loss: 0.11471 (QuantReg: 8.84319) QuantErr: 8.84319 batch_time=0.64942 
Train Epoch: 48 [78/250 9984/32000 (31%)] Loss: 0.12639 (QuantReg: 8.88132) QuantErr: 8.88132 batch_time=0.64325 
Train Epoch: 48 [89/250 11392/32000 (36%)] Loss: 0.08134 (QuantReg: 8.94613) QuantErr: 8.94613 batch_time=0.92443 
Train Epoch: 48 [100/250 12800/32000 (40%)] Loss: 0.13004 (QuantReg: 8.83574) QuantErr: 8.83574 batch_time=0.65196 
Train Epoch: 48 [111/250 14208/32000 (44%)] Loss: 0.08304 (QuantReg: 8.89592) QuantErr: 8.89592 batch_time=0.65514 
Train Epoch: 48 [122/250 15616/32000 (49%)] Loss: 0.08635 (QuantReg: 8.87254) QuantErr: 8.87254 batch_time=0.63747 
Train Epoch: 48 [133/250 17024/32000 (53%)] Loss: 0.09095 (QuantReg: 8.89265) QuantErr: 8.89265 batch_time=0.63891 
Train Epoch: 48 [144/250 18432/32000 (58%)] Loss: 0.10969 (QuantReg: 8.87119) QuantErr: 8.87119 batch_time=2.13915 
Train Epoch: 48 [155/250 19840/32000 (62%)] Loss: 0.08483 (QuantReg: 8.84925) QuantErr: 8.84925 batch_time=0.65082 
Train Epoch: 48 [166/250 21248/32000 (66%)] Loss: 0.07745 (QuantReg: 8.77376) QuantErr: 8.77376 batch_time=0.68409 
Train Epoch: 48 [177/250 22656/32000 (71%)] Loss: 0.11401 (QuantReg: 8.89277) QuantErr: 8.89277 batch_time=0.64929 
Train Epoch: 48 [188/250 24064/32000 (75%)] Loss: 0.06513 (QuantReg: 8.81174) QuantErr: 8.81174 batch_time=0.64879 
Train Epoch: 48 [199/250 25472/32000 (80%)] Loss: 0.06643 (QuantReg: 8.88272) QuantErr: 8.88272 batch_time=0.64663 
Train Epoch: 48 [210/250 26880/32000 (84%)] Loss: 0.08701 (QuantReg: 8.90290) QuantErr: 8.90290 batch_time=1.10550 
Train Epoch: 48 [221/250 28288/32000 (88%)] Loss: 0.07843 (QuantReg: 8.80738) QuantErr: 8.80738 batch_time=0.64597 
Train Epoch: 48 [232/250 29696/32000 (93%)] Loss: 0.11495 (QuantReg: 8.89857) QuantErr: 8.89857 batch_time=0.63798 
Train Epoch: 48 [243/250 31104/32000 (97%)] Loss: 0.05971 (QuantReg: 8.78261) QuantErr: 8.78261 batch_time=0.65263 
Train Epoch: 48 codebook_update_time=1.74975
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_ActivityNet_bs128/checkpoint-epoch48.pth ...
Done in 4.965s
removing stale ckpt [epoch 47] [took 0.00s]
 epoch          : 48
 loss           : 0.09336238980293274
 quant_reg      : 8.836048763275146
 quant_err      : 8.836048763275146
 learning_rate  : 1.1901598513638682e-06
 n_samples      : 1536000
 n_steps        : 12000
 ActivityNet_val1_test/t2v_metrics/R1: 18.832621517185277
 ActivityNet_val1_test/t2v_metrics/R5: 48.5865365059996
 ActivityNet_val1_test/t2v_metrics/R10: 64.7345942647956
 ActivityNet_val1_test/t2v_metrics/R50: 87.79743746186699
 ActivityNet_val1_test/t2v_metrics/MedR: 6.0
 ActivityNet_val1_test/t2v_metrics/MeanR: 38.83221476510067
 ActivityNet_val1_test/t2v_metrics/geometric_mean_R1-R5-R10: 38.981126314062784
 ActivityNet_val1_test/v2t_metrics/R1: 20.052877770998577
 ActivityNet_val1_test/v2t_metrics/R5: 50.03050640634533
 ActivityNet_val1_test/v2t_metrics/R10: 65.28370957901159
 ActivityNet_val1_test/v2t_metrics/R50: 88.6516168395363
 ActivityNet_val1_test/v2t_metrics/MedR: 5.0
 ActivityNet_val1_test/v2t_metrics/MeanR: 35.15476916819199
 ActivityNet_val1_test/v2t_metrics/geometric_mean_R1-R5-R10: 40.3093204327989
 mnt_best       : 39.37279520634257
 not_improved_count: 18
Train Epoch: 49 [1/250 128/32000 (0%)] Loss: 0.06563 (QuantReg: 8.88708) QuantErr: 8.88708 batch_time=26.04472 
Train Epoch: 49 [12/250 1536/32000 (5%)] Loss: 0.10424 (QuantReg: 8.79985) QuantErr: 8.79985 batch_time=2.05742 
Train Epoch: 49 [23/250 2944/32000 (9%)] Loss: 0.07686 (QuantReg: 8.98470) QuantErr: 8.98470 batch_time=0.65251 
Train Epoch: 49 [34/250 4352/32000 (14%)] Loss: 0.08215 (QuantReg: 8.93070) QuantErr: 8.93070 batch_time=0.65080 
Train Epoch: 49 [45/250 5760/32000 (18%)] Loss: 0.06421 (QuantReg: 8.83206) QuantErr: 8.83206 batch_time=0.80680 
Train Epoch: 49 [56/250 7168/32000 (22%)] Loss: 0.12190 (QuantReg: 8.76513) QuantErr: 8.76513 batch_time=0.64258 
Train Epoch: 49 [67/250 8576/32000 (27%)] Loss: 0.09281 (QuantReg: 8.79724) QuantErr: 8.79724 batch_time=0.65424 
Train Epoch: 49 [78/250 9984/32000 (31%)] Loss: 0.10421 (QuantReg: 8.81663) QuantErr: 8.81663 batch_time=0.64184 
Train Epoch: 49 [89/250 11392/32000 (36%)] Loss: 0.08266 (QuantReg: 8.74875) QuantErr: 8.74875 batch_time=0.65222 
Train Epoch: 49 [100/250 12800/32000 (40%)] Loss: 0.06465 (QuantReg: 8.85481) QuantErr: 8.85481 batch_time=0.64765 
Train Epoch: 49 [111/250 14208/32000 (44%)] Loss: 0.08669 (QuantReg: 8.84081) QuantErr: 8.84081 batch_time=0.63792 
Train Epoch: 49 [122/250 15616/32000 (49%)] Loss: 0.11019 (QuantReg: 8.77784) QuantErr: 8.77784 batch_time=0.65014 
Train Epoch: 49 [133/250 17024/32000 (53%)] Loss: 0.15496 (QuantReg: 8.85582) QuantErr: 8.85582 batch_time=0.64335 
Train Epoch: 49 [144/250 18432/32000 (58%)] Loss: 0.07102 (QuantReg: 8.93403) QuantErr: 8.93403 batch_time=2.94494 
Train Epoch: 49 [155/250 19840/32000 (62%)] Loss: 0.06856 (QuantReg: 8.79607) QuantErr: 8.79607 batch_time=1.05041 
Train Epoch: 49 [166/250 21248/32000 (66%)] Loss: 0.06507 (QuantReg: 8.78250) QuantErr: 8.78250 batch_time=0.65302 
Train Epoch: 49 [177/250 22656/32000 (71%)] Loss: 0.07322 (QuantReg: 8.82484) QuantErr: 8.82484 batch_time=0.66127 
Train Epoch: 49 [188/250 24064/32000 (75%)] Loss: 0.11128 (QuantReg: 8.77120) QuantErr: 8.77120 batch_time=0.65654 
Train Epoch: 49 [199/250 25472/32000 (80%)] Loss: 0.10769 (QuantReg: 8.96220) QuantErr: 8.96220 batch_time=0.65049 
Train Epoch: 49 [210/250 26880/32000 (84%)] Loss: 0.07452 (QuantReg: 8.67196) QuantErr: 8.67196 batch_time=0.66514 
Train Epoch: 49 [221/250 28288/32000 (88%)] Loss: 0.06638 (QuantReg: 8.73390) QuantErr: 8.73390 batch_time=0.64776 
Train Epoch: 49 [232/250 29696/32000 (93%)] Loss: 0.08607 (QuantReg: 8.83450) QuantErr: 8.83450 batch_time=0.65076 
Train Epoch: 49 [243/250 31104/32000 (97%)] Loss: 0.07409 (QuantReg: 8.78537) QuantErr: 8.78537 batch_time=0.67627 
Train Epoch: 49 codebook_update_time=2.04329
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_ActivityNet_bs128/checkpoint-epoch49.pth ...
Done in 4.498s
removing stale ckpt [epoch 48] [took 0.02s]
 epoch          : 49
 loss           : 0.08957988658547401
 quant_reg      : 8.82296809387207
 quant_err      : 8.82296809387207
 learning_rate  : 1.0116358736592879e-06
 n_samples      : 1568000
 n_steps        : 12250
 ActivityNet_val1_test/t2v_metrics/R1: 19.11734797640838
 ActivityNet_val1_test/t2v_metrics/R5: 48.261134838316046
 ActivityNet_val1_test/t2v_metrics/R10: 64.57189343095384
 ActivityNet_val1_test/t2v_metrics/R50: 88.06182631685988
 ActivityNet_val1_test/t2v_metrics/MedR: 6.0
 ActivityNet_val1_test/t2v_metrics/MeanR: 38.38377059182428
 ActivityNet_val1_test/t2v_metrics/geometric_mean_R1-R5-R10: 39.05616218432464
 ActivityNet_val1_test/v2t_metrics/R1: 19.625788082163922
 ActivityNet_val1_test/v2t_metrics/R5: 49.66442953020134
 ActivityNet_val1_test/v2t_metrics/R10: 65.24303437055114
 ActivityNet_val1_test/v2t_metrics/R50: 88.71262965222697
 ActivityNet_val1_test/v2t_metrics/MedR: 6.0
 ActivityNet_val1_test/v2t_metrics/MeanR: 35.01647345942648
 ActivityNet_val1_test/v2t_metrics/geometric_mean_R1-R5-R10: 39.914948129575954
 mnt_best       : 39.37279520634257
 not_improved_count: 19
Train Epoch: 50 [1/250 128/32000 (0%)] Loss: 0.12686 (QuantReg: 8.85949) QuantErr: 8.85949 batch_time=24.06268 
Train Epoch: 50 [12/250 1536/32000 (5%)] Loss: 0.07097 (QuantReg: 8.74715) QuantErr: 8.74715 batch_time=1.49250 
Train Epoch: 50 [23/250 2944/32000 (9%)] Loss: 0.15042 (QuantReg: 8.81100) QuantErr: 8.81100 batch_time=0.64121 
Train Epoch: 50 [34/250 4352/32000 (14%)] Loss: 0.07607 (QuantReg: 8.72039) QuantErr: 8.72039 batch_time=0.63573 
Train Epoch: 50 [45/250 5760/32000 (18%)] Loss: 0.09451 (QuantReg: 8.86438) QuantErr: 8.86438 batch_time=0.64385 
Train Epoch: 50 [56/250 7168/32000 (22%)] Loss: 0.08996 (QuantReg: 8.80313) QuantErr: 8.80313 batch_time=0.66093 
Train Epoch: 50 [67/250 8576/32000 (27%)] Loss: 0.06381 (QuantReg: 8.86827) QuantErr: 8.86827 batch_time=0.64001 
Train Epoch: 50 [78/250 9984/32000 (31%)] Loss: 0.08859 (QuantReg: 8.81597) QuantErr: 8.81597 batch_time=0.64489 
Train Epoch: 50 [89/250 11392/32000 (36%)] Loss: 0.14206 (QuantReg: 8.86297) QuantErr: 8.86297 batch_time=0.69315 
Train Epoch: 50 [100/250 12800/32000 (40%)] Loss: 0.08510 (QuantReg: 8.78193) QuantErr: 8.78193 batch_time=0.66112 
Train Epoch: 50 [111/250 14208/32000 (44%)] Loss: 0.10113 (QuantReg: 8.74636) QuantErr: 8.74636 batch_time=0.65593 
Train Epoch: 50 [122/250 15616/32000 (49%)] Loss: 0.07249 (QuantReg: 8.85620) QuantErr: 8.85620 batch_time=0.65369 
Train Epoch: 50 [133/250 17024/32000 (53%)] Loss: 0.06801 (QuantReg: 8.78621) QuantErr: 8.78621 batch_time=0.64506 
Train Epoch: 50 [144/250 18432/32000 (58%)] Loss: 0.09896 (QuantReg: 8.75414) QuantErr: 8.75414 batch_time=1.08364 
Train Epoch: 50 [155/250 19840/32000 (62%)] Loss: 0.09873 (QuantReg: 8.66496) QuantErr: 8.66496 batch_time=0.65049 
Train Epoch: 50 [166/250 21248/32000 (66%)] Loss: 0.08043 (QuantReg: 8.89489) QuantErr: 8.89489 batch_time=0.68649 
Train Epoch: 50 [177/250 22656/32000 (71%)] Loss: 0.10109 (QuantReg: 8.70956) QuantErr: 8.70956 batch_time=0.78741 
Train Epoch: 50 [188/250 24064/32000 (75%)] Loss: 0.10934 (QuantReg: 8.88640) QuantErr: 8.88640 batch_time=0.66086 
Train Epoch: 50 [199/250 25472/32000 (80%)] Loss: 0.09468 (QuantReg: 8.65533) QuantErr: 8.65533 batch_time=0.68016 
Train Epoch: 50 [210/250 26880/32000 (84%)] Loss: 0.06657 (QuantReg: 8.78367) QuantErr: 8.78367 batch_time=0.64903 
Train Epoch: 50 [221/250 28288/32000 (88%)] Loss: 0.07868 (QuantReg: 8.91596) QuantErr: 8.91596 batch_time=0.64727 
Train Epoch: 50 [232/250 29696/32000 (93%)] Loss: 0.06587 (QuantReg: 8.91159) QuantErr: 8.91159 batch_time=0.64952 
Train Epoch: 50 [243/250 31104/32000 (97%)] Loss: 0.08577 (QuantReg: 8.75058) QuantErr: 8.75058 batch_time=0.65117 
Train Epoch: 50 codebook_update_time=1.83556
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_ActivityNet_bs128/checkpoint-epoch50.pth ...
Done in 3.950s
removing stale ckpt [epoch 49] [took 0.10s]
 epoch          : 50
 loss           : 0.09369264556467533
 quant_reg      : 8.794505531311035
 quant_err      : 8.794505531311035
 learning_rate  : 1.0116358736592879e-06
 n_samples      : 1600000
 n_steps        : 12500
 ActivityNet_val1_test/t2v_metrics/R1: 18.364856619890176
 ActivityNet_val1_test/t2v_metrics/R5: 48.30181004677649
 ActivityNet_val1_test/t2v_metrics/R10: 64.34817978442139
 ActivityNet_val1_test/t2v_metrics/R50: 87.85845027455765
 ActivityNet_val1_test/t2v_metrics/MedR: 6.0
 ActivityNet_val1_test/t2v_metrics/MeanR: 38.78767541183649
 ActivityNet_val1_test/t2v_metrics/geometric_mean_R1-R5-R10: 38.5031036180532
 ActivityNet_val1_test/v2t_metrics/R1: 20.13422818791946
 ActivityNet_val1_test/v2t_metrics/R5: 49.50172869635957
 ActivityNet_val1_test/v2t_metrics/R10: 64.81594468171649
 ActivityNet_val1_test/v2t_metrics/R50: 88.5499288183852
 ActivityNet_val1_test/v2t_metrics/MedR: 6.0
 ActivityNet_val1_test/v2t_metrics/MeanR: 35.3481797844214
 ActivityNet_val1_test/v2t_metrics/geometric_mean_R1-R5-R10: 40.12475580629753
 mnt_best       : 39.37279520634257
 not_improved_count: 20
Final evaluation ...
Loading checkpoint from: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_ActivityNet_bs128/trained_model.pth ...
Ckpt loaded at epoch 30.
Saved similarity matrix (quantize videos) to /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_ActivityNet_bs128/ActivityNet-test-qv-sims.npy
Saved v2t similarity matrix (quantize texts) to /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_ActivityNet_bs128/ActivityNet-test-qt-sims.npy
ActivityNet_val1_test:
 t2v_metrics/R1/final_eval: 19.361399227171038
 t2v_metrics/R5/final_eval: 48.60687411022982
 t2v_metrics/R10/final_eval: 64.85661989017694
 t2v_metrics/R50/final_eval: 88.40756558877364
 t2v_metrics/MedR/final_eval: 6.0
 t2v_metrics/MeanR/final_eval: 35.37929631889364
 t2v_metrics/geometric_mean_R1-R5-R10/final_eval: 39.37279520634257
 v2t_metrics/R1/final_eval: 19.219035997559487
 v2t_metrics/R5/final_eval: 49.68476713443157
 v2t_metrics/R10/final_eval: 66.03620093552979
 v2t_metrics/R50/final_eval: 89.1193817368314
 v2t_metrics/MedR/final_eval: 6.0
 v2t_metrics/MeanR/final_eval: 33.153752287980474
 v2t_metrics/geometric_mean_R1-R5-R10/final_eval: 39.80267982038903
Best epoch for the monitored metric: 30
Script took 04h11m17s
The best performing ckpt can be found at /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_ActivityNet_bs128/trained_model.pth
