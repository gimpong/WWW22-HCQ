Experiment directory: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_LSMDC_t0.03
Preparing the dataloaders ...
Loading dataset LSMDC_full_trainval in ram ...
Finish loading dataset LSMDC_full_trainval in ram, taking 4760.364514827728 s.
Loading dataset LSMDC_full_test in ram ...
Finish loading dataset LSMDC_full_test in ram, taking 141.9911825656891 s.
Loading dataset LSMDC_full_test in ram ...
Finish loading dataset LSMDC_full_test in ram, taking 74.27371382713318 s.
Training ...
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_LSMDC_t0.03/checkpoint-epoch0.pth ...
Done in 2.998s
Updating 'best' checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_LSMDC_t0.03/checkpoint-epoch0.pth ...
Done in 6.191s
 epoch          : 0
 loss           : 0
 learning_rate  : 5e-05
 n_samples      : 0
 n_steps        : 0
 LSMDC_full_test/t2v_metrics/R1: 0.0
 LSMDC_full_test/t2v_metrics/R5: 0.9
 LSMDC_full_test/t2v_metrics/R10: 1.6
 LSMDC_full_test/t2v_metrics/R50: 4.4
 LSMDC_full_test/t2v_metrics/MedR: 508.5
 LSMDC_full_test/t2v_metrics/MeanR: 502.992
 LSMDC_full_test/t2v_metrics/geometric_mean_R1-R5-R10: 0.0
 LSMDC_full_test/v2t_metrics/R1: 0.0
 LSMDC_full_test/v2t_metrics/R5: 0.3
 LSMDC_full_test/v2t_metrics/R10: 0.9
 LSMDC_full_test/v2t_metrics/R50: 5.1
 LSMDC_full_test/v2t_metrics/MedR: 510.0
 LSMDC_full_test/v2t_metrics/MeanR: 501.125
 LSMDC_full_test/v2t_metrics/geometric_mean_R1-R5-R10: 0.0
 mnt_best       : 0.0
 not_improved_count: 0
Train Epoch: 1 [1/250 128/32000 (0%)] Loss: 9.98514 (QuantReg: 22.49566) QuantErr: 22.49566 batch_time=21.91914 
Train Epoch: 1 [12/250 1536/32000 (5%)] Loss: 9.48910 (QuantReg: 22.70084) QuantErr: 22.70084 batch_time=0.52391 
Train Epoch: 1 [23/250 2944/32000 (9%)] Loss: 8.93816 (QuantReg: 22.78124) QuantErr: 22.78124 batch_time=0.53800 
Train Epoch: 1 [34/250 4352/32000 (14%)] Loss: 8.30606 (QuantReg: 22.74493) QuantErr: 22.74493 batch_time=0.54080 
Train Epoch: 1 [45/250 5760/32000 (18%)] Loss: 7.99376 (QuantReg: 22.73358) QuantErr: 22.73358 batch_time=0.55327 
Train Epoch: 1 [56/250 7168/32000 (22%)] Loss: 7.56413 (QuantReg: 22.70661) QuantErr: 22.70661 batch_time=0.49225 
Train Epoch: 1 [67/250 8576/32000 (27%)] Loss: 7.37572 (QuantReg: 22.82521) QuantErr: 22.82521 batch_time=0.51497 
Train Epoch: 1 [78/250 9984/32000 (31%)] Loss: 7.04182 (QuantReg: 22.77296) QuantErr: 22.77296 batch_time=0.54121 
Train Epoch: 1 [89/250 11392/32000 (36%)] Loss: 7.10345 (QuantReg: 22.68091) QuantErr: 22.68091 batch_time=0.50533 
Train Epoch: 1 [100/250 12800/32000 (40%)] Loss: 6.74948 (QuantReg: 22.66408) QuantErr: 22.66408 batch_time=0.49888 
Train Epoch: 1 [111/250 14208/32000 (44%)] Loss: 7.16199 (QuantReg: 22.69939) QuantErr: 22.69939 batch_time=0.50002 
Train Epoch: 1 [122/250 15616/32000 (49%)] Loss: 6.28310 (QuantReg: 22.75757) QuantErr: 22.75757 batch_time=0.49195 
Train Epoch: 1 [133/250 17024/32000 (53%)] Loss: 6.71331 (QuantReg: 22.73063) QuantErr: 22.73063 batch_time=0.50863 
Train Epoch: 1 [144/250 18432/32000 (58%)] Loss: 7.05694 (QuantReg: 22.69620) QuantErr: 22.69620 batch_time=0.55725 
Train Epoch: 1 [155/250 19840/32000 (62%)] Loss: 6.58470 (QuantReg: 22.69415) QuantErr: 22.69415 batch_time=0.50642 
Train Epoch: 1 [166/250 21248/32000 (66%)] Loss: 6.22092 (QuantReg: 22.70195) QuantErr: 22.70195 batch_time=0.51615 
Train Epoch: 1 [177/250 22656/32000 (71%)] Loss: 6.95294 (QuantReg: 22.65427) QuantErr: 22.65427 batch_time=0.62338 
Train Epoch: 1 [188/250 24064/32000 (75%)] Loss: 6.37097 (QuantReg: 22.64941) QuantErr: 22.64941 batch_time=0.50990 
Train Epoch: 1 [199/250 25472/32000 (80%)] Loss: 6.09913 (QuantReg: 22.62158) QuantErr: 22.62158 batch_time=0.79666 
Train Epoch: 1 [210/250 26880/32000 (84%)] Loss: 6.46845 (QuantReg: 22.65393) QuantErr: 22.65393 batch_time=0.53439 
Train Epoch: 1 [221/250 28288/32000 (88%)] Loss: 5.78129 (QuantReg: 22.72780) QuantErr: 22.72780 batch_time=0.49858 
Train Epoch: 1 [232/250 29696/32000 (93%)] Loss: 5.81527 (QuantReg: 22.70182) QuantErr: 22.70182 batch_time=0.49669 
Train Epoch: 1 [243/250 31104/32000 (97%)] Loss: 7.06640 (QuantReg: 22.69108) QuantErr: 22.69108 batch_time=0.51602 
Train Epoch: 1 codebook_update_time=1.94815
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_LSMDC_t0.03/checkpoint-epoch1.pth ...
Done in 4.843s
Updating 'best' checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_LSMDC_t0.03/checkpoint-epoch1.pth ...
Done in 9.984s
 epoch          : 1
 loss           : 7.092259418487549
 quant_reg      : 22.70752062225342
 quant_err      : 22.70752062225342
 learning_rate  : 5e-05
 n_samples      : 32000
 n_steps        : 250
 LSMDC_full_test/t2v_metrics/R1: 7.6
 LSMDC_full_test/t2v_metrics/R5: 20.0
 LSMDC_full_test/t2v_metrics/R10: 27.5
 LSMDC_full_test/t2v_metrics/R50: 56.2
 LSMDC_full_test/t2v_metrics/MedR: 36.0
 LSMDC_full_test/t2v_metrics/MeanR: 101.252
 LSMDC_full_test/t2v_metrics/geometric_mean_R1-R5-R10: 16.10863572309328
 LSMDC_full_test/v2t_metrics/R1: 6.4
 LSMDC_full_test/v2t_metrics/R5: 16.9
 LSMDC_full_test/v2t_metrics/R10: 24.8
 LSMDC_full_test/v2t_metrics/R50: 56.4
 LSMDC_full_test/v2t_metrics/MedR: 40.0
 LSMDC_full_test/v2t_metrics/MeanR: 104.073
 LSMDC_full_test/v2t_metrics/geometric_mean_R1-R5-R10: 13.894388984895713
 mnt_best       : 16.10863572309328
 not_improved_count: 0
Train Epoch: 2 [1/250 128/32000 (0%)] Loss: 5.85796 (QuantReg: 7.25308) QuantErr: 7.25308 batch_time=18.86814 
Train Epoch: 2 [12/250 1536/32000 (5%)] Loss: 6.04242 (QuantReg: 7.27219) QuantErr: 7.27219 batch_time=0.50285 
Train Epoch: 2 [23/250 2944/32000 (9%)] Loss: 6.19086 (QuantReg: 7.79906) QuantErr: 7.79906 batch_time=0.51258 
Train Epoch: 2 [34/250 4352/32000 (14%)] Loss: 5.87618 (QuantReg: 7.99230) QuantErr: 7.99230 batch_time=0.49892 
Train Epoch: 2 [45/250 5760/32000 (18%)] Loss: 6.20215 (QuantReg: 7.49506) QuantErr: 7.49506 batch_time=0.50367 
Train Epoch: 2 [56/250 7168/32000 (22%)] Loss: 6.62935 (QuantReg: 8.32617) QuantErr: 8.32617 batch_time=0.50235 
Train Epoch: 2 [67/250 8576/32000 (27%)] Loss: 6.20273 (QuantReg: 7.93802) QuantErr: 7.93802 batch_time=0.48818 
Train Epoch: 2 [78/250 9984/32000 (31%)] Loss: 5.42480 (QuantReg: 8.37970) QuantErr: 8.37970 batch_time=0.54873 
Train Epoch: 2 [89/250 11392/32000 (36%)] Loss: 5.84970 (QuantReg: 8.87826) QuantErr: 8.87826 batch_time=0.51897 
Train Epoch: 2 [100/250 12800/32000 (40%)] Loss: 4.79398 (QuantReg: 9.53203) QuantErr: 9.53203 batch_time=0.50350 
Train Epoch: 2 [111/250 14208/32000 (44%)] Loss: 5.35992 (QuantReg: 8.67562) QuantErr: 8.67562 batch_time=0.51590 
Train Epoch: 2 [122/250 15616/32000 (49%)] Loss: 5.69155 (QuantReg: 9.19067) QuantErr: 9.19067 batch_time=0.52479 
Train Epoch: 2 [133/250 17024/32000 (53%)] Loss: 5.96735 (QuantReg: 8.86368) QuantErr: 8.86368 batch_time=0.51338 
Train Epoch: 2 [144/250 18432/32000 (58%)] Loss: 5.85022 (QuantReg: 9.32692) QuantErr: 9.32692 batch_time=1.15576 
Train Epoch: 2 [155/250 19840/32000 (62%)] Loss: 5.86422 (QuantReg: 9.06000) QuantErr: 9.06000 batch_time=0.54242 
Train Epoch: 2 [166/250 21248/32000 (66%)] Loss: 5.35152 (QuantReg: 9.44207) QuantErr: 9.44207 batch_time=0.51519 
Train Epoch: 2 [177/250 22656/32000 (71%)] Loss: 5.24609 (QuantReg: 9.37177) QuantErr: 9.37177 batch_time=0.52488 
Train Epoch: 2 [188/250 24064/32000 (75%)] Loss: 6.24805 (QuantReg: 9.97486) QuantErr: 9.97486 batch_time=0.51632 
Train Epoch: 2 [199/250 25472/32000 (80%)] Loss: 6.27312 (QuantReg: 9.72537) QuantErr: 9.72537 batch_time=0.50519 
Train Epoch: 2 [210/250 26880/32000 (84%)] Loss: 5.60582 (QuantReg: 10.09572) QuantErr: 10.09572 batch_time=0.51568 
Train Epoch: 2 [221/250 28288/32000 (88%)] Loss: 5.37810 (QuantReg: 9.83288) QuantErr: 9.83288 batch_time=0.50879 
Train Epoch: 2 [232/250 29696/32000 (93%)] Loss: 5.68556 (QuantReg: 10.38179) QuantErr: 10.38179 batch_time=0.49250 
Train Epoch: 2 [243/250 31104/32000 (97%)] Loss: 5.63055 (QuantReg: 9.80499) QuantErr: 9.80499 batch_time=0.53680 
Train Epoch: 2 codebook_update_time=1.82449
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_LSMDC_t0.03/checkpoint-epoch2.pth ...
Done in 7.122s
Updating 'best' checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_LSMDC_t0.03/checkpoint-epoch2.pth ...
Done in 12.001s
removing stale ckpt [epoch 1] [took 0.03s]
removing stale ckpt [epoch 0] [took 0.04s]
 epoch          : 2
 loss           : 5.724356561660767
 quant_reg      : 8.95188332939148
 quant_err      : 8.95188332939148
 learning_rate  : 4.75e-05
 n_samples      : 64000
 n_steps        : 500
 LSMDC_full_test/t2v_metrics/R1: 8.9
 LSMDC_full_test/t2v_metrics/R5: 22.0
 LSMDC_full_test/t2v_metrics/R10: 30.4
 LSMDC_full_test/t2v_metrics/R50: 61.2
 LSMDC_full_test/t2v_metrics/MedR: 32.0
 LSMDC_full_test/t2v_metrics/MeanR: 88.651
 LSMDC_full_test/t2v_metrics/geometric_mean_R1-R5-R10: 18.12294435664251
 LSMDC_full_test/v2t_metrics/R1: 7.4
 LSMDC_full_test/v2t_metrics/R5: 20.0
 LSMDC_full_test/v2t_metrics/R10: 29.9
 LSMDC_full_test/v2t_metrics/R50: 58.8
 LSMDC_full_test/v2t_metrics/MedR: 32.0
 LSMDC_full_test/v2t_metrics/MeanR: 91.443
 LSMDC_full_test/v2t_metrics/geometric_mean_R1-R5-R10: 16.417649054676367
 mnt_best       : 18.12294435664251
 not_improved_count: 0
Train Epoch: 3 [1/250 128/32000 (0%)] Loss: 5.66993 (QuantReg: 8.57466) QuantErr: 8.57466 batch_time=16.66592 
Train Epoch: 3 [12/250 1536/32000 (5%)] Loss: 5.12393 (QuantReg: 8.33496) QuantErr: 8.33496 batch_time=0.51031 
Train Epoch: 3 [23/250 2944/32000 (9%)] Loss: 5.67581 (QuantReg: 8.26792) QuantErr: 8.26792 batch_time=0.49946 
Train Epoch: 3 [34/250 4352/32000 (14%)] Loss: 5.11093 (QuantReg: 8.61757) QuantErr: 8.61757 batch_time=0.75288 
Train Epoch: 3 [45/250 5760/32000 (18%)] Loss: 5.09600 (QuantReg: 9.18409) QuantErr: 9.18409 batch_time=0.94599 
Train Epoch: 3 [56/250 7168/32000 (22%)] Loss: 5.23700 (QuantReg: 8.91786) QuantErr: 8.91786 batch_time=0.53305 
Train Epoch: 3 [67/250 8576/32000 (27%)] Loss: 5.09757 (QuantReg: 9.25711) QuantErr: 9.25711 batch_time=0.51697 
Train Epoch: 3 [78/250 9984/32000 (31%)] Loss: 5.72224 (QuantReg: 8.72482) QuantErr: 8.72482 batch_time=0.51812 
Train Epoch: 3 [89/250 11392/32000 (36%)] Loss: 5.17528 (QuantReg: 9.13321) QuantErr: 9.13321 batch_time=0.56856 
Train Epoch: 3 [100/250 12800/32000 (40%)] Loss: 4.88626 (QuantReg: 9.61572) QuantErr: 9.61572 batch_time=0.49939 
Train Epoch: 3 [111/250 14208/32000 (44%)] Loss: 5.13235 (QuantReg: 9.11867) QuantErr: 9.11867 batch_time=0.49586 
Train Epoch: 3 [122/250 15616/32000 (49%)] Loss: 5.02928 (QuantReg: 9.38129) QuantErr: 9.38129 batch_time=0.50290 
Train Epoch: 3 [133/250 17024/32000 (53%)] Loss: 5.16264 (QuantReg: 8.98436) QuantErr: 8.98436 batch_time=1.15353 
Train Epoch: 3 [144/250 18432/32000 (58%)] Loss: 5.35187 (QuantReg: 9.55695) QuantErr: 9.55695 batch_time=0.50277 
Train Epoch: 3 [155/250 19840/32000 (62%)] Loss: 4.81150 (QuantReg: 9.40491) QuantErr: 9.40491 batch_time=0.52853 
Train Epoch: 3 [166/250 21248/32000 (66%)] Loss: 5.22300 (QuantReg: 9.30166) QuantErr: 9.30166 batch_time=0.54446 
Train Epoch: 3 [177/250 22656/32000 (71%)] Loss: 4.88367 (QuantReg: 9.69522) QuantErr: 9.69522 batch_time=0.56793 
Train Epoch: 3 [188/250 24064/32000 (75%)] Loss: 5.37034 (QuantReg: 8.99964) QuantErr: 8.99964 batch_time=0.51057 
Train Epoch: 3 [199/250 25472/32000 (80%)] Loss: 4.71199 (QuantReg: 9.96626) QuantErr: 9.96626 batch_time=0.49373 
Train Epoch: 3 [210/250 26880/32000 (84%)] Loss: 5.21502 (QuantReg: 9.76937) QuantErr: 9.76937 batch_time=0.52039 
Train Epoch: 3 [221/250 28288/32000 (88%)] Loss: 4.86005 (QuantReg: 9.29659) QuantErr: 9.29659 batch_time=0.49999 
Train Epoch: 3 [232/250 29696/32000 (93%)] Loss: 4.99518 (QuantReg: 10.06645) QuantErr: 10.06645 batch_time=0.51903 
Train Epoch: 3 [243/250 31104/32000 (97%)] Loss: 5.05738 (QuantReg: 9.90371) QuantErr: 9.90371 batch_time=0.50786 
Train Epoch: 3 codebook_update_time=1.68347
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_LSMDC_t0.03/checkpoint-epoch3.pth ...
Done in 4.852s
Updating 'best' checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_LSMDC_t0.03/checkpoint-epoch3.pth ...
Done in 11.201s
removing stale ckpt [epoch 2] [took 0.71s]
 epoch          : 3
 loss           : 5.212393970489502
 quant_reg      : 9.19029257774353
 quant_err      : 9.19029257774353
 learning_rate  : 4.5125e-05
 n_samples      : 96000
 n_steps        : 750
 LSMDC_full_test/t2v_metrics/R1: 9.0
 LSMDC_full_test/t2v_metrics/R5: 24.6
 LSMDC_full_test/t2v_metrics/R10: 33.1
 LSMDC_full_test/t2v_metrics/R50: 62.3
 LSMDC_full_test/t2v_metrics/MedR: 26.0
 LSMDC_full_test/t2v_metrics/MeanR: 82.297
 LSMDC_full_test/t2v_metrics/geometric_mean_R1-R5-R10: 19.423844984319455
 LSMDC_full_test/v2t_metrics/R1: 8.4
 LSMDC_full_test/v2t_metrics/R5: 23.6
 LSMDC_full_test/v2t_metrics/R10: 34.1
 LSMDC_full_test/v2t_metrics/R50: 61.2
 LSMDC_full_test/v2t_metrics/MedR: 29.0
 LSMDC_full_test/v2t_metrics/MeanR: 85.204
 LSMDC_full_test/v2t_metrics/geometric_mean_R1-R5-R10: 18.908128974286086
 mnt_best       : 19.423844984319455
 not_improved_count: 0
Train Epoch: 4 [1/250 128/32000 (0%)] Loss: 5.21241 (QuantReg: 8.59566) QuantErr: 8.59566 batch_time=21.14341 
Train Epoch: 4 [12/250 1536/32000 (5%)] Loss: 4.85766 (QuantReg: 9.16453) QuantErr: 9.16453 batch_time=0.50008 
Train Epoch: 4 [23/250 2944/32000 (9%)] Loss: 5.23485 (QuantReg: 9.16356) QuantErr: 9.16356 batch_time=0.52414 
Train Epoch: 4 [34/250 4352/32000 (14%)] Loss: 4.86192 (QuantReg: 9.31500) QuantErr: 9.31500 batch_time=0.50870 
Train Epoch: 4 [45/250 5760/32000 (18%)] Loss: 4.42637 (QuantReg: 9.86557) QuantErr: 9.86557 batch_time=0.50966 
Train Epoch: 4 [56/250 7168/32000 (22%)] Loss: 4.38862 (QuantReg: 9.75531) QuantErr: 9.75531 batch_time=0.49321 
Train Epoch: 4 [67/250 8576/32000 (27%)] Loss: 5.01486 (QuantReg: 9.54045) QuantErr: 9.54045 batch_time=0.49794 
Train Epoch: 4 [78/250 9984/32000 (31%)] Loss: 5.24407 (QuantReg: 9.28552) QuantErr: 9.28552 batch_time=0.52147 
Train Epoch: 4 [89/250 11392/32000 (36%)] Loss: 4.32244 (QuantReg: 9.35811) QuantErr: 9.35811 batch_time=0.50115 
Train Epoch: 4 [100/250 12800/32000 (40%)] Loss: 4.92305 (QuantReg: 9.25592) QuantErr: 9.25592 batch_time=0.57022 
Train Epoch: 4 [111/250 14208/32000 (44%)] Loss: 5.49514 (QuantReg: 9.16078) QuantErr: 9.16078 batch_time=0.53428 
Train Epoch: 4 [122/250 15616/32000 (49%)] Loss: 4.26159 (QuantReg: 9.88977) QuantErr: 9.88977 batch_time=0.50576 
Train Epoch: 4 [133/250 17024/32000 (53%)] Loss: 5.04031 (QuantReg: 9.88949) QuantErr: 9.88949 batch_time=0.52528 
Train Epoch: 4 [144/250 18432/32000 (58%)] Loss: 5.00679 (QuantReg: 9.53678) QuantErr: 9.53678 batch_time=0.50073 
Train Epoch: 4 [155/250 19840/32000 (62%)] Loss: 5.14073 (QuantReg: 9.67732) QuantErr: 9.67732 batch_time=0.49829 
Train Epoch: 4 [166/250 21248/32000 (66%)] Loss: 5.30803 (QuantReg: 9.74582) QuantErr: 9.74582 batch_time=0.52594 
Train Epoch: 4 [177/250 22656/32000 (71%)] Loss: 4.51567 (QuantReg: 9.87143) QuantErr: 9.87143 batch_time=0.53323 
Train Epoch: 4 [188/250 24064/32000 (75%)] Loss: 5.22786 (QuantReg: 9.82255) QuantErr: 9.82255 batch_time=0.51255 
Train Epoch: 4 [199/250 25472/32000 (80%)] Loss: 4.33789 (QuantReg: 10.47891) QuantErr: 10.47891 batch_time=0.55362 
Train Epoch: 4 [210/250 26880/32000 (84%)] Loss: 4.59808 (QuantReg: 10.20259) QuantErr: 10.20259 batch_time=0.51056 
Train Epoch: 4 [221/250 28288/32000 (88%)] Loss: 3.72073 (QuantReg: 10.75281) QuantErr: 10.75281 batch_time=0.50767 
Train Epoch: 4 [232/250 29696/32000 (93%)] Loss: 4.49928 (QuantReg: 10.78371) QuantErr: 10.78371 batch_time=0.51428 
Train Epoch: 4 [243/250 31104/32000 (97%)] Loss: 4.67988 (QuantReg: 10.10650) QuantErr: 10.10650 batch_time=0.51718 
Train Epoch: 4 codebook_update_time=1.79246
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_LSMDC_t0.03/checkpoint-epoch4.pth ...
Done in 7.512s
Updating 'best' checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_LSMDC_t0.03/checkpoint-epoch4.pth ...
Done in 12.374s
removing stale ckpt [epoch 3] [took 0.02s]
 epoch          : 4
 loss           : 4.837412541389465
 quant_reg      : 9.729822257995606
 quant_err      : 9.729822257995606
 learning_rate  : 4.2868749999999995e-05
 n_samples      : 128000
 n_steps        : 1000
 LSMDC_full_test/t2v_metrics/R1: 10.0
 LSMDC_full_test/t2v_metrics/R5: 24.5
 LSMDC_full_test/t2v_metrics/R10: 34.2
 LSMDC_full_test/t2v_metrics/R50: 62.2
 LSMDC_full_test/t2v_metrics/MedR: 27.0
 LSMDC_full_test/t2v_metrics/MeanR: 82.627
 LSMDC_full_test/t2v_metrics/geometric_mean_R1-R5-R10: 20.310973060761608
 LSMDC_full_test/v2t_metrics/R1: 8.7
 LSMDC_full_test/v2t_metrics/R5: 24.1
 LSMDC_full_test/v2t_metrics/R10: 33.4
 LSMDC_full_test/v2t_metrics/R50: 61.7
 LSMDC_full_test/v2t_metrics/MedR: 27.0
 LSMDC_full_test/v2t_metrics/MeanR: 81.214
 LSMDC_full_test/v2t_metrics/geometric_mean_R1-R5-R10: 19.132024161726545
 mnt_best       : 20.310973060761608
 not_improved_count: 0
Train Epoch: 5 [1/250 128/32000 (0%)] Loss: 5.59983 (QuantReg: 9.13127) QuantErr: 9.13127 batch_time=24.92952 
Train Epoch: 5 [12/250 1536/32000 (5%)] Loss: 4.34591 (QuantReg: 9.87340) QuantErr: 9.87340 batch_time=0.65228 
Train Epoch: 5 [23/250 2944/32000 (9%)] Loss: 4.64010 (QuantReg: 10.14518) QuantErr: 10.14518 batch_time=0.49431 
Train Epoch: 5 [34/250 4352/32000 (14%)] Loss: 4.93454 (QuantReg: 9.97691) QuantErr: 9.97691 batch_time=0.49978 
Train Epoch: 5 [45/250 5760/32000 (18%)] Loss: 4.69998 (QuantReg: 10.28778) QuantErr: 10.28778 batch_time=0.52610 
Train Epoch: 5 [56/250 7168/32000 (22%)] Loss: 4.19892 (QuantReg: 10.37155) QuantErr: 10.37155 batch_time=0.50864 
Train Epoch: 5 [67/250 8576/32000 (27%)] Loss: 4.47638 (QuantReg: 10.34951) QuantErr: 10.34951 batch_time=0.50361 
Train Epoch: 5 [78/250 9984/32000 (31%)] Loss: 4.90215 (QuantReg: 10.36512) QuantErr: 10.36512 batch_time=0.50630 
Train Epoch: 5 [89/250 11392/32000 (36%)] Loss: 5.22257 (QuantReg: 10.05035) QuantErr: 10.05035 batch_time=0.49593 
Train Epoch: 5 [100/250 12800/32000 (40%)] Loss: 4.96352 (QuantReg: 10.36400) QuantErr: 10.36400 batch_time=0.55892 
Train Epoch: 5 [111/250 14208/32000 (44%)] Loss: 4.72436 (QuantReg: 10.24490) QuantErr: 10.24490 batch_time=0.48727 
Train Epoch: 5 [122/250 15616/32000 (49%)] Loss: 4.47746 (QuantReg: 10.65119) QuantErr: 10.65119 batch_time=0.49884 
Train Epoch: 5 [133/250 17024/32000 (53%)] Loss: 4.21539 (QuantReg: 10.44792) QuantErr: 10.44792 batch_time=0.50316 
Train Epoch: 5 [144/250 18432/32000 (58%)] Loss: 4.42428 (QuantReg: 10.49244) QuantErr: 10.49244 batch_time=0.51197 
Train Epoch: 5 [155/250 19840/32000 (62%)] Loss: 4.86631 (QuantReg: 10.48986) QuantErr: 10.48986 batch_time=0.53642 
Train Epoch: 5 [166/250 21248/32000 (66%)] Loss: 4.84623 (QuantReg: 10.18270) QuantErr: 10.18270 batch_time=0.49819 
Train Epoch: 5 [177/250 22656/32000 (71%)] Loss: 4.05163 (QuantReg: 11.04078) QuantErr: 11.04078 batch_time=0.53615 
Train Epoch: 5 [188/250 24064/32000 (75%)] Loss: 4.20136 (QuantReg: 10.61311) QuantErr: 10.61311 batch_time=1.06911 
Train Epoch: 5 [199/250 25472/32000 (80%)] Loss: 4.24178 (QuantReg: 10.95977) QuantErr: 10.95977 batch_time=0.51780 
Train Epoch: 5 [210/250 26880/32000 (84%)] Loss: 4.45167 (QuantReg: 10.83725) QuantErr: 10.83725 batch_time=0.52030 
Train Epoch: 5 [221/250 28288/32000 (88%)] Loss: 4.10153 (QuantReg: 10.92734) QuantErr: 10.92734 batch_time=0.50021 
Train Epoch: 5 [232/250 29696/32000 (93%)] Loss: 4.33257 (QuantReg: 11.36714) QuantErr: 11.36714 batch_time=0.49847 
Train Epoch: 5 [243/250 31104/32000 (97%)] Loss: 3.82053 (QuantReg: 11.10239) QuantErr: 11.10239 batch_time=0.49222 
Train Epoch: 5 codebook_update_time=2.01245
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_LSMDC_t0.03/checkpoint-epoch5.pth ...
Done in 5.090s
Updating 'best' checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_LSMDC_t0.03/checkpoint-epoch5.pth ...
Done in 10.564s
removing stale ckpt [epoch 4] [took 0.01s]
 epoch          : 5
 loss           : 4.499166204452514
 quant_reg      : 10.506342262268067
 quant_err      : 10.506342262268067
 learning_rate  : 4.072531249999999e-05
 n_samples      : 160000
 n_steps        : 1250
 LSMDC_full_test/t2v_metrics/R1: 11.6
 LSMDC_full_test/t2v_metrics/R5: 27.4
 LSMDC_full_test/t2v_metrics/R10: 36.4
 LSMDC_full_test/t2v_metrics/R50: 64.4
 LSMDC_full_test/t2v_metrics/MedR: 23.5
 LSMDC_full_test/t2v_metrics/MeanR: 77.553
 LSMDC_full_test/t2v_metrics/geometric_mean_R1-R5-R10: 22.61708578234258
 LSMDC_full_test/v2t_metrics/R1: 10.7
 LSMDC_full_test/v2t_metrics/R5: 27.2
 LSMDC_full_test/v2t_metrics/R10: 36.1
 LSMDC_full_test/v2t_metrics/R50: 62.9
 LSMDC_full_test/v2t_metrics/MedR: 25.0
 LSMDC_full_test/v2t_metrics/MeanR: 78.271
 LSMDC_full_test/v2t_metrics/geometric_mean_R1-R5-R10: 21.902143893312374
 mnt_best       : 22.61708578234258
 not_improved_count: 0
Train Epoch: 6 [1/250 128/32000 (0%)] Loss: 4.92775 (QuantReg: 10.40559) QuantErr: 10.40559 batch_time=17.25102 
Train Epoch: 6 [12/250 1536/32000 (5%)] Loss: 4.35566 (QuantReg: 10.42138) QuantErr: 10.42138 batch_time=0.51006 
Train Epoch: 6 [23/250 2944/32000 (9%)] Loss: 4.71130 (QuantReg: 10.54586) QuantErr: 10.54586 batch_time=0.49294 
Train Epoch: 6 [34/250 4352/32000 (14%)] Loss: 4.16861 (QuantReg: 10.94672) QuantErr: 10.94672 batch_time=0.67309 
Train Epoch: 6 [45/250 5760/32000 (18%)] Loss: 4.10506 (QuantReg: 10.94990) QuantErr: 10.94990 batch_time=0.49951 
Train Epoch: 6 [56/250 7168/32000 (22%)] Loss: 4.50014 (QuantReg: 10.55670) QuantErr: 10.55670 batch_time=0.49819 
Train Epoch: 6 [67/250 8576/32000 (27%)] Loss: 4.25427 (QuantReg: 10.78158) QuantErr: 10.78158 batch_time=0.52259 
Train Epoch: 6 [78/250 9984/32000 (31%)] Loss: 4.26807 (QuantReg: 11.07476) QuantErr: 11.07476 batch_time=0.51505 
Train Epoch: 6 [89/250 11392/32000 (36%)] Loss: 4.79834 (QuantReg: 10.52943) QuantErr: 10.52943 batch_time=0.51845 
Train Epoch: 6 [100/250 12800/32000 (40%)] Loss: 4.45844 (QuantReg: 10.81887) QuantErr: 10.81887 batch_time=0.50477 
Train Epoch: 6 [111/250 14208/32000 (44%)] Loss: 3.79251 (QuantReg: 11.34404) QuantErr: 11.34404 batch_time=0.50505 
Train Epoch: 6 [122/250 15616/32000 (49%)] Loss: 4.21643 (QuantReg: 10.77279) QuantErr: 10.77279 batch_time=0.50965 
Train Epoch: 6 [133/250 17024/32000 (53%)] Loss: 4.09066 (QuantReg: 11.36747) QuantErr: 11.36747 batch_time=0.51168 
Train Epoch: 6 [144/250 18432/32000 (58%)] Loss: 5.01391 (QuantReg: 11.10165) QuantErr: 11.10165 batch_time=0.50562 
Train Epoch: 6 [155/250 19840/32000 (62%)] Loss: 3.96706 (QuantReg: 11.58521) QuantErr: 11.58521 batch_time=0.57573 
Train Epoch: 6 [166/250 21248/32000 (66%)] Loss: 3.48161 (QuantReg: 11.36058) QuantErr: 11.36058 batch_time=0.53939 
Train Epoch: 6 [177/250 22656/32000 (71%)] Loss: 3.86988 (QuantReg: 11.55095) QuantErr: 11.55095 batch_time=0.50367 
Train Epoch: 6 [188/250 24064/32000 (75%)] Loss: 4.12991 (QuantReg: 11.71652) QuantErr: 11.71652 batch_time=0.50317 
Train Epoch: 6 [199/250 25472/32000 (80%)] Loss: 4.75764 (QuantReg: 11.21321) QuantErr: 11.21321 batch_time=0.52989 
Train Epoch: 6 [210/250 26880/32000 (84%)] Loss: 4.16933 (QuantReg: 11.54354) QuantErr: 11.54354 batch_time=0.49843 
Train Epoch: 6 [221/250 28288/32000 (88%)] Loss: 3.86918 (QuantReg: 11.82799) QuantErr: 11.82799 batch_time=0.50988 
Train Epoch: 6 [232/250 29696/32000 (93%)] Loss: 4.75584 (QuantReg: 10.68860) QuantErr: 10.68860 batch_time=0.52882 
Train Epoch: 6 [243/250 31104/32000 (97%)] Loss: 4.48516 (QuantReg: 11.08255) QuantErr: 11.08255 batch_time=0.52343 
Train Epoch: 6 codebook_update_time=1.79143
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_LSMDC_t0.03/checkpoint-epoch6.pth ...
Done in 4.864s
Updating 'best' checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_LSMDC_t0.03/checkpoint-epoch6.pth ...
Done in 10.266s
removing stale ckpt [epoch 5] [took 0.01s]
 epoch          : 6
 loss           : 4.292045039176941
 quant_reg      : 11.10253269958496
 quant_err      : 11.10253269958496
 learning_rate  : 3.868904687499999e-05
 n_samples      : 192000
 n_steps        : 1500
 LSMDC_full_test/t2v_metrics/R1: 12.1
 LSMDC_full_test/t2v_metrics/R5: 28.0
 LSMDC_full_test/t2v_metrics/R10: 37.0
 LSMDC_full_test/t2v_metrics/R50: 64.0
 LSMDC_full_test/t2v_metrics/MedR: 23.5
 LSMDC_full_test/t2v_metrics/MeanR: 76.18
 LSMDC_full_test/t2v_metrics/geometric_mean_R1-R5-R10: 23.22995536030829
 LSMDC_full_test/v2t_metrics/R1: 10.8
 LSMDC_full_test/v2t_metrics/R5: 27.7
 LSMDC_full_test/v2t_metrics/R10: 36.4
 LSMDC_full_test/v2t_metrics/R50: 64.1
 LSMDC_full_test/v2t_metrics/MedR: 23.0
 LSMDC_full_test/v2t_metrics/MeanR: 80.026
 LSMDC_full_test/v2t_metrics/geometric_mean_R1-R5-R10: 22.16502894289201
 mnt_best       : 23.22995536030829
 not_improved_count: 0
Train Epoch: 7 [1/250 128/32000 (0%)] Loss: 4.27519 (QuantReg: 11.19657) QuantErr: 11.19657 batch_time=18.25062 
Train Epoch: 7 [12/250 1536/32000 (5%)] Loss: 4.00196 (QuantReg: 11.28275) QuantErr: 11.28275 batch_time=0.50722 
Train Epoch: 7 [23/250 2944/32000 (9%)] Loss: 3.98518 (QuantReg: 10.98679) QuantErr: 10.98679 batch_time=0.50255 
Train Epoch: 7 [34/250 4352/32000 (14%)] Loss: 3.86824 (QuantReg: 11.40745) QuantErr: 11.40745 batch_time=0.49841 
Train Epoch: 7 [45/250 5760/32000 (18%)] Loss: 4.48059 (QuantReg: 11.10724) QuantErr: 11.10724 batch_time=0.49687 
Train Epoch: 7 [56/250 7168/32000 (22%)] Loss: 4.02998 (QuantReg: 11.58745) QuantErr: 11.58745 batch_time=0.89730 
Train Epoch: 7 [67/250 8576/32000 (27%)] Loss: 4.09439 (QuantReg: 11.32643) QuantErr: 11.32643 batch_time=0.50335 
Train Epoch: 7 [78/250 9984/32000 (31%)] Loss: 4.49210 (QuantReg: 11.29639) QuantErr: 11.29639 batch_time=1.44615 
Train Epoch: 7 [89/250 11392/32000 (36%)] Loss: 3.93772 (QuantReg: 11.01928) QuantErr: 11.01928 batch_time=0.49900 
Train Epoch: 7 [100/250 12800/32000 (40%)] Loss: 4.04468 (QuantReg: 11.41882) QuantErr: 11.41882 batch_time=0.49356 
Train Epoch: 7 [111/250 14208/32000 (44%)] Loss: 4.01500 (QuantReg: 11.96430) QuantErr: 11.96430 batch_time=0.52590 
Train Epoch: 7 [122/250 15616/32000 (49%)] Loss: 4.36456 (QuantReg: 11.46616) QuantErr: 11.46616 batch_time=0.51709 
Train Epoch: 7 [133/250 17024/32000 (53%)] Loss: 4.00231 (QuantReg: 11.51459) QuantErr: 11.51459 batch_time=0.50695 
Train Epoch: 7 [144/250 18432/32000 (58%)] Loss: 3.74251 (QuantReg: 11.78836) QuantErr: 11.78836 batch_time=1.12277 
Train Epoch: 7 [155/250 19840/32000 (62%)] Loss: 3.93490 (QuantReg: 12.00490) QuantErr: 12.00490 batch_time=0.53269 
Train Epoch: 7 [166/250 21248/32000 (66%)] Loss: 3.67835 (QuantReg: 11.52709) QuantErr: 11.52709 batch_time=0.49276 
Train Epoch: 7 [177/250 22656/32000 (71%)] Loss: 4.18690 (QuantReg: 11.83943) QuantErr: 11.83943 batch_time=0.49804 
Train Epoch: 7 [188/250 24064/32000 (75%)] Loss: 4.01805 (QuantReg: 12.04802) QuantErr: 12.04802 batch_time=0.50860 
Train Epoch: 7 [199/250 25472/32000 (80%)] Loss: 3.68288 (QuantReg: 11.77297) QuantErr: 11.77297 batch_time=0.54903 
Train Epoch: 7 [210/250 26880/32000 (84%)] Loss: 3.87602 (QuantReg: 11.90742) QuantErr: 11.90742 batch_time=0.51426 
Train Epoch: 7 [221/250 28288/32000 (88%)] Loss: 3.68986 (QuantReg: 12.01134) QuantErr: 12.01134 batch_time=0.51140 
Train Epoch: 7 [232/250 29696/32000 (93%)] Loss: 3.83951 (QuantReg: 12.15225) QuantErr: 12.15225 batch_time=0.53746 
Train Epoch: 7 [243/250 31104/32000 (97%)] Loss: 3.69156 (QuantReg: 12.09214) QuantErr: 12.09214 batch_time=0.49465 
Train Epoch: 7 codebook_update_time=1.72572
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_LSMDC_t0.03/checkpoint-epoch7.pth ...
Done in 6.444s
Updating 'best' checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_LSMDC_t0.03/checkpoint-epoch7.pth ...
Done in 11.531s
removing stale ckpt [epoch 6] [took 0.06s]
 epoch          : 7
 loss           : 4.053584080696106
 quant_reg      : 11.623634479522705
 quant_err      : 11.623634479522705
 learning_rate  : 3.675459453124999e-05
 n_samples      : 224000
 n_steps        : 1750
 LSMDC_full_test/t2v_metrics/R1: 11.5
 LSMDC_full_test/t2v_metrics/R5: 28.3
 LSMDC_full_test/t2v_metrics/R10: 38.8
 LSMDC_full_test/t2v_metrics/R50: 65.9
 LSMDC_full_test/t2v_metrics/MedR: 22.0
 LSMDC_full_test/t2v_metrics/MeanR: 73.347
 LSMDC_full_test/t2v_metrics/geometric_mean_R1-R5-R10: 23.286559816165195
 LSMDC_full_test/v2t_metrics/R1: 10.2
 LSMDC_full_test/v2t_metrics/R5: 29.9
 LSMDC_full_test/v2t_metrics/R10: 38.5
 LSMDC_full_test/v2t_metrics/R50: 65.4
 LSMDC_full_test/v2t_metrics/MedR: 21.0
 LSMDC_full_test/v2t_metrics/MeanR: 72.428
 LSMDC_full_test/v2t_metrics/geometric_mean_R1-R5-R10: 22.7288448027701
 mnt_best       : 23.286559816165195
 not_improved_count: 0
Train Epoch: 8 [1/250 128/32000 (0%)] Loss: 4.01951 (QuantReg: 11.79506) QuantErr: 11.79506 batch_time=25.36421 
Train Epoch: 8 [12/250 1536/32000 (5%)] Loss: 3.66304 (QuantReg: 11.90194) QuantErr: 11.90194 batch_time=0.50843 
Train Epoch: 8 [23/250 2944/32000 (9%)] Loss: 4.08554 (QuantReg: 11.91057) QuantErr: 11.91057 batch_time=0.52684 
Train Epoch: 8 [34/250 4352/32000 (14%)] Loss: 4.44190 (QuantReg: 11.72733) QuantErr: 11.72733 batch_time=0.52284 
Train Epoch: 8 [45/250 5760/32000 (18%)] Loss: 3.52054 (QuantReg: 11.95941) QuantErr: 11.95941 batch_time=0.49495 
Train Epoch: 8 [56/250 7168/32000 (22%)] Loss: 3.87633 (QuantReg: 11.82593) QuantErr: 11.82593 batch_time=0.48428 
Train Epoch: 8 [67/250 8576/32000 (27%)] Loss: 3.73821 (QuantReg: 11.63395) QuantErr: 11.63395 batch_time=0.49099 
Train Epoch: 8 [78/250 9984/32000 (31%)] Loss: 4.20356 (QuantReg: 11.97766) QuantErr: 11.97766 batch_time=0.51074 
Train Epoch: 8 [89/250 11392/32000 (36%)] Loss: 3.55593 (QuantReg: 12.19468) QuantErr: 12.19468 batch_time=0.52431 
Train Epoch: 8 [100/250 12800/32000 (40%)] Loss: 3.84392 (QuantReg: 11.73869) QuantErr: 11.73869 batch_time=0.49500 
Train Epoch: 8 [111/250 14208/32000 (44%)] Loss: 4.28808 (QuantReg: 11.92125) QuantErr: 11.92125 batch_time=0.50263 
Train Epoch: 8 [122/250 15616/32000 (49%)] Loss: 3.80930 (QuantReg: 12.26013) QuantErr: 12.26013 batch_time=0.50855 
Train Epoch: 8 [133/250 17024/32000 (53%)] Loss: 3.78979 (QuantReg: 12.16919) QuantErr: 12.16919 batch_time=0.50490 
Train Epoch: 8 [144/250 18432/32000 (58%)] Loss: 3.49371 (QuantReg: 12.78449) QuantErr: 12.78449 batch_time=0.50374 
Train Epoch: 8 [155/250 19840/32000 (62%)] Loss: 4.04159 (QuantReg: 12.37179) QuantErr: 12.37179 batch_time=0.52054 
Train Epoch: 8 [166/250 21248/32000 (66%)] Loss: 3.54789 (QuantReg: 12.39912) QuantErr: 12.39912 batch_time=0.50941 
Train Epoch: 8 [177/250 22656/32000 (71%)] Loss: 3.84693 (QuantReg: 12.10783) QuantErr: 12.10783 batch_time=0.51325 
Train Epoch: 8 [188/250 24064/32000 (75%)] Loss: 3.67639 (QuantReg: 12.29393) QuantErr: 12.29393 batch_time=0.50662 
Train Epoch: 8 [199/250 25472/32000 (80%)] Loss: 3.77308 (QuantReg: 12.23176) QuantErr: 12.23176 batch_time=3.17189 
Train Epoch: 8 [210/250 26880/32000 (84%)] Loss: 3.89129 (QuantReg: 12.23362) QuantErr: 12.23362 batch_time=0.50942 
Train Epoch: 8 [221/250 28288/32000 (88%)] Loss: 3.51556 (QuantReg: 12.78162) QuantErr: 12.78162 batch_time=0.52595 
Train Epoch: 8 [232/250 29696/32000 (93%)] Loss: 3.59163 (QuantReg: 12.88474) QuantErr: 12.88474 batch_time=0.48721 
Train Epoch: 8 [243/250 31104/32000 (97%)] Loss: 3.71723 (QuantReg: 12.37965) QuantErr: 12.37965 batch_time=0.49077 
Train Epoch: 8 codebook_update_time=1.68643
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_LSMDC_t0.03/checkpoint-epoch8.pth ...
Done in 4.634s
removing stale ckpt [epoch 7] [took 0.01s]
 epoch          : 8
 loss           : 3.854290849685669
 quant_reg      : 12.125828372955322
 quant_err      : 12.125828372955322
 learning_rate  : 3.4916864804687486e-05
 n_samples      : 256000
 n_steps        : 2000
 LSMDC_full_test/t2v_metrics/R1: 11.2
 LSMDC_full_test/t2v_metrics/R5: 28.0
 LSMDC_full_test/t2v_metrics/R10: 37.4
 LSMDC_full_test/t2v_metrics/R50: 64.3
 LSMDC_full_test/t2v_metrics/MedR: 22.0
 LSMDC_full_test/t2v_metrics/MeanR: 73.92
 LSMDC_full_test/t2v_metrics/geometric_mean_R1-R5-R10: 22.720395417306463
 LSMDC_full_test/v2t_metrics/R1: 11.5
 LSMDC_full_test/v2t_metrics/R5: 29.1
 LSMDC_full_test/v2t_metrics/R10: 37.7
 LSMDC_full_test/v2t_metrics/R50: 65.2
 LSMDC_full_test/v2t_metrics/MedR: 22.0
 LSMDC_full_test/v2t_metrics/MeanR: 74.84
 LSMDC_full_test/v2t_metrics/geometric_mean_R1-R5-R10: 23.279700740712105
 mnt_best       : 23.286559816165195
 not_improved_count: 1
Train Epoch: 9 [1/250 128/32000 (0%)] Loss: 3.80164 (QuantReg: 11.72135) QuantErr: 11.72135 batch_time=18.89641 
Train Epoch: 9 [12/250 1536/32000 (5%)] Loss: 3.78352 (QuantReg: 12.34028) QuantErr: 12.34028 batch_time=0.50300 
Train Epoch: 9 [23/250 2944/32000 (9%)] Loss: 3.41287 (QuantReg: 12.40570) QuantErr: 12.40570 batch_time=0.50540 
Train Epoch: 9 [34/250 4352/32000 (14%)] Loss: 4.08132 (QuantReg: 12.80232) QuantErr: 12.80232 batch_time=0.58282 
Train Epoch: 9 [45/250 5760/32000 (18%)] Loss: 4.06146 (QuantReg: 12.55924) QuantErr: 12.55924 batch_time=0.49875 
Train Epoch: 9 [56/250 7168/32000 (22%)] Loss: 3.37241 (QuantReg: 13.10691) QuantErr: 13.10691 batch_time=0.50060 
Train Epoch: 9 [67/250 8576/32000 (27%)] Loss: 3.70851 (QuantReg: 12.40464) QuantErr: 12.40464 batch_time=1.74726 
Train Epoch: 9 [78/250 9984/32000 (31%)] Loss: 4.11947 (QuantReg: 12.22077) QuantErr: 12.22077 batch_time=0.53997 
Train Epoch: 9 [89/250 11392/32000 (36%)] Loss: 3.60145 (QuantReg: 12.38742) QuantErr: 12.38742 batch_time=0.51283 
Train Epoch: 9 [100/250 12800/32000 (40%)] Loss: 3.52052 (QuantReg: 12.78042) QuantErr: 12.78042 batch_time=0.50620 
Train Epoch: 9 [111/250 14208/32000 (44%)] Loss: 4.11031 (QuantReg: 12.45193) QuantErr: 12.45193 batch_time=0.49434 
Train Epoch: 9 [122/250 15616/32000 (49%)] Loss: 3.50147 (QuantReg: 12.70679) QuantErr: 12.70679 batch_time=0.51281 
Train Epoch: 9 [133/250 17024/32000 (53%)] Loss: 3.35034 (QuantReg: 12.97891) QuantErr: 12.97891 batch_time=0.60568 
Train Epoch: 9 [144/250 18432/32000 (58%)] Loss: 3.49207 (QuantReg: 13.14457) QuantErr: 13.14457 batch_time=0.49209 
Train Epoch: 9 [155/250 19840/32000 (62%)] Loss: 3.59021 (QuantReg: 12.78537) QuantErr: 12.78537 batch_time=0.50639 
Train Epoch: 9 [166/250 21248/32000 (66%)] Loss: 3.80107 (QuantReg: 13.10164) QuantErr: 13.10164 batch_time=0.48655 
Train Epoch: 9 [177/250 22656/32000 (71%)] Loss: 3.41802 (QuantReg: 13.14157) QuantErr: 13.14157 batch_time=0.83639 
Train Epoch: 9 [188/250 24064/32000 (75%)] Loss: 3.30109 (QuantReg: 12.61543) QuantErr: 12.61543 batch_time=0.51587 
Train Epoch: 9 [199/250 25472/32000 (80%)] Loss: 3.69969 (QuantReg: 12.76726) QuantErr: 12.76726 batch_time=0.48840 
Train Epoch: 9 [210/250 26880/32000 (84%)] Loss: 3.59705 (QuantReg: 13.39892) QuantErr: 13.39892 batch_time=0.52092 
Train Epoch: 9 [221/250 28288/32000 (88%)] Loss: 4.15098 (QuantReg: 13.23306) QuantErr: 13.23306 batch_time=0.53442 
Train Epoch: 9 [232/250 29696/32000 (93%)] Loss: 4.28318 (QuantReg: 13.05255) QuantErr: 13.05255 batch_time=0.50146 
Train Epoch: 9 [243/250 31104/32000 (97%)] Loss: 3.65125 (QuantReg: 12.83609) QuantErr: 12.83609 batch_time=0.49400 
Train Epoch: 9 codebook_update_time=2.01689
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_LSMDC_t0.03/checkpoint-epoch9.pth ...
Done in 4.244s
Updating 'best' checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_LSMDC_t0.03/checkpoint-epoch9.pth ...
Done in 9.645s
removing stale ckpt [epoch 8] [took 0.03s]
 epoch          : 9
 loss           : 3.6587708740234377
 quant_reg      : 12.783386840820313
 quant_err      : 12.783386840820313
 learning_rate  : 3.317102156445311e-05
 n_samples      : 288000
 n_steps        : 2250
 LSMDC_full_test/t2v_metrics/R1: 11.6
 LSMDC_full_test/t2v_metrics/R5: 28.3
 LSMDC_full_test/t2v_metrics/R10: 39.0
 LSMDC_full_test/t2v_metrics/R50: 66.9
 LSMDC_full_test/t2v_metrics/MedR: 21.0
 LSMDC_full_test/t2v_metrics/MeanR: 71.086
 LSMDC_full_test/t2v_metrics/geometric_mean_R1-R5-R10: 23.393920547916284
 LSMDC_full_test/v2t_metrics/R1: 11.7
 LSMDC_full_test/v2t_metrics/R5: 30.0
 LSMDC_full_test/v2t_metrics/R10: 40.0
 LSMDC_full_test/v2t_metrics/R50: 66.4
 LSMDC_full_test/v2t_metrics/MedR: 20.0
 LSMDC_full_test/v2t_metrics/MeanR: 69.368
 LSMDC_full_test/v2t_metrics/geometric_mean_R1-R5-R10: 24.12435455153434
 mnt_best       : 23.393920547916284
 not_improved_count: 0
Train Epoch: 10 [1/250 128/32000 (0%)] Loss: 3.55606 (QuantReg: 12.88066) QuantErr: 12.88066 batch_time=21.11158 
Train Epoch: 10 [12/250 1536/32000 (5%)] Loss: 3.44633 (QuantReg: 12.24036) QuantErr: 12.24036 batch_time=0.51994 
Train Epoch: 10 [23/250 2944/32000 (9%)] Loss: 3.51605 (QuantReg: 12.45205) QuantErr: 12.45205 batch_time=0.50734 
Train Epoch: 10 [34/250 4352/32000 (14%)] Loss: 3.35607 (QuantReg: 12.73322) QuantErr: 12.73322 batch_time=0.62009 
Train Epoch: 10 [45/250 5760/32000 (18%)] Loss: 3.80106 (QuantReg: 12.96562) QuantErr: 12.96562 batch_time=0.51741 
Train Epoch: 10 [56/250 7168/32000 (22%)] Loss: 3.12608 (QuantReg: 13.22292) QuantErr: 13.22292 batch_time=0.50982 
Train Epoch: 10 [67/250 8576/32000 (27%)] Loss: 3.61008 (QuantReg: 13.06452) QuantErr: 13.06452 batch_time=0.50286 
Train Epoch: 10 [78/250 9984/32000 (31%)] Loss: 3.39375 (QuantReg: 12.78998) QuantErr: 12.78998 batch_time=0.53052 
Train Epoch: 10 [89/250 11392/32000 (36%)] Loss: 3.50597 (QuantReg: 13.57636) QuantErr: 13.57636 batch_time=0.50281 
Train Epoch: 10 [100/250 12800/32000 (40%)] Loss: 3.77503 (QuantReg: 13.21147) QuantErr: 13.21147 batch_time=0.49443 
Train Epoch: 10 [111/250 14208/32000 (44%)] Loss: 3.50998 (QuantReg: 13.23206) QuantErr: 13.23206 batch_time=0.50006 
Train Epoch: 10 [122/250 15616/32000 (49%)] Loss: 3.57188 (QuantReg: 13.02238) QuantErr: 13.02238 batch_time=0.53378 
Train Epoch: 10 [133/250 17024/32000 (53%)] Loss: 3.18008 (QuantReg: 13.41401) QuantErr: 13.41401 batch_time=0.63643 
Train Epoch: 10 [144/250 18432/32000 (58%)] Loss: 3.39019 (QuantReg: 13.41992) QuantErr: 13.41992 batch_time=0.49123 
Train Epoch: 10 [155/250 19840/32000 (62%)] Loss: 3.85300 (QuantReg: 13.43880) QuantErr: 13.43880 batch_time=0.49722 
Train Epoch: 10 [166/250 21248/32000 (66%)] Loss: 3.74395 (QuantReg: 13.74537) QuantErr: 13.74537 batch_time=0.51804 
Train Epoch: 10 [177/250 22656/32000 (71%)] Loss: 3.62280 (QuantReg: 13.15547) QuantErr: 13.15547 batch_time=0.50578 
Train Epoch: 10 [188/250 24064/32000 (75%)] Loss: 3.53173 (QuantReg: 13.62379) QuantErr: 13.62379 batch_time=0.52450 
Train Epoch: 10 [199/250 25472/32000 (80%)] Loss: 3.23016 (QuantReg: 13.38816) QuantErr: 13.38816 batch_time=0.49400 
Train Epoch: 10 [210/250 26880/32000 (84%)] Loss: 3.18348 (QuantReg: 13.54149) QuantErr: 13.54149 batch_time=0.50070 
Train Epoch: 10 [221/250 28288/32000 (88%)] Loss: 3.08639 (QuantReg: 13.67076) QuantErr: 13.67076 batch_time=0.51470 
Train Epoch: 10 [232/250 29696/32000 (93%)] Loss: 4.09069 (QuantReg: 13.44936) QuantErr: 13.44936 batch_time=0.50860 
Train Epoch: 10 [243/250 31104/32000 (97%)] Loss: 3.53184 (QuantReg: 13.49532) QuantErr: 13.49532 batch_time=0.58610 
Train Epoch: 10 codebook_update_time=1.66901
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_LSMDC_t0.03/checkpoint-epoch10.pth ...
Done in 13.047s
Updating 'best' checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_LSMDC_t0.03/checkpoint-epoch10.pth ...
Done in 17.947s
removing stale ckpt [epoch 9] [took 0.09s]
 epoch          : 10
 loss           : 3.4976204643249513
 quant_reg      : 13.22139315032959
 quant_err      : 13.22139315032959
 learning_rate  : 3.151247048623045e-05
 n_samples      : 320000
 n_steps        : 2500
 LSMDC_full_test/t2v_metrics/R1: 12.9
 LSMDC_full_test/t2v_metrics/R5: 29.5
 LSMDC_full_test/t2v_metrics/R10: 39.2
 LSMDC_full_test/t2v_metrics/R50: 67.3
 LSMDC_full_test/t2v_metrics/MedR: 21.0
 LSMDC_full_test/t2v_metrics/MeanR: 71.785
 LSMDC_full_test/t2v_metrics/geometric_mean_R1-R5-R10: 24.616856712842402
 LSMDC_full_test/v2t_metrics/R1: 10.8
 LSMDC_full_test/v2t_metrics/R5: 28.7
 LSMDC_full_test/v2t_metrics/R10: 37.6
 LSMDC_full_test/v2t_metrics/R50: 65.3
 LSMDC_full_test/v2t_metrics/MedR: 22.5
 LSMDC_full_test/v2t_metrics/MeanR: 71.545
 LSMDC_full_test/v2t_metrics/geometric_mean_R1-R5-R10: 22.672417610346688
 mnt_best       : 24.616856712842402
 not_improved_count: 0
Train Epoch: 11 [1/250 128/32000 (0%)] Loss: 2.86357 (QuantReg: 13.75952) QuantErr: 13.75952 batch_time=23.06334 
Train Epoch: 11 [12/250 1536/32000 (5%)] Loss: 3.50204 (QuantReg: 13.52185) QuantErr: 13.52185 batch_time=0.50218 
Train Epoch: 11 [23/250 2944/32000 (9%)] Loss: 3.50712 (QuantReg: 13.17315) QuantErr: 13.17315 batch_time=0.57662 
Train Epoch: 11 [34/250 4352/32000 (14%)] Loss: 3.41228 (QuantReg: 13.48015) QuantErr: 13.48015 batch_time=0.51385 
Train Epoch: 11 [45/250 5760/32000 (18%)] Loss: 3.48352 (QuantReg: 13.59643) QuantErr: 13.59643 batch_time=1.08306 
Train Epoch: 11 [56/250 7168/32000 (22%)] Loss: 4.00875 (QuantReg: 13.28920) QuantErr: 13.28920 batch_time=0.50460 
Train Epoch: 11 [67/250 8576/32000 (27%)] Loss: 3.54595 (QuantReg: 13.41714) QuantErr: 13.41714 batch_time=0.52157 
Train Epoch: 11 [78/250 9984/32000 (31%)] Loss: 3.44038 (QuantReg: 13.54706) QuantErr: 13.54706 batch_time=0.50011 
Train Epoch: 11 [89/250 11392/32000 (36%)] Loss: 3.47492 (QuantReg: 13.49974) QuantErr: 13.49974 batch_time=0.49748 
Train Epoch: 11 [100/250 12800/32000 (40%)] Loss: 2.78402 (QuantReg: 13.64721) QuantErr: 13.64721 batch_time=0.52155 
Train Epoch: 11 [111/250 14208/32000 (44%)] Loss: 3.51870 (QuantReg: 14.02256) QuantErr: 14.02256 batch_time=0.49921 
Train Epoch: 11 [122/250 15616/32000 (49%)] Loss: 2.79120 (QuantReg: 13.94070) QuantErr: 13.94070 batch_time=0.49495 
Train Epoch: 11 [133/250 17024/32000 (53%)] Loss: 3.53295 (QuantReg: 13.91559) QuantErr: 13.91559 batch_time=0.51962 
Train Epoch: 11 [144/250 18432/32000 (58%)] Loss: 2.98650 (QuantReg: 13.68198) QuantErr: 13.68198 batch_time=0.50111 
Train Epoch: 11 [155/250 19840/32000 (62%)] Loss: 3.30641 (QuantReg: 13.68255) QuantErr: 13.68255 batch_time=0.55327 
Train Epoch: 11 [166/250 21248/32000 (66%)] Loss: 3.94323 (QuantReg: 13.58136) QuantErr: 13.58136 batch_time=0.50508 
Train Epoch: 11 [177/250 22656/32000 (71%)] Loss: 2.83679 (QuantReg: 13.95010) QuantErr: 13.95010 batch_time=0.49440 
Train Epoch: 11 [188/250 24064/32000 (75%)] Loss: 3.13211 (QuantReg: 13.86448) QuantErr: 13.86448 batch_time=0.49846 
Train Epoch: 11 [199/250 25472/32000 (80%)] Loss: 3.46877 (QuantReg: 13.55467) QuantErr: 13.55467 batch_time=0.52034 
Train Epoch: 11 [210/250 26880/32000 (84%)] Loss: 3.56813 (QuantReg: 14.00273) QuantErr: 14.00273 batch_time=0.49905 
Train Epoch: 11 [221/250 28288/32000 (88%)] Loss: 3.40272 (QuantReg: 13.50689) QuantErr: 13.50689 batch_time=0.50290 
Train Epoch: 11 [232/250 29696/32000 (93%)] Loss: 2.81073 (QuantReg: 13.99825) QuantErr: 13.99825 batch_time=0.49514 
Train Epoch: 11 [243/250 31104/32000 (97%)] Loss: 3.27048 (QuantReg: 13.66777) QuantErr: 13.66777 batch_time=1.13240 
Train Epoch: 11 codebook_update_time=1.68281
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_LSMDC_t0.03/checkpoint-epoch11.pth ...
Done in 4.753s
removing stale ckpt [epoch 10] [took 0.05s]
 epoch          : 11
 loss           : 3.3261898221969606
 quant_reg      : 13.727463394165039
 quant_err      : 13.727463394165039
 learning_rate  : 2.993684696191893e-05
 n_samples      : 352000
 n_steps        : 2750
 LSMDC_full_test/t2v_metrics/R1: 11.4
 LSMDC_full_test/t2v_metrics/R5: 28.6
 LSMDC_full_test/t2v_metrics/R10: 39.4
 LSMDC_full_test/t2v_metrics/R50: 66.2
 LSMDC_full_test/t2v_metrics/MedR: 21.0
 LSMDC_full_test/t2v_metrics/MeanR: 75.495
 LSMDC_full_test/t2v_metrics/geometric_mean_R1-R5-R10: 23.420115656219544
 LSMDC_full_test/v2t_metrics/R1: 11.1
 LSMDC_full_test/v2t_metrics/R5: 28.6
 LSMDC_full_test/v2t_metrics/R10: 38.5
 LSMDC_full_test/v2t_metrics/R50: 66.0
 LSMDC_full_test/v2t_metrics/MedR: 21.0
 LSMDC_full_test/v2t_metrics/MeanR: 72.967
 LSMDC_full_test/v2t_metrics/geometric_mean_R1-R5-R10: 23.03473642178669
 mnt_best       : 24.616856712842402
 not_improved_count: 1
Train Epoch: 12 [1/250 128/32000 (0%)] Loss: 3.22451 (QuantReg: 13.37775) QuantErr: 13.37775 batch_time=21.09080 
Train Epoch: 12 [12/250 1536/32000 (5%)] Loss: 2.93296 (QuantReg: 13.75723) QuantErr: 13.75723 batch_time=0.51634 
Train Epoch: 12 [23/250 2944/32000 (9%)] Loss: 3.80906 (QuantReg: 13.49538) QuantErr: 13.49538 batch_time=0.52216 
Train Epoch: 12 [34/250 4352/32000 (14%)] Loss: 2.73535 (QuantReg: 13.97484) QuantErr: 13.97484 batch_time=0.49368 
Train Epoch: 12 [45/250 5760/32000 (18%)] Loss: 2.73865 (QuantReg: 14.16261) QuantErr: 14.16261 batch_time=0.50280 
Train Epoch: 12 [56/250 7168/32000 (22%)] Loss: 2.94472 (QuantReg: 14.03619) QuantErr: 14.03619 batch_time=0.48970 
Train Epoch: 12 [67/250 8576/32000 (27%)] Loss: 3.28723 (QuantReg: 14.21892) QuantErr: 14.21892 batch_time=0.49750 
Train Epoch: 12 [78/250 9984/32000 (31%)] Loss: 3.26058 (QuantReg: 13.79285) QuantErr: 13.79285 batch_time=0.52067 
Train Epoch: 12 [89/250 11392/32000 (36%)] Loss: 3.14263 (QuantReg: 14.11921) QuantErr: 14.11921 batch_time=0.49917 
Train Epoch: 12 [100/250 12800/32000 (40%)] Loss: 3.01054 (QuantReg: 14.14971) QuantErr: 14.14971 batch_time=0.50220 
Train Epoch: 12 [111/250 14208/32000 (44%)] Loss: 3.21194 (QuantReg: 14.10735) QuantErr: 14.10735 batch_time=0.49902 
Train Epoch: 12 [122/250 15616/32000 (49%)] Loss: 3.06683 (QuantReg: 14.11983) QuantErr: 14.11983 batch_time=0.51695 
Train Epoch: 12 [133/250 17024/32000 (53%)] Loss: 3.58535 (QuantReg: 13.95160) QuantErr: 13.95160 batch_time=0.51728 
Train Epoch: 12 [144/250 18432/32000 (58%)] Loss: 3.50392 (QuantReg: 14.03537) QuantErr: 14.03537 batch_time=0.53609 
Train Epoch: 12 [155/250 19840/32000 (62%)] Loss: 3.24398 (QuantReg: 13.80696) QuantErr: 13.80696 batch_time=0.52459 
Train Epoch: 12 [166/250 21248/32000 (66%)] Loss: 3.30961 (QuantReg: 14.20040) QuantErr: 14.20040 batch_time=0.55319 
Train Epoch: 12 [177/250 22656/32000 (71%)] Loss: 2.34872 (QuantReg: 14.38853) QuantErr: 14.38853 batch_time=0.49588 
Train Epoch: 12 [188/250 24064/32000 (75%)] Loss: 3.48992 (QuantReg: 13.84877) QuantErr: 13.84877 batch_time=0.75623 
Train Epoch: 12 [199/250 25472/32000 (80%)] Loss: 2.78969 (QuantReg: 14.05698) QuantErr: 14.05698 batch_time=0.82324 
Train Epoch: 12 [210/250 26880/32000 (84%)] Loss: 3.59828 (QuantReg: 14.06470) QuantErr: 14.06470 batch_time=1.92016 
Train Epoch: 12 [221/250 28288/32000 (88%)] Loss: 3.11467 (QuantReg: 14.39524) QuantErr: 14.39524 batch_time=0.51979 
Train Epoch: 12 [232/250 29696/32000 (93%)] Loss: 2.95261 (QuantReg: 14.43019) QuantErr: 14.43019 batch_time=0.51288 
Train Epoch: 12 [243/250 31104/32000 (97%)] Loss: 3.16527 (QuantReg: 14.23497) QuantErr: 14.23497 batch_time=0.53160 
Train Epoch: 12 codebook_update_time=1.74977
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_LSMDC_t0.03/checkpoint-epoch12.pth ...
Done in 4.129s
removing stale ckpt [epoch 11] [took 1.12s]
 epoch          : 12
 loss           : 3.1955235652923584
 quant_reg      : 14.04886220550537
 quant_err      : 14.04886220550537
 learning_rate  : 2.844000461382298e-05
 n_samples      : 384000
 n_steps        : 3000
 LSMDC_full_test/t2v_metrics/R1: 11.8
 LSMDC_full_test/t2v_metrics/R5: 30.0
 LSMDC_full_test/t2v_metrics/R10: 40.1
 LSMDC_full_test/t2v_metrics/R50: 67.2
 LSMDC_full_test/t2v_metrics/MedR: 20.0
 LSMDC_full_test/t2v_metrics/MeanR: 73.268
 LSMDC_full_test/t2v_metrics/geometric_mean_R1-R5-R10: 24.21303398228545
 LSMDC_full_test/v2t_metrics/R1: 12.0
 LSMDC_full_test/v2t_metrics/R5: 29.0
 LSMDC_full_test/v2t_metrics/R10: 39.6
 LSMDC_full_test/v2t_metrics/R50: 66.2
 LSMDC_full_test/v2t_metrics/MedR: 19.0
 LSMDC_full_test/v2t_metrics/MeanR: 69.624
 LSMDC_full_test/v2t_metrics/geometric_mean_R1-R5-R10: 23.974973913027696
 mnt_best       : 24.616856712842402
 not_improved_count: 2
Train Epoch: 13 [1/250 128/32000 (0%)] Loss: 2.76852 (QuantReg: 14.17772) QuantErr: 14.17772 batch_time=19.11513 
Train Epoch: 13 [12/250 1536/32000 (5%)] Loss: 3.18306 (QuantReg: 14.15963) QuantErr: 14.15963 batch_time=3.00938 
Train Epoch: 13 [23/250 2944/32000 (9%)] Loss: 3.19366 (QuantReg: 14.65181) QuantErr: 14.65181 batch_time=0.50549 
Train Epoch: 13 [34/250 4352/32000 (14%)] Loss: 3.00801 (QuantReg: 14.42173) QuantErr: 14.42173 batch_time=0.50366 
Train Epoch: 13 [45/250 5760/32000 (18%)] Loss: 2.89210 (QuantReg: 14.60179) QuantErr: 14.60179 batch_time=0.52231 
Train Epoch: 13 [56/250 7168/32000 (22%)] Loss: 3.32535 (QuantReg: 14.17934) QuantErr: 14.17934 batch_time=0.50843 
Train Epoch: 13 [67/250 8576/32000 (27%)] Loss: 3.05248 (QuantReg: 14.48961) QuantErr: 14.48961 batch_time=0.50156 
Train Epoch: 13 [78/250 9984/32000 (31%)] Loss: 3.17158 (QuantReg: 14.72756) QuantErr: 14.72756 batch_time=0.51207 
Train Epoch: 13 [89/250 11392/32000 (36%)] Loss: 2.57556 (QuantReg: 14.46123) QuantErr: 14.46123 batch_time=0.51854 
Train Epoch: 13 [100/250 12800/32000 (40%)] Loss: 3.29616 (QuantReg: 14.36668) QuantErr: 14.36668 batch_time=0.52610 
Train Epoch: 13 [111/250 14208/32000 (44%)] Loss: 3.11498 (QuantReg: 14.44864) QuantErr: 14.44864 batch_time=0.50972 
Train Epoch: 13 [122/250 15616/32000 (49%)] Loss: 2.87972 (QuantReg: 14.71186) QuantErr: 14.71186 batch_time=0.51223 
Train Epoch: 13 [133/250 17024/32000 (53%)] Loss: 3.20946 (QuantReg: 14.42194) QuantErr: 14.42194 batch_time=0.65957 
Train Epoch: 13 [144/250 18432/32000 (58%)] Loss: 3.23980 (QuantReg: 14.51396) QuantErr: 14.51396 batch_time=0.50423 
Train Epoch: 13 [155/250 19840/32000 (62%)] Loss: 3.15181 (QuantReg: 15.09681) QuantErr: 15.09681 batch_time=0.49673 
Train Epoch: 13 [166/250 21248/32000 (66%)] Loss: 2.97988 (QuantReg: 14.95308) QuantErr: 14.95308 batch_time=0.54802 
Train Epoch: 13 [177/250 22656/32000 (71%)] Loss: 2.91702 (QuantReg: 14.34507) QuantErr: 14.34507 batch_time=0.52253 
Train Epoch: 13 [188/250 24064/32000 (75%)] Loss: 3.35139 (QuantReg: 14.57256) QuantErr: 14.57256 batch_time=0.48908 
Train Epoch: 13 [199/250 25472/32000 (80%)] Loss: 3.10484 (QuantReg: 14.80713) QuantErr: 14.80713 batch_time=0.49030 
Train Epoch: 13 [210/250 26880/32000 (84%)] Loss: 2.88035 (QuantReg: 14.36793) QuantErr: 14.36793 batch_time=0.48972 
Train Epoch: 13 [221/250 28288/32000 (88%)] Loss: 3.12092 (QuantReg: 14.39367) QuantErr: 14.39367 batch_time=0.88104 
Train Epoch: 13 [232/250 29696/32000 (93%)] Loss: 2.98814 (QuantReg: 14.51327) QuantErr: 14.51327 batch_time=0.49917 
Train Epoch: 13 [243/250 31104/32000 (97%)] Loss: 2.87690 (QuantReg: 14.58293) QuantErr: 14.58293 batch_time=0.54620 
Train Epoch: 13 codebook_update_time=1.72889
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_LSMDC_t0.03/checkpoint-epoch13.pth ...
Done in 4.990s
removing stale ckpt [epoch 12] [took 0.02s]
 epoch          : 13
 loss           : 3.0417536563873293
 quant_reg      : 14.502163482666015
 quant_err      : 14.502163482666015
 learning_rate  : 2.7018004383131832e-05
 n_samples      : 416000
 n_steps        : 3250
 LSMDC_full_test/t2v_metrics/R1: 12.0
 LSMDC_full_test/t2v_metrics/R5: 30.5
 LSMDC_full_test/t2v_metrics/R10: 40.4
 LSMDC_full_test/t2v_metrics/R50: 66.1
 LSMDC_full_test/t2v_metrics/MedR: 19.0
 LSMDC_full_test/t2v_metrics/MeanR: 71.147
 LSMDC_full_test/t2v_metrics/geometric_mean_R1-R5-R10: 24.54449778038944
 LSMDC_full_test/v2t_metrics/R1: 12.6
 LSMDC_full_test/v2t_metrics/R5: 30.3
 LSMDC_full_test/v2t_metrics/R10: 40.5
 LSMDC_full_test/v2t_metrics/R50: 68.0
 LSMDC_full_test/v2t_metrics/MedR: 19.0
 LSMDC_full_test/v2t_metrics/MeanR: 69.349
 LSMDC_full_test/v2t_metrics/geometric_mean_R1-R5-R10: 24.912810942895643
 mnt_best       : 24.616856712842402
 not_improved_count: 3
Train Epoch: 14 [1/250 128/32000 (0%)] Loss: 3.12100 (QuantReg: 14.22288) QuantErr: 14.22288 batch_time=18.27684 
Train Epoch: 14 [12/250 1536/32000 (5%)] Loss: 2.91508 (QuantReg: 14.52956) QuantErr: 14.52956 batch_time=0.50376 
Train Epoch: 14 [23/250 2944/32000 (9%)] Loss: 3.39674 (QuantReg: 14.30454) QuantErr: 14.30454 batch_time=0.52273 
Train Epoch: 14 [34/250 4352/32000 (14%)] Loss: 2.65358 (QuantReg: 14.41420) QuantErr: 14.41420 batch_time=0.53637 
Train Epoch: 14 [45/250 5760/32000 (18%)] Loss: 2.77832 (QuantReg: 14.82712) QuantErr: 14.82712 batch_time=0.55203 
Train Epoch: 14 [56/250 7168/32000 (22%)] Loss: 2.81779 (QuantReg: 14.63865) QuantErr: 14.63865 batch_time=0.50998 
Train Epoch: 14 [67/250 8576/32000 (27%)] Loss: 2.80779 (QuantReg: 14.66038) QuantErr: 14.66038 batch_time=0.50619 
Train Epoch: 14 [78/250 9984/32000 (31%)] Loss: 3.70603 (QuantReg: 14.40348) QuantErr: 14.40348 batch_time=0.53372 
Train Epoch: 14 [89/250 11392/32000 (36%)] Loss: 2.79828 (QuantReg: 14.61130) QuantErr: 14.61130 batch_time=0.55997 
Train Epoch: 14 [100/250 12800/32000 (40%)] Loss: 3.13634 (QuantReg: 14.82778) QuantErr: 14.82778 batch_time=0.50708 
Train Epoch: 14 [111/250 14208/32000 (44%)] Loss: 2.79250 (QuantReg: 14.95485) QuantErr: 14.95485 batch_time=0.61971 
Train Epoch: 14 [122/250 15616/32000 (49%)] Loss: 3.24948 (QuantReg: 14.94348) QuantErr: 14.94348 batch_time=0.51232 
Train Epoch: 14 [133/250 17024/32000 (53%)] Loss: 3.25723 (QuantReg: 14.42719) QuantErr: 14.42719 batch_time=0.51230 
Train Epoch: 14 [144/250 18432/32000 (58%)] Loss: 2.91204 (QuantReg: 14.87614) QuantErr: 14.87614 batch_time=0.54351 
Train Epoch: 14 [155/250 19840/32000 (62%)] Loss: 3.09942 (QuantReg: 14.84713) QuantErr: 14.84713 batch_time=0.51351 
Train Epoch: 14 [166/250 21248/32000 (66%)] Loss: 2.95436 (QuantReg: 14.68797) QuantErr: 14.68797 batch_time=0.50098 
Train Epoch: 14 [177/250 22656/32000 (71%)] Loss: 2.85898 (QuantReg: 14.91199) QuantErr: 14.91199 batch_time=0.56564 
Train Epoch: 14 [188/250 24064/32000 (75%)] Loss: 3.29779 (QuantReg: 15.06883) QuantErr: 15.06883 batch_time=0.51245 
Train Epoch: 14 [199/250 25472/32000 (80%)] Loss: 3.36845 (QuantReg: 14.70109) QuantErr: 14.70109 batch_time=0.51503 
Train Epoch: 14 [210/250 26880/32000 (84%)] Loss: 3.05295 (QuantReg: 14.90351) QuantErr: 14.90351 batch_time=4.82036 
Train Epoch: 14 [221/250 28288/32000 (88%)] Loss: 2.70033 (QuantReg: 15.11292) QuantErr: 15.11292 batch_time=0.65418 
Train Epoch: 14 [232/250 29696/32000 (93%)] Loss: 2.61891 (QuantReg: 15.20076) QuantErr: 15.20076 batch_time=0.51438 
Train Epoch: 14 [243/250 31104/32000 (97%)] Loss: 2.79861 (QuantReg: 15.06131) QuantErr: 15.06131 batch_time=0.48950 
Train Epoch: 14 codebook_update_time=1.68657
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_LSMDC_t0.03/checkpoint-epoch14.pth ...
Done in 6.144s
Updating 'best' checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_LSMDC_t0.03/checkpoint-epoch14.pth ...
Done in 11.745s
removing stale ckpt [epoch 13] [took 0.05s]
 epoch          : 14
 loss           : 2.9563326864242554
 quant_reg      : 14.778128837585449
 quant_err      : 14.778128837585449
 learning_rate  : 2.566710416397524e-05
 n_samples      : 448000
 n_steps        : 3500
 LSMDC_full_test/t2v_metrics/R1: 12.7
 LSMDC_full_test/t2v_metrics/R5: 31.1
 LSMDC_full_test/t2v_metrics/R10: 41.0
 LSMDC_full_test/t2v_metrics/R50: 66.4
 LSMDC_full_test/t2v_metrics/MedR: 18.0
 LSMDC_full_test/t2v_metrics/MeanR: 72.681
 LSMDC_full_test/t2v_metrics/geometric_mean_R1-R5-R10: 25.299735971873204
 LSMDC_full_test/v2t_metrics/R1: 11.5
 LSMDC_full_test/v2t_metrics/R5: 30.8
 LSMDC_full_test/v2t_metrics/R10: 41.0
 LSMDC_full_test/v2t_metrics/R50: 67.2
 LSMDC_full_test/v2t_metrics/MedR: 18.5
 LSMDC_full_test/v2t_metrics/MeanR: 69.904
 LSMDC_full_test/v2t_metrics/geometric_mean_R1-R5-R10: 24.39743321561595
 mnt_best       : 25.299735971873204
 not_improved_count: 0
Train Epoch: 15 [1/250 128/32000 (0%)] Loss: 2.17381 (QuantReg: 14.81111) QuantErr: 14.81111 batch_time=18.53733 
Train Epoch: 15 [12/250 1536/32000 (5%)] Loss: 2.66257 (QuantReg: 14.59810) QuantErr: 14.59810 batch_time=0.52818 
Train Epoch: 15 [23/250 2944/32000 (9%)] Loss: 2.88604 (QuantReg: 15.03105) QuantErr: 15.03105 batch_time=0.51627 
Train Epoch: 15 [34/250 4352/32000 (14%)] Loss: 2.88330 (QuantReg: 14.95950) QuantErr: 14.95950 batch_time=0.55580 
Train Epoch: 15 [45/250 5760/32000 (18%)] Loss: 2.37074 (QuantReg: 15.17113) QuantErr: 15.17113 batch_time=0.60146 
Train Epoch: 15 [56/250 7168/32000 (22%)] Loss: 3.04723 (QuantReg: 15.28032) QuantErr: 15.28032 batch_time=0.52372 
Train Epoch: 15 [67/250 8576/32000 (27%)] Loss: 2.21254 (QuantReg: 15.44188) QuantErr: 15.44188 batch_time=0.95494 
Train Epoch: 15 [78/250 9984/32000 (31%)] Loss: 2.58171 (QuantReg: 15.03363) QuantErr: 15.03363 batch_time=0.50245 
Train Epoch: 15 [89/250 11392/32000 (36%)] Loss: 3.32210 (QuantReg: 15.04419) QuantErr: 15.04419 batch_time=0.52902 
Train Epoch: 15 [100/250 12800/32000 (40%)] Loss: 3.16479 (QuantReg: 14.89038) QuantErr: 14.89038 batch_time=0.50998 
Train Epoch: 15 [111/250 14208/32000 (44%)] Loss: 2.48817 (QuantReg: 15.30130) QuantErr: 15.30130 batch_time=0.50453 
Train Epoch: 15 [122/250 15616/32000 (49%)] Loss: 2.66156 (QuantReg: 15.17963) QuantErr: 15.17963 batch_time=0.50057 
Train Epoch: 15 [133/250 17024/32000 (53%)] Loss: 2.77744 (QuantReg: 15.19649) QuantErr: 15.19649 batch_time=0.50197 
Train Epoch: 15 [144/250 18432/32000 (58%)] Loss: 3.23574 (QuantReg: 15.41255) QuantErr: 15.41255 batch_time=0.63947 
Train Epoch: 15 [155/250 19840/32000 (62%)] Loss: 2.54232 (QuantReg: 15.29571) QuantErr: 15.29571 batch_time=0.52068 
Train Epoch: 15 [166/250 21248/32000 (66%)] Loss: 2.66207 (QuantReg: 15.43553) QuantErr: 15.43553 batch_time=0.51499 
Train Epoch: 15 [177/250 22656/32000 (71%)] Loss: 3.14212 (QuantReg: 15.37089) QuantErr: 15.37089 batch_time=0.51816 
Train Epoch: 15 [188/250 24064/32000 (75%)] Loss: 3.06674 (QuantReg: 15.23132) QuantErr: 15.23132 batch_time=0.52017 
Train Epoch: 15 [199/250 25472/32000 (80%)] Loss: 2.75841 (QuantReg: 15.12967) QuantErr: 15.12967 batch_time=0.53067 
Train Epoch: 15 [210/250 26880/32000 (84%)] Loss: 2.65386 (QuantReg: 15.10222) QuantErr: 15.10222 batch_time=0.50714 
Train Epoch: 15 [221/250 28288/32000 (88%)] Loss: 2.73065 (QuantReg: 15.51199) QuantErr: 15.51199 batch_time=0.50815 
Train Epoch: 15 [232/250 29696/32000 (93%)] Loss: 2.76489 (QuantReg: 15.40419) QuantErr: 15.40419 batch_time=0.50670 
Train Epoch: 15 [243/250 31104/32000 (97%)] Loss: 2.81402 (QuantReg: 15.27001) QuantErr: 15.27001 batch_time=0.55227 
Train Epoch: 15 codebook_update_time=1.78296
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_LSMDC_t0.03/checkpoint-epoch15.pth ...
Done in 4.025s
Updating 'best' checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_LSMDC_t0.03/checkpoint-epoch15.pth ...
Done in 9.262s
removing stale ckpt [epoch 14] [took 0.01s]
 epoch          : 15
 loss           : 2.8340960664749146
 quant_reg      : 15.148891372680664
 quant_err      : 15.148891372680664
 learning_rate  : 2.4383748955776477e-05
 n_samples      : 480000
 n_steps        : 3750
 LSMDC_full_test/t2v_metrics/R1: 12.5
 LSMDC_full_test/t2v_metrics/R5: 32.2
 LSMDC_full_test/t2v_metrics/R10: 41.9
 LSMDC_full_test/t2v_metrics/R50: 68.5
 LSMDC_full_test/t2v_metrics/MedR: 19.0
 LSMDC_full_test/t2v_metrics/MeanR: 71.273
 LSMDC_full_test/t2v_metrics/geometric_mean_R1-R5-R10: 25.644444888038073
 LSMDC_full_test/v2t_metrics/R1: 11.9
 LSMDC_full_test/v2t_metrics/R5: 30.7
 LSMDC_full_test/v2t_metrics/R10: 40.6
 LSMDC_full_test/v2t_metrics/R50: 67.2
 LSMDC_full_test/v2t_metrics/MedR: 19.0
 LSMDC_full_test/v2t_metrics/MeanR: 68.168
 LSMDC_full_test/v2t_metrics/geometric_mean_R1-R5-R10: 24.569922700600685
 mnt_best       : 25.644444888038073
 not_improved_count: 0
Train Epoch: 16 [1/250 128/32000 (0%)] Loss: 2.77261 (QuantReg: 15.33324) QuantErr: 15.33324 batch_time=22.29518 
Train Epoch: 16 [12/250 1536/32000 (5%)] Loss: 2.44277 (QuantReg: 15.28925) QuantErr: 15.28925 batch_time=0.49134 
Train Epoch: 16 [23/250 2944/32000 (9%)] Loss: 2.41497 (QuantReg: 15.42460) QuantErr: 15.42460 batch_time=0.49512 
Train Epoch: 16 [34/250 4352/32000 (14%)] Loss: 3.22362 (QuantReg: 15.12672) QuantErr: 15.12672 batch_time=0.49764 
Train Epoch: 16 [45/250 5760/32000 (18%)] Loss: 3.03899 (QuantReg: 15.04262) QuantErr: 15.04262 batch_time=0.49400 
Train Epoch: 16 [56/250 7168/32000 (22%)] Loss: 2.65507 (QuantReg: 15.45123) QuantErr: 15.45123 batch_time=0.81228 
Train Epoch: 16 [67/250 8576/32000 (27%)] Loss: 2.55663 (QuantReg: 15.12569) QuantErr: 15.12569 batch_time=0.48357 
Train Epoch: 16 [78/250 9984/32000 (31%)] Loss: 2.70479 (QuantReg: 15.28614) QuantErr: 15.28614 batch_time=0.48852 
Train Epoch: 16 [89/250 11392/32000 (36%)] Loss: 2.60047 (QuantReg: 15.61132) QuantErr: 15.61132 batch_time=0.53811 
Train Epoch: 16 [100/250 12800/32000 (40%)] Loss: 2.82833 (QuantReg: 15.51375) QuantErr: 15.51375 batch_time=0.47896 
Train Epoch: 16 [111/250 14208/32000 (44%)] Loss: 2.97279 (QuantReg: 15.19759) QuantErr: 15.19759 batch_time=0.49441 
Train Epoch: 16 [122/250 15616/32000 (49%)] Loss: 3.04664 (QuantReg: 14.94159) QuantErr: 14.94159 batch_time=0.52086 
Train Epoch: 16 [133/250 17024/32000 (53%)] Loss: 2.70644 (QuantReg: 15.33579) QuantErr: 15.33579 batch_time=0.50784 
Train Epoch: 16 [144/250 18432/32000 (58%)] Loss: 3.04902 (QuantReg: 15.46714) QuantErr: 15.46714 batch_time=0.49868 
Train Epoch: 16 [155/250 19840/32000 (62%)] Loss: 2.34154 (QuantReg: 15.77114) QuantErr: 15.77114 batch_time=0.52713 
Train Epoch: 16 [166/250 21248/32000 (66%)] Loss: 2.56416 (QuantReg: 15.84330) QuantErr: 15.84330 batch_time=0.50860 
Train Epoch: 16 [177/250 22656/32000 (71%)] Loss: 2.73383 (QuantReg: 15.32058) QuantErr: 15.32058 batch_time=0.54614 
Train Epoch: 16 [188/250 24064/32000 (75%)] Loss: 2.82107 (QuantReg: 15.68111) QuantErr: 15.68111 batch_time=0.49167 
Train Epoch: 16 [199/250 25472/32000 (80%)] Loss: 2.73596 (QuantReg: 15.65185) QuantErr: 15.65185 batch_time=0.55503 
Train Epoch: 16 [210/250 26880/32000 (84%)] Loss: 3.04710 (QuantReg: 15.69923) QuantErr: 15.69923 batch_time=0.51854 
Train Epoch: 16 [221/250 28288/32000 (88%)] Loss: 2.46631 (QuantReg: 15.82942) QuantErr: 15.82942 batch_time=0.56054 
Train Epoch: 16 [232/250 29696/32000 (93%)] Loss: 2.52048 (QuantReg: 15.84833) QuantErr: 15.84833 batch_time=0.51722 
Train Epoch: 16 [243/250 31104/32000 (97%)] Loss: 2.53139 (QuantReg: 15.83432) QuantErr: 15.83432 batch_time=0.48497 
Train Epoch: 16 codebook_update_time=1.70776
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_LSMDC_t0.03/checkpoint-epoch16.pth ...
Done in 22.817s
removing stale ckpt [epoch 15] [took 0.02s]
 epoch          : 16
 loss           : 2.727659976005554
 quant_reg      : 15.453642143249512
 quant_err      : 15.453642143249512
 learning_rate  : 2.3164561507987653e-05
 n_samples      : 512000
 n_steps        : 4000
 LSMDC_full_test/t2v_metrics/R1: 12.2
 LSMDC_full_test/t2v_metrics/R5: 31.4
 LSMDC_full_test/t2v_metrics/R10: 40.6
 LSMDC_full_test/t2v_metrics/R50: 67.5
 LSMDC_full_test/t2v_metrics/MedR: 18.0
 LSMDC_full_test/t2v_metrics/MeanR: 71.457
 LSMDC_full_test/t2v_metrics/geometric_mean_R1-R5-R10: 24.961566545059643
 LSMDC_full_test/v2t_metrics/R1: 11.6
 LSMDC_full_test/v2t_metrics/R5: 30.0
 LSMDC_full_test/v2t_metrics/R10: 40.4
 LSMDC_full_test/v2t_metrics/R50: 66.0
 LSMDC_full_test/v2t_metrics/MedR: 19.0
 LSMDC_full_test/v2t_metrics/MeanR: 70.796
 LSMDC_full_test/v2t_metrics/geometric_mean_R1-R5-R10: 24.13534639930271
 mnt_best       : 25.644444888038073
 not_improved_count: 1
Train Epoch: 17 [1/250 128/32000 (0%)] Loss: 2.59346 (QuantReg: 15.34087) QuantErr: 15.34087 batch_time=19.01764 
Train Epoch: 17 [12/250 1536/32000 (5%)] Loss: 3.09792 (QuantReg: 15.32359) QuantErr: 15.32359 batch_time=0.49667 
Train Epoch: 17 [23/250 2944/32000 (9%)] Loss: 2.80327 (QuantReg: 15.68697) QuantErr: 15.68697 batch_time=0.49350 
Train Epoch: 17 [34/250 4352/32000 (14%)] Loss: 2.43258 (QuantReg: 15.93682) QuantErr: 15.93682 batch_time=0.51056 
Train Epoch: 17 [45/250 5760/32000 (18%)] Loss: 3.00264 (QuantReg: 15.58120) QuantErr: 15.58120 batch_time=0.50053 
Train Epoch: 17 [56/250 7168/32000 (22%)] Loss: 2.59998 (QuantReg: 15.34070) QuantErr: 15.34070 batch_time=0.53023 
Train Epoch: 17 [67/250 8576/32000 (27%)] Loss: 2.38001 (QuantReg: 15.71725) QuantErr: 15.71725 batch_time=0.49598 
Train Epoch: 17 [78/250 9984/32000 (31%)] Loss: 2.16054 (QuantReg: 15.91565) QuantErr: 15.91565 batch_time=0.51593 
Train Epoch: 17 [89/250 11392/32000 (36%)] Loss: 2.82402 (QuantReg: 15.68816) QuantErr: 15.68816 batch_time=0.48995 
Train Epoch: 17 [100/250 12800/32000 (40%)] Loss: 2.53376 (QuantReg: 15.89071) QuantErr: 15.89071 batch_time=0.50508 
Train Epoch: 17 [111/250 14208/32000 (44%)] Loss: 1.99106 (QuantReg: 16.20169) QuantErr: 16.20169 batch_time=0.52919 
Train Epoch: 17 [122/250 15616/32000 (49%)] Loss: 2.72143 (QuantReg: 15.78574) QuantErr: 15.78574 batch_time=0.62040 
Train Epoch: 17 [133/250 17024/32000 (53%)] Loss: 2.49087 (QuantReg: 15.88121) QuantErr: 15.88121 batch_time=0.82544 
Train Epoch: 17 [144/250 18432/32000 (58%)] Loss: 2.73397 (QuantReg: 15.73943) QuantErr: 15.73943 batch_time=0.50093 
Train Epoch: 17 [155/250 19840/32000 (62%)] Loss: 2.81079 (QuantReg: 15.67095) QuantErr: 15.67095 batch_time=0.50474 
Train Epoch: 17 [166/250 21248/32000 (66%)] Loss: 2.38976 (QuantReg: 15.86381) QuantErr: 15.86381 batch_time=0.49755 
Train Epoch: 17 [177/250 22656/32000 (71%)] Loss: 2.67466 (QuantReg: 15.65937) QuantErr: 15.65937 batch_time=0.50086 
Train Epoch: 17 [188/250 24064/32000 (75%)] Loss: 2.95485 (QuantReg: 15.77350) QuantErr: 15.77350 batch_time=0.50545 
Train Epoch: 17 [199/250 25472/32000 (80%)] Loss: 2.34612 (QuantReg: 16.11422) QuantErr: 16.11422 batch_time=0.50731 
Train Epoch: 17 [210/250 26880/32000 (84%)] Loss: 2.91950 (QuantReg: 15.80094) QuantErr: 15.80094 batch_time=0.50345 
Train Epoch: 17 [221/250 28288/32000 (88%)] Loss: 2.44938 (QuantReg: 15.91125) QuantErr: 15.91125 batch_time=0.51725 
Train Epoch: 17 [232/250 29696/32000 (93%)] Loss: 3.13643 (QuantReg: 15.72406) QuantErr: 15.72406 batch_time=0.49313 
Train Epoch: 17 [243/250 31104/32000 (97%)] Loss: 2.23940 (QuantReg: 15.85292) QuantErr: 15.85292 batch_time=0.50100 
Train Epoch: 17 codebook_update_time=1.87817
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_LSMDC_t0.03/checkpoint-epoch17.pth ...
Done in 4.197s
removing stale ckpt [epoch 16] [took 0.01s]
 epoch          : 17
 loss           : 2.615510983943939
 quant_reg      : 15.71787160873413
 quant_err      : 15.71787160873413
 learning_rate  : 2.2006333432588268e-05
 n_samples      : 544000
 n_steps        : 4250
 LSMDC_full_test/t2v_metrics/R1: 12.3
 LSMDC_full_test/t2v_metrics/R5: 32.2
 LSMDC_full_test/t2v_metrics/R10: 41.5
 LSMDC_full_test/t2v_metrics/R50: 66.8
 LSMDC_full_test/t2v_metrics/MedR: 18.0
 LSMDC_full_test/t2v_metrics/MeanR: 72.13
 LSMDC_full_test/t2v_metrics/geometric_mean_R1-R5-R10: 25.42551118630265
 LSMDC_full_test/v2t_metrics/R1: 10.7
 LSMDC_full_test/v2t_metrics/R5: 29.7
 LSMDC_full_test/v2t_metrics/R10: 40.8
 LSMDC_full_test/v2t_metrics/R50: 67.2
 LSMDC_full_test/v2t_metrics/MedR: 18.0
 LSMDC_full_test/v2t_metrics/MeanR: 69.901
 LSMDC_full_test/v2t_metrics/geometric_mean_R1-R5-R10: 23.492728699515187
 mnt_best       : 25.644444888038073
 not_improved_count: 2
Train Epoch: 18 [1/250 128/32000 (0%)] Loss: 2.57441 (QuantReg: 15.56168) QuantErr: 15.56168 batch_time=20.09179 
Train Epoch: 18 [12/250 1536/32000 (5%)] Loss: 2.30914 (QuantReg: 15.83814) QuantErr: 15.83814 batch_time=0.50923 
Train Epoch: 18 [23/250 2944/32000 (9%)] Loss: 2.29952 (QuantReg: 15.79907) QuantErr: 15.79907 batch_time=0.54418 
Train Epoch: 18 [34/250 4352/32000 (14%)] Loss: 2.40313 (QuantReg: 16.00583) QuantErr: 16.00583 batch_time=0.49009 
Train Epoch: 18 [45/250 5760/32000 (18%)] Loss: 2.49552 (QuantReg: 16.01347) QuantErr: 16.01347 batch_time=0.49961 
Train Epoch: 18 [56/250 7168/32000 (22%)] Loss: 2.41809 (QuantReg: 15.91059) QuantErr: 15.91059 batch_time=0.49527 
Train Epoch: 18 [67/250 8576/32000 (27%)] Loss: 2.43758 (QuantReg: 16.02126) QuantErr: 16.02126 batch_time=0.51759 
Train Epoch: 18 [78/250 9984/32000 (31%)] Loss: 2.67626 (QuantReg: 16.15030) QuantErr: 16.15030 batch_time=0.52209 
Train Epoch: 18 [89/250 11392/32000 (36%)] Loss: 2.96486 (QuantReg: 15.74280) QuantErr: 15.74280 batch_time=0.51718 
Train Epoch: 18 [100/250 12800/32000 (40%)] Loss: 2.36262 (QuantReg: 16.01246) QuantErr: 16.01246 batch_time=0.50487 
Train Epoch: 18 [111/250 14208/32000 (44%)] Loss: 2.54643 (QuantReg: 16.17530) QuantErr: 16.17530 batch_time=0.50100 
Train Epoch: 18 [122/250 15616/32000 (49%)] Loss: 2.26385 (QuantReg: 16.22714) QuantErr: 16.22714 batch_time=0.50747 
Train Epoch: 18 [133/250 17024/32000 (53%)] Loss: 2.18449 (QuantReg: 15.99400) QuantErr: 15.99400 batch_time=0.50216 
Train Epoch: 18 [144/250 18432/32000 (58%)] Loss: 2.56102 (QuantReg: 16.09100) QuantErr: 16.09100 batch_time=0.59329 
Train Epoch: 18 [155/250 19840/32000 (62%)] Loss: 2.43820 (QuantReg: 16.09319) QuantErr: 16.09319 batch_time=0.49440 
Train Epoch: 18 [166/250 21248/32000 (66%)] Loss: 2.86350 (QuantReg: 15.95969) QuantErr: 15.95969 batch_time=0.49731 
Train Epoch: 18 [177/250 22656/32000 (71%)] Loss: 2.59239 (QuantReg: 16.07050) QuantErr: 16.07050 batch_time=0.52037 
Train Epoch: 18 [188/250 24064/32000 (75%)] Loss: 2.63140 (QuantReg: 15.89696) QuantErr: 15.89696 batch_time=0.52823 
Train Epoch: 18 [199/250 25472/32000 (80%)] Loss: 2.26499 (QuantReg: 16.30750) QuantErr: 16.30750 batch_time=0.51031 
Train Epoch: 18 [210/250 26880/32000 (84%)] Loss: 2.61949 (QuantReg: 16.08769) QuantErr: 16.08769 batch_time=0.49732 
Train Epoch: 18 [221/250 28288/32000 (88%)] Loss: 3.04502 (QuantReg: 15.88647) QuantErr: 15.88647 batch_time=0.50514 
Train Epoch: 18 [232/250 29696/32000 (93%)] Loss: 2.79537 (QuantReg: 16.05619) QuantErr: 16.05619 batch_time=0.82745 
Train Epoch: 18 [243/250 31104/32000 (97%)] Loss: 2.57514 (QuantReg: 16.00427) QuantErr: 16.00427 batch_time=0.49514 
Train Epoch: 18 codebook_update_time=1.82026
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_LSMDC_t0.03/checkpoint-epoch18.pth ...
Done in 5.341s
removing stale ckpt [epoch 17] [took 0.01s]
 epoch          : 18
 loss           : 2.5075857481956483
 quant_reg      : 15.987174938201905
 quant_err      : 15.987174938201905
 learning_rate  : 2.0906016760958855e-05
 n_samples      : 576000
 n_steps        : 4500
 LSMDC_full_test/t2v_metrics/R1: 13.0
 LSMDC_full_test/t2v_metrics/R5: 30.6
 LSMDC_full_test/t2v_metrics/R10: 41.9
 LSMDC_full_test/t2v_metrics/R50: 67.5
 LSMDC_full_test/t2v_metrics/MedR: 18.0
 LSMDC_full_test/t2v_metrics/MeanR: 70.948
 LSMDC_full_test/t2v_metrics/geometric_mean_R1-R5-R10: 25.54423693966927
 LSMDC_full_test/v2t_metrics/R1: 13.1
 LSMDC_full_test/v2t_metrics/R5: 31.1
 LSMDC_full_test/v2t_metrics/R10: 40.9
 LSMDC_full_test/v2t_metrics/R50: 67.5
 LSMDC_full_test/v2t_metrics/MedR: 18.0
 LSMDC_full_test/v2t_metrics/MeanR: 68.676
 LSMDC_full_test/v2t_metrics/geometric_mean_R1-R5-R10: 25.541809663588385
 mnt_best       : 25.644444888038073
 not_improved_count: 3
Train Epoch: 19 [1/250 128/32000 (0%)] Loss: 2.07232 (QuantReg: 16.08555) QuantErr: 16.08555 batch_time=23.41700 
Train Epoch: 19 [12/250 1536/32000 (5%)] Loss: 2.79237 (QuantReg: 15.85509) QuantErr: 15.85509 batch_time=0.53675 
Train Epoch: 19 [23/250 2944/32000 (9%)] Loss: 2.69061 (QuantReg: 16.02020) QuantErr: 16.02020 batch_time=0.54055 
Train Epoch: 19 [34/250 4352/32000 (14%)] Loss: 2.57500 (QuantReg: 15.99179) QuantErr: 15.99179 batch_time=0.53789 
Train Epoch: 19 [45/250 5760/32000 (18%)] Loss: 2.26754 (QuantReg: 16.01073) QuantErr: 16.01073 batch_time=0.52230 
Train Epoch: 19 [56/250 7168/32000 (22%)] Loss: 2.94746 (QuantReg: 16.16800) QuantErr: 16.16800 batch_time=0.51877 
Train Epoch: 19 [67/250 8576/32000 (27%)] Loss: 2.54076 (QuantReg: 16.07229) QuantErr: 16.07229 batch_time=0.72808 
Train Epoch: 19 [78/250 9984/32000 (31%)] Loss: 2.73976 (QuantReg: 16.26838) QuantErr: 16.26838 batch_time=0.50295 
Train Epoch: 19 [89/250 11392/32000 (36%)] Loss: 2.36776 (QuantReg: 16.24125) QuantErr: 16.24125 batch_time=0.49366 
Train Epoch: 19 [100/250 12800/32000 (40%)] Loss: 2.44253 (QuantReg: 16.22419) QuantErr: 16.22419 batch_time=0.59740 
Train Epoch: 19 [111/250 14208/32000 (44%)] Loss: 2.61383 (QuantReg: 16.01265) QuantErr: 16.01265 batch_time=0.54776 
Train Epoch: 19 [122/250 15616/32000 (49%)] Loss: 2.52654 (QuantReg: 16.26793) QuantErr: 16.26793 batch_time=0.50084 
Train Epoch: 19 [133/250 17024/32000 (53%)] Loss: 2.27642 (QuantReg: 16.41724) QuantErr: 16.41724 batch_time=0.49957 
Train Epoch: 19 [144/250 18432/32000 (58%)] Loss: 2.65856 (QuantReg: 16.23636) QuantErr: 16.23636 batch_time=0.49572 
Train Epoch: 19 [155/250 19840/32000 (62%)] Loss: 2.64994 (QuantReg: 16.34918) QuantErr: 16.34918 batch_time=0.49643 
Train Epoch: 19 [166/250 21248/32000 (66%)] Loss: 2.32196 (QuantReg: 16.73325) QuantErr: 16.73325 batch_time=0.51732 
Train Epoch: 19 [177/250 22656/32000 (71%)] Loss: 2.22667 (QuantReg: 16.33953) QuantErr: 16.33953 batch_time=0.54417 
Train Epoch: 19 [188/250 24064/32000 (75%)] Loss: 2.35614 (QuantReg: 16.19517) QuantErr: 16.19517 batch_time=0.50216 
Train Epoch: 19 [199/250 25472/32000 (80%)] Loss: 2.04283 (QuantReg: 16.57066) QuantErr: 16.57066 batch_time=0.51214 
Train Epoch: 19 [210/250 26880/32000 (84%)] Loss: 2.54821 (QuantReg: 16.30731) QuantErr: 16.30731 batch_time=0.52303 
Train Epoch: 19 [221/250 28288/32000 (88%)] Loss: 2.43071 (QuantReg: 16.24306) QuantErr: 16.24306 batch_time=1.53864 
Train Epoch: 19 [232/250 29696/32000 (93%)] Loss: 2.35950 (QuantReg: 16.43497) QuantErr: 16.43497 batch_time=0.52010 
Train Epoch: 19 [243/250 31104/32000 (97%)] Loss: 1.94015 (QuantReg: 16.47412) QuantErr: 16.47412 batch_time=0.50406 
Train Epoch: 19 codebook_update_time=1.72714
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_LSMDC_t0.03/checkpoint-epoch19.pth ...
Done in 4.270s
removing stale ckpt [epoch 18] [took 0.02s]
 epoch          : 19
 loss           : 2.4405412940979003
 quant_reg      : 16.22606852722168
 quant_err      : 16.22606852722168
 learning_rate  : 1.986071592291091e-05
 n_samples      : 608000
 n_steps        : 4750
 LSMDC_full_test/t2v_metrics/R1: 11.7
 LSMDC_full_test/t2v_metrics/R5: 32.2
 LSMDC_full_test/t2v_metrics/R10: 43.4
 LSMDC_full_test/t2v_metrics/R50: 68.3
 LSMDC_full_test/t2v_metrics/MedR: 18.0
 LSMDC_full_test/t2v_metrics/MeanR: 70.028
 LSMDC_full_test/t2v_metrics/geometric_mean_R1-R5-R10: 25.381102773127758
 LSMDC_full_test/v2t_metrics/R1: 11.1
 LSMDC_full_test/v2t_metrics/R5: 30.6
 LSMDC_full_test/v2t_metrics/R10: 41.2
 LSMDC_full_test/v2t_metrics/R50: 65.7
 LSMDC_full_test/v2t_metrics/MedR: 19.5
 LSMDC_full_test/v2t_metrics/MeanR: 70.491
 LSMDC_full_test/v2t_metrics/geometric_mean_R1-R5-R10: 24.097974497331837
 mnt_best       : 25.644444888038073
 not_improved_count: 4
Train Epoch: 20 [1/250 128/32000 (0%)] Loss: 2.48914 (QuantReg: 16.63898) QuantErr: 16.63898 batch_time=20.62728 
Train Epoch: 20 [12/250 1536/32000 (5%)] Loss: 2.78205 (QuantReg: 16.31638) QuantErr: 16.31638 batch_time=0.54188 
Train Epoch: 20 [23/250 2944/32000 (9%)] Loss: 1.88843 (QuantReg: 16.41726) QuantErr: 16.41726 batch_time=0.51367 
Train Epoch: 20 [34/250 4352/32000 (14%)] Loss: 2.50968 (QuantReg: 16.48578) QuantErr: 16.48578 batch_time=0.50628 
Train Epoch: 20 [45/250 5760/32000 (18%)] Loss: 1.91196 (QuantReg: 16.32668) QuantErr: 16.32668 batch_time=0.55370 
Train Epoch: 20 [56/250 7168/32000 (22%)] Loss: 2.39535 (QuantReg: 16.47435) QuantErr: 16.47435 batch_time=0.95449 
Train Epoch: 20 [67/250 8576/32000 (27%)] Loss: 2.58197 (QuantReg: 16.27114) QuantErr: 16.27114 batch_time=0.49975 
Train Epoch: 20 [78/250 9984/32000 (31%)] Loss: 2.68617 (QuantReg: 16.45309) QuantErr: 16.45309 batch_time=0.50994 
Train Epoch: 20 [89/250 11392/32000 (36%)] Loss: 2.24600 (QuantReg: 16.10078) QuantErr: 16.10078 batch_time=0.53930 
Train Epoch: 20 [100/250 12800/32000 (40%)] Loss: 2.46664 (QuantReg: 15.95614) QuantErr: 15.95614 batch_time=0.52525 
Train Epoch: 20 [111/250 14208/32000 (44%)] Loss: 2.44227 (QuantReg: 16.04503) QuantErr: 16.04503 batch_time=0.49356 
Train Epoch: 20 [122/250 15616/32000 (49%)] Loss: 2.21896 (QuantReg: 16.42883) QuantErr: 16.42883 batch_time=0.50113 
Train Epoch: 20 [133/250 17024/32000 (53%)] Loss: 2.53290 (QuantReg: 16.31435) QuantErr: 16.31435 batch_time=0.94784 
Train Epoch: 20 [144/250 18432/32000 (58%)] Loss: 2.36059 (QuantReg: 16.14875) QuantErr: 16.14875 batch_time=0.50149 
Train Epoch: 20 [155/250 19840/32000 (62%)] Loss: 2.24867 (QuantReg: 16.26191) QuantErr: 16.26191 batch_time=0.96986 
Train Epoch: 20 [166/250 21248/32000 (66%)] Loss: 2.46674 (QuantReg: 16.60911) QuantErr: 16.60911 batch_time=0.51111 
Train Epoch: 20 [177/250 22656/32000 (71%)] Loss: 2.02511 (QuantReg: 16.44771) QuantErr: 16.44771 batch_time=0.49774 
Train Epoch: 20 [188/250 24064/32000 (75%)] Loss: 2.15302 (QuantReg: 16.14250) QuantErr: 16.14250 batch_time=0.51043 
Train Epoch: 20 [199/250 25472/32000 (80%)] Loss: 2.15858 (QuantReg: 16.69817) QuantErr: 16.69817 batch_time=0.53596 
Train Epoch: 20 [210/250 26880/32000 (84%)] Loss: 2.06717 (QuantReg: 16.54794) QuantErr: 16.54794 batch_time=0.53063 
Train Epoch: 20 [221/250 28288/32000 (88%)] Loss: 2.26515 (QuantReg: 16.58026) QuantErr: 16.58026 batch_time=1.82811 
Train Epoch: 20 [232/250 29696/32000 (93%)] Loss: 2.21120 (QuantReg: 16.40566) QuantErr: 16.40566 batch_time=0.50977 
Train Epoch: 20 [243/250 31104/32000 (97%)] Loss: 1.90394 (QuantReg: 16.61164) QuantErr: 16.61164 batch_time=0.49091 
Train Epoch: 20 codebook_update_time=1.75792
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_LSMDC_t0.03/checkpoint-epoch20.pth ...
Done in 4.976s
removing stale ckpt [epoch 19] [took 0.03s]
 epoch          : 20
 loss           : 2.3622595443725585
 quant_reg      : 16.387881565093995
 quant_err      : 16.387881565093995
 learning_rate  : 1.8867680126765363e-05
 n_samples      : 640000
 n_steps        : 5000
 LSMDC_full_test/t2v_metrics/R1: 11.8
 LSMDC_full_test/t2v_metrics/R5: 33.0
 LSMDC_full_test/t2v_metrics/R10: 41.4
 LSMDC_full_test/t2v_metrics/R50: 67.1
 LSMDC_full_test/t2v_metrics/MedR: 18.0
 LSMDC_full_test/t2v_metrics/MeanR: 70.492
 LSMDC_full_test/t2v_metrics/geometric_mean_R1-R5-R10: 25.26186613460851
 LSMDC_full_test/v2t_metrics/R1: 12.4
 LSMDC_full_test/v2t_metrics/R5: 31.2
 LSMDC_full_test/v2t_metrics/R10: 41.2
 LSMDC_full_test/v2t_metrics/R50: 66.8
 LSMDC_full_test/v2t_metrics/MedR: 17.0
 LSMDC_full_test/v2t_metrics/MeanR: 68.4035
 LSMDC_full_test/v2t_metrics/geometric_mean_R1-R5-R10: 25.16659721533007
 mnt_best       : 25.644444888038073
 not_improved_count: 5
Train Epoch: 21 [1/250 128/32000 (0%)] Loss: 2.30103 (QuantReg: 16.47268) QuantErr: 16.47268 batch_time=16.12166 
Train Epoch: 21 [12/250 1536/32000 (5%)] Loss: 2.28474 (QuantReg: 16.38481) QuantErr: 16.38481 batch_time=0.50094 
Train Epoch: 21 [23/250 2944/32000 (9%)] Loss: 2.39014 (QuantReg: 16.81771) QuantErr: 16.81771 batch_time=0.50873 
Train Epoch: 21 [34/250 4352/32000 (14%)] Loss: 2.29070 (QuantReg: 16.24865) QuantErr: 16.24865 batch_time=0.52494 
Train Epoch: 21 [45/250 5760/32000 (18%)] Loss: 2.08269 (QuantReg: 16.58364) QuantErr: 16.58364 batch_time=0.55779 
Train Epoch: 21 [56/250 7168/32000 (22%)] Loss: 2.41270 (QuantReg: 16.46338) QuantErr: 16.46338 batch_time=0.52429 
Train Epoch: 21 [67/250 8576/32000 (27%)] Loss: 2.07903 (QuantReg: 16.60011) QuantErr: 16.60011 batch_time=0.61022 
Train Epoch: 21 [78/250 9984/32000 (31%)] Loss: 1.96082 (QuantReg: 16.79848) QuantErr: 16.79848 batch_time=0.49697 
Train Epoch: 21 [89/250 11392/32000 (36%)] Loss: 2.66670 (QuantReg: 16.60151) QuantErr: 16.60151 batch_time=0.53375 
Train Epoch: 21 [100/250 12800/32000 (40%)] Loss: 2.04454 (QuantReg: 16.73449) QuantErr: 16.73449 batch_time=0.50314 
Train Epoch: 21 [111/250 14208/32000 (44%)] Loss: 2.01863 (QuantReg: 16.48672) QuantErr: 16.48672 batch_time=0.55289 
Train Epoch: 21 [122/250 15616/32000 (49%)] Loss: 2.21330 (QuantReg: 16.56555) QuantErr: 16.56555 batch_time=0.49702 
Train Epoch: 21 [133/250 17024/32000 (53%)] Loss: 2.12330 (QuantReg: 16.74333) QuantErr: 16.74333 batch_time=0.53638 
Train Epoch: 21 [144/250 18432/32000 (58%)] Loss: 2.89054 (QuantReg: 16.40369) QuantErr: 16.40369 batch_time=0.96697 
Train Epoch: 21 [155/250 19840/32000 (62%)] Loss: 1.92121 (QuantReg: 16.59667) QuantErr: 16.59667 batch_time=0.51162 
Train Epoch: 21 [166/250 21248/32000 (66%)] Loss: 2.47167 (QuantReg: 16.69707) QuantErr: 16.69707 batch_time=0.54283 
Train Epoch: 21 [177/250 22656/32000 (71%)] Loss: 2.27084 (QuantReg: 16.68527) QuantErr: 16.68527 batch_time=0.58695 
Train Epoch: 21 [188/250 24064/32000 (75%)] Loss: 2.34550 (QuantReg: 16.89093) QuantErr: 16.89093 batch_time=0.49055 
Train Epoch: 21 [199/250 25472/32000 (80%)] Loss: 2.13523 (QuantReg: 16.77490) QuantErr: 16.77490 batch_time=0.49928 
Train Epoch: 21 [210/250 26880/32000 (84%)] Loss: 2.28421 (QuantReg: 16.89973) QuantErr: 16.89973 batch_time=3.23921 
Train Epoch: 21 [221/250 28288/32000 (88%)] Loss: 2.29943 (QuantReg: 16.65117) QuantErr: 16.65117 batch_time=0.49052 
Train Epoch: 21 [232/250 29696/32000 (93%)] Loss: 2.30529 (QuantReg: 16.92163) QuantErr: 16.92163 batch_time=0.50262 
Train Epoch: 21 [243/250 31104/32000 (97%)] Loss: 2.90298 (QuantReg: 16.79038) QuantErr: 16.79038 batch_time=0.62827 
Train Epoch: 21 codebook_update_time=1.79290
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_LSMDC_t0.03/checkpoint-epoch21.pth ...
Done in 4.050s
removing stale ckpt [epoch 20] [took 0.00s]
 epoch          : 21
 loss           : 2.2694245414733887
 quant_reg      : 16.603514976501465
 quant_err      : 16.603514976501465
 learning_rate  : 1.7924296120427095e-05
 n_samples      : 672000
 n_steps        : 5250
 LSMDC_full_test/t2v_metrics/R1: 12.5
 LSMDC_full_test/t2v_metrics/R5: 31.9
 LSMDC_full_test/t2v_metrics/R10: 41.7
 LSMDC_full_test/t2v_metrics/R50: 67.0
 LSMDC_full_test/t2v_metrics/MedR: 18.5
 LSMDC_full_test/t2v_metrics/MeanR: 71.563
 LSMDC_full_test/t2v_metrics/geometric_mean_R1-R5-R10: 25.52381473799826
 LSMDC_full_test/v2t_metrics/R1: 12.5
 LSMDC_full_test/v2t_metrics/R5: 31.7
 LSMDC_full_test/v2t_metrics/R10: 41.2
 LSMDC_full_test/v2t_metrics/R50: 65.9
 LSMDC_full_test/v2t_metrics/MedR: 19.0
 LSMDC_full_test/v2t_metrics/MeanR: 67.678
 LSMDC_full_test/v2t_metrics/geometric_mean_R1-R5-R10: 25.36815195341228
 mnt_best       : 25.644444888038073
 not_improved_count: 6
Train Epoch: 22 [1/250 128/32000 (0%)] Loss: 2.57216 (QuantReg: 16.54865) QuantErr: 16.54865 batch_time=19.77302 
Train Epoch: 22 [12/250 1536/32000 (5%)] Loss: 2.14884 (QuantReg: 16.79341) QuantErr: 16.79341 batch_time=0.50348 
Train Epoch: 22 [23/250 2944/32000 (9%)] Loss: 2.43436 (QuantReg: 16.49372) QuantErr: 16.49372 batch_time=0.50670 
Train Epoch: 22 [34/250 4352/32000 (14%)] Loss: 1.96997 (QuantReg: 16.65742) QuantErr: 16.65742 batch_time=0.48904 
Train Epoch: 22 [45/250 5760/32000 (18%)] Loss: 2.12549 (QuantReg: 16.76368) QuantErr: 16.76368 batch_time=0.50824 
Train Epoch: 22 [56/250 7168/32000 (22%)] Loss: 2.28565 (QuantReg: 16.83768) QuantErr: 16.83768 batch_time=1.00361 
Train Epoch: 22 [67/250 8576/32000 (27%)] Loss: 2.13010 (QuantReg: 16.74611) QuantErr: 16.74611 batch_time=0.48787 
Train Epoch: 22 [78/250 9984/32000 (31%)] Loss: 2.10062 (QuantReg: 16.76842) QuantErr: 16.76842 batch_time=0.54607 
Train Epoch: 22 [89/250 11392/32000 (36%)] Loss: 2.31098 (QuantReg: 16.67014) QuantErr: 16.67014 batch_time=0.52764 
Train Epoch: 22 [100/250 12800/32000 (40%)] Loss: 1.92659 (QuantReg: 16.78119) QuantErr: 16.78119 batch_time=0.52634 
Train Epoch: 22 [111/250 14208/32000 (44%)] Loss: 2.06873 (QuantReg: 16.87823) QuantErr: 16.87823 batch_time=0.51172 
Train Epoch: 22 [122/250 15616/32000 (49%)] Loss: 2.29884 (QuantReg: 16.81812) QuantErr: 16.81812 batch_time=0.63607 
Train Epoch: 22 [133/250 17024/32000 (53%)] Loss: 2.19630 (QuantReg: 16.98522) QuantErr: 16.98522 batch_time=0.51470 
Train Epoch: 22 [144/250 18432/32000 (58%)] Loss: 2.72118 (QuantReg: 16.72041) QuantErr: 16.72041 batch_time=1.95289 
Train Epoch: 22 [155/250 19840/32000 (62%)] Loss: 2.37147 (QuantReg: 16.68269) QuantErr: 16.68269 batch_time=0.50473 
Train Epoch: 22 [166/250 21248/32000 (66%)] Loss: 2.02225 (QuantReg: 16.75214) QuantErr: 16.75214 batch_time=0.52948 
Train Epoch: 22 [177/250 22656/32000 (71%)] Loss: 2.52892 (QuantReg: 16.86200) QuantErr: 16.86200 batch_time=0.50021 
Train Epoch: 22 [188/250 24064/32000 (75%)] Loss: 2.10940 (QuantReg: 16.92652) QuantErr: 16.92652 batch_time=0.50338 
Train Epoch: 22 [199/250 25472/32000 (80%)] Loss: 2.16258 (QuantReg: 16.74180) QuantErr: 16.74180 batch_time=1.18165 
Train Epoch: 22 [210/250 26880/32000 (84%)] Loss: 1.89304 (QuantReg: 16.80067) QuantErr: 16.80067 batch_time=0.93898 
Train Epoch: 22 [221/250 28288/32000 (88%)] Loss: 1.78607 (QuantReg: 16.96023) QuantErr: 16.96023 batch_time=0.50026 
Train Epoch: 22 [232/250 29696/32000 (93%)] Loss: 1.85159 (QuantReg: 17.17605) QuantErr: 17.17605 batch_time=0.51202 
Train Epoch: 22 [243/250 31104/32000 (97%)] Loss: 2.29306 (QuantReg: 16.78529) QuantErr: 16.78529 batch_time=0.55678 
Train Epoch: 22 codebook_update_time=1.83097
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_LSMDC_t0.03/checkpoint-epoch22.pth ...
Done in 5.145s
removing stale ckpt [epoch 21] [took 0.00s]
 epoch          : 22
 loss           : 2.2058771834373476
 quant_reg      : 16.78983489227295
 quant_err      : 16.78983489227295
 learning_rate  : 1.702808131440574e-05
 n_samples      : 704000
 n_steps        : 5500
 LSMDC_full_test/t2v_metrics/R1: 12.1
 LSMDC_full_test/t2v_metrics/R5: 32.4
 LSMDC_full_test/t2v_metrics/R10: 41.6
 LSMDC_full_test/t2v_metrics/R50: 68.2
 LSMDC_full_test/t2v_metrics/MedR: 18.0
 LSMDC_full_test/t2v_metrics/MeanR: 70.918
 LSMDC_full_test/t2v_metrics/geometric_mean_R1-R5-R10: 25.359532145800337
 LSMDC_full_test/v2t_metrics/R1: 11.2
 LSMDC_full_test/v2t_metrics/R5: 31.5
 LSMDC_full_test/v2t_metrics/R10: 41.6
 LSMDC_full_test/v2t_metrics/R50: 67.7
 LSMDC_full_test/v2t_metrics/MedR: 19.0
 LSMDC_full_test/v2t_metrics/MeanR: 67.838
 LSMDC_full_test/v2t_metrics/geometric_mean_R1-R5-R10: 24.483526340654677
 mnt_best       : 25.644444888038073
 not_improved_count: 7
Train Epoch: 23 [1/250 128/32000 (0%)] Loss: 2.15454 (QuantReg: 17.01465) QuantErr: 17.01465 batch_time=19.30812 
Train Epoch: 23 [12/250 1536/32000 (5%)] Loss: 2.25130 (QuantReg: 16.98660) QuantErr: 16.98660 batch_time=0.52156 
Train Epoch: 23 [23/250 2944/32000 (9%)] Loss: 1.82625 (QuantReg: 16.83647) QuantErr: 16.83647 batch_time=0.50169 
Train Epoch: 23 [34/250 4352/32000 (14%)] Loss: 2.30399 (QuantReg: 16.95110) QuantErr: 16.95110 batch_time=0.50377 
Train Epoch: 23 [45/250 5760/32000 (18%)] Loss: 1.82725 (QuantReg: 16.90783) QuantErr: 16.90783 batch_time=0.51425 
Train Epoch: 23 [56/250 7168/32000 (22%)] Loss: 2.44561 (QuantReg: 16.85508) QuantErr: 16.85508 batch_time=0.50161 
Train Epoch: 23 [67/250 8576/32000 (27%)] Loss: 2.22559 (QuantReg: 16.93129) QuantErr: 16.93129 batch_time=3.16977 
Train Epoch: 23 [78/250 9984/32000 (31%)] Loss: 1.91080 (QuantReg: 17.05127) QuantErr: 17.05127 batch_time=0.49431 
Train Epoch: 23 [89/250 11392/32000 (36%)] Loss: 1.98743 (QuantReg: 16.89716) QuantErr: 16.89716 batch_time=0.86964 
Train Epoch: 23 [100/250 12800/32000 (40%)] Loss: 1.84112 (QuantReg: 16.96643) QuantErr: 16.96643 batch_time=0.54620 
Train Epoch: 23 [111/250 14208/32000 (44%)] Loss: 2.18871 (QuantReg: 17.00177) QuantErr: 17.00177 batch_time=0.53643 
Train Epoch: 23 [122/250 15616/32000 (49%)] Loss: 2.25119 (QuantReg: 16.86390) QuantErr: 16.86390 batch_time=0.49886 
Train Epoch: 23 [133/250 17024/32000 (53%)] Loss: 2.32617 (QuantReg: 16.82645) QuantErr: 16.82645 batch_time=0.50719 
Train Epoch: 23 [144/250 18432/32000 (58%)] Loss: 1.91517 (QuantReg: 16.91306) QuantErr: 16.91306 batch_time=0.49465 
Train Epoch: 23 [155/250 19840/32000 (62%)] Loss: 2.21013 (QuantReg: 16.96517) QuantErr: 16.96517 batch_time=0.50778 
Train Epoch: 23 [166/250 21248/32000 (66%)] Loss: 1.88343 (QuantReg: 16.97140) QuantErr: 16.97140 batch_time=0.55521 
Train Epoch: 23 [177/250 22656/32000 (71%)] Loss: 2.09145 (QuantReg: 17.04931) QuantErr: 17.04931 batch_time=0.50628 
Train Epoch: 23 [188/250 24064/32000 (75%)] Loss: 1.71185 (QuantReg: 16.96279) QuantErr: 16.96279 batch_time=0.50307 
Train Epoch: 23 [199/250 25472/32000 (80%)] Loss: 1.99698 (QuantReg: 16.95709) QuantErr: 16.95709 batch_time=0.50617 
Train Epoch: 23 [210/250 26880/32000 (84%)] Loss: 1.60906 (QuantReg: 17.26892) QuantErr: 17.26892 batch_time=0.51367 
Train Epoch: 23 [221/250 28288/32000 (88%)] Loss: 2.24949 (QuantReg: 16.99853) QuantErr: 16.99853 batch_time=0.54672 
Train Epoch: 23 [232/250 29696/32000 (93%)] Loss: 2.09592 (QuantReg: 17.07587) QuantErr: 17.07587 batch_time=0.53709 
Train Epoch: 23 [243/250 31104/32000 (97%)] Loss: 1.74104 (QuantReg: 17.14631) QuantErr: 17.14631 batch_time=0.53187 
Train Epoch: 23 codebook_update_time=1.72028
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_LSMDC_t0.03/checkpoint-epoch23.pth ...
Done in 4.607s
removing stale ckpt [epoch 22] [took 0.01s]
 epoch          : 23
 loss           : 2.1288502402305602
 quant_reg      : 16.963503982543944
 quant_err      : 16.963503982543944
 learning_rate  : 1.6176677248685452e-05
 n_samples      : 736000
 n_steps        : 5750
 LSMDC_full_test/t2v_metrics/R1: 12.2
 LSMDC_full_test/t2v_metrics/R5: 31.7
 LSMDC_full_test/t2v_metrics/R10: 41.5
 LSMDC_full_test/t2v_metrics/R50: 68.6
 LSMDC_full_test/t2v_metrics/MedR: 18.0
 LSMDC_full_test/t2v_metrics/MeanR: 68.265
 LSMDC_full_test/t2v_metrics/geometric_mean_R1-R5-R10: 25.224490133405823
 LSMDC_full_test/v2t_metrics/R1: 11.6
 LSMDC_full_test/v2t_metrics/R5: 30.3
 LSMDC_full_test/v2t_metrics/R10: 40.6
 LSMDC_full_test/v2t_metrics/R50: 66.6
 LSMDC_full_test/v2t_metrics/MedR: 20.0
 LSMDC_full_test/v2t_metrics/MeanR: 68.543
 LSMDC_full_test/v2t_metrics/geometric_mean_R1-R5-R10: 24.255424726101158
 mnt_best       : 25.644444888038073
 not_improved_count: 8
Train Epoch: 24 [1/250 128/32000 (0%)] Loss: 2.08542 (QuantReg: 17.10839) QuantErr: 17.10839 batch_time=23.52226 
Train Epoch: 24 [12/250 1536/32000 (5%)] Loss: 1.77880 (QuantReg: 17.12056) QuantErr: 17.12056 batch_time=0.52851 
Train Epoch: 24 [23/250 2944/32000 (9%)] Loss: 2.50353 (QuantReg: 16.74979) QuantErr: 16.74979 batch_time=0.53559 
Train Epoch: 24 [34/250 4352/32000 (14%)] Loss: 2.25741 (QuantReg: 17.01909) QuantErr: 17.01909 batch_time=0.50689 
Train Epoch: 24 [45/250 5760/32000 (18%)] Loss: 2.17083 (QuantReg: 17.10657) QuantErr: 17.10657 batch_time=0.50642 
Train Epoch: 24 [56/250 7168/32000 (22%)] Loss: 2.29387 (QuantReg: 17.01157) QuantErr: 17.01157 batch_time=0.50182 
Train Epoch: 24 [67/250 8576/32000 (27%)] Loss: 1.75994 (QuantReg: 17.08833) QuantErr: 17.08833 batch_time=0.54744 
Train Epoch: 24 [78/250 9984/32000 (31%)] Loss: 1.87633 (QuantReg: 17.15133) QuantErr: 17.15133 batch_time=0.50273 
Train Epoch: 24 [89/250 11392/32000 (36%)] Loss: 2.13569 (QuantReg: 17.13800) QuantErr: 17.13800 batch_time=0.50413 
Train Epoch: 24 [100/250 12800/32000 (40%)] Loss: 2.01619 (QuantReg: 17.09842) QuantErr: 17.09842 batch_time=0.60924 
Train Epoch: 24 [111/250 14208/32000 (44%)] Loss: 1.64426 (QuantReg: 17.25210) QuantErr: 17.25210 batch_time=0.55261 
Train Epoch: 24 [122/250 15616/32000 (49%)] Loss: 1.98931 (QuantReg: 17.23184) QuantErr: 17.23184 batch_time=0.52975 
Train Epoch: 24 [133/250 17024/32000 (53%)] Loss: 1.96404 (QuantReg: 17.30125) QuantErr: 17.30125 batch_time=0.49299 
Train Epoch: 24 [144/250 18432/32000 (58%)] Loss: 1.80564 (QuantReg: 17.10041) QuantErr: 17.10041 batch_time=0.50897 
Train Epoch: 24 [155/250 19840/32000 (62%)] Loss: 1.95528 (QuantReg: 17.13286) QuantErr: 17.13286 batch_time=0.51639 
Train Epoch: 24 [166/250 21248/32000 (66%)] Loss: 2.64495 (QuantReg: 17.13360) QuantErr: 17.13360 batch_time=0.51550 
Train Epoch: 24 [177/250 22656/32000 (71%)] Loss: 2.17409 (QuantReg: 16.97090) QuantErr: 16.97090 batch_time=0.54218 
Train Epoch: 24 [188/250 24064/32000 (75%)] Loss: 2.13400 (QuantReg: 17.15283) QuantErr: 17.15283 batch_time=0.50904 
Train Epoch: 24 [199/250 25472/32000 (80%)] Loss: 2.18570 (QuantReg: 17.04764) QuantErr: 17.04764 batch_time=0.52115 
Train Epoch: 24 [210/250 26880/32000 (84%)] Loss: 2.22803 (QuantReg: 17.37286) QuantErr: 17.37286 batch_time=0.50690 
Train Epoch: 24 [221/250 28288/32000 (88%)] Loss: 2.23489 (QuantReg: 17.02928) QuantErr: 17.02928 batch_time=0.50018 
Train Epoch: 24 [232/250 29696/32000 (93%)] Loss: 1.66565 (QuantReg: 17.33106) QuantErr: 17.33106 batch_time=1.26302 
Train Epoch: 24 [243/250 31104/32000 (97%)] Loss: 1.99439 (QuantReg: 17.12814) QuantErr: 17.12814 batch_time=0.50697 
Train Epoch: 24 codebook_update_time=1.94779
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_LSMDC_t0.03/checkpoint-epoch24.pth ...
Done in 4.442s
removing stale ckpt [epoch 23] [took 0.00s]
 epoch          : 24
 loss           : 2.0835448274612425
 quant_reg      : 17.089181549072265
 quant_err      : 17.089181549072265
 learning_rate  : 1.5367843386251178e-05
 n_samples      : 768000
 n_steps        : 6000
 LSMDC_full_test/t2v_metrics/R1: 12.6
 LSMDC_full_test/t2v_metrics/R5: 31.6
 LSMDC_full_test/t2v_metrics/R10: 41.4
 LSMDC_full_test/t2v_metrics/R50: 68.0
 LSMDC_full_test/t2v_metrics/MedR: 18.0
 LSMDC_full_test/t2v_metrics/MeanR: 70.6985
 LSMDC_full_test/t2v_metrics/geometric_mean_R1-R5-R10: 25.449894691443102
 LSMDC_full_test/v2t_metrics/R1: 12.4
 LSMDC_full_test/v2t_metrics/R5: 31.8
 LSMDC_full_test/v2t_metrics/R10: 41.8
 LSMDC_full_test/v2t_metrics/R50: 67.9
 LSMDC_full_test/v2t_metrics/MedR: 18.5
 LSMDC_full_test/v2t_metrics/MeanR: 67.838
 LSMDC_full_test/v2t_metrics/geometric_mean_R1-R5-R10: 25.449252399740065
 mnt_best       : 25.644444888038073
 not_improved_count: 9
Train Epoch: 25 [1/250 128/32000 (0%)] Loss: 2.04192 (QuantReg: 17.13551) QuantErr: 17.13551 batch_time=16.27392 
Train Epoch: 25 [12/250 1536/32000 (5%)] Loss: 2.06921 (QuantReg: 16.95613) QuantErr: 16.95613 batch_time=0.50365 
Train Epoch: 25 [23/250 2944/32000 (9%)] Loss: 1.78374 (QuantReg: 17.10363) QuantErr: 17.10363 batch_time=0.51573 
Train Epoch: 25 [34/250 4352/32000 (14%)] Loss: 2.00968 (QuantReg: 17.08218) QuantErr: 17.08218 batch_time=0.52455 
Train Epoch: 25 [45/250 5760/32000 (18%)] Loss: 2.04848 (QuantReg: 17.14552) QuantErr: 17.14552 batch_time=0.50201 
Train Epoch: 25 [56/250 7168/32000 (22%)] Loss: 2.11696 (QuantReg: 17.08641) QuantErr: 17.08641 batch_time=0.61899 
Train Epoch: 25 [67/250 8576/32000 (27%)] Loss: 2.42685 (QuantReg: 17.13402) QuantErr: 17.13402 batch_time=0.51331 
Train Epoch: 25 [78/250 9984/32000 (31%)] Loss: 1.93580 (QuantReg: 17.10140) QuantErr: 17.10140 batch_time=0.51184 
Train Epoch: 25 [89/250 11392/32000 (36%)] Loss: 1.84376 (QuantReg: 17.23933) QuantErr: 17.23933 batch_time=1.14023 
Train Epoch: 25 [100/250 12800/32000 (40%)] Loss: 1.86963 (QuantReg: 17.07417) QuantErr: 17.07417 batch_time=0.50409 
Train Epoch: 25 [111/250 14208/32000 (44%)] Loss: 1.77179 (QuantReg: 17.22322) QuantErr: 17.22322 batch_time=0.53566 
Train Epoch: 25 [122/250 15616/32000 (49%)] Loss: 2.23333 (QuantReg: 17.07784) QuantErr: 17.07784 batch_time=0.48056 
Train Epoch: 25 [133/250 17024/32000 (53%)] Loss: 2.93271 (QuantReg: 17.09337) QuantErr: 17.09337 batch_time=0.51105 
Train Epoch: 25 [144/250 18432/32000 (58%)] Loss: 1.87010 (QuantReg: 17.19535) QuantErr: 17.19535 batch_time=0.53716 
Train Epoch: 25 [155/250 19840/32000 (62%)] Loss: 2.07468 (QuantReg: 17.24438) QuantErr: 17.24438 batch_time=3.23498 
Train Epoch: 25 [166/250 21248/32000 (66%)] Loss: 2.16159 (QuantReg: 17.47470) QuantErr: 17.47470 batch_time=0.51710 
Train Epoch: 25 [177/250 22656/32000 (71%)] Loss: 1.92392 (QuantReg: 17.13241) QuantErr: 17.13241 batch_time=0.49460 
Train Epoch: 25 [188/250 24064/32000 (75%)] Loss: 2.26030 (QuantReg: 17.37762) QuantErr: 17.37762 batch_time=0.48787 
Train Epoch: 25 [199/250 25472/32000 (80%)] Loss: 2.22598 (QuantReg: 17.13618) QuantErr: 17.13618 batch_time=0.49228 
Train Epoch: 25 [210/250 26880/32000 (84%)] Loss: 1.92770 (QuantReg: 17.43319) QuantErr: 17.43319 batch_time=0.55734 
Train Epoch: 25 [221/250 28288/32000 (88%)] Loss: 2.07387 (QuantReg: 17.54884) QuantErr: 17.54884 batch_time=0.52981 
Train Epoch: 25 [232/250 29696/32000 (93%)] Loss: 1.77833 (QuantReg: 17.23843) QuantErr: 17.23843 batch_time=0.50941 
Train Epoch: 25 [243/250 31104/32000 (97%)] Loss: 1.94698 (QuantReg: 17.34410) QuantErr: 17.34410 batch_time=0.51381 
Train Epoch: 25 codebook_update_time=1.85275
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_LSMDC_t0.03/checkpoint-epoch25.pth ...
Done in 4.578s
Updating 'best' checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_LSMDC_t0.03/checkpoint-epoch25.pth ...
Done in 9.777s
removing stale ckpt [epoch 24] [took 0.04s]
 epoch          : 25
 loss           : 2.033212435722351
 quant_reg      : 17.20409449005127
 quant_err      : 17.20409449005127
 learning_rate  : 1.4599451216938618e-05
 n_samples      : 800000
 n_steps        : 6250
 LSMDC_full_test/t2v_metrics/R1: 12.8
 LSMDC_full_test/t2v_metrics/R5: 32.8
 LSMDC_full_test/t2v_metrics/R10: 41.5
 LSMDC_full_test/t2v_metrics/R50: 67.8
 LSMDC_full_test/t2v_metrics/MedR: 18.0
 LSMDC_full_test/t2v_metrics/MeanR: 69.726
 LSMDC_full_test/t2v_metrics/geometric_mean_R1-R5-R10: 25.92451478537534
 LSMDC_full_test/v2t_metrics/R1: 12.8
 LSMDC_full_test/v2t_metrics/R5: 31.3
 LSMDC_full_test/v2t_metrics/R10: 39.6
 LSMDC_full_test/v2t_metrics/R50: 67.6
 LSMDC_full_test/v2t_metrics/MedR: 19.0
 LSMDC_full_test/v2t_metrics/MeanR: 68.996
 LSMDC_full_test/v2t_metrics/geometric_mean_R1-R5-R10: 25.127531786155508
 mnt_best       : 25.92451478537534
 not_improved_count: 0
Train Epoch: 26 [1/250 128/32000 (0%)] Loss: 2.09252 (QuantReg: 17.50865) QuantErr: 17.50865 batch_time=20.40668 
Train Epoch: 26 [12/250 1536/32000 (5%)] Loss: 2.07534 (QuantReg: 17.05068) QuantErr: 17.05068 batch_time=0.49858 
Train Epoch: 26 [23/250 2944/32000 (9%)] Loss: 1.86121 (QuantReg: 17.32414) QuantErr: 17.32414 batch_time=0.51382 
Train Epoch: 26 [34/250 4352/32000 (14%)] Loss: 1.82832 (QuantReg: 17.33469) QuantErr: 17.33469 batch_time=0.49516 
Train Epoch: 26 [45/250 5760/32000 (18%)] Loss: 1.96803 (QuantReg: 16.99843) QuantErr: 16.99843 batch_time=0.51999 
Train Epoch: 26 [56/250 7168/32000 (22%)] Loss: 1.81155 (QuantReg: 17.23024) QuantErr: 17.23024 batch_time=0.49189 
Train Epoch: 26 [67/250 8576/32000 (27%)] Loss: 1.96009 (QuantReg: 17.42839) QuantErr: 17.42839 batch_time=0.51801 
Train Epoch: 26 [78/250 9984/32000 (31%)] Loss: 2.22398 (QuantReg: 17.03261) QuantErr: 17.03261 batch_time=0.51445 
Train Epoch: 26 [89/250 11392/32000 (36%)] Loss: 2.29512 (QuantReg: 17.15396) QuantErr: 17.15396 batch_time=0.50180 
Train Epoch: 26 [100/250 12800/32000 (40%)] Loss: 2.16864 (QuantReg: 17.21243) QuantErr: 17.21243 batch_time=0.49727 
Train Epoch: 26 [111/250 14208/32000 (44%)] Loss: 2.40970 (QuantReg: 17.13702) QuantErr: 17.13702 batch_time=1.21424 
Train Epoch: 26 [122/250 15616/32000 (49%)] Loss: 2.13882 (QuantReg: 17.32942) QuantErr: 17.32942 batch_time=0.55046 
Train Epoch: 26 [133/250 17024/32000 (53%)] Loss: 2.18462 (QuantReg: 17.48819) QuantErr: 17.48819 batch_time=0.53454 
Train Epoch: 26 [144/250 18432/32000 (58%)] Loss: 2.20668 (QuantReg: 17.35560) QuantErr: 17.35560 batch_time=0.50346 
Train Epoch: 26 [155/250 19840/32000 (62%)] Loss: 2.47855 (QuantReg: 17.32890) QuantErr: 17.32890 batch_time=0.51893 
Train Epoch: 26 [166/250 21248/32000 (66%)] Loss: 2.06898 (QuantReg: 17.33074) QuantErr: 17.33074 batch_time=0.55807 
Train Epoch: 26 [177/250 22656/32000 (71%)] Loss: 1.64633 (QuantReg: 17.45812) QuantErr: 17.45812 batch_time=0.50992 
Train Epoch: 26 [188/250 24064/32000 (75%)] Loss: 2.50039 (QuantReg: 17.02542) QuantErr: 17.02542 batch_time=0.50898 
Train Epoch: 26 [199/250 25472/32000 (80%)] Loss: 1.84586 (QuantReg: 17.20770) QuantErr: 17.20770 batch_time=0.50150 
Train Epoch: 26 [210/250 26880/32000 (84%)] Loss: 2.05593 (QuantReg: 17.29400) QuantErr: 17.29400 batch_time=0.51076 
Train Epoch: 26 [221/250 28288/32000 (88%)] Loss: 1.74478 (QuantReg: 17.44038) QuantErr: 17.44038 batch_time=0.53639 
Train Epoch: 26 [232/250 29696/32000 (93%)] Loss: 2.24018 (QuantReg: 17.35184) QuantErr: 17.35184 batch_time=0.50398 
Train Epoch: 26 [243/250 31104/32000 (97%)] Loss: 1.71446 (QuantReg: 17.57008) QuantErr: 17.57008 batch_time=0.50788 
Train Epoch: 26 codebook_update_time=1.79723
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_LSMDC_t0.03/checkpoint-epoch26.pth ...
Done in 4.052s
removing stale ckpt [epoch 25] [took 0.00s]
 epoch          : 26
 loss           : 1.9695875430107117
 quant_reg      : 17.334876304626466
 quant_err      : 17.334876304626466
 learning_rate  : 1.3869478656091687e-05
 n_samples      : 832000
 n_steps        : 6500
 LSMDC_full_test/t2v_metrics/R1: 13.0
 LSMDC_full_test/t2v_metrics/R5: 31.9
 LSMDC_full_test/t2v_metrics/R10: 42.0
 LSMDC_full_test/t2v_metrics/R50: 67.8
 LSMDC_full_test/t2v_metrics/MedR: 18.0
 LSMDC_full_test/t2v_metrics/MeanR: 70.848
 LSMDC_full_test/t2v_metrics/geometric_mean_R1-R5-R10: 25.921558453010793
 LSMDC_full_test/v2t_metrics/R1: 13.2
 LSMDC_full_test/v2t_metrics/R5: 31.1
 LSMDC_full_test/v2t_metrics/R10: 40.0
 LSMDC_full_test/v2t_metrics/R50: 67.6
 LSMDC_full_test/v2t_metrics/MedR: 19.0
 LSMDC_full_test/v2t_metrics/MeanR: 67.845
 LSMDC_full_test/v2t_metrics/geometric_mean_R1-R5-R10: 25.417418353952165
 mnt_best       : 25.92451478537534
 not_improved_count: 1
Train Epoch: 27 [1/250 128/32000 (0%)] Loss: 1.92152 (QuantReg: 17.30212) QuantErr: 17.30212 batch_time=16.71908 
Train Epoch: 27 [12/250 1536/32000 (5%)] Loss: 1.46461 (QuantReg: 17.33848) QuantErr: 17.33848 batch_time=0.50254 
Train Epoch: 27 [23/250 2944/32000 (9%)] Loss: 2.09400 (QuantReg: 17.17926) QuantErr: 17.17926 batch_time=0.49621 
Train Epoch: 27 [34/250 4352/32000 (14%)] Loss: 2.02733 (QuantReg: 17.04686) QuantErr: 17.04686 batch_time=0.53823 
Train Epoch: 27 [45/250 5760/32000 (18%)] Loss: 2.38223 (QuantReg: 17.14040) QuantErr: 17.14040 batch_time=0.49246 
Train Epoch: 27 [56/250 7168/32000 (22%)] Loss: 1.79259 (QuantReg: 17.39088) QuantErr: 17.39088 batch_time=0.49118 
Train Epoch: 27 [67/250 8576/32000 (27%)] Loss: 1.98900 (QuantReg: 17.53097) QuantErr: 17.53097 batch_time=1.09827 
Train Epoch: 27 [78/250 9984/32000 (31%)] Loss: 2.35412 (QuantReg: 17.23763) QuantErr: 17.23763 batch_time=0.49587 
Train Epoch: 27 [89/250 11392/32000 (36%)] Loss: 1.70586 (QuantReg: 17.60821) QuantErr: 17.60821 batch_time=0.52811 
Train Epoch: 27 [100/250 12800/32000 (40%)] Loss: 2.06236 (QuantReg: 17.33129) QuantErr: 17.33129 batch_time=0.53207 
Train Epoch: 27 [111/250 14208/32000 (44%)] Loss: 2.01873 (QuantReg: 17.25850) QuantErr: 17.25850 batch_time=0.63180 
Train Epoch: 27 [122/250 15616/32000 (49%)] Loss: 2.18821 (QuantReg: 17.54619) QuantErr: 17.54619 batch_time=0.62670 
Train Epoch: 27 [133/250 17024/32000 (53%)] Loss: 1.62913 (QuantReg: 17.29465) QuantErr: 17.29465 batch_time=0.50987 
Train Epoch: 27 [144/250 18432/32000 (58%)] Loss: 1.99908 (QuantReg: 17.32361) QuantErr: 17.32361 batch_time=0.49893 
Train Epoch: 27 [155/250 19840/32000 (62%)] Loss: 2.40969 (QuantReg: 17.45938) QuantErr: 17.45938 batch_time=0.49555 
Train Epoch: 27 [166/250 21248/32000 (66%)] Loss: 1.72409 (QuantReg: 17.60142) QuantErr: 17.60142 batch_time=0.51391 
Train Epoch: 27 [177/250 22656/32000 (71%)] Loss: 1.97187 (QuantReg: 17.51518) QuantErr: 17.51518 batch_time=0.51098 
Train Epoch: 27 [188/250 24064/32000 (75%)] Loss: 2.07572 (QuantReg: 17.62922) QuantErr: 17.62922 batch_time=0.50684 
Train Epoch: 27 [199/250 25472/32000 (80%)] Loss: 1.83000 (QuantReg: 17.57138) QuantErr: 17.57138 batch_time=0.48875 
Train Epoch: 27 [210/250 26880/32000 (84%)] Loss: 1.85408 (QuantReg: 17.32040) QuantErr: 17.32040 batch_time=0.50146 
Train Epoch: 27 [221/250 28288/32000 (88%)] Loss: 1.97691 (QuantReg: 17.29391) QuantErr: 17.29391 batch_time=0.49646 
Train Epoch: 27 [232/250 29696/32000 (93%)] Loss: 1.36562 (QuantReg: 17.71992) QuantErr: 17.71992 batch_time=0.52627 
Train Epoch: 27 [243/250 31104/32000 (97%)] Loss: 2.11141 (QuantReg: 17.54760) QuantErr: 17.54760 batch_time=0.49621 
Train Epoch: 27 codebook_update_time=1.67473
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_LSMDC_t0.03/checkpoint-epoch27.pth ...
Done in 4.113s
Updating 'best' checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_LSMDC_t0.03/checkpoint-epoch27.pth ...
Done in 9.672s
removing stale ckpt [epoch 26] [took 0.01s]
 epoch          : 27
 loss           : 1.9479453830718994
 quant_reg      : 17.423051788330078
 quant_err      : 17.423051788330078
 learning_rate  : 1.3176004723287102e-05
 n_samples      : 864000
 n_steps        : 6750
 LSMDC_full_test/t2v_metrics/R1: 13.6
 LSMDC_full_test/t2v_metrics/R5: 31.6
 LSMDC_full_test/t2v_metrics/R10: 41.1
 LSMDC_full_test/t2v_metrics/R50: 68.3
 LSMDC_full_test/t2v_metrics/MedR: 19.0
 LSMDC_full_test/t2v_metrics/MeanR: 71.362
 LSMDC_full_test/t2v_metrics/geometric_mean_R1-R5-R10: 26.04289565982991
 LSMDC_full_test/v2t_metrics/R1: 12.3
 LSMDC_full_test/v2t_metrics/R5: 30.7
 LSMDC_full_test/v2t_metrics/R10: 40.2
 LSMDC_full_test/v2t_metrics/R50: 65.8
 LSMDC_full_test/v2t_metrics/MedR: 20.0
 LSMDC_full_test/v2t_metrics/MeanR: 68.907
 LSMDC_full_test/v2t_metrics/geometric_mean_R1-R5-R10: 24.7603348329598
 mnt_best       : 26.04289565982991
 not_improved_count: 0
Train Epoch: 28 [1/250 128/32000 (0%)] Loss: 1.81660 (QuantReg: 17.32415) QuantErr: 17.32415 batch_time=20.53634 
Train Epoch: 28 [12/250 1536/32000 (5%)] Loss: 2.07523 (QuantReg: 17.36855) QuantErr: 17.36855 batch_time=0.50993 
Train Epoch: 28 [23/250 2944/32000 (9%)] Loss: 1.77026 (QuantReg: 17.42750) QuantErr: 17.42750 batch_time=0.53584 
Train Epoch: 28 [34/250 4352/32000 (14%)] Loss: 1.84423 (QuantReg: 17.28599) QuantErr: 17.28599 batch_time=0.50048 
Train Epoch: 28 [45/250 5760/32000 (18%)] Loss: 1.97089 (QuantReg: 17.49630) QuantErr: 17.49630 batch_time=0.52856 
Train Epoch: 28 [56/250 7168/32000 (22%)] Loss: 1.91317 (QuantReg: 17.43236) QuantErr: 17.43236 batch_time=0.53554 
Train Epoch: 28 [67/250 8576/32000 (27%)] Loss: 1.94032 (QuantReg: 17.60474) QuantErr: 17.60474 batch_time=0.52898 
Train Epoch: 28 [78/250 9984/32000 (31%)] Loss: 1.78741 (QuantReg: 17.47557) QuantErr: 17.47557 batch_time=0.51686 
Train Epoch: 28 [89/250 11392/32000 (36%)] Loss: 1.92539 (QuantReg: 17.47239) QuantErr: 17.47239 batch_time=0.55919 
Train Epoch: 28 [100/250 12800/32000 (40%)] Loss: 2.27870 (QuantReg: 17.62808) QuantErr: 17.62808 batch_time=0.50217 
Train Epoch: 28 [111/250 14208/32000 (44%)] Loss: 2.09960 (QuantReg: 17.64296) QuantErr: 17.64296 batch_time=0.53942 
Train Epoch: 28 [122/250 15616/32000 (49%)] Loss: 1.41874 (QuantReg: 17.48309) QuantErr: 17.48309 batch_time=0.50239 
Train Epoch: 28 [133/250 17024/32000 (53%)] Loss: 1.84464 (QuantReg: 17.29039) QuantErr: 17.29039 batch_time=0.51168 
Train Epoch: 28 [144/250 18432/32000 (58%)] Loss: 1.65313 (QuantReg: 17.44373) QuantErr: 17.44373 batch_time=0.64820 
Train Epoch: 28 [155/250 19840/32000 (62%)] Loss: 2.13549 (QuantReg: 17.47671) QuantErr: 17.47671 batch_time=1.07190 
Train Epoch: 28 [166/250 21248/32000 (66%)] Loss: 1.56685 (QuantReg: 17.45871) QuantErr: 17.45871 batch_time=0.50982 
Train Epoch: 28 [177/250 22656/32000 (71%)] Loss: 2.10840 (QuantReg: 17.38201) QuantErr: 17.38201 batch_time=0.58014 
Train Epoch: 28 [188/250 24064/32000 (75%)] Loss: 1.82349 (QuantReg: 17.90505) QuantErr: 17.90505 batch_time=1.60902 
Train Epoch: 28 [199/250 25472/32000 (80%)] Loss: 1.86221 (QuantReg: 17.40558) QuantErr: 17.40558 batch_time=0.53851 
Train Epoch: 28 [210/250 26880/32000 (84%)] Loss: 1.60772 (QuantReg: 17.56347) QuantErr: 17.56347 batch_time=0.82214 
Train Epoch: 28 [221/250 28288/32000 (88%)] Loss: 1.82158 (QuantReg: 17.59724) QuantErr: 17.59724 batch_time=0.49671 
Train Epoch: 28 [232/250 29696/32000 (93%)] Loss: 1.64943 (QuantReg: 17.66419) QuantErr: 17.66419 batch_time=0.50399 
Train Epoch: 28 [243/250 31104/32000 (97%)] Loss: 1.46411 (QuantReg: 17.67405) QuantErr: 17.67405 batch_time=0.50539 
Train Epoch: 28 codebook_update_time=1.67583
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_LSMDC_t0.03/checkpoint-epoch28.pth ...
Done in 4.829s
Updating 'best' checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_LSMDC_t0.03/checkpoint-epoch28.pth ...
Done in 8.864s
removing stale ckpt [epoch 27] [took 0.15s]
 epoch          : 28
 loss           : 1.9029349632263184
 quant_reg      : 17.519388092041016
 quant_err      : 17.519388092041016
 learning_rate  : 1.2517204487122746e-05
 n_samples      : 896000
 n_steps        : 7000
 LSMDC_full_test/t2v_metrics/R1: 13.1
 LSMDC_full_test/t2v_metrics/R5: 32.0
 LSMDC_full_test/t2v_metrics/R10: 42.7
 LSMDC_full_test/t2v_metrics/R50: 68.0
 LSMDC_full_test/t2v_metrics/MedR: 19.0
 LSMDC_full_test/t2v_metrics/MeanR: 71.418
 LSMDC_full_test/t2v_metrics/geometric_mean_R1-R5-R10: 26.158713600326845
 LSMDC_full_test/v2t_metrics/R1: 13.1
 LSMDC_full_test/v2t_metrics/R5: 30.9
 LSMDC_full_test/v2t_metrics/R10: 40.2
 LSMDC_full_test/v2t_metrics/R50: 67.2
 LSMDC_full_test/v2t_metrics/MedR: 19.0
 LSMDC_full_test/v2t_metrics/MeanR: 68.437
 LSMDC_full_test/v2t_metrics/geometric_mean_R1-R5-R10: 25.340700112117872
 mnt_best       : 26.158713600326845
 not_improved_count: 0
Train Epoch: 29 [1/250 128/32000 (0%)] Loss: 1.93376 (QuantReg: 17.49593) QuantErr: 17.49593 batch_time=16.74097 
Train Epoch: 29 [12/250 1536/32000 (5%)] Loss: 1.91006 (QuantReg: 17.54369) QuantErr: 17.54369 batch_time=0.50966 
Train Epoch: 29 [23/250 2944/32000 (9%)] Loss: 2.11903 (QuantReg: 17.42885) QuantErr: 17.42885 batch_time=0.59590 
Train Epoch: 29 [34/250 4352/32000 (14%)] Loss: 2.02023 (QuantReg: 17.37180) QuantErr: 17.37180 batch_time=0.52316 
Train Epoch: 29 [45/250 5760/32000 (18%)] Loss: 1.99008 (QuantReg: 17.38642) QuantErr: 17.38642 batch_time=0.51822 
Train Epoch: 29 [56/250 7168/32000 (22%)] Loss: 1.52790 (QuantReg: 17.57473) QuantErr: 17.57473 batch_time=0.50645 
Train Epoch: 29 [67/250 8576/32000 (27%)] Loss: 1.94754 (QuantReg: 17.46000) QuantErr: 17.46000 batch_time=0.48710 
Train Epoch: 29 [78/250 9984/32000 (31%)] Loss: 2.16673 (QuantReg: 17.70365) QuantErr: 17.70365 batch_time=1.07489 
Train Epoch: 29 [89/250 11392/32000 (36%)] Loss: 1.43376 (QuantReg: 17.71696) QuantErr: 17.71696 batch_time=0.49965 
Train Epoch: 29 [100/250 12800/32000 (40%)] Loss: 2.04897 (QuantReg: 17.43616) QuantErr: 17.43616 batch_time=0.52457 
Train Epoch: 29 [111/250 14208/32000 (44%)] Loss: 1.80219 (QuantReg: 17.37576) QuantErr: 17.37576 batch_time=0.51068 
Train Epoch: 29 [122/250 15616/32000 (49%)] Loss: 1.73311 (QuantReg: 17.59211) QuantErr: 17.59211 batch_time=0.51901 
Train Epoch: 29 [133/250 17024/32000 (53%)] Loss: 1.95786 (QuantReg: 17.66457) QuantErr: 17.66457 batch_time=0.49884 
Train Epoch: 29 [144/250 18432/32000 (58%)] Loss: 1.47903 (QuantReg: 17.78924) QuantErr: 17.78924 batch_time=1.07207 
Train Epoch: 29 [155/250 19840/32000 (62%)] Loss: 2.14049 (QuantReg: 17.59019) QuantErr: 17.59019 batch_time=0.50935 
Train Epoch: 29 [166/250 21248/32000 (66%)] Loss: 1.73207 (QuantReg: 17.75038) QuantErr: 17.75038 batch_time=0.56864 
Train Epoch: 29 [177/250 22656/32000 (71%)] Loss: 1.91371 (QuantReg: 17.59686) QuantErr: 17.59686 batch_time=0.54833 
Train Epoch: 29 [188/250 24064/32000 (75%)] Loss: 1.59093 (QuantReg: 17.61919) QuantErr: 17.61919 batch_time=0.53008 
Train Epoch: 29 [199/250 25472/32000 (80%)] Loss: 1.83558 (QuantReg: 17.77371) QuantErr: 17.77371 batch_time=1.99864 
Train Epoch: 29 [210/250 26880/32000 (84%)] Loss: 1.61957 (QuantReg: 17.74184) QuantErr: 17.74184 batch_time=0.49291 
Train Epoch: 29 [221/250 28288/32000 (88%)] Loss: 1.59569 (QuantReg: 17.68905) QuantErr: 17.68905 batch_time=0.50937 
Train Epoch: 29 [232/250 29696/32000 (93%)] Loss: 1.27559 (QuantReg: 17.79498) QuantErr: 17.79498 batch_time=1.39829 
Train Epoch: 29 [243/250 31104/32000 (97%)] Loss: 1.86740 (QuantReg: 17.64886) QuantErr: 17.64886 batch_time=0.50118 
Train Epoch: 29 codebook_update_time=1.88560
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_LSMDC_t0.03/checkpoint-epoch29.pth ...
Done in 4.036s
removing stale ckpt [epoch 28] [took 0.05s]
 epoch          : 29
 loss           : 1.8527355952262878
 quant_reg      : 17.59497457885742
 quant_err      : 17.59497457885742
 learning_rate  : 1.1891344262766608e-05
 n_samples      : 928000
 n_steps        : 7250
 LSMDC_full_test/t2v_metrics/R1: 12.7
 LSMDC_full_test/t2v_metrics/R5: 31.4
 LSMDC_full_test/t2v_metrics/R10: 41.9
 LSMDC_full_test/t2v_metrics/R50: 67.5
 LSMDC_full_test/t2v_metrics/MedR: 18.0
 LSMDC_full_test/t2v_metrics/MeanR: 71.993
 LSMDC_full_test/t2v_metrics/geometric_mean_R1-R5-R10: 25.565196235230022
 LSMDC_full_test/v2t_metrics/R1: 12.9
 LSMDC_full_test/v2t_metrics/R5: 30.2
 LSMDC_full_test/v2t_metrics/R10: 39.2
 LSMDC_full_test/v2t_metrics/R50: 66.5
 LSMDC_full_test/v2t_metrics/MedR: 19.0
 LSMDC_full_test/v2t_metrics/MeanR: 69.477
 LSMDC_full_test/v2t_metrics/geometric_mean_R1-R5-R10: 24.810046224660073
 mnt_best       : 26.158713600326845
 not_improved_count: 1
Train Epoch: 30 [1/250 128/32000 (0%)] Loss: 1.94930 (QuantReg: 17.65329) QuantErr: 17.65329 batch_time=15.15788 
Train Epoch: 30 [12/250 1536/32000 (5%)] Loss: 1.92652 (QuantReg: 17.53668) QuantErr: 17.53668 batch_time=0.52565 
Train Epoch: 30 [23/250 2944/32000 (9%)] Loss: 2.02302 (QuantReg: 17.48068) QuantErr: 17.48068 batch_time=0.51232 
Train Epoch: 30 [34/250 4352/32000 (14%)] Loss: 1.96714 (QuantReg: 17.76581) QuantErr: 17.76581 batch_time=0.50842 
Train Epoch: 30 [45/250 5760/32000 (18%)] Loss: 1.93510 (QuantReg: 17.69515) QuantErr: 17.69515 batch_time=0.50402 
Train Epoch: 30 [56/250 7168/32000 (22%)] Loss: 2.02947 (QuantReg: 17.60254) QuantErr: 17.60254 batch_time=0.51268 
Train Epoch: 30 [67/250 8576/32000 (27%)] Loss: 1.68961 (QuantReg: 17.81429) QuantErr: 17.81429 batch_time=2.85412 
Train Epoch: 30 [78/250 9984/32000 (31%)] Loss: 1.90703 (QuantReg: 17.47460) QuantErr: 17.47460 batch_time=0.59828 
Train Epoch: 30 [89/250 11392/32000 (36%)] Loss: 2.01601 (QuantReg: 17.53160) QuantErr: 17.53160 batch_time=0.51460 
Train Epoch: 30 [100/250 12800/32000 (40%)] Loss: 1.59443 (QuantReg: 17.70794) QuantErr: 17.70794 batch_time=0.50689 
Train Epoch: 30 [111/250 14208/32000 (44%)] Loss: 1.56390 (QuantReg: 17.72642) QuantErr: 17.72642 batch_time=0.51236 
Train Epoch: 30 [122/250 15616/32000 (49%)] Loss: 1.87403 (QuantReg: 17.63572) QuantErr: 17.63572 batch_time=0.49935 
Train Epoch: 30 [133/250 17024/32000 (53%)] Loss: 1.80783 (QuantReg: 17.57092) QuantErr: 17.57092 batch_time=0.50925 
Train Epoch: 30 [144/250 18432/32000 (58%)] Loss: 1.66432 (QuantReg: 17.60877) QuantErr: 17.60877 batch_time=0.82431 
Train Epoch: 30 [155/250 19840/32000 (62%)] Loss: 1.82032 (QuantReg: 17.74138) QuantErr: 17.74138 batch_time=0.51035 
Train Epoch: 30 [166/250 21248/32000 (66%)] Loss: 1.72708 (QuantReg: 17.69948) QuantErr: 17.69948 batch_time=0.50767 
Train Epoch: 30 [177/250 22656/32000 (71%)] Loss: 1.66456 (QuantReg: 17.59020) QuantErr: 17.59020 batch_time=0.51253 
Train Epoch: 30 [188/250 24064/32000 (75%)] Loss: 1.85395 (QuantReg: 17.59536) QuantErr: 17.59536 batch_time=0.49989 
Train Epoch: 30 [199/250 25472/32000 (80%)] Loss: 2.11391 (QuantReg: 17.78440) QuantErr: 17.78440 batch_time=0.51831 
Train Epoch: 30 [210/250 26880/32000 (84%)] Loss: 1.60026 (QuantReg: 17.65847) QuantErr: 17.65847 batch_time=0.58998 
Train Epoch: 30 [221/250 28288/32000 (88%)] Loss: 1.78852 (QuantReg: 17.63770) QuantErr: 17.63770 batch_time=0.48962 
Train Epoch: 30 [232/250 29696/32000 (93%)] Loss: 1.73411 (QuantReg: 17.80902) QuantErr: 17.80902 batch_time=0.50519 
Train Epoch: 30 [243/250 31104/32000 (97%)] Loss: 2.03422 (QuantReg: 17.79275) QuantErr: 17.79275 batch_time=0.49991 
Train Epoch: 30 codebook_update_time=1.80778
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_LSMDC_t0.03/checkpoint-epoch30.pth ...
Done in 5.008s
removing stale ckpt [epoch 29] [took 0.01s]
 epoch          : 30
 loss           : 1.8441863193511963
 quant_reg      : 17.673450317382812
 quant_err      : 17.673450317382812
 learning_rate  : 1.1296777049628277e-05
 n_samples      : 960000
 n_steps        : 7500
 LSMDC_full_test/t2v_metrics/R1: 12.6
 LSMDC_full_test/t2v_metrics/R5: 31.4
 LSMDC_full_test/t2v_metrics/R10: 41.3
 LSMDC_full_test/t2v_metrics/R50: 67.9
 LSMDC_full_test/t2v_metrics/MedR: 18.0
 LSMDC_full_test/t2v_metrics/MeanR: 72.331
 LSMDC_full_test/t2v_metrics/geometric_mean_R1-R5-R10: 25.375625034148296
 LSMDC_full_test/v2t_metrics/R1: 12.7
 LSMDC_full_test/v2t_metrics/R5: 30.1
 LSMDC_full_test/v2t_metrics/R10: 40.0
 LSMDC_full_test/v2t_metrics/R50: 67.7
 LSMDC_full_test/v2t_metrics/MedR: 19.0
 LSMDC_full_test/v2t_metrics/MeanR: 69.261
 LSMDC_full_test/v2t_metrics/geometric_mean_R1-R5-R10: 24.820473901090004
 mnt_best       : 26.158713600326845
 not_improved_count: 2
Train Epoch: 31 [1/250 128/32000 (0%)] Loss: 1.49843 (QuantReg: 17.82255) QuantErr: 17.82255 batch_time=17.24916 
Train Epoch: 31 [12/250 1536/32000 (5%)] Loss: 1.76041 (QuantReg: 17.68320) QuantErr: 17.68320 batch_time=0.53357 
Train Epoch: 31 [23/250 2944/32000 (9%)] Loss: 1.94003 (QuantReg: 17.67347) QuantErr: 17.67347 batch_time=0.50940 
Train Epoch: 31 [34/250 4352/32000 (14%)] Loss: 1.68600 (QuantReg: 17.77279) QuantErr: 17.77279 batch_time=0.50041 
Train Epoch: 31 [45/250 5760/32000 (18%)] Loss: 1.61586 (QuantReg: 17.65712) QuantErr: 17.65712 batch_time=0.50753 
Train Epoch: 31 [56/250 7168/32000 (22%)] Loss: 1.72973 (QuantReg: 17.67495) QuantErr: 17.67495 batch_time=0.50181 
Train Epoch: 31 [67/250 8576/32000 (27%)] Loss: 1.49475 (QuantReg: 17.56592) QuantErr: 17.56592 batch_time=0.52077 
Train Epoch: 31 [78/250 9984/32000 (31%)] Loss: 1.78728 (QuantReg: 17.50242) QuantErr: 17.50242 batch_time=0.50047 
Train Epoch: 31 [89/250 11392/32000 (36%)] Loss: 1.78212 (QuantReg: 17.62649) QuantErr: 17.62649 batch_time=0.50492 
Train Epoch: 31 [100/250 12800/32000 (40%)] Loss: 1.68869 (QuantReg: 17.69605) QuantErr: 17.69605 batch_time=0.50900 
Train Epoch: 31 [111/250 14208/32000 (44%)] Loss: 1.62225 (QuantReg: 17.95509) QuantErr: 17.95509 batch_time=0.56260 
Train Epoch: 31 [122/250 15616/32000 (49%)] Loss: 1.54586 (QuantReg: 17.78619) QuantErr: 17.78619 batch_time=0.50730 
Train Epoch: 31 [133/250 17024/32000 (53%)] Loss: 1.72323 (QuantReg: 17.70203) QuantErr: 17.70203 batch_time=0.49926 
Train Epoch: 31 [144/250 18432/32000 (58%)] Loss: 2.21241 (QuantReg: 17.68486) QuantErr: 17.68486 batch_time=1.61367 
Train Epoch: 31 [155/250 19840/32000 (62%)] Loss: 1.73739 (QuantReg: 17.89395) QuantErr: 17.89395 batch_time=0.51553 
Train Epoch: 31 [166/250 21248/32000 (66%)] Loss: 2.07670 (QuantReg: 17.71457) QuantErr: 17.71457 batch_time=0.51175 
Train Epoch: 31 [177/250 22656/32000 (71%)] Loss: 1.61010 (QuantReg: 17.75300) QuantErr: 17.75300 batch_time=0.53381 
Train Epoch: 31 [188/250 24064/32000 (75%)] Loss: 1.69876 (QuantReg: 17.60527) QuantErr: 17.60527 batch_time=0.49250 
Train Epoch: 31 [199/250 25472/32000 (80%)] Loss: 1.73000 (QuantReg: 17.73647) QuantErr: 17.73647 batch_time=0.49201 
Train Epoch: 31 [210/250 26880/32000 (84%)] Loss: 1.56745 (QuantReg: 17.71603) QuantErr: 17.71603 batch_time=1.52966 
Train Epoch: 31 [221/250 28288/32000 (88%)] Loss: 1.58940 (QuantReg: 17.99248) QuantErr: 17.99248 batch_time=0.50292 
Train Epoch: 31 [232/250 29696/32000 (93%)] Loss: 1.74266 (QuantReg: 17.83697) QuantErr: 17.83697 batch_time=0.52308 
Train Epoch: 31 [243/250 31104/32000 (97%)] Loss: 2.16743 (QuantReg: 17.81137) QuantErr: 17.81137 batch_time=0.49881 
Train Epoch: 31 codebook_update_time=1.85906
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_LSMDC_t0.03/checkpoint-epoch31.pth ...
Done in 4.100s
removing stale ckpt [epoch 30] [took 0.00s]
 epoch          : 31
 loss           : 1.798484459400177
 quant_reg      : 17.735376007080077
 quant_err      : 17.735376007080077
 learning_rate  : 1.0731938197146863e-05
 n_samples      : 992000
 n_steps        : 7750
 LSMDC_full_test/t2v_metrics/R1: 13.1
 LSMDC_full_test/t2v_metrics/R5: 31.6
 LSMDC_full_test/t2v_metrics/R10: 41.6
 LSMDC_full_test/t2v_metrics/R50: 67.3
 LSMDC_full_test/t2v_metrics/MedR: 18.5
 LSMDC_full_test/t2v_metrics/MeanR: 73.701
 LSMDC_full_test/t2v_metrics/geometric_mean_R1-R5-R10: 25.82362677535085
 LSMDC_full_test/v2t_metrics/R1: 12.2
 LSMDC_full_test/v2t_metrics/R5: 31.4
 LSMDC_full_test/v2t_metrics/R10: 41.0
 LSMDC_full_test/v2t_metrics/R50: 67.5
 LSMDC_full_test/v2t_metrics/MedR: 18.5
 LSMDC_full_test/v2t_metrics/MeanR: 69.273
 LSMDC_full_test/v2t_metrics/geometric_mean_R1-R5-R10: 25.043274383222954
 mnt_best       : 26.158713600326845
 not_improved_count: 3
Train Epoch: 32 [1/250 128/32000 (0%)] Loss: 1.98688 (QuantReg: 17.79328) QuantErr: 17.79328 batch_time=19.10343 
Train Epoch: 32 [12/250 1536/32000 (5%)] Loss: 1.65613 (QuantReg: 17.70378) QuantErr: 17.70378 batch_time=0.49466 
Train Epoch: 32 [23/250 2944/32000 (9%)] Loss: 1.71549 (QuantReg: 17.92839) QuantErr: 17.92839 batch_time=0.49687 
Train Epoch: 32 [34/250 4352/32000 (14%)] Loss: 1.91063 (QuantReg: 17.96665) QuantErr: 17.96665 batch_time=0.49781 
Train Epoch: 32 [45/250 5760/32000 (18%)] Loss: 1.77006 (QuantReg: 17.64730) QuantErr: 17.64730 batch_time=0.50074 
Train Epoch: 32 [56/250 7168/32000 (22%)] Loss: 1.85110 (QuantReg: 17.58259) QuantErr: 17.58259 batch_time=0.50280 
Train Epoch: 32 [67/250 8576/32000 (27%)] Loss: 1.53995 (QuantReg: 17.85698) QuantErr: 17.85698 batch_time=0.51454 
Train Epoch: 32 [78/250 9984/32000 (31%)] Loss: 1.78346 (QuantReg: 17.89383) QuantErr: 17.89383 batch_time=0.57339 
Train Epoch: 32 [89/250 11392/32000 (36%)] Loss: 2.25936 (QuantReg: 17.80606) QuantErr: 17.80606 batch_time=1.74255 
Train Epoch: 32 [100/250 12800/32000 (40%)] Loss: 1.76882 (QuantReg: 17.80762) QuantErr: 17.80762 batch_time=0.51575 
Train Epoch: 32 [111/250 14208/32000 (44%)] Loss: 2.07069 (QuantReg: 17.94558) QuantErr: 17.94558 batch_time=0.58467 
Train Epoch: 32 [122/250 15616/32000 (49%)] Loss: 1.90632 (QuantReg: 17.76331) QuantErr: 17.76331 batch_time=0.52020 
Train Epoch: 32 [133/250 17024/32000 (53%)] Loss: 1.84388 (QuantReg: 17.67908) QuantErr: 17.67908 batch_time=0.50525 
Train Epoch: 32 [144/250 18432/32000 (58%)] Loss: 1.63624 (QuantReg: 18.03318) QuantErr: 18.03318 batch_time=1.00816 
Train Epoch: 32 [155/250 19840/32000 (62%)] Loss: 1.71263 (QuantReg: 17.90964) QuantErr: 17.90964 batch_time=0.49518 
Train Epoch: 32 [166/250 21248/32000 (66%)] Loss: 1.88730 (QuantReg: 17.82754) QuantErr: 17.82754 batch_time=0.50565 
Train Epoch: 32 [177/250 22656/32000 (71%)] Loss: 1.39511 (QuantReg: 18.01537) QuantErr: 18.01537 batch_time=0.55478 
Train Epoch: 32 [188/250 24064/32000 (75%)] Loss: 1.67259 (QuantReg: 17.92803) QuantErr: 17.92803 batch_time=0.49397 
Train Epoch: 32 [199/250 25472/32000 (80%)] Loss: 2.03563 (QuantReg: 17.98605) QuantErr: 17.98605 batch_time=0.51202 
Train Epoch: 32 [210/250 26880/32000 (84%)] Loss: 1.62820 (QuantReg: 18.01202) QuantErr: 18.01202 batch_time=0.49974 
Train Epoch: 32 [221/250 28288/32000 (88%)] Loss: 2.18017 (QuantReg: 17.89121) QuantErr: 17.89121 batch_time=0.49045 
Train Epoch: 32 [232/250 29696/32000 (93%)] Loss: 1.52463 (QuantReg: 17.68727) QuantErr: 17.68727 batch_time=0.50208 
Train Epoch: 32 [243/250 31104/32000 (97%)] Loss: 1.55544 (QuantReg: 17.83530) QuantErr: 17.83530 batch_time=0.48951 
Train Epoch: 32 codebook_update_time=1.79712
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_LSMDC_t0.03/checkpoint-epoch32.pth ...
Done in 4.189s
removing stale ckpt [epoch 31] [took 0.01s]
 epoch          : 32
 loss           : 1.7759801859855653
 quant_reg      : 17.83756664276123
 quant_err      : 17.83756664276123
 learning_rate  : 1.019534128728952e-05
 n_samples      : 1024000
 n_steps        : 8000
 LSMDC_full_test/t2v_metrics/R1: 13.5
 LSMDC_full_test/t2v_metrics/R5: 31.4
 LSMDC_full_test/t2v_metrics/R10: 41.7
 LSMDC_full_test/t2v_metrics/R50: 67.6
 LSMDC_full_test/t2v_metrics/MedR: 19.0
 LSMDC_full_test/t2v_metrics/MeanR: 72.238
 LSMDC_full_test/t2v_metrics/geometric_mean_R1-R5-R10: 26.04952591658862
 LSMDC_full_test/v2t_metrics/R1: 13.6
 LSMDC_full_test/v2t_metrics/R5: 31.2
 LSMDC_full_test/v2t_metrics/R10: 40.5
 LSMDC_full_test/v2t_metrics/R50: 67.7
 LSMDC_full_test/v2t_metrics/MedR: 20.0
 LSMDC_full_test/v2t_metrics/MeanR: 68.735
 LSMDC_full_test/v2t_metrics/geometric_mean_R1-R5-R10: 25.805731555177783
 mnt_best       : 26.158713600326845
 not_improved_count: 4
Train Epoch: 33 [1/250 128/32000 (0%)] Loss: 1.56647 (QuantReg: 17.86409) QuantErr: 17.86409 batch_time=20.44453 
Train Epoch: 33 [12/250 1536/32000 (5%)] Loss: 1.94499 (QuantReg: 17.85238) QuantErr: 17.85238 batch_time=0.48591 
Train Epoch: 33 [23/250 2944/32000 (9%)] Loss: 1.55747 (QuantReg: 18.01091) QuantErr: 18.01091 batch_time=0.50976 
Train Epoch: 33 [34/250 4352/32000 (14%)] Loss: 1.60333 (QuantReg: 17.94577) QuantErr: 17.94577 batch_time=0.54724 
Train Epoch: 33 [45/250 5760/32000 (18%)] Loss: 1.83485 (QuantReg: 17.83510) QuantErr: 17.83510 batch_time=0.50136 
Train Epoch: 33 [56/250 7168/32000 (22%)] Loss: 1.54425 (QuantReg: 17.95636) QuantErr: 17.95636 batch_time=0.54296 
Train Epoch: 33 [67/250 8576/32000 (27%)] Loss: 1.81978 (QuantReg: 17.75087) QuantErr: 17.75087 batch_time=1.40772 
Train Epoch: 33 [78/250 9984/32000 (31%)] Loss: 1.78372 (QuantReg: 18.03338) QuantErr: 18.03338 batch_time=0.50394 
Train Epoch: 33 [89/250 11392/32000 (36%)] Loss: 1.57805 (QuantReg: 17.99021) QuantErr: 17.99021 batch_time=0.50037 
Train Epoch: 33 [100/250 12800/32000 (40%)] Loss: 1.97843 (QuantReg: 17.93587) QuantErr: 17.93587 batch_time=0.50517 
Train Epoch: 33 [111/250 14208/32000 (44%)] Loss: 1.78884 (QuantReg: 17.67311) QuantErr: 17.67311 batch_time=0.53735 
Train Epoch: 33 [122/250 15616/32000 (49%)] Loss: 2.00686 (QuantReg: 17.97554) QuantErr: 17.97554 batch_time=0.51170 
Train Epoch: 33 [133/250 17024/32000 (53%)] Loss: 1.67296 (QuantReg: 17.83562) QuantErr: 17.83562 batch_time=0.49181 
Train Epoch: 33 [144/250 18432/32000 (58%)] Loss: 1.57421 (QuantReg: 17.84189) QuantErr: 17.84189 batch_time=0.75480 
Train Epoch: 33 [155/250 19840/32000 (62%)] Loss: 2.07037 (QuantReg: 17.96336) QuantErr: 17.96336 batch_time=0.52024 
Train Epoch: 33 [166/250 21248/32000 (66%)] Loss: 1.59266 (QuantReg: 17.96336) QuantErr: 17.96336 batch_time=0.50239 
Train Epoch: 33 [177/250 22656/32000 (71%)] Loss: 1.68777 (QuantReg: 18.01523) QuantErr: 18.01523 batch_time=0.52674 
Train Epoch: 33 [188/250 24064/32000 (75%)] Loss: 1.93114 (QuantReg: 17.89690) QuantErr: 17.89690 batch_time=0.49411 
Train Epoch: 33 [199/250 25472/32000 (80%)] Loss: 1.61215 (QuantReg: 17.89627) QuantErr: 17.89627 batch_time=0.49237 
Train Epoch: 33 [210/250 26880/32000 (84%)] Loss: 1.64274 (QuantReg: 18.05966) QuantErr: 18.05966 batch_time=5.59528 
Train Epoch: 33 [221/250 28288/32000 (88%)] Loss: 1.59495 (QuantReg: 17.92025) QuantErr: 17.92025 batch_time=0.50922 
Train Epoch: 33 [232/250 29696/32000 (93%)] Loss: 1.59167 (QuantReg: 17.74679) QuantErr: 17.74679 batch_time=0.49743 
Train Epoch: 33 [243/250 31104/32000 (97%)] Loss: 1.57275 (QuantReg: 17.97896) QuantErr: 17.97896 batch_time=0.52680 
Train Epoch: 33 codebook_update_time=1.74598
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_LSMDC_t0.03/checkpoint-epoch33.pth ...
Done in 5.973s
removing stale ckpt [epoch 32] [took 0.02s]
 epoch          : 33
 loss           : 1.7629140791893005
 quant_reg      : 17.884035995483398
 quant_err      : 17.884035995483398
 learning_rate  : 9.685574222925043e-06
 n_samples      : 1056000
 n_steps        : 8250
 LSMDC_full_test/t2v_metrics/R1: 13.2
 LSMDC_full_test/t2v_metrics/R5: 32.1
 LSMDC_full_test/t2v_metrics/R10: 41.7
 LSMDC_full_test/t2v_metrics/R50: 65.6
 LSMDC_full_test/t2v_metrics/MedR: 20.0
 LSMDC_full_test/t2v_metrics/MeanR: 74.791
 LSMDC_full_test/t2v_metrics/geometric_mean_R1-R5-R10: 26.045838271307684
 LSMDC_full_test/v2t_metrics/R1: 11.6
 LSMDC_full_test/v2t_metrics/R5: 31.2
 LSMDC_full_test/v2t_metrics/R10: 40.0
 LSMDC_full_test/v2t_metrics/R50: 65.4
 LSMDC_full_test/v2t_metrics/MedR: 20.0
 LSMDC_full_test/v2t_metrics/MeanR: 68.777
 LSMDC_full_test/v2t_metrics/geometric_mean_R1-R5-R10: 24.37198253245532
 mnt_best       : 26.158713600326845
 not_improved_count: 5
Train Epoch: 34 [1/250 128/32000 (0%)] Loss: 1.74836 (QuantReg: 17.90013) QuantErr: 17.90013 batch_time=19.22293 
Train Epoch: 34 [12/250 1536/32000 (5%)] Loss: 1.62968 (QuantReg: 17.94951) QuantErr: 17.94951 batch_time=0.50284 
Train Epoch: 34 [23/250 2944/32000 (9%)] Loss: 2.12626 (QuantReg: 17.69325) QuantErr: 17.69325 batch_time=1.06413 
Train Epoch: 34 [34/250 4352/32000 (14%)] Loss: 1.31957 (QuantReg: 18.15625) QuantErr: 18.15625 batch_time=0.51262 
Train Epoch: 34 [45/250 5760/32000 (18%)] Loss: 1.89394 (QuantReg: 17.85057) QuantErr: 17.85057 batch_time=0.57616 
Train Epoch: 34 [56/250 7168/32000 (22%)] Loss: 1.33095 (QuantReg: 17.92994) QuantErr: 17.92994 batch_time=0.49666 
Train Epoch: 34 [67/250 8576/32000 (27%)] Loss: 1.70418 (QuantReg: 18.01022) QuantErr: 18.01022 batch_time=0.48940 
Train Epoch: 34 [78/250 9984/32000 (31%)] Loss: 1.96294 (QuantReg: 18.10004) QuantErr: 18.10004 batch_time=0.50863 
Train Epoch: 34 [89/250 11392/32000 (36%)] Loss: 1.69378 (QuantReg: 17.97023) QuantErr: 17.97023 batch_time=0.51189 
Train Epoch: 34 [100/250 12800/32000 (40%)] Loss: 1.53794 (QuantReg: 17.88965) QuantErr: 17.88965 batch_time=0.50895 
Train Epoch: 34 [111/250 14208/32000 (44%)] Loss: 1.49854 (QuantReg: 18.02943) QuantErr: 18.02943 batch_time=0.49873 
Train Epoch: 34 [122/250 15616/32000 (49%)] Loss: 1.75401 (QuantReg: 17.91430) QuantErr: 17.91430 batch_time=0.49975 
Train Epoch: 34 [133/250 17024/32000 (53%)] Loss: 1.89312 (QuantReg: 17.98209) QuantErr: 17.98209 batch_time=0.59401 
Train Epoch: 34 [144/250 18432/32000 (58%)] Loss: 1.63731 (QuantReg: 17.77777) QuantErr: 17.77777 batch_time=1.54667 
Train Epoch: 34 [155/250 19840/32000 (62%)] Loss: 1.44216 (QuantReg: 17.92942) QuantErr: 17.92942 batch_time=0.54380 
Train Epoch: 34 [166/250 21248/32000 (66%)] Loss: 1.69679 (QuantReg: 17.85562) QuantErr: 17.85562 batch_time=0.50654 
Train Epoch: 34 [177/250 22656/32000 (71%)] Loss: 1.48707 (QuantReg: 17.92256) QuantErr: 17.92256 batch_time=0.59874 
Train Epoch: 34 [188/250 24064/32000 (75%)] Loss: 1.57042 (QuantReg: 18.11540) QuantErr: 18.11540 batch_time=0.53212 
Train Epoch: 34 [199/250 25472/32000 (80%)] Loss: 1.89919 (QuantReg: 17.93272) QuantErr: 17.93272 batch_time=1.78802 
Train Epoch: 34 [210/250 26880/32000 (84%)] Loss: 1.77529 (QuantReg: 17.85005) QuantErr: 17.85005 batch_time=0.49768 
Train Epoch: 34 [221/250 28288/32000 (88%)] Loss: 1.74320 (QuantReg: 18.07299) QuantErr: 18.07299 batch_time=0.50400 
Train Epoch: 34 [232/250 29696/32000 (93%)] Loss: 1.79364 (QuantReg: 18.11708) QuantErr: 18.11708 batch_time=0.52364 
Train Epoch: 34 [243/250 31104/32000 (97%)] Loss: 2.20062 (QuantReg: 17.89422) QuantErr: 17.89422 batch_time=0.52530 
Train Epoch: 34 codebook_update_time=1.78209
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_LSMDC_t0.03/checkpoint-epoch34.pth ...
Done in 4.003s
Updating 'best' checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_LSMDC_t0.03/checkpoint-epoch34.pth ...
Done in 9.340s
removing stale ckpt [epoch 33] [took 0.05s]
 epoch          : 34
 loss           : 1.7300667128562928
 quant_reg      : 17.95320677947998
 quant_err      : 17.95320677947998
 learning_rate  : 9.20129551177879e-06
 n_samples      : 1088000
 n_steps        : 8500
 LSMDC_full_test/t2v_metrics/R1: 13.2
 LSMDC_full_test/t2v_metrics/R5: 32.8
 LSMDC_full_test/t2v_metrics/R10: 42.0
 LSMDC_full_test/t2v_metrics/R50: 66.1
 LSMDC_full_test/t2v_metrics/MedR: 19.0
 LSMDC_full_test/t2v_metrics/MeanR: 72.143
 LSMDC_full_test/t2v_metrics/geometric_mean_R1-R5-R10: 26.29656496844182
 LSMDC_full_test/v2t_metrics/R1: 12.2
 LSMDC_full_test/v2t_metrics/R5: 31.9
 LSMDC_full_test/v2t_metrics/R10: 40.4
 LSMDC_full_test/v2t_metrics/R50: 67.6
 LSMDC_full_test/v2t_metrics/MedR: 20.0
 LSMDC_full_test/v2t_metrics/MeanR: 68.737
 LSMDC_full_test/v2t_metrics/geometric_mean_R1-R5-R10: 25.052089790767837
 mnt_best       : 26.29656496844182
 not_improved_count: 0
Train Epoch: 35 [1/250 128/32000 (0%)] Loss: 2.02116 (QuantReg: 17.73864) QuantErr: 17.73864 batch_time=17.42915 
Train Epoch: 35 [12/250 1536/32000 (5%)] Loss: 1.83503 (QuantReg: 17.91162) QuantErr: 17.91162 batch_time=1.02292 
Train Epoch: 35 [23/250 2944/32000 (9%)] Loss: 1.41412 (QuantReg: 18.00140) QuantErr: 18.00140 batch_time=0.54188 
Train Epoch: 35 [34/250 4352/32000 (14%)] Loss: 1.48858 (QuantReg: 18.03474) QuantErr: 18.03474 batch_time=0.50548 
Train Epoch: 35 [45/250 5760/32000 (18%)] Loss: 1.98230 (QuantReg: 18.04778) QuantErr: 18.04778 batch_time=0.55600 
Train Epoch: 35 [56/250 7168/32000 (22%)] Loss: 1.77067 (QuantReg: 18.07782) QuantErr: 18.07782 batch_time=0.48932 
Train Epoch: 35 [67/250 8576/32000 (27%)] Loss: 2.23445 (QuantReg: 17.89193) QuantErr: 17.89193 batch_time=0.51784 
Train Epoch: 35 [78/250 9984/32000 (31%)] Loss: 1.57879 (QuantReg: 18.23267) QuantErr: 18.23267 batch_time=0.49953 
Train Epoch: 35 [89/250 11392/32000 (36%)] Loss: 1.36804 (QuantReg: 17.98530) QuantErr: 17.98530 batch_time=0.51811 
Train Epoch: 35 [100/250 12800/32000 (40%)] Loss: 1.22744 (QuantReg: 17.97274) QuantErr: 17.97274 batch_time=0.53608 
Train Epoch: 35 [111/250 14208/32000 (44%)] Loss: 1.93248 (QuantReg: 18.02223) QuantErr: 18.02223 batch_time=0.54785 
Train Epoch: 35 [122/250 15616/32000 (49%)] Loss: 1.46499 (QuantReg: 18.01532) QuantErr: 18.01532 batch_time=0.54770 
Train Epoch: 35 [133/250 17024/32000 (53%)] Loss: 2.04076 (QuantReg: 17.93150) QuantErr: 17.93150 batch_time=0.53846 
Train Epoch: 35 [144/250 18432/32000 (58%)] Loss: 1.34787 (QuantReg: 18.09138) QuantErr: 18.09138 batch_time=0.50915 
Train Epoch: 35 [155/250 19840/32000 (62%)] Loss: 1.66676 (QuantReg: 18.11096) QuantErr: 18.11096 batch_time=0.51242 
Train Epoch: 35 [166/250 21248/32000 (66%)] Loss: 1.44450 (QuantReg: 18.00814) QuantErr: 18.00814 batch_time=0.50647 
Train Epoch: 35 [177/250 22656/32000 (71%)] Loss: 1.56240 (QuantReg: 18.01973) QuantErr: 18.01973 batch_time=0.52689 
Train Epoch: 35 [188/250 24064/32000 (75%)] Loss: 1.78031 (QuantReg: 17.86513) QuantErr: 17.86513 batch_time=0.50911 
Train Epoch: 35 [199/250 25472/32000 (80%)] Loss: 1.61968 (QuantReg: 17.93597) QuantErr: 17.93597 batch_time=0.49752 
Train Epoch: 35 [210/250 26880/32000 (84%)] Loss: 1.72488 (QuantReg: 17.98055) QuantErr: 17.98055 batch_time=0.48631 
Train Epoch: 35 [221/250 28288/32000 (88%)] Loss: 1.48130 (QuantReg: 18.16528) QuantErr: 18.16528 batch_time=1.05056 
Train Epoch: 35 [232/250 29696/32000 (93%)] Loss: 1.85788 (QuantReg: 17.99536) QuantErr: 17.99536 batch_time=0.48807 
Train Epoch: 35 [243/250 31104/32000 (97%)] Loss: 1.65380 (QuantReg: 17.98517) QuantErr: 17.98517 batch_time=0.72868 
Train Epoch: 35 codebook_update_time=2.11933
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_LSMDC_t0.03/checkpoint-epoch35.pth ...
Done in 4.644s
removing stale ckpt [epoch 34] [took 0.01s]
 epoch          : 35
 loss           : 1.6921910972595215
 quant_reg      : 17.996383491516113
 quant_err      : 17.996383491516113
 learning_rate  : 8.74123073618985e-06
 n_samples      : 1120000
 n_steps        : 8750
 LSMDC_full_test/t2v_metrics/R1: 12.5
 LSMDC_full_test/t2v_metrics/R5: 32.9
 LSMDC_full_test/t2v_metrics/R10: 42.1
 LSMDC_full_test/t2v_metrics/R50: 66.8
 LSMDC_full_test/t2v_metrics/MedR: 18.0
 LSMDC_full_test/t2v_metrics/MeanR: 71.811
 LSMDC_full_test/t2v_metrics/geometric_mean_R1-R5-R10: 25.869974597173833
 LSMDC_full_test/v2t_metrics/R1: 13.1
 LSMDC_full_test/v2t_metrics/R5: 31.8
 LSMDC_full_test/v2t_metrics/R10: 40.5
 LSMDC_full_test/v2t_metrics/R50: 67.6
 LSMDC_full_test/v2t_metrics/MedR: 19.0
 LSMDC_full_test/v2t_metrics/MeanR: 69.294
 LSMDC_full_test/v2t_metrics/geometric_mean_R1-R5-R10: 25.64786070185098
 mnt_best       : 26.29656496844182
 not_improved_count: 1
Train Epoch: 36 [1/250 128/32000 (0%)] Loss: 1.77932 (QuantReg: 18.09021) QuantErr: 18.09021 batch_time=16.89943 
Train Epoch: 36 [12/250 1536/32000 (5%)] Loss: 1.58836 (QuantReg: 18.12007) QuantErr: 18.12007 batch_time=0.50966 
Train Epoch: 36 [23/250 2944/32000 (9%)] Loss: 1.70911 (QuantReg: 18.05222) QuantErr: 18.05222 batch_time=1.51991 
Train Epoch: 36 [34/250 4352/32000 (14%)] Loss: 1.49857 (QuantReg: 17.90805) QuantErr: 17.90805 batch_time=0.49655 
Train Epoch: 36 [45/250 5760/32000 (18%)] Loss: 1.63003 (QuantReg: 17.95842) QuantErr: 17.95842 batch_time=0.50264 
Train Epoch: 36 [56/250 7168/32000 (22%)] Loss: 1.61278 (QuantReg: 18.06775) QuantErr: 18.06775 batch_time=0.50276 
Train Epoch: 36 [67/250 8576/32000 (27%)] Loss: 1.88966 (QuantReg: 17.84401) QuantErr: 17.84401 batch_time=1.21873 
Train Epoch: 36 [78/250 9984/32000 (31%)] Loss: 1.67675 (QuantReg: 17.97868) QuantErr: 17.97868 batch_time=0.50818 
Train Epoch: 36 [89/250 11392/32000 (36%)] Loss: 1.67183 (QuantReg: 18.09832) QuantErr: 18.09832 batch_time=0.53341 
Train Epoch: 36 [100/250 12800/32000 (40%)] Loss: 1.36463 (QuantReg: 18.21615) QuantErr: 18.21615 batch_time=0.53833 
Train Epoch: 36 [111/250 14208/32000 (44%)] Loss: 1.57986 (QuantReg: 17.91660) QuantErr: 17.91660 batch_time=0.52152 
Train Epoch: 36 [122/250 15616/32000 (49%)] Loss: 1.89576 (QuantReg: 18.11121) QuantErr: 18.11121 batch_time=0.50775 
Train Epoch: 36 [133/250 17024/32000 (53%)] Loss: 1.58788 (QuantReg: 18.13369) QuantErr: 18.13369 batch_time=0.57057 
Train Epoch: 36 [144/250 18432/32000 (58%)] Loss: 1.63816 (QuantReg: 17.93877) QuantErr: 17.93877 batch_time=2.90404 
Train Epoch: 36 [155/250 19840/32000 (62%)] Loss: 1.49576 (QuantReg: 18.18195) QuantErr: 18.18195 batch_time=0.49801 
Train Epoch: 36 [166/250 21248/32000 (66%)] Loss: 1.48453 (QuantReg: 18.23357) QuantErr: 18.23357 batch_time=0.48861 
Train Epoch: 36 [177/250 22656/32000 (71%)] Loss: 1.69407 (QuantReg: 18.07677) QuantErr: 18.07677 batch_time=0.53291 
Train Epoch: 36 [188/250 24064/32000 (75%)] Loss: 1.58435 (QuantReg: 17.85598) QuantErr: 17.85598 batch_time=0.50887 
Train Epoch: 36 [199/250 25472/32000 (80%)] Loss: 1.75015 (QuantReg: 18.18688) QuantErr: 18.18688 batch_time=0.49611 
Train Epoch: 36 [210/250 26880/32000 (84%)] Loss: 1.70109 (QuantReg: 18.11354) QuantErr: 18.11354 batch_time=0.49345 
Train Epoch: 36 [221/250 28288/32000 (88%)] Loss: 1.71437 (QuantReg: 17.99376) QuantErr: 17.99376 batch_time=0.53743 
Train Epoch: 36 [232/250 29696/32000 (93%)] Loss: 1.78467 (QuantReg: 18.24714) QuantErr: 18.24714 batch_time=0.56198 
Train Epoch: 36 [243/250 31104/32000 (97%)] Loss: 1.69340 (QuantReg: 17.98894) QuantErr: 17.98894 batch_time=0.51484 
Train Epoch: 36 codebook_update_time=1.80067
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_LSMDC_t0.03/checkpoint-epoch36.pth ...
Done in 5.338s
removing stale ckpt [epoch 35] [took 0.01s]
 epoch          : 36
 loss           : 1.6843275318145752
 quant_reg      : 18.05471466064453
 quant_err      : 18.05471466064453
 learning_rate  : 8.304169199380357e-06
 n_samples      : 1152000
 n_steps        : 9000
 LSMDC_full_test/t2v_metrics/R1: 13.5
 LSMDC_full_test/t2v_metrics/R5: 31.3
 LSMDC_full_test/t2v_metrics/R10: 42.3
 LSMDC_full_test/t2v_metrics/R50: 67.0
 LSMDC_full_test/t2v_metrics/MedR: 18.5
 LSMDC_full_test/t2v_metrics/MeanR: 74.113
 LSMDC_full_test/t2v_metrics/geometric_mean_R1-R5-R10: 26.146054241011512
 LSMDC_full_test/v2t_metrics/R1: 13.5
 LSMDC_full_test/v2t_metrics/R5: 32.0
 LSMDC_full_test/v2t_metrics/R10: 40.5
 LSMDC_full_test/v2t_metrics/R50: 66.9
 LSMDC_full_test/v2t_metrics/MedR: 20.0
 LSMDC_full_test/v2t_metrics/MeanR: 69.087
 LSMDC_full_test/v2t_metrics/geometric_mean_R1-R5-R10: 25.96049226553335
 mnt_best       : 26.29656496844182
 not_improved_count: 2
Train Epoch: 37 [1/250 128/32000 (0%)] Loss: 1.68311 (QuantReg: 18.01970) QuantErr: 18.01970 batch_time=16.49334 
Train Epoch: 37 [12/250 1536/32000 (5%)] Loss: 1.55807 (QuantReg: 18.09694) QuantErr: 18.09694 batch_time=0.58183 
Train Epoch: 37 [23/250 2944/32000 (9%)] Loss: 1.60528 (QuantReg: 18.08897) QuantErr: 18.08897 batch_time=0.49452 
Train Epoch: 37 [34/250 4352/32000 (14%)] Loss: 1.56387 (QuantReg: 18.15004) QuantErr: 18.15004 batch_time=0.51310 
Train Epoch: 37 [45/250 5760/32000 (18%)] Loss: 1.73559 (QuantReg: 18.14441) QuantErr: 18.14441 batch_time=0.51087 
Train Epoch: 37 [56/250 7168/32000 (22%)] Loss: 1.64797 (QuantReg: 18.12957) QuantErr: 18.12957 batch_time=0.50555 
Train Epoch: 37 [67/250 8576/32000 (27%)] Loss: 2.05031 (QuantReg: 18.03807) QuantErr: 18.03807 batch_time=0.52587 
Train Epoch: 37 [78/250 9984/32000 (31%)] Loss: 1.98753 (QuantReg: 18.01230) QuantErr: 18.01230 batch_time=0.49902 
Train Epoch: 37 [89/250 11392/32000 (36%)] Loss: 1.83138 (QuantReg: 18.16893) QuantErr: 18.16893 batch_time=0.60172 
Train Epoch: 37 [100/250 12800/32000 (40%)] Loss: 1.61676 (QuantReg: 18.07142) QuantErr: 18.07142 batch_time=0.50411 
Train Epoch: 37 [111/250 14208/32000 (44%)] Loss: 1.33544 (QuantReg: 18.04007) QuantErr: 18.04007 batch_time=0.51655 
Train Epoch: 37 [122/250 15616/32000 (49%)] Loss: 1.55483 (QuantReg: 18.09765) QuantErr: 18.09765 batch_time=0.51128 
Train Epoch: 37 [133/250 17024/32000 (53%)] Loss: 1.60700 (QuantReg: 18.12317) QuantErr: 18.12317 batch_time=0.51014 
Train Epoch: 37 [144/250 18432/32000 (58%)] Loss: 1.84454 (QuantReg: 18.07162) QuantErr: 18.07162 batch_time=1.19188 
Train Epoch: 37 [155/250 19840/32000 (62%)] Loss: 1.80795 (QuantReg: 18.15830) QuantErr: 18.15830 batch_time=1.11842 
Train Epoch: 37 [166/250 21248/32000 (66%)] Loss: 1.31999 (QuantReg: 18.24911) QuantErr: 18.24911 batch_time=0.51268 
Train Epoch: 37 [177/250 22656/32000 (71%)] Loss: 1.42155 (QuantReg: 17.99644) QuantErr: 17.99644 batch_time=0.52020 
Train Epoch: 37 [188/250 24064/32000 (75%)] Loss: 1.89058 (QuantReg: 18.02631) QuantErr: 18.02631 batch_time=0.50539 
Train Epoch: 37 [199/250 25472/32000 (80%)] Loss: 1.40418 (QuantReg: 18.18724) QuantErr: 18.18724 batch_time=0.61831 
Train Epoch: 37 [210/250 26880/32000 (84%)] Loss: 1.71279 (QuantReg: 17.93040) QuantErr: 17.93040 batch_time=0.50213 
Train Epoch: 37 [221/250 28288/32000 (88%)] Loss: 1.72143 (QuantReg: 18.22003) QuantErr: 18.22003 batch_time=0.51766 
Train Epoch: 37 [232/250 29696/32000 (93%)] Loss: 1.84013 (QuantReg: 18.18547) QuantErr: 18.18547 batch_time=0.57169 
Train Epoch: 37 [243/250 31104/32000 (97%)] Loss: 1.71142 (QuantReg: 18.33735) QuantErr: 18.33735 batch_time=0.50512 
Train Epoch: 37 codebook_update_time=1.88013
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_LSMDC_t0.03/checkpoint-epoch37.pth ...
Done in 5.374s
removing stale ckpt [epoch 36] [took 0.01s]
 epoch          : 37
 loss           : 1.6662343888282776
 quant_reg      : 18.117532737731935
 quant_err      : 18.117532737731935
 learning_rate  : 7.888960739411339e-06
 n_samples      : 1184000
 n_steps        : 9250
 LSMDC_full_test/t2v_metrics/R1: 13.6
 LSMDC_full_test/t2v_metrics/R5: 31.5
 LSMDC_full_test/t2v_metrics/R10: 42.4
 LSMDC_full_test/t2v_metrics/R50: 66.9
 LSMDC_full_test/t2v_metrics/MedR: 19.0
 LSMDC_full_test/t2v_metrics/MeanR: 73.756
 LSMDC_full_test/t2v_metrics/geometric_mean_R1-R5-R10: 26.28684350176352
 LSMDC_full_test/v2t_metrics/R1: 12.7
 LSMDC_full_test/v2t_metrics/R5: 30.6
 LSMDC_full_test/v2t_metrics/R10: 39.5
 LSMDC_full_test/v2t_metrics/R50: 66.3
 LSMDC_full_test/v2t_metrics/MedR: 21.0
 LSMDC_full_test/v2t_metrics/MeanR: 70.634
 LSMDC_full_test/v2t_metrics/geometric_mean_R1-R5-R10: 24.85272881816557
 mnt_best       : 26.29656496844182
 not_improved_count: 3
Train Epoch: 38 [1/250 128/32000 (0%)] Loss: 1.73179 (QuantReg: 18.05060) QuantErr: 18.05060 batch_time=20.53716 
Train Epoch: 38 [12/250 1536/32000 (5%)] Loss: 1.73333 (QuantReg: 18.09300) QuantErr: 18.09300 batch_time=0.55277 
Train Epoch: 38 [23/250 2944/32000 (9%)] Loss: 1.66641 (QuantReg: 18.05118) QuantErr: 18.05118 batch_time=0.50001 
Train Epoch: 38 [34/250 4352/32000 (14%)] Loss: 1.57508 (QuantReg: 18.21416) QuantErr: 18.21416 batch_time=0.50716 
Train Epoch: 38 [45/250 5760/32000 (18%)] Loss: 1.69491 (QuantReg: 17.95584) QuantErr: 17.95584 batch_time=1.02823 
Train Epoch: 38 [56/250 7168/32000 (22%)] Loss: 1.78708 (QuantReg: 18.03644) QuantErr: 18.03644 batch_time=0.54135 
Train Epoch: 38 [67/250 8576/32000 (27%)] Loss: 1.78499 (QuantReg: 18.04734) QuantErr: 18.04734 batch_time=0.55627 
Train Epoch: 38 [78/250 9984/32000 (31%)] Loss: 1.51925 (QuantReg: 18.09485) QuantErr: 18.09485 batch_time=0.50086 
Train Epoch: 38 [89/250 11392/32000 (36%)] Loss: 1.53375 (QuantReg: 18.16416) QuantErr: 18.16416 batch_time=0.51750 
Train Epoch: 38 [100/250 12800/32000 (40%)] Loss: 1.56855 (QuantReg: 18.08134) QuantErr: 18.08134 batch_time=0.53168 
Train Epoch: 38 [111/250 14208/32000 (44%)] Loss: 1.59575 (QuantReg: 18.15295) QuantErr: 18.15295 batch_time=0.50930 
Train Epoch: 38 [122/250 15616/32000 (49%)] Loss: 1.67135 (QuantReg: 18.17623) QuantErr: 18.17623 batch_time=0.50636 
Train Epoch: 38 [133/250 17024/32000 (53%)] Loss: 1.66489 (QuantReg: 18.04707) QuantErr: 18.04707 batch_time=0.51327 
Train Epoch: 38 [144/250 18432/32000 (58%)] Loss: 1.32984 (QuantReg: 18.24033) QuantErr: 18.24033 batch_time=1.49321 
Train Epoch: 38 [155/250 19840/32000 (62%)] Loss: 1.62490 (QuantReg: 18.23526) QuantErr: 18.23526 batch_time=0.56599 
Train Epoch: 38 [166/250 21248/32000 (66%)] Loss: 1.76799 (QuantReg: 18.13354) QuantErr: 18.13354 batch_time=0.49952 
Train Epoch: 38 [177/250 22656/32000 (71%)] Loss: 1.37013 (QuantReg: 18.16014) QuantErr: 18.16014 batch_time=0.49938 
Train Epoch: 38 [188/250 24064/32000 (75%)] Loss: 1.90503 (QuantReg: 18.11057) QuantErr: 18.11057 batch_time=0.49724 
Train Epoch: 38 [199/250 25472/32000 (80%)] Loss: 1.86112 (QuantReg: 17.90728) QuantErr: 17.90728 batch_time=0.49595 
Train Epoch: 38 [210/250 26880/32000 (84%)] Loss: 1.83189 (QuantReg: 18.31291) QuantErr: 18.31291 batch_time=0.50733 
Train Epoch: 38 [221/250 28288/32000 (88%)] Loss: 1.71407 (QuantReg: 18.25157) QuantErr: 18.25157 batch_time=0.50907 
Train Epoch: 38 [232/250 29696/32000 (93%)] Loss: 1.32890 (QuantReg: 18.28496) QuantErr: 18.28496 batch_time=0.50990 
Train Epoch: 38 [243/250 31104/32000 (97%)] Loss: 1.69784 (QuantReg: 18.09417) QuantErr: 18.09417 batch_time=0.50984 
Train Epoch: 38 codebook_update_time=2.31819
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_LSMDC_t0.03/checkpoint-epoch38.pth ...
Done in 4.464s
Updating 'best' checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_LSMDC_t0.03/checkpoint-epoch38.pth ...
Done in 9.153s
removing stale ckpt [epoch 37] [took 0.01s]
 epoch          : 38
 loss           : 1.6427573285102843
 quant_reg      : 18.124271713256835
 quant_err      : 18.124271713256835
 learning_rate  : 7.494512702440772e-06
 n_samples      : 1216000
 n_steps        : 9500
 LSMDC_full_test/t2v_metrics/R1: 14.5
 LSMDC_full_test/t2v_metrics/R5: 31.3
 LSMDC_full_test/t2v_metrics/R10: 41.8
 LSMDC_full_test/t2v_metrics/R50: 67.5
 LSMDC_full_test/t2v_metrics/MedR: 20.0
 LSMDC_full_test/t2v_metrics/MeanR: 73.676
 LSMDC_full_test/t2v_metrics/geometric_mean_R1-R5-R10: 26.670400692392814
 LSMDC_full_test/v2t_metrics/R1: 12.6
 LSMDC_full_test/v2t_metrics/R5: 31.8
 LSMDC_full_test/v2t_metrics/R10: 41.9
 LSMDC_full_test/v2t_metrics/R50: 65.9
 LSMDC_full_test/v2t_metrics/MedR: 18.0
 LSMDC_full_test/v2t_metrics/MeanR: 69.909
 LSMDC_full_test/v2t_metrics/geometric_mean_R1-R5-R10: 25.605733985766374
 mnt_best       : 26.670400692392814
 not_improved_count: 0
Train Epoch: 39 [1/250 128/32000 (0%)] Loss: 1.48936 (QuantReg: 18.31324) QuantErr: 18.31324 batch_time=16.77545 
Train Epoch: 39 [12/250 1536/32000 (5%)] Loss: 1.36726 (QuantReg: 18.35257) QuantErr: 18.35257 batch_time=0.49560 
Train Epoch: 39 [23/250 2944/32000 (9%)] Loss: 1.90724 (QuantReg: 18.13585) QuantErr: 18.13585 batch_time=0.53443 
Train Epoch: 39 [34/250 4352/32000 (14%)] Loss: 1.74016 (QuantReg: 18.01378) QuantErr: 18.01378 batch_time=0.51350 
Train Epoch: 39 [45/250 5760/32000 (18%)] Loss: 1.67544 (QuantReg: 18.13386) QuantErr: 18.13386 batch_time=0.50464 
Train Epoch: 39 [56/250 7168/32000 (22%)] Loss: 1.48122 (QuantReg: 18.34061) QuantErr: 18.34061 batch_time=0.58500 
Train Epoch: 39 [67/250 8576/32000 (27%)] Loss: 1.56811 (QuantReg: 18.06997) QuantErr: 18.06997 batch_time=0.51330 
Train Epoch: 39 [78/250 9984/32000 (31%)] Loss: 1.98833 (QuantReg: 18.18188) QuantErr: 18.18188 batch_time=0.50692 
Train Epoch: 39 [89/250 11392/32000 (36%)] Loss: 2.04292 (QuantReg: 18.14042) QuantErr: 18.14042 batch_time=0.49393 
Train Epoch: 39 [100/250 12800/32000 (40%)] Loss: 1.78227 (QuantReg: 18.22815) QuantErr: 18.22815 batch_time=0.50113 
Train Epoch: 39 [111/250 14208/32000 (44%)] Loss: 2.08500 (QuantReg: 18.19896) QuantErr: 18.19896 batch_time=0.52720 
Train Epoch: 39 [122/250 15616/32000 (49%)] Loss: 1.84302 (QuantReg: 18.31300) QuantErr: 18.31300 batch_time=0.51340 
Train Epoch: 39 [133/250 17024/32000 (53%)] Loss: 1.52673 (QuantReg: 18.06763) QuantErr: 18.06763 batch_time=0.50975 
Train Epoch: 39 [144/250 18432/32000 (58%)] Loss: 1.71655 (QuantReg: 18.32757) QuantErr: 18.32757 batch_time=4.14714 
Train Epoch: 39 [155/250 19840/32000 (62%)] Loss: 1.49635 (QuantReg: 18.43259) QuantErr: 18.43259 batch_time=0.51544 
Train Epoch: 39 [166/250 21248/32000 (66%)] Loss: 1.62264 (QuantReg: 18.18239) QuantErr: 18.18239 batch_time=0.52027 
Train Epoch: 39 [177/250 22656/32000 (71%)] Loss: 2.10726 (QuantReg: 18.18434) QuantErr: 18.18434 batch_time=0.52524 
Train Epoch: 39 [188/250 24064/32000 (75%)] Loss: 1.49418 (QuantReg: 18.30089) QuantErr: 18.30089 batch_time=0.50558 
Train Epoch: 39 [199/250 25472/32000 (80%)] Loss: 1.87415 (QuantReg: 18.14030) QuantErr: 18.14030 batch_time=0.51122 
Train Epoch: 39 [210/250 26880/32000 (84%)] Loss: 1.64583 (QuantReg: 17.95950) QuantErr: 17.95950 batch_time=0.50952 
Train Epoch: 39 [221/250 28288/32000 (88%)] Loss: 1.62287 (QuantReg: 18.24678) QuantErr: 18.24678 batch_time=0.68924 
Train Epoch: 39 [232/250 29696/32000 (93%)] Loss: 1.53399 (QuantReg: 17.99711) QuantErr: 17.99711 batch_time=0.50278 
Train Epoch: 39 [243/250 31104/32000 (97%)] Loss: 1.49179 (QuantReg: 18.29635) QuantErr: 18.29635 batch_time=0.52194 
Train Epoch: 39 codebook_update_time=1.82283
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_LSMDC_t0.03/checkpoint-epoch39.pth ...
Done in 4.761s
removing stale ckpt [epoch 38] [took 0.16s]
 epoch          : 39
 loss           : 1.6396579637527466
 quant_reg      : 18.185243225097658
 quant_err      : 18.185243225097658
 learning_rate  : 7.119787067318733e-06
 n_samples      : 1248000
 n_steps        : 9750
 LSMDC_full_test/t2v_metrics/R1: 13.4
 LSMDC_full_test/t2v_metrics/R5: 31.6
 LSMDC_full_test/t2v_metrics/R10: 41.7
 LSMDC_full_test/t2v_metrics/R50: 66.1
 LSMDC_full_test/t2v_metrics/MedR: 20.0
 LSMDC_full_test/t2v_metrics/MeanR: 74.3
 LSMDC_full_test/t2v_metrics/geometric_mean_R1-R5-R10: 26.040099857805217
 LSMDC_full_test/v2t_metrics/R1: 12.9
 LSMDC_full_test/v2t_metrics/R5: 30.7
 LSMDC_full_test/v2t_metrics/R10: 40.6
 LSMDC_full_test/v2t_metrics/R50: 65.9
 LSMDC_full_test/v2t_metrics/MedR: 19.75
 LSMDC_full_test/v2t_metrics/MeanR: 69.46
 LSMDC_full_test/v2t_metrics/geometric_mean_R1-R5-R10: 25.239730097918947
 mnt_best       : 26.670400692392814
 not_improved_count: 1
Train Epoch: 40 [1/250 128/32000 (0%)] Loss: 1.73581 (QuantReg: 18.07474) QuantErr: 18.07474 batch_time=16.73255 
Train Epoch: 40 [12/250 1536/32000 (5%)] Loss: 1.51510 (QuantReg: 18.22423) QuantErr: 18.22423 batch_time=0.49410 
Train Epoch: 40 [23/250 2944/32000 (9%)] Loss: 1.60166 (QuantReg: 18.10443) QuantErr: 18.10443 batch_time=0.58636 
Train Epoch: 40 [34/250 4352/32000 (14%)] Loss: 1.54802 (QuantReg: 18.33093) QuantErr: 18.33093 batch_time=0.51003 
Train Epoch: 40 [45/250 5760/32000 (18%)] Loss: 1.31124 (QuantReg: 18.27636) QuantErr: 18.27636 batch_time=0.51991 
Train Epoch: 40 [56/250 7168/32000 (22%)] Loss: 1.84631 (QuantReg: 18.27895) QuantErr: 18.27895 batch_time=0.57334 
Train Epoch: 40 [67/250 8576/32000 (27%)] Loss: 2.09558 (QuantReg: 17.99444) QuantErr: 17.99444 batch_time=0.71642 
Train Epoch: 40 [78/250 9984/32000 (31%)] Loss: 1.90850 (QuantReg: 18.37504) QuantErr: 18.37504 batch_time=0.48996 
Train Epoch: 40 [89/250 11392/32000 (36%)] Loss: 1.31177 (QuantReg: 18.15645) QuantErr: 18.15645 batch_time=0.48617 
Train Epoch: 40 [100/250 12800/32000 (40%)] Loss: 1.79584 (QuantReg: 18.03862) QuantErr: 18.03862 batch_time=0.50964 
Train Epoch: 40 [111/250 14208/32000 (44%)] Loss: 1.64696 (QuantReg: 18.20053) QuantErr: 18.20053 batch_time=1.09458 
Train Epoch: 40 [122/250 15616/32000 (49%)] Loss: 1.63002 (QuantReg: 18.40848) QuantErr: 18.40848 batch_time=0.48090 
Train Epoch: 40 [133/250 17024/32000 (53%)] Loss: 1.72566 (QuantReg: 18.00563) QuantErr: 18.00563 batch_time=0.97661 
Train Epoch: 40 [144/250 18432/32000 (58%)] Loss: 1.37953 (QuantReg: 18.29104) QuantErr: 18.29104 batch_time=0.49679 
Train Epoch: 40 [155/250 19840/32000 (62%)] Loss: 1.60725 (QuantReg: 18.29109) QuantErr: 18.29109 batch_time=0.50907 
Train Epoch: 40 [166/250 21248/32000 (66%)] Loss: 1.47883 (QuantReg: 18.18353) QuantErr: 18.18353 batch_time=0.63530 
Train Epoch: 40 [177/250 22656/32000 (71%)] Loss: 1.62855 (QuantReg: 18.19724) QuantErr: 18.19724 batch_time=0.49782 
Train Epoch: 40 [188/250 24064/32000 (75%)] Loss: 1.99787 (QuantReg: 18.26162) QuantErr: 18.26162 batch_time=0.51678 
Train Epoch: 40 [199/250 25472/32000 (80%)] Loss: 1.41971 (QuantReg: 18.28320) QuantErr: 18.28320 batch_time=1.24235 
Train Epoch: 40 [210/250 26880/32000 (84%)] Loss: 1.56782 (QuantReg: 18.21757) QuantErr: 18.21757 batch_time=0.50610 
Train Epoch: 40 [221/250 28288/32000 (88%)] Loss: 1.30338 (QuantReg: 18.26073) QuantErr: 18.26073 batch_time=0.51870 
Train Epoch: 40 [232/250 29696/32000 (93%)] Loss: 1.44358 (QuantReg: 18.36280) QuantErr: 18.36280 batch_time=0.51791 
Train Epoch: 40 [243/250 31104/32000 (97%)] Loss: 1.54518 (QuantReg: 18.19010) QuantErr: 18.19010 batch_time=0.55324 
Train Epoch: 40 codebook_update_time=1.87158
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_LSMDC_t0.03/checkpoint-epoch40.pth ...
Done in 4.643s
removing stale ckpt [epoch 39] [took 0.00s]
 epoch          : 40
 loss           : 1.6324517092704773
 quant_reg      : 18.215613342285156
 quant_err      : 18.215613342285156
 learning_rate  : 6.763797713952796e-06
 n_samples      : 1280000
 n_steps        : 10000
 LSMDC_full_test/t2v_metrics/R1: 13.6
 LSMDC_full_test/t2v_metrics/R5: 32.0
 LSMDC_full_test/t2v_metrics/R10: 41.2
 LSMDC_full_test/t2v_metrics/R50: 66.4
 LSMDC_full_test/t2v_metrics/MedR: 19.0
 LSMDC_full_test/t2v_metrics/MeanR: 74.761
 LSMDC_full_test/t2v_metrics/geometric_mean_R1-R5-R10: 26.17351401438136
 LSMDC_full_test/v2t_metrics/R1: 12.7
 LSMDC_full_test/v2t_metrics/R5: 31.4
 LSMDC_full_test/v2t_metrics/R10: 39.8
 LSMDC_full_test/v2t_metrics/R50: 66.5
 LSMDC_full_test/v2t_metrics/MedR: 19.0
 LSMDC_full_test/v2t_metrics/MeanR: 70.349
 LSMDC_full_test/v2t_metrics/geometric_mean_R1-R5-R10: 25.13075176683984
 mnt_best       : 26.670400692392814
 not_improved_count: 2
Train Epoch: 41 [1/250 128/32000 (0%)] Loss: 1.43148 (QuantReg: 18.20115) QuantErr: 18.20115 batch_time=22.70859 
Train Epoch: 41 [12/250 1536/32000 (5%)] Loss: 1.68503 (QuantReg: 18.33732) QuantErr: 18.33732 batch_time=0.54208 
Train Epoch: 41 [23/250 2944/32000 (9%)] Loss: 1.60265 (QuantReg: 18.09286) QuantErr: 18.09286 batch_time=0.52758 
Train Epoch: 41 [34/250 4352/32000 (14%)] Loss: 1.91474 (QuantReg: 18.21757) QuantErr: 18.21757 batch_time=0.51406 
Train Epoch: 41 [45/250 5760/32000 (18%)] Loss: 1.51115 (QuantReg: 18.17803) QuantErr: 18.17803 batch_time=0.72163 
Train Epoch: 41 [56/250 7168/32000 (22%)] Loss: 1.53923 (QuantReg: 18.30376) QuantErr: 18.30376 batch_time=0.56068 
Train Epoch: 41 [67/250 8576/32000 (27%)] Loss: 1.60911 (QuantReg: 18.29312) QuantErr: 18.29312 batch_time=1.07107 
Train Epoch: 41 [78/250 9984/32000 (31%)] Loss: 1.37847 (QuantReg: 18.32146) QuantErr: 18.32146 batch_time=0.51226 
Train Epoch: 41 [89/250 11392/32000 (36%)] Loss: 1.39487 (QuantReg: 18.33882) QuantErr: 18.33882 batch_time=0.50337 
Train Epoch: 41 [100/250 12800/32000 (40%)] Loss: 1.71804 (QuantReg: 18.14078) QuantErr: 18.14078 batch_time=0.55906 
Train Epoch: 41 [111/250 14208/32000 (44%)] Loss: 1.70818 (QuantReg: 18.30440) QuantErr: 18.30440 batch_time=0.55166 
Train Epoch: 41 [122/250 15616/32000 (49%)] Loss: 1.44488 (QuantReg: 18.46552) QuantErr: 18.46552 batch_time=0.50540 
Train Epoch: 41 [133/250 17024/32000 (53%)] Loss: 1.60387 (QuantReg: 18.27979) QuantErr: 18.27979 batch_time=0.50210 
Train Epoch: 41 [144/250 18432/32000 (58%)] Loss: 2.11262 (QuantReg: 18.31507) QuantErr: 18.31507 batch_time=2.43473 
Train Epoch: 41 [155/250 19840/32000 (62%)] Loss: 1.27895 (QuantReg: 18.20396) QuantErr: 18.20396 batch_time=0.51059 
Train Epoch: 41 [166/250 21248/32000 (66%)] Loss: 1.84143 (QuantReg: 18.28373) QuantErr: 18.28373 batch_time=0.88283 
Train Epoch: 41 [177/250 22656/32000 (71%)] Loss: 1.71569 (QuantReg: 18.17616) QuantErr: 18.17616 batch_time=0.50814 
Train Epoch: 41 [188/250 24064/32000 (75%)] Loss: 1.95720 (QuantReg: 18.14402) QuantErr: 18.14402 batch_time=0.50673 
Train Epoch: 41 [199/250 25472/32000 (80%)] Loss: 1.54051 (QuantReg: 18.20663) QuantErr: 18.20663 batch_time=0.52630 
Train Epoch: 41 [210/250 26880/32000 (84%)] Loss: 1.38861 (QuantReg: 18.25662) QuantErr: 18.25662 batch_time=0.57843 
Train Epoch: 41 [221/250 28288/32000 (88%)] Loss: 1.99763 (QuantReg: 18.38932) QuantErr: 18.38932 batch_time=0.71609 
Train Epoch: 41 [232/250 29696/32000 (93%)] Loss: 1.72769 (QuantReg: 18.20786) QuantErr: 18.20786 batch_time=0.50677 
Train Epoch: 41 [243/250 31104/32000 (97%)] Loss: 1.69186 (QuantReg: 18.19418) QuantErr: 18.19418 batch_time=0.50036 
Train Epoch: 41 codebook_update_time=2.02269
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_LSMDC_t0.03/checkpoint-epoch41.pth ...
Done in 4.489s
removing stale ckpt [epoch 40] [took 0.03s]
 epoch          : 41
 loss           : 1.6307026505470277
 quant_reg      : 18.2545927734375
 quant_err      : 18.2545927734375
 learning_rate  : 6.425607828255156e-06
 n_samples      : 1312000
 n_steps        : 10250
 LSMDC_full_test/t2v_metrics/R1: 12.5
 LSMDC_full_test/t2v_metrics/R5: 32.5
 LSMDC_full_test/t2v_metrics/R10: 41.9
 LSMDC_full_test/t2v_metrics/R50: 65.0
 LSMDC_full_test/t2v_metrics/MedR: 17.0
 LSMDC_full_test/t2v_metrics/MeanR: 75.039
 LSMDC_full_test/t2v_metrics/geometric_mean_R1-R5-R10: 25.72383996081143
 LSMDC_full_test/v2t_metrics/R1: 12.7
 LSMDC_full_test/v2t_metrics/R5: 31.9
 LSMDC_full_test/v2t_metrics/R10: 40.2
 LSMDC_full_test/v2t_metrics/R50: 66.6
 LSMDC_full_test/v2t_metrics/MedR: 19.0
 LSMDC_full_test/v2t_metrics/MeanR: 70.897
 LSMDC_full_test/v2t_metrics/geometric_mean_R1-R5-R10: 25.347793030170816
 mnt_best       : 26.670400692392814
 not_improved_count: 3
Train Epoch: 42 [1/250 128/32000 (0%)] Loss: 1.67363 (QuantReg: 18.32024) QuantErr: 18.32024 batch_time=21.82132 
Train Epoch: 42 [12/250 1536/32000 (5%)] Loss: 1.48708 (QuantReg: 18.29453) QuantErr: 18.29453 batch_time=0.49586 
Train Epoch: 42 [23/250 2944/32000 (9%)] Loss: 1.74465 (QuantReg: 18.23310) QuantErr: 18.23310 batch_time=0.50828 
Train Epoch: 42 [34/250 4352/32000 (14%)] Loss: 1.30036 (QuantReg: 18.25536) QuantErr: 18.25536 batch_time=0.54210 
Train Epoch: 42 [45/250 5760/32000 (18%)] Loss: 1.56411 (QuantReg: 18.27792) QuantErr: 18.27792 batch_time=0.50248 
Train Epoch: 42 [56/250 7168/32000 (22%)] Loss: 1.40059 (QuantReg: 18.32801) QuantErr: 18.32801 batch_time=0.49718 
Train Epoch: 42 [67/250 8576/32000 (27%)] Loss: 1.85663 (QuantReg: 18.24195) QuantErr: 18.24195 batch_time=4.20753 
Train Epoch: 42 [78/250 9984/32000 (31%)] Loss: 1.56203 (QuantReg: 18.29554) QuantErr: 18.29554 batch_time=0.51060 
Train Epoch: 42 [89/250 11392/32000 (36%)] Loss: 1.48785 (QuantReg: 18.52923) QuantErr: 18.52923 batch_time=0.51181 
Train Epoch: 42 [100/250 12800/32000 (40%)] Loss: 1.38660 (QuantReg: 18.23676) QuantErr: 18.23676 batch_time=0.50210 
Train Epoch: 42 [111/250 14208/32000 (44%)] Loss: 1.72106 (QuantReg: 18.41665) QuantErr: 18.41665 batch_time=0.57452 
Train Epoch: 42 [122/250 15616/32000 (49%)] Loss: 1.79250 (QuantReg: 18.21450) QuantErr: 18.21450 batch_time=0.49647 
Train Epoch: 42 [133/250 17024/32000 (53%)] Loss: 1.40412 (QuantReg: 18.37952) QuantErr: 18.37952 batch_time=0.49592 
Train Epoch: 42 [144/250 18432/32000 (58%)] Loss: 1.67195 (QuantReg: 18.03005) QuantErr: 18.03005 batch_time=0.49672 
Train Epoch: 42 [155/250 19840/32000 (62%)] Loss: 1.48463 (QuantReg: 18.47287) QuantErr: 18.47287 batch_time=0.50565 
Train Epoch: 42 [166/250 21248/32000 (66%)] Loss: 1.76742 (QuantReg: 18.26081) QuantErr: 18.26081 batch_time=0.51986 
Train Epoch: 42 [177/250 22656/32000 (71%)] Loss: 1.50813 (QuantReg: 18.04587) QuantErr: 18.04587 batch_time=0.50506 
Train Epoch: 42 [188/250 24064/32000 (75%)] Loss: 1.86417 (QuantReg: 18.13114) QuantErr: 18.13114 batch_time=0.52188 
Train Epoch: 42 [199/250 25472/32000 (80%)] Loss: 1.49134 (QuantReg: 18.41868) QuantErr: 18.41868 batch_time=0.59034 
Train Epoch: 42 [210/250 26880/32000 (84%)] Loss: 1.59060 (QuantReg: 18.20092) QuantErr: 18.20092 batch_time=0.49838 
Train Epoch: 42 [221/250 28288/32000 (88%)] Loss: 1.58282 (QuantReg: 18.26573) QuantErr: 18.26573 batch_time=0.51052 
Train Epoch: 42 [232/250 29696/32000 (93%)] Loss: 1.49207 (QuantReg: 18.50689) QuantErr: 18.50689 batch_time=0.49251 
Train Epoch: 42 [243/250 31104/32000 (97%)] Loss: 1.82922 (QuantReg: 18.37771) QuantErr: 18.37771 batch_time=0.59134 
Train Epoch: 42 codebook_update_time=1.76481
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_LSMDC_t0.03/checkpoint-epoch42.pth ...
Done in 4.021s
removing stale ckpt [epoch 41] [took 0.05s]
 epoch          : 42
 loss           : 1.6032276792526245
 quant_reg      : 18.287465156555175
 quant_err      : 18.287465156555175
 learning_rate  : 6.104327436842398e-06
 n_samples      : 1344000
 n_steps        : 10500
 LSMDC_full_test/t2v_metrics/R1: 12.9
 LSMDC_full_test/t2v_metrics/R5: 31.0
 LSMDC_full_test/t2v_metrics/R10: 40.9
 LSMDC_full_test/t2v_metrics/R50: 65.4
 LSMDC_full_test/t2v_metrics/MedR: 19.0
 LSMDC_full_test/t2v_metrics/MeanR: 76.874
 LSMDC_full_test/t2v_metrics/geometric_mean_R1-R5-R10: 25.383893523302568
 LSMDC_full_test/v2t_metrics/R1: 13.0
 LSMDC_full_test/v2t_metrics/R5: 29.9
 LSMDC_full_test/v2t_metrics/R10: 38.6
 LSMDC_full_test/v2t_metrics/R50: 66.6
 LSMDC_full_test/v2t_metrics/MedR: 19.0
 LSMDC_full_test/v2t_metrics/MeanR: 71.39
 LSMDC_full_test/v2t_metrics/geometric_mean_R1-R5-R10: 24.664214105639097
 mnt_best       : 26.670400692392814
 not_improved_count: 4
Train Epoch: 43 [1/250 128/32000 (0%)] Loss: 1.61120 (QuantReg: 18.24184) QuantErr: 18.24184 batch_time=28.25933 
Train Epoch: 43 [12/250 1536/32000 (5%)] Loss: 1.65468 (QuantReg: 18.29599) QuantErr: 18.29599 batch_time=0.49299 
Train Epoch: 43 [23/250 2944/32000 (9%)] Loss: 1.51115 (QuantReg: 18.09933) QuantErr: 18.09933 batch_time=0.54630 
Train Epoch: 43 [34/250 4352/32000 (14%)] Loss: 1.70266 (QuantReg: 18.33103) QuantErr: 18.33103 batch_time=0.52965 
Train Epoch: 43 [45/250 5760/32000 (18%)] Loss: 1.52936 (QuantReg: 18.28214) QuantErr: 18.28214 batch_time=0.51145 
Train Epoch: 43 [56/250 7168/32000 (22%)] Loss: 1.76329 (QuantReg: 18.36068) QuantErr: 18.36068 batch_time=0.51535 
Train Epoch: 43 [67/250 8576/32000 (27%)] Loss: 1.40248 (QuantReg: 18.41860) QuantErr: 18.41860 batch_time=0.56053 
Train Epoch: 43 [78/250 9984/32000 (31%)] Loss: 1.76347 (QuantReg: 18.31082) QuantErr: 18.31082 batch_time=0.54141 
Train Epoch: 43 [89/250 11392/32000 (36%)] Loss: 1.85957 (QuantReg: 18.19312) QuantErr: 18.19312 batch_time=0.49111 
Train Epoch: 43 [100/250 12800/32000 (40%)] Loss: 1.45346 (QuantReg: 18.48821) QuantErr: 18.48821 batch_time=0.53507 
Train Epoch: 43 [111/250 14208/32000 (44%)] Loss: 1.81966 (QuantReg: 18.25586) QuantErr: 18.25586 batch_time=0.55570 
Train Epoch: 43 [122/250 15616/32000 (49%)] Loss: 1.51230 (QuantReg: 18.28728) QuantErr: 18.28728 batch_time=0.50967 
Train Epoch: 43 [133/250 17024/32000 (53%)] Loss: 1.56858 (QuantReg: 18.24128) QuantErr: 18.24128 batch_time=0.50003 
Train Epoch: 43 [144/250 18432/32000 (58%)] Loss: 1.70316 (QuantReg: 18.33221) QuantErr: 18.33221 batch_time=0.49786 
Train Epoch: 43 [155/250 19840/32000 (62%)] Loss: 1.45336 (QuantReg: 18.40597) QuantErr: 18.40597 batch_time=0.53839 
Train Epoch: 43 [166/250 21248/32000 (66%)] Loss: 1.84131 (QuantReg: 18.30143) QuantErr: 18.30143 batch_time=1.04952 
Train Epoch: 43 [177/250 22656/32000 (71%)] Loss: 1.41483 (QuantReg: 18.26865) QuantErr: 18.26865 batch_time=0.52553 
Train Epoch: 43 [188/250 24064/32000 (75%)] Loss: 1.57127 (QuantReg: 18.27490) QuantErr: 18.27490 batch_time=0.48964 
Train Epoch: 43 [199/250 25472/32000 (80%)] Loss: 1.79290 (QuantReg: 18.31454) QuantErr: 18.31454 batch_time=0.48624 
Train Epoch: 43 [210/250 26880/32000 (84%)] Loss: 1.79744 (QuantReg: 18.23099) QuantErr: 18.23099 batch_time=0.48481 
Train Epoch: 43 [221/250 28288/32000 (88%)] Loss: 1.19164 (QuantReg: 18.35787) QuantErr: 18.35787 batch_time=0.53906 
Train Epoch: 43 [232/250 29696/32000 (93%)] Loss: 1.65279 (QuantReg: 18.45369) QuantErr: 18.45369 batch_time=0.55093 
Train Epoch: 43 [243/250 31104/32000 (97%)] Loss: 1.38120 (QuantReg: 18.23826) QuantErr: 18.23826 batch_time=0.50875 
Train Epoch: 43 codebook_update_time=2.09404
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_LSMDC_t0.03/checkpoint-epoch43.pth ...
Done in 6.037s
removing stale ckpt [epoch 42] [took 0.01s]
 epoch          : 43
 loss           : 1.6262387461662293
 quant_reg      : 18.31475862121582
 quant_err      : 18.31475862121582
 learning_rate  : 5.799111065000278e-06
 n_samples      : 1376000
 n_steps        : 10750
 LSMDC_full_test/t2v_metrics/R1: 14.5
 LSMDC_full_test/t2v_metrics/R5: 32.1
 LSMDC_full_test/t2v_metrics/R10: 40.5
 LSMDC_full_test/t2v_metrics/R50: 66.4
 LSMDC_full_test/t2v_metrics/MedR: 19.0
 LSMDC_full_test/t2v_metrics/MeanR: 76.613
 LSMDC_full_test/t2v_metrics/geometric_mean_R1-R5-R10: 26.613950979810284
 LSMDC_full_test/v2t_metrics/R1: 13.1
 LSMDC_full_test/v2t_metrics/R5: 31.7
 LSMDC_full_test/v2t_metrics/R10: 41.1
 LSMDC_full_test/v2t_metrics/R50: 66.1
 LSMDC_full_test/v2t_metrics/MedR: 19.0
 LSMDC_full_test/v2t_metrics/MeanR: 71.347
 LSMDC_full_test/v2t_metrics/geometric_mean_R1-R5-R10: 25.746851407523394
 mnt_best       : 26.670400692392814
 not_improved_count: 5
Train Epoch: 44 [1/250 128/32000 (0%)] Loss: 1.73154 (QuantReg: 18.27897) QuantErr: 18.27897 batch_time=21.26451 
Train Epoch: 44 [12/250 1536/32000 (5%)] Loss: 1.61092 (QuantReg: 18.19736) QuantErr: 18.19736 batch_time=0.50578 
Train Epoch: 44 [23/250 2944/32000 (9%)] Loss: 1.46834 (QuantReg: 18.39378) QuantErr: 18.39378 batch_time=0.54958 
Train Epoch: 44 [34/250 4352/32000 (14%)] Loss: 1.59804 (QuantReg: 18.27108) QuantErr: 18.27108 batch_time=0.49357 
Train Epoch: 44 [45/250 5760/32000 (18%)] Loss: 1.40536 (QuantReg: 18.33433) QuantErr: 18.33433 batch_time=0.53776 
Train Epoch: 44 [56/250 7168/32000 (22%)] Loss: 1.76575 (QuantReg: 18.28587) QuantErr: 18.28587 batch_time=0.52198 
Train Epoch: 44 [67/250 8576/32000 (27%)] Loss: 1.58274 (QuantReg: 18.15038) QuantErr: 18.15038 batch_time=0.49836 
Train Epoch: 44 [78/250 9984/32000 (31%)] Loss: 1.58325 (QuantReg: 18.26345) QuantErr: 18.26345 batch_time=0.48836 
Train Epoch: 44 [89/250 11392/32000 (36%)] Loss: 1.44101 (QuantReg: 18.29808) QuantErr: 18.29808 batch_time=0.49691 
Train Epoch: 44 [100/250 12800/32000 (40%)] Loss: 1.67563 (QuantReg: 18.34364) QuantErr: 18.34364 batch_time=0.49205 
Train Epoch: 44 [111/250 14208/32000 (44%)] Loss: 1.64062 (QuantReg: 18.35925) QuantErr: 18.35925 batch_time=0.50436 
Train Epoch: 44 [122/250 15616/32000 (49%)] Loss: 1.51707 (QuantReg: 18.38904) QuantErr: 18.38904 batch_time=0.95467 
Train Epoch: 44 [133/250 17024/32000 (53%)] Loss: 1.39095 (QuantReg: 18.40088) QuantErr: 18.40088 batch_time=4.22827 
Train Epoch: 44 [144/250 18432/32000 (58%)] Loss: 1.58424 (QuantReg: 18.50458) QuantErr: 18.50458 batch_time=0.49079 
Train Epoch: 44 [155/250 19840/32000 (62%)] Loss: 1.80704 (QuantReg: 18.33544) QuantErr: 18.33544 batch_time=0.58850 
Train Epoch: 44 [166/250 21248/32000 (66%)] Loss: 1.38261 (QuantReg: 18.35785) QuantErr: 18.35785 batch_time=0.52680 
Train Epoch: 44 [177/250 22656/32000 (71%)] Loss: 1.45619 (QuantReg: 18.39837) QuantErr: 18.39837 batch_time=0.54364 
Train Epoch: 44 [188/250 24064/32000 (75%)] Loss: 1.78607 (QuantReg: 18.27359) QuantErr: 18.27359 batch_time=0.49250 
Train Epoch: 44 [199/250 25472/32000 (80%)] Loss: 1.42075 (QuantReg: 18.38580) QuantErr: 18.38580 batch_time=1.23720 
Train Epoch: 44 [210/250 26880/32000 (84%)] Loss: 1.81950 (QuantReg: 18.29576) QuantErr: 18.29576 batch_time=0.55393 
Train Epoch: 44 [221/250 28288/32000 (88%)] Loss: 1.59899 (QuantReg: 18.29816) QuantErr: 18.29816 batch_time=0.49579 
Train Epoch: 44 [232/250 29696/32000 (93%)] Loss: 1.38367 (QuantReg: 18.17302) QuantErr: 18.17302 batch_time=0.50944 
Train Epoch: 44 [243/250 31104/32000 (97%)] Loss: 1.40119 (QuantReg: 18.37976) QuantErr: 18.37976 batch_time=0.49104 
Train Epoch: 44 codebook_update_time=1.82085
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_LSMDC_t0.03/checkpoint-epoch44.pth ...
Done in 23.123s
removing stale ckpt [epoch 43] [took 0.01s]
 epoch          : 44
 loss           : 1.6036948432922364
 quant_reg      : 18.331209770202637
 quant_err      : 18.331209770202637
 learning_rate  : 5.5091555117502635e-06
 n_samples      : 1408000
 n_steps        : 11000
 LSMDC_full_test/t2v_metrics/R1: 13.3
 LSMDC_full_test/t2v_metrics/R5: 31.7
 LSMDC_full_test/t2v_metrics/R10: 41.1
 LSMDC_full_test/t2v_metrics/R50: 65.7
 LSMDC_full_test/t2v_metrics/MedR: 19.0
 LSMDC_full_test/t2v_metrics/MeanR: 76.439
 LSMDC_full_test/t2v_metrics/geometric_mean_R1-R5-R10: 25.877217434646983
 LSMDC_full_test/v2t_metrics/R1: 13.5
 LSMDC_full_test/v2t_metrics/R5: 30.8
 LSMDC_full_test/v2t_metrics/R10: 40.9
 LSMDC_full_test/v2t_metrics/R50: 66.5
 LSMDC_full_test/v2t_metrics/MedR: 19.0
 LSMDC_full_test/v2t_metrics/MeanR: 71.279
 LSMDC_full_test/v2t_metrics/geometric_mean_R1-R5-R10: 25.715951479391403
 mnt_best       : 26.670400692392814
 not_improved_count: 6
Train Epoch: 45 [1/250 128/32000 (0%)] Loss: 1.50615 (QuantReg: 18.24132) QuantErr: 18.24132 batch_time=18.87708 
Train Epoch: 45 [12/250 1536/32000 (5%)] Loss: 1.57452 (QuantReg: 18.34512) QuantErr: 18.34512 batch_time=0.50572 
Train Epoch: 45 [23/250 2944/32000 (9%)] Loss: 1.74444 (QuantReg: 18.33811) QuantErr: 18.33811 batch_time=0.49841 
Train Epoch: 45 [34/250 4352/32000 (14%)] Loss: 1.60439 (QuantReg: 18.31130) QuantErr: 18.31130 batch_time=0.49922 
Train Epoch: 45 [45/250 5760/32000 (18%)] Loss: 1.43456 (QuantReg: 18.37256) QuantErr: 18.37256 batch_time=0.52009 
Train Epoch: 45 [56/250 7168/32000 (22%)] Loss: 1.53947 (QuantReg: 18.33287) QuantErr: 18.33287 batch_time=0.52913 
Train Epoch: 45 [67/250 8576/32000 (27%)] Loss: 1.65261 (QuantReg: 18.45418) QuantErr: 18.45418 batch_time=0.53886 
Train Epoch: 45 [78/250 9984/32000 (31%)] Loss: 1.51288 (QuantReg: 18.46258) QuantErr: 18.46258 batch_time=0.51236 
Train Epoch: 45 [89/250 11392/32000 (36%)] Loss: 1.47092 (QuantReg: 18.39615) QuantErr: 18.39615 batch_time=0.53705 
Train Epoch: 45 [100/250 12800/32000 (40%)] Loss: 1.68560 (QuantReg: 18.25594) QuantErr: 18.25594 batch_time=0.51570 
Train Epoch: 45 [111/250 14208/32000 (44%)] Loss: 1.63666 (QuantReg: 18.46050) QuantErr: 18.46050 batch_time=0.50482 
Train Epoch: 45 [122/250 15616/32000 (49%)] Loss: 2.12635 (QuantReg: 18.36955) QuantErr: 18.36955 batch_time=0.52069 
Train Epoch: 45 [133/250 17024/32000 (53%)] Loss: 1.65106 (QuantReg: 18.36020) QuantErr: 18.36020 batch_time=0.52701 
Train Epoch: 45 [144/250 18432/32000 (58%)] Loss: 1.39330 (QuantReg: 18.32852) QuantErr: 18.32852 batch_time=5.59927 
Train Epoch: 45 [155/250 19840/32000 (62%)] Loss: 1.49551 (QuantReg: 18.22010) QuantErr: 18.22010 batch_time=0.52657 
Train Epoch: 45 [166/250 21248/32000 (66%)] Loss: 1.46470 (QuantReg: 18.49060) QuantErr: 18.49060 batch_time=0.51445 
Train Epoch: 45 [177/250 22656/32000 (71%)] Loss: 1.83490 (QuantReg: 18.48502) QuantErr: 18.48502 batch_time=0.53232 
Train Epoch: 45 [188/250 24064/32000 (75%)] Loss: 1.59153 (QuantReg: 18.33746) QuantErr: 18.33746 batch_time=0.50844 
Train Epoch: 45 [199/250 25472/32000 (80%)] Loss: 1.72236 (QuantReg: 18.41160) QuantErr: 18.41160 batch_time=0.49726 
Train Epoch: 45 [210/250 26880/32000 (84%)] Loss: 1.74381 (QuantReg: 18.27994) QuantErr: 18.27994 batch_time=0.49672 
Train Epoch: 45 [221/250 28288/32000 (88%)] Loss: 1.28616 (QuantReg: 18.52427) QuantErr: 18.52427 batch_time=0.53521 
Train Epoch: 45 [232/250 29696/32000 (93%)] Loss: 1.76328 (QuantReg: 18.47959) QuantErr: 18.47959 batch_time=0.50315 
Train Epoch: 45 [243/250 31104/32000 (97%)] Loss: 1.61879 (QuantReg: 18.41486) QuantErr: 18.41486 batch_time=0.49418 
Train Epoch: 45 codebook_update_time=1.76496
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_LSMDC_t0.03/checkpoint-epoch45.pth ...
Done in 5.213s
removing stale ckpt [epoch 44] [took 0.00s]
 epoch          : 45
 loss           : 1.6051814713478088
 quant_reg      : 18.36680020904541
 quant_err      : 18.36680020904541
 learning_rate  : 5.23369773616275e-06
 n_samples      : 1440000
 n_steps        : 11250
 LSMDC_full_test/t2v_metrics/R1: 13.7
 LSMDC_full_test/t2v_metrics/R5: 31.8
 LSMDC_full_test/t2v_metrics/R10: 41.6
 LSMDC_full_test/t2v_metrics/R50: 66.8
 LSMDC_full_test/t2v_metrics/MedR: 17.0
 LSMDC_full_test/t2v_metrics/MeanR: 75.735
 LSMDC_full_test/t2v_metrics/geometric_mean_R1-R5-R10: 26.267193452577935
 LSMDC_full_test/v2t_metrics/R1: 13.0
 LSMDC_full_test/v2t_metrics/R5: 31.6
 LSMDC_full_test/v2t_metrics/R10: 42.5
 LSMDC_full_test/v2t_metrics/R50: 66.0
 LSMDC_full_test/v2t_metrics/MedR: 19.0
 LSMDC_full_test/v2t_metrics/MeanR: 72.773
 LSMDC_full_test/v2t_metrics/geometric_mean_R1-R5-R10: 25.942179201290692
 mnt_best       : 26.670400692392814
 not_improved_count: 7
Train Epoch: 46 [1/250 128/32000 (0%)] Loss: 1.55591 (QuantReg: 18.38907) QuantErr: 18.38907 batch_time=16.79838 
Train Epoch: 46 [12/250 1536/32000 (5%)] Loss: 1.63088 (QuantReg: 18.49379) QuantErr: 18.49379 batch_time=0.49739 
Train Epoch: 46 [23/250 2944/32000 (9%)] Loss: 1.65735 (QuantReg: 18.31596) QuantErr: 18.31596 batch_time=0.49716 
Train Epoch: 46 [34/250 4352/32000 (14%)] Loss: 1.43358 (QuantReg: 18.40397) QuantErr: 18.40397 batch_time=0.50696 
Train Epoch: 46 [45/250 5760/32000 (18%)] Loss: 1.57990 (QuantReg: 18.41117) QuantErr: 18.41117 batch_time=0.49758 
Train Epoch: 46 [56/250 7168/32000 (22%)] Loss: 1.35982 (QuantReg: 18.41957) QuantErr: 18.41957 batch_time=0.51469 
Train Epoch: 46 [67/250 8576/32000 (27%)] Loss: 1.50803 (QuantReg: 18.30950) QuantErr: 18.30950 batch_time=0.94440 
Train Epoch: 46 [78/250 9984/32000 (31%)] Loss: 1.86691 (QuantReg: 18.37092) QuantErr: 18.37092 batch_time=0.49999 
Train Epoch: 46 [89/250 11392/32000 (36%)] Loss: 2.05211 (QuantReg: 18.33001) QuantErr: 18.33001 batch_time=0.52229 
Train Epoch: 46 [100/250 12800/32000 (40%)] Loss: 1.54651 (QuantReg: 18.39142) QuantErr: 18.39142 batch_time=0.49350 
Train Epoch: 46 [111/250 14208/32000 (44%)] Loss: 1.54968 (QuantReg: 18.38261) QuantErr: 18.38261 batch_time=0.50723 
Train Epoch: 46 [122/250 15616/32000 (49%)] Loss: 1.41467 (QuantReg: 18.46121) QuantErr: 18.46121 batch_time=0.56309 
Train Epoch: 46 [133/250 17024/32000 (53%)] Loss: 1.63200 (QuantReg: 18.53825) QuantErr: 18.53825 batch_time=0.49129 
Train Epoch: 46 [144/250 18432/32000 (58%)] Loss: 1.43616 (QuantReg: 18.59820) QuantErr: 18.59820 batch_time=0.50797 
Train Epoch: 46 [155/250 19840/32000 (62%)] Loss: 1.82584 (QuantReg: 18.33883) QuantErr: 18.33883 batch_time=0.50309 
Train Epoch: 46 [166/250 21248/32000 (66%)] Loss: 1.97791 (QuantReg: 18.40756) QuantErr: 18.40756 batch_time=0.54135 
Train Epoch: 46 [177/250 22656/32000 (71%)] Loss: 1.48732 (QuantReg: 18.50618) QuantErr: 18.50618 batch_time=0.49945 
Train Epoch: 46 [188/250 24064/32000 (75%)] Loss: 1.62277 (QuantReg: 18.47740) QuantErr: 18.47740 batch_time=0.50093 
Train Epoch: 46 [199/250 25472/32000 (80%)] Loss: 1.68092 (QuantReg: 18.46809) QuantErr: 18.46809 batch_time=0.50960 
Train Epoch: 46 [210/250 26880/32000 (84%)] Loss: 1.65820 (QuantReg: 18.56127) QuantErr: 18.56127 batch_time=2.87294 
Train Epoch: 46 [221/250 28288/32000 (88%)] Loss: 1.96661 (QuantReg: 18.37712) QuantErr: 18.37712 batch_time=0.96153 
Train Epoch: 46 [232/250 29696/32000 (93%)] Loss: 1.36344 (QuantReg: 18.45927) QuantErr: 18.45927 batch_time=0.52324 
Train Epoch: 46 [243/250 31104/32000 (97%)] Loss: 1.44642 (QuantReg: 18.36777) QuantErr: 18.36777 batch_time=0.50824 
Train Epoch: 46 codebook_update_time=1.78162
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_LSMDC_t0.03/checkpoint-epoch46.pth ...
Done in 4.086s
removing stale ckpt [epoch 45] [took 0.03s]
 epoch          : 46
 loss           : 1.604581214427948
 quant_reg      : 18.3852266998291
 quant_err      : 18.3852266998291
 learning_rate  : 4.972012849354612e-06
 n_samples      : 1472000
 n_steps        : 11500
 LSMDC_full_test/t2v_metrics/R1: 14.0
 LSMDC_full_test/t2v_metrics/R5: 31.6
 LSMDC_full_test/t2v_metrics/R10: 41.5
 LSMDC_full_test/t2v_metrics/R50: 67.3
 LSMDC_full_test/t2v_metrics/MedR: 17.5
 LSMDC_full_test/t2v_metrics/MeanR: 75.884
 LSMDC_full_test/t2v_metrics/geometric_mean_R1-R5-R10: 26.3807864485655
 LSMDC_full_test/v2t_metrics/R1: 14.0
 LSMDC_full_test/v2t_metrics/R5: 30.8
 LSMDC_full_test/v2t_metrics/R10: 40.9
 LSMDC_full_test/v2t_metrics/R50: 66.9
 LSMDC_full_test/v2t_metrics/MedR: 19.0
 LSMDC_full_test/v2t_metrics/MeanR: 71.706
 LSMDC_full_test/v2t_metrics/geometric_mean_R1-R5-R10: 26.02959155453652
 mnt_best       : 26.670400692392814
 not_improved_count: 8
Train Epoch: 47 [1/250 128/32000 (0%)] Loss: 1.65552 (QuantReg: 18.47435) QuantErr: 18.47435 batch_time=17.40697 
Train Epoch: 47 [12/250 1536/32000 (5%)] Loss: 2.05219 (QuantReg: 18.30827) QuantErr: 18.30827 batch_time=0.49809 
Train Epoch: 47 [23/250 2944/32000 (9%)] Loss: 1.37269 (QuantReg: 18.37629) QuantErr: 18.37629 batch_time=1.28815 
Train Epoch: 47 [34/250 4352/32000 (14%)] Loss: 1.57046 (QuantReg: 18.53491) QuantErr: 18.53491 batch_time=0.50230 
Train Epoch: 47 [45/250 5760/32000 (18%)] Loss: 1.69384 (QuantReg: 18.41441) QuantErr: 18.41441 batch_time=0.50384 
Train Epoch: 47 [56/250 7168/32000 (22%)] Loss: 1.54392 (QuantReg: 18.44396) QuantErr: 18.44396 batch_time=0.54344 
Train Epoch: 47 [67/250 8576/32000 (27%)] Loss: 1.53902 (QuantReg: 18.33248) QuantErr: 18.33248 batch_time=2.94518 
Train Epoch: 47 [78/250 9984/32000 (31%)] Loss: 1.39207 (QuantReg: 18.30802) QuantErr: 18.30802 batch_time=0.49383 
Train Epoch: 47 [89/250 11392/32000 (36%)] Loss: 1.39633 (QuantReg: 18.42629) QuantErr: 18.42629 batch_time=0.55041 
Train Epoch: 47 [100/250 12800/32000 (40%)] Loss: 1.45521 (QuantReg: 18.46834) QuantErr: 18.46834 batch_time=0.51938 
Train Epoch: 47 [111/250 14208/32000 (44%)] Loss: 1.41459 (QuantReg: 18.54198) QuantErr: 18.54198 batch_time=0.56308 
Train Epoch: 47 [122/250 15616/32000 (49%)] Loss: 1.46042 (QuantReg: 18.42569) QuantErr: 18.42569 batch_time=0.50349 
Train Epoch: 47 [133/250 17024/32000 (53%)] Loss: 1.29952 (QuantReg: 18.38734) QuantErr: 18.38734 batch_time=0.50727 
Train Epoch: 47 [144/250 18432/32000 (58%)] Loss: 1.42772 (QuantReg: 18.36120) QuantErr: 18.36120 batch_time=0.51023 
Train Epoch: 47 [155/250 19840/32000 (62%)] Loss: 1.76263 (QuantReg: 18.55489) QuantErr: 18.55489 batch_time=0.53968 
Train Epoch: 47 [166/250 21248/32000 (66%)] Loss: 1.45815 (QuantReg: 18.44687) QuantErr: 18.44687 batch_time=0.49940 
Train Epoch: 47 [177/250 22656/32000 (71%)] Loss: 1.55633 (QuantReg: 18.37028) QuantErr: 18.37028 batch_time=0.49490 
Train Epoch: 47 [188/250 24064/32000 (75%)] Loss: 1.59528 (QuantReg: 18.60622) QuantErr: 18.60622 batch_time=0.53097 
Train Epoch: 47 [199/250 25472/32000 (80%)] Loss: 1.75731 (QuantReg: 18.40359) QuantErr: 18.40359 batch_time=0.49786 
Train Epoch: 47 [210/250 26880/32000 (84%)] Loss: 1.63622 (QuantReg: 18.38325) QuantErr: 18.38325 batch_time=0.49342 
Train Epoch: 47 [221/250 28288/32000 (88%)] Loss: 1.27002 (QuantReg: 18.61526) QuantErr: 18.61526 batch_time=0.49384 
Train Epoch: 47 [232/250 29696/32000 (93%)] Loss: 1.37822 (QuantReg: 18.48462) QuantErr: 18.48462 batch_time=1.68597 
Train Epoch: 47 [243/250 31104/32000 (97%)] Loss: 1.77406 (QuantReg: 18.42635) QuantErr: 18.42635 batch_time=0.50417 
Train Epoch: 47 codebook_update_time=1.67679
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_LSMDC_t0.03/checkpoint-epoch47.pth ...
Done in 4.607s
Updating 'best' checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_LSMDC_t0.03/checkpoint-epoch47.pth ...
Done in 9.030s
removing stale ckpt [epoch 46] [took 0.01s]
 epoch          : 47
 loss           : 1.5930373692512512
 quant_reg      : 18.402101600646972
 quant_err      : 18.402101600646972
 learning_rate  : 4.723412206886882e-06
 n_samples      : 1504000
 n_steps        : 11750
 LSMDC_full_test/t2v_metrics/R1: 14.9
 LSMDC_full_test/t2v_metrics/R5: 32.2
 LSMDC_full_test/t2v_metrics/R10: 42.1
 LSMDC_full_test/t2v_metrics/R50: 66.6
 LSMDC_full_test/t2v_metrics/MedR: 18.0
 LSMDC_full_test/t2v_metrics/MeanR: 76.061
 LSMDC_full_test/t2v_metrics/geometric_mean_R1-R5-R10: 27.233789646149496
 LSMDC_full_test/v2t_metrics/R1: 13.6
 LSMDC_full_test/v2t_metrics/R5: 31.3
 LSMDC_full_test/v2t_metrics/R10: 41.0
 LSMDC_full_test/v2t_metrics/R50: 66.0
 LSMDC_full_test/v2t_metrics/MedR: 19.0
 LSMDC_full_test/v2t_metrics/MeanR: 71.372
 LSMDC_full_test/v2t_metrics/geometric_mean_R1-R5-R10: 25.939147628436526
 mnt_best       : 27.233789646149496
 not_improved_count: 0
Train Epoch: 48 [1/250 128/32000 (0%)] Loss: 1.49172 (QuantReg: 18.43125) QuantErr: 18.43125 batch_time=17.31043 
Train Epoch: 48 [12/250 1536/32000 (5%)] Loss: 1.72927 (QuantReg: 18.44457) QuantErr: 18.44457 batch_time=0.49448 
Train Epoch: 48 [23/250 2944/32000 (9%)] Loss: 1.94367 (QuantReg: 18.43811) QuantErr: 18.43811 batch_time=0.50981 
Train Epoch: 48 [34/250 4352/32000 (14%)] Loss: 1.90137 (QuantReg: 18.38484) QuantErr: 18.38484 batch_time=0.53832 
Train Epoch: 48 [45/250 5760/32000 (18%)] Loss: 1.72607 (QuantReg: 18.32844) QuantErr: 18.32844 batch_time=0.55630 
Train Epoch: 48 [56/250 7168/32000 (22%)] Loss: 1.54817 (QuantReg: 18.56281) QuantErr: 18.56281 batch_time=0.51583 
Train Epoch: 48 [67/250 8576/32000 (27%)] Loss: 1.24228 (QuantReg: 18.49726) QuantErr: 18.49726 batch_time=0.82996 
Train Epoch: 48 [78/250 9984/32000 (31%)] Loss: 1.48202 (QuantReg: 18.55715) QuantErr: 18.55715 batch_time=0.48717 
Train Epoch: 48 [89/250 11392/32000 (36%)] Loss: 1.54627 (QuantReg: 18.41904) QuantErr: 18.41904 batch_time=0.50987 
Train Epoch: 48 [100/250 12800/32000 (40%)] Loss: 1.58513 (QuantReg: 18.48499) QuantErr: 18.48499 batch_time=0.83849 
Train Epoch: 48 [111/250 14208/32000 (44%)] Loss: 1.49305 (QuantReg: 18.35137) QuantErr: 18.35137 batch_time=0.52061 
Train Epoch: 48 [122/250 15616/32000 (49%)] Loss: 1.51666 (QuantReg: 18.37937) QuantErr: 18.37937 batch_time=0.50424 
Train Epoch: 48 [133/250 17024/32000 (53%)] Loss: 1.77503 (QuantReg: 18.47894) QuantErr: 18.47894 batch_time=0.50644 
Train Epoch: 48 [144/250 18432/32000 (58%)] Loss: 1.63193 (QuantReg: 18.49631) QuantErr: 18.49631 batch_time=0.74349 
Train Epoch: 48 [155/250 19840/32000 (62%)] Loss: 1.62157 (QuantReg: 18.42235) QuantErr: 18.42235 batch_time=0.56344 
Train Epoch: 48 [166/250 21248/32000 (66%)] Loss: 1.55687 (QuantReg: 18.39452) QuantErr: 18.39452 batch_time=0.50537 
Train Epoch: 48 [177/250 22656/32000 (71%)] Loss: 1.61690 (QuantReg: 18.42303) QuantErr: 18.42303 batch_time=0.50499 
Train Epoch: 48 [188/250 24064/32000 (75%)] Loss: 1.77766 (QuantReg: 18.37370) QuantErr: 18.37370 batch_time=0.52909 
Train Epoch: 48 [199/250 25472/32000 (80%)] Loss: 1.50685 (QuantReg: 18.35080) QuantErr: 18.35080 batch_time=0.51326 
Train Epoch: 48 [210/250 26880/32000 (84%)] Loss: 1.60456 (QuantReg: 18.40314) QuantErr: 18.40314 batch_time=2.37382 
Train Epoch: 48 [221/250 28288/32000 (88%)] Loss: 1.68405 (QuantReg: 18.45843) QuantErr: 18.45843 batch_time=0.54118 
Train Epoch: 48 [232/250 29696/32000 (93%)] Loss: 1.77350 (QuantReg: 18.31332) QuantErr: 18.31332 batch_time=0.51747 
Train Epoch: 48 [243/250 31104/32000 (97%)] Loss: 1.56391 (QuantReg: 18.56633) QuantErr: 18.56633 batch_time=0.50951 
Train Epoch: 48 codebook_update_time=1.80791
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_LSMDC_t0.03/checkpoint-epoch48.pth ...
Done in 9.781s
removing stale ckpt [epoch 47] [took 0.08s]
 epoch          : 48
 loss           : 1.5722670092582702
 quant_reg      : 18.441423583984374
 quant_err      : 18.441423583984374
 learning_rate  : 4.487241596542537e-06
 n_samples      : 1536000
 n_steps        : 12000
 LSMDC_full_test/t2v_metrics/R1: 13.9
 LSMDC_full_test/t2v_metrics/R5: 32.3
 LSMDC_full_test/t2v_metrics/R10: 42.7
 LSMDC_full_test/t2v_metrics/R50: 66.3
 LSMDC_full_test/t2v_metrics/MedR: 16.0
 LSMDC_full_test/t2v_metrics/MeanR: 75.802
 LSMDC_full_test/t2v_metrics/geometric_mean_R1-R5-R10: 26.76383841585429
 LSMDC_full_test/v2t_metrics/R1: 12.6
 LSMDC_full_test/v2t_metrics/R5: 31.5
 LSMDC_full_test/v2t_metrics/R10: 41.0
 LSMDC_full_test/v2t_metrics/R50: 65.6
 LSMDC_full_test/v2t_metrics/MedR: 19.0
 LSMDC_full_test/v2t_metrics/MeanR: 73.479
 LSMDC_full_test/v2t_metrics/geometric_mean_R1-R5-R10: 25.340877639189827
 mnt_best       : 27.233789646149496
 not_improved_count: 1
Train Epoch: 49 [1/250 128/32000 (0%)] Loss: 1.40792 (QuantReg: 18.43633) QuantErr: 18.43633 batch_time=21.25892 
Train Epoch: 49 [12/250 1536/32000 (5%)] Loss: 1.36096 (QuantReg: 18.42243) QuantErr: 18.42243 batch_time=0.51687 
Train Epoch: 49 [23/250 2944/32000 (9%)] Loss: 1.67583 (QuantReg: 18.50644) QuantErr: 18.50644 batch_time=0.49505 
Train Epoch: 49 [34/250 4352/32000 (14%)] Loss: 1.25446 (QuantReg: 18.44053) QuantErr: 18.44053 batch_time=0.50234 
Train Epoch: 49 [45/250 5760/32000 (18%)] Loss: 1.51692 (QuantReg: 18.33038) QuantErr: 18.33038 batch_time=0.51288 
Train Epoch: 49 [56/250 7168/32000 (22%)] Loss: 1.28356 (QuantReg: 18.38823) QuantErr: 18.38823 batch_time=0.55474 
Train Epoch: 49 [67/250 8576/32000 (27%)] Loss: 1.49660 (QuantReg: 18.66849) QuantErr: 18.66849 batch_time=0.52810 
Train Epoch: 49 [78/250 9984/32000 (31%)] Loss: 1.61836 (QuantReg: 18.39622) QuantErr: 18.39622 batch_time=0.52027 
Train Epoch: 49 [89/250 11392/32000 (36%)] Loss: 1.44509 (QuantReg: 18.60785) QuantErr: 18.60785 batch_time=0.80627 
Train Epoch: 49 [100/250 12800/32000 (40%)] Loss: 1.58518 (QuantReg: 18.46806) QuantErr: 18.46806 batch_time=0.49776 
Train Epoch: 49 [111/250 14208/32000 (44%)] Loss: 1.47550 (QuantReg: 18.62028) QuantErr: 18.62028 batch_time=0.53216 
Train Epoch: 49 [122/250 15616/32000 (49%)] Loss: 1.59288 (QuantReg: 18.54410) QuantErr: 18.54410 batch_time=0.50955 
Train Epoch: 49 [133/250 17024/32000 (53%)] Loss: 1.72858 (QuantReg: 18.49018) QuantErr: 18.49018 batch_time=0.54355 
Train Epoch: 49 [144/250 18432/32000 (58%)] Loss: 1.48501 (QuantReg: 18.56563) QuantErr: 18.56563 batch_time=0.50499 
Train Epoch: 49 [155/250 19840/32000 (62%)] Loss: 1.56604 (QuantReg: 18.46991) QuantErr: 18.46991 batch_time=0.51170 
Train Epoch: 49 [166/250 21248/32000 (66%)] Loss: 1.49499 (QuantReg: 18.68649) QuantErr: 18.68649 batch_time=0.63503 
Train Epoch: 49 [177/250 22656/32000 (71%)] Loss: 1.72423 (QuantReg: 18.49260) QuantErr: 18.49260 batch_time=0.50371 
Train Epoch: 49 [188/250 24064/32000 (75%)] Loss: 1.96054 (QuantReg: 18.49550) QuantErr: 18.49550 batch_time=0.51998 
Train Epoch: 49 [199/250 25472/32000 (80%)] Loss: 1.37922 (QuantReg: 18.58018) QuantErr: 18.58018 batch_time=4.32373 
Train Epoch: 49 [210/250 26880/32000 (84%)] Loss: 1.68538 (QuantReg: 18.46072) QuantErr: 18.46072 batch_time=0.56548 
Train Epoch: 49 [221/250 28288/32000 (88%)] Loss: 1.71387 (QuantReg: 18.39369) QuantErr: 18.39369 batch_time=0.49179 
Train Epoch: 49 [232/250 29696/32000 (93%)] Loss: 1.60065 (QuantReg: 18.46768) QuantErr: 18.46768 batch_time=0.49323 
Train Epoch: 49 [243/250 31104/32000 (97%)] Loss: 1.21156 (QuantReg: 18.56798) QuantErr: 18.56798 batch_time=0.50148 
Train Epoch: 49 codebook_update_time=1.83978
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_LSMDC_t0.03/checkpoint-epoch49.pth ...
Done in 4.841s
removing stale ckpt [epoch 48] [took 0.00s]
 epoch          : 49
 loss           : 1.5842753639221192
 quant_reg      : 18.45496095275879
 quant_err      : 18.45496095275879
 learning_rate  : 4.26287951671541e-06
 n_samples      : 1568000
 n_steps        : 12250
 LSMDC_full_test/t2v_metrics/R1: 13.8
 LSMDC_full_test/t2v_metrics/R5: 32.2
 LSMDC_full_test/t2v_metrics/R10: 41.9
 LSMDC_full_test/t2v_metrics/R50: 67.0
 LSMDC_full_test/t2v_metrics/MedR: 18.0
 LSMDC_full_test/t2v_metrics/MeanR: 75.991
 LSMDC_full_test/t2v_metrics/geometric_mean_R1-R5-R10: 26.504299290590023
 LSMDC_full_test/v2t_metrics/R1: 12.5
 LSMDC_full_test/v2t_metrics/R5: 31.7
 LSMDC_full_test/v2t_metrics/R10: 41.3
 LSMDC_full_test/v2t_metrics/R50: 67.0
 LSMDC_full_test/v2t_metrics/MedR: 19.0
 LSMDC_full_test/v2t_metrics/MeanR: 71.375
 LSMDC_full_test/v2t_metrics/geometric_mean_R1-R5-R10: 25.38865976505446
 mnt_best       : 27.233789646149496
 not_improved_count: 2
Train Epoch: 50 [1/250 128/32000 (0%)] Loss: 1.94044 (QuantReg: 18.39716) QuantErr: 18.39716 batch_time=16.92853 
Train Epoch: 50 [12/250 1536/32000 (5%)] Loss: 1.64412 (QuantReg: 18.50149) QuantErr: 18.50149 batch_time=0.58696 
Train Epoch: 50 [23/250 2944/32000 (9%)] Loss: 1.43295 (QuantReg: 18.51735) QuantErr: 18.51735 batch_time=0.50701 
Train Epoch: 50 [34/250 4352/32000 (14%)] Loss: 1.81831 (QuantReg: 18.43972) QuantErr: 18.43972 batch_time=0.50030 
Train Epoch: 50 [45/250 5760/32000 (18%)] Loss: 1.49098 (QuantReg: 18.36787) QuantErr: 18.36787 batch_time=0.53672 
Train Epoch: 50 [56/250 7168/32000 (22%)] Loss: 1.92252 (QuantReg: 18.34139) QuantErr: 18.34139 batch_time=0.51953 
Train Epoch: 50 [67/250 8576/32000 (27%)] Loss: 1.85313 (QuantReg: 18.44409) QuantErr: 18.44409 batch_time=1.29164 
Train Epoch: 50 [78/250 9984/32000 (31%)] Loss: 1.61765 (QuantReg: 18.36364) QuantErr: 18.36364 batch_time=0.52272 
Train Epoch: 50 [89/250 11392/32000 (36%)] Loss: 1.46073 (QuantReg: 18.50203) QuantErr: 18.50203 batch_time=0.49315 
Train Epoch: 50 [100/250 12800/32000 (40%)] Loss: 1.31771 (QuantReg: 18.53497) QuantErr: 18.53497 batch_time=0.50172 
Train Epoch: 50 [111/250 14208/32000 (44%)] Loss: 1.59977 (QuantReg: 18.41366) QuantErr: 18.41366 batch_time=0.50595 
Train Epoch: 50 [122/250 15616/32000 (49%)] Loss: 1.50649 (QuantReg: 18.48430) QuantErr: 18.48430 batch_time=0.53450 
Train Epoch: 50 [133/250 17024/32000 (53%)] Loss: 1.54404 (QuantReg: 18.40343) QuantErr: 18.40343 batch_time=1.18607 
Train Epoch: 50 [144/250 18432/32000 (58%)] Loss: 1.38645 (QuantReg: 18.45191) QuantErr: 18.45191 batch_time=0.49589 
Train Epoch: 50 [155/250 19840/32000 (62%)] Loss: 1.46344 (QuantReg: 18.42912) QuantErr: 18.42912 batch_time=0.50074 
Train Epoch: 50 [166/250 21248/32000 (66%)] Loss: 1.58426 (QuantReg: 18.52920) QuantErr: 18.52920 batch_time=0.50378 
Train Epoch: 50 [177/250 22656/32000 (71%)] Loss: 1.37389 (QuantReg: 18.64685) QuantErr: 18.64685 batch_time=0.49821 
Train Epoch: 50 [188/250 24064/32000 (75%)] Loss: 1.64532 (QuantReg: 18.58275) QuantErr: 18.58275 batch_time=0.49660 
Train Epoch: 50 [199/250 25472/32000 (80%)] Loss: 1.71951 (QuantReg: 18.63283) QuantErr: 18.63283 batch_time=0.54276 
Train Epoch: 50 [210/250 26880/32000 (84%)] Loss: 1.68088 (QuantReg: 18.45623) QuantErr: 18.45623 batch_time=2.71509 
Train Epoch: 50 [221/250 28288/32000 (88%)] Loss: 1.42295 (QuantReg: 18.49992) QuantErr: 18.49992 batch_time=0.50336 
Train Epoch: 50 [232/250 29696/32000 (93%)] Loss: 1.41448 (QuantReg: 18.43785) QuantErr: 18.43785 batch_time=0.52486 
Train Epoch: 50 [243/250 31104/32000 (97%)] Loss: 1.74882 (QuantReg: 18.40319) QuantErr: 18.40319 batch_time=0.56820 
Train Epoch: 50 codebook_update_time=1.87088
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_LSMDC_t0.03/checkpoint-epoch50.pth ...
Done in 7.005s
Updating 'best' checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_LSMDC_t0.03/checkpoint-epoch50.pth ...
Done in 12.065s
removing stale ckpt [epoch 49] [took 0.02s]
 epoch          : 50
 loss           : 1.589120702266693
 quant_reg      : 18.459349861145018
 quant_err      : 18.459349861145018
 learning_rate  : 4.04973554087964e-06
 n_samples      : 1600000
 n_steps        : 12500
 LSMDC_full_test/t2v_metrics/R1: 14.9
 LSMDC_full_test/t2v_metrics/R5: 32.0
 LSMDC_full_test/t2v_metrics/R10: 42.5
 LSMDC_full_test/t2v_metrics/R50: 66.2
 LSMDC_full_test/t2v_metrics/MedR: 18.0
 LSMDC_full_test/t2v_metrics/MeanR: 76.142
 LSMDC_full_test/t2v_metrics/geometric_mean_R1-R5-R10: 27.26308884998979
 LSMDC_full_test/v2t_metrics/R1: 12.9
 LSMDC_full_test/v2t_metrics/R5: 31.8
 LSMDC_full_test/v2t_metrics/R10: 40.8
 LSMDC_full_test/v2t_metrics/R50: 66.8
 LSMDC_full_test/v2t_metrics/MedR: 20.0
 LSMDC_full_test/v2t_metrics/MeanR: 72.309
 LSMDC_full_test/v2t_metrics/geometric_mean_R1-R5-R10: 25.57951649236278
 mnt_best       : 27.26308884998979
 not_improved_count: 0
Final evaluation ...
Loading checkpoint from: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_LSMDC_t0.03/trained_model.pth ...
Ckpt loaded at epoch 50.
Saved similarity matrix (quantize videos) to /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_LSMDC_t0.03/LSMDC-test-qv-sims.npy
Saved v2t similarity matrix (quantize texts) to /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_LSMDC_t0.03/LSMDC-test-qt-sims.npy
LSMDC_full_test:
 t2v_metrics/R1/final_eval: 14.9
 t2v_metrics/R5/final_eval: 32.0
 t2v_metrics/R10/final_eval: 42.5
 t2v_metrics/R50/final_eval: 66.2
 t2v_metrics/MedR/final_eval: 18.0
 t2v_metrics/MeanR/final_eval: 76.142
 t2v_metrics/geometric_mean_R1-R5-R10/final_eval: 27.26308884998979
 v2t_metrics/R1/final_eval: 12.9
 v2t_metrics/R5/final_eval: 31.8
 v2t_metrics/R10/final_eval: 40.8
 v2t_metrics/R50/final_eval: 66.8
 v2t_metrics/MedR/final_eval: 20.0
 v2t_metrics/MeanR/final_eval: 72.309
 v2t_metrics/geometric_mean_R1-R5-R10/final_eval: 25.57951649236278
Best epoch for the monitored metric: 50
Script took 04h17m38s
The best performing ckpt can be found at /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_LSMDC_t0.03/trained_model.pth
