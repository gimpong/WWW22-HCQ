Experiment directory: /apdcephfs/share_47076/gimwang/HCQ/exps/DCMH_MSRVTT_1kA
Preparing the dataloaders ...
Loading dataset MSRVTT_jsfusion_trainval in ram ...
Finish loading dataset MSRVTT_jsfusion_trainval in ram, taking 546.9244015216827 s.
Loading dataset MSRVTT_jsfusion_test in ram ...
Finish loading dataset MSRVTT_jsfusion_test in ram, taking 69.83318901062012 s.
Loading dataset MSRVTT_jsfusion_test in ram ...
Finish loading dataset MSRVTT_jsfusion_test in ram, taking 60.15059280395508 s.
Training ...
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/DCMH_MSRVTT_1kA/checkpoint-epoch0.pth ...
Done in 6.558s
Updating 'best' checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/DCMH_MSRVTT_1kA/checkpoint-epoch0.pth ...
Done in 8.222s
 epoch          : 0
 loss           : 0
 learning_rate  : 5e-05
 n_samples      : 0
 n_steps        : 0
 MSRVTT_jsfusion_test/t2v_metrics/R1: 0.1
 MSRVTT_jsfusion_test/t2v_metrics/R5: 0.5
 MSRVTT_jsfusion_test/t2v_metrics/R10: 1.0
 MSRVTT_jsfusion_test/t2v_metrics/R50: 4.5
 MSRVTT_jsfusion_test/t2v_metrics/MedR: 502.5
 MSRVTT_jsfusion_test/t2v_metrics/MeanR: 499.848
 MSRVTT_jsfusion_test/t2v_metrics/geometric_mean_R1-R5-R10: 0.3684031498640387
 MSRVTT_jsfusion_test/v2t_metrics/R1: 0.1
 MSRVTT_jsfusion_test/v2t_metrics/R5: 0.4
 MSRVTT_jsfusion_test/v2t_metrics/R10: 1.0
 MSRVTT_jsfusion_test/v2t_metrics/R50: 4.6
 MSRVTT_jsfusion_test/v2t_metrics/MedR: 503.0
 MSRVTT_jsfusion_test/v2t_metrics/MeanR: 500.8045
 MSRVTT_jsfusion_test/v2t_metrics/geometric_mean_R1-R5-R10: 0.3419951893353394
 mnt_best       : 0.3684031498640387
 not_improved_count: 0
Train Epoch: 1 [1/250 128/32000 (0%)] Loss: 2.68994 (semantic_loss: 0.74034, quant_loss: 1.94922, bit_balance_loss: 0.00038) batch_time=22.97347 
Train Epoch: 1 [12/250 1536/32000 (5%)] Loss: 1.99995 (semantic_loss: 0.04833, quant_loss: 1.95117, bit_balance_loss: 0.00045) batch_time=0.34628 
Train Epoch: 1 [23/250 2944/32000 (9%)] Loss: 1.99769 (semantic_loss: 0.04604, quant_loss: 1.95117, bit_balance_loss: 0.00047) batch_time=0.33036 
Train Epoch: 1 [34/250 4352/32000 (14%)] Loss: 1.99667 (semantic_loss: 0.04599, quant_loss: 1.95020, bit_balance_loss: 0.00048) batch_time=0.32395 
Train Epoch: 1 [45/250 5760/32000 (18%)] Loss: 1.99752 (semantic_loss: 0.04586, quant_loss: 1.95117, bit_balance_loss: 0.00048) batch_time=0.32902 
Train Epoch: 1 [56/250 7168/32000 (22%)] Loss: 1.99643 (semantic_loss: 0.04575, quant_loss: 1.95020, bit_balance_loss: 0.00048) batch_time=0.35001 
Train Epoch: 1 [67/250 8576/32000 (27%)] Loss: 1.99643 (semantic_loss: 0.04575, quant_loss: 1.95020, bit_balance_loss: 0.00048) batch_time=0.32516 
Train Epoch: 1 [78/250 9984/32000 (31%)] Loss: 1.99738 (semantic_loss: 0.04573, quant_loss: 1.95117, bit_balance_loss: 0.00048) batch_time=0.33290 
Train Epoch: 1 [89/250 11392/32000 (36%)] Loss: 1.99738 (semantic_loss: 0.04573, quant_loss: 1.95117, bit_balance_loss: 0.00048) batch_time=0.32463 
Train Epoch: 1 [100/250 12800/32000 (40%)] Loss: 1.99735 (semantic_loss: 0.04570, quant_loss: 1.95117, bit_balance_loss: 0.00048) batch_time=0.34818 
Train Epoch: 1 [111/250 14208/32000 (44%)] Loss: 1.99637 (semantic_loss: 0.04570, quant_loss: 1.95020, bit_balance_loss: 0.00047) batch_time=0.36100 
Train Epoch: 1 [122/250 15616/32000 (49%)] Loss: 1.99637 (semantic_loss: 0.04571, quant_loss: 1.95020, bit_balance_loss: 0.00047) batch_time=0.32936 
Train Epoch: 1 [133/250 17024/32000 (53%)] Loss: 1.99736 (semantic_loss: 0.04573, quant_loss: 1.95117, bit_balance_loss: 0.00046) batch_time=0.35055 
Train Epoch: 1 [144/250 18432/32000 (58%)] Loss: 1.99733 (semantic_loss: 0.04570, quant_loss: 1.95117, bit_balance_loss: 0.00046) batch_time=0.32414 
Train Epoch: 1 [155/250 19840/32000 (62%)] Loss: 1.99736 (semantic_loss: 0.04573, quant_loss: 1.95117, bit_balance_loss: 0.00046) batch_time=0.34215 
Train Epoch: 1 [166/250 21248/32000 (66%)] Loss: 1.99732 (semantic_loss: 0.04569, quant_loss: 1.95117, bit_balance_loss: 0.00045) batch_time=0.35292 
Train Epoch: 1 [177/250 22656/32000 (71%)] Loss: 1.99730 (semantic_loss: 0.04568, quant_loss: 1.95117, bit_balance_loss: 0.00045) batch_time=0.33110 
Train Epoch: 1 [188/250 24064/32000 (75%)] Loss: 1.99732 (semantic_loss: 0.04571, quant_loss: 1.95117, bit_balance_loss: 0.00045) batch_time=0.39705 
Train Epoch: 1 [199/250 25472/32000 (80%)] Loss: 1.99629 (semantic_loss: 0.04565, quant_loss: 1.95020, bit_balance_loss: 0.00044) batch_time=0.32698 
Train Epoch: 1 [210/250 26880/32000 (84%)] Loss: 1.99723 (semantic_loss: 0.04562, quant_loss: 1.95117, bit_balance_loss: 0.00044) batch_time=5.77071 
Train Epoch: 1 [221/250 28288/32000 (88%)] Loss: 1.99619 (semantic_loss: 0.04557, quant_loss: 1.95020, bit_balance_loss: 0.00043) batch_time=0.34086 
Train Epoch: 1 [232/250 29696/32000 (93%)] Loss: 1.99623 (semantic_loss: 0.04561, quant_loss: 1.95020, bit_balance_loss: 0.00043) batch_time=0.34422 
Train Epoch: 1 [243/250 31104/32000 (97%)] Loss: 1.99623 (semantic_loss: 0.04561, quant_loss: 1.95020, bit_balance_loss: 0.00042) batch_time=0.32681 
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/DCMH_MSRVTT_1kA/checkpoint-epoch1.pth ...
Done in 3.870s
Updating 'best' checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/DCMH_MSRVTT_1kA/checkpoint-epoch1.pth ...
Done in 7.779s
 epoch          : 1
 loss           : 2.002893678188324
 learning_rate  : 5e-05
 n_samples      : 32000
 n_steps        : 250
 MSRVTT_jsfusion_test/t2v_metrics/R1: 0.1
 MSRVTT_jsfusion_test/t2v_metrics/R5: 0.8
 MSRVTT_jsfusion_test/t2v_metrics/R10: 1.6
 MSRVTT_jsfusion_test/t2v_metrics/R50: 7.3
 MSRVTT_jsfusion_test/t2v_metrics/MedR: 454.25
 MSRVTT_jsfusion_test/t2v_metrics/MeanR: 470.219
 MSRVTT_jsfusion_test/t2v_metrics/geometric_mean_R1-R5-R10: 0.5039684199579494
 MSRVTT_jsfusion_test/v2t_metrics/R1: 0.0
 MSRVTT_jsfusion_test/v2t_metrics/R5: 0.6
 MSRVTT_jsfusion_test/v2t_metrics/R10: 1.6
 MSRVTT_jsfusion_test/v2t_metrics/R50: 5.6
 MSRVTT_jsfusion_test/v2t_metrics/MedR: 454.25
 MSRVTT_jsfusion_test/v2t_metrics/MeanR: 476.6665
 MSRVTT_jsfusion_test/v2t_metrics/geometric_mean_R1-R5-R10: 0.0
 mnt_best       : 0.5039684199579494
 not_improved_count: 0
Train Epoch: 2 [1/250 128/32000 (0%)] Loss: 1.99702 (semantic_loss: 0.04543, quant_loss: 1.95117, bit_balance_loss: 0.00042) batch_time=27.67402 
Train Epoch: 2 [12/250 1536/32000 (5%)] Loss: 1.99699 (semantic_loss: 0.04541, quant_loss: 1.95117, bit_balance_loss: 0.00041) batch_time=0.33488 
Train Epoch: 2 [23/250 2944/32000 (9%)] Loss: 1.99622 (semantic_loss: 0.04561, quant_loss: 1.95020, bit_balance_loss: 0.00042) batch_time=0.33755 
Train Epoch: 2 [34/250 4352/32000 (14%)] Loss: 1.99605 (semantic_loss: 0.04545, quant_loss: 1.95020, bit_balance_loss: 0.00041) batch_time=0.35204 
Train Epoch: 2 [45/250 5760/32000 (18%)] Loss: 1.99589 (semantic_loss: 0.04529, quant_loss: 1.95020, bit_balance_loss: 0.00040) batch_time=0.33885 
Train Epoch: 2 [56/250 7168/32000 (22%)] Loss: 1.99682 (semantic_loss: 0.04526, quant_loss: 1.95117, bit_balance_loss: 0.00039) batch_time=0.34402 
Train Epoch: 2 [67/250 8576/32000 (27%)] Loss: 1.99669 (semantic_loss: 0.04512, quant_loss: 1.95117, bit_balance_loss: 0.00039) batch_time=0.34548 
Train Epoch: 2 [78/250 9984/32000 (31%)] Loss: 1.99559 (semantic_loss: 0.04501, quant_loss: 1.95020, bit_balance_loss: 0.00039) batch_time=4.30400 
Train Epoch: 2 [89/250 11392/32000 (36%)] Loss: 1.99546 (semantic_loss: 0.04488, quant_loss: 1.95020, bit_balance_loss: 0.00038) batch_time=0.33674 
Train Epoch: 2 [100/250 12800/32000 (40%)] Loss: 1.99608 (semantic_loss: 0.04551, quant_loss: 1.95020, bit_balance_loss: 0.00038) batch_time=0.33340 
Train Epoch: 2 [111/250 14208/32000 (44%)] Loss: 1.99591 (semantic_loss: 0.04534, quant_loss: 1.95020, bit_balance_loss: 0.00038) batch_time=0.32623 
Train Epoch: 2 [122/250 15616/32000 (49%)] Loss: 1.99476 (semantic_loss: 0.04419, quant_loss: 1.95020, bit_balance_loss: 0.00037) batch_time=0.32464 
Train Epoch: 2 [133/250 17024/32000 (53%)] Loss: 1.99588 (semantic_loss: 0.04434, quant_loss: 1.95117, bit_balance_loss: 0.00036) batch_time=0.33094 
Train Epoch: 2 [144/250 18432/32000 (58%)] Loss: 1.99450 (semantic_loss: 0.04395, quant_loss: 1.95020, bit_balance_loss: 0.00036) batch_time=1.05294 
Train Epoch: 2 [155/250 19840/32000 (62%)] Loss: 1.99451 (semantic_loss: 0.04395, quant_loss: 1.95020, bit_balance_loss: 0.00036) batch_time=0.32559 
Train Epoch: 2 [166/250 21248/32000 (66%)] Loss: 1.99548 (semantic_loss: 0.04395, quant_loss: 1.95117, bit_balance_loss: 0.00035) batch_time=0.32195 
Train Epoch: 2 [177/250 22656/32000 (71%)] Loss: 1.99576 (semantic_loss: 0.04424, quant_loss: 1.95117, bit_balance_loss: 0.00035) batch_time=0.34834 
Train Epoch: 2 [188/250 24064/32000 (75%)] Loss: 1.99493 (semantic_loss: 0.04439, quant_loss: 1.95020, bit_balance_loss: 0.00035) batch_time=0.35347 
Train Epoch: 2 [199/250 25472/32000 (80%)] Loss: 1.99388 (semantic_loss: 0.04334, quant_loss: 1.95020, bit_balance_loss: 0.00034) batch_time=0.33256 
Train Epoch: 2 [210/250 26880/32000 (84%)] Loss: 1.99487 (semantic_loss: 0.04336, quant_loss: 1.95117, bit_balance_loss: 0.00034) batch_time=0.34094 
Train Epoch: 2 [221/250 28288/32000 (88%)] Loss: 1.99385 (semantic_loss: 0.04332, quant_loss: 1.95020, bit_balance_loss: 0.00034) batch_time=0.32201 
Train Epoch: 2 [232/250 29696/32000 (93%)] Loss: 1.99467 (semantic_loss: 0.04316, quant_loss: 1.95117, bit_balance_loss: 0.00033) batch_time=0.33833 
Train Epoch: 2 [243/250 31104/32000 (97%)] Loss: 1.99425 (semantic_loss: 0.04275, quant_loss: 1.95117, bit_balance_loss: 0.00033) batch_time=0.32278 
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/DCMH_MSRVTT_1kA/checkpoint-epoch2.pth ...
Done in 4.159s
Updating 'best' checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/DCMH_MSRVTT_1kA/checkpoint-epoch2.pth ...
Done in 7.883s
removing stale ckpt [epoch 1] [took 0.00s]
removing stale ckpt [epoch 0] [took 0.00s]
 epoch          : 2
 loss           : 1.9955712633132934
 learning_rate  : 4.75e-05
 n_samples      : 64000
 n_steps        : 500
 MSRVTT_jsfusion_test/t2v_metrics/R1: 0.2
 MSRVTT_jsfusion_test/t2v_metrics/R5: 1.7
 MSRVTT_jsfusion_test/t2v_metrics/R10: 2.8
 MSRVTT_jsfusion_test/t2v_metrics/R50: 13.8
 MSRVTT_jsfusion_test/t2v_metrics/MedR: 256.5
 MSRVTT_jsfusion_test/t2v_metrics/MeanR: 290.412
 MSRVTT_jsfusion_test/t2v_metrics/geometric_mean_R1-R5-R10: 0.9837369468917456
 MSRVTT_jsfusion_test/v2t_metrics/R1: 0.1
 MSRVTT_jsfusion_test/v2t_metrics/R5: 1.0
 MSRVTT_jsfusion_test/v2t_metrics/R10: 2.5
 MSRVTT_jsfusion_test/v2t_metrics/R50: 11.8
 MSRVTT_jsfusion_test/v2t_metrics/MedR: 238.5
 MSRVTT_jsfusion_test/v2t_metrics/MeanR: 283.8205
 MSRVTT_jsfusion_test/v2t_metrics/geometric_mean_R1-R5-R10: 0.6299605249474366
 mnt_best       : 0.9837369468917456
 not_improved_count: 0
Train Epoch: 3 [1/250 128/32000 (0%)] Loss: 1.99304 (semantic_loss: 0.04252, quant_loss: 1.95020, bit_balance_loss: 0.00033) batch_time=24.52264 
Train Epoch: 3 [12/250 1536/32000 (5%)] Loss: 1.99399 (semantic_loss: 0.04250, quant_loss: 1.95117, bit_balance_loss: 0.00032) batch_time=2.49927 
Train Epoch: 3 [23/250 2944/32000 (9%)] Loss: 1.99287 (semantic_loss: 0.04235, quant_loss: 1.95020, bit_balance_loss: 0.00032) batch_time=0.34087 
Train Epoch: 3 [34/250 4352/32000 (14%)] Loss: 1.99219 (semantic_loss: 0.04169, quant_loss: 1.95020, bit_balance_loss: 0.00031) batch_time=0.34155 
Train Epoch: 3 [45/250 5760/32000 (18%)] Loss: 1.99159 (semantic_loss: 0.04206, quant_loss: 1.94922, bit_balance_loss: 0.00031) batch_time=0.34564 
Train Epoch: 3 [56/250 7168/32000 (22%)] Loss: 1.99173 (semantic_loss: 0.04123, quant_loss: 1.95020, bit_balance_loss: 0.00031) batch_time=0.34210 
Train Epoch: 3 [67/250 8576/32000 (27%)] Loss: 1.99086 (semantic_loss: 0.04133, quant_loss: 1.94922, bit_balance_loss: 0.00031) batch_time=0.34120 
Train Epoch: 3 [78/250 9984/32000 (31%)] Loss: 1.99252 (semantic_loss: 0.04105, quant_loss: 1.95117, bit_balance_loss: 0.00030) batch_time=0.36533 
Train Epoch: 3 [89/250 11392/32000 (36%)] Loss: 1.99131 (semantic_loss: 0.04081, quant_loss: 1.95020, bit_balance_loss: 0.00030) batch_time=0.34230 
Train Epoch: 3 [100/250 12800/32000 (40%)] Loss: 1.99120 (semantic_loss: 0.04071, quant_loss: 1.95020, bit_balance_loss: 0.00030) batch_time=0.33869 
Train Epoch: 3 [111/250 14208/32000 (44%)] Loss: 1.99121 (semantic_loss: 0.03975, quant_loss: 1.95117, bit_balance_loss: 0.00029) batch_time=0.33668 
Train Epoch: 3 [122/250 15616/32000 (49%)] Loss: 1.98890 (semantic_loss: 0.03939, quant_loss: 1.94922, bit_balance_loss: 0.00029) batch_time=0.32599 
Train Epoch: 3 [133/250 17024/32000 (53%)] Loss: 1.98969 (semantic_loss: 0.03921, quant_loss: 1.95020, bit_balance_loss: 0.00029) batch_time=0.34284 
Train Epoch: 3 [144/250 18432/32000 (58%)] Loss: 1.99016 (semantic_loss: 0.03968, quant_loss: 1.95020, bit_balance_loss: 0.00028) batch_time=0.33150 
Train Epoch: 3 [155/250 19840/32000 (62%)] Loss: 1.98819 (semantic_loss: 0.03869, quant_loss: 1.94922, bit_balance_loss: 0.00028) batch_time=0.34062 
Train Epoch: 3 [166/250 21248/32000 (66%)] Loss: 1.98764 (semantic_loss: 0.03717, quant_loss: 1.95020, bit_balance_loss: 0.00027) batch_time=0.32692 
Train Epoch: 3 [177/250 22656/32000 (71%)] Loss: 1.98730 (semantic_loss: 0.03781, quant_loss: 1.94922, bit_balance_loss: 0.00027) batch_time=0.33965 
Train Epoch: 3 [188/250 24064/32000 (75%)] Loss: 1.98535 (semantic_loss: 0.03683, quant_loss: 1.94824, bit_balance_loss: 0.00027) batch_time=0.35133 
Train Epoch: 3 [199/250 25472/32000 (80%)] Loss: 1.98684 (semantic_loss: 0.03638, quant_loss: 1.95020, bit_balance_loss: 0.00027) batch_time=0.32899 
Train Epoch: 3 [210/250 26880/32000 (84%)] Loss: 1.98708 (semantic_loss: 0.03662, quant_loss: 1.95020, bit_balance_loss: 0.00026) batch_time=0.32451 
Train Epoch: 3 [221/250 28288/32000 (88%)] Loss: 1.98647 (semantic_loss: 0.03698, quant_loss: 1.94922, bit_balance_loss: 0.00026) batch_time=2.12151 
Train Epoch: 3 [232/250 29696/32000 (93%)] Loss: 1.98596 (semantic_loss: 0.03648, quant_loss: 1.94922, bit_balance_loss: 0.00026) batch_time=0.33921 
Train Epoch: 3 [243/250 31104/32000 (97%)] Loss: 1.98399 (semantic_loss: 0.03451, quant_loss: 1.94922, bit_balance_loss: 0.00026) batch_time=0.33004 
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/DCMH_MSRVTT_1kA/checkpoint-epoch3.pth ...
Done in 4.098s
Updating 'best' checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/DCMH_MSRVTT_1kA/checkpoint-epoch3.pth ...
Done in 8.047s
removing stale ckpt [epoch 2] [took 0.00s]
 epoch          : 3
 loss           : 1.9893670625686646
 learning_rate  : 4.5125e-05
 n_samples      : 96000
 n_steps        : 750
 MSRVTT_jsfusion_test/t2v_metrics/R1: 2.0
 MSRVTT_jsfusion_test/t2v_metrics/R5: 8.7
 MSRVTT_jsfusion_test/t2v_metrics/R10: 15.0
 MSRVTT_jsfusion_test/t2v_metrics/R50: 48.8
 MSRVTT_jsfusion_test/t2v_metrics/MedR: 52.0
 MSRVTT_jsfusion_test/t2v_metrics/MeanR: 112.439
 MSRVTT_jsfusion_test/t2v_metrics/geometric_mean_R1-R5-R10: 6.3906765283993066
 MSRVTT_jsfusion_test/v2t_metrics/R1: 2.8
 MSRVTT_jsfusion_test/v2t_metrics/R5: 10.1
 MSRVTT_jsfusion_test/v2t_metrics/R10: 17.0
 MSRVTT_jsfusion_test/v2t_metrics/R50: 51.4
 MSRVTT_jsfusion_test/v2t_metrics/MedR: 48.0
 MSRVTT_jsfusion_test/v2t_metrics/MeanR: 105.4345
 MSRVTT_jsfusion_test/v2t_metrics/geometric_mean_R1-R5-R10: 7.833865463574119
 mnt_best       : 6.3906765283993066
 not_improved_count: 0
Train Epoch: 4 [1/250 128/32000 (0%)] Loss: 1.98367 (semantic_loss: 0.03420, quant_loss: 1.94922, bit_balance_loss: 0.00025) batch_time=25.84425 
Train Epoch: 4 [12/250 1536/32000 (5%)] Loss: 1.98639 (semantic_loss: 0.03594, quant_loss: 1.95020, bit_balance_loss: 0.00026) batch_time=0.67224 
Train Epoch: 4 [23/250 2944/32000 (9%)] Loss: 1.98547 (semantic_loss: 0.03502, quant_loss: 1.95020, bit_balance_loss: 0.00025) batch_time=1.18812 
Train Epoch: 4 [34/250 4352/32000 (14%)] Loss: 1.98436 (semantic_loss: 0.03490, quant_loss: 1.94922, bit_balance_loss: 0.00025) batch_time=0.33996 
Train Epoch: 4 [45/250 5760/32000 (18%)] Loss: 1.98309 (semantic_loss: 0.03363, quant_loss: 1.94922, bit_balance_loss: 0.00024) batch_time=0.33626 
Train Epoch: 4 [56/250 7168/32000 (22%)] Loss: 1.98308 (semantic_loss: 0.03362, quant_loss: 1.94922, bit_balance_loss: 0.00024) batch_time=0.34410 
Train Epoch: 4 [67/250 8576/32000 (27%)] Loss: 1.98359 (semantic_loss: 0.03413, quant_loss: 1.94922, bit_balance_loss: 0.00024) batch_time=2.96249 
Train Epoch: 4 [78/250 9984/32000 (31%)] Loss: 1.98372 (semantic_loss: 0.03328, quant_loss: 1.95020, bit_balance_loss: 0.00024) batch_time=0.34048 
Train Epoch: 4 [89/250 11392/32000 (36%)] Loss: 1.98223 (semantic_loss: 0.03278, quant_loss: 1.94922, bit_balance_loss: 0.00024) batch_time=0.32326 
Train Epoch: 4 [100/250 12800/32000 (40%)] Loss: 1.98431 (semantic_loss: 0.03388, quant_loss: 1.95020, bit_balance_loss: 0.00024) batch_time=0.33253 
Train Epoch: 4 [111/250 14208/32000 (44%)] Loss: 1.98296 (semantic_loss: 0.03253, quant_loss: 1.95020, bit_balance_loss: 0.00023) batch_time=1.49998 
Train Epoch: 4 [122/250 15616/32000 (49%)] Loss: 1.98356 (semantic_loss: 0.03411, quant_loss: 1.94922, bit_balance_loss: 0.00023) batch_time=0.57107 
Train Epoch: 4 [133/250 17024/32000 (53%)] Loss: 1.98433 (semantic_loss: 0.03391, quant_loss: 1.95020, bit_balance_loss: 0.00023) batch_time=0.35517 
Train Epoch: 4 [144/250 18432/32000 (58%)] Loss: 1.98237 (semantic_loss: 0.03292, quant_loss: 1.94922, bit_balance_loss: 0.00023) batch_time=1.37063 
Train Epoch: 4 [155/250 19840/32000 (62%)] Loss: 1.98449 (semantic_loss: 0.03407, quant_loss: 1.95020, bit_balance_loss: 0.00023) batch_time=0.32443 
Train Epoch: 4 [166/250 21248/32000 (66%)] Loss: 1.98375 (semantic_loss: 0.03333, quant_loss: 1.95020, bit_balance_loss: 0.00023) batch_time=0.33849 
Train Epoch: 4 [177/250 22656/32000 (71%)] Loss: 1.98120 (semantic_loss: 0.03176, quant_loss: 1.94922, bit_balance_loss: 0.00022) batch_time=0.33056 
Train Epoch: 4 [188/250 24064/32000 (75%)] Loss: 1.98336 (semantic_loss: 0.03294, quant_loss: 1.95020, bit_balance_loss: 0.00022) batch_time=0.35123 
Train Epoch: 4 [199/250 25472/32000 (80%)] Loss: 1.98178 (semantic_loss: 0.03234, quant_loss: 1.94922, bit_balance_loss: 0.00022) batch_time=0.38238 
Train Epoch: 4 [210/250 26880/32000 (84%)] Loss: 1.98297 (semantic_loss: 0.03256, quant_loss: 1.95020, bit_balance_loss: 0.00022) batch_time=0.34366 
Train Epoch: 4 [221/250 28288/32000 (88%)] Loss: 1.98205 (semantic_loss: 0.03164, quant_loss: 1.95020, bit_balance_loss: 0.00022) batch_time=0.34690 
Train Epoch: 4 [232/250 29696/32000 (93%)] Loss: 1.98047 (semantic_loss: 0.03007, quant_loss: 1.95020, bit_balance_loss: 0.00021) batch_time=0.35810 
Train Epoch: 4 [243/250 31104/32000 (97%)] Loss: 1.98109 (semantic_loss: 0.03166, quant_loss: 1.94922, bit_balance_loss: 0.00021) batch_time=0.34256 
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/DCMH_MSRVTT_1kA/checkpoint-epoch4.pth ...
Done in 4.208s
Updating 'best' checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/DCMH_MSRVTT_1kA/checkpoint-epoch4.pth ...
Done in 21.501s
removing stale ckpt [epoch 3] [took 0.01s]
 epoch          : 4
 loss           : 1.9828839597702026
 learning_rate  : 4.2868749999999995e-05
 n_samples      : 128000
 n_steps        : 1000
 MSRVTT_jsfusion_test/t2v_metrics/R1: 4.1
 MSRVTT_jsfusion_test/t2v_metrics/R5: 15.6
 MSRVTT_jsfusion_test/t2v_metrics/R10: 25.9
 MSRVTT_jsfusion_test/t2v_metrics/R50: 63.7
 MSRVTT_jsfusion_test/t2v_metrics/MedR: 31.25
 MSRVTT_jsfusion_test/t2v_metrics/MeanR: 74.5245
 MSRVTT_jsfusion_test/t2v_metrics/geometric_mean_R1-R5-R10: 11.832306375644585
 MSRVTT_jsfusion_test/v2t_metrics/R1: 3.1
 MSRVTT_jsfusion_test/v2t_metrics/R5: 14.1
 MSRVTT_jsfusion_test/v2t_metrics/R10: 26.0
 MSRVTT_jsfusion_test/v2t_metrics/R50: 64.8
 MSRVTT_jsfusion_test/v2t_metrics/MedR: 31.0
 MSRVTT_jsfusion_test/v2t_metrics/MeanR: 71.724
 MSRVTT_jsfusion_test/v2t_metrics/geometric_mean_R1-R5-R10: 10.435615075493853
 mnt_best       : 11.832306375644585
 not_improved_count: 0
Train Epoch: 5 [1/250 128/32000 (0%)] Loss: 1.98151 (semantic_loss: 0.03208, quant_loss: 1.94922, bit_balance_loss: 0.00021) batch_time=30.94472 
Train Epoch: 5 [12/250 1536/32000 (5%)] Loss: 1.97998 (semantic_loss: 0.03056, quant_loss: 1.94922, bit_balance_loss: 0.00020) batch_time=0.35294 
Train Epoch: 5 [23/250 2944/32000 (9%)] Loss: 1.98053 (semantic_loss: 0.03110, quant_loss: 1.94922, bit_balance_loss: 0.00021) batch_time=0.34209 
Train Epoch: 5 [34/250 4352/32000 (14%)] Loss: 1.97996 (semantic_loss: 0.03054, quant_loss: 1.94922, bit_balance_loss: 0.00020) batch_time=0.33087 
Train Epoch: 5 [45/250 5760/32000 (18%)] Loss: 1.97876 (semantic_loss: 0.02934, quant_loss: 1.94922, bit_balance_loss: 0.00020) batch_time=0.37877 
Train Epoch: 5 [56/250 7168/32000 (22%)] Loss: 1.98018 (semantic_loss: 0.03076, quant_loss: 1.94922, bit_balance_loss: 0.00020) batch_time=0.32354 
Train Epoch: 5 [67/250 8576/32000 (27%)] Loss: 1.98065 (semantic_loss: 0.03123, quant_loss: 1.94922, bit_balance_loss: 0.00020) batch_time=0.32341 
Train Epoch: 5 [78/250 9984/32000 (31%)] Loss: 1.98090 (semantic_loss: 0.03051, quant_loss: 1.95020, bit_balance_loss: 0.00020) batch_time=0.34839 
Train Epoch: 5 [89/250 11392/32000 (36%)] Loss: 1.97900 (semantic_loss: 0.02861, quant_loss: 1.95020, bit_balance_loss: 0.00019) batch_time=0.33749 
Train Epoch: 5 [100/250 12800/32000 (40%)] Loss: 1.98030 (semantic_loss: 0.03089, quant_loss: 1.94922, bit_balance_loss: 0.00019) batch_time=0.33259 
Train Epoch: 5 [111/250 14208/32000 (44%)] Loss: 1.97942 (semantic_loss: 0.02904, quant_loss: 1.95020, bit_balance_loss: 0.00019) batch_time=0.34503 
Train Epoch: 5 [122/250 15616/32000 (49%)] Loss: 1.97979 (semantic_loss: 0.02941, quant_loss: 1.95020, bit_balance_loss: 0.00019) batch_time=0.33206 
Train Epoch: 5 [133/250 17024/32000 (53%)] Loss: 1.98059 (semantic_loss: 0.03020, quant_loss: 1.95020, bit_balance_loss: 0.00019) batch_time=0.34651 
Train Epoch: 5 [144/250 18432/32000 (58%)] Loss: 1.97912 (semantic_loss: 0.02874, quant_loss: 1.95020, bit_balance_loss: 0.00019) batch_time=0.35917 
Train Epoch: 5 [155/250 19840/32000 (62%)] Loss: 1.97847 (semantic_loss: 0.02809, quant_loss: 1.95020, bit_balance_loss: 0.00019) batch_time=0.33773 
Train Epoch: 5 [166/250 21248/32000 (66%)] Loss: 1.97972 (semantic_loss: 0.03031, quant_loss: 1.94922, bit_balance_loss: 0.00019) batch_time=0.35197 
Train Epoch: 5 [177/250 22656/32000 (71%)] Loss: 1.97900 (semantic_loss: 0.02863, quant_loss: 1.95020, bit_balance_loss: 0.00018) batch_time=0.34012 
Train Epoch: 5 [188/250 24064/32000 (75%)] Loss: 1.97848 (semantic_loss: 0.02908, quant_loss: 1.94922, bit_balance_loss: 0.00018) batch_time=0.32895 
Train Epoch: 5 [199/250 25472/32000 (80%)] Loss: 1.97903 (semantic_loss: 0.02963, quant_loss: 1.94922, bit_balance_loss: 0.00018) batch_time=0.33839 
Train Epoch: 5 [210/250 26880/32000 (84%)] Loss: 1.97972 (semantic_loss: 0.02935, quant_loss: 1.95020, bit_balance_loss: 0.00018) batch_time=0.36511 
Train Epoch: 5 [221/250 28288/32000 (88%)] Loss: 1.97850 (semantic_loss: 0.02911, quant_loss: 1.94922, bit_balance_loss: 0.00018) batch_time=0.33600 
Train Epoch: 5 [232/250 29696/32000 (93%)] Loss: 1.97782 (semantic_loss: 0.02843, quant_loss: 1.94922, bit_balance_loss: 0.00018) batch_time=0.34379 
Train Epoch: 5 [243/250 31104/32000 (97%)] Loss: 1.97941 (semantic_loss: 0.03001, quant_loss: 1.94922, bit_balance_loss: 0.00017) batch_time=0.38014 
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/DCMH_MSRVTT_1kA/checkpoint-epoch5.pth ...
Done in 12.206s
Updating 'best' checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/DCMH_MSRVTT_1kA/checkpoint-epoch5.pth ...
Done in 16.068s
removing stale ckpt [epoch 4] [took 0.00s]
 epoch          : 5
 loss           : 1.9797719712257384
 learning_rate  : 4.072531249999999e-05
 n_samples      : 160000
 n_steps        : 1250
 MSRVTT_jsfusion_test/t2v_metrics/R1: 6.8
 MSRVTT_jsfusion_test/t2v_metrics/R5: 22.1
 MSRVTT_jsfusion_test/t2v_metrics/R10: 32.9
 MSRVTT_jsfusion_test/t2v_metrics/R50: 69.3
 MSRVTT_jsfusion_test/t2v_metrics/MedR: 21.5
 MSRVTT_jsfusion_test/t2v_metrics/MeanR: 61.515
 MSRVTT_jsfusion_test/t2v_metrics/geometric_mean_R1-R5-R10: 17.035924032637332
 MSRVTT_jsfusion_test/v2t_metrics/R1: 4.9
 MSRVTT_jsfusion_test/v2t_metrics/R5: 20.3
 MSRVTT_jsfusion_test/v2t_metrics/R10: 32.5
 MSRVTT_jsfusion_test/v2t_metrics/R50: 70.5
 MSRVTT_jsfusion_test/v2t_metrics/MedR: 20.0
 MSRVTT_jsfusion_test/v2t_metrics/MeanR: 60.411
 MSRVTT_jsfusion_test/v2t_metrics/geometric_mean_R1-R5-R10: 14.78626525876031
 mnt_best       : 17.035924032637332
 not_improved_count: 0
Train Epoch: 6 [1/250 128/32000 (0%)] Loss: 1.97860 (semantic_loss: 0.02823, quant_loss: 1.95020, bit_balance_loss: 0.00018) batch_time=25.66846 
Train Epoch: 6 [12/250 1536/32000 (5%)] Loss: 1.97635 (semantic_loss: 0.02696, quant_loss: 1.94922, bit_balance_loss: 0.00017) batch_time=0.32844 
Train Epoch: 6 [23/250 2944/32000 (9%)] Loss: 1.97772 (semantic_loss: 0.02832, quant_loss: 1.94922, bit_balance_loss: 0.00017) batch_time=0.33309 
Train Epoch: 6 [34/250 4352/32000 (14%)] Loss: 1.98121 (semantic_loss: 0.02986, quant_loss: 1.95117, bit_balance_loss: 0.00017) batch_time=0.34432 
Train Epoch: 6 [45/250 5760/32000 (18%)] Loss: 1.97765 (semantic_loss: 0.02825, quant_loss: 1.94922, bit_balance_loss: 0.00017) batch_time=0.33056 
Train Epoch: 6 [56/250 7168/32000 (22%)] Loss: 1.97847 (semantic_loss: 0.02908, quant_loss: 1.94922, bit_balance_loss: 0.00017) batch_time=0.35378 
Train Epoch: 6 [67/250 8576/32000 (27%)] Loss: 1.97796 (semantic_loss: 0.02760, quant_loss: 1.95020, bit_balance_loss: 0.00017) batch_time=0.35475 
Train Epoch: 6 [78/250 9984/32000 (31%)] Loss: 1.97894 (semantic_loss: 0.02955, quant_loss: 1.94922, bit_balance_loss: 0.00017) batch_time=0.32255 
Train Epoch: 6 [89/250 11392/32000 (36%)] Loss: 1.97942 (semantic_loss: 0.03003, quant_loss: 1.94922, bit_balance_loss: 0.00017) batch_time=0.33031 
Train Epoch: 6 [100/250 12800/32000 (40%)] Loss: 1.97844 (semantic_loss: 0.02905, quant_loss: 1.94922, bit_balance_loss: 0.00017) batch_time=0.32299 
Train Epoch: 6 [111/250 14208/32000 (44%)] Loss: 1.97894 (semantic_loss: 0.02858, quant_loss: 1.95020, bit_balance_loss: 0.00016) batch_time=0.32768 
Train Epoch: 6 [122/250 15616/32000 (49%)] Loss: 1.97868 (semantic_loss: 0.02832, quant_loss: 1.95020, bit_balance_loss: 0.00016) batch_time=0.34093 
Train Epoch: 6 [133/250 17024/32000 (53%)] Loss: 1.97759 (semantic_loss: 0.02723, quant_loss: 1.95020, bit_balance_loss: 0.00016) batch_time=2.03154 
Train Epoch: 6 [144/250 18432/32000 (58%)] Loss: 1.97680 (semantic_loss: 0.02742, quant_loss: 1.94922, bit_balance_loss: 0.00016) batch_time=1.97644 
Train Epoch: 6 [155/250 19840/32000 (62%)] Loss: 1.97766 (semantic_loss: 0.02731, quant_loss: 1.95020, bit_balance_loss: 0.00016) batch_time=0.33963 
Train Epoch: 6 [166/250 21248/32000 (66%)] Loss: 1.97568 (semantic_loss: 0.02630, quant_loss: 1.94922, bit_balance_loss: 0.00016) batch_time=0.33865 
Train Epoch: 6 [177/250 22656/32000 (71%)] Loss: 1.97842 (semantic_loss: 0.02807, quant_loss: 1.95020, bit_balance_loss: 0.00016) batch_time=0.34252 
Train Epoch: 6 [188/250 24064/32000 (75%)] Loss: 1.97919 (semantic_loss: 0.02884, quant_loss: 1.95020, bit_balance_loss: 0.00016) batch_time=0.32597 
Train Epoch: 6 [199/250 25472/32000 (80%)] Loss: 1.97680 (semantic_loss: 0.02743, quant_loss: 1.94922, bit_balance_loss: 0.00016) batch_time=2.47898 
Train Epoch: 6 [210/250 26880/32000 (84%)] Loss: 1.97966 (semantic_loss: 0.02931, quant_loss: 1.95020, bit_balance_loss: 0.00016) batch_time=0.34378 
Train Epoch: 6 [221/250 28288/32000 (88%)] Loss: 1.97708 (semantic_loss: 0.02770, quant_loss: 1.94922, bit_balance_loss: 0.00016) batch_time=1.62352 
Train Epoch: 6 [232/250 29696/32000 (93%)] Loss: 1.97571 (semantic_loss: 0.02634, quant_loss: 1.94922, bit_balance_loss: 0.00015) batch_time=0.34669 
Train Epoch: 6 [243/250 31104/32000 (97%)] Loss: 1.97633 (semantic_loss: 0.02696, quant_loss: 1.94922, bit_balance_loss: 0.00016) batch_time=0.32764 
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/DCMH_MSRVTT_1kA/checkpoint-epoch6.pth ...
Done in 3.913s
Updating 'best' checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/DCMH_MSRVTT_1kA/checkpoint-epoch6.pth ...
Done in 7.607s
removing stale ckpt [epoch 5] [took 0.00s]
 epoch          : 6
 loss           : 1.9776311101913453
 learning_rate  : 3.868904687499999e-05
 n_samples      : 192000
 n_steps        : 1500
 MSRVTT_jsfusion_test/t2v_metrics/R1: 7.4
 MSRVTT_jsfusion_test/t2v_metrics/R5: 25.8
 MSRVTT_jsfusion_test/t2v_metrics/R10: 39.9
 MSRVTT_jsfusion_test/t2v_metrics/R50: 76.1
 MSRVTT_jsfusion_test/t2v_metrics/MedR: 17.0
 MSRVTT_jsfusion_test/t2v_metrics/MeanR: 50.0435
 MSRVTT_jsfusion_test/t2v_metrics/geometric_mean_R1-R5-R10: 19.676209611080754
 MSRVTT_jsfusion_test/v2t_metrics/R1: 7.1
 MSRVTT_jsfusion_test/v2t_metrics/R5: 26.0
 MSRVTT_jsfusion_test/v2t_metrics/R10: 39.7
 MSRVTT_jsfusion_test/v2t_metrics/R50: 75.1
 MSRVTT_jsfusion_test/v2t_metrics/MedR: 16.5
 MSRVTT_jsfusion_test/v2t_metrics/MeanR: 50.818
 MSRVTT_jsfusion_test/v2t_metrics/geometric_mean_R1-R5-R10: 19.4240923621854
 mnt_best       : 19.676209611080754
 not_improved_count: 0
Train Epoch: 7 [1/250 128/32000 (0%)] Loss: 1.97488 (semantic_loss: 0.02551, quant_loss: 1.94922, bit_balance_loss: 0.00016) batch_time=29.61169 
Train Epoch: 7 [12/250 1536/32000 (5%)] Loss: 1.97713 (semantic_loss: 0.02775, quant_loss: 1.94922, bit_balance_loss: 0.00016) batch_time=0.45703 
Train Epoch: 7 [23/250 2944/32000 (9%)] Loss: 1.97719 (semantic_loss: 0.02684, quant_loss: 1.95020, bit_balance_loss: 0.00015) batch_time=0.34296 
Train Epoch: 7 [34/250 4352/32000 (14%)] Loss: 1.97592 (semantic_loss: 0.02655, quant_loss: 1.94922, bit_balance_loss: 0.00015) batch_time=1.57383 
Train Epoch: 7 [45/250 5760/32000 (18%)] Loss: 1.97617 (semantic_loss: 0.02583, quant_loss: 1.95020, bit_balance_loss: 0.00015) batch_time=0.34423 
Train Epoch: 7 [56/250 7168/32000 (22%)] Loss: 1.97494 (semantic_loss: 0.02557, quant_loss: 1.94922, bit_balance_loss: 0.00015) batch_time=0.33076 
Train Epoch: 7 [67/250 8576/32000 (27%)] Loss: 1.97640 (semantic_loss: 0.02605, quant_loss: 1.95020, bit_balance_loss: 0.00016) batch_time=0.88075 
Train Epoch: 7 [78/250 9984/32000 (31%)] Loss: 1.97757 (semantic_loss: 0.02723, quant_loss: 1.95020, bit_balance_loss: 0.00015) batch_time=0.34393 
Train Epoch: 7 [89/250 11392/32000 (36%)] Loss: 1.97702 (semantic_loss: 0.02765, quant_loss: 1.94922, bit_balance_loss: 0.00015) batch_time=0.33866 
Train Epoch: 7 [100/250 12800/32000 (40%)] Loss: 1.97844 (semantic_loss: 0.02810, quant_loss: 1.95020, bit_balance_loss: 0.00015) batch_time=0.35191 
Train Epoch: 7 [111/250 14208/32000 (44%)] Loss: 1.97608 (semantic_loss: 0.02573, quant_loss: 1.95020, bit_balance_loss: 0.00015) batch_time=0.35797 
Train Epoch: 7 [122/250 15616/32000 (49%)] Loss: 1.97728 (semantic_loss: 0.02694, quant_loss: 1.95020, bit_balance_loss: 0.00015) batch_time=0.34227 
Train Epoch: 7 [133/250 17024/32000 (53%)] Loss: 1.97593 (semantic_loss: 0.02558, quant_loss: 1.95020, bit_balance_loss: 0.00015) batch_time=0.33701 
Train Epoch: 7 [144/250 18432/32000 (58%)] Loss: 1.97578 (semantic_loss: 0.02641, quant_loss: 1.94922, bit_balance_loss: 0.00015) batch_time=0.32540 
Train Epoch: 7 [155/250 19840/32000 (62%)] Loss: 1.97670 (semantic_loss: 0.02733, quant_loss: 1.94922, bit_balance_loss: 0.00015) batch_time=0.32619 
Train Epoch: 7 [166/250 21248/32000 (66%)] Loss: 1.97527 (semantic_loss: 0.02492, quant_loss: 1.95020, bit_balance_loss: 0.00015) batch_time=0.35803 
Train Epoch: 7 [177/250 22656/32000 (71%)] Loss: 1.97558 (semantic_loss: 0.02622, quant_loss: 1.94922, bit_balance_loss: 0.00015) batch_time=0.37538 
Train Epoch: 7 [188/250 24064/32000 (75%)] Loss: 1.97342 (semantic_loss: 0.02503, quant_loss: 1.94824, bit_balance_loss: 0.00015) batch_time=0.32589 
Train Epoch: 7 [199/250 25472/32000 (80%)] Loss: 1.97566 (semantic_loss: 0.02629, quant_loss: 1.94922, bit_balance_loss: 0.00015) batch_time=0.36427 
Train Epoch: 7 [210/250 26880/32000 (84%)] Loss: 1.97432 (semantic_loss: 0.02397, quant_loss: 1.95020, bit_balance_loss: 0.00015) batch_time=0.55100 
Train Epoch: 7 [221/250 28288/32000 (88%)] Loss: 1.97547 (semantic_loss: 0.02513, quant_loss: 1.95020, bit_balance_loss: 0.00015) batch_time=0.33333 
Train Epoch: 7 [232/250 29696/32000 (93%)] Loss: 1.97485 (semantic_loss: 0.02548, quant_loss: 1.94922, bit_balance_loss: 0.00015) batch_time=0.35949 
Train Epoch: 7 [243/250 31104/32000 (97%)] Loss: 1.97692 (semantic_loss: 0.02658, quant_loss: 1.95020, bit_balance_loss: 0.00015) batch_time=0.35162 
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/DCMH_MSRVTT_1kA/checkpoint-epoch7.pth ...
Done in 3.959s
Updating 'best' checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/DCMH_MSRVTT_1kA/checkpoint-epoch7.pth ...
Done in 7.767s
removing stale ckpt [epoch 6] [took 0.00s]
 epoch          : 7
 loss           : 1.9759862656593323
 learning_rate  : 3.675459453124999e-05
 n_samples      : 224000
 n_steps        : 1750
 MSRVTT_jsfusion_test/t2v_metrics/R1: 9.0
 MSRVTT_jsfusion_test/t2v_metrics/R5: 28.8
 MSRVTT_jsfusion_test/t2v_metrics/R10: 42.0
 MSRVTT_jsfusion_test/t2v_metrics/R50: 78.3
 MSRVTT_jsfusion_test/t2v_metrics/MedR: 15.0
 MSRVTT_jsfusion_test/t2v_metrics/MeanR: 45.1885
 MSRVTT_jsfusion_test/t2v_metrics/geometric_mean_R1-R5-R10: 22.162977005374003
 MSRVTT_jsfusion_test/v2t_metrics/R1: 8.7
 MSRVTT_jsfusion_test/v2t_metrics/R5: 29.3
 MSRVTT_jsfusion_test/v2t_metrics/R10: 42.5
 MSRVTT_jsfusion_test/v2t_metrics/R50: 77.5
 MSRVTT_jsfusion_test/v2t_metrics/MedR: 14.5
 MSRVTT_jsfusion_test/v2t_metrics/MeanR: 44.519
 MSRVTT_jsfusion_test/v2t_metrics/geometric_mean_R1-R5-R10: 22.127139184781417
 mnt_best       : 22.162977005374003
 not_improved_count: 0
Train Epoch: 8 [1/250 128/32000 (0%)] Loss: 1.97545 (semantic_loss: 0.02609, quant_loss: 1.94922, bit_balance_loss: 0.00015) batch_time=29.08181 
Train Epoch: 8 [12/250 1536/32000 (5%)] Loss: 1.97689 (semantic_loss: 0.02655, quant_loss: 1.95020, bit_balance_loss: 0.00015) batch_time=0.32351 
Train Epoch: 8 [23/250 2944/32000 (9%)] Loss: 1.97449 (semantic_loss: 0.02415, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.33379 
Train Epoch: 8 [34/250 4352/32000 (14%)] Loss: 1.97573 (semantic_loss: 0.02538, quant_loss: 1.95020, bit_balance_loss: 0.00015) batch_time=0.33053 
Train Epoch: 8 [45/250 5760/32000 (18%)] Loss: 1.97501 (semantic_loss: 0.02467, quant_loss: 1.95020, bit_balance_loss: 0.00015) batch_time=0.35077 
Train Epoch: 8 [56/250 7168/32000 (22%)] Loss: 1.97569 (semantic_loss: 0.02535, quant_loss: 1.95020, bit_balance_loss: 0.00015) batch_time=0.32053 
Train Epoch: 8 [67/250 8576/32000 (27%)] Loss: 1.97547 (semantic_loss: 0.02513, quant_loss: 1.95020, bit_balance_loss: 0.00015) batch_time=2.98766 
Train Epoch: 8 [78/250 9984/32000 (31%)] Loss: 1.97411 (semantic_loss: 0.02474, quant_loss: 1.94922, bit_balance_loss: 0.00015) batch_time=0.33794 
Train Epoch: 8 [89/250 11392/32000 (36%)] Loss: 1.97630 (semantic_loss: 0.02596, quant_loss: 1.95020, bit_balance_loss: 0.00015) batch_time=0.36877 
Train Epoch: 8 [100/250 12800/32000 (40%)] Loss: 1.97501 (semantic_loss: 0.02467, quant_loss: 1.95020, bit_balance_loss: 0.00015) batch_time=0.32742 
Train Epoch: 8 [111/250 14208/32000 (44%)] Loss: 1.97376 (semantic_loss: 0.02342, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.32047 
Train Epoch: 8 [122/250 15616/32000 (49%)] Loss: 1.97538 (semantic_loss: 0.02601, quant_loss: 1.94922, bit_balance_loss: 0.00015) batch_time=0.43797 
Train Epoch: 8 [133/250 17024/32000 (53%)] Loss: 1.97304 (semantic_loss: 0.02367, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.96069 
Train Epoch: 8 [144/250 18432/32000 (58%)] Loss: 1.97483 (semantic_loss: 0.02546, quant_loss: 1.94922, bit_balance_loss: 0.00015) batch_time=0.33601 
Train Epoch: 8 [155/250 19840/32000 (62%)] Loss: 1.97570 (semantic_loss: 0.02634, quant_loss: 1.94922, bit_balance_loss: 0.00015) batch_time=0.38556 
Train Epoch: 8 [166/250 21248/32000 (66%)] Loss: 1.97404 (semantic_loss: 0.02467, quant_loss: 1.94922, bit_balance_loss: 0.00015) batch_time=0.33069 
Train Epoch: 8 [177/250 22656/32000 (71%)] Loss: 1.97567 (semantic_loss: 0.02631, quant_loss: 1.94922, bit_balance_loss: 0.00015) batch_time=0.32924 
Train Epoch: 8 [188/250 24064/32000 (75%)] Loss: 1.97653 (semantic_loss: 0.02619, quant_loss: 1.95020, bit_balance_loss: 0.00015) batch_time=0.33155 
Train Epoch: 8 [199/250 25472/32000 (80%)] Loss: 1.97433 (semantic_loss: 0.02497, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.33886 
Train Epoch: 8 [210/250 26880/32000 (84%)] Loss: 1.97475 (semantic_loss: 0.02539, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.37317 
Train Epoch: 8 [221/250 28288/32000 (88%)] Loss: 1.97252 (semantic_loss: 0.02218, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.34071 
Train Epoch: 8 [232/250 29696/32000 (93%)] Loss: 1.97458 (semantic_loss: 0.02522, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.31998 
Train Epoch: 8 [243/250 31104/32000 (97%)] Loss: 1.97380 (semantic_loss: 0.02444, quant_loss: 1.94922, bit_balance_loss: 0.00015) batch_time=0.32104 
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/DCMH_MSRVTT_1kA/checkpoint-epoch8.pth ...
Done in 18.063s
Updating 'best' checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/DCMH_MSRVTT_1kA/checkpoint-epoch8.pth ...
Done in 21.734s
removing stale ckpt [epoch 7] [took 0.00s]
 epoch          : 8
 loss           : 1.974881987094879
 learning_rate  : 3.4916864804687486e-05
 n_samples      : 256000
 n_steps        : 2000
 MSRVTT_jsfusion_test/t2v_metrics/R1: 10.5
 MSRVTT_jsfusion_test/t2v_metrics/R5: 30.3
 MSRVTT_jsfusion_test/t2v_metrics/R10: 43.6
 MSRVTT_jsfusion_test/t2v_metrics/R50: 77.7
 MSRVTT_jsfusion_test/t2v_metrics/MedR: 14.0
 MSRVTT_jsfusion_test/t2v_metrics/MeanR: 44.226
 MSRVTT_jsfusion_test/t2v_metrics/geometric_mean_R1-R5-R10: 24.02736462053925
 MSRVTT_jsfusion_test/v2t_metrics/R1: 9.9
 MSRVTT_jsfusion_test/v2t_metrics/R5: 30.7
 MSRVTT_jsfusion_test/v2t_metrics/R10: 44.4
 MSRVTT_jsfusion_test/v2t_metrics/R50: 79.9
 MSRVTT_jsfusion_test/v2t_metrics/MedR: 13.0
 MSRVTT_jsfusion_test/v2t_metrics/MeanR: 43.1955
 MSRVTT_jsfusion_test/v2t_metrics/geometric_mean_R1-R5-R10: 23.807777040868576
 mnt_best       : 24.02736462053925
 not_improved_count: 0
Train Epoch: 9 [1/250 128/32000 (0%)] Loss: 1.97520 (semantic_loss: 0.02486, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=25.96196 
Train Epoch: 9 [12/250 1536/32000 (5%)] Loss: 1.97404 (semantic_loss: 0.02468, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=2.22275 
Train Epoch: 9 [23/250 2944/32000 (9%)] Loss: 1.97166 (semantic_loss: 0.02229, quant_loss: 1.94922, bit_balance_loss: 0.00015) batch_time=0.71324 
Train Epoch: 9 [34/250 4352/32000 (14%)] Loss: 1.97284 (semantic_loss: 0.02347, quant_loss: 1.94922, bit_balance_loss: 0.00015) batch_time=0.56360 
Train Epoch: 9 [45/250 5760/32000 (18%)] Loss: 1.97120 (semantic_loss: 0.02184, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.33420 
Train Epoch: 9 [56/250 7168/32000 (22%)] Loss: 1.97331 (semantic_loss: 0.02395, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.32978 
Train Epoch: 9 [67/250 8576/32000 (27%)] Loss: 1.97237 (semantic_loss: 0.02301, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.32839 
Train Epoch: 9 [78/250 9984/32000 (31%)] Loss: 1.97200 (semantic_loss: 0.02166, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.33374 
Train Epoch: 9 [89/250 11392/32000 (36%)] Loss: 1.97264 (semantic_loss: 0.02327, quant_loss: 1.94922, bit_balance_loss: 0.00015) batch_time=0.35652 
Train Epoch: 9 [100/250 12800/32000 (40%)] Loss: 1.97335 (semantic_loss: 0.02301, quant_loss: 1.95020, bit_balance_loss: 0.00015) batch_time=0.33607 
Train Epoch: 9 [111/250 14208/32000 (44%)] Loss: 1.97382 (semantic_loss: 0.02446, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.35435 
Train Epoch: 9 [122/250 15616/32000 (49%)] Loss: 1.97420 (semantic_loss: 0.02484, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.37089 
Train Epoch: 9 [133/250 17024/32000 (53%)] Loss: 1.97386 (semantic_loss: 0.02352, quant_loss: 1.95020, bit_balance_loss: 0.00015) batch_time=0.33946 
Train Epoch: 9 [144/250 18432/32000 (58%)] Loss: 1.97422 (semantic_loss: 0.02388, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.37548 
Train Epoch: 9 [155/250 19840/32000 (62%)] Loss: 1.97527 (semantic_loss: 0.02493, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.33815 
Train Epoch: 9 [166/250 21248/32000 (66%)] Loss: 1.97331 (semantic_loss: 0.02395, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.35505 
Train Epoch: 9 [177/250 22656/32000 (71%)] Loss: 1.97337 (semantic_loss: 0.02304, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.33342 
Train Epoch: 9 [188/250 24064/32000 (75%)] Loss: 1.97193 (semantic_loss: 0.02257, quant_loss: 1.94922, bit_balance_loss: 0.00015) batch_time=0.33307 
Train Epoch: 9 [199/250 25472/32000 (80%)] Loss: 1.97539 (semantic_loss: 0.02505, quant_loss: 1.95020, bit_balance_loss: 0.00015) batch_time=0.32648 
Train Epoch: 9 [210/250 26880/32000 (84%)] Loss: 1.97300 (semantic_loss: 0.02363, quant_loss: 1.94922, bit_balance_loss: 0.00015) batch_time=0.40197 
Train Epoch: 9 [221/250 28288/32000 (88%)] Loss: 1.97241 (semantic_loss: 0.02305, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.34184 
Train Epoch: 9 [232/250 29696/32000 (93%)] Loss: 1.97507 (semantic_loss: 0.02474, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.34223 
Train Epoch: 9 [243/250 31104/32000 (97%)] Loss: 1.97392 (semantic_loss: 0.02358, quant_loss: 1.95020, bit_balance_loss: 0.00015) batch_time=0.34206 
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/DCMH_MSRVTT_1kA/checkpoint-epoch9.pth ...
Done in 3.798s
Updating 'best' checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/DCMH_MSRVTT_1kA/checkpoint-epoch9.pth ...
Done in 7.457s
removing stale ckpt [epoch 8] [took 0.00s]
 epoch          : 9
 loss           : 1.9737976188659667
 learning_rate  : 3.317102156445311e-05
 n_samples      : 288000
 n_steps        : 2250
 MSRVTT_jsfusion_test/t2v_metrics/R1: 10.4
 MSRVTT_jsfusion_test/t2v_metrics/R5: 34.5
 MSRVTT_jsfusion_test/t2v_metrics/R10: 47.9
 MSRVTT_jsfusion_test/t2v_metrics/R50: 79.6
 MSRVTT_jsfusion_test/t2v_metrics/MedR: 12.0
 MSRVTT_jsfusion_test/t2v_metrics/MeanR: 42.0315
 MSRVTT_jsfusion_test/t2v_metrics/geometric_mean_R1-R5-R10: 25.806512387625688
 MSRVTT_jsfusion_test/v2t_metrics/R1: 12.1
 MSRVTT_jsfusion_test/v2t_metrics/R5: 35.4
 MSRVTT_jsfusion_test/v2t_metrics/R10: 49.1
 MSRVTT_jsfusion_test/v2t_metrics/R50: 80.9
 MSRVTT_jsfusion_test/v2t_metrics/MedR: 11.0
 MSRVTT_jsfusion_test/v2t_metrics/MeanR: 40.673
 MSRVTT_jsfusion_test/v2t_metrics/geometric_mean_R1-R5-R10: 27.603026868201866
 mnt_best       : 25.806512387625688
 not_improved_count: 0
Train Epoch: 10 [1/250 128/32000 (0%)] Loss: 1.97439 (semantic_loss: 0.02405, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=34.64514 
Train Epoch: 10 [12/250 1536/32000 (5%)] Loss: 1.97377 (semantic_loss: 0.02440, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.32886 
Train Epoch: 10 [23/250 2944/32000 (9%)] Loss: 1.97356 (semantic_loss: 0.02322, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.34312 
Train Epoch: 10 [34/250 4352/32000 (14%)] Loss: 1.97361 (semantic_loss: 0.02327, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.36421 
Train Epoch: 10 [45/250 5760/32000 (18%)] Loss: 1.97392 (semantic_loss: 0.02358, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.34345 
Train Epoch: 10 [56/250 7168/32000 (22%)] Loss: 1.97434 (semantic_loss: 0.02400, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.33982 
Train Epoch: 10 [67/250 8576/32000 (27%)] Loss: 1.97192 (semantic_loss: 0.02256, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.32800 
Train Epoch: 10 [78/250 9984/32000 (31%)] Loss: 1.97259 (semantic_loss: 0.02226, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=2.71621 
Train Epoch: 10 [89/250 11392/32000 (36%)] Loss: 1.97659 (semantic_loss: 0.02625, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=1.39139 
Train Epoch: 10 [100/250 12800/32000 (40%)] Loss: 1.97476 (semantic_loss: 0.02442, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.34165 
Train Epoch: 10 [111/250 14208/32000 (44%)] Loss: 1.97129 (semantic_loss: 0.02193, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.34638 
Train Epoch: 10 [122/250 15616/32000 (49%)] Loss: 1.97349 (semantic_loss: 0.02412, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.33273 
Train Epoch: 10 [133/250 17024/32000 (53%)] Loss: 1.97347 (semantic_loss: 0.02313, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.32621 
Train Epoch: 10 [144/250 18432/32000 (58%)] Loss: 1.97256 (semantic_loss: 0.02222, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.32883 
Train Epoch: 10 [155/250 19840/32000 (62%)] Loss: 1.97290 (semantic_loss: 0.02256, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.32626 
Train Epoch: 10 [166/250 21248/32000 (66%)] Loss: 1.97613 (semantic_loss: 0.02580, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.33112 
Train Epoch: 10 [177/250 22656/32000 (71%)] Loss: 1.97145 (semantic_loss: 0.02209, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.33426 
Train Epoch: 10 [188/250 24064/32000 (75%)] Loss: 1.97271 (semantic_loss: 0.02335, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.34032 
Train Epoch: 10 [199/250 25472/32000 (80%)] Loss: 1.97232 (semantic_loss: 0.02198, quant_loss: 1.95020, bit_balance_loss: 0.00015) batch_time=0.33800 
Train Epoch: 10 [210/250 26880/32000 (84%)] Loss: 1.97365 (semantic_loss: 0.02331, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.32796 
Train Epoch: 10 [221/250 28288/32000 (88%)] Loss: 1.97211 (semantic_loss: 0.02275, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.34693 
Train Epoch: 10 [232/250 29696/32000 (93%)] Loss: 1.97313 (semantic_loss: 0.02280, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.33457 
Train Epoch: 10 [243/250 31104/32000 (97%)] Loss: 1.97353 (semantic_loss: 0.02319, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.44650 
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/DCMH_MSRVTT_1kA/checkpoint-epoch10.pth ...
Done in 3.786s
Updating 'best' checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/DCMH_MSRVTT_1kA/checkpoint-epoch10.pth ...
Done in 7.617s
removing stale ckpt [epoch 9] [took 0.00s]
 epoch          : 10
 loss           : 1.9729892263412476
 learning_rate  : 3.151247048623045e-05
 n_samples      : 320000
 n_steps        : 2500
 MSRVTT_jsfusion_test/t2v_metrics/R1: 12.1
 MSRVTT_jsfusion_test/t2v_metrics/R5: 33.2
 MSRVTT_jsfusion_test/t2v_metrics/R10: 48.2
 MSRVTT_jsfusion_test/t2v_metrics/R50: 80.6
 MSRVTT_jsfusion_test/t2v_metrics/MedR: 11.5
 MSRVTT_jsfusion_test/t2v_metrics/MeanR: 38.947
 MSRVTT_jsfusion_test/t2v_metrics/geometric_mean_R1-R5-R10: 26.852836285912055
 MSRVTT_jsfusion_test/v2t_metrics/R1: 11.4
 MSRVTT_jsfusion_test/v2t_metrics/R5: 33.4
 MSRVTT_jsfusion_test/v2t_metrics/R10: 48.2
 MSRVTT_jsfusion_test/v2t_metrics/R50: 81.8
 MSRVTT_jsfusion_test/v2t_metrics/MedR: 11.0
 MSRVTT_jsfusion_test/v2t_metrics/MeanR: 37.8105
 MSRVTT_jsfusion_test/v2t_metrics/geometric_mean_R1-R5-R10: 26.377448602061047
 mnt_best       : 26.852836285912055
 not_improved_count: 0
Train Epoch: 11 [1/250 128/32000 (0%)] Loss: 1.97116 (semantic_loss: 0.02180, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=31.32738 
Train Epoch: 11 [12/250 1536/32000 (5%)] Loss: 1.97347 (semantic_loss: 0.02313, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.34292 
Train Epoch: 11 [23/250 2944/32000 (9%)] Loss: 1.97150 (semantic_loss: 0.02116, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=2.44624 
Train Epoch: 11 [34/250 4352/32000 (14%)] Loss: 1.97387 (semantic_loss: 0.02353, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.36694 
Train Epoch: 11 [45/250 5760/32000 (18%)] Loss: 1.97233 (semantic_loss: 0.02297, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.33960 
Train Epoch: 11 [56/250 7168/32000 (22%)] Loss: 1.97325 (semantic_loss: 0.02291, quant_loss: 1.95020, bit_balance_loss: 0.00015) batch_time=0.37048 
Train Epoch: 11 [67/250 8576/32000 (27%)] Loss: 1.97339 (semantic_loss: 0.02305, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.34649 
Train Epoch: 11 [78/250 9984/32000 (31%)] Loss: 1.97259 (semantic_loss: 0.02323, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.36936 
Train Epoch: 11 [89/250 11392/32000 (36%)] Loss: 1.97218 (semantic_loss: 0.02184, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.33934 
Train Epoch: 11 [100/250 12800/32000 (40%)] Loss: 1.97443 (semantic_loss: 0.02409, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.34164 
Train Epoch: 11 [111/250 14208/32000 (44%)] Loss: 1.97378 (semantic_loss: 0.02345, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.45050 
Train Epoch: 11 [122/250 15616/32000 (49%)] Loss: 1.97223 (semantic_loss: 0.02288, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.34065 
Train Epoch: 11 [133/250 17024/32000 (53%)] Loss: 1.97203 (semantic_loss: 0.02268, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.33708 
Train Epoch: 11 [144/250 18432/32000 (58%)] Loss: 1.97099 (semantic_loss: 0.02163, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.34635 
Train Epoch: 11 [155/250 19840/32000 (62%)] Loss: 1.97121 (semantic_loss: 0.02088, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.38816 
Train Epoch: 11 [166/250 21248/32000 (66%)] Loss: 1.97042 (semantic_loss: 0.02105, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.34196 
Train Epoch: 11 [177/250 22656/32000 (71%)] Loss: 1.97241 (semantic_loss: 0.02305, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.80074 
Train Epoch: 11 [188/250 24064/32000 (75%)] Loss: 1.97240 (semantic_loss: 0.02303, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.33488 
Train Epoch: 11 [199/250 25472/32000 (80%)] Loss: 1.97072 (semantic_loss: 0.02136, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.34533 
Train Epoch: 11 [210/250 26880/32000 (84%)] Loss: 1.97380 (semantic_loss: 0.02444, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.32803 
Train Epoch: 11 [221/250 28288/32000 (88%)] Loss: 1.97190 (semantic_loss: 0.02254, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.33899 
Train Epoch: 11 [232/250 29696/32000 (93%)] Loss: 1.97052 (semantic_loss: 0.02117, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.33738 
Train Epoch: 11 [243/250 31104/32000 (97%)] Loss: 1.97281 (semantic_loss: 0.02247, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.58384 
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/DCMH_MSRVTT_1kA/checkpoint-epoch11.pth ...
Done in 3.895s
Updating 'best' checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/DCMH_MSRVTT_1kA/checkpoint-epoch11.pth ...
Done in 7.611s
removing stale ckpt [epoch 10] [took 0.00s]
 epoch          : 11
 loss           : 1.9723797092437745
 learning_rate  : 2.993684696191893e-05
 n_samples      : 352000
 n_steps        : 2750
 MSRVTT_jsfusion_test/t2v_metrics/R1: 12.3
 MSRVTT_jsfusion_test/t2v_metrics/R5: 35.4
 MSRVTT_jsfusion_test/t2v_metrics/R10: 49.6
 MSRVTT_jsfusion_test/t2v_metrics/R50: 80.6
 MSRVTT_jsfusion_test/t2v_metrics/MedR: 11.0
 MSRVTT_jsfusion_test/t2v_metrics/MeanR: 39.242
 MSRVTT_jsfusion_test/t2v_metrics/geometric_mean_R1-R5-R10: 27.848171402382903
 MSRVTT_jsfusion_test/v2t_metrics/R1: 14.1
 MSRVTT_jsfusion_test/v2t_metrics/R5: 36.6
 MSRVTT_jsfusion_test/v2t_metrics/R10: 50.1
 MSRVTT_jsfusion_test/v2t_metrics/R50: 82.1
 MSRVTT_jsfusion_test/v2t_metrics/MedR: 10.25
 MSRVTT_jsfusion_test/v2t_metrics/MeanR: 38.26
 MSRVTT_jsfusion_test/v2t_metrics/geometric_mean_R1-R5-R10: 29.569635742119843
 mnt_best       : 27.848171402382903
 not_improved_count: 0
Train Epoch: 12 [1/250 128/32000 (0%)] Loss: 1.97174 (semantic_loss: 0.02141, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=32.12269 
Train Epoch: 12 [12/250 1536/32000 (5%)] Loss: 1.97271 (semantic_loss: 0.02237, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.35051 
Train Epoch: 12 [23/250 2944/32000 (9%)] Loss: 1.96907 (semantic_loss: 0.01972, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.33783 
Train Epoch: 12 [34/250 4352/32000 (14%)] Loss: 1.97050 (semantic_loss: 0.02114, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.35880 
Train Epoch: 12 [45/250 5760/32000 (18%)] Loss: 1.97198 (semantic_loss: 0.02165, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.35126 
Train Epoch: 12 [56/250 7168/32000 (22%)] Loss: 1.97487 (semantic_loss: 0.02453, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.33884 
Train Epoch: 12 [67/250 8576/32000 (27%)] Loss: 1.97247 (semantic_loss: 0.02214, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.32716 
Train Epoch: 12 [78/250 9984/32000 (31%)] Loss: 1.97147 (semantic_loss: 0.02113, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.35572 
Train Epoch: 12 [89/250 11392/32000 (36%)] Loss: 1.97206 (semantic_loss: 0.02172, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.34481 
Train Epoch: 12 [100/250 12800/32000 (40%)] Loss: 1.97225 (semantic_loss: 0.02290, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.34446 
Train Epoch: 12 [111/250 14208/32000 (44%)] Loss: 1.97123 (semantic_loss: 0.02285, quant_loss: 1.94824, bit_balance_loss: 0.00014) batch_time=0.33387 
Train Epoch: 12 [122/250 15616/32000 (49%)] Loss: 1.97147 (semantic_loss: 0.02113, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.33942 
Train Epoch: 12 [133/250 17024/32000 (53%)] Loss: 1.97107 (semantic_loss: 0.02171, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.33627 
Train Epoch: 12 [144/250 18432/32000 (58%)] Loss: 1.97092 (semantic_loss: 0.02156, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.33145 
Train Epoch: 12 [155/250 19840/32000 (62%)] Loss: 1.97314 (semantic_loss: 0.02281, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.33930 
Train Epoch: 12 [166/250 21248/32000 (66%)] Loss: 1.97207 (semantic_loss: 0.02173, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.33331 
Train Epoch: 12 [177/250 22656/32000 (71%)] Loss: 1.97145 (semantic_loss: 0.02209, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.35273 
Train Epoch: 12 [188/250 24064/32000 (75%)] Loss: 1.97302 (semantic_loss: 0.02268, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.32924 
Train Epoch: 12 [199/250 25472/32000 (80%)] Loss: 1.97107 (semantic_loss: 0.02171, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.35578 
Train Epoch: 12 [210/250 26880/32000 (84%)] Loss: 1.97239 (semantic_loss: 0.02206, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.35270 
Train Epoch: 12 [221/250 28288/32000 (88%)] Loss: 1.97221 (semantic_loss: 0.02187, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.36533 
Train Epoch: 12 [232/250 29696/32000 (93%)] Loss: 1.97024 (semantic_loss: 0.01991, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.36974 
Train Epoch: 12 [243/250 31104/32000 (97%)] Loss: 1.97141 (semantic_loss: 0.02108, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.33004 
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/DCMH_MSRVTT_1kA/checkpoint-epoch12.pth ...
Done in 3.964s
Updating 'best' checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/DCMH_MSRVTT_1kA/checkpoint-epoch12.pth ...
Done in 8.041s
removing stale ckpt [epoch 11] [took 0.00s]
 epoch          : 12
 loss           : 1.9716937117576598
 learning_rate  : 2.844000461382298e-05
 n_samples      : 384000
 n_steps        : 3000
 MSRVTT_jsfusion_test/t2v_metrics/R1: 12.5
 MSRVTT_jsfusion_test/t2v_metrics/R5: 36.2
 MSRVTT_jsfusion_test/t2v_metrics/R10: 50.7
 MSRVTT_jsfusion_test/t2v_metrics/R50: 82.1
 MSRVTT_jsfusion_test/t2v_metrics/MedR: 10.0
 MSRVTT_jsfusion_test/t2v_metrics/MeanR: 36.4805
 MSRVTT_jsfusion_test/t2v_metrics/geometric_mean_R1-R5-R10: 28.414641494846443
 MSRVTT_jsfusion_test/v2t_metrics/R1: 12.4
 MSRVTT_jsfusion_test/v2t_metrics/R5: 38.6
 MSRVTT_jsfusion_test/v2t_metrics/R10: 51.9
 MSRVTT_jsfusion_test/v2t_metrics/R50: 81.6
 MSRVTT_jsfusion_test/v2t_metrics/MedR: 10.0
 MSRVTT_jsfusion_test/v2t_metrics/MeanR: 36.6785
 MSRVTT_jsfusion_test/v2t_metrics/geometric_mean_R1-R5-R10: 29.178219198647007
 mnt_best       : 28.414641494846443
 not_improved_count: 0
Train Epoch: 13 [1/250 128/32000 (0%)] Loss: 1.97230 (semantic_loss: 0.02196, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=27.74543 
Train Epoch: 13 [12/250 1536/32000 (5%)] Loss: 1.97160 (semantic_loss: 0.02127, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.36037 
Train Epoch: 13 [23/250 2944/32000 (9%)] Loss: 1.97128 (semantic_loss: 0.02192, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.36287 
Train Epoch: 13 [34/250 4352/32000 (14%)] Loss: 1.97107 (semantic_loss: 0.02073, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.71264 
Train Epoch: 13 [45/250 5760/32000 (18%)] Loss: 1.97082 (semantic_loss: 0.02049, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.34811 
Train Epoch: 13 [56/250 7168/32000 (22%)] Loss: 1.97025 (semantic_loss: 0.02089, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.34717 
Train Epoch: 13 [67/250 8576/32000 (27%)] Loss: 1.97294 (semantic_loss: 0.02261, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.36064 
Train Epoch: 13 [78/250 9984/32000 (31%)] Loss: 1.97024 (semantic_loss: 0.02089, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.35638 
Train Epoch: 13 [89/250 11392/32000 (36%)] Loss: 1.96851 (semantic_loss: 0.01915, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.36998 
Train Epoch: 13 [100/250 12800/32000 (40%)] Loss: 1.97192 (semantic_loss: 0.02256, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.34756 
Train Epoch: 13 [111/250 14208/32000 (44%)] Loss: 1.97054 (semantic_loss: 0.02021, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.36122 
Train Epoch: 13 [122/250 15616/32000 (49%)] Loss: 1.97308 (semantic_loss: 0.02275, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.34918 
Train Epoch: 13 [133/250 17024/32000 (53%)] Loss: 1.96986 (semantic_loss: 0.02050, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.34114 
Train Epoch: 13 [144/250 18432/32000 (58%)] Loss: 1.97280 (semantic_loss: 0.02246, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.33744 
Train Epoch: 13 [155/250 19840/32000 (62%)] Loss: 1.96934 (semantic_loss: 0.01999, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.34297 
Train Epoch: 13 [166/250 21248/32000 (66%)] Loss: 1.97305 (semantic_loss: 0.02272, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.34328 
Train Epoch: 13 [177/250 22656/32000 (71%)] Loss: 1.97272 (semantic_loss: 0.02238, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.33536 
Train Epoch: 13 [188/250 24064/32000 (75%)] Loss: 1.97186 (semantic_loss: 0.02152, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.33970 
Train Epoch: 13 [199/250 25472/32000 (80%)] Loss: 1.96999 (semantic_loss: 0.01966, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.34932 
Train Epoch: 13 [210/250 26880/32000 (84%)] Loss: 1.97004 (semantic_loss: 0.02068, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.33585 
Train Epoch: 13 [221/250 28288/32000 (88%)] Loss: 1.97090 (semantic_loss: 0.02154, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.33629 
Train Epoch: 13 [232/250 29696/32000 (93%)] Loss: 1.97209 (semantic_loss: 0.02175, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.36215 
Train Epoch: 13 [243/250 31104/32000 (97%)] Loss: 1.97119 (semantic_loss: 0.02086, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.33919 
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/DCMH_MSRVTT_1kA/checkpoint-epoch13.pth ...
Done in 3.879s
Updating 'best' checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/DCMH_MSRVTT_1kA/checkpoint-epoch13.pth ...
Done in 7.465s
removing stale ckpt [epoch 12] [took 0.00s]
 epoch          : 13
 loss           : 1.9710919966697693
 learning_rate  : 2.7018004383131832e-05
 n_samples      : 416000
 n_steps        : 3250
 MSRVTT_jsfusion_test/t2v_metrics/R1: 13.0
 MSRVTT_jsfusion_test/t2v_metrics/R5: 37.6
 MSRVTT_jsfusion_test/t2v_metrics/R10: 50.9
 MSRVTT_jsfusion_test/t2v_metrics/R50: 82.5
 MSRVTT_jsfusion_test/t2v_metrics/MedR: 10.0
 MSRVTT_jsfusion_test/t2v_metrics/MeanR: 35.135
 MSRVTT_jsfusion_test/t2v_metrics/geometric_mean_R1-R5-R10: 29.19328675344571
 MSRVTT_jsfusion_test/v2t_metrics/R1: 14.3
 MSRVTT_jsfusion_test/v2t_metrics/R5: 38.6
 MSRVTT_jsfusion_test/v2t_metrics/R10: 53.7
 MSRVTT_jsfusion_test/v2t_metrics/R50: 83.1
 MSRVTT_jsfusion_test/v2t_metrics/MedR: 9.0
 MSRVTT_jsfusion_test/v2t_metrics/MeanR: 34.7395
 MSRVTT_jsfusion_test/v2t_metrics/geometric_mean_R1-R5-R10: 30.947996752418568
 mnt_best       : 29.19328675344571
 not_improved_count: 0
Train Epoch: 14 [1/250 128/32000 (0%)] Loss: 1.97062 (semantic_loss: 0.02029, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=29.41704 
Train Epoch: 14 [12/250 1536/32000 (5%)] Loss: 1.97272 (semantic_loss: 0.02238, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.32949 
Train Epoch: 14 [23/250 2944/32000 (9%)] Loss: 1.97093 (semantic_loss: 0.02157, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.33227 
Train Epoch: 14 [34/250 4352/32000 (14%)] Loss: 1.97055 (semantic_loss: 0.02021, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.33660 
Train Epoch: 14 [45/250 5760/32000 (18%)] Loss: 1.97062 (semantic_loss: 0.02126, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.32996 
Train Epoch: 14 [56/250 7168/32000 (22%)] Loss: 1.96947 (semantic_loss: 0.02011, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.32662 
Train Epoch: 14 [67/250 8576/32000 (27%)] Loss: 1.96835 (semantic_loss: 0.01900, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.33676 
Train Epoch: 14 [78/250 9984/32000 (31%)] Loss: 1.96988 (semantic_loss: 0.01955, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.33285 
Train Epoch: 14 [89/250 11392/32000 (36%)] Loss: 1.97026 (semantic_loss: 0.01992, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.33596 
Train Epoch: 14 [100/250 12800/32000 (40%)] Loss: 1.97033 (semantic_loss: 0.02097, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.35301 
Train Epoch: 14 [111/250 14208/32000 (44%)] Loss: 1.97046 (semantic_loss: 0.02111, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.33916 
Train Epoch: 14 [122/250 15616/32000 (49%)] Loss: 1.97088 (semantic_loss: 0.02152, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.34296 
Train Epoch: 14 [133/250 17024/32000 (53%)] Loss: 1.97013 (semantic_loss: 0.01980, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.32406 
Train Epoch: 14 [144/250 18432/32000 (58%)] Loss: 1.96925 (semantic_loss: 0.01989, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.34644 
Train Epoch: 14 [155/250 19840/32000 (62%)] Loss: 1.96806 (semantic_loss: 0.01870, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.32481 
Train Epoch: 14 [166/250 21248/32000 (66%)] Loss: 1.97100 (semantic_loss: 0.02164, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.32781 
Train Epoch: 14 [177/250 22656/32000 (71%)] Loss: 1.97178 (semantic_loss: 0.02145, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.32821 
Train Epoch: 14 [188/250 24064/32000 (75%)] Loss: 1.96992 (semantic_loss: 0.01959, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.34976 
Train Epoch: 14 [199/250 25472/32000 (80%)] Loss: 1.97018 (semantic_loss: 0.01984, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=6.53753 
Train Epoch: 14 [210/250 26880/32000 (84%)] Loss: 1.97073 (semantic_loss: 0.02138, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.33645 
Train Epoch: 14 [221/250 28288/32000 (88%)] Loss: 1.97068 (semantic_loss: 0.02035, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.33672 
Train Epoch: 14 [232/250 29696/32000 (93%)] Loss: 1.97038 (semantic_loss: 0.02004, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.33759 
Train Epoch: 14 [243/250 31104/32000 (97%)] Loss: 1.97118 (semantic_loss: 0.02085, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.32813 
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/DCMH_MSRVTT_1kA/checkpoint-epoch14.pth ...
Done in 3.931s
Updating 'best' checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/DCMH_MSRVTT_1kA/checkpoint-epoch14.pth ...
Done in 8.721s
removing stale ckpt [epoch 13] [took 0.00s]
 epoch          : 14
 loss           : 1.9705258221626283
 learning_rate  : 2.566710416397524e-05
 n_samples      : 448000
 n_steps        : 3500
 MSRVTT_jsfusion_test/t2v_metrics/R1: 12.3
 MSRVTT_jsfusion_test/t2v_metrics/R5: 39.4
 MSRVTT_jsfusion_test/t2v_metrics/R10: 52.5
 MSRVTT_jsfusion_test/t2v_metrics/R50: 83.5
 MSRVTT_jsfusion_test/t2v_metrics/MedR: 10.0
 MSRVTT_jsfusion_test/t2v_metrics/MeanR: 36.1765
 MSRVTT_jsfusion_test/t2v_metrics/geometric_mean_R1-R5-R10: 29.411705737136675
 MSRVTT_jsfusion_test/v2t_metrics/R1: 13.2
 MSRVTT_jsfusion_test/v2t_metrics/R5: 41.0
 MSRVTT_jsfusion_test/v2t_metrics/R10: 54.7
 MSRVTT_jsfusion_test/v2t_metrics/R50: 84.3
 MSRVTT_jsfusion_test/v2t_metrics/MedR: 8.0
 MSRVTT_jsfusion_test/v2t_metrics/MeanR: 35.5925
 MSRVTT_jsfusion_test/v2t_metrics/geometric_mean_R1-R5-R10: 30.934875422693057
 mnt_best       : 29.411705737136675
 not_improved_count: 0
Train Epoch: 15 [1/250 128/32000 (0%)] Loss: 1.96814 (semantic_loss: 0.01878, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=31.90274 
Train Epoch: 15 [12/250 1536/32000 (5%)] Loss: 1.97028 (semantic_loss: 0.01994, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.32878 
Train Epoch: 15 [23/250 2944/32000 (9%)] Loss: 1.96929 (semantic_loss: 0.01994, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.33210 
Train Epoch: 15 [34/250 4352/32000 (14%)] Loss: 1.97132 (semantic_loss: 0.02099, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=1.09976 
Train Epoch: 15 [45/250 5760/32000 (18%)] Loss: 1.96903 (semantic_loss: 0.01967, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.32354 
Train Epoch: 15 [56/250 7168/32000 (22%)] Loss: 1.96883 (semantic_loss: 0.01947, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.80725 
Train Epoch: 15 [67/250 8576/32000 (27%)] Loss: 1.96965 (semantic_loss: 0.02030, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.34606 
Train Epoch: 15 [78/250 9984/32000 (31%)] Loss: 1.96800 (semantic_loss: 0.01865, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.36205 
Train Epoch: 15 [89/250 11392/32000 (36%)] Loss: 1.97049 (semantic_loss: 0.02113, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.34163 
Train Epoch: 15 [100/250 12800/32000 (40%)] Loss: 1.96915 (semantic_loss: 0.01980, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.34203 
Train Epoch: 15 [111/250 14208/32000 (44%)] Loss: 1.96888 (semantic_loss: 0.01952, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.33980 
Train Epoch: 15 [122/250 15616/32000 (49%)] Loss: 1.97036 (semantic_loss: 0.02002, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.33136 
Train Epoch: 15 [133/250 17024/32000 (53%)] Loss: 1.96904 (semantic_loss: 0.01870, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.37776 
Train Epoch: 15 [144/250 18432/32000 (58%)] Loss: 1.97047 (semantic_loss: 0.02014, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.32953 
Train Epoch: 15 [155/250 19840/32000 (62%)] Loss: 1.96989 (semantic_loss: 0.02053, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.33918 
Train Epoch: 15 [166/250 21248/32000 (66%)] Loss: 1.96951 (semantic_loss: 0.02015, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.34371 
Train Epoch: 15 [177/250 22656/32000 (71%)] Loss: 1.97002 (semantic_loss: 0.01969, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.32295 
Train Epoch: 15 [188/250 24064/32000 (75%)] Loss: 1.96855 (semantic_loss: 0.01822, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.32450 
Train Epoch: 15 [199/250 25472/32000 (80%)] Loss: 1.97021 (semantic_loss: 0.01988, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.44555 
Train Epoch: 15 [210/250 26880/32000 (84%)] Loss: 1.96850 (semantic_loss: 0.01915, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.32939 
Train Epoch: 15 [221/250 28288/32000 (88%)] Loss: 1.97001 (semantic_loss: 0.02066, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.34026 
Train Epoch: 15 [232/250 29696/32000 (93%)] Loss: 1.97278 (semantic_loss: 0.02245, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.33184 
Train Epoch: 15 [243/250 31104/32000 (97%)] Loss: 1.96894 (semantic_loss: 0.01958, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.33569 
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/DCMH_MSRVTT_1kA/checkpoint-epoch15.pth ...
Done in 4.336s
Updating 'best' checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/DCMH_MSRVTT_1kA/checkpoint-epoch15.pth ...
Done in 9.230s
removing stale ckpt [epoch 14] [took 0.00s]
 epoch          : 15
 loss           : 1.9699746775627136
 learning_rate  : 2.4383748955776477e-05
 n_samples      : 480000
 n_steps        : 3750
 MSRVTT_jsfusion_test/t2v_metrics/R1: 13.6
 MSRVTT_jsfusion_test/t2v_metrics/R5: 39.5
 MSRVTT_jsfusion_test/t2v_metrics/R10: 53.4
 MSRVTT_jsfusion_test/t2v_metrics/R50: 83.0
 MSRVTT_jsfusion_test/t2v_metrics/MedR: 9.0
 MSRVTT_jsfusion_test/t2v_metrics/MeanR: 34.8075
 MSRVTT_jsfusion_test/t2v_metrics/geometric_mean_R1-R5-R10: 30.612050446293168
 MSRVTT_jsfusion_test/v2t_metrics/R1: 14.4
 MSRVTT_jsfusion_test/v2t_metrics/R5: 41.5
 MSRVTT_jsfusion_test/v2t_metrics/R10: 55.7
 MSRVTT_jsfusion_test/v2t_metrics/R50: 83.4
 MSRVTT_jsfusion_test/v2t_metrics/MedR: 8.0
 MSRVTT_jsfusion_test/v2t_metrics/MeanR: 34.188
 MSRVTT_jsfusion_test/v2t_metrics/geometric_mean_R1-R5-R10: 32.167842076598355
 mnt_best       : 30.612050446293168
 not_improved_count: 0
Train Epoch: 16 [1/250 128/32000 (0%)] Loss: 1.96898 (semantic_loss: 0.01865, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=32.11603 
Train Epoch: 16 [12/250 1536/32000 (5%)] Loss: 1.96929 (semantic_loss: 0.01993, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.33362 
Train Epoch: 16 [23/250 2944/32000 (9%)] Loss: 1.97000 (semantic_loss: 0.01967, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.33392 
Train Epoch: 16 [34/250 4352/32000 (14%)] Loss: 1.96904 (semantic_loss: 0.01871, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.37830 
Train Epoch: 16 [45/250 5760/32000 (18%)] Loss: 1.97027 (semantic_loss: 0.01994, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.33387 
Train Epoch: 16 [56/250 7168/32000 (22%)] Loss: 1.96855 (semantic_loss: 0.01919, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.33720 
Train Epoch: 16 [67/250 8576/32000 (27%)] Loss: 1.96907 (semantic_loss: 0.01971, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.32981 
Train Epoch: 16 [78/250 9984/32000 (31%)] Loss: 1.96820 (semantic_loss: 0.01884, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.33099 
Train Epoch: 16 [89/250 11392/32000 (36%)] Loss: 1.96865 (semantic_loss: 0.01929, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.32228 
Train Epoch: 16 [100/250 12800/32000 (40%)] Loss: 1.97266 (semantic_loss: 0.02232, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.85404 
Train Epoch: 16 [111/250 14208/32000 (44%)] Loss: 1.96912 (semantic_loss: 0.01878, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.32658 
Train Epoch: 16 [122/250 15616/32000 (49%)] Loss: 1.97097 (semantic_loss: 0.02064, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.32598 
Train Epoch: 16 [133/250 17024/32000 (53%)] Loss: 1.96929 (semantic_loss: 0.01896, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.33394 
Train Epoch: 16 [144/250 18432/32000 (58%)] Loss: 1.96821 (semantic_loss: 0.01885, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.33204 
Train Epoch: 16 [155/250 19840/32000 (62%)] Loss: 1.97107 (semantic_loss: 0.02074, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.32437 
Train Epoch: 16 [166/250 21248/32000 (66%)] Loss: 1.96992 (semantic_loss: 0.01958, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.33767 
Train Epoch: 16 [177/250 22656/32000 (71%)] Loss: 1.96841 (semantic_loss: 0.01808, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.35637 
Train Epoch: 16 [188/250 24064/32000 (75%)] Loss: 1.97061 (semantic_loss: 0.02027, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.33985 
Train Epoch: 16 [199/250 25472/32000 (80%)] Loss: 1.97116 (semantic_loss: 0.02083, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.35571 
Train Epoch: 16 [210/250 26880/32000 (84%)] Loss: 1.96851 (semantic_loss: 0.01915, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.32364 
Train Epoch: 16 [221/250 28288/32000 (88%)] Loss: 1.97108 (semantic_loss: 0.02075, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.32627 
Train Epoch: 16 [232/250 29696/32000 (93%)] Loss: 1.96913 (semantic_loss: 0.01978, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.33241 
Train Epoch: 16 [243/250 31104/32000 (97%)] Loss: 1.96917 (semantic_loss: 0.01884, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.32566 
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/DCMH_MSRVTT_1kA/checkpoint-epoch16.pth ...
Done in 3.810s
Updating 'best' checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/DCMH_MSRVTT_1kA/checkpoint-epoch16.pth ...
Done in 7.896s
removing stale ckpt [epoch 15] [took 0.23s]
 epoch          : 16
 loss           : 1.9694899773597718
 learning_rate  : 2.3164561507987653e-05
 n_samples      : 512000
 n_steps        : 4000
 MSRVTT_jsfusion_test/t2v_metrics/R1: 15.5
 MSRVTT_jsfusion_test/t2v_metrics/R5: 39.7
 MSRVTT_jsfusion_test/t2v_metrics/R10: 55.7
 MSRVTT_jsfusion_test/t2v_metrics/R50: 83.6
 MSRVTT_jsfusion_test/t2v_metrics/MedR: 8.0
 MSRVTT_jsfusion_test/t2v_metrics/MeanR: 34.097
 MSRVTT_jsfusion_test/t2v_metrics/geometric_mean_R1-R5-R10: 32.48322447856545
 MSRVTT_jsfusion_test/v2t_metrics/R1: 14.8
 MSRVTT_jsfusion_test/v2t_metrics/R5: 41.4
 MSRVTT_jsfusion_test/v2t_metrics/R10: 56.7
 MSRVTT_jsfusion_test/v2t_metrics/R50: 82.6
 MSRVTT_jsfusion_test/v2t_metrics/MedR: 8.0
 MSRVTT_jsfusion_test/v2t_metrics/MeanR: 33.8205
 MSRVTT_jsfusion_test/v2t_metrics/geometric_mean_R1-R5-R10: 32.629847080073866
 mnt_best       : 32.48322447856545
 not_improved_count: 0
Train Epoch: 17 [1/250 128/32000 (0%)] Loss: 1.96893 (semantic_loss: 0.01957, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=25.30211 
Train Epoch: 17 [12/250 1536/32000 (5%)] Loss: 1.96928 (semantic_loss: 0.01895, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.32611 
Train Epoch: 17 [23/250 2944/32000 (9%)] Loss: 1.97006 (semantic_loss: 0.01973, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.34513 
Train Epoch: 17 [34/250 4352/32000 (14%)] Loss: 1.96963 (semantic_loss: 0.01930, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.33445 
Train Epoch: 17 [45/250 5760/32000 (18%)] Loss: 1.97130 (semantic_loss: 0.02096, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.33560 
Train Epoch: 17 [56/250 7168/32000 (22%)] Loss: 1.96934 (semantic_loss: 0.01999, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.35344 
Train Epoch: 17 [67/250 8576/32000 (27%)] Loss: 1.97035 (semantic_loss: 0.02100, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.34470 
Train Epoch: 17 [78/250 9984/32000 (31%)] Loss: 1.96901 (semantic_loss: 0.01965, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.34946 
Train Epoch: 17 [89/250 11392/32000 (36%)] Loss: 1.96816 (semantic_loss: 0.01978, quant_loss: 1.94824, bit_balance_loss: 0.00014) batch_time=0.34522 
Train Epoch: 17 [100/250 12800/32000 (40%)] Loss: 1.96844 (semantic_loss: 0.01909, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.33476 
Train Epoch: 17 [111/250 14208/32000 (44%)] Loss: 1.96782 (semantic_loss: 0.01846, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.33555 
Train Epoch: 17 [122/250 15616/32000 (49%)] Loss: 1.96979 (semantic_loss: 0.01946, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.33006 
Train Epoch: 17 [133/250 17024/32000 (53%)] Loss: 1.97031 (semantic_loss: 0.02096, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.66092 
Train Epoch: 17 [144/250 18432/32000 (58%)] Loss: 1.96892 (semantic_loss: 0.01956, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.35362 
Train Epoch: 17 [155/250 19840/32000 (62%)] Loss: 1.96964 (semantic_loss: 0.01931, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.34774 
Train Epoch: 17 [166/250 21248/32000 (66%)] Loss: 1.96792 (semantic_loss: 0.01856, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.33908 
Train Epoch: 17 [177/250 22656/32000 (71%)] Loss: 1.96861 (semantic_loss: 0.01926, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.35446 
Train Epoch: 17 [188/250 24064/32000 (75%)] Loss: 1.96853 (semantic_loss: 0.01918, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.32811 
Train Epoch: 17 [199/250 25472/32000 (80%)] Loss: 1.96806 (semantic_loss: 0.01871, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.33046 
Train Epoch: 17 [210/250 26880/32000 (84%)] Loss: 1.96875 (semantic_loss: 0.01841, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.32868 
Train Epoch: 17 [221/250 28288/32000 (88%)] Loss: 1.97039 (semantic_loss: 0.02006, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.36715 
Train Epoch: 17 [232/250 29696/32000 (93%)] Loss: 1.97000 (semantic_loss: 0.01967, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.67887 
Train Epoch: 17 [243/250 31104/32000 (97%)] Loss: 1.96993 (semantic_loss: 0.01960, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.32400 
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/DCMH_MSRVTT_1kA/checkpoint-epoch17.pth ...
Done in 4.034s
removing stale ckpt [epoch 16] [took 0.00s]
 epoch          : 17
 loss           : 1.9692578253746034
 learning_rate  : 2.2006333432588268e-05
 n_samples      : 544000
 n_steps        : 4250
 MSRVTT_jsfusion_test/t2v_metrics/R1: 14.8
 MSRVTT_jsfusion_test/t2v_metrics/R5: 40.5
 MSRVTT_jsfusion_test/t2v_metrics/R10: 55.5
 MSRVTT_jsfusion_test/t2v_metrics/R50: 83.5
 MSRVTT_jsfusion_test/t2v_metrics/MedR: 8.0
 MSRVTT_jsfusion_test/t2v_metrics/MeanR: 33.7415
 MSRVTT_jsfusion_test/t2v_metrics/geometric_mean_R1-R5-R10: 32.16152058971961
 MSRVTT_jsfusion_test/v2t_metrics/R1: 15.8
 MSRVTT_jsfusion_test/v2t_metrics/R5: 43.5
 MSRVTT_jsfusion_test/v2t_metrics/R10: 56.6
 MSRVTT_jsfusion_test/v2t_metrics/R50: 84.8
 MSRVTT_jsfusion_test/v2t_metrics/MedR: 7.0
 MSRVTT_jsfusion_test/v2t_metrics/MeanR: 32.473
 MSRVTT_jsfusion_test/v2t_metrics/geometric_mean_R1-R5-R10: 33.88344751039688
 mnt_best       : 32.48322447856545
 not_improved_count: 1
Train Epoch: 18 [1/250 128/32000 (0%)] Loss: 1.97001 (semantic_loss: 0.02065, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=32.97279 
Train Epoch: 18 [12/250 1536/32000 (5%)] Loss: 1.96957 (semantic_loss: 0.02022, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=2.18891 
Train Epoch: 18 [23/250 2944/32000 (9%)] Loss: 1.96915 (semantic_loss: 0.01882, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.33359 
Train Epoch: 18 [34/250 4352/32000 (14%)] Loss: 1.96805 (semantic_loss: 0.01869, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.32448 
Train Epoch: 18 [45/250 5760/32000 (18%)] Loss: 1.96853 (semantic_loss: 0.01917, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.36690 
Train Epoch: 18 [56/250 7168/32000 (22%)] Loss: 1.96774 (semantic_loss: 0.01838, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.35332 
Train Epoch: 18 [67/250 8576/32000 (27%)] Loss: 1.96864 (semantic_loss: 0.01831, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.37670 
Train Epoch: 18 [78/250 9984/32000 (31%)] Loss: 1.97007 (semantic_loss: 0.01974, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.32137 
Train Epoch: 18 [89/250 11392/32000 (36%)] Loss: 1.97123 (semantic_loss: 0.02090, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.33211 
Train Epoch: 18 [100/250 12800/32000 (40%)] Loss: 1.96697 (semantic_loss: 0.01762, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.35046 
Train Epoch: 18 [111/250 14208/32000 (44%)] Loss: 1.96842 (semantic_loss: 0.01809, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.32676 
Train Epoch: 18 [122/250 15616/32000 (49%)] Loss: 1.97040 (semantic_loss: 0.02007, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.32740 
Train Epoch: 18 [133/250 17024/32000 (53%)] Loss: 1.96928 (semantic_loss: 0.01895, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.35731 
Train Epoch: 18 [144/250 18432/32000 (58%)] Loss: 1.96853 (semantic_loss: 0.01820, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.37198 
Train Epoch: 18 [155/250 19840/32000 (62%)] Loss: 1.97164 (semantic_loss: 0.02131, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.32633 
Train Epoch: 18 [166/250 21248/32000 (66%)] Loss: 1.96857 (semantic_loss: 0.01824, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.34087 
Train Epoch: 18 [177/250 22656/32000 (71%)] Loss: 1.96972 (semantic_loss: 0.01939, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.57843 
Train Epoch: 18 [188/250 24064/32000 (75%)] Loss: 1.96808 (semantic_loss: 0.01775, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.35509 
Train Epoch: 18 [199/250 25472/32000 (80%)] Loss: 1.96980 (semantic_loss: 0.01946, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=3.19903 
Train Epoch: 18 [210/250 26880/32000 (84%)] Loss: 1.96857 (semantic_loss: 0.01823, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=1.69988 
Train Epoch: 18 [221/250 28288/32000 (88%)] Loss: 1.96717 (semantic_loss: 0.01782, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.40585 
Train Epoch: 18 [232/250 29696/32000 (93%)] Loss: 1.96718 (semantic_loss: 0.01783, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.33986 
Train Epoch: 18 [243/250 31104/32000 (97%)] Loss: 1.96765 (semantic_loss: 0.01830, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.34444 
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/DCMH_MSRVTT_1kA/checkpoint-epoch18.pth ...
Done in 4.060s
Updating 'best' checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/DCMH_MSRVTT_1kA/checkpoint-epoch18.pth ...
Done in 8.019s
removing stale ckpt [epoch 17] [took 0.00s]
 epoch          : 18
 loss           : 1.9689448275566102
 learning_rate  : 2.0906016760958855e-05
 n_samples      : 576000
 n_steps        : 4500
 MSRVTT_jsfusion_test/t2v_metrics/R1: 14.9
 MSRVTT_jsfusion_test/t2v_metrics/R5: 41.9
 MSRVTT_jsfusion_test/t2v_metrics/R10: 56.6
 MSRVTT_jsfusion_test/t2v_metrics/R50: 83.6
 MSRVTT_jsfusion_test/t2v_metrics/MedR: 8.0
 MSRVTT_jsfusion_test/t2v_metrics/MeanR: 33.386
 MSRVTT_jsfusion_test/t2v_metrics/geometric_mean_R1-R5-R10: 32.814987325882335
 MSRVTT_jsfusion_test/v2t_metrics/R1: 16.0
 MSRVTT_jsfusion_test/v2t_metrics/R5: 43.7
 MSRVTT_jsfusion_test/v2t_metrics/R10: 58.7
 MSRVTT_jsfusion_test/v2t_metrics/R50: 84.3
 MSRVTT_jsfusion_test/v2t_metrics/MedR: 7.0
 MSRVTT_jsfusion_test/v2t_metrics/MeanR: 31.91
 MSRVTT_jsfusion_test/v2t_metrics/geometric_mean_R1-R5-R10: 34.49423414109665
 mnt_best       : 32.814987325882335
 not_improved_count: 0
Train Epoch: 19 [1/250 128/32000 (0%)] Loss: 1.96740 (semantic_loss: 0.01805, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=28.37734 
Train Epoch: 19 [12/250 1536/32000 (5%)] Loss: 1.96892 (semantic_loss: 0.01956, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.33215 
Train Epoch: 19 [23/250 2944/32000 (9%)] Loss: 1.96863 (semantic_loss: 0.01830, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.33674 
Train Epoch: 19 [34/250 4352/32000 (14%)] Loss: 1.96831 (semantic_loss: 0.01896, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.33743 
Train Epoch: 19 [45/250 5760/32000 (18%)] Loss: 1.96874 (semantic_loss: 0.01841, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.35802 
Train Epoch: 19 [56/250 7168/32000 (22%)] Loss: 1.96641 (semantic_loss: 0.01705, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.33643 
Train Epoch: 19 [67/250 8576/32000 (27%)] Loss: 1.96848 (semantic_loss: 0.01815, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=1.83501 
Train Epoch: 19 [78/250 9984/32000 (31%)] Loss: 1.96737 (semantic_loss: 0.01704, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.34312 
Train Epoch: 19 [89/250 11392/32000 (36%)] Loss: 1.96828 (semantic_loss: 0.01795, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.33231 
Train Epoch: 19 [100/250 12800/32000 (40%)] Loss: 1.96774 (semantic_loss: 0.01838, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.32719 
Train Epoch: 19 [111/250 14208/32000 (44%)] Loss: 1.96901 (semantic_loss: 0.01868, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.33152 
Train Epoch: 19 [122/250 15616/32000 (49%)] Loss: 1.96735 (semantic_loss: 0.01702, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.32258 
Train Epoch: 19 [133/250 17024/32000 (53%)] Loss: 1.96932 (semantic_loss: 0.01899, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.33970 
Train Epoch: 19 [144/250 18432/32000 (58%)] Loss: 1.96865 (semantic_loss: 0.01930, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.32520 
Train Epoch: 19 [155/250 19840/32000 (62%)] Loss: 1.96822 (semantic_loss: 0.01887, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.35675 
Train Epoch: 19 [166/250 21248/32000 (66%)] Loss: 1.96680 (semantic_loss: 0.01745, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.32395 
Train Epoch: 19 [177/250 22656/32000 (71%)] Loss: 1.96665 (semantic_loss: 0.01729, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.34097 
Train Epoch: 19 [188/250 24064/32000 (75%)] Loss: 1.96844 (semantic_loss: 0.01908, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.34773 
Train Epoch: 19 [199/250 25472/32000 (80%)] Loss: 1.96720 (semantic_loss: 0.01785, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.32999 
Train Epoch: 19 [210/250 26880/32000 (84%)] Loss: 1.96819 (semantic_loss: 0.01884, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.32605 
Train Epoch: 19 [221/250 28288/32000 (88%)] Loss: 1.96856 (semantic_loss: 0.01823, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.33109 
Train Epoch: 19 [232/250 29696/32000 (93%)] Loss: 1.96907 (semantic_loss: 0.01874, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.34252 
Train Epoch: 19 [243/250 31104/32000 (97%)] Loss: 1.96894 (semantic_loss: 0.01861, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.32684 
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/DCMH_MSRVTT_1kA/checkpoint-epoch19.pth ...
Done in 3.881s
Updating 'best' checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/DCMH_MSRVTT_1kA/checkpoint-epoch19.pth ...
Done in 7.878s
removing stale ckpt [epoch 18] [took 0.00s]
 epoch          : 19
 loss           : 1.968436700820923
 learning_rate  : 1.986071592291091e-05
 n_samples      : 608000
 n_steps        : 4750
 MSRVTT_jsfusion_test/t2v_metrics/R1: 16.3
 MSRVTT_jsfusion_test/t2v_metrics/R5: 41.7
 MSRVTT_jsfusion_test/t2v_metrics/R10: 55.3
 MSRVTT_jsfusion_test/t2v_metrics/R50: 84.4
 MSRVTT_jsfusion_test/t2v_metrics/MedR: 8.0
 MSRVTT_jsfusion_test/t2v_metrics/MeanR: 32.7385
 MSRVTT_jsfusion_test/t2v_metrics/geometric_mean_R1-R5-R10: 33.497798325640446
 MSRVTT_jsfusion_test/v2t_metrics/R1: 14.9
 MSRVTT_jsfusion_test/v2t_metrics/R5: 43.2
 MSRVTT_jsfusion_test/v2t_metrics/R10: 58.4
 MSRVTT_jsfusion_test/v2t_metrics/R50: 85.5
 MSRVTT_jsfusion_test/v2t_metrics/MedR: 7.0
 MSRVTT_jsfusion_test/v2t_metrics/MeanR: 31.44
 MSRVTT_jsfusion_test/v2t_metrics/geometric_mean_R1-R5-R10: 33.498674336789286
 mnt_best       : 33.497798325640446
 not_improved_count: 0
Train Epoch: 20 [1/250 128/32000 (0%)] Loss: 1.96757 (semantic_loss: 0.01724, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=26.86768 
Train Epoch: 20 [12/250 1536/32000 (5%)] Loss: 1.96709 (semantic_loss: 0.01774, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.33212 
Train Epoch: 20 [23/250 2944/32000 (9%)] Loss: 1.97026 (semantic_loss: 0.01994, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.33806 
Train Epoch: 20 [34/250 4352/32000 (14%)] Loss: 1.96619 (semantic_loss: 0.01684, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.32712 
Train Epoch: 20 [45/250 5760/32000 (18%)] Loss: 1.96671 (semantic_loss: 0.01638, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.34164 
Train Epoch: 20 [56/250 7168/32000 (22%)] Loss: 1.96842 (semantic_loss: 0.01907, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.32400 
Train Epoch: 20 [67/250 8576/32000 (27%)] Loss: 1.96867 (semantic_loss: 0.01834, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.88469 
Train Epoch: 20 [78/250 9984/32000 (31%)] Loss: 1.96723 (semantic_loss: 0.01788, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=1.77187 
Train Epoch: 20 [89/250 11392/32000 (36%)] Loss: 1.96837 (semantic_loss: 0.01804, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.33537 
Train Epoch: 20 [100/250 12800/32000 (40%)] Loss: 1.96875 (semantic_loss: 0.01940, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.34271 
Train Epoch: 20 [111/250 14208/32000 (44%)] Loss: 1.96802 (semantic_loss: 0.01769, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.33601 
Train Epoch: 20 [122/250 15616/32000 (49%)] Loss: 1.96955 (semantic_loss: 0.01922, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.32761 
Train Epoch: 20 [133/250 17024/32000 (53%)] Loss: 1.96743 (semantic_loss: 0.01808, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=5.77753 
Train Epoch: 20 [144/250 18432/32000 (58%)] Loss: 1.96934 (semantic_loss: 0.01803, quant_loss: 1.95117, bit_balance_loss: 0.00014) batch_time=0.33187 
Train Epoch: 20 [155/250 19840/32000 (62%)] Loss: 1.96909 (semantic_loss: 0.01876, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=1.55490 
Train Epoch: 20 [166/250 21248/32000 (66%)] Loss: 1.96999 (semantic_loss: 0.01966, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.35033 
Train Epoch: 20 [177/250 22656/32000 (71%)] Loss: 1.96648 (semantic_loss: 0.01712, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.34092 
Train Epoch: 20 [188/250 24064/32000 (75%)] Loss: 1.96820 (semantic_loss: 0.01885, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.32580 
Train Epoch: 20 [199/250 25472/32000 (80%)] Loss: 1.96950 (semantic_loss: 0.01918, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.33346 
Train Epoch: 20 [210/250 26880/32000 (84%)] Loss: 1.96824 (semantic_loss: 0.01791, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.32928 
Train Epoch: 20 [221/250 28288/32000 (88%)] Loss: 1.96857 (semantic_loss: 0.01824, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.32350 
Train Epoch: 20 [232/250 29696/32000 (93%)] Loss: 1.96766 (semantic_loss: 0.01733, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.32976 
Train Epoch: 20 [243/250 31104/32000 (97%)] Loss: 1.96834 (semantic_loss: 0.01898, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.33435 
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/DCMH_MSRVTT_1kA/checkpoint-epoch20.pth ...
Done in 4.114s
Updating 'best' checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/DCMH_MSRVTT_1kA/checkpoint-epoch20.pth ...
Done in 8.918s
removing stale ckpt [epoch 19] [took 0.00s]
 epoch          : 20
 loss           : 1.9683022408485413
 learning_rate  : 1.8867680126765363e-05
 n_samples      : 640000
 n_steps        : 5000
 MSRVTT_jsfusion_test/t2v_metrics/R1: 16.2
 MSRVTT_jsfusion_test/t2v_metrics/R5: 42.3
 MSRVTT_jsfusion_test/t2v_metrics/R10: 56.7
 MSRVTT_jsfusion_test/t2v_metrics/R50: 84.5
 MSRVTT_jsfusion_test/t2v_metrics/MedR: 8.0
 MSRVTT_jsfusion_test/t2v_metrics/MeanR: 32.8475
 MSRVTT_jsfusion_test/t2v_metrics/geometric_mean_R1-R5-R10: 33.8698141505727
 MSRVTT_jsfusion_test/v2t_metrics/R1: 14.9
 MSRVTT_jsfusion_test/v2t_metrics/R5: 44.1
 MSRVTT_jsfusion_test/v2t_metrics/R10: 57.4
 MSRVTT_jsfusion_test/v2t_metrics/R50: 85.3
 MSRVTT_jsfusion_test/v2t_metrics/MedR: 7.0
 MSRVTT_jsfusion_test/v2t_metrics/MeanR: 31.779
 MSRVTT_jsfusion_test/v2t_metrics/geometric_mean_R1-R5-R10: 33.536076379824955
 mnt_best       : 33.8698141505727
 not_improved_count: 0
Train Epoch: 21 [1/250 128/32000 (0%)] Loss: 1.96910 (semantic_loss: 0.01975, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=33.06707 
Train Epoch: 21 [12/250 1536/32000 (5%)] Loss: 1.96887 (semantic_loss: 0.01854, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.33308 
Train Epoch: 21 [23/250 2944/32000 (9%)] Loss: 1.96729 (semantic_loss: 0.01794, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.35079 
Train Epoch: 21 [34/250 4352/32000 (14%)] Loss: 1.96854 (semantic_loss: 0.01919, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.36598 
Train Epoch: 21 [45/250 5760/32000 (18%)] Loss: 1.96874 (semantic_loss: 0.01841, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.36475 
Train Epoch: 21 [56/250 7168/32000 (22%)] Loss: 1.96719 (semantic_loss: 0.01784, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.32603 
Train Epoch: 21 [67/250 8576/32000 (27%)] Loss: 1.96785 (semantic_loss: 0.01850, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.33406 
Train Epoch: 21 [78/250 9984/32000 (31%)] Loss: 1.96747 (semantic_loss: 0.01812, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.33853 
Train Epoch: 21 [89/250 11392/32000 (36%)] Loss: 1.96739 (semantic_loss: 0.01706, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.33156 
Train Epoch: 21 [100/250 12800/32000 (40%)] Loss: 1.96752 (semantic_loss: 0.01719, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.35049 
Train Epoch: 21 [111/250 14208/32000 (44%)] Loss: 1.96860 (semantic_loss: 0.01925, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.33971 
Train Epoch: 21 [122/250 15616/32000 (49%)] Loss: 1.96722 (semantic_loss: 0.01787, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.33080 
Train Epoch: 21 [133/250 17024/32000 (53%)] Loss: 1.96977 (semantic_loss: 0.01944, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.33339 
Train Epoch: 21 [144/250 18432/32000 (58%)] Loss: 1.96863 (semantic_loss: 0.01830, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=3.05066 
Train Epoch: 21 [155/250 19840/32000 (62%)] Loss: 1.97005 (semantic_loss: 0.01972, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.34356 
Train Epoch: 21 [166/250 21248/32000 (66%)] Loss: 1.97039 (semantic_loss: 0.02007, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.35670 
Train Epoch: 21 [177/250 22656/32000 (71%)] Loss: 1.96607 (semantic_loss: 0.01672, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.32209 
Train Epoch: 21 [188/250 24064/32000 (75%)] Loss: 1.96557 (semantic_loss: 0.01621, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.34314 
Train Epoch: 21 [199/250 25472/32000 (80%)] Loss: 1.96620 (semantic_loss: 0.01587, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.34235 
Train Epoch: 21 [210/250 26880/32000 (84%)] Loss: 1.96694 (semantic_loss: 0.01759, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.34520 
Train Epoch: 21 [221/250 28288/32000 (88%)] Loss: 1.96843 (semantic_loss: 0.01810, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.32684 
Train Epoch: 21 [232/250 29696/32000 (93%)] Loss: 1.96885 (semantic_loss: 0.01852, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.33908 
Train Epoch: 21 [243/250 31104/32000 (97%)] Loss: 1.96833 (semantic_loss: 0.01703, quant_loss: 1.95117, bit_balance_loss: 0.00013) batch_time=0.34572 
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/DCMH_MSRVTT_1kA/checkpoint-epoch21.pth ...
Done in 4.296s
removing stale ckpt [epoch 20] [took 0.00s]
 epoch          : 21
 loss           : 1.9679967579841613
 learning_rate  : 1.7924296120427095e-05
 n_samples      : 672000
 n_steps        : 5250
 MSRVTT_jsfusion_test/t2v_metrics/R1: 15.2
 MSRVTT_jsfusion_test/t2v_metrics/R5: 40.4
 MSRVTT_jsfusion_test/t2v_metrics/R10: 56.4
 MSRVTT_jsfusion_test/t2v_metrics/R50: 84.5
 MSRVTT_jsfusion_test/t2v_metrics/MedR: 8.0
 MSRVTT_jsfusion_test/t2v_metrics/MeanR: 33.665
 MSRVTT_jsfusion_test/t2v_metrics/geometric_mean_R1-R5-R10: 32.59627844653714
 MSRVTT_jsfusion_test/v2t_metrics/R1: 16.8
 MSRVTT_jsfusion_test/v2t_metrics/R5: 44.5
 MSRVTT_jsfusion_test/v2t_metrics/R10: 55.8
 MSRVTT_jsfusion_test/v2t_metrics/R50: 84.8
 MSRVTT_jsfusion_test/v2t_metrics/MedR: 7.25
 MSRVTT_jsfusion_test/v2t_metrics/MeanR: 32.933
 MSRVTT_jsfusion_test/v2t_metrics/geometric_mean_R1-R5-R10: 34.681762820319335
 mnt_best       : 33.8698141505727
 not_improved_count: 1
Train Epoch: 22 [1/250 128/32000 (0%)] Loss: 1.97042 (semantic_loss: 0.02009, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=29.31592 
Train Epoch: 22 [12/250 1536/32000 (5%)] Loss: 1.96860 (semantic_loss: 0.01827, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.35135 
Train Epoch: 22 [23/250 2944/32000 (9%)] Loss: 1.96721 (semantic_loss: 0.01786, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.34226 
Train Epoch: 22 [34/250 4352/32000 (14%)] Loss: 1.96992 (semantic_loss: 0.01959, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.33814 
Train Epoch: 22 [45/250 5760/32000 (18%)] Loss: 1.96729 (semantic_loss: 0.01794, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.34381 
Train Epoch: 22 [56/250 7168/32000 (22%)] Loss: 1.96819 (semantic_loss: 0.01786, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.34444 
Train Epoch: 22 [67/250 8576/32000 (27%)] Loss: 1.96889 (semantic_loss: 0.01855, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=1.66707 
Train Epoch: 22 [78/250 9984/32000 (31%)] Loss: 1.96891 (semantic_loss: 0.01858, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.34396 
Train Epoch: 22 [89/250 11392/32000 (36%)] Loss: 1.96786 (semantic_loss: 0.01850, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.35435 
Train Epoch: 22 [100/250 12800/32000 (40%)] Loss: 1.96672 (semantic_loss: 0.01639, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.33056 
Train Epoch: 22 [111/250 14208/32000 (44%)] Loss: 1.96722 (semantic_loss: 0.01787, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.36975 
Train Epoch: 22 [122/250 15616/32000 (49%)] Loss: 1.96802 (semantic_loss: 0.01769, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.33921 
Train Epoch: 22 [133/250 17024/32000 (53%)] Loss: 1.96729 (semantic_loss: 0.01696, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.35049 
Train Epoch: 22 [144/250 18432/32000 (58%)] Loss: 1.96607 (semantic_loss: 0.01574, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.34271 
Train Epoch: 22 [155/250 19840/32000 (62%)] Loss: 1.96909 (semantic_loss: 0.01876, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.34612 
Train Epoch: 22 [166/250 21248/32000 (66%)] Loss: 1.96667 (semantic_loss: 0.01731, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.34123 
Train Epoch: 22 [177/250 22656/32000 (71%)] Loss: 1.96709 (semantic_loss: 0.01773, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.34112 
Train Epoch: 22 [188/250 24064/32000 (75%)] Loss: 1.96743 (semantic_loss: 0.01808, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.45351 
Train Epoch: 22 [199/250 25472/32000 (80%)] Loss: 1.96688 (semantic_loss: 0.01753, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.35088 
Train Epoch: 22 [210/250 26880/32000 (84%)] Loss: 1.96805 (semantic_loss: 0.01773, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=5.46886 
Train Epoch: 22 [221/250 28288/32000 (88%)] Loss: 1.96535 (semantic_loss: 0.01698, quant_loss: 1.94824, bit_balance_loss: 0.00013) batch_time=0.34313 
Train Epoch: 22 [232/250 29696/32000 (93%)] Loss: 1.96708 (semantic_loss: 0.01772, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.35256 
Train Epoch: 22 [243/250 31104/32000 (97%)] Loss: 1.96769 (semantic_loss: 0.01736, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.36717 
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/DCMH_MSRVTT_1kA/checkpoint-epoch22.pth ...
Done in 4.484s
Updating 'best' checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/DCMH_MSRVTT_1kA/checkpoint-epoch22.pth ...
Done in 8.354s
removing stale ckpt [epoch 21] [took 0.00s]
 epoch          : 22
 loss           : 1.9676301960945128
 learning_rate  : 1.702808131440574e-05
 n_samples      : 704000
 n_steps        : 5500
 MSRVTT_jsfusion_test/t2v_metrics/R1: 16.5
 MSRVTT_jsfusion_test/t2v_metrics/R5: 42.7
 MSRVTT_jsfusion_test/t2v_metrics/R10: 56.5
 MSRVTT_jsfusion_test/t2v_metrics/R50: 85.7
 MSRVTT_jsfusion_test/t2v_metrics/MedR: 8.0
 MSRVTT_jsfusion_test/t2v_metrics/MeanR: 33.1975
 MSRVTT_jsfusion_test/t2v_metrics/geometric_mean_R1-R5-R10: 34.14444744793616
 MSRVTT_jsfusion_test/v2t_metrics/R1: 16.1
 MSRVTT_jsfusion_test/v2t_metrics/R5: 43.9
 MSRVTT_jsfusion_test/v2t_metrics/R10: 58.2
 MSRVTT_jsfusion_test/v2t_metrics/R50: 85.6
 MSRVTT_jsfusion_test/v2t_metrics/MedR: 7.5
 MSRVTT_jsfusion_test/v2t_metrics/MeanR: 31.287
 MSRVTT_jsfusion_test/v2t_metrics/geometric_mean_R1-R5-R10: 34.520027019542404
 mnt_best       : 34.14444744793616
 not_improved_count: 0
Train Epoch: 23 [1/250 128/32000 (0%)] Loss: 1.96791 (semantic_loss: 0.01856, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=33.78668 
Train Epoch: 23 [12/250 1536/32000 (5%)] Loss: 1.96591 (semantic_loss: 0.01656, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.37474 
Train Epoch: 23 [23/250 2944/32000 (9%)] Loss: 1.96623 (semantic_loss: 0.01688, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.33621 
Train Epoch: 23 [34/250 4352/32000 (14%)] Loss: 1.96670 (semantic_loss: 0.01734, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.35017 
Train Epoch: 23 [45/250 5760/32000 (18%)] Loss: 1.96785 (semantic_loss: 0.01752, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.34872 
Train Epoch: 23 [56/250 7168/32000 (22%)] Loss: 1.96689 (semantic_loss: 0.01656, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.33631 
Train Epoch: 23 [67/250 8576/32000 (27%)] Loss: 1.96722 (semantic_loss: 0.01688, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.33201 
Train Epoch: 23 [78/250 9984/32000 (31%)] Loss: 1.96686 (semantic_loss: 0.01653, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.34054 
Train Epoch: 23 [89/250 11392/32000 (36%)] Loss: 1.96684 (semantic_loss: 0.01749, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.33893 
Train Epoch: 23 [100/250 12800/32000 (40%)] Loss: 1.96635 (semantic_loss: 0.01700, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.33806 
Train Epoch: 23 [111/250 14208/32000 (44%)] Loss: 1.96616 (semantic_loss: 0.01681, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.63049 
Train Epoch: 23 [122/250 15616/32000 (49%)] Loss: 1.96704 (semantic_loss: 0.01671, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.33995 
Train Epoch: 23 [133/250 17024/32000 (53%)] Loss: 1.96662 (semantic_loss: 0.01726, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.32838 
Train Epoch: 23 [144/250 18432/32000 (58%)] Loss: 1.96771 (semantic_loss: 0.01738, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.34025 
Train Epoch: 23 [155/250 19840/32000 (62%)] Loss: 1.96826 (semantic_loss: 0.01891, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.38636 
Train Epoch: 23 [166/250 21248/32000 (66%)] Loss: 1.96863 (semantic_loss: 0.01830, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.34105 
Train Epoch: 23 [177/250 22656/32000 (71%)] Loss: 1.96596 (semantic_loss: 0.01661, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.35707 
Train Epoch: 23 [188/250 24064/32000 (75%)] Loss: 1.96728 (semantic_loss: 0.01793, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.32846 
Train Epoch: 23 [199/250 25472/32000 (80%)] Loss: 1.96810 (semantic_loss: 0.01777, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.33281 
Train Epoch: 23 [210/250 26880/32000 (84%)] Loss: 1.96702 (semantic_loss: 0.01669, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.34004 
Train Epoch: 23 [221/250 28288/32000 (88%)] Loss: 1.96812 (semantic_loss: 0.01779, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.34031 
Train Epoch: 23 [232/250 29696/32000 (93%)] Loss: 1.96943 (semantic_loss: 0.02008, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.34785 
Train Epoch: 23 [243/250 31104/32000 (97%)] Loss: 1.96593 (semantic_loss: 0.01561, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.34803 
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/DCMH_MSRVTT_1kA/checkpoint-epoch23.pth ...
Done in 4.237s
removing stale ckpt [epoch 22] [took 0.00s]
 epoch          : 23
 loss           : 1.967487823009491
 learning_rate  : 1.6176677248685452e-05
 n_samples      : 736000
 n_steps        : 5750
 MSRVTT_jsfusion_test/t2v_metrics/R1: 15.4
 MSRVTT_jsfusion_test/t2v_metrics/R5: 42.9
 MSRVTT_jsfusion_test/t2v_metrics/R10: 56.6
 MSRVTT_jsfusion_test/t2v_metrics/R50: 85.1
 MSRVTT_jsfusion_test/t2v_metrics/MedR: 7.5
 MSRVTT_jsfusion_test/t2v_metrics/MeanR: 32.685500000000005
 MSRVTT_jsfusion_test/t2v_metrics/geometric_mean_R1-R5-R10: 33.43988804209977
 MSRVTT_jsfusion_test/v2t_metrics/R1: 16.5
 MSRVTT_jsfusion_test/v2t_metrics/R5: 45.4
 MSRVTT_jsfusion_test/v2t_metrics/R10: 59.2
 MSRVTT_jsfusion_test/v2t_metrics/R50: 85.5
 MSRVTT_jsfusion_test/v2t_metrics/MedR: 7.0
 MSRVTT_jsfusion_test/v2t_metrics/MeanR: 31.5565
 MSRVTT_jsfusion_test/v2t_metrics/geometric_mean_R1-R5-R10: 35.39597132486825
 mnt_best       : 34.14444744793616
 not_improved_count: 1
Train Epoch: 24 [1/250 128/32000 (0%)] Loss: 1.96671 (semantic_loss: 0.01735, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=30.03099 
Train Epoch: 24 [12/250 1536/32000 (5%)] Loss: 1.96775 (semantic_loss: 0.01840, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.34455 
Train Epoch: 24 [23/250 2944/32000 (9%)] Loss: 1.96915 (semantic_loss: 0.01881, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.34825 
Train Epoch: 24 [34/250 4352/32000 (14%)] Loss: 1.96762 (semantic_loss: 0.01729, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.32248 
Train Epoch: 24 [45/250 5760/32000 (18%)] Loss: 1.96782 (semantic_loss: 0.01847, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.36023 
Train Epoch: 24 [56/250 7168/32000 (22%)] Loss: 1.96794 (semantic_loss: 0.01761, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.34575 
Train Epoch: 24 [67/250 8576/32000 (27%)] Loss: 1.96963 (semantic_loss: 0.01930, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.34842 
Train Epoch: 24 [78/250 9984/32000 (31%)] Loss: 1.96819 (semantic_loss: 0.01786, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.35170 
Train Epoch: 24 [89/250 11392/32000 (36%)] Loss: 1.96699 (semantic_loss: 0.01666, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.35318 
Train Epoch: 24 [100/250 12800/32000 (40%)] Loss: 1.96692 (semantic_loss: 0.01660, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.33661 
Train Epoch: 24 [111/250 14208/32000 (44%)] Loss: 1.96706 (semantic_loss: 0.01770, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.32630 
Train Epoch: 24 [122/250 15616/32000 (49%)] Loss: 1.96713 (semantic_loss: 0.01680, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.34041 
Train Epoch: 24 [133/250 17024/32000 (53%)] Loss: 1.96689 (semantic_loss: 0.01754, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.34590 
Train Epoch: 24 [144/250 18432/32000 (58%)] Loss: 1.96996 (semantic_loss: 0.01963, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.34112 
Train Epoch: 24 [155/250 19840/32000 (62%)] Loss: 1.96724 (semantic_loss: 0.01691, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.33053 
Train Epoch: 24 [166/250 21248/32000 (66%)] Loss: 1.96745 (semantic_loss: 0.01713, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.32862 
Train Epoch: 24 [177/250 22656/32000 (71%)] Loss: 1.96704 (semantic_loss: 0.01671, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.33353 
Train Epoch: 24 [188/250 24064/32000 (75%)] Loss: 1.96764 (semantic_loss: 0.01829, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.36105 
Train Epoch: 24 [199/250 25472/32000 (80%)] Loss: 1.96888 (semantic_loss: 0.01855, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.33274 
Train Epoch: 24 [210/250 26880/32000 (84%)] Loss: 1.96660 (semantic_loss: 0.01725, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.33317 
Train Epoch: 24 [221/250 28288/32000 (88%)] Loss: 1.96648 (semantic_loss: 0.01713, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.33757 
Train Epoch: 24 [232/250 29696/32000 (93%)] Loss: 1.96680 (semantic_loss: 0.01647, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.36129 
Train Epoch: 24 [243/250 31104/32000 (97%)] Loss: 1.96643 (semantic_loss: 0.01708, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.33921 
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/DCMH_MSRVTT_1kA/checkpoint-epoch24.pth ...
Done in 3.839s
Updating 'best' checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/DCMH_MSRVTT_1kA/checkpoint-epoch24.pth ...
Done in 7.625s
removing stale ckpt [epoch 23] [took 0.00s]
 epoch          : 24
 loss           : 1.9672569122314454
 learning_rate  : 1.5367843386251178e-05
 n_samples      : 768000
 n_steps        : 6000
 MSRVTT_jsfusion_test/t2v_metrics/R1: 16.8
 MSRVTT_jsfusion_test/t2v_metrics/R5: 42.3
 MSRVTT_jsfusion_test/t2v_metrics/R10: 56.8
 MSRVTT_jsfusion_test/t2v_metrics/R50: 84.6
 MSRVTT_jsfusion_test/t2v_metrics/MedR: 8.0
 MSRVTT_jsfusion_test/t2v_metrics/MeanR: 34.086
 MSRVTT_jsfusion_test/t2v_metrics/geometric_mean_R1-R5-R10: 34.303044096265616
 MSRVTT_jsfusion_test/v2t_metrics/R1: 17.1
 MSRVTT_jsfusion_test/v2t_metrics/R5: 43.0
 MSRVTT_jsfusion_test/v2t_metrics/R10: 58.4
 MSRVTT_jsfusion_test/v2t_metrics/R50: 84.5
 MSRVTT_jsfusion_test/v2t_metrics/MedR: 7.5
 MSRVTT_jsfusion_test/v2t_metrics/MeanR: 32.950500000000005
 MSRVTT_jsfusion_test/v2t_metrics/geometric_mean_R1-R5-R10: 35.01809132734306
 mnt_best       : 34.303044096265616
 not_improved_count: 0
Train Epoch: 25 [1/250 128/32000 (0%)] Loss: 1.96763 (semantic_loss: 0.01730, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=38.17679 
Train Epoch: 25 [12/250 1536/32000 (5%)] Loss: 1.96632 (semantic_loss: 0.01599, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.32814 
Train Epoch: 25 [23/250 2944/32000 (9%)] Loss: 1.96783 (semantic_loss: 0.01751, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.33647 
Train Epoch: 25 [34/250 4352/32000 (14%)] Loss: 1.96677 (semantic_loss: 0.01742, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.33708 
Train Epoch: 25 [45/250 5760/32000 (18%)] Loss: 1.96587 (semantic_loss: 0.01651, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.34146 
Train Epoch: 25 [56/250 7168/32000 (22%)] Loss: 1.96625 (semantic_loss: 0.01592, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.35662 
Train Epoch: 25 [67/250 8576/32000 (27%)] Loss: 1.96593 (semantic_loss: 0.01560, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.35424 
Train Epoch: 25 [78/250 9984/32000 (31%)] Loss: 1.96578 (semantic_loss: 0.01643, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.33281 
Train Epoch: 25 [89/250 11392/32000 (36%)] Loss: 1.96660 (semantic_loss: 0.01725, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.34130 
Train Epoch: 25 [100/250 12800/32000 (40%)] Loss: 1.96514 (semantic_loss: 0.01579, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.32968 
Train Epoch: 25 [111/250 14208/32000 (44%)] Loss: 1.96712 (semantic_loss: 0.01777, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.32909 
Train Epoch: 25 [122/250 15616/32000 (49%)] Loss: 1.96668 (semantic_loss: 0.01733, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.33023 
Train Epoch: 25 [133/250 17024/32000 (53%)] Loss: 1.96641 (semantic_loss: 0.01706, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.32637 
Train Epoch: 25 [144/250 18432/32000 (58%)] Loss: 1.96742 (semantic_loss: 0.01612, quant_loss: 1.95117, bit_balance_loss: 0.00013) batch_time=0.33136 
Train Epoch: 25 [155/250 19840/32000 (62%)] Loss: 1.96471 (semantic_loss: 0.01536, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.34993 
Train Epoch: 25 [166/250 21248/32000 (66%)] Loss: 1.96588 (semantic_loss: 0.01653, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.34729 
Train Epoch: 25 [177/250 22656/32000 (71%)] Loss: 1.96627 (semantic_loss: 0.01692, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.33739 
Train Epoch: 25 [188/250 24064/32000 (75%)] Loss: 1.96595 (semantic_loss: 0.01660, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.37530 
Train Epoch: 25 [199/250 25472/32000 (80%)] Loss: 1.96850 (semantic_loss: 0.01817, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.35327 
Train Epoch: 25 [210/250 26880/32000 (84%)] Loss: 1.96547 (semantic_loss: 0.01612, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.36133 
Train Epoch: 25 [221/250 28288/32000 (88%)] Loss: 1.96588 (semantic_loss: 0.01653, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.33830 
Train Epoch: 25 [232/250 29696/32000 (93%)] Loss: 1.96664 (semantic_loss: 0.01729, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.34407 
Train Epoch: 25 [243/250 31104/32000 (97%)] Loss: 1.96744 (semantic_loss: 0.01809, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.72526 
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/DCMH_MSRVTT_1kA/checkpoint-epoch25.pth ...
Done in 4.493s
Updating 'best' checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/DCMH_MSRVTT_1kA/checkpoint-epoch25.pth ...
Done in 9.265s
removing stale ckpt [epoch 24] [took 0.00s]
 epoch          : 25
 loss           : 1.9669339327812194
 learning_rate  : 1.4599451216938618e-05
 n_samples      : 800000
 n_steps        : 6250
 MSRVTT_jsfusion_test/t2v_metrics/R1: 17.1
 MSRVTT_jsfusion_test/t2v_metrics/R5: 44.1
 MSRVTT_jsfusion_test/t2v_metrics/R10: 58.1
 MSRVTT_jsfusion_test/t2v_metrics/R50: 84.0
 MSRVTT_jsfusion_test/t2v_metrics/MedR: 7.0
 MSRVTT_jsfusion_test/t2v_metrics/MeanR: 32.5925
 MSRVTT_jsfusion_test/t2v_metrics/geometric_mean_R1-R5-R10: 35.25361121898697
 MSRVTT_jsfusion_test/v2t_metrics/R1: 16.9
 MSRVTT_jsfusion_test/v2t_metrics/R5: 44.8
 MSRVTT_jsfusion_test/v2t_metrics/R10: 60.2
 MSRVTT_jsfusion_test/v2t_metrics/R50: 85.5
 MSRVTT_jsfusion_test/v2t_metrics/MedR: 7.0
 MSRVTT_jsfusion_test/v2t_metrics/MeanR: 31.687
 MSRVTT_jsfusion_test/v2t_metrics/geometric_mean_R1-R5-R10: 35.72073638300877
 mnt_best       : 35.25361121898697
 not_improved_count: 0
Train Epoch: 26 [1/250 128/32000 (0%)] Loss: 1.96606 (semantic_loss: 0.01671, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=34.39797 
Train Epoch: 26 [12/250 1536/32000 (5%)] Loss: 1.96741 (semantic_loss: 0.01708, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=2.15499 
Train Epoch: 26 [23/250 2944/32000 (9%)] Loss: 1.96713 (semantic_loss: 0.01680, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.33465 
Train Epoch: 26 [34/250 4352/32000 (14%)] Loss: 1.96810 (semantic_loss: 0.01777, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.37036 
Train Epoch: 26 [45/250 5760/32000 (18%)] Loss: 1.96689 (semantic_loss: 0.01754, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.35808 
Train Epoch: 26 [56/250 7168/32000 (22%)] Loss: 1.96732 (semantic_loss: 0.01699, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.32466 
Train Epoch: 26 [67/250 8576/32000 (27%)] Loss: 1.96602 (semantic_loss: 0.01666, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.35112 
Train Epoch: 26 [78/250 9984/32000 (31%)] Loss: 1.96643 (semantic_loss: 0.01708, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.33538 
Train Epoch: 26 [89/250 11392/32000 (36%)] Loss: 1.96625 (semantic_loss: 0.01691, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.35502 
Train Epoch: 26 [100/250 12800/32000 (40%)] Loss: 1.96661 (semantic_loss: 0.01628, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.77710 
Train Epoch: 26 [111/250 14208/32000 (44%)] Loss: 1.96641 (semantic_loss: 0.01706, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.33865 
Train Epoch: 26 [122/250 15616/32000 (49%)] Loss: 1.96444 (semantic_loss: 0.01509, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.32788 
Train Epoch: 26 [133/250 17024/32000 (53%)] Loss: 1.96568 (semantic_loss: 0.01633, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.44466 
Train Epoch: 26 [144/250 18432/32000 (58%)] Loss: 1.96616 (semantic_loss: 0.01681, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.33332 
Train Epoch: 26 [155/250 19840/32000 (62%)] Loss: 1.96979 (semantic_loss: 0.01946, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.34614 
Train Epoch: 26 [166/250 21248/32000 (66%)] Loss: 1.96754 (semantic_loss: 0.01819, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.36694 
Train Epoch: 26 [177/250 22656/32000 (71%)] Loss: 1.96589 (semantic_loss: 0.01654, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.34128 
Train Epoch: 26 [188/250 24064/32000 (75%)] Loss: 1.96591 (semantic_loss: 0.01655, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.32484 
Train Epoch: 26 [199/250 25472/32000 (80%)] Loss: 1.96774 (semantic_loss: 0.01741, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=2.35183 
Train Epoch: 26 [210/250 26880/32000 (84%)] Loss: 1.96940 (semantic_loss: 0.01908, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.33160 
Train Epoch: 26 [221/250 28288/32000 (88%)] Loss: 1.96771 (semantic_loss: 0.01738, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.33404 
Train Epoch: 26 [232/250 29696/32000 (93%)] Loss: 1.96652 (semantic_loss: 0.01717, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.34023 
Train Epoch: 26 [243/250 31104/32000 (97%)] Loss: 1.96743 (semantic_loss: 0.01710, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.35575 
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/DCMH_MSRVTT_1kA/checkpoint-epoch26.pth ...
Done in 4.165s
Updating 'best' checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/DCMH_MSRVTT_1kA/checkpoint-epoch26.pth ...
Done in 7.986s
removing stale ckpt [epoch 25] [took 0.24s]
 epoch          : 26
 loss           : 1.9667443647384644
 learning_rate  : 1.3869478656091687e-05
 n_samples      : 832000
 n_steps        : 6500
 MSRVTT_jsfusion_test/t2v_metrics/R1: 18.1
 MSRVTT_jsfusion_test/t2v_metrics/R5: 43.0
 MSRVTT_jsfusion_test/t2v_metrics/R10: 58.6
 MSRVTT_jsfusion_test/t2v_metrics/R50: 84.1
 MSRVTT_jsfusion_test/t2v_metrics/MedR: 7.0
 MSRVTT_jsfusion_test/t2v_metrics/MeanR: 33.201
 MSRVTT_jsfusion_test/t2v_metrics/geometric_mean_R1-R5-R10: 35.72850811835554
 MSRVTT_jsfusion_test/v2t_metrics/R1: 16.3
 MSRVTT_jsfusion_test/v2t_metrics/R5: 46.3
 MSRVTT_jsfusion_test/v2t_metrics/R10: 59.6
 MSRVTT_jsfusion_test/v2t_metrics/R50: 85.0
 MSRVTT_jsfusion_test/v2t_metrics/MedR: 6.25
 MSRVTT_jsfusion_test/v2t_metrics/MeanR: 32.2535
 MSRVTT_jsfusion_test/v2t_metrics/geometric_mean_R1-R5-R10: 35.56353734144415
 mnt_best       : 35.72850811835554
 not_improved_count: 0
Train Epoch: 27 [1/250 128/32000 (0%)] Loss: 1.96729 (semantic_loss: 0.01696, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=29.75794 
Train Epoch: 27 [12/250 1536/32000 (5%)] Loss: 1.96536 (semantic_loss: 0.01503, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.33503 
Train Epoch: 27 [23/250 2944/32000 (9%)] Loss: 1.96691 (semantic_loss: 0.01659, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.32928 
Train Epoch: 27 [34/250 4352/32000 (14%)] Loss: 1.96826 (semantic_loss: 0.01794, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.66727 
Train Epoch: 27 [45/250 5760/32000 (18%)] Loss: 1.96772 (semantic_loss: 0.01739, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.33747 
Train Epoch: 27 [56/250 7168/32000 (22%)] Loss: 1.96721 (semantic_loss: 0.01688, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.35680 
Train Epoch: 27 [67/250 8576/32000 (27%)] Loss: 1.96736 (semantic_loss: 0.01800, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=3.08428 
Train Epoch: 27 [78/250 9984/32000 (31%)] Loss: 1.96639 (semantic_loss: 0.01606, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.35343 
Train Epoch: 27 [89/250 11392/32000 (36%)] Loss: 1.96701 (semantic_loss: 0.01668, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.32715 
Train Epoch: 27 [100/250 12800/32000 (40%)] Loss: 1.96504 (semantic_loss: 0.01667, quant_loss: 1.94824, bit_balance_loss: 0.00013) batch_time=0.33121 
Train Epoch: 27 [111/250 14208/32000 (44%)] Loss: 1.96849 (semantic_loss: 0.01817, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.34862 
Train Epoch: 27 [122/250 15616/32000 (49%)] Loss: 1.96638 (semantic_loss: 0.01605, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.34886 
Train Epoch: 27 [133/250 17024/32000 (53%)] Loss: 1.96566 (semantic_loss: 0.01630, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.34073 
Train Epoch: 27 [144/250 18432/32000 (58%)] Loss: 1.96724 (semantic_loss: 0.01789, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.32453 
Train Epoch: 27 [155/250 19840/32000 (62%)] Loss: 1.96625 (semantic_loss: 0.01592, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.32792 
Train Epoch: 27 [166/250 21248/32000 (66%)] Loss: 1.96753 (semantic_loss: 0.01818, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.32828 
Train Epoch: 27 [177/250 22656/32000 (71%)] Loss: 1.96693 (semantic_loss: 0.01660, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.44964 
Train Epoch: 27 [188/250 24064/32000 (75%)] Loss: 1.96551 (semantic_loss: 0.01616, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.32896 
Train Epoch: 27 [199/250 25472/32000 (80%)] Loss: 1.96584 (semantic_loss: 0.01551, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.35688 
Train Epoch: 27 [210/250 26880/32000 (84%)] Loss: 1.96654 (semantic_loss: 0.01621, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.35789 
Train Epoch: 27 [221/250 28288/32000 (88%)] Loss: 1.96637 (semantic_loss: 0.01604, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.32815 
Train Epoch: 27 [232/250 29696/32000 (93%)] Loss: 1.96745 (semantic_loss: 0.01713, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.32755 
Train Epoch: 27 [243/250 31104/32000 (97%)] Loss: 1.96661 (semantic_loss: 0.01726, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.33557 
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/DCMH_MSRVTT_1kA/checkpoint-epoch27.pth ...
Done in 4.236s
Updating 'best' checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/DCMH_MSRVTT_1kA/checkpoint-epoch27.pth ...
Done in 9.023s
removing stale ckpt [epoch 26] [took 0.00s]
 epoch          : 27
 loss           : 1.966619641304016
 learning_rate  : 1.3176004723287102e-05
 n_samples      : 864000
 n_steps        : 6750
 MSRVTT_jsfusion_test/t2v_metrics/R1: 18.3
 MSRVTT_jsfusion_test/t2v_metrics/R5: 43.9
 MSRVTT_jsfusion_test/t2v_metrics/R10: 60.0
 MSRVTT_jsfusion_test/t2v_metrics/R50: 84.7
 MSRVTT_jsfusion_test/t2v_metrics/MedR: 7.0
 MSRVTT_jsfusion_test/t2v_metrics/MeanR: 32.638000000000005
 MSRVTT_jsfusion_test/t2v_metrics/geometric_mean_R1-R5-R10: 36.39337117143003
 MSRVTT_jsfusion_test/v2t_metrics/R1: 17.9
 MSRVTT_jsfusion_test/v2t_metrics/R5: 44.7
 MSRVTT_jsfusion_test/v2t_metrics/R10: 59.5
 MSRVTT_jsfusion_test/v2t_metrics/R50: 85.4
 MSRVTT_jsfusion_test/v2t_metrics/MedR: 7.0
 MSRVTT_jsfusion_test/v2t_metrics/MeanR: 31.106
 MSRVTT_jsfusion_test/v2t_metrics/geometric_mean_R1-R5-R10: 36.24314194479396
 mnt_best       : 36.39337117143003
 not_improved_count: 0
Train Epoch: 28 [1/250 128/32000 (0%)] Loss: 1.96510 (semantic_loss: 0.01575, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=39.92631 
Train Epoch: 28 [12/250 1536/32000 (5%)] Loss: 1.96611 (semantic_loss: 0.01676, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.33534 
Train Epoch: 28 [23/250 2944/32000 (9%)] Loss: 1.96580 (semantic_loss: 0.01547, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.33434 
Train Epoch: 28 [34/250 4352/32000 (14%)] Loss: 1.96678 (semantic_loss: 0.01645, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.33483 
Train Epoch: 28 [45/250 5760/32000 (18%)] Loss: 1.96769 (semantic_loss: 0.01737, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.35231 
Train Epoch: 28 [56/250 7168/32000 (22%)] Loss: 1.96469 (semantic_loss: 0.01534, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.34373 
Train Epoch: 28 [67/250 8576/32000 (27%)] Loss: 1.96674 (semantic_loss: 0.01642, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.34192 
Train Epoch: 28 [78/250 9984/32000 (31%)] Loss: 1.96643 (semantic_loss: 0.01610, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.33046 
Train Epoch: 28 [89/250 11392/32000 (36%)] Loss: 1.96807 (semantic_loss: 0.01774, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.35159 
Train Epoch: 28 [100/250 12800/32000 (40%)] Loss: 1.96685 (semantic_loss: 0.01653, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.33754 
Train Epoch: 28 [111/250 14208/32000 (44%)] Loss: 1.96687 (semantic_loss: 0.01654, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.34725 
Train Epoch: 28 [122/250 15616/32000 (49%)] Loss: 1.96628 (semantic_loss: 0.01596, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.34355 
Train Epoch: 28 [133/250 17024/32000 (53%)] Loss: 1.96681 (semantic_loss: 0.01649, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.35750 
Train Epoch: 28 [144/250 18432/32000 (58%)] Loss: 1.96640 (semantic_loss: 0.01607, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.32635 
Train Epoch: 28 [155/250 19840/32000 (62%)] Loss: 1.96657 (semantic_loss: 0.01625, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.34356 
Train Epoch: 28 [166/250 21248/32000 (66%)] Loss: 1.96481 (semantic_loss: 0.01546, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.33820 
Train Epoch: 28 [177/250 22656/32000 (71%)] Loss: 1.96546 (semantic_loss: 0.01611, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.41246 
Train Epoch: 28 [188/250 24064/32000 (75%)] Loss: 1.96643 (semantic_loss: 0.01707, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.32803 
Train Epoch: 28 [199/250 25472/32000 (80%)] Loss: 1.96735 (semantic_loss: 0.01703, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.32666 
Train Epoch: 28 [210/250 26880/32000 (84%)] Loss: 1.96512 (semantic_loss: 0.01576, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.34316 
Train Epoch: 28 [221/250 28288/32000 (88%)] Loss: 1.96755 (semantic_loss: 0.01820, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.32711 
Train Epoch: 28 [232/250 29696/32000 (93%)] Loss: 1.96923 (semantic_loss: 0.01890, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.32291 
Train Epoch: 28 [243/250 31104/32000 (97%)] Loss: 1.96513 (semantic_loss: 0.01578, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.36144 
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/DCMH_MSRVTT_1kA/checkpoint-epoch28.pth ...
Done in 3.777s
removing stale ckpt [epoch 27] [took 0.00s]
 epoch          : 28
 loss           : 1.9665147786140442
 learning_rate  : 1.2517204487122746e-05
 n_samples      : 896000
 n_steps        : 7000
 MSRVTT_jsfusion_test/t2v_metrics/R1: 18.1
 MSRVTT_jsfusion_test/t2v_metrics/R5: 44.0
 MSRVTT_jsfusion_test/t2v_metrics/R10: 58.8
 MSRVTT_jsfusion_test/t2v_metrics/R50: 85.2
 MSRVTT_jsfusion_test/t2v_metrics/MedR: 8.0
 MSRVTT_jsfusion_test/t2v_metrics/MeanR: 32.6635
 MSRVTT_jsfusion_test/t2v_metrics/geometric_mean_R1-R5-R10: 36.044266534065436
 MSRVTT_jsfusion_test/v2t_metrics/R1: 17.4
 MSRVTT_jsfusion_test/v2t_metrics/R5: 46.6
 MSRVTT_jsfusion_test/v2t_metrics/R10: 60.5
 MSRVTT_jsfusion_test/v2t_metrics/R50: 85.1
 MSRVTT_jsfusion_test/v2t_metrics/MedR: 6.0
 MSRVTT_jsfusion_test/v2t_metrics/MeanR: 31.311
 MSRVTT_jsfusion_test/v2t_metrics/geometric_mean_R1-R5-R10: 36.606947231497585
 mnt_best       : 36.39337117143003
 not_improved_count: 1
Train Epoch: 29 [1/250 128/32000 (0%)] Loss: 1.96544 (semantic_loss: 0.01608, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=30.00091 
Train Epoch: 29 [12/250 1536/32000 (5%)] Loss: 1.96443 (semantic_loss: 0.01507, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.33389 
Train Epoch: 29 [23/250 2944/32000 (9%)] Loss: 1.96750 (semantic_loss: 0.01717, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.32346 
Train Epoch: 29 [34/250 4352/32000 (14%)] Loss: 1.96721 (semantic_loss: 0.01688, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.34809 
Train Epoch: 29 [45/250 5760/32000 (18%)] Loss: 1.96708 (semantic_loss: 0.01676, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.32648 
Train Epoch: 29 [56/250 7168/32000 (22%)] Loss: 1.96760 (semantic_loss: 0.01727, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.33585 
Train Epoch: 29 [67/250 8576/32000 (27%)] Loss: 1.96651 (semantic_loss: 0.01618, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.35242 
Train Epoch: 29 [78/250 9984/32000 (31%)] Loss: 1.96421 (semantic_loss: 0.01486, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.33297 
Train Epoch: 29 [89/250 11392/32000 (36%)] Loss: 1.96475 (semantic_loss: 0.01539, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.34436 
Train Epoch: 29 [100/250 12800/32000 (40%)] Loss: 1.96815 (semantic_loss: 0.01782, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.35137 
Train Epoch: 29 [111/250 14208/32000 (44%)] Loss: 1.96543 (semantic_loss: 0.01511, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.34077 
Train Epoch: 29 [122/250 15616/32000 (49%)] Loss: 1.96693 (semantic_loss: 0.01660, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.34187 
Train Epoch: 29 [133/250 17024/32000 (53%)] Loss: 1.96541 (semantic_loss: 0.01606, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.32975 
Train Epoch: 29 [144/250 18432/32000 (58%)] Loss: 1.96823 (semantic_loss: 0.01888, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.33050 
Train Epoch: 29 [155/250 19840/32000 (62%)] Loss: 1.96642 (semantic_loss: 0.01610, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.35765 
Train Epoch: 29 [166/250 21248/32000 (66%)] Loss: 1.96623 (semantic_loss: 0.01590, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.33952 
Train Epoch: 29 [177/250 22656/32000 (71%)] Loss: 1.96635 (semantic_loss: 0.01601, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.32490 
Train Epoch: 29 [188/250 24064/32000 (75%)] Loss: 1.96703 (semantic_loss: 0.01669, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.34264 
Train Epoch: 29 [199/250 25472/32000 (80%)] Loss: 1.96846 (semantic_loss: 0.01813, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=3.56153 
Train Epoch: 29 [210/250 26880/32000 (84%)] Loss: 1.96592 (semantic_loss: 0.01657, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.33552 
Train Epoch: 29 [221/250 28288/32000 (88%)] Loss: 1.96621 (semantic_loss: 0.01589, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.32999 
Train Epoch: 29 [232/250 29696/32000 (93%)] Loss: 1.96561 (semantic_loss: 0.01626, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.32383 
Train Epoch: 29 [243/250 31104/32000 (97%)] Loss: 1.96505 (semantic_loss: 0.01570, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.33572 
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/DCMH_MSRVTT_1kA/checkpoint-epoch29.pth ...
Done in 4.538s
removing stale ckpt [epoch 28] [took 0.00s]
 epoch          : 29
 loss           : 1.966331030845642
 learning_rate  : 1.1891344262766608e-05
 n_samples      : 928000
 n_steps        : 7250
 MSRVTT_jsfusion_test/t2v_metrics/R1: 17.5
 MSRVTT_jsfusion_test/t2v_metrics/R5: 44.7
 MSRVTT_jsfusion_test/t2v_metrics/R10: 58.2
 MSRVTT_jsfusion_test/t2v_metrics/R50: 84.6
 MSRVTT_jsfusion_test/t2v_metrics/MedR: 7.0
 MSRVTT_jsfusion_test/t2v_metrics/MeanR: 33.2755
 MSRVTT_jsfusion_test/t2v_metrics/geometric_mean_R1-R5-R10: 35.707232016485264
 MSRVTT_jsfusion_test/v2t_metrics/R1: 17.5
 MSRVTT_jsfusion_test/v2t_metrics/R5: 44.8
 MSRVTT_jsfusion_test/v2t_metrics/R10: 60.7
 MSRVTT_jsfusion_test/v2t_metrics/R50: 84.3
 MSRVTT_jsfusion_test/v2t_metrics/MedR: 7.0
 MSRVTT_jsfusion_test/v2t_metrics/MeanR: 32.119
 MSRVTT_jsfusion_test/v2t_metrics/geometric_mean_R1-R5-R10: 36.23833631887836
 mnt_best       : 36.39337117143003
 not_improved_count: 2
Train Epoch: 30 [1/250 128/32000 (0%)] Loss: 1.96481 (semantic_loss: 0.01546, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=30.19475 
Train Epoch: 30 [12/250 1536/32000 (5%)] Loss: 1.96558 (semantic_loss: 0.01623, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.34800 
Train Epoch: 30 [23/250 2944/32000 (9%)] Loss: 1.96662 (semantic_loss: 0.01629, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.34906 
Train Epoch: 30 [34/250 4352/32000 (14%)] Loss: 1.96745 (semantic_loss: 0.01713, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.34071 
Train Epoch: 30 [45/250 5760/32000 (18%)] Loss: 1.96566 (semantic_loss: 0.01631, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.37953 
Train Epoch: 30 [56/250 7168/32000 (22%)] Loss: 1.96731 (semantic_loss: 0.01698, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.32705 
Train Epoch: 30 [67/250 8576/32000 (27%)] Loss: 1.96796 (semantic_loss: 0.01763, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.35164 
Train Epoch: 30 [78/250 9984/32000 (31%)] Loss: 1.96788 (semantic_loss: 0.01755, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.34743 
Train Epoch: 30 [89/250 11392/32000 (36%)] Loss: 1.96724 (semantic_loss: 0.01692, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.36671 
Train Epoch: 30 [100/250 12800/32000 (40%)] Loss: 1.96781 (semantic_loss: 0.01748, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.33394 
Train Epoch: 30 [111/250 14208/32000 (44%)] Loss: 1.96606 (semantic_loss: 0.01671, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.32783 
Train Epoch: 30 [122/250 15616/32000 (49%)] Loss: 1.96596 (semantic_loss: 0.01563, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.33546 
Train Epoch: 30 [133/250 17024/32000 (53%)] Loss: 1.96766 (semantic_loss: 0.01733, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.33173 
Train Epoch: 30 [144/250 18432/32000 (58%)] Loss: 1.96524 (semantic_loss: 0.01491, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=1.80492 
Train Epoch: 30 [155/250 19840/32000 (62%)] Loss: 1.96577 (semantic_loss: 0.01642, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.34103 
Train Epoch: 30 [166/250 21248/32000 (66%)] Loss: 1.96781 (semantic_loss: 0.01748, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.36055 
Train Epoch: 30 [177/250 22656/32000 (71%)] Loss: 1.96729 (semantic_loss: 0.01696, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.34088 
Train Epoch: 30 [188/250 24064/32000 (75%)] Loss: 1.96444 (semantic_loss: 0.01509, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.34591 
Train Epoch: 30 [199/250 25472/32000 (80%)] Loss: 1.96541 (semantic_loss: 0.01606, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.34483 
Train Epoch: 30 [210/250 26880/32000 (84%)] Loss: 1.96520 (semantic_loss: 0.01585, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.33880 
Train Epoch: 30 [221/250 28288/32000 (88%)] Loss: 1.96512 (semantic_loss: 0.01577, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.33978 
Train Epoch: 30 [232/250 29696/32000 (93%)] Loss: 1.96533 (semantic_loss: 0.01598, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.34725 
Train Epoch: 30 [243/250 31104/32000 (97%)] Loss: 1.96558 (semantic_loss: 0.01526, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.34081 
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/DCMH_MSRVTT_1kA/checkpoint-epoch30.pth ...
Done in 3.892s
removing stale ckpt [epoch 29] [took 0.00s]
 epoch          : 30
 loss           : 1.966190145969391
 learning_rate  : 1.1296777049628277e-05
 n_samples      : 960000
 n_steps        : 7500
 MSRVTT_jsfusion_test/t2v_metrics/R1: 17.4
 MSRVTT_jsfusion_test/t2v_metrics/R5: 43.6
 MSRVTT_jsfusion_test/t2v_metrics/R10: 57.8
 MSRVTT_jsfusion_test/t2v_metrics/R50: 84.4
 MSRVTT_jsfusion_test/t2v_metrics/MedR: 7.0
 MSRVTT_jsfusion_test/t2v_metrics/MeanR: 32.984
 MSRVTT_jsfusion_test/t2v_metrics/geometric_mean_R1-R5-R10: 35.26315710246877
 MSRVTT_jsfusion_test/v2t_metrics/R1: 17.1
 MSRVTT_jsfusion_test/v2t_metrics/R5: 45.0
 MSRVTT_jsfusion_test/v2t_metrics/R10: 60.5
 MSRVTT_jsfusion_test/v2t_metrics/R50: 85.4
 MSRVTT_jsfusion_test/v2t_metrics/MedR: 7.0
 MSRVTT_jsfusion_test/v2t_metrics/MeanR: 32.195499999999996
 MSRVTT_jsfusion_test/v2t_metrics/geometric_mean_R1-R5-R10: 35.97393947257751
 mnt_best       : 36.39337117143003
 not_improved_count: 3
Train Epoch: 31 [1/250 128/32000 (0%)] Loss: 1.96474 (semantic_loss: 0.01539, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=31.48009 
Train Epoch: 31 [12/250 1536/32000 (5%)] Loss: 1.96694 (semantic_loss: 0.01662, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.32618 
Train Epoch: 31 [23/250 2944/32000 (9%)] Loss: 1.96630 (semantic_loss: 0.01597, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.32862 
Train Epoch: 31 [34/250 4352/32000 (14%)] Loss: 1.96534 (semantic_loss: 0.01599, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.34652 
Train Epoch: 31 [45/250 5760/32000 (18%)] Loss: 1.96581 (semantic_loss: 0.01645, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.35160 
Train Epoch: 31 [56/250 7168/32000 (22%)] Loss: 1.96531 (semantic_loss: 0.01596, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.38014 
Train Epoch: 31 [67/250 8576/32000 (27%)] Loss: 1.96447 (semantic_loss: 0.01512, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=4.71773 
Train Epoch: 31 [78/250 9984/32000 (31%)] Loss: 1.96597 (semantic_loss: 0.01564, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.32932 
Train Epoch: 31 [89/250 11392/32000 (36%)] Loss: 1.96539 (semantic_loss: 0.01604, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.33049 
Train Epoch: 31 [100/250 12800/32000 (40%)] Loss: 1.96397 (semantic_loss: 0.01364, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.34579 
Train Epoch: 31 [111/250 14208/32000 (44%)] Loss: 1.96534 (semantic_loss: 0.01501, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.34031 
Train Epoch: 31 [122/250 15616/32000 (49%)] Loss: 1.96786 (semantic_loss: 0.01753, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.32766 
Train Epoch: 31 [133/250 17024/32000 (53%)] Loss: 1.96667 (semantic_loss: 0.01634, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.34153 
Train Epoch: 31 [144/250 18432/32000 (58%)] Loss: 1.96607 (semantic_loss: 0.01574, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.33401 
Train Epoch: 31 [155/250 19840/32000 (62%)] Loss: 1.96625 (semantic_loss: 0.01592, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.35353 
Train Epoch: 31 [166/250 21248/32000 (66%)] Loss: 1.96731 (semantic_loss: 0.01698, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.33153 
Train Epoch: 31 [177/250 22656/32000 (71%)] Loss: 1.96571 (semantic_loss: 0.01636, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.32609 
Train Epoch: 31 [188/250 24064/32000 (75%)] Loss: 1.96489 (semantic_loss: 0.01554, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.33970 
Train Epoch: 31 [199/250 25472/32000 (80%)] Loss: 1.96652 (semantic_loss: 0.01717, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.36864 
Train Epoch: 31 [210/250 26880/32000 (84%)] Loss: 1.96499 (semantic_loss: 0.01564, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.32641 
Train Epoch: 31 [221/250 28288/32000 (88%)] Loss: 1.96700 (semantic_loss: 0.01667, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.33871 
Train Epoch: 31 [232/250 29696/32000 (93%)] Loss: 1.96569 (semantic_loss: 0.01634, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.35331 
Train Epoch: 31 [243/250 31104/32000 (97%)] Loss: 1.96393 (semantic_loss: 0.01556, quant_loss: 1.94824, bit_balance_loss: 0.00013) batch_time=0.33163 
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/DCMH_MSRVTT_1kA/checkpoint-epoch31.pth ...
Done in 9.138s
Updating 'best' checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/DCMH_MSRVTT_1kA/checkpoint-epoch31.pth ...
Done in 21.265s
removing stale ckpt [epoch 30] [took 0.00s]
 epoch          : 31
 loss           : 1.9660240120887755
 learning_rate  : 1.0731938197146863e-05
 n_samples      : 992000
 n_steps        : 7750
 MSRVTT_jsfusion_test/t2v_metrics/R1: 18.7
 MSRVTT_jsfusion_test/t2v_metrics/R5: 44.3
 MSRVTT_jsfusion_test/t2v_metrics/R10: 59.2
 MSRVTT_jsfusion_test/t2v_metrics/R50: 85.2
 MSRVTT_jsfusion_test/t2v_metrics/MedR: 7.0
 MSRVTT_jsfusion_test/t2v_metrics/MeanR: 32.316500000000005
 MSRVTT_jsfusion_test/t2v_metrics/geometric_mean_R1-R5-R10: 36.60347742845921
 MSRVTT_jsfusion_test/v2t_metrics/R1: 17.3
 MSRVTT_jsfusion_test/v2t_metrics/R5: 44.7
 MSRVTT_jsfusion_test/v2t_metrics/R10: 61.0
 MSRVTT_jsfusion_test/v2t_metrics/R50: 85.4
 MSRVTT_jsfusion_test/v2t_metrics/MedR: 6.5
 MSRVTT_jsfusion_test/v2t_metrics/MeanR: 31.037
 MSRVTT_jsfusion_test/v2t_metrics/geometric_mean_R1-R5-R10: 36.13220678925215
 mnt_best       : 36.60347742845921
 not_improved_count: 0
Train Epoch: 32 [1/250 128/32000 (0%)] Loss: 1.96421 (semantic_loss: 0.01486, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=36.77082 
Train Epoch: 32 [12/250 1536/32000 (5%)] Loss: 1.96558 (semantic_loss: 0.01525, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.32354 
Train Epoch: 32 [23/250 2944/32000 (9%)] Loss: 1.96657 (semantic_loss: 0.01624, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.35167 
Train Epoch: 32 [34/250 4352/32000 (14%)] Loss: 1.96607 (semantic_loss: 0.01574, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.32629 
Train Epoch: 32 [45/250 5760/32000 (18%)] Loss: 1.96593 (semantic_loss: 0.01658, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.37043 
Train Epoch: 32 [56/250 7168/32000 (22%)] Loss: 1.96768 (semantic_loss: 0.01736, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.33928 
Train Epoch: 32 [67/250 8576/32000 (27%)] Loss: 1.96514 (semantic_loss: 0.01579, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.98803 
Train Epoch: 32 [78/250 9984/32000 (31%)] Loss: 1.96487 (semantic_loss: 0.01453, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.32574 
Train Epoch: 32 [89/250 11392/32000 (36%)] Loss: 1.96500 (semantic_loss: 0.01564, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.32877 
Train Epoch: 32 [100/250 12800/32000 (40%)] Loss: 1.96678 (semantic_loss: 0.01743, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.33678 
Train Epoch: 32 [111/250 14208/32000 (44%)] Loss: 1.96537 (semantic_loss: 0.01504, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.33861 
Train Epoch: 32 [122/250 15616/32000 (49%)] Loss: 1.96439 (semantic_loss: 0.01407, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.35547 
Train Epoch: 32 [133/250 17024/32000 (53%)] Loss: 1.96569 (semantic_loss: 0.01634, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.32582 
Train Epoch: 32 [144/250 18432/32000 (58%)] Loss: 1.96645 (semantic_loss: 0.01612, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.32848 
Train Epoch: 32 [155/250 19840/32000 (62%)] Loss: 1.96587 (semantic_loss: 0.01555, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.35193 
Train Epoch: 32 [166/250 21248/32000 (66%)] Loss: 1.96797 (semantic_loss: 0.01862, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.45050 
Train Epoch: 32 [177/250 22656/32000 (71%)] Loss: 1.96496 (semantic_loss: 0.01561, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=1.00514 
Train Epoch: 32 [188/250 24064/32000 (75%)] Loss: 1.96745 (semantic_loss: 0.01810, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.32649 
Train Epoch: 32 [199/250 25472/32000 (80%)] Loss: 1.96551 (semantic_loss: 0.01616, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.32609 
Train Epoch: 32 [210/250 26880/32000 (84%)] Loss: 1.96379 (semantic_loss: 0.01444, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.33895 
Train Epoch: 32 [221/250 28288/32000 (88%)] Loss: 1.96594 (semantic_loss: 0.01561, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.33745 
Train Epoch: 32 [232/250 29696/32000 (93%)] Loss: 1.96489 (semantic_loss: 0.01554, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.37509 
Train Epoch: 32 [243/250 31104/32000 (97%)] Loss: 1.96489 (semantic_loss: 0.01554, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.32920 
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/DCMH_MSRVTT_1kA/checkpoint-epoch32.pth ...
Done in 4.056s
Updating 'best' checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/DCMH_MSRVTT_1kA/checkpoint-epoch32.pth ...
Done in 8.651s
removing stale ckpt [epoch 31] [took 0.00s]
 epoch          : 32
 loss           : 1.9657710366249084
 learning_rate  : 1.019534128728952e-05
 n_samples      : 1024000
 n_steps        : 8000
 MSRVTT_jsfusion_test/t2v_metrics/R1: 18.8
 MSRVTT_jsfusion_test/t2v_metrics/R5: 46.1
 MSRVTT_jsfusion_test/t2v_metrics/R10: 59.4
 MSRVTT_jsfusion_test/t2v_metrics/R50: 84.5
 MSRVTT_jsfusion_test/t2v_metrics/MedR: 7.0
 MSRVTT_jsfusion_test/t2v_metrics/MeanR: 32.769
 MSRVTT_jsfusion_test/t2v_metrics/geometric_mean_R1-R5-R10: 37.200468256332606
 MSRVTT_jsfusion_test/v2t_metrics/R1: 18.6
 MSRVTT_jsfusion_test/v2t_metrics/R5: 46.5
 MSRVTT_jsfusion_test/v2t_metrics/R10: 60.7
 MSRVTT_jsfusion_test/v2t_metrics/R50: 84.9
 MSRVTT_jsfusion_test/v2t_metrics/MedR: 7.0
 MSRVTT_jsfusion_test/v2t_metrics/MeanR: 31.481
 MSRVTT_jsfusion_test/v2t_metrics/geometric_mean_R1-R5-R10: 37.44422642267319
 mnt_best       : 37.200468256332606
 not_improved_count: 0
Train Epoch: 33 [1/250 128/32000 (0%)] Loss: 1.96400 (semantic_loss: 0.01464, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=32.11655 
Train Epoch: 33 [12/250 1536/32000 (5%)] Loss: 1.96645 (semantic_loss: 0.01612, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.87542 
Train Epoch: 33 [23/250 2944/32000 (9%)] Loss: 1.96580 (semantic_loss: 0.01645, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.32364 
Train Epoch: 33 [34/250 4352/32000 (14%)] Loss: 1.96664 (semantic_loss: 0.01729, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.33889 
Train Epoch: 33 [45/250 5760/32000 (18%)] Loss: 1.96762 (semantic_loss: 0.01631, quant_loss: 1.95117, bit_balance_loss: 0.00013) batch_time=0.68594 
Train Epoch: 33 [56/250 7168/32000 (22%)] Loss: 1.96481 (semantic_loss: 0.01546, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.32784 
Train Epoch: 33 [67/250 8576/32000 (27%)] Loss: 1.96699 (semantic_loss: 0.01763, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.55416 
Train Epoch: 33 [78/250 9984/32000 (31%)] Loss: 1.96577 (semantic_loss: 0.01642, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.33990 
Train Epoch: 33 [89/250 11392/32000 (36%)] Loss: 1.96503 (semantic_loss: 0.01470, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.33792 
Train Epoch: 33 [100/250 12800/32000 (40%)] Loss: 1.96663 (semantic_loss: 0.01630, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.33955 
Train Epoch: 33 [111/250 14208/32000 (44%)] Loss: 1.96626 (semantic_loss: 0.01594, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.34500 
Train Epoch: 33 [122/250 15616/32000 (49%)] Loss: 1.96627 (semantic_loss: 0.01692, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.32754 
Train Epoch: 33 [133/250 17024/32000 (53%)] Loss: 1.96589 (semantic_loss: 0.01557, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.32880 
Train Epoch: 33 [144/250 18432/32000 (58%)] Loss: 1.96449 (semantic_loss: 0.01514, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.33956 
Train Epoch: 33 [155/250 19840/32000 (62%)] Loss: 1.96601 (semantic_loss: 0.01666, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.33926 
Train Epoch: 33 [166/250 21248/32000 (66%)] Loss: 1.96695 (semantic_loss: 0.01662, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.32861 
Train Epoch: 33 [177/250 22656/32000 (71%)] Loss: 1.96652 (semantic_loss: 0.01717, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.33677 
Train Epoch: 33 [188/250 24064/32000 (75%)] Loss: 1.96532 (semantic_loss: 0.01499, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.46183 
Train Epoch: 33 [199/250 25472/32000 (80%)] Loss: 1.96510 (semantic_loss: 0.01574, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.32673 
Train Epoch: 33 [210/250 26880/32000 (84%)] Loss: 1.96690 (semantic_loss: 0.01756, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.34729 
Train Epoch: 33 [221/250 28288/32000 (88%)] Loss: 1.96689 (semantic_loss: 0.01657, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.33785 
Train Epoch: 33 [232/250 29696/32000 (93%)] Loss: 1.96564 (semantic_loss: 0.01531, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.32890 
Train Epoch: 33 [243/250 31104/32000 (97%)] Loss: 1.96584 (semantic_loss: 0.01649, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.33018 
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/DCMH_MSRVTT_1kA/checkpoint-epoch33.pth ...
Done in 3.713s
removing stale ckpt [epoch 32] [took 0.00s]
 epoch          : 33
 loss           : 1.9657777342796325
 learning_rate  : 9.685574222925043e-06
 n_samples      : 1056000
 n_steps        : 8250
 MSRVTT_jsfusion_test/t2v_metrics/R1: 17.7
 MSRVTT_jsfusion_test/t2v_metrics/R5: 46.4
 MSRVTT_jsfusion_test/t2v_metrics/R10: 60.2
 MSRVTT_jsfusion_test/t2v_metrics/R50: 84.6
 MSRVTT_jsfusion_test/t2v_metrics/MedR: 6.0
 MSRVTT_jsfusion_test/t2v_metrics/MeanR: 32.822
 MSRVTT_jsfusion_test/t2v_metrics/geometric_mean_R1-R5-R10: 36.70252242807675
 MSRVTT_jsfusion_test/v2t_metrics/R1: 18.2
 MSRVTT_jsfusion_test/v2t_metrics/R5: 47.2
 MSRVTT_jsfusion_test/v2t_metrics/R10: 61.4
 MSRVTT_jsfusion_test/v2t_metrics/R50: 85.5
 MSRVTT_jsfusion_test/v2t_metrics/MedR: 7.0
 MSRVTT_jsfusion_test/v2t_metrics/MeanR: 31.7985
 MSRVTT_jsfusion_test/v2t_metrics/geometric_mean_R1-R5-R10: 37.502531621679175
 mnt_best       : 37.200468256332606
 not_improved_count: 1
Train Epoch: 34 [1/250 128/32000 (0%)] Loss: 1.96513 (semantic_loss: 0.01578, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=25.24971 
Train Epoch: 34 [12/250 1536/32000 (5%)] Loss: 1.96546 (semantic_loss: 0.01611, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.33818 
Train Epoch: 34 [23/250 2944/32000 (9%)] Loss: 1.96580 (semantic_loss: 0.01547, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.33415 
Train Epoch: 34 [34/250 4352/32000 (14%)] Loss: 1.96636 (semantic_loss: 0.01603, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.34556 
Train Epoch: 34 [45/250 5760/32000 (18%)] Loss: 1.96758 (semantic_loss: 0.01725, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.34279 
Train Epoch: 34 [56/250 7168/32000 (22%)] Loss: 1.96562 (semantic_loss: 0.01529, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.34257 
Train Epoch: 34 [67/250 8576/32000 (27%)] Loss: 1.96635 (semantic_loss: 0.01700, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=1.32596 
Train Epoch: 34 [78/250 9984/32000 (31%)] Loss: 1.96519 (semantic_loss: 0.01486, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.32495 
Train Epoch: 34 [89/250 11392/32000 (36%)] Loss: 1.96580 (semantic_loss: 0.01548, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.34474 
Train Epoch: 34 [100/250 12800/32000 (40%)] Loss: 1.96431 (semantic_loss: 0.01496, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.32563 
Train Epoch: 34 [111/250 14208/32000 (44%)] Loss: 1.96683 (semantic_loss: 0.01650, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.37964 
Train Epoch: 34 [122/250 15616/32000 (49%)] Loss: 1.96650 (semantic_loss: 0.01617, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.34727 
Train Epoch: 34 [133/250 17024/32000 (53%)] Loss: 1.96564 (semantic_loss: 0.01629, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.88576 
Train Epoch: 34 [144/250 18432/32000 (58%)] Loss: 1.96573 (semantic_loss: 0.01541, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.36506 
Train Epoch: 34 [155/250 19840/32000 (62%)] Loss: 1.96467 (semantic_loss: 0.01532, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.32717 
Train Epoch: 34 [166/250 21248/32000 (66%)] Loss: 1.96602 (semantic_loss: 0.01569, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.33095 
Train Epoch: 34 [177/250 22656/32000 (71%)] Loss: 1.96632 (semantic_loss: 0.01600, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.37889 
Train Epoch: 34 [188/250 24064/32000 (75%)] Loss: 1.96616 (semantic_loss: 0.01583, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.33713 
Train Epoch: 34 [199/250 25472/32000 (80%)] Loss: 1.96691 (semantic_loss: 0.01658, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.34711 
Train Epoch: 34 [210/250 26880/32000 (84%)] Loss: 1.96597 (semantic_loss: 0.01565, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.34459 
Train Epoch: 34 [221/250 28288/32000 (88%)] Loss: 1.96583 (semantic_loss: 0.01550, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.35138 
Train Epoch: 34 [232/250 29696/32000 (93%)] Loss: 1.96596 (semantic_loss: 0.01564, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.43978 
Train Epoch: 34 [243/250 31104/32000 (97%)] Loss: 1.96466 (semantic_loss: 0.01531, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.32852 
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/DCMH_MSRVTT_1kA/checkpoint-epoch34.pth ...
Done in 4.203s
Updating 'best' checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/DCMH_MSRVTT_1kA/checkpoint-epoch34.pth ...
Done in 21.800s
removing stale ckpt [epoch 33] [took 0.00s]
 epoch          : 34
 loss           : 1.9656540331840515
 learning_rate  : 9.20129551177879e-06
 n_samples      : 1088000
 n_steps        : 8500
 MSRVTT_jsfusion_test/t2v_metrics/R1: 18.9
 MSRVTT_jsfusion_test/t2v_metrics/R5: 46.0
 MSRVTT_jsfusion_test/t2v_metrics/R10: 60.1
 MSRVTT_jsfusion_test/t2v_metrics/R50: 84.8
 MSRVTT_jsfusion_test/t2v_metrics/MedR: 6.25
 MSRVTT_jsfusion_test/t2v_metrics/MeanR: 32.853
 MSRVTT_jsfusion_test/t2v_metrics/geometric_mean_R1-R5-R10: 37.38505603691966
 MSRVTT_jsfusion_test/v2t_metrics/R1: 18.2
 MSRVTT_jsfusion_test/v2t_metrics/R5: 47.2
 MSRVTT_jsfusion_test/v2t_metrics/R10: 62.0
 MSRVTT_jsfusion_test/v2t_metrics/R50: 85.0
 MSRVTT_jsfusion_test/v2t_metrics/MedR: 6.0
 MSRVTT_jsfusion_test/v2t_metrics/MeanR: 31.9515
 MSRVTT_jsfusion_test/v2t_metrics/geometric_mean_R1-R5-R10: 37.62429394229914
 mnt_best       : 37.38505603691966
 not_improved_count: 0
Train Epoch: 35 [1/250 128/32000 (0%)] Loss: 1.96562 (semantic_loss: 0.01725, quant_loss: 1.94824, bit_balance_loss: 0.00013) batch_time=29.92264 
Train Epoch: 35 [12/250 1536/32000 (5%)] Loss: 1.96453 (semantic_loss: 0.01518, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.32048 
Train Epoch: 35 [23/250 2944/32000 (9%)] Loss: 1.96632 (semantic_loss: 0.01600, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.32100 
Train Epoch: 35 [34/250 4352/32000 (14%)] Loss: 1.96561 (semantic_loss: 0.01528, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.33942 
Train Epoch: 35 [45/250 5760/32000 (18%)] Loss: 1.96618 (semantic_loss: 0.01585, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.33964 
Train Epoch: 35 [56/250 7168/32000 (22%)] Loss: 1.96487 (semantic_loss: 0.01455, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.34658 
Train Epoch: 35 [67/250 8576/32000 (27%)] Loss: 1.96829 (semantic_loss: 0.01797, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.33893 
Train Epoch: 35 [78/250 9984/32000 (31%)] Loss: 1.96418 (semantic_loss: 0.01483, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.33403 
Train Epoch: 35 [89/250 11392/32000 (36%)] Loss: 1.96881 (semantic_loss: 0.01848, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.36879 
Train Epoch: 35 [100/250 12800/32000 (40%)] Loss: 1.96672 (semantic_loss: 0.01639, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.33018 
Train Epoch: 35 [111/250 14208/32000 (44%)] Loss: 1.96547 (semantic_loss: 0.01514, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.34549 
Train Epoch: 35 [122/250 15616/32000 (49%)] Loss: 1.96555 (semantic_loss: 0.01522, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.33077 
Train Epoch: 35 [133/250 17024/32000 (53%)] Loss: 1.96627 (semantic_loss: 0.01594, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=2.37509 
Train Epoch: 35 [144/250 18432/32000 (58%)] Loss: 1.96445 (semantic_loss: 0.01511, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.33338 
Train Epoch: 35 [155/250 19840/32000 (62%)] Loss: 1.96490 (semantic_loss: 0.01555, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.37711 
Train Epoch: 35 [166/250 21248/32000 (66%)] Loss: 1.96543 (semantic_loss: 0.01511, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.35871 
Train Epoch: 35 [177/250 22656/32000 (71%)] Loss: 1.96594 (semantic_loss: 0.01660, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.34440 
Train Epoch: 35 [188/250 24064/32000 (75%)] Loss: 1.96630 (semantic_loss: 0.01597, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.33832 
Train Epoch: 35 [199/250 25472/32000 (80%)] Loss: 1.96368 (semantic_loss: 0.01433, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.33914 
Train Epoch: 35 [210/250 26880/32000 (84%)] Loss: 1.96502 (semantic_loss: 0.01469, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.32278 
Train Epoch: 35 [221/250 28288/32000 (88%)] Loss: 1.96376 (semantic_loss: 0.01441, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.33794 
Train Epoch: 35 [232/250 29696/32000 (93%)] Loss: 1.96632 (semantic_loss: 0.01697, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.34398 
Train Epoch: 35 [243/250 31104/32000 (97%)] Loss: 1.96548 (semantic_loss: 0.01515, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.32679 
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/DCMH_MSRVTT_1kA/checkpoint-epoch35.pth ...
Done in 4.041s
removing stale ckpt [epoch 34] [took 0.00s]
 epoch          : 35
 loss           : 1.9655632300376893
 learning_rate  : 8.74123073618985e-06
 n_samples      : 1120000
 n_steps        : 8750
 MSRVTT_jsfusion_test/t2v_metrics/R1: 17.1
 MSRVTT_jsfusion_test/t2v_metrics/R5: 47.0
 MSRVTT_jsfusion_test/t2v_metrics/R10: 59.9
 MSRVTT_jsfusion_test/t2v_metrics/R50: 85.0
 MSRVTT_jsfusion_test/t2v_metrics/MedR: 6.0
 MSRVTT_jsfusion_test/t2v_metrics/MeanR: 32.223
 MSRVTT_jsfusion_test/t2v_metrics/geometric_mean_R1-R5-R10: 36.37812103450168
 MSRVTT_jsfusion_test/v2t_metrics/R1: 18.1
 MSRVTT_jsfusion_test/v2t_metrics/R5: 47.4
 MSRVTT_jsfusion_test/v2t_metrics/R10: 62.5
 MSRVTT_jsfusion_test/v2t_metrics/R50: 84.5
 MSRVTT_jsfusion_test/v2t_metrics/MedR: 6.0
 MSRVTT_jsfusion_test/v2t_metrics/MeanR: 31.96
 MSRVTT_jsfusion_test/v2t_metrics/geometric_mean_R1-R5-R10: 37.709054620948315
 mnt_best       : 37.38505603691966
 not_improved_count: 1
Train Epoch: 36 [1/250 128/32000 (0%)] Loss: 1.96641 (semantic_loss: 0.01609, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=37.40611 
Train Epoch: 36 [12/250 1536/32000 (5%)] Loss: 1.96582 (semantic_loss: 0.01549, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.34532 
Train Epoch: 36 [23/250 2944/32000 (9%)] Loss: 1.96654 (semantic_loss: 0.01621, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.32656 
Train Epoch: 36 [34/250 4352/32000 (14%)] Loss: 1.96420 (semantic_loss: 0.01485, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.34371 
Train Epoch: 36 [45/250 5760/32000 (18%)] Loss: 1.96511 (semantic_loss: 0.01576, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.33439 
Train Epoch: 36 [56/250 7168/32000 (22%)] Loss: 1.96450 (semantic_loss: 0.01515, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.33969 
Train Epoch: 36 [67/250 8576/32000 (27%)] Loss: 1.96447 (semantic_loss: 0.01512, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.32611 
Train Epoch: 36 [78/250 9984/32000 (31%)] Loss: 1.96585 (semantic_loss: 0.01552, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.33498 
Train Epoch: 36 [89/250 11392/32000 (36%)] Loss: 1.96444 (semantic_loss: 0.01412, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.33669 
Train Epoch: 36 [100/250 12800/32000 (40%)] Loss: 1.96727 (semantic_loss: 0.01694, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.33415 
Train Epoch: 36 [111/250 14208/32000 (44%)] Loss: 1.96507 (semantic_loss: 0.01475, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.32501 
Train Epoch: 36 [122/250 15616/32000 (49%)] Loss: 1.96751 (semantic_loss: 0.01718, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.34430 
Train Epoch: 36 [133/250 17024/32000 (53%)] Loss: 1.96577 (semantic_loss: 0.01545, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=1.68667 
Train Epoch: 36 [144/250 18432/32000 (58%)] Loss: 1.96613 (semantic_loss: 0.01581, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.68902 
Train Epoch: 36 [155/250 19840/32000 (62%)] Loss: 1.96574 (semantic_loss: 0.01639, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.33700 
Train Epoch: 36 [166/250 21248/32000 (66%)] Loss: 1.96630 (semantic_loss: 0.01597, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.32673 
Train Epoch: 36 [177/250 22656/32000 (71%)] Loss: 1.96585 (semantic_loss: 0.01553, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.33674 
Train Epoch: 36 [188/250 24064/32000 (75%)] Loss: 1.96552 (semantic_loss: 0.01617, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.35307 
Train Epoch: 36 [199/250 25472/32000 (80%)] Loss: 1.96511 (semantic_loss: 0.01479, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.38027 
Train Epoch: 36 [210/250 26880/32000 (84%)] Loss: 1.96541 (semantic_loss: 0.01606, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.36945 
Train Epoch: 36 [221/250 28288/32000 (88%)] Loss: 1.96426 (semantic_loss: 0.01491, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.32694 
Train Epoch: 36 [232/250 29696/32000 (93%)] Loss: 1.96618 (semantic_loss: 0.01586, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.50335 
Train Epoch: 36 [243/250 31104/32000 (97%)] Loss: 1.96674 (semantic_loss: 0.01641, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.33355 
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/DCMH_MSRVTT_1kA/checkpoint-epoch36.pth ...
Done in 3.901s
removing stale ckpt [epoch 35] [took 0.00s]
 epoch          : 36
 loss           : 1.965443027973175
 learning_rate  : 8.304169199380357e-06
 n_samples      : 1152000
 n_steps        : 9000
 MSRVTT_jsfusion_test/t2v_metrics/R1: 18.6
 MSRVTT_jsfusion_test/t2v_metrics/R5: 45.6
 MSRVTT_jsfusion_test/t2v_metrics/R10: 59.8
 MSRVTT_jsfusion_test/t2v_metrics/R50: 85.0
 MSRVTT_jsfusion_test/t2v_metrics/MedR: 6.0
 MSRVTT_jsfusion_test/t2v_metrics/MeanR: 33.177
 MSRVTT_jsfusion_test/t2v_metrics/geometric_mean_R1-R5-R10: 37.01629863866724
 MSRVTT_jsfusion_test/v2t_metrics/R1: 18.7
 MSRVTT_jsfusion_test/v2t_metrics/R5: 46.2
 MSRVTT_jsfusion_test/v2t_metrics/R10: 61.7
 MSRVTT_jsfusion_test/v2t_metrics/R50: 85.1
 MSRVTT_jsfusion_test/v2t_metrics/MedR: 6.5
 MSRVTT_jsfusion_test/v2t_metrics/MeanR: 31.8045
 MSRVTT_jsfusion_test/v2t_metrics/geometric_mean_R1-R5-R10: 37.634797366179654
 mnt_best       : 37.38505603691966
 not_improved_count: 2
Train Epoch: 37 [1/250 128/32000 (0%)] Loss: 1.96613 (semantic_loss: 0.01580, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=28.84288 
Train Epoch: 37 [12/250 1536/32000 (5%)] Loss: 1.96342 (semantic_loss: 0.01407, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.34082 
Train Epoch: 37 [23/250 2944/32000 (9%)] Loss: 1.96587 (semantic_loss: 0.01555, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.35903 
Train Epoch: 37 [34/250 4352/32000 (14%)] Loss: 1.96565 (semantic_loss: 0.01533, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.68992 
Train Epoch: 37 [45/250 5760/32000 (18%)] Loss: 1.96642 (semantic_loss: 0.01609, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.35478 
Train Epoch: 37 [56/250 7168/32000 (22%)] Loss: 1.96564 (semantic_loss: 0.01531, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.35455 
Train Epoch: 37 [67/250 8576/32000 (27%)] Loss: 1.96617 (semantic_loss: 0.01585, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.45371 
Train Epoch: 37 [78/250 9984/32000 (31%)] Loss: 1.96561 (semantic_loss: 0.01626, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.36385 
Train Epoch: 37 [89/250 11392/32000 (36%)] Loss: 1.96704 (semantic_loss: 0.01671, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.34373 
Train Epoch: 37 [100/250 12800/32000 (40%)] Loss: 1.96616 (semantic_loss: 0.01583, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.38881 
Train Epoch: 37 [111/250 14208/32000 (44%)] Loss: 1.96770 (semantic_loss: 0.01640, quant_loss: 1.95117, bit_balance_loss: 0.00013) batch_time=0.32203 
Train Epoch: 37 [122/250 15616/32000 (49%)] Loss: 1.96552 (semantic_loss: 0.01520, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.32359 
Train Epoch: 37 [133/250 17024/32000 (53%)] Loss: 1.96511 (semantic_loss: 0.01577, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.32407 
Train Epoch: 37 [144/250 18432/32000 (58%)] Loss: 1.96420 (semantic_loss: 0.01485, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.35371 
Train Epoch: 37 [155/250 19840/32000 (62%)] Loss: 1.96609 (semantic_loss: 0.01576, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.33517 
Train Epoch: 37 [166/250 21248/32000 (66%)] Loss: 1.96426 (semantic_loss: 0.01492, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.35018 
Train Epoch: 37 [177/250 22656/32000 (71%)] Loss: 1.96603 (semantic_loss: 0.01571, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.35125 
Train Epoch: 37 [188/250 24064/32000 (75%)] Loss: 1.96482 (semantic_loss: 0.01450, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.34205 
Train Epoch: 37 [199/250 25472/32000 (80%)] Loss: 1.96434 (semantic_loss: 0.01500, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=2.50420 
Train Epoch: 37 [210/250 26880/32000 (84%)] Loss: 1.96327 (semantic_loss: 0.01392, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.33000 
Train Epoch: 37 [221/250 28288/32000 (88%)] Loss: 1.96361 (semantic_loss: 0.01426, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.38365 
Train Epoch: 37 [232/250 29696/32000 (93%)] Loss: 1.96483 (semantic_loss: 0.01548, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.32686 
Train Epoch: 37 [243/250 31104/32000 (97%)] Loss: 1.96608 (semantic_loss: 0.01576, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.33074 
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/DCMH_MSRVTT_1kA/checkpoint-epoch37.pth ...
Done in 3.971s
Updating 'best' checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/DCMH_MSRVTT_1kA/checkpoint-epoch37.pth ...
Done in 7.815s
removing stale ckpt [epoch 36] [took 0.01s]
 epoch          : 37
 loss           : 1.9654188194274902
 learning_rate  : 7.888960739411339e-06
 n_samples      : 1184000
 n_steps        : 9250
 MSRVTT_jsfusion_test/t2v_metrics/R1: 19.2
 MSRVTT_jsfusion_test/t2v_metrics/R5: 46.5
 MSRVTT_jsfusion_test/t2v_metrics/R10: 59.8
 MSRVTT_jsfusion_test/t2v_metrics/R50: 85.4
 MSRVTT_jsfusion_test/t2v_metrics/MedR: 7.0
 MSRVTT_jsfusion_test/t2v_metrics/MeanR: 33.0865
 MSRVTT_jsfusion_test/t2v_metrics/geometric_mean_R1-R5-R10: 37.6546361279836
 MSRVTT_jsfusion_test/v2t_metrics/R1: 19.0
 MSRVTT_jsfusion_test/v2t_metrics/R5: 46.1
 MSRVTT_jsfusion_test/v2t_metrics/R10: 62.8
 MSRVTT_jsfusion_test/v2t_metrics/R50: 85.1
 MSRVTT_jsfusion_test/v2t_metrics/MedR: 6.75
 MSRVTT_jsfusion_test/v2t_metrics/MeanR: 32.5195
 MSRVTT_jsfusion_test/v2t_metrics/geometric_mean_R1-R5-R10: 38.03102729066366
 mnt_best       : 37.6546361279836
 not_improved_count: 0
Train Epoch: 38 [1/250 128/32000 (0%)] Loss: 1.96674 (semantic_loss: 0.01641, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=34.95591 
Train Epoch: 38 [12/250 1536/32000 (5%)] Loss: 1.96491 (semantic_loss: 0.01556, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.33965 
Train Epoch: 38 [23/250 2944/32000 (9%)] Loss: 1.96503 (semantic_loss: 0.01470, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.33818 
Train Epoch: 38 [34/250 4352/32000 (14%)] Loss: 1.96486 (semantic_loss: 0.01552, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.32794 
Train Epoch: 38 [45/250 5760/32000 (18%)] Loss: 1.96595 (semantic_loss: 0.01562, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.34331 
Train Epoch: 38 [56/250 7168/32000 (22%)] Loss: 1.96718 (semantic_loss: 0.01686, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.32957 
Train Epoch: 38 [67/250 8576/32000 (27%)] Loss: 1.96489 (semantic_loss: 0.01456, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=1.12197 
Train Epoch: 38 [78/250 9984/32000 (31%)] Loss: 1.96379 (semantic_loss: 0.01444, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.32825 
Train Epoch: 38 [89/250 11392/32000 (36%)] Loss: 1.96648 (semantic_loss: 0.01615, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.33520 
Train Epoch: 38 [100/250 12800/32000 (40%)] Loss: 1.96626 (semantic_loss: 0.01691, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.34587 
Train Epoch: 38 [111/250 14208/32000 (44%)] Loss: 1.96291 (semantic_loss: 0.01356, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=1.02690 
Train Epoch: 38 [122/250 15616/32000 (49%)] Loss: 1.96500 (semantic_loss: 0.01565, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.35370 
Train Epoch: 38 [133/250 17024/32000 (53%)] Loss: 1.96551 (semantic_loss: 0.01518, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.33351 
Train Epoch: 38 [144/250 18432/32000 (58%)] Loss: 1.96584 (semantic_loss: 0.01649, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.33080 
Train Epoch: 38 [155/250 19840/32000 (62%)] Loss: 1.96542 (semantic_loss: 0.01510, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.36465 
Train Epoch: 38 [166/250 21248/32000 (66%)] Loss: 1.96552 (semantic_loss: 0.01519, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.33306 
Train Epoch: 38 [177/250 22656/32000 (71%)] Loss: 1.96440 (semantic_loss: 0.01505, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.36512 
Train Epoch: 38 [188/250 24064/32000 (75%)] Loss: 1.96646 (semantic_loss: 0.01614, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.34196 
Train Epoch: 38 [199/250 25472/32000 (80%)] Loss: 1.96376 (semantic_loss: 0.01441, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.33419 
Train Epoch: 38 [210/250 26880/32000 (84%)] Loss: 1.96571 (semantic_loss: 0.01539, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.34273 
Train Epoch: 38 [221/250 28288/32000 (88%)] Loss: 1.96465 (semantic_loss: 0.01530, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.33097 
Train Epoch: 38 [232/250 29696/32000 (93%)] Loss: 1.96668 (semantic_loss: 0.01635, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.33557 
Train Epoch: 38 [243/250 31104/32000 (97%)] Loss: 1.96399 (semantic_loss: 0.01464, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.32790 
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/DCMH_MSRVTT_1kA/checkpoint-epoch38.pth ...
Done in 3.814s
removing stale ckpt [epoch 37] [took 0.00s]
 epoch          : 38
 loss           : 1.965257071018219
 learning_rate  : 7.494512702440772e-06
 n_samples      : 1216000
 n_steps        : 9500
 MSRVTT_jsfusion_test/t2v_metrics/R1: 19.2
 MSRVTT_jsfusion_test/t2v_metrics/R5: 46.4
 MSRVTT_jsfusion_test/t2v_metrics/R10: 59.5
 MSRVTT_jsfusion_test/t2v_metrics/R50: 85.0
 MSRVTT_jsfusion_test/t2v_metrics/MedR: 7.0
 MSRVTT_jsfusion_test/t2v_metrics/MeanR: 32.4595
 MSRVTT_jsfusion_test/t2v_metrics/geometric_mean_R1-R5-R10: 37.56459622041974
 MSRVTT_jsfusion_test/v2t_metrics/R1: 19.2
 MSRVTT_jsfusion_test/v2t_metrics/R5: 46.7
 MSRVTT_jsfusion_test/v2t_metrics/R10: 60.5
 MSRVTT_jsfusion_test/v2t_metrics/R50: 85.0
 MSRVTT_jsfusion_test/v2t_metrics/MedR: 6.5
 MSRVTT_jsfusion_test/v2t_metrics/MeanR: 31.7055
 MSRVTT_jsfusion_test/v2t_metrics/geometric_mean_R1-R5-R10: 37.85510844311607
 mnt_best       : 37.6546361279836
 not_improved_count: 1
Train Epoch: 39 [1/250 128/32000 (0%)] Loss: 1.96494 (semantic_loss: 0.01462, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=37.00422 
Train Epoch: 39 [12/250 1536/32000 (5%)] Loss: 1.96533 (semantic_loss: 0.01500, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.32331 
Train Epoch: 39 [23/250 2944/32000 (9%)] Loss: 1.96643 (semantic_loss: 0.01610, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.33112 
Train Epoch: 39 [34/250 4352/32000 (14%)] Loss: 1.96678 (semantic_loss: 0.01646, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.36063 
Train Epoch: 39 [45/250 5760/32000 (18%)] Loss: 1.96533 (semantic_loss: 0.01501, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.35771 
Train Epoch: 39 [56/250 7168/32000 (22%)] Loss: 1.96550 (semantic_loss: 0.01518, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.35200 
Train Epoch: 39 [67/250 8576/32000 (27%)] Loss: 1.96607 (semantic_loss: 0.01574, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.34183 
Train Epoch: 39 [78/250 9984/32000 (31%)] Loss: 1.96471 (semantic_loss: 0.01439, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.32723 
Train Epoch: 39 [89/250 11392/32000 (36%)] Loss: 1.96577 (semantic_loss: 0.01545, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.34114 
Train Epoch: 39 [100/250 12800/32000 (40%)] Loss: 1.96688 (semantic_loss: 0.01655, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.32205 
Train Epoch: 39 [111/250 14208/32000 (44%)] Loss: 1.96569 (semantic_loss: 0.01536, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.32706 
Train Epoch: 39 [122/250 15616/32000 (49%)] Loss: 1.96416 (semantic_loss: 0.01481, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.34774 
Train Epoch: 39 [133/250 17024/32000 (53%)] Loss: 1.96561 (semantic_loss: 0.01528, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.32786 
Train Epoch: 39 [144/250 18432/32000 (58%)] Loss: 1.96424 (semantic_loss: 0.01489, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=3.15110 
Train Epoch: 39 [155/250 19840/32000 (62%)] Loss: 1.96273 (semantic_loss: 0.01338, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.32402 
Train Epoch: 39 [166/250 21248/32000 (66%)] Loss: 1.96355 (semantic_loss: 0.01420, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.32541 
Train Epoch: 39 [177/250 22656/32000 (71%)] Loss: 1.96873 (semantic_loss: 0.01743, quant_loss: 1.95117, bit_balance_loss: 0.00013) batch_time=0.35238 
Train Epoch: 39 [188/250 24064/32000 (75%)] Loss: 1.96504 (semantic_loss: 0.01471, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.32943 
Train Epoch: 39 [199/250 25472/32000 (80%)] Loss: 1.96588 (semantic_loss: 0.01556, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.33739 
Train Epoch: 39 [210/250 26880/32000 (84%)] Loss: 1.96535 (semantic_loss: 0.01502, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=1.58193 
Train Epoch: 39 [221/250 28288/32000 (88%)] Loss: 1.96631 (semantic_loss: 0.01598, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.36694 
Train Epoch: 39 [232/250 29696/32000 (93%)] Loss: 1.96625 (semantic_loss: 0.01592, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.32773 
Train Epoch: 39 [243/250 31104/32000 (97%)] Loss: 1.96422 (semantic_loss: 0.01390, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.35438 
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/DCMH_MSRVTT_1kA/checkpoint-epoch39.pth ...
Done in 3.894s
removing stale ckpt [epoch 38] [took 0.00s]
 epoch          : 39
 loss           : 1.9652062239646912
 learning_rate  : 7.119787067318733e-06
 n_samples      : 1248000
 n_steps        : 9750
 MSRVTT_jsfusion_test/t2v_metrics/R1: 18.7
 MSRVTT_jsfusion_test/t2v_metrics/R5: 46.1
 MSRVTT_jsfusion_test/t2v_metrics/R10: 60.6
 MSRVTT_jsfusion_test/t2v_metrics/R50: 84.9
 MSRVTT_jsfusion_test/t2v_metrics/MedR: 6.25
 MSRVTT_jsfusion_test/t2v_metrics/MeanR: 33.014
 MSRVTT_jsfusion_test/t2v_metrics/geometric_mean_R1-R5-R10: 37.382790656432796
 MSRVTT_jsfusion_test/v2t_metrics/R1: 17.8
 MSRVTT_jsfusion_test/v2t_metrics/R5: 48.1
 MSRVTT_jsfusion_test/v2t_metrics/R10: 61.1
 MSRVTT_jsfusion_test/v2t_metrics/R50: 85.0
 MSRVTT_jsfusion_test/v2t_metrics/MedR: 6.0
 MSRVTT_jsfusion_test/v2t_metrics/MeanR: 31.658
 MSRVTT_jsfusion_test/v2t_metrics/geometric_mean_R1-R5-R10: 37.39975549612813
 mnt_best       : 37.6546361279836
 not_improved_count: 2
Train Epoch: 40 [1/250 128/32000 (0%)] Loss: 1.96361 (semantic_loss: 0.01328, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=28.72934 
Train Epoch: 40 [12/250 1536/32000 (5%)] Loss: 1.96447 (semantic_loss: 0.01414, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.33394 
Train Epoch: 40 [23/250 2944/32000 (9%)] Loss: 1.96481 (semantic_loss: 0.01546, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.34082 
Train Epoch: 40 [34/250 4352/32000 (14%)] Loss: 1.96572 (semantic_loss: 0.01442, quant_loss: 1.95117, bit_balance_loss: 0.00013) batch_time=0.34572 
Train Epoch: 40 [45/250 5760/32000 (18%)] Loss: 1.96382 (semantic_loss: 0.01350, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.34740 
Train Epoch: 40 [56/250 7168/32000 (22%)] Loss: 1.96663 (semantic_loss: 0.01729, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.33766 
Train Epoch: 40 [67/250 8576/32000 (27%)] Loss: 1.96757 (semantic_loss: 0.01724, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.33560 
Train Epoch: 40 [78/250 9984/32000 (31%)] Loss: 1.96742 (semantic_loss: 0.01709, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.32693 
Train Epoch: 40 [89/250 11392/32000 (36%)] Loss: 1.96550 (semantic_loss: 0.01518, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.32725 
Train Epoch: 40 [100/250 12800/32000 (40%)] Loss: 1.96481 (semantic_loss: 0.01546, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.35096 
Train Epoch: 40 [111/250 14208/32000 (44%)] Loss: 1.96492 (semantic_loss: 0.01557, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.34037 
Train Epoch: 40 [122/250 15616/32000 (49%)] Loss: 1.96609 (semantic_loss: 0.01577, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.34237 
Train Epoch: 40 [133/250 17024/32000 (53%)] Loss: 1.96416 (semantic_loss: 0.01384, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.32339 
Train Epoch: 40 [144/250 18432/32000 (58%)] Loss: 1.96385 (semantic_loss: 0.01450, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.32686 
Train Epoch: 40 [155/250 19840/32000 (62%)] Loss: 1.96398 (semantic_loss: 0.01365, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.32403 
Train Epoch: 40 [166/250 21248/32000 (66%)] Loss: 1.96551 (semantic_loss: 0.01519, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.34224 
Train Epoch: 40 [177/250 22656/32000 (71%)] Loss: 1.96511 (semantic_loss: 0.01479, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.33498 
Train Epoch: 40 [188/250 24064/32000 (75%)] Loss: 1.96674 (semantic_loss: 0.01642, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.33941 
Train Epoch: 40 [199/250 25472/32000 (80%)] Loss: 1.96411 (semantic_loss: 0.01476, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.32226 
Train Epoch: 40 [210/250 26880/32000 (84%)] Loss: 1.96429 (semantic_loss: 0.01397, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=1.42106 
Train Epoch: 40 [221/250 28288/32000 (88%)] Loss: 1.96633 (semantic_loss: 0.01600, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.34212 
Train Epoch: 40 [232/250 29696/32000 (93%)] Loss: 1.96407 (semantic_loss: 0.01375, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.32544 
Train Epoch: 40 [243/250 31104/32000 (97%)] Loss: 1.96391 (semantic_loss: 0.01358, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.35261 
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/DCMH_MSRVTT_1kA/checkpoint-epoch40.pth ...
Done in 4.028s
removing stale ckpt [epoch 39] [took 0.00s]
 epoch          : 40
 loss           : 1.9650887880325318
 learning_rate  : 6.763797713952796e-06
 n_samples      : 1280000
 n_steps        : 10000
 MSRVTT_jsfusion_test/t2v_metrics/R1: 17.6
 MSRVTT_jsfusion_test/t2v_metrics/R5: 47.0
 MSRVTT_jsfusion_test/t2v_metrics/R10: 60.9
 MSRVTT_jsfusion_test/t2v_metrics/R50: 84.8
 MSRVTT_jsfusion_test/t2v_metrics/MedR: 6.0
 MSRVTT_jsfusion_test/t2v_metrics/MeanR: 32.299499999999995
 MSRVTT_jsfusion_test/t2v_metrics/geometric_mean_R1-R5-R10: 36.932548157907945
 MSRVTT_jsfusion_test/v2t_metrics/R1: 18.9
 MSRVTT_jsfusion_test/v2t_metrics/R5: 47.3
 MSRVTT_jsfusion_test/v2t_metrics/R10: 63.4
 MSRVTT_jsfusion_test/v2t_metrics/R50: 85.5
 MSRVTT_jsfusion_test/v2t_metrics/MedR: 6.0
 MSRVTT_jsfusion_test/v2t_metrics/MeanR: 31.4215
 MSRVTT_jsfusion_test/v2t_metrics/geometric_mean_R1-R5-R10: 38.41233734436541
 mnt_best       : 37.6546361279836
 not_improved_count: 3
Train Epoch: 41 [1/250 128/32000 (0%)] Loss: 1.96501 (semantic_loss: 0.01468, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=27.38370 
Train Epoch: 41 [12/250 1536/32000 (5%)] Loss: 1.96544 (semantic_loss: 0.01609, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.33603 
Train Epoch: 41 [23/250 2944/32000 (9%)] Loss: 1.96448 (semantic_loss: 0.01415, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.34609 
Train Epoch: 41 [34/250 4352/32000 (14%)] Loss: 1.96593 (semantic_loss: 0.01560, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.34005 
Train Epoch: 41 [45/250 5760/32000 (18%)] Loss: 1.96483 (semantic_loss: 0.01450, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.34025 
Train Epoch: 41 [56/250 7168/32000 (22%)] Loss: 1.96408 (semantic_loss: 0.01473, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.33671 
Train Epoch: 41 [67/250 8576/32000 (27%)] Loss: 1.96779 (semantic_loss: 0.01746, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.32325 
Train Epoch: 41 [78/250 9984/32000 (31%)] Loss: 1.96536 (semantic_loss: 0.01601, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.32452 
Train Epoch: 41 [89/250 11392/32000 (36%)] Loss: 1.96436 (semantic_loss: 0.01404, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.32566 
Train Epoch: 41 [100/250 12800/32000 (40%)] Loss: 1.96540 (semantic_loss: 0.01605, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.35117 
Train Epoch: 41 [111/250 14208/32000 (44%)] Loss: 1.96583 (semantic_loss: 0.01648, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.33090 
Train Epoch: 41 [122/250 15616/32000 (49%)] Loss: 1.96552 (semantic_loss: 0.01519, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.34403 
Train Epoch: 41 [133/250 17024/32000 (53%)] Loss: 1.96508 (semantic_loss: 0.01476, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.63793 
Train Epoch: 41 [144/250 18432/32000 (58%)] Loss: 1.96608 (semantic_loss: 0.01575, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.32710 
Train Epoch: 41 [155/250 19840/32000 (62%)] Loss: 1.96599 (semantic_loss: 0.01567, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.34135 
Train Epoch: 41 [166/250 21248/32000 (66%)] Loss: 1.96669 (semantic_loss: 0.01637, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.35183 
Train Epoch: 41 [177/250 22656/32000 (71%)] Loss: 1.96453 (semantic_loss: 0.01420, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.33093 
Train Epoch: 41 [188/250 24064/32000 (75%)] Loss: 1.96463 (semantic_loss: 0.01431, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.34507 
Train Epoch: 41 [199/250 25472/32000 (80%)] Loss: 1.96508 (semantic_loss: 0.01476, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.35565 
Train Epoch: 41 [210/250 26880/32000 (84%)] Loss: 1.96655 (semantic_loss: 0.01525, quant_loss: 1.95117, bit_balance_loss: 0.00013) batch_time=0.32894 
Train Epoch: 41 [221/250 28288/32000 (88%)] Loss: 1.96587 (semantic_loss: 0.01554, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.37649 
Train Epoch: 41 [232/250 29696/32000 (93%)] Loss: 1.96503 (semantic_loss: 0.01568, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.32678 
Train Epoch: 41 [243/250 31104/32000 (97%)] Loss: 1.96500 (semantic_loss: 0.01566, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.33712 
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/DCMH_MSRVTT_1kA/checkpoint-epoch41.pth ...
Done in 3.904s
removing stale ckpt [epoch 40] [took 0.00s]
 epoch          : 41
 loss           : 1.9650768885612488
 learning_rate  : 6.425607828255156e-06
 n_samples      : 1312000
 n_steps        : 10250
 MSRVTT_jsfusion_test/t2v_metrics/R1: 18.1
 MSRVTT_jsfusion_test/t2v_metrics/R5: 46.0
 MSRVTT_jsfusion_test/t2v_metrics/R10: 61.0
 MSRVTT_jsfusion_test/t2v_metrics/R50: 85.2
 MSRVTT_jsfusion_test/t2v_metrics/MedR: 7.0
 MSRVTT_jsfusion_test/t2v_metrics/MeanR: 32.428
 MSRVTT_jsfusion_test/t2v_metrics/geometric_mean_R1-R5-R10: 37.03298738191544
 MSRVTT_jsfusion_test/v2t_metrics/R1: 19.9
 MSRVTT_jsfusion_test/v2t_metrics/R5: 47.6
 MSRVTT_jsfusion_test/v2t_metrics/R10: 62.5
 MSRVTT_jsfusion_test/v2t_metrics/R50: 84.5
 MSRVTT_jsfusion_test/v2t_metrics/MedR: 6.0
 MSRVTT_jsfusion_test/v2t_metrics/MeanR: 31.8005
 MSRVTT_jsfusion_test/v2t_metrics/geometric_mean_R1-R5-R10: 38.97445181890365
 mnt_best       : 37.6546361279836
 not_improved_count: 4
Train Epoch: 42 [1/250 128/32000 (0%)] Loss: 1.96503 (semantic_loss: 0.01471, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=25.20640 
Train Epoch: 42 [12/250 1536/32000 (5%)] Loss: 1.96760 (semantic_loss: 0.01727, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.36168 
Train Epoch: 42 [23/250 2944/32000 (9%)] Loss: 1.96278 (semantic_loss: 0.01343, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.34074 
Train Epoch: 42 [34/250 4352/32000 (14%)] Loss: 1.96325 (semantic_loss: 0.01390, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.34489 
Train Epoch: 42 [45/250 5760/32000 (18%)] Loss: 1.96558 (semantic_loss: 0.01526, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.39135 
Train Epoch: 42 [56/250 7168/32000 (22%)] Loss: 1.96652 (semantic_loss: 0.01620, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.34105 
Train Epoch: 42 [67/250 8576/32000 (27%)] Loss: 1.96538 (semantic_loss: 0.01506, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.35624 
Train Epoch: 42 [78/250 9984/32000 (31%)] Loss: 1.96702 (semantic_loss: 0.01670, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.35788 
Train Epoch: 42 [89/250 11392/32000 (36%)] Loss: 1.96575 (semantic_loss: 0.01543, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.34109 
Train Epoch: 42 [100/250 12800/32000 (40%)] Loss: 1.96624 (semantic_loss: 0.01592, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.34486 
Train Epoch: 42 [111/250 14208/32000 (44%)] Loss: 1.96445 (semantic_loss: 0.01511, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.34576 
Train Epoch: 42 [122/250 15616/32000 (49%)] Loss: 1.96643 (semantic_loss: 0.01611, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.34164 
Train Epoch: 42 [133/250 17024/32000 (53%)] Loss: 1.96469 (semantic_loss: 0.01534, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.32692 
Train Epoch: 42 [144/250 18432/32000 (58%)] Loss: 1.96461 (semantic_loss: 0.01428, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=1.90078 
Train Epoch: 42 [155/250 19840/32000 (62%)] Loss: 1.96420 (semantic_loss: 0.01387, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.32899 
Train Epoch: 42 [166/250 21248/32000 (66%)] Loss: 1.96446 (semantic_loss: 0.01414, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.35224 
Train Epoch: 42 [177/250 22656/32000 (71%)] Loss: 1.96320 (semantic_loss: 0.01385, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.34866 
Train Epoch: 42 [188/250 24064/32000 (75%)] Loss: 1.96482 (semantic_loss: 0.01547, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.34089 
Train Epoch: 42 [199/250 25472/32000 (80%)] Loss: 1.96438 (semantic_loss: 0.01406, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.32653 
Train Epoch: 42 [210/250 26880/32000 (84%)] Loss: 1.96260 (semantic_loss: 0.01325, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=1.37827 
Train Epoch: 42 [221/250 28288/32000 (88%)] Loss: 1.96545 (semantic_loss: 0.01513, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.33900 
Train Epoch: 42 [232/250 29696/32000 (93%)] Loss: 1.96424 (semantic_loss: 0.01489, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.46292 
Train Epoch: 42 [243/250 31104/32000 (97%)] Loss: 1.96557 (semantic_loss: 0.01622, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.35275 
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/DCMH_MSRVTT_1kA/checkpoint-epoch42.pth ...
Done in 3.723s
Updating 'best' checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/DCMH_MSRVTT_1kA/checkpoint-epoch42.pth ...
Done in 7.659s
removing stale ckpt [epoch 41] [took 0.00s]
 epoch          : 42
 loss           : 1.9649286160469055
 learning_rate  : 6.104327436842398e-06
 n_samples      : 1344000
 n_steps        : 10500
 MSRVTT_jsfusion_test/t2v_metrics/R1: 19.4
 MSRVTT_jsfusion_test/t2v_metrics/R5: 47.2
 MSRVTT_jsfusion_test/t2v_metrics/R10: 61.1
 MSRVTT_jsfusion_test/t2v_metrics/R50: 85.2
 MSRVTT_jsfusion_test/t2v_metrics/MedR: 6.0
 MSRVTT_jsfusion_test/t2v_metrics/MeanR: 32.111999999999995
 MSRVTT_jsfusion_test/t2v_metrics/geometric_mean_R1-R5-R10: 38.24678897105204
 MSRVTT_jsfusion_test/v2t_metrics/R1: 19.6
 MSRVTT_jsfusion_test/v2t_metrics/R5: 47.5
 MSRVTT_jsfusion_test/v2t_metrics/R10: 62.3
 MSRVTT_jsfusion_test/v2t_metrics/R50: 84.9
 MSRVTT_jsfusion_test/v2t_metrics/MedR: 6.0
 MSRVTT_jsfusion_test/v2t_metrics/MeanR: 31.1965
 MSRVTT_jsfusion_test/v2t_metrics/geometric_mean_R1-R5-R10: 38.70905560754447
 mnt_best       : 38.24678897105204
 not_improved_count: 0
Train Epoch: 43 [1/250 128/32000 (0%)] Loss: 1.96411 (semantic_loss: 0.01476, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=41.44558 
Train Epoch: 43 [12/250 1536/32000 (5%)] Loss: 1.96464 (semantic_loss: 0.01432, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.33986 
Train Epoch: 43 [23/250 2944/32000 (9%)] Loss: 1.96568 (semantic_loss: 0.01536, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.38263 
Train Epoch: 43 [34/250 4352/32000 (14%)] Loss: 1.96378 (semantic_loss: 0.01345, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.34788 
Train Epoch: 43 [45/250 5760/32000 (18%)] Loss: 1.96552 (semantic_loss: 0.01519, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.32601 
Train Epoch: 43 [56/250 7168/32000 (22%)] Loss: 1.96569 (semantic_loss: 0.01537, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.33786 
Train Epoch: 43 [67/250 8576/32000 (27%)] Loss: 1.96380 (semantic_loss: 0.01446, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.34287 
Train Epoch: 43 [78/250 9984/32000 (31%)] Loss: 1.96476 (semantic_loss: 0.01444, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.32647 
Train Epoch: 43 [89/250 11392/32000 (36%)] Loss: 1.96736 (semantic_loss: 0.01703, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.34707 
Train Epoch: 43 [100/250 12800/32000 (40%)] Loss: 1.96471 (semantic_loss: 0.01537, quant_loss: 1.94922, bit_balance_loss: 0.00012) batch_time=0.33113 
Train Epoch: 43 [111/250 14208/32000 (44%)] Loss: 1.96416 (semantic_loss: 0.01482, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.34883 
Train Epoch: 43 [122/250 15616/32000 (49%)] Loss: 1.96330 (semantic_loss: 0.01395, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.33538 
Train Epoch: 43 [133/250 17024/32000 (53%)] Loss: 1.96439 (semantic_loss: 0.01407, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.77530 
Train Epoch: 43 [144/250 18432/32000 (58%)] Loss: 1.96436 (semantic_loss: 0.01501, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.33812 
Train Epoch: 43 [155/250 19840/32000 (62%)] Loss: 1.96476 (semantic_loss: 0.01541, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.34766 
Train Epoch: 43 [166/250 21248/32000 (66%)] Loss: 1.96399 (semantic_loss: 0.01367, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.34326 
Train Epoch: 43 [177/250 22656/32000 (71%)] Loss: 1.96586 (semantic_loss: 0.01554, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.33031 
Train Epoch: 43 [188/250 24064/32000 (75%)] Loss: 1.96559 (semantic_loss: 0.01526, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.35235 
Train Epoch: 43 [199/250 25472/32000 (80%)] Loss: 1.96539 (semantic_loss: 0.01604, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.33659 
Train Epoch: 43 [210/250 26880/32000 (84%)] Loss: 1.96449 (semantic_loss: 0.01417, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.33343 
Train Epoch: 43 [221/250 28288/32000 (88%)] Loss: 1.96541 (semantic_loss: 0.01509, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.34588 
Train Epoch: 43 [232/250 29696/32000 (93%)] Loss: 1.96475 (semantic_loss: 0.01443, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.32458 
Train Epoch: 43 [243/250 31104/32000 (97%)] Loss: 1.96333 (semantic_loss: 0.01399, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.35198 
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/DCMH_MSRVTT_1kA/checkpoint-epoch43.pth ...
Done in 4.533s
removing stale ckpt [epoch 42] [took 0.09s]
 epoch          : 43
 loss           : 1.9648711557388305
 learning_rate  : 5.799111065000278e-06
 n_samples      : 1376000
 n_steps        : 10750
 MSRVTT_jsfusion_test/t2v_metrics/R1: 18.8
 MSRVTT_jsfusion_test/t2v_metrics/R5: 47.8
 MSRVTT_jsfusion_test/t2v_metrics/R10: 60.2
 MSRVTT_jsfusion_test/t2v_metrics/R50: 85.2
 MSRVTT_jsfusion_test/t2v_metrics/MedR: 6.0
 MSRVTT_jsfusion_test/t2v_metrics/MeanR: 32.058
 MSRVTT_jsfusion_test/t2v_metrics/geometric_mean_R1-R5-R10: 37.820512741282236
 MSRVTT_jsfusion_test/v2t_metrics/R1: 20.7
 MSRVTT_jsfusion_test/v2t_metrics/R5: 48.2
 MSRVTT_jsfusion_test/v2t_metrics/R10: 62.3
 MSRVTT_jsfusion_test/v2t_metrics/R50: 85.0
 MSRVTT_jsfusion_test/v2t_metrics/MedR: 6.0
 MSRVTT_jsfusion_test/v2t_metrics/MeanR: 31.173
 MSRVTT_jsfusion_test/v2t_metrics/geometric_mean_R1-R5-R10: 39.61276371542099
 mnt_best       : 38.24678897105204
 not_improved_count: 1
Train Epoch: 44 [1/250 128/32000 (0%)] Loss: 1.96569 (semantic_loss: 0.01537, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=29.38897 
Train Epoch: 44 [12/250 1536/32000 (5%)] Loss: 1.96467 (semantic_loss: 0.01435, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.32324 
Train Epoch: 44 [23/250 2944/32000 (9%)] Loss: 1.96452 (semantic_loss: 0.01419, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.34356 
Train Epoch: 44 [34/250 4352/32000 (14%)] Loss: 1.96528 (semantic_loss: 0.01495, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.32818 
Train Epoch: 44 [45/250 5760/32000 (18%)] Loss: 1.96522 (semantic_loss: 0.01490, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.32446 
Train Epoch: 44 [56/250 7168/32000 (22%)] Loss: 1.96481 (semantic_loss: 0.01448, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.39614 
Train Epoch: 44 [67/250 8576/32000 (27%)] Loss: 1.96477 (semantic_loss: 0.01445, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.33964 
Train Epoch: 44 [78/250 9984/32000 (31%)] Loss: 1.96387 (semantic_loss: 0.01452, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.34274 
Train Epoch: 44 [89/250 11392/32000 (36%)] Loss: 1.96635 (semantic_loss: 0.01602, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.37125 
Train Epoch: 44 [100/250 12800/32000 (40%)] Loss: 1.96422 (semantic_loss: 0.01487, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.32803 
Train Epoch: 44 [111/250 14208/32000 (44%)] Loss: 1.96592 (semantic_loss: 0.01560, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.33719 
Train Epoch: 44 [122/250 15616/32000 (49%)] Loss: 1.96592 (semantic_loss: 0.01658, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.43087 
Train Epoch: 44 [133/250 17024/32000 (53%)] Loss: 1.96357 (semantic_loss: 0.01422, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=3.11756 
Train Epoch: 44 [144/250 18432/32000 (58%)] Loss: 1.96438 (semantic_loss: 0.01503, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.33404 
Train Epoch: 44 [155/250 19840/32000 (62%)] Loss: 1.96446 (semantic_loss: 0.01512, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.34047 
Train Epoch: 44 [166/250 21248/32000 (66%)] Loss: 1.96413 (semantic_loss: 0.01479, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.34128 
Train Epoch: 44 [177/250 22656/32000 (71%)] Loss: 1.96546 (semantic_loss: 0.01514, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.32412 
Train Epoch: 44 [188/250 24064/32000 (75%)] Loss: 1.96583 (semantic_loss: 0.01550, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.33288 
Train Epoch: 44 [199/250 25472/32000 (80%)] Loss: 1.96408 (semantic_loss: 0.01474, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.34060 
Train Epoch: 44 [210/250 26880/32000 (84%)] Loss: 1.96574 (semantic_loss: 0.01542, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.35633 
Train Epoch: 44 [221/250 28288/32000 (88%)] Loss: 1.96477 (semantic_loss: 0.01347, quant_loss: 1.95117, bit_balance_loss: 0.00013) batch_time=0.33509 
Train Epoch: 44 [232/250 29696/32000 (93%)] Loss: 1.96355 (semantic_loss: 0.01322, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.32189 
Train Epoch: 44 [243/250 31104/32000 (97%)] Loss: 1.96446 (semantic_loss: 0.01414, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.33680 
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/DCMH_MSRVTT_1kA/checkpoint-epoch44.pth ...
Done in 3.996s
removing stale ckpt [epoch 43] [took 0.03s]
 epoch          : 44
 loss           : 1.9648289804458619
 learning_rate  : 5.5091555117502635e-06
 n_samples      : 1408000
 n_steps        : 11000
 MSRVTT_jsfusion_test/t2v_metrics/R1: 19.0
 MSRVTT_jsfusion_test/t2v_metrics/R5: 47.2
 MSRVTT_jsfusion_test/t2v_metrics/R10: 61.0
 MSRVTT_jsfusion_test/t2v_metrics/R50: 85.4
 MSRVTT_jsfusion_test/t2v_metrics/MedR: 6.0
 MSRVTT_jsfusion_test/t2v_metrics/MeanR: 32.693
 MSRVTT_jsfusion_test/t2v_metrics/geometric_mean_R1-R5-R10: 37.96136423992833
 MSRVTT_jsfusion_test/v2t_metrics/R1: 18.7
 MSRVTT_jsfusion_test/v2t_metrics/R5: 47.1
 MSRVTT_jsfusion_test/v2t_metrics/R10: 61.5
 MSRVTT_jsfusion_test/v2t_metrics/R50: 85.9
 MSRVTT_jsfusion_test/v2t_metrics/MedR: 6.0
 MSRVTT_jsfusion_test/v2t_metrics/MeanR: 31.4735
 MSRVTT_jsfusion_test/v2t_metrics/geometric_mean_R1-R5-R10: 37.83663828158438
 mnt_best       : 38.24678897105204
 not_improved_count: 2
Train Epoch: 45 [1/250 128/32000 (0%)] Loss: 1.96488 (semantic_loss: 0.01456, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=34.03286 
Train Epoch: 45 [12/250 1536/32000 (5%)] Loss: 1.96571 (semantic_loss: 0.01539, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.32396 
Train Epoch: 45 [23/250 2944/32000 (9%)] Loss: 1.96413 (semantic_loss: 0.01381, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=2.14509 
Train Epoch: 45 [34/250 4352/32000 (14%)] Loss: 1.96366 (semantic_loss: 0.01333, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.34664 
Train Epoch: 45 [45/250 5760/32000 (18%)] Loss: 1.96668 (semantic_loss: 0.01636, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=1.37089 
Train Epoch: 45 [56/250 7168/32000 (22%)] Loss: 1.96542 (semantic_loss: 0.01608, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.38145 
Train Epoch: 45 [67/250 8576/32000 (27%)] Loss: 1.96286 (semantic_loss: 0.01351, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.33966 
Train Epoch: 45 [78/250 9984/32000 (31%)] Loss: 1.96468 (semantic_loss: 0.01533, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.32375 
Train Epoch: 45 [89/250 11392/32000 (36%)] Loss: 1.96776 (semantic_loss: 0.01744, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.37712 
Train Epoch: 45 [100/250 12800/32000 (40%)] Loss: 1.96356 (semantic_loss: 0.01422, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.35861 
Train Epoch: 45 [111/250 14208/32000 (44%)] Loss: 1.96392 (semantic_loss: 0.01457, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.44992 
Train Epoch: 45 [122/250 15616/32000 (49%)] Loss: 1.96367 (semantic_loss: 0.01335, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.34699 
Train Epoch: 45 [133/250 17024/32000 (53%)] Loss: 1.96481 (semantic_loss: 0.01449, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.33328 
Train Epoch: 45 [144/250 18432/32000 (58%)] Loss: 1.96500 (semantic_loss: 0.01468, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.32575 
Train Epoch: 45 [155/250 19840/32000 (62%)] Loss: 1.96426 (semantic_loss: 0.01492, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.38332 
Train Epoch: 45 [166/250 21248/32000 (66%)] Loss: 1.96509 (semantic_loss: 0.01476, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.34195 
Train Epoch: 45 [177/250 22656/32000 (71%)] Loss: 1.96430 (semantic_loss: 0.01495, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.35954 
Train Epoch: 45 [188/250 24064/32000 (75%)] Loss: 1.96508 (semantic_loss: 0.01476, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.34903 
Train Epoch: 45 [199/250 25472/32000 (80%)] Loss: 1.96481 (semantic_loss: 0.01546, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.33016 
Train Epoch: 45 [210/250 26880/32000 (84%)] Loss: 1.96508 (semantic_loss: 0.01476, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=1.46708 
Train Epoch: 45 [221/250 28288/32000 (88%)] Loss: 1.96304 (semantic_loss: 0.01272, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.33870 
Train Epoch: 45 [232/250 29696/32000 (93%)] Loss: 1.96776 (semantic_loss: 0.01744, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.34998 
Train Epoch: 45 [243/250 31104/32000 (97%)] Loss: 1.96460 (semantic_loss: 0.01428, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.33927 
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/DCMH_MSRVTT_1kA/checkpoint-epoch45.pth ...
Done in 3.971s
Updating 'best' checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/DCMH_MSRVTT_1kA/checkpoint-epoch45.pth ...
Done in 7.856s
removing stale ckpt [epoch 44] [took 0.00s]
 epoch          : 45
 loss           : 1.9647727041244507
 learning_rate  : 5.23369773616275e-06
 n_samples      : 1440000
 n_steps        : 11250
 MSRVTT_jsfusion_test/t2v_metrics/R1: 19.9
 MSRVTT_jsfusion_test/t2v_metrics/R5: 47.1
 MSRVTT_jsfusion_test/t2v_metrics/R10: 60.3
 MSRVTT_jsfusion_test/t2v_metrics/R50: 85.5
 MSRVTT_jsfusion_test/t2v_metrics/MedR: 6.0
 MSRVTT_jsfusion_test/t2v_metrics/MeanR: 32.8765
 MSRVTT_jsfusion_test/t2v_metrics/geometric_mean_R1-R5-R10: 38.37635873907502
 MSRVTT_jsfusion_test/v2t_metrics/R1: 19.2
 MSRVTT_jsfusion_test/v2t_metrics/R5: 47.6
 MSRVTT_jsfusion_test/v2t_metrics/R10: 62.4
 MSRVTT_jsfusion_test/v2t_metrics/R50: 85.1
 MSRVTT_jsfusion_test/v2t_metrics/MedR: 6.0
 MSRVTT_jsfusion_test/v2t_metrics/MeanR: 31.9545
 MSRVTT_jsfusion_test/v2t_metrics/geometric_mean_R1-R5-R10: 38.49144871079781
 mnt_best       : 38.37635873907502
 not_improved_count: 0
Train Epoch: 46 [1/250 128/32000 (0%)] Loss: 1.96642 (semantic_loss: 0.01610, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=30.47838 
Train Epoch: 46 [12/250 1536/32000 (5%)] Loss: 1.96369 (semantic_loss: 0.01337, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=3.71033 
Train Epoch: 46 [23/250 2944/32000 (9%)] Loss: 1.96604 (semantic_loss: 0.01572, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.33120 
Train Epoch: 46 [34/250 4352/32000 (14%)] Loss: 1.96372 (semantic_loss: 0.01437, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.35029 
Train Epoch: 46 [45/250 5760/32000 (18%)] Loss: 1.96551 (semantic_loss: 0.01519, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.33695 
Train Epoch: 46 [56/250 7168/32000 (22%)] Loss: 1.96400 (semantic_loss: 0.01368, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.34780 
Train Epoch: 46 [67/250 8576/32000 (27%)] Loss: 1.96386 (semantic_loss: 0.01451, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.32218 
Train Epoch: 46 [78/250 9984/32000 (31%)] Loss: 1.96608 (semantic_loss: 0.01575, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=1.65047 
Train Epoch: 46 [89/250 11392/32000 (36%)] Loss: 1.96530 (semantic_loss: 0.01498, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.32189 
Train Epoch: 46 [100/250 12800/32000 (40%)] Loss: 1.96516 (semantic_loss: 0.01484, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.34427 
Train Epoch: 46 [111/250 14208/32000 (44%)] Loss: 1.96523 (semantic_loss: 0.01589, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.32579 
Train Epoch: 46 [122/250 15616/32000 (49%)] Loss: 1.96402 (semantic_loss: 0.01369, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.33240 
Train Epoch: 46 [133/250 17024/32000 (53%)] Loss: 1.96472 (semantic_loss: 0.01537, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.46502 
Train Epoch: 46 [144/250 18432/32000 (58%)] Loss: 1.96565 (semantic_loss: 0.01533, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.33767 
Train Epoch: 46 [155/250 19840/32000 (62%)] Loss: 1.96374 (semantic_loss: 0.01440, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.34938 
Train Epoch: 46 [166/250 21248/32000 (66%)] Loss: 1.96499 (semantic_loss: 0.01564, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.32305 
Train Epoch: 46 [177/250 22656/32000 (71%)] Loss: 1.96517 (semantic_loss: 0.01484, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.32660 
Train Epoch: 46 [188/250 24064/32000 (75%)] Loss: 1.96468 (semantic_loss: 0.01436, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.34192 
Train Epoch: 46 [199/250 25472/32000 (80%)] Loss: 1.96555 (semantic_loss: 0.01523, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.34369 
Train Epoch: 46 [210/250 26880/32000 (84%)] Loss: 1.96296 (semantic_loss: 0.01361, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.32676 
Train Epoch: 46 [221/250 28288/32000 (88%)] Loss: 1.96572 (semantic_loss: 0.01540, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.32349 
Train Epoch: 46 [232/250 29696/32000 (93%)] Loss: 1.96498 (semantic_loss: 0.01465, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.35762 
Train Epoch: 46 [243/250 31104/32000 (97%)] Loss: 1.96452 (semantic_loss: 0.01420, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.34318 
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/DCMH_MSRVTT_1kA/checkpoint-epoch46.pth ...
Done in 3.928s
removing stale ckpt [epoch 45] [took 0.00s]
 epoch          : 46
 loss           : 1.9647240495681764
 learning_rate  : 4.972012849354612e-06
 n_samples      : 1472000
 n_steps        : 11500
 MSRVTT_jsfusion_test/t2v_metrics/R1: 18.9
 MSRVTT_jsfusion_test/t2v_metrics/R5: 48.1
 MSRVTT_jsfusion_test/t2v_metrics/R10: 61.1
 MSRVTT_jsfusion_test/t2v_metrics/R50: 85.6
 MSRVTT_jsfusion_test/t2v_metrics/MedR: 6.0
 MSRVTT_jsfusion_test/t2v_metrics/MeanR: 32.5
 MSRVTT_jsfusion_test/t2v_metrics/geometric_mean_R1-R5-R10: 38.1548160059696
 MSRVTT_jsfusion_test/v2t_metrics/R1: 20.2
 MSRVTT_jsfusion_test/v2t_metrics/R5: 48.2
 MSRVTT_jsfusion_test/v2t_metrics/R10: 62.3
 MSRVTT_jsfusion_test/v2t_metrics/R50: 85.3
 MSRVTT_jsfusion_test/v2t_metrics/MedR: 6.0
 MSRVTT_jsfusion_test/v2t_metrics/MeanR: 31.3745
 MSRVTT_jsfusion_test/v2t_metrics/geometric_mean_R1-R5-R10: 39.29121736117664
 mnt_best       : 38.37635873907502
 not_improved_count: 1
Train Epoch: 47 [1/250 128/32000 (0%)] Loss: 1.96579 (semantic_loss: 0.01547, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=26.35733 
Train Epoch: 47 [12/250 1536/32000 (5%)] Loss: 1.96439 (semantic_loss: 0.01406, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.33507 
Train Epoch: 47 [23/250 2944/32000 (9%)] Loss: 1.96427 (semantic_loss: 0.01394, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.33978 
Train Epoch: 47 [34/250 4352/32000 (14%)] Loss: 1.96387 (semantic_loss: 0.01355, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.32990 
Train Epoch: 47 [45/250 5760/32000 (18%)] Loss: 1.96443 (semantic_loss: 0.01508, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.37539 
Train Epoch: 47 [56/250 7168/32000 (22%)] Loss: 1.96433 (semantic_loss: 0.01400, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.34937 
Train Epoch: 47 [67/250 8576/32000 (27%)] Loss: 1.96368 (semantic_loss: 0.01336, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=3.94105 
Train Epoch: 47 [78/250 9984/32000 (31%)] Loss: 1.96408 (semantic_loss: 0.01376, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.33029 
Train Epoch: 47 [89/250 11392/32000 (36%)] Loss: 1.96356 (semantic_loss: 0.01421, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.32934 
Train Epoch: 47 [100/250 12800/32000 (40%)] Loss: 1.96457 (semantic_loss: 0.01523, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.34319 
Train Epoch: 47 [111/250 14208/32000 (44%)] Loss: 1.96358 (semantic_loss: 0.01325, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.32610 
Train Epoch: 47 [122/250 15616/32000 (49%)] Loss: 1.96523 (semantic_loss: 0.01589, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.32963 
Train Epoch: 47 [133/250 17024/32000 (53%)] Loss: 1.96399 (semantic_loss: 0.01367, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=2.48178 
Train Epoch: 47 [144/250 18432/32000 (58%)] Loss: 1.96464 (semantic_loss: 0.01530, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.33601 
Train Epoch: 47 [155/250 19840/32000 (62%)] Loss: 1.96593 (semantic_loss: 0.01560, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.32355 
Train Epoch: 47 [166/250 21248/32000 (66%)] Loss: 1.96453 (semantic_loss: 0.01421, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.32617 
Train Epoch: 47 [177/250 22656/32000 (71%)] Loss: 1.96470 (semantic_loss: 0.01438, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.34288 
Train Epoch: 47 [188/250 24064/32000 (75%)] Loss: 1.96258 (semantic_loss: 0.01323, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.34092 
Train Epoch: 47 [199/250 25472/32000 (80%)] Loss: 1.96434 (semantic_loss: 0.01499, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.33600 
Train Epoch: 47 [210/250 26880/32000 (84%)] Loss: 1.96508 (semantic_loss: 0.01476, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.32373 
Train Epoch: 47 [221/250 28288/32000 (88%)] Loss: 1.96615 (semantic_loss: 0.01583, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.33371 
Train Epoch: 47 [232/250 29696/32000 (93%)] Loss: 1.96549 (semantic_loss: 0.01516, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.34666 
Train Epoch: 47 [243/250 31104/32000 (97%)] Loss: 1.96390 (semantic_loss: 0.01456, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.55141 
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/DCMH_MSRVTT_1kA/checkpoint-epoch47.pth ...
Done in 4.402s
removing stale ckpt [epoch 46] [took 0.01s]
 epoch          : 47
 loss           : 1.9645500330924988
 learning_rate  : 4.723412206886882e-06
 n_samples      : 1504000
 n_steps        : 11750
 MSRVTT_jsfusion_test/t2v_metrics/R1: 19.0
 MSRVTT_jsfusion_test/t2v_metrics/R5: 47.3
 MSRVTT_jsfusion_test/t2v_metrics/R10: 60.7
 MSRVTT_jsfusion_test/t2v_metrics/R50: 84.5
 MSRVTT_jsfusion_test/t2v_metrics/MedR: 6.0
 MSRVTT_jsfusion_test/t2v_metrics/MeanR: 33.299
 MSRVTT_jsfusion_test/t2v_metrics/geometric_mean_R1-R5-R10: 37.925776168679306
 MSRVTT_jsfusion_test/v2t_metrics/R1: 19.8
 MSRVTT_jsfusion_test/v2t_metrics/R5: 47.0
 MSRVTT_jsfusion_test/v2t_metrics/R10: 63.1
 MSRVTT_jsfusion_test/v2t_metrics/R50: 85.0
 MSRVTT_jsfusion_test/v2t_metrics/MedR: 6.0
 MSRVTT_jsfusion_test/v2t_metrics/MeanR: 32.3
 MSRVTT_jsfusion_test/v2t_metrics/geometric_mean_R1-R5-R10: 38.86847210688984
 mnt_best       : 38.37635873907502
 not_improved_count: 2
Train Epoch: 48 [1/250 128/32000 (0%)] Loss: 1.96606 (semantic_loss: 0.01573, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=24.00551 
Train Epoch: 48 [12/250 1536/32000 (5%)] Loss: 1.96357 (semantic_loss: 0.01422, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.34449 
Train Epoch: 48 [23/250 2944/32000 (9%)] Loss: 1.96343 (semantic_loss: 0.01409, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.33831 
Train Epoch: 48 [34/250 4352/32000 (14%)] Loss: 1.96437 (semantic_loss: 0.01502, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.35889 
Train Epoch: 48 [45/250 5760/32000 (18%)] Loss: 1.96456 (semantic_loss: 0.01424, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.33464 
Train Epoch: 48 [56/250 7168/32000 (22%)] Loss: 1.96459 (semantic_loss: 0.01426, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.32143 
Train Epoch: 48 [67/250 8576/32000 (27%)] Loss: 1.96341 (semantic_loss: 0.01406, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=1.04439 
Train Epoch: 48 [78/250 9984/32000 (31%)] Loss: 1.96412 (semantic_loss: 0.01380, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.33060 
Train Epoch: 48 [89/250 11392/32000 (36%)] Loss: 1.96522 (semantic_loss: 0.01490, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.32709 
Train Epoch: 48 [100/250 12800/32000 (40%)] Loss: 1.96537 (semantic_loss: 0.01505, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.33382 
Train Epoch: 48 [111/250 14208/32000 (44%)] Loss: 1.96433 (semantic_loss: 0.01400, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.32960 
Train Epoch: 48 [122/250 15616/32000 (49%)] Loss: 1.96334 (semantic_loss: 0.01399, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.40341 
Train Epoch: 48 [133/250 17024/32000 (53%)] Loss: 1.96733 (semantic_loss: 0.01701, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.33912 
Train Epoch: 48 [144/250 18432/32000 (58%)] Loss: 1.96307 (semantic_loss: 0.01372, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.35060 
Train Epoch: 48 [155/250 19840/32000 (62%)] Loss: 1.96402 (semantic_loss: 0.01369, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.33589 
Train Epoch: 48 [166/250 21248/32000 (66%)] Loss: 1.96563 (semantic_loss: 0.01628, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.34196 
Train Epoch: 48 [177/250 22656/32000 (71%)] Loss: 1.96377 (semantic_loss: 0.01344, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.53338 
Train Epoch: 48 [188/250 24064/32000 (75%)] Loss: 1.96446 (semantic_loss: 0.01413, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.35210 
Train Epoch: 48 [199/250 25472/32000 (80%)] Loss: 1.96379 (semantic_loss: 0.01347, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.32553 
Train Epoch: 48 [210/250 26880/32000 (84%)] Loss: 1.96476 (semantic_loss: 0.01443, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.34021 
Train Epoch: 48 [221/250 28288/32000 (88%)] Loss: 1.96469 (semantic_loss: 0.01437, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.35214 
Train Epoch: 48 [232/250 29696/32000 (93%)] Loss: 1.96418 (semantic_loss: 0.01484, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.36968 
Train Epoch: 48 [243/250 31104/32000 (97%)] Loss: 1.96534 (semantic_loss: 0.01502, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.34041 
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/DCMH_MSRVTT_1kA/checkpoint-epoch48.pth ...
Done in 4.067s
Updating 'best' checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/DCMH_MSRVTT_1kA/checkpoint-epoch48.pth ...
Done in 13.089s
removing stale ckpt [epoch 47] [took 0.01s]
 epoch          : 48
 loss           : 1.9645647835731506
 learning_rate  : 4.487241596542537e-06
 n_samples      : 1536000
 n_steps        : 12000
 MSRVTT_jsfusion_test/t2v_metrics/R1: 19.6
 MSRVTT_jsfusion_test/t2v_metrics/R5: 47.7
 MSRVTT_jsfusion_test/t2v_metrics/R10: 60.9
 MSRVTT_jsfusion_test/t2v_metrics/R50: 85.1
 MSRVTT_jsfusion_test/t2v_metrics/MedR: 6.0
 MSRVTT_jsfusion_test/t2v_metrics/MeanR: 33.1625
 MSRVTT_jsfusion_test/t2v_metrics/geometric_mean_R1-R5-R10: 38.47074361374438
 MSRVTT_jsfusion_test/v2t_metrics/R1: 19.7
 MSRVTT_jsfusion_test/v2t_metrics/R5: 47.2
 MSRVTT_jsfusion_test/v2t_metrics/R10: 62.6
 MSRVTT_jsfusion_test/v2t_metrics/R50: 84.4
 MSRVTT_jsfusion_test/v2t_metrics/MedR: 6.0
 MSRVTT_jsfusion_test/v2t_metrics/MeanR: 31.893
 MSRVTT_jsfusion_test/v2t_metrics/geometric_mean_R1-R5-R10: 38.75498019931442
 mnt_best       : 38.47074361374438
 not_improved_count: 0
Train Epoch: 49 [1/250 128/32000 (0%)] Loss: 1.96348 (semantic_loss: 0.01413, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=31.22271 
Train Epoch: 49 [12/250 1536/32000 (5%)] Loss: 1.96585 (semantic_loss: 0.01651, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.36750 
Train Epoch: 49 [23/250 2944/32000 (9%)] Loss: 1.96367 (semantic_loss: 0.01432, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.33654 
Train Epoch: 49 [34/250 4352/32000 (14%)] Loss: 1.96522 (semantic_loss: 0.01490, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.34054 
Train Epoch: 49 [45/250 5760/32000 (18%)] Loss: 1.96518 (semantic_loss: 0.01486, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.32568 
Train Epoch: 49 [56/250 7168/32000 (22%)] Loss: 1.96413 (semantic_loss: 0.01479, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.33580 
Train Epoch: 49 [67/250 8576/32000 (27%)] Loss: 1.96323 (semantic_loss: 0.01388, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.45490 
Train Epoch: 49 [78/250 9984/32000 (31%)] Loss: 1.96548 (semantic_loss: 0.01516, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.33670 
Train Epoch: 49 [89/250 11392/32000 (36%)] Loss: 1.96268 (semantic_loss: 0.01334, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.33910 
Train Epoch: 49 [100/250 12800/32000 (40%)] Loss: 1.96581 (semantic_loss: 0.01646, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.33933 
Train Epoch: 49 [111/250 14208/32000 (44%)] Loss: 1.96460 (semantic_loss: 0.01526, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.42835 
Train Epoch: 49 [122/250 15616/32000 (49%)] Loss: 1.96722 (semantic_loss: 0.01788, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.41236 
Train Epoch: 49 [133/250 17024/32000 (53%)] Loss: 1.96400 (semantic_loss: 0.01368, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.34327 
Train Epoch: 49 [144/250 18432/32000 (58%)] Loss: 1.96455 (semantic_loss: 0.01520, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.33328 
Train Epoch: 49 [155/250 19840/32000 (62%)] Loss: 1.96308 (semantic_loss: 0.01374, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.33383 
Train Epoch: 49 [166/250 21248/32000 (66%)] Loss: 1.96375 (semantic_loss: 0.01342, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.98545 
Train Epoch: 49 [177/250 22656/32000 (71%)] Loss: 1.96427 (semantic_loss: 0.01394, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.32896 
Train Epoch: 49 [188/250 24064/32000 (75%)] Loss: 1.96513 (semantic_loss: 0.01480, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.32772 
Train Epoch: 49 [199/250 25472/32000 (80%)] Loss: 1.96613 (semantic_loss: 0.01581, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.67999 
Train Epoch: 49 [210/250 26880/32000 (84%)] Loss: 1.96430 (semantic_loss: 0.01495, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=3.77954 
Train Epoch: 49 [221/250 28288/32000 (88%)] Loss: 1.96400 (semantic_loss: 0.01368, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.32622 
Train Epoch: 49 [232/250 29696/32000 (93%)] Loss: 1.96532 (semantic_loss: 0.01500, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.56871 
Train Epoch: 49 [243/250 31104/32000 (97%)] Loss: 1.96552 (semantic_loss: 0.01520, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.33565 
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/DCMH_MSRVTT_1kA/checkpoint-epoch49.pth ...
Done in 4.389s
Updating 'best' checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/DCMH_MSRVTT_1kA/checkpoint-epoch49.pth ...
Done in 9.038s
removing stale ckpt [epoch 48] [took 0.01s]
 epoch          : 49
 loss           : 1.964580701828003
 learning_rate  : 4.26287951671541e-06
 n_samples      : 1568000
 n_steps        : 12250
 MSRVTT_jsfusion_test/t2v_metrics/R1: 19.0
 MSRVTT_jsfusion_test/t2v_metrics/R5: 48.4
 MSRVTT_jsfusion_test/t2v_metrics/R10: 62.2
 MSRVTT_jsfusion_test/t2v_metrics/R50: 85.3
 MSRVTT_jsfusion_test/t2v_metrics/MedR: 6.0
 MSRVTT_jsfusion_test/t2v_metrics/MeanR: 32.403999999999996
 MSRVTT_jsfusion_test/t2v_metrics/geometric_mean_R1-R5-R10: 38.52977288840937
 MSRVTT_jsfusion_test/v2t_metrics/R1: 20.0
 MSRVTT_jsfusion_test/v2t_metrics/R5: 50.2
 MSRVTT_jsfusion_test/v2t_metrics/R10: 63.3
 MSRVTT_jsfusion_test/v2t_metrics/R50: 84.9
 MSRVTT_jsfusion_test/v2t_metrics/MedR: 5.5
 MSRVTT_jsfusion_test/v2t_metrics/MeanR: 31.693
 MSRVTT_jsfusion_test/v2t_metrics/geometric_mean_R1-R5-R10: 39.90669920993659
 mnt_best       : 38.52977288840937
 not_improved_count: 0
Train Epoch: 50 [1/250 128/32000 (0%)] Loss: 1.96619 (semantic_loss: 0.01587, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=29.90892 
Train Epoch: 50 [12/250 1536/32000 (5%)] Loss: 1.96630 (semantic_loss: 0.01597, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.34813 
Train Epoch: 50 [23/250 2944/32000 (9%)] Loss: 1.96293 (semantic_loss: 0.01358, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.35888 
Train Epoch: 50 [34/250 4352/32000 (14%)] Loss: 1.96370 (semantic_loss: 0.01338, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.35419 
Train Epoch: 50 [45/250 5760/32000 (18%)] Loss: 1.96504 (semantic_loss: 0.01471, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.36250 
Train Epoch: 50 [56/250 7168/32000 (22%)] Loss: 1.96458 (semantic_loss: 0.01523, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.34476 
Train Epoch: 50 [67/250 8576/32000 (27%)] Loss: 1.96438 (semantic_loss: 0.01504, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.33195 
Train Epoch: 50 [78/250 9984/32000 (31%)] Loss: 1.96270 (semantic_loss: 0.01335, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=1.69078 
Train Epoch: 50 [89/250 11392/32000 (36%)] Loss: 1.96479 (semantic_loss: 0.01545, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.35096 
Train Epoch: 50 [100/250 12800/32000 (40%)] Loss: 1.96580 (semantic_loss: 0.01547, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.35589 
Train Epoch: 50 [111/250 14208/32000 (44%)] Loss: 1.96466 (semantic_loss: 0.01434, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.36193 
Train Epoch: 50 [122/250 15616/32000 (49%)] Loss: 1.96429 (semantic_loss: 0.01495, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.32311 
Train Epoch: 50 [133/250 17024/32000 (53%)] Loss: 1.96523 (semantic_loss: 0.01588, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.36229 
Train Epoch: 50 [144/250 18432/32000 (58%)] Loss: 1.96332 (semantic_loss: 0.01397, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=4.09724 
Train Epoch: 50 [155/250 19840/32000 (62%)] Loss: 1.96515 (semantic_loss: 0.01483, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.34315 
Train Epoch: 50 [166/250 21248/32000 (66%)] Loss: 1.96533 (semantic_loss: 0.01598, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.36863 
Train Epoch: 50 [177/250 22656/32000 (71%)] Loss: 1.96628 (semantic_loss: 0.01693, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.37276 
Train Epoch: 50 [188/250 24064/32000 (75%)] Loss: 1.96531 (semantic_loss: 0.01499, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.33109 
Train Epoch: 50 [199/250 25472/32000 (80%)] Loss: 1.96518 (semantic_loss: 0.01583, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.34018 
Train Epoch: 50 [210/250 26880/32000 (84%)] Loss: 1.96386 (semantic_loss: 0.01452, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.32517 
Train Epoch: 50 [221/250 28288/32000 (88%)] Loss: 1.96481 (semantic_loss: 0.01449, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.36463 
Train Epoch: 50 [232/250 29696/32000 (93%)] Loss: 1.96494 (semantic_loss: 0.01461, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.36486 
Train Epoch: 50 [243/250 31104/32000 (97%)] Loss: 1.96448 (semantic_loss: 0.01514, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.32871 
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/DCMH_MSRVTT_1kA/checkpoint-epoch50.pth ...
Done in 3.710s
removing stale ckpt [epoch 49] [took 0.00s]
 epoch          : 50
 loss           : 1.964496088027954
 learning_rate  : 4.04973554087964e-06
 n_samples      : 1600000
 n_steps        : 12500
 MSRVTT_jsfusion_test/t2v_metrics/R1: 18.2
 MSRVTT_jsfusion_test/t2v_metrics/R5: 48.4
 MSRVTT_jsfusion_test/t2v_metrics/R10: 60.8
 MSRVTT_jsfusion_test/t2v_metrics/R50: 84.7
 MSRVTT_jsfusion_test/t2v_metrics/MedR: 6.0
 MSRVTT_jsfusion_test/t2v_metrics/MeanR: 32.91
 MSRVTT_jsfusion_test/t2v_metrics/geometric_mean_R1-R5-R10: 37.694105606097764
 MSRVTT_jsfusion_test/v2t_metrics/R1: 19.5
 MSRVTT_jsfusion_test/v2t_metrics/R5: 47.6
 MSRVTT_jsfusion_test/v2t_metrics/R10: 63.4
 MSRVTT_jsfusion_test/v2t_metrics/R50: 84.7
 MSRVTT_jsfusion_test/v2t_metrics/MedR: 6.0
 MSRVTT_jsfusion_test/v2t_metrics/MeanR: 32.119
 MSRVTT_jsfusion_test/v2t_metrics/geometric_mean_R1-R5-R10: 38.8964775878434
 mnt_best       : 38.52977288840937
 not_improved_count: 1
Final evaluation ...
Loading checkpoint from: /apdcephfs/share_47076/gimwang/HCQ/exps/DCMH_MSRVTT_1kA/trained_model.pth ...
Ckpt loaded at epoch 49.
Saved v2t similarity matrix to /apdcephfs/share_47076/gimwang/HCQ/exps/DCMH_MSRVTT_1kA/MSRVTT-test-sims.npy
MSRVTT_jsfusion_test:
 t2v_metrics/R1/final_eval: 19.0
 t2v_metrics/R5/final_eval: 48.4
 t2v_metrics/R10/final_eval: 62.2
 t2v_metrics/R50/final_eval: 85.3
 t2v_metrics/MedR/final_eval: 6.0
 t2v_metrics/MeanR/final_eval: 32.403999999999996
 t2v_metrics/geometric_mean_R1-R5-R10/final_eval: 38.52977288840937
 v2t_metrics/R1/final_eval: 20.0
 v2t_metrics/R5/final_eval: 50.2
 v2t_metrics/R10/final_eval: 63.3
 v2t_metrics/R50/final_eval: 84.9
 v2t_metrics/MedR/final_eval: 5.5
 v2t_metrics/MeanR/final_eval: 31.693
 v2t_metrics/geometric_mean_R1-R5-R10/final_eval: 39.90669920993659
Best epoch for the monitored metric: 49
Script took 02h50m28s
The best performing ckpt can be found at /apdcephfs/share_47076/gimwang/HCQ/exps/DCMH_MSRVTT_1kA/trained_model.pth
