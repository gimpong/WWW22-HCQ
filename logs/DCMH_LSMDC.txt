Experiment directory: /apdcephfs/share_47076/gimwang/HCQ/exps/DCMH_LSMDC
Preparing the dataloaders ...
Loading dataset LSMDC_full_trainval in ram ...
Finish loading dataset LSMDC_full_trainval in ram, taking 1742.2795560359955 s.
Loading dataset LSMDC_full_test in ram ...
Finish loading dataset LSMDC_full_test in ram, taking 8.089824438095093 s.
Loading dataset LSMDC_full_test in ram ...
Finish loading dataset LSMDC_full_test in ram, taking 6.383724689483643 s.
Training ...
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/DCMH_LSMDC/checkpoint-epoch0.pth ...
Done in 14.936s
Updating 'best' checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/DCMH_LSMDC/checkpoint-epoch0.pth ...
Done in 16.572s
 epoch          : 0
 loss           : 0
 learning_rate  : 5e-05
 n_samples      : 0
 n_steps        : 0
 LSMDC_full_test/t2v_metrics/R1: 0.1
 LSMDC_full_test/t2v_metrics/R5: 0.6
 LSMDC_full_test/t2v_metrics/R10: 1.0
 LSMDC_full_test/t2v_metrics/R50: 5.3
 LSMDC_full_test/t2v_metrics/MedR: 498.5
 LSMDC_full_test/t2v_metrics/MeanR: 497.618
 LSMDC_full_test/t2v_metrics/geometric_mean_R1-R5-R10: 0.3914867641168864
 LSMDC_full_test/v2t_metrics/R1: 0.1
 LSMDC_full_test/v2t_metrics/R5: 0.7
 LSMDC_full_test/v2t_metrics/R10: 0.9
 LSMDC_full_test/v2t_metrics/R50: 5.4
 LSMDC_full_test/v2t_metrics/MedR: 485.5
 LSMDC_full_test/v2t_metrics/MeanR: 496.3395
 LSMDC_full_test/v2t_metrics/geometric_mean_R1-R5-R10: 0.3979057207896392
 mnt_best       : 0.3914867641168864
 not_improved_count: 0
Train Epoch: 1 [1/250 128/32000 (0%)] Loss: 3.03912 (semantic_loss: 1.08952, quant_loss: 1.94922, bit_balance_loss: 0.00038) batch_time=12.76600 
Train Epoch: 1 [12/250 1536/32000 (5%)] Loss: 2.00161 (semantic_loss: 0.05097, quant_loss: 1.95020, bit_balance_loss: 0.00045) batch_time=0.33396 
Train Epoch: 1 [23/250 2944/32000 (9%)] Loss: 1.99662 (semantic_loss: 0.04595, quant_loss: 1.95020, bit_balance_loss: 0.00047) batch_time=0.34557 
Train Epoch: 1 [34/250 4352/32000 (14%)] Loss: 1.99748 (semantic_loss: 0.04583, quant_loss: 1.95117, bit_balance_loss: 0.00048) batch_time=0.32804 
Train Epoch: 1 [45/250 5760/32000 (18%)] Loss: 1.99648 (semantic_loss: 0.04580, quant_loss: 1.95020, bit_balance_loss: 0.00048) batch_time=0.33687 
Train Epoch: 1 [56/250 7168/32000 (22%)] Loss: 1.99548 (semantic_loss: 0.04578, quant_loss: 1.94922, bit_balance_loss: 0.00048) batch_time=0.32620 
Train Epoch: 1 [67/250 8576/32000 (27%)] Loss: 1.99644 (semantic_loss: 0.04576, quant_loss: 1.95020, bit_balance_loss: 0.00048) batch_time=0.33315 
Train Epoch: 1 [78/250 9984/32000 (31%)] Loss: 1.99545 (semantic_loss: 0.04575, quant_loss: 1.94922, bit_balance_loss: 0.00048) batch_time=0.31855 
Train Epoch: 1 [89/250 11392/32000 (36%)] Loss: 1.99641 (semantic_loss: 0.04573, quant_loss: 1.95020, bit_balance_loss: 0.00048) batch_time=0.32648 
Train Epoch: 1 [100/250 12800/32000 (40%)] Loss: 1.99640 (semantic_loss: 0.04573, quant_loss: 1.95020, bit_balance_loss: 0.00048) batch_time=0.33062 
Train Epoch: 1 [111/250 14208/32000 (44%)] Loss: 1.99639 (semantic_loss: 0.04572, quant_loss: 1.95020, bit_balance_loss: 0.00047) batch_time=0.32659 
Train Epoch: 1 [122/250 15616/32000 (49%)] Loss: 1.99641 (semantic_loss: 0.04575, quant_loss: 1.95020, bit_balance_loss: 0.00047) batch_time=0.32707 
Train Epoch: 1 [133/250 17024/32000 (53%)] Loss: 1.99639 (semantic_loss: 0.04573, quant_loss: 1.95020, bit_balance_loss: 0.00047) batch_time=0.31701 
Train Epoch: 1 [144/250 18432/32000 (58%)] Loss: 1.99638 (semantic_loss: 0.04572, quant_loss: 1.95020, bit_balance_loss: 0.00046) batch_time=0.32642 
Train Epoch: 1 [155/250 19840/32000 (62%)] Loss: 1.99638 (semantic_loss: 0.04572, quant_loss: 1.95020, bit_balance_loss: 0.00046) batch_time=0.32453 
Train Epoch: 1 [166/250 21248/32000 (66%)] Loss: 1.99638 (semantic_loss: 0.04572, quant_loss: 1.95020, bit_balance_loss: 0.00046) batch_time=0.31740 
Train Epoch: 1 [177/250 22656/32000 (71%)] Loss: 1.99638 (semantic_loss: 0.04573, quant_loss: 1.95020, bit_balance_loss: 0.00045) batch_time=0.32299 
Train Epoch: 1 [188/250 24064/32000 (75%)] Loss: 1.99636 (semantic_loss: 0.04571, quant_loss: 1.95020, bit_balance_loss: 0.00045) batch_time=0.34186 
Train Epoch: 1 [199/250 25472/32000 (80%)] Loss: 1.99635 (semantic_loss: 0.04570, quant_loss: 1.95020, bit_balance_loss: 0.00045) batch_time=0.31749 
Train Epoch: 1 [210/250 26880/32000 (84%)] Loss: 1.99635 (semantic_loss: 0.04571, quant_loss: 1.95020, bit_balance_loss: 0.00045) batch_time=0.32812 
Train Epoch: 1 [221/250 28288/32000 (88%)] Loss: 1.99635 (semantic_loss: 0.04572, quant_loss: 1.95020, bit_balance_loss: 0.00044) batch_time=0.32860 
Train Epoch: 1 [232/250 29696/32000 (93%)] Loss: 1.99732 (semantic_loss: 0.04571, quant_loss: 1.95117, bit_balance_loss: 0.00044) batch_time=0.32085 
Train Epoch: 1 [243/250 31104/32000 (97%)] Loss: 1.99634 (semantic_loss: 0.04571, quant_loss: 1.95020, bit_balance_loss: 0.00043) batch_time=0.34495 
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/DCMH_LSMDC/checkpoint-epoch1.pth ...
Done in 10.042s
 epoch          : 1
 loss           : 2.0056123695373533
 learning_rate  : 5e-05
 n_samples      : 32000
 n_steps        : 250
 LSMDC_full_test/t2v_metrics/R1: 0.1
 LSMDC_full_test/t2v_metrics/R5: 0.5
 LSMDC_full_test/t2v_metrics/R10: 0.9
 LSMDC_full_test/t2v_metrics/R50: 5.3
 LSMDC_full_test/t2v_metrics/MedR: 503.75
 LSMDC_full_test/t2v_metrics/MeanR: 502.2105
 LSMDC_full_test/t2v_metrics/geometric_mean_R1-R5-R10: 0.3556893304490063
 LSMDC_full_test/v2t_metrics/R1: 0.1
 LSMDC_full_test/v2t_metrics/R5: 0.5
 LSMDC_full_test/v2t_metrics/R10: 0.6
 LSMDC_full_test/v2t_metrics/R50: 4.9
 LSMDC_full_test/v2t_metrics/MedR: 490.0
 LSMDC_full_test/v2t_metrics/MeanR: 500.646
 LSMDC_full_test/v2t_metrics/geometric_mean_R1-R5-R10: 0.31072325059538586
 mnt_best       : 0.3914867641168864
 not_improved_count: 1
Train Epoch: 2 [1/250 128/32000 (0%)] Loss: 1.99633 (semantic_loss: 0.04571, quant_loss: 1.95020, bit_balance_loss: 0.00043) batch_time=12.40297 
Train Epoch: 2 [12/250 1536/32000 (5%)] Loss: 1.99632 (semantic_loss: 0.04570, quant_loss: 1.95020, bit_balance_loss: 0.00043) batch_time=0.32949 
Train Epoch: 2 [23/250 2944/32000 (9%)] Loss: 1.99633 (semantic_loss: 0.04571, quant_loss: 1.95020, bit_balance_loss: 0.00043) batch_time=0.37052 
Train Epoch: 2 [34/250 4352/32000 (14%)] Loss: 1.99632 (semantic_loss: 0.04570, quant_loss: 1.95020, bit_balance_loss: 0.00042) batch_time=0.34317 
Train Epoch: 2 [45/250 5760/32000 (18%)] Loss: 1.99631 (semantic_loss: 0.04570, quant_loss: 1.95020, bit_balance_loss: 0.00042) batch_time=0.37215 
Train Epoch: 2 [56/250 7168/32000 (22%)] Loss: 1.99630 (semantic_loss: 0.04569, quant_loss: 1.95020, bit_balance_loss: 0.00041) batch_time=0.34984 
Train Epoch: 2 [67/250 8576/32000 (27%)] Loss: 1.99629 (semantic_loss: 0.04569, quant_loss: 1.95020, bit_balance_loss: 0.00041) batch_time=0.34524 
Train Epoch: 2 [78/250 9984/32000 (31%)] Loss: 1.99629 (semantic_loss: 0.04569, quant_loss: 1.95020, bit_balance_loss: 0.00041) batch_time=4.38341 
Train Epoch: 2 [89/250 11392/32000 (36%)] Loss: 1.99628 (semantic_loss: 0.04568, quant_loss: 1.95020, bit_balance_loss: 0.00040) batch_time=0.31723 
Train Epoch: 2 [100/250 12800/32000 (40%)] Loss: 1.99629 (semantic_loss: 0.04570, quant_loss: 1.95020, bit_balance_loss: 0.00040) batch_time=0.31302 
Train Epoch: 2 [111/250 14208/32000 (44%)] Loss: 1.99628 (semantic_loss: 0.04569, quant_loss: 1.95020, bit_balance_loss: 0.00040) batch_time=0.33248 
Train Epoch: 2 [122/250 15616/32000 (49%)] Loss: 1.99725 (semantic_loss: 0.04568, quant_loss: 1.95117, bit_balance_loss: 0.00039) batch_time=0.32970 
Train Epoch: 2 [133/250 17024/32000 (53%)] Loss: 1.99625 (semantic_loss: 0.04567, quant_loss: 1.95020, bit_balance_loss: 0.00039) batch_time=0.32670 
Train Epoch: 2 [144/250 18432/32000 (58%)] Loss: 1.99620 (semantic_loss: 0.04562, quant_loss: 1.95020, bit_balance_loss: 0.00038) batch_time=0.33249 
Train Epoch: 2 [155/250 19840/32000 (62%)] Loss: 1.99619 (semantic_loss: 0.04562, quant_loss: 1.95020, bit_balance_loss: 0.00038) batch_time=0.31771 
Train Epoch: 2 [166/250 21248/32000 (66%)] Loss: 1.99618 (semantic_loss: 0.04561, quant_loss: 1.95020, bit_balance_loss: 0.00037) batch_time=0.32454 
Train Epoch: 2 [177/250 22656/32000 (71%)] Loss: 1.99604 (semantic_loss: 0.04547, quant_loss: 1.95020, bit_balance_loss: 0.00037) batch_time=0.32569 
Train Epoch: 2 [188/250 24064/32000 (75%)] Loss: 1.99689 (semantic_loss: 0.04536, quant_loss: 1.95117, bit_balance_loss: 0.00037) batch_time=0.32534 
Train Epoch: 2 [199/250 25472/32000 (80%)] Loss: 1.99575 (semantic_loss: 0.04519, quant_loss: 1.95020, bit_balance_loss: 0.00036) batch_time=0.37261 
Train Epoch: 2 [210/250 26880/32000 (84%)] Loss: 1.99584 (semantic_loss: 0.04529, quant_loss: 1.95020, bit_balance_loss: 0.00036) batch_time=0.31778 
Train Epoch: 2 [221/250 28288/32000 (88%)] Loss: 1.99534 (semantic_loss: 0.04479, quant_loss: 1.95020, bit_balance_loss: 0.00035) batch_time=0.32572 
Train Epoch: 2 [232/250 29696/32000 (93%)] Loss: 1.99562 (semantic_loss: 0.04508, quant_loss: 1.95020, bit_balance_loss: 0.00034) batch_time=0.31771 
Train Epoch: 2 [243/250 31104/32000 (97%)] Loss: 1.99473 (semantic_loss: 0.04420, quant_loss: 1.95020, bit_balance_loss: 0.00034) batch_time=0.33637 
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/DCMH_LSMDC/checkpoint-epoch2.pth ...
Done in 4.897s
Updating 'best' checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/DCMH_LSMDC/checkpoint-epoch2.pth ...
Done in 9.767s
removing stale ckpt [epoch 1] [took 0.00s]
removing stale ckpt [epoch 0] [took 0.02s]
 epoch          : 2
 loss           : 1.9961583204269409
 learning_rate  : 4.75e-05
 n_samples      : 64000
 n_steps        : 500
 LSMDC_full_test/t2v_metrics/R1: 0.1
 LSMDC_full_test/t2v_metrics/R5: 1.1
 LSMDC_full_test/t2v_metrics/R10: 1.8
 LSMDC_full_test/t2v_metrics/R50: 10.3
 LSMDC_full_test/t2v_metrics/MedR: 312.25
 LSMDC_full_test/t2v_metrics/MeanR: 363.449
 LSMDC_full_test/t2v_metrics/geometric_mean_R1-R5-R10: 0.5828476683251457
 LSMDC_full_test/v2t_metrics/R1: 0.0
 LSMDC_full_test/v2t_metrics/R5: 0.9
 LSMDC_full_test/v2t_metrics/R10: 1.4
 LSMDC_full_test/v2t_metrics/R50: 8.7
 LSMDC_full_test/v2t_metrics/MedR: 343.0
 LSMDC_full_test/v2t_metrics/MeanR: 382.7175
 LSMDC_full_test/v2t_metrics/geometric_mean_R1-R5-R10: 0.0
 mnt_best       : 0.5828476683251457
 not_improved_count: 0
Train Epoch: 3 [1/250 128/32000 (0%)] Loss: 1.99491 (semantic_loss: 0.04438, quant_loss: 1.95020, bit_balance_loss: 0.00034) batch_time=13.99417 
Train Epoch: 3 [12/250 1536/32000 (5%)] Loss: 1.99506 (semantic_loss: 0.04453, quant_loss: 1.95020, bit_balance_loss: 0.00033) batch_time=0.32650 
Train Epoch: 3 [23/250 2944/32000 (9%)] Loss: 1.99501 (semantic_loss: 0.04449, quant_loss: 1.95020, bit_balance_loss: 0.00033) batch_time=0.32062 
Train Epoch: 3 [34/250 4352/32000 (14%)] Loss: 1.99468 (semantic_loss: 0.04416, quant_loss: 1.95020, bit_balance_loss: 0.00033) batch_time=0.42516 
Train Epoch: 3 [45/250 5760/32000 (18%)] Loss: 1.99357 (semantic_loss: 0.04403, quant_loss: 1.94922, bit_balance_loss: 0.00032) batch_time=0.35558 
Train Epoch: 3 [56/250 7168/32000 (22%)] Loss: 1.99435 (semantic_loss: 0.04383, quant_loss: 1.95020, bit_balance_loss: 0.00032) batch_time=0.32012 
Train Epoch: 3 [67/250 8576/32000 (27%)] Loss: 1.99440 (semantic_loss: 0.04389, quant_loss: 1.95020, bit_balance_loss: 0.00032) batch_time=0.33049 
Train Epoch: 3 [78/250 9984/32000 (31%)] Loss: 1.99335 (semantic_loss: 0.04381, quant_loss: 1.94922, bit_balance_loss: 0.00032) batch_time=0.34631 
Train Epoch: 3 [89/250 11392/32000 (36%)] Loss: 1.99398 (semantic_loss: 0.04445, quant_loss: 1.94922, bit_balance_loss: 0.00031) batch_time=0.49074 
Train Epoch: 3 [100/250 12800/32000 (40%)] Loss: 1.99314 (semantic_loss: 0.04361, quant_loss: 1.94922, bit_balance_loss: 0.00031) batch_time=0.32077 
Train Epoch: 3 [111/250 14208/32000 (44%)] Loss: 1.99409 (semantic_loss: 0.04359, quant_loss: 1.95020, bit_balance_loss: 0.00031) batch_time=0.33754 
Train Epoch: 3 [122/250 15616/32000 (49%)] Loss: 1.99305 (semantic_loss: 0.04353, quant_loss: 1.94922, bit_balance_loss: 0.00030) batch_time=0.33375 
Train Epoch: 3 [133/250 17024/32000 (53%)] Loss: 1.99403 (semantic_loss: 0.04354, quant_loss: 1.95020, bit_balance_loss: 0.00030) batch_time=0.31348 
Train Epoch: 3 [144/250 18432/32000 (58%)] Loss: 1.99347 (semantic_loss: 0.04395, quant_loss: 1.94922, bit_balance_loss: 0.00030) batch_time=0.33209 
Train Epoch: 3 [155/250 19840/32000 (62%)] Loss: 1.99544 (semantic_loss: 0.04397, quant_loss: 1.95117, bit_balance_loss: 0.00030) batch_time=0.34547 
Train Epoch: 3 [166/250 21248/32000 (66%)] Loss: 1.99381 (semantic_loss: 0.04333, quant_loss: 1.95020, bit_balance_loss: 0.00029) batch_time=0.33777 
Train Epoch: 3 [177/250 22656/32000 (71%)] Loss: 1.99439 (semantic_loss: 0.04390, quant_loss: 1.95020, bit_balance_loss: 0.00029) batch_time=0.32566 
Train Epoch: 3 [188/250 24064/32000 (75%)] Loss: 1.99367 (semantic_loss: 0.04318, quant_loss: 1.95020, bit_balance_loss: 0.00029) batch_time=0.31679 
Train Epoch: 3 [199/250 25472/32000 (80%)] Loss: 1.99327 (semantic_loss: 0.04279, quant_loss: 1.95020, bit_balance_loss: 0.00029) batch_time=0.32188 
Train Epoch: 3 [210/250 26880/32000 (84%)] Loss: 1.99338 (semantic_loss: 0.04290, quant_loss: 1.95020, bit_balance_loss: 0.00028) batch_time=0.34291 
Train Epoch: 3 [221/250 28288/32000 (88%)] Loss: 1.99191 (semantic_loss: 0.04241, quant_loss: 1.94922, bit_balance_loss: 0.00028) batch_time=0.36232 
Train Epoch: 3 [232/250 29696/32000 (93%)] Loss: 1.99173 (semantic_loss: 0.04224, quant_loss: 1.94922, bit_balance_loss: 0.00028) batch_time=0.32731 
Train Epoch: 3 [243/250 31104/32000 (97%)] Loss: 1.99174 (semantic_loss: 0.04225, quant_loss: 1.94922, bit_balance_loss: 0.00027) batch_time=0.32440 
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/DCMH_LSMDC/checkpoint-epoch3.pth ...
Done in 18.301s
Updating 'best' checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/DCMH_LSMDC/checkpoint-epoch3.pth ...
Done in 22.946s
removing stale ckpt [epoch 2] [took 0.00s]
 epoch          : 3
 loss           : 1.99387796831131
 learning_rate  : 4.5125e-05
 n_samples      : 96000
 n_steps        : 750
 LSMDC_full_test/t2v_metrics/R1: 0.2
 LSMDC_full_test/t2v_metrics/R5: 1.8
 LSMDC_full_test/t2v_metrics/R10: 3.6
 LSMDC_full_test/t2v_metrics/R50: 16.6
 LSMDC_full_test/t2v_metrics/MedR: 198.5
 LSMDC_full_test/t2v_metrics/MeanR: 257.4335
 LSMDC_full_test/t2v_metrics/geometric_mean_R1-R5-R10: 1.0902723556992837
 LSMDC_full_test/v2t_metrics/R1: 0.5
 LSMDC_full_test/v2t_metrics/R5: 2.5
 LSMDC_full_test/v2t_metrics/R10: 4.0
 LSMDC_full_test/v2t_metrics/R50: 17.1
 LSMDC_full_test/v2t_metrics/MedR: 193.0
 LSMDC_full_test/v2t_metrics/MeanR: 251.318
 LSMDC_full_test/v2t_metrics/geometric_mean_R1-R5-R10: 1.709975946676697
 mnt_best       : 1.0902723556992837
 not_improved_count: 0
Train Epoch: 4 [1/250 128/32000 (0%)] Loss: 1.99163 (semantic_loss: 0.04214, quant_loss: 1.94922, bit_balance_loss: 0.00027) batch_time=13.88802 
Train Epoch: 4 [12/250 1536/32000 (5%)] Loss: 1.99336 (semantic_loss: 0.04289, quant_loss: 1.95020, bit_balance_loss: 0.00027) batch_time=0.31664 
Train Epoch: 4 [23/250 2944/32000 (9%)] Loss: 1.99160 (semantic_loss: 0.04212, quant_loss: 1.94922, bit_balance_loss: 0.00026) batch_time=0.36387 
Train Epoch: 4 [34/250 4352/32000 (14%)] Loss: 1.99148 (semantic_loss: 0.04200, quant_loss: 1.94922, bit_balance_loss: 0.00026) batch_time=0.32014 
Train Epoch: 4 [45/250 5760/32000 (18%)] Loss: 1.99191 (semantic_loss: 0.04146, quant_loss: 1.95020, bit_balance_loss: 0.00026) batch_time=0.33534 
Train Epoch: 4 [56/250 7168/32000 (22%)] Loss: 1.99196 (semantic_loss: 0.04151, quant_loss: 1.95020, bit_balance_loss: 0.00026) batch_time=0.33319 
Train Epoch: 4 [67/250 8576/32000 (27%)] Loss: 1.99190 (semantic_loss: 0.04242, quant_loss: 1.94922, bit_balance_loss: 0.00026) batch_time=6.48518 
Train Epoch: 4 [78/250 9984/32000 (31%)] Loss: 1.99185 (semantic_loss: 0.04140, quant_loss: 1.95020, bit_balance_loss: 0.00025) batch_time=0.33055 
Train Epoch: 4 [89/250 11392/32000 (36%)] Loss: 1.99048 (semantic_loss: 0.04101, quant_loss: 1.94922, bit_balance_loss: 0.00025) batch_time=1.32858 
Train Epoch: 4 [100/250 12800/32000 (40%)] Loss: 1.99060 (semantic_loss: 0.04113, quant_loss: 1.94922, bit_balance_loss: 0.00024) batch_time=0.33523 
Train Epoch: 4 [111/250 14208/32000 (44%)] Loss: 1.99115 (semantic_loss: 0.04169, quant_loss: 1.94922, bit_balance_loss: 0.00024) batch_time=0.33846 
Train Epoch: 4 [122/250 15616/32000 (49%)] Loss: 1.99067 (semantic_loss: 0.04024, quant_loss: 1.95020, bit_balance_loss: 0.00024) batch_time=0.35286 
Train Epoch: 4 [133/250 17024/32000 (53%)] Loss: 1.99049 (semantic_loss: 0.04103, quant_loss: 1.94922, bit_balance_loss: 0.00024) batch_time=0.32312 
Train Epoch: 4 [144/250 18432/32000 (58%)] Loss: 1.99073 (semantic_loss: 0.04030, quant_loss: 1.95020, bit_balance_loss: 0.00023) batch_time=0.32802 
Train Epoch: 4 [155/250 19840/32000 (62%)] Loss: 1.99070 (semantic_loss: 0.04027, quant_loss: 1.95020, bit_balance_loss: 0.00023) batch_time=0.32736 
Train Epoch: 4 [166/250 21248/32000 (66%)] Loss: 1.99154 (semantic_loss: 0.04112, quant_loss: 1.95020, bit_balance_loss: 0.00023) batch_time=0.32612 
Train Epoch: 4 [177/250 22656/32000 (71%)] Loss: 1.98887 (semantic_loss: 0.03845, quant_loss: 1.95020, bit_balance_loss: 0.00023) batch_time=0.32695 
Train Epoch: 4 [188/250 24064/32000 (75%)] Loss: 1.99001 (semantic_loss: 0.03959, quant_loss: 1.95020, bit_balance_loss: 0.00022) batch_time=0.35684 
Train Epoch: 4 [199/250 25472/32000 (80%)] Loss: 1.98936 (semantic_loss: 0.03895, quant_loss: 1.95020, bit_balance_loss: 0.00022) batch_time=0.32591 
Train Epoch: 4 [210/250 26880/32000 (84%)] Loss: 1.99089 (semantic_loss: 0.04048, quant_loss: 1.95020, bit_balance_loss: 0.00022) batch_time=0.33266 
Train Epoch: 4 [221/250 28288/32000 (88%)] Loss: 1.98989 (semantic_loss: 0.03948, quant_loss: 1.95020, bit_balance_loss: 0.00021) batch_time=0.34788 
Train Epoch: 4 [232/250 29696/32000 (93%)] Loss: 1.98790 (semantic_loss: 0.03847, quant_loss: 1.94922, bit_balance_loss: 0.00021) batch_time=0.32570 
Train Epoch: 4 [243/250 31104/32000 (97%)] Loss: 1.98722 (semantic_loss: 0.03779, quant_loss: 1.94922, bit_balance_loss: 0.00021) batch_time=0.34903 
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/DCMH_LSMDC/checkpoint-epoch4.pth ...
Done in 4.771s
Updating 'best' checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/DCMH_LSMDC/checkpoint-epoch4.pth ...
Done in 9.673s
removing stale ckpt [epoch 3] [took 0.55s]
 epoch          : 4
 loss           : 1.990595157146454
 learning_rate  : 4.2868749999999995e-05
 n_samples      : 128000
 n_steps        : 1000
 LSMDC_full_test/t2v_metrics/R1: 1.8
 LSMDC_full_test/t2v_metrics/R5: 7.3
 LSMDC_full_test/t2v_metrics/R10: 11.4
 LSMDC_full_test/t2v_metrics/R50: 35.2
 LSMDC_full_test/t2v_metrics/MedR: 89.25
 LSMDC_full_test/t2v_metrics/MeanR: 157.5795
 LSMDC_full_test/t2v_metrics/geometric_mean_R1-R5-R10: 5.310883060389755
 LSMDC_full_test/v2t_metrics/R1: 1.9
 LSMDC_full_test/v2t_metrics/R5: 6.5
 LSMDC_full_test/v2t_metrics/R10: 12.3
 LSMDC_full_test/v2t_metrics/R50: 37.0
 LSMDC_full_test/v2t_metrics/MedR: 91.75
 LSMDC_full_test/v2t_metrics/MeanR: 156.5225
 LSMDC_full_test/v2t_metrics/geometric_mean_R1-R5-R10: 5.33569123171104
 mnt_best       : 5.310883060389755
 not_improved_count: 0
Train Epoch: 5 [1/250 128/32000 (0%)] Loss: 1.98720 (semantic_loss: 0.03777, quant_loss: 1.94922, bit_balance_loss: 0.00021) batch_time=17.53207 
Train Epoch: 5 [12/250 1536/32000 (5%)] Loss: 1.98716 (semantic_loss: 0.03676, quant_loss: 1.95020, bit_balance_loss: 0.00021) batch_time=0.33765 
Train Epoch: 5 [23/250 2944/32000 (9%)] Loss: 1.98735 (semantic_loss: 0.03694, quant_loss: 1.95020, bit_balance_loss: 0.00021) batch_time=2.37983 
Train Epoch: 5 [34/250 4352/32000 (14%)] Loss: 1.98626 (semantic_loss: 0.03684, quant_loss: 1.94922, bit_balance_loss: 0.00020) batch_time=0.32666 
Train Epoch: 5 [45/250 5760/32000 (18%)] Loss: 1.98769 (semantic_loss: 0.03730, quant_loss: 1.95020, bit_balance_loss: 0.00020) batch_time=0.31689 
Train Epoch: 5 [56/250 7168/32000 (22%)] Loss: 1.98795 (semantic_loss: 0.03853, quant_loss: 1.94922, bit_balance_loss: 0.00020) batch_time=0.33364 
Train Epoch: 5 [67/250 8576/32000 (27%)] Loss: 1.98670 (semantic_loss: 0.03728, quant_loss: 1.94922, bit_balance_loss: 0.00020) batch_time=0.34338 
Train Epoch: 5 [78/250 9984/32000 (31%)] Loss: 1.98606 (semantic_loss: 0.03665, quant_loss: 1.94922, bit_balance_loss: 0.00019) batch_time=0.44601 
Train Epoch: 5 [89/250 11392/32000 (36%)] Loss: 1.98822 (semantic_loss: 0.03783, quant_loss: 1.95020, bit_balance_loss: 0.00019) batch_time=0.32199 
Train Epoch: 5 [100/250 12800/32000 (40%)] Loss: 1.98783 (semantic_loss: 0.03745, quant_loss: 1.95020, bit_balance_loss: 0.00019) batch_time=0.32508 
Train Epoch: 5 [111/250 14208/32000 (44%)] Loss: 1.98691 (semantic_loss: 0.03653, quant_loss: 1.95020, bit_balance_loss: 0.00019) batch_time=0.32104 
Train Epoch: 5 [122/250 15616/32000 (49%)] Loss: 1.98541 (semantic_loss: 0.03601, quant_loss: 1.94922, bit_balance_loss: 0.00019) batch_time=0.32649 
Train Epoch: 5 [133/250 17024/32000 (53%)] Loss: 1.98567 (semantic_loss: 0.03627, quant_loss: 1.94922, bit_balance_loss: 0.00018) batch_time=0.32975 
Train Epoch: 5 [144/250 18432/32000 (58%)] Loss: 1.98596 (semantic_loss: 0.03656, quant_loss: 1.94922, bit_balance_loss: 0.00018) batch_time=2.82182 
Train Epoch: 5 [155/250 19840/32000 (62%)] Loss: 1.98670 (semantic_loss: 0.03633, quant_loss: 1.95020, bit_balance_loss: 0.00018) batch_time=0.34149 
Train Epoch: 5 [166/250 21248/32000 (66%)] Loss: 1.98546 (semantic_loss: 0.03509, quant_loss: 1.95020, bit_balance_loss: 0.00018) batch_time=0.32896 
Train Epoch: 5 [177/250 22656/32000 (71%)] Loss: 1.98578 (semantic_loss: 0.03638, quant_loss: 1.94922, bit_balance_loss: 0.00018) batch_time=0.35319 
Train Epoch: 5 [188/250 24064/32000 (75%)] Loss: 1.98466 (semantic_loss: 0.03429, quant_loss: 1.95020, bit_balance_loss: 0.00018) batch_time=0.32842 
Train Epoch: 5 [199/250 25472/32000 (80%)] Loss: 1.98716 (semantic_loss: 0.03679, quant_loss: 1.95020, bit_balance_loss: 0.00018) batch_time=0.34591 
Train Epoch: 5 [210/250 26880/32000 (84%)] Loss: 1.98735 (semantic_loss: 0.03698, quant_loss: 1.95020, bit_balance_loss: 0.00017) batch_time=3.06587 
Train Epoch: 5 [221/250 28288/32000 (88%)] Loss: 1.98540 (semantic_loss: 0.03503, quant_loss: 1.95020, bit_balance_loss: 0.00017) batch_time=0.32928 
Train Epoch: 5 [232/250 29696/32000 (93%)] Loss: 1.98572 (semantic_loss: 0.03535, quant_loss: 1.95020, bit_balance_loss: 0.00017) batch_time=0.34990 
Train Epoch: 5 [243/250 31104/32000 (97%)] Loss: 1.98702 (semantic_loss: 0.03666, quant_loss: 1.95020, bit_balance_loss: 0.00017) batch_time=0.32510 
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/DCMH_LSMDC/checkpoint-epoch5.pth ...
Done in 3.838s
Updating 'best' checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/DCMH_LSMDC/checkpoint-epoch5.pth ...
Done in 7.681s
removing stale ckpt [epoch 4] [took 0.00s]
 epoch          : 5
 loss           : 1.9866640586853028
 learning_rate  : 4.072531249999999e-05
 n_samples      : 160000
 n_steps        : 1250
 LSMDC_full_test/t2v_metrics/R1: 3.4
 LSMDC_full_test/t2v_metrics/R5: 13.1
 LSMDC_full_test/t2v_metrics/R10: 19.2
 LSMDC_full_test/t2v_metrics/R50: 46.0
 LSMDC_full_test/t2v_metrics/MedR: 62.0
 LSMDC_full_test/t2v_metrics/MeanR: 126.4855
 LSMDC_full_test/t2v_metrics/geometric_mean_R1-R5-R10: 9.491841564472848
 LSMDC_full_test/v2t_metrics/R1: 3.2
 LSMDC_full_test/v2t_metrics/R5: 11.5
 LSMDC_full_test/v2t_metrics/R10: 19.6
 LSMDC_full_test/v2t_metrics/R50: 47.4
 LSMDC_full_test/v2t_metrics/MedR: 57.0
 LSMDC_full_test/v2t_metrics/MeanR: 122.192
 LSMDC_full_test/v2t_metrics/geometric_mean_R1-R5-R10: 8.968117643299879
 mnt_best       : 9.491841564472848
 not_improved_count: 0
Train Epoch: 6 [1/250 128/32000 (0%)] Loss: 1.98439 (semantic_loss: 0.03402, quant_loss: 1.95020, bit_balance_loss: 0.00017) batch_time=23.20242 
Train Epoch: 6 [12/250 1536/32000 (5%)] Loss: 1.98539 (semantic_loss: 0.03503, quant_loss: 1.95020, bit_balance_loss: 0.00017) batch_time=0.32509 
Train Epoch: 6 [23/250 2944/32000 (9%)] Loss: 1.98599 (semantic_loss: 0.03563, quant_loss: 1.95020, bit_balance_loss: 0.00017) batch_time=0.32658 
Train Epoch: 6 [34/250 4352/32000 (14%)] Loss: 1.98442 (semantic_loss: 0.03503, quant_loss: 1.94922, bit_balance_loss: 0.00017) batch_time=0.32827 
Train Epoch: 6 [45/250 5760/32000 (18%)] Loss: 1.98563 (semantic_loss: 0.03526, quant_loss: 1.95020, bit_balance_loss: 0.00017) batch_time=0.33216 
Train Epoch: 6 [56/250 7168/32000 (22%)] Loss: 1.98439 (semantic_loss: 0.03500, quant_loss: 1.94922, bit_balance_loss: 0.00017) batch_time=0.33458 
Train Epoch: 6 [67/250 8576/32000 (27%)] Loss: 1.98475 (semantic_loss: 0.03537, quant_loss: 1.94922, bit_balance_loss: 0.00016) batch_time=0.31790 
Train Epoch: 6 [78/250 9984/32000 (31%)] Loss: 1.98605 (semantic_loss: 0.03667, quant_loss: 1.94922, bit_balance_loss: 0.00017) batch_time=0.76937 
Train Epoch: 6 [89/250 11392/32000 (36%)] Loss: 1.98448 (semantic_loss: 0.03509, quant_loss: 1.94922, bit_balance_loss: 0.00017) batch_time=0.33415 
Train Epoch: 6 [100/250 12800/32000 (40%)] Loss: 1.98490 (semantic_loss: 0.03454, quant_loss: 1.95020, bit_balance_loss: 0.00017) batch_time=0.35707 
Train Epoch: 6 [111/250 14208/32000 (44%)] Loss: 1.98667 (semantic_loss: 0.03631, quant_loss: 1.95020, bit_balance_loss: 0.00016) batch_time=0.34920 
Train Epoch: 6 [122/250 15616/32000 (49%)] Loss: 1.98594 (semantic_loss: 0.03558, quant_loss: 1.95020, bit_balance_loss: 0.00016) batch_time=0.32530 
Train Epoch: 6 [133/250 17024/32000 (53%)] Loss: 1.98257 (semantic_loss: 0.03319, quant_loss: 1.94922, bit_balance_loss: 0.00016) batch_time=0.31819 
Train Epoch: 6 [144/250 18432/32000 (58%)] Loss: 1.98491 (semantic_loss: 0.03456, quant_loss: 1.95020, bit_balance_loss: 0.00016) batch_time=0.36187 
Train Epoch: 6 [155/250 19840/32000 (62%)] Loss: 1.98600 (semantic_loss: 0.03565, quant_loss: 1.95020, bit_balance_loss: 0.00016) batch_time=0.36953 
Train Epoch: 6 [166/250 21248/32000 (66%)] Loss: 1.98472 (semantic_loss: 0.03436, quant_loss: 1.95020, bit_balance_loss: 0.00016) batch_time=0.31346 
Train Epoch: 6 [177/250 22656/32000 (71%)] Loss: 1.98481 (semantic_loss: 0.03446, quant_loss: 1.95020, bit_balance_loss: 0.00016) batch_time=0.32670 
Train Epoch: 6 [188/250 24064/32000 (75%)] Loss: 1.98271 (semantic_loss: 0.03236, quant_loss: 1.95020, bit_balance_loss: 0.00015) batch_time=0.32475 
Train Epoch: 6 [199/250 25472/32000 (80%)] Loss: 1.98446 (semantic_loss: 0.03508, quant_loss: 1.94922, bit_balance_loss: 0.00016) batch_time=0.33093 
Train Epoch: 6 [210/250 26880/32000 (84%)] Loss: 1.98313 (semantic_loss: 0.03376, quant_loss: 1.94922, bit_balance_loss: 0.00015) batch_time=0.35538 
Train Epoch: 6 [221/250 28288/32000 (88%)] Loss: 1.98430 (semantic_loss: 0.03396, quant_loss: 1.95020, bit_balance_loss: 0.00015) batch_time=0.31877 
Train Epoch: 6 [232/250 29696/32000 (93%)] Loss: 1.98469 (semantic_loss: 0.03531, quant_loss: 1.94922, bit_balance_loss: 0.00016) batch_time=0.32361 
Train Epoch: 6 [243/250 31104/32000 (97%)] Loss: 1.98384 (semantic_loss: 0.03447, quant_loss: 1.94922, bit_balance_loss: 0.00015) batch_time=0.33384 
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/DCMH_LSMDC/checkpoint-epoch6.pth ...
Done in 5.574s
Updating 'best' checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/DCMH_LSMDC/checkpoint-epoch6.pth ...
Done in 10.612s
removing stale ckpt [epoch 5] [took 0.01s]
 epoch          : 6
 loss           : 1.9846772456169128
 learning_rate  : 3.868904687499999e-05
 n_samples      : 192000
 n_steps        : 1500
 LSMDC_full_test/t2v_metrics/R1: 5.4
 LSMDC_full_test/t2v_metrics/R5: 14.2
 LSMDC_full_test/t2v_metrics/R10: 22.5
 LSMDC_full_test/t2v_metrics/R50: 52.5
 LSMDC_full_test/t2v_metrics/MedR: 44.75
 LSMDC_full_test/t2v_metrics/MeanR: 107.0105
 LSMDC_full_test/t2v_metrics/geometric_mean_R1-R5-R10: 11.993746741963019
 LSMDC_full_test/v2t_metrics/R1: 4.8
 LSMDC_full_test/v2t_metrics/R5: 14.2
 LSMDC_full_test/v2t_metrics/R10: 22.6
 LSMDC_full_test/v2t_metrics/R50: 52.5
 LSMDC_full_test/v2t_metrics/MedR: 45.25
 LSMDC_full_test/v2t_metrics/MeanR: 107.5585
 LSMDC_full_test/v2t_metrics/geometric_mean_R1-R5-R10: 11.549043229529504
 mnt_best       : 11.993746741963019
 not_improved_count: 0
Train Epoch: 7 [1/250 128/32000 (0%)] Loss: 1.98300 (semantic_loss: 0.03266, quant_loss: 1.95020, bit_balance_loss: 0.00015) batch_time=28.15736 
Train Epoch: 7 [12/250 1536/32000 (5%)] Loss: 1.98451 (semantic_loss: 0.03416, quant_loss: 1.95020, bit_balance_loss: 0.00015) batch_time=0.33481 
Train Epoch: 7 [23/250 2944/32000 (9%)] Loss: 1.98150 (semantic_loss: 0.03214, quant_loss: 1.94922, bit_balance_loss: 0.00015) batch_time=0.33454 
Train Epoch: 7 [34/250 4352/32000 (14%)] Loss: 1.98451 (semantic_loss: 0.03417, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.32709 
Train Epoch: 7 [45/250 5760/32000 (18%)] Loss: 1.98345 (semantic_loss: 0.03311, quant_loss: 1.95020, bit_balance_loss: 0.00015) batch_time=0.34438 
Train Epoch: 7 [56/250 7168/32000 (22%)] Loss: 1.98260 (semantic_loss: 0.03226, quant_loss: 1.95020, bit_balance_loss: 0.00015) batch_time=0.35697 
Train Epoch: 7 [67/250 8576/32000 (27%)] Loss: 1.98503 (semantic_loss: 0.03470, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.32657 
Train Epoch: 7 [78/250 9984/32000 (31%)] Loss: 1.98384 (semantic_loss: 0.03350, quant_loss: 1.95020, bit_balance_loss: 0.00015) batch_time=0.32973 
Train Epoch: 7 [89/250 11392/32000 (36%)] Loss: 1.98375 (semantic_loss: 0.03341, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.32076 
Train Epoch: 7 [100/250 12800/32000 (40%)] Loss: 1.98185 (semantic_loss: 0.03054, quant_loss: 1.95117, bit_balance_loss: 0.00014) batch_time=0.33476 
Train Epoch: 7 [111/250 14208/32000 (44%)] Loss: 1.98423 (semantic_loss: 0.03486, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.35161 
Train Epoch: 7 [122/250 15616/32000 (49%)] Loss: 1.98301 (semantic_loss: 0.03365, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.31845 
Train Epoch: 7 [133/250 17024/32000 (53%)] Loss: 1.98153 (semantic_loss: 0.03218, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.33033 
Train Epoch: 7 [144/250 18432/32000 (58%)] Loss: 1.98033 (semantic_loss: 0.03097, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.38644 
Train Epoch: 7 [155/250 19840/32000 (62%)] Loss: 1.98274 (semantic_loss: 0.03241, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.34372 
Train Epoch: 7 [166/250 21248/32000 (66%)] Loss: 1.98161 (semantic_loss: 0.03225, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.31839 
Train Epoch: 7 [177/250 22656/32000 (71%)] Loss: 1.98207 (semantic_loss: 0.03174, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.32109 
Train Epoch: 7 [188/250 24064/32000 (75%)] Loss: 1.98209 (semantic_loss: 0.03274, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.88654 
Train Epoch: 7 [199/250 25472/32000 (80%)] Loss: 1.98075 (semantic_loss: 0.03041, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.34883 
Train Epoch: 7 [210/250 26880/32000 (84%)] Loss: 1.98300 (semantic_loss: 0.03364, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.32572 
Train Epoch: 7 [221/250 28288/32000 (88%)] Loss: 1.98091 (semantic_loss: 0.03156, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.34936 
Train Epoch: 7 [232/250 29696/32000 (93%)] Loss: 1.98210 (semantic_loss: 0.03177, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.32852 
Train Epoch: 7 [243/250 31104/32000 (97%)] Loss: 1.98231 (semantic_loss: 0.03393, quant_loss: 1.94824, bit_balance_loss: 0.00014) batch_time=0.35873 
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/DCMH_LSMDC/checkpoint-epoch7.pth ...
Done in 5.089s
removing stale ckpt [epoch 6] [took 0.00s]
 epoch          : 7
 loss           : 1.982935338973999
 learning_rate  : 3.675459453124999e-05
 n_samples      : 224000
 n_steps        : 1750
 LSMDC_full_test/t2v_metrics/R1: 3.9
 LSMDC_full_test/t2v_metrics/R5: 15.9
 LSMDC_full_test/t2v_metrics/R10: 24.7
 LSMDC_full_test/t2v_metrics/R50: 54.0
 LSMDC_full_test/t2v_metrics/MedR: 42.5
 LSMDC_full_test/t2v_metrics/MeanR: 102.594
 LSMDC_full_test/t2v_metrics/geometric_mean_R1-R5-R10: 11.527086749220528
 LSMDC_full_test/v2t_metrics/R1: 4.9
 LSMDC_full_test/v2t_metrics/R5: 15.6
 LSMDC_full_test/v2t_metrics/R10: 23.4
 LSMDC_full_test/v2t_metrics/R50: 52.7
 LSMDC_full_test/v2t_metrics/MedR: 45.5
 LSMDC_full_test/v2t_metrics/MeanR: 102.331
 LSMDC_full_test/v2t_metrics/geometric_mean_R1-R5-R10: 12.13888634707577
 mnt_best       : 11.993746741963019
 not_improved_count: 1
Train Epoch: 8 [1/250 128/32000 (0%)] Loss: 1.98170 (semantic_loss: 0.03137, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=11.95752 
Train Epoch: 8 [12/250 1536/32000 (5%)] Loss: 1.98223 (semantic_loss: 0.03288, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.32999 
Train Epoch: 8 [23/250 2944/32000 (9%)] Loss: 1.98194 (semantic_loss: 0.03161, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.33091 
Train Epoch: 8 [34/250 4352/32000 (14%)] Loss: 1.98283 (semantic_loss: 0.03348, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.36040 
Train Epoch: 8 [45/250 5760/32000 (18%)] Loss: 1.98161 (semantic_loss: 0.03226, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.34845 
Train Epoch: 8 [56/250 7168/32000 (22%)] Loss: 1.98322 (semantic_loss: 0.03290, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.36682 
Train Epoch: 8 [67/250 8576/32000 (27%)] Loss: 1.98047 (semantic_loss: 0.03112, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.32450 
Train Epoch: 8 [78/250 9984/32000 (31%)] Loss: 1.98264 (semantic_loss: 0.03231, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.33953 
Train Epoch: 8 [89/250 11392/32000 (36%)] Loss: 1.98072 (semantic_loss: 0.03040, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.32506 
Train Epoch: 8 [100/250 12800/32000 (40%)] Loss: 1.98287 (semantic_loss: 0.03255, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.32661 
Train Epoch: 8 [111/250 14208/32000 (44%)] Loss: 1.98111 (semantic_loss: 0.03078, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.36101 
Train Epoch: 8 [122/250 15616/32000 (49%)] Loss: 1.98194 (semantic_loss: 0.03259, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.33970 
Train Epoch: 8 [133/250 17024/32000 (53%)] Loss: 1.98121 (semantic_loss: 0.03186, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.33150 
Train Epoch: 8 [144/250 18432/32000 (58%)] Loss: 1.98189 (semantic_loss: 0.03157, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.33127 
Train Epoch: 8 [155/250 19840/32000 (62%)] Loss: 1.98181 (semantic_loss: 0.03246, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.34795 
Train Epoch: 8 [166/250 21248/32000 (66%)] Loss: 1.98410 (semantic_loss: 0.03378, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.34380 
Train Epoch: 8 [177/250 22656/32000 (71%)] Loss: 1.98451 (semantic_loss: 0.03418, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.32720 
Train Epoch: 8 [188/250 24064/32000 (75%)] Loss: 1.98365 (semantic_loss: 0.03333, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.34160 
Train Epoch: 8 [199/250 25472/32000 (80%)] Loss: 1.97958 (semantic_loss: 0.02926, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=3.66855 
Train Epoch: 8 [210/250 26880/32000 (84%)] Loss: 1.98214 (semantic_loss: 0.03279, quant_loss: 1.94922, bit_balance_loss: 0.00012) batch_time=0.32452 
Train Epoch: 8 [221/250 28288/32000 (88%)] Loss: 1.98284 (semantic_loss: 0.03252, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.32596 
Train Epoch: 8 [232/250 29696/32000 (93%)] Loss: 1.98294 (semantic_loss: 0.03262, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.33343 
Train Epoch: 8 [243/250 31104/32000 (97%)] Loss: 1.98305 (semantic_loss: 0.03272, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.36887 
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/DCMH_LSMDC/checkpoint-epoch8.pth ...
Done in 6.218s
Updating 'best' checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/DCMH_LSMDC/checkpoint-epoch8.pth ...
Done in 10.685s
removing stale ckpt [epoch 7] [took 0.00s]
 epoch          : 8
 loss           : 1.9818022541999818
 learning_rate  : 3.4916864804687486e-05
 n_samples      : 256000
 n_steps        : 2000
 LSMDC_full_test/t2v_metrics/R1: 5.1
 LSMDC_full_test/t2v_metrics/R5: 17.6
 LSMDC_full_test/t2v_metrics/R10: 26.4
 LSMDC_full_test/t2v_metrics/R50: 56.4
 LSMDC_full_test/t2v_metrics/MedR: 38.0
 LSMDC_full_test/t2v_metrics/MeanR: 98.5505
 LSMDC_full_test/t2v_metrics/geometric_mean_R1-R5-R10: 13.332008757305628
 LSMDC_full_test/v2t_metrics/R1: 5.1
 LSMDC_full_test/v2t_metrics/R5: 17.6
 LSMDC_full_test/v2t_metrics/R10: 25.3
 LSMDC_full_test/v2t_metrics/R50: 55.9
 LSMDC_full_test/v2t_metrics/MedR: 38.0
 LSMDC_full_test/v2t_metrics/MeanR: 97.721
 LSMDC_full_test/v2t_metrics/geometric_mean_R1-R5-R10: 13.14420897068185
 mnt_best       : 13.332008757305628
 not_improved_count: 0
Train Epoch: 9 [1/250 128/32000 (0%)] Loss: 1.98050 (semantic_loss: 0.03019, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=12.40770 
Train Epoch: 9 [12/250 1536/32000 (5%)] Loss: 1.98053 (semantic_loss: 0.03021, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.32772 
Train Epoch: 9 [23/250 2944/32000 (9%)] Loss: 1.97980 (semantic_loss: 0.03046, quant_loss: 1.94922, bit_balance_loss: 0.00012) batch_time=0.35536 
Train Epoch: 9 [34/250 4352/32000 (14%)] Loss: 1.98099 (semantic_loss: 0.03067, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.34603 
Train Epoch: 9 [45/250 5760/32000 (18%)] Loss: 1.98069 (semantic_loss: 0.03134, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.32911 
Train Epoch: 9 [56/250 7168/32000 (22%)] Loss: 1.97987 (semantic_loss: 0.02956, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.32740 
Train Epoch: 9 [67/250 8576/32000 (27%)] Loss: 1.98173 (semantic_loss: 0.03238, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.31929 
Train Epoch: 9 [78/250 9984/32000 (31%)] Loss: 1.97747 (semantic_loss: 0.02813, quant_loss: 1.94922, bit_balance_loss: 0.00012) batch_time=0.32234 
Train Epoch: 9 [89/250 11392/32000 (36%)] Loss: 1.98222 (semantic_loss: 0.03190, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.32942 
Train Epoch: 9 [100/250 12800/32000 (40%)] Loss: 1.98037 (semantic_loss: 0.03005, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.32761 
Train Epoch: 9 [111/250 14208/32000 (44%)] Loss: 1.98164 (semantic_loss: 0.03132, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.33708 
Train Epoch: 9 [122/250 15616/32000 (49%)] Loss: 1.97993 (semantic_loss: 0.03059, quant_loss: 1.94922, bit_balance_loss: 0.00012) batch_time=0.34244 
Train Epoch: 9 [133/250 17024/32000 (53%)] Loss: 1.97983 (semantic_loss: 0.02951, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.33605 
Train Epoch: 9 [144/250 18432/32000 (58%)] Loss: 1.98199 (semantic_loss: 0.03167, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.35244 
Train Epoch: 9 [155/250 19840/32000 (62%)] Loss: 1.98254 (semantic_loss: 0.03222, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.31888 
Train Epoch: 9 [166/250 21248/32000 (66%)] Loss: 1.98206 (semantic_loss: 0.03174, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.33133 
Train Epoch: 9 [177/250 22656/32000 (71%)] Loss: 1.98187 (semantic_loss: 0.03155, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.33633 
Train Epoch: 9 [188/250 24064/32000 (75%)] Loss: 1.97948 (semantic_loss: 0.02917, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.32784 
Train Epoch: 9 [199/250 25472/32000 (80%)] Loss: 1.98107 (semantic_loss: 0.03075, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.33305 
Train Epoch: 9 [210/250 26880/32000 (84%)] Loss: 1.98207 (semantic_loss: 0.03175, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.32703 
Train Epoch: 9 [221/250 28288/32000 (88%)] Loss: 1.97901 (semantic_loss: 0.02967, quant_loss: 1.94922, bit_balance_loss: 0.00012) batch_time=0.32091 
Train Epoch: 9 [232/250 29696/32000 (93%)] Loss: 1.98057 (semantic_loss: 0.03026, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.32444 
Train Epoch: 9 [243/250 31104/32000 (97%)] Loss: 1.98091 (semantic_loss: 0.03060, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.31883 
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/DCMH_LSMDC/checkpoint-epoch9.pth ...
Done in 4.941s
Updating 'best' checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/DCMH_LSMDC/checkpoint-epoch9.pth ...
Done in 9.529s
removing stale ckpt [epoch 8] [took 0.00s]
 epoch          : 9
 loss           : 1.9808243174552917
 learning_rate  : 3.317102156445311e-05
 n_samples      : 288000
 n_steps        : 2250
 LSMDC_full_test/t2v_metrics/R1: 5.7
 LSMDC_full_test/t2v_metrics/R5: 18.4
 LSMDC_full_test/t2v_metrics/R10: 28.9
 LSMDC_full_test/t2v_metrics/R50: 56.0
 LSMDC_full_test/t2v_metrics/MedR: 37.0
 LSMDC_full_test/t2v_metrics/MeanR: 95.3565
 LSMDC_full_test/t2v_metrics/geometric_mean_R1-R5-R10: 14.472053982083029
 LSMDC_full_test/v2t_metrics/R1: 5.4
 LSMDC_full_test/v2t_metrics/R5: 18.2
 LSMDC_full_test/v2t_metrics/R10: 27.5
 LSMDC_full_test/v2t_metrics/R50: 55.3
 LSMDC_full_test/v2t_metrics/MedR: 38.0
 LSMDC_full_test/v2t_metrics/MeanR: 95.518
 LSMDC_full_test/v2t_metrics/geometric_mean_R1-R5-R10: 13.929406543334656
 mnt_best       : 14.472053982083029
 not_improved_count: 0
Train Epoch: 10 [1/250 128/32000 (0%)] Loss: 1.98028 (semantic_loss: 0.03094, quant_loss: 1.94922, bit_balance_loss: 0.00012) batch_time=20.30418 
Train Epoch: 10 [12/250 1536/32000 (5%)] Loss: 1.97989 (semantic_loss: 0.03056, quant_loss: 1.94922, bit_balance_loss: 0.00012) batch_time=1.04569 
Train Epoch: 10 [23/250 2944/32000 (9%)] Loss: 1.97869 (semantic_loss: 0.02935, quant_loss: 1.94922, bit_balance_loss: 0.00012) batch_time=0.32089 
Train Epoch: 10 [34/250 4352/32000 (14%)] Loss: 1.97919 (semantic_loss: 0.02888, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.33452 
Train Epoch: 10 [45/250 5760/32000 (18%)] Loss: 1.97894 (semantic_loss: 0.02960, quant_loss: 1.94922, bit_balance_loss: 0.00012) batch_time=0.35078 
Train Epoch: 10 [56/250 7168/32000 (22%)] Loss: 1.98197 (semantic_loss: 0.03165, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.33005 
Train Epoch: 10 [67/250 8576/32000 (27%)] Loss: 1.97953 (semantic_loss: 0.03019, quant_loss: 1.94922, bit_balance_loss: 0.00012) batch_time=0.31569 
Train Epoch: 10 [78/250 9984/32000 (31%)] Loss: 1.97891 (semantic_loss: 0.02957, quant_loss: 1.94922, bit_balance_loss: 0.00012) batch_time=5.64914 
Train Epoch: 10 [89/250 11392/32000 (36%)] Loss: 1.98146 (semantic_loss: 0.03115, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.32500 
Train Epoch: 10 [100/250 12800/32000 (40%)] Loss: 1.97967 (semantic_loss: 0.03033, quant_loss: 1.94922, bit_balance_loss: 0.00012) batch_time=0.31671 
Train Epoch: 10 [111/250 14208/32000 (44%)] Loss: 1.98140 (semantic_loss: 0.03108, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.33786 
Train Epoch: 10 [122/250 15616/32000 (49%)] Loss: 1.98089 (semantic_loss: 0.03058, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.33019 
Train Epoch: 10 [133/250 17024/32000 (53%)] Loss: 1.97912 (semantic_loss: 0.02881, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.33264 
Train Epoch: 10 [144/250 18432/32000 (58%)] Loss: 1.98050 (semantic_loss: 0.02921, quant_loss: 1.95117, bit_balance_loss: 0.00011) batch_time=0.36309 
Train Epoch: 10 [155/250 19840/32000 (62%)] Loss: 1.97943 (semantic_loss: 0.02912, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.32275 
Train Epoch: 10 [166/250 21248/32000 (66%)] Loss: 1.98148 (semantic_loss: 0.03116, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.31375 
Train Epoch: 10 [177/250 22656/32000 (71%)] Loss: 1.97774 (semantic_loss: 0.02840, quant_loss: 1.94922, bit_balance_loss: 0.00012) batch_time=0.33751 
Train Epoch: 10 [188/250 24064/32000 (75%)] Loss: 1.98011 (semantic_loss: 0.02980, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.34474 
Train Epoch: 10 [199/250 25472/32000 (80%)] Loss: 1.97991 (semantic_loss: 0.02960, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.31317 
Train Epoch: 10 [210/250 26880/32000 (84%)] Loss: 1.97901 (semantic_loss: 0.02968, quant_loss: 1.94922, bit_balance_loss: 0.00012) batch_time=0.32233 
Train Epoch: 10 [221/250 28288/32000 (88%)] Loss: 1.97768 (semantic_loss: 0.02737, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.31650 
Train Epoch: 10 [232/250 29696/32000 (93%)] Loss: 1.98026 (semantic_loss: 0.02995, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.32410 
Train Epoch: 10 [243/250 31104/32000 (97%)] Loss: 1.98009 (semantic_loss: 0.03076, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=0.33993 
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/DCMH_LSMDC/checkpoint-epoch10.pth ...
Done in 4.438s
Updating 'best' checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/DCMH_LSMDC/checkpoint-epoch10.pth ...
Done in 8.895s
removing stale ckpt [epoch 9] [took 0.00s]
 epoch          : 10
 loss           : 1.9801599164009094
 learning_rate  : 3.151247048623045e-05
 n_samples      : 320000
 n_steps        : 2500
 LSMDC_full_test/t2v_metrics/R1: 6.9
 LSMDC_full_test/t2v_metrics/R5: 20.9
 LSMDC_full_test/t2v_metrics/R10: 28.4
 LSMDC_full_test/t2v_metrics/R50: 57.8
 LSMDC_full_test/t2v_metrics/MedR: 35.0
 LSMDC_full_test/t2v_metrics/MeanR: 91.3885
 LSMDC_full_test/t2v_metrics/geometric_mean_R1-R5-R10: 15.999432271522185
 LSMDC_full_test/v2t_metrics/R1: 5.6
 LSMDC_full_test/v2t_metrics/R5: 18.0
 LSMDC_full_test/v2t_metrics/R10: 27.8
 LSMDC_full_test/v2t_metrics/R50: 55.4
 LSMDC_full_test/v2t_metrics/MedR: 35.5
 LSMDC_full_test/v2t_metrics/MeanR: 95.4545
 LSMDC_full_test/v2t_metrics/geometric_mean_R1-R5-R10: 14.098355021616289
 mnt_best       : 15.999432271522185
 not_improved_count: 0
Train Epoch: 11 [1/250 128/32000 (0%)] Loss: 1.98160 (semantic_loss: 0.03129, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=13.85531 
Train Epoch: 11 [12/250 1536/32000 (5%)] Loss: 1.97895 (semantic_loss: 0.02865, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.32214 
Train Epoch: 11 [23/250 2944/32000 (9%)] Loss: 1.98024 (semantic_loss: 0.02992, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.33322 
Train Epoch: 11 [34/250 4352/32000 (14%)] Loss: 1.97846 (semantic_loss: 0.02913, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=0.32010 
Train Epoch: 11 [45/250 5760/32000 (18%)] Loss: 1.97875 (semantic_loss: 0.02942, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=0.34864 
Train Epoch: 11 [56/250 7168/32000 (22%)] Loss: 1.98076 (semantic_loss: 0.03046, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.43665 
Train Epoch: 11 [67/250 8576/32000 (27%)] Loss: 1.97995 (semantic_loss: 0.02965, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=6.13733 
Train Epoch: 11 [78/250 9984/32000 (31%)] Loss: 1.97927 (semantic_loss: 0.02993, quant_loss: 1.94922, bit_balance_loss: 0.00012) batch_time=0.32789 
Train Epoch: 11 [89/250 11392/32000 (36%)] Loss: 1.97879 (semantic_loss: 0.02946, quant_loss: 1.94922, bit_balance_loss: 0.00012) batch_time=0.92314 
Train Epoch: 11 [100/250 12800/32000 (40%)] Loss: 1.97913 (semantic_loss: 0.02881, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.32334 
Train Epoch: 11 [111/250 14208/32000 (44%)] Loss: 1.97747 (semantic_loss: 0.02814, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=0.32839 
Train Epoch: 11 [122/250 15616/32000 (49%)] Loss: 1.97873 (semantic_loss: 0.02940, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=0.33676 
Train Epoch: 11 [133/250 17024/32000 (53%)] Loss: 1.97808 (semantic_loss: 0.02875, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=0.33779 
Train Epoch: 11 [144/250 18432/32000 (58%)] Loss: 1.97982 (semantic_loss: 0.02951, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.35029 
Train Epoch: 11 [155/250 19840/32000 (62%)] Loss: 1.97829 (semantic_loss: 0.02896, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=0.33478 
Train Epoch: 11 [166/250 21248/32000 (66%)] Loss: 1.98078 (semantic_loss: 0.03048, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.32016 
Train Epoch: 11 [177/250 22656/32000 (71%)] Loss: 1.97959 (semantic_loss: 0.03026, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=0.33763 
Train Epoch: 11 [188/250 24064/32000 (75%)] Loss: 1.97851 (semantic_loss: 0.02918, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=0.32542 
Train Epoch: 11 [199/250 25472/32000 (80%)] Loss: 1.97814 (semantic_loss: 0.02784, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.34086 
Train Epoch: 11 [210/250 26880/32000 (84%)] Loss: 1.97749 (semantic_loss: 0.02816, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=0.42301 
Train Epoch: 11 [221/250 28288/32000 (88%)] Loss: 1.97721 (semantic_loss: 0.02788, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=0.33814 
Train Epoch: 11 [232/250 29696/32000 (93%)] Loss: 1.98015 (semantic_loss: 0.02984, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.31787 
Train Epoch: 11 [243/250 31104/32000 (97%)] Loss: 1.97846 (semantic_loss: 0.02913, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=0.32805 
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/DCMH_LSMDC/checkpoint-epoch11.pth ...
Done in 4.429s
Updating 'best' checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/DCMH_LSMDC/checkpoint-epoch11.pth ...
Done in 9.300s
removing stale ckpt [epoch 10] [took 0.21s]
 epoch          : 11
 loss           : 1.9792315955162048
 learning_rate  : 2.993684696191893e-05
 n_samples      : 352000
 n_steps        : 2750
 LSMDC_full_test/t2v_metrics/R1: 6.9
 LSMDC_full_test/t2v_metrics/R5: 19.9
 LSMDC_full_test/t2v_metrics/R10: 30.0
 LSMDC_full_test/t2v_metrics/R50: 56.8
 LSMDC_full_test/t2v_metrics/MedR: 36.5
 LSMDC_full_test/t2v_metrics/MeanR: 90.552
 LSMDC_full_test/t2v_metrics/geometric_mean_R1-R5-R10: 16.030281196085276
 LSMDC_full_test/v2t_metrics/R1: 7.0
 LSMDC_full_test/v2t_metrics/R5: 20.3
 LSMDC_full_test/v2t_metrics/R10: 29.5
 LSMDC_full_test/v2t_metrics/R50: 58.3
 LSMDC_full_test/v2t_metrics/MedR: 36.25
 LSMDC_full_test/v2t_metrics/MeanR: 88.202
 LSMDC_full_test/v2t_metrics/geometric_mean_R1-R5-R10: 16.12397185119723
 mnt_best       : 16.030281196085276
 not_improved_count: 0
Train Epoch: 12 [1/250 128/32000 (0%)] Loss: 1.97977 (semantic_loss: 0.03043, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=14.42930 
Train Epoch: 12 [12/250 1536/32000 (5%)] Loss: 1.97989 (semantic_loss: 0.02958, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.32764 
Train Epoch: 12 [23/250 2944/32000 (9%)] Loss: 1.97934 (semantic_loss: 0.02903, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.34070 
Train Epoch: 12 [34/250 4352/32000 (14%)] Loss: 1.97682 (semantic_loss: 0.02750, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=0.32907 
Train Epoch: 12 [45/250 5760/32000 (18%)] Loss: 1.98096 (semantic_loss: 0.03065, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.32716 
Train Epoch: 12 [56/250 7168/32000 (22%)] Loss: 1.97808 (semantic_loss: 0.02875, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=0.35239 
Train Epoch: 12 [67/250 8576/32000 (27%)] Loss: 1.97984 (semantic_loss: 0.03051, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=0.54925 
Train Epoch: 12 [78/250 9984/32000 (31%)] Loss: 1.98056 (semantic_loss: 0.03025, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.34819 
Train Epoch: 12 [89/250 11392/32000 (36%)] Loss: 1.97998 (semantic_loss: 0.03065, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=0.34571 
Train Epoch: 12 [100/250 12800/32000 (40%)] Loss: 1.97951 (semantic_loss: 0.03017, quant_loss: 1.94922, bit_balance_loss: 0.00012) batch_time=0.31731 
Train Epoch: 12 [111/250 14208/32000 (44%)] Loss: 1.97822 (semantic_loss: 0.02791, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.31752 
Train Epoch: 12 [122/250 15616/32000 (49%)] Loss: 1.97861 (semantic_loss: 0.02830, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.35213 
Train Epoch: 12 [133/250 17024/32000 (53%)] Loss: 1.97900 (semantic_loss: 0.02967, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=4.43141 
Train Epoch: 12 [144/250 18432/32000 (58%)] Loss: 1.97888 (semantic_loss: 0.02856, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.32968 
Train Epoch: 12 [155/250 19840/32000 (62%)] Loss: 1.97823 (semantic_loss: 0.02890, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=0.32567 
Train Epoch: 12 [166/250 21248/32000 (66%)] Loss: 1.97746 (semantic_loss: 0.02814, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=0.34419 
Train Epoch: 12 [177/250 22656/32000 (71%)] Loss: 1.97793 (semantic_loss: 0.02860, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=0.32660 
Train Epoch: 12 [188/250 24064/32000 (75%)] Loss: 1.97906 (semantic_loss: 0.02974, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=0.35867 
Train Epoch: 12 [199/250 25472/32000 (80%)] Loss: 1.97853 (semantic_loss: 0.02823, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.38209 
Train Epoch: 12 [210/250 26880/32000 (84%)] Loss: 1.97715 (semantic_loss: 0.02782, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=0.36660 
Train Epoch: 12 [221/250 28288/32000 (88%)] Loss: 1.97761 (semantic_loss: 0.02828, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=0.33216 
Train Epoch: 12 [232/250 29696/32000 (93%)] Loss: 1.97846 (semantic_loss: 0.02913, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=0.32024 
Train Epoch: 12 [243/250 31104/32000 (97%)] Loss: 1.97623 (semantic_loss: 0.02592, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.36560 
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/DCMH_LSMDC/checkpoint-epoch12.pth ...
Done in 4.652s
Updating 'best' checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/DCMH_LSMDC/checkpoint-epoch12.pth ...
Done in 9.481s
removing stale ckpt [epoch 11] [took 0.01s]
 epoch          : 12
 loss           : 1.9787542052268983
 learning_rate  : 2.844000461382298e-05
 n_samples      : 384000
 n_steps        : 3000
 LSMDC_full_test/t2v_metrics/R1: 6.6
 LSMDC_full_test/t2v_metrics/R5: 21.1
 LSMDC_full_test/t2v_metrics/R10: 29.9
 LSMDC_full_test/t2v_metrics/R50: 60.1
 LSMDC_full_test/t2v_metrics/MedR: 32.0
 LSMDC_full_test/t2v_metrics/MeanR: 87.8465
 LSMDC_full_test/t2v_metrics/geometric_mean_R1-R5-R10: 16.087893886583227
 LSMDC_full_test/v2t_metrics/R1: 5.9
 LSMDC_full_test/v2t_metrics/R5: 20.0
 LSMDC_full_test/v2t_metrics/R10: 29.7
 LSMDC_full_test/v2t_metrics/R50: 58.7
 LSMDC_full_test/v2t_metrics/MedR: 32.5
 LSMDC_full_test/v2t_metrics/MeanR: 88.7685
 LSMDC_full_test/v2t_metrics/geometric_mean_R1-R5-R10: 15.189593523323595
 mnt_best       : 16.087893886583227
 not_improved_count: 0
Train Epoch: 13 [1/250 128/32000 (0%)] Loss: 1.97916 (semantic_loss: 0.02885, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=18.35272 
Train Epoch: 13 [12/250 1536/32000 (5%)] Loss: 1.97750 (semantic_loss: 0.02817, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=0.32102 
Train Epoch: 13 [23/250 2944/32000 (9%)] Loss: 1.97916 (semantic_loss: 0.02886, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.34106 
Train Epoch: 13 [34/250 4352/32000 (14%)] Loss: 1.97817 (semantic_loss: 0.02884, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=0.32611 
Train Epoch: 13 [45/250 5760/32000 (18%)] Loss: 1.97741 (semantic_loss: 0.02710, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.32757 
Train Epoch: 13 [56/250 7168/32000 (22%)] Loss: 1.97826 (semantic_loss: 0.02893, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=0.31561 
Train Epoch: 13 [67/250 8576/32000 (27%)] Loss: 1.98054 (semantic_loss: 0.03024, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.33059 
Train Epoch: 13 [78/250 9984/32000 (31%)] Loss: 1.97659 (semantic_loss: 0.02629, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.31539 
Train Epoch: 13 [89/250 11392/32000 (36%)] Loss: 1.97814 (semantic_loss: 0.02881, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=0.89124 
Train Epoch: 13 [100/250 12800/32000 (40%)] Loss: 1.97823 (semantic_loss: 0.02890, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=0.32573 
Train Epoch: 13 [111/250 14208/32000 (44%)] Loss: 1.97782 (semantic_loss: 0.02849, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=0.31385 
Train Epoch: 13 [122/250 15616/32000 (49%)] Loss: 1.97727 (semantic_loss: 0.02794, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=0.31211 
Train Epoch: 13 [133/250 17024/32000 (53%)] Loss: 1.97874 (semantic_loss: 0.02843, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.31550 
Train Epoch: 13 [144/250 18432/32000 (58%)] Loss: 1.97743 (semantic_loss: 0.02810, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=0.33260 
Train Epoch: 13 [155/250 19840/32000 (62%)] Loss: 1.97790 (semantic_loss: 0.02759, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.34510 
Train Epoch: 13 [166/250 21248/32000 (66%)] Loss: 1.97766 (semantic_loss: 0.02833, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=0.32948 
Train Epoch: 13 [177/250 22656/32000 (71%)] Loss: 1.98019 (semantic_loss: 0.02988, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.32972 
Train Epoch: 13 [188/250 24064/32000 (75%)] Loss: 1.98037 (semantic_loss: 0.03006, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.31226 
Train Epoch: 13 [199/250 25472/32000 (80%)] Loss: 1.97708 (semantic_loss: 0.02678, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.31310 
Train Epoch: 13 [210/250 26880/32000 (84%)] Loss: 1.97676 (semantic_loss: 0.02743, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=1.24120 
Train Epoch: 13 [221/250 28288/32000 (88%)] Loss: 1.97687 (semantic_loss: 0.02657, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.31522 
Train Epoch: 13 [232/250 29696/32000 (93%)] Loss: 1.97780 (semantic_loss: 0.02847, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=0.32750 
Train Epoch: 13 [243/250 31104/32000 (97%)] Loss: 1.97753 (semantic_loss: 0.02820, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=0.32524 
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/DCMH_LSMDC/checkpoint-epoch13.pth ...
Done in 5.413s
Updating 'best' checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/DCMH_LSMDC/checkpoint-epoch13.pth ...
Done in 10.286s
removing stale ckpt [epoch 12] [took 0.01s]
 epoch          : 13
 loss           : 1.9780727987289428
 learning_rate  : 2.7018004383131832e-05
 n_samples      : 416000
 n_steps        : 3250
 LSMDC_full_test/t2v_metrics/R1: 7.5
 LSMDC_full_test/t2v_metrics/R5: 22.6
 LSMDC_full_test/t2v_metrics/R10: 31.5
 LSMDC_full_test/t2v_metrics/R50: 59.8
 LSMDC_full_test/t2v_metrics/MedR: 33.25
 LSMDC_full_test/t2v_metrics/MeanR: 83.525
 LSMDC_full_test/t2v_metrics/geometric_mean_R1-R5-R10: 17.478067762547283
 LSMDC_full_test/v2t_metrics/R1: 7.9
 LSMDC_full_test/v2t_metrics/R5: 21.7
 LSMDC_full_test/v2t_metrics/R10: 30.1
 LSMDC_full_test/v2t_metrics/R50: 61.1
 LSMDC_full_test/v2t_metrics/MedR: 31.75
 LSMDC_full_test/v2t_metrics/MeanR: 81.9815
 LSMDC_full_test/v2t_metrics/geometric_mean_R1-R5-R10: 17.280293195971144
 mnt_best       : 17.478067762547283
 not_improved_count: 0
Train Epoch: 14 [1/250 128/32000 (0%)] Loss: 1.97874 (semantic_loss: 0.02941, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=14.40953 
Train Epoch: 14 [12/250 1536/32000 (5%)] Loss: 1.97513 (semantic_loss: 0.02581, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=0.33033 
Train Epoch: 14 [23/250 2944/32000 (9%)] Loss: 1.97666 (semantic_loss: 0.02635, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.33459 
Train Epoch: 14 [34/250 4352/32000 (14%)] Loss: 1.97760 (semantic_loss: 0.02729, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.35584 
Train Epoch: 14 [45/250 5760/32000 (18%)] Loss: 1.97751 (semantic_loss: 0.02818, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=0.32079 
Train Epoch: 14 [56/250 7168/32000 (22%)] Loss: 1.97708 (semantic_loss: 0.02677, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.42591 
Train Epoch: 14 [67/250 8576/32000 (27%)] Loss: 1.97745 (semantic_loss: 0.02714, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=2.66888 
Train Epoch: 14 [78/250 9984/32000 (31%)] Loss: 1.97875 (semantic_loss: 0.02845, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.34778 
Train Epoch: 14 [89/250 11392/32000 (36%)] Loss: 1.97708 (semantic_loss: 0.02775, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=0.32621 
Train Epoch: 14 [100/250 12800/32000 (40%)] Loss: 1.97810 (semantic_loss: 0.02779, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.32809 
Train Epoch: 14 [111/250 14208/32000 (44%)] Loss: 1.97725 (semantic_loss: 0.02792, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=0.33166 
Train Epoch: 14 [122/250 15616/32000 (49%)] Loss: 1.97624 (semantic_loss: 0.02691, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=0.32289 
Train Epoch: 14 [133/250 17024/32000 (53%)] Loss: 1.97888 (semantic_loss: 0.02857, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.32465 
Train Epoch: 14 [144/250 18432/32000 (58%)] Loss: 1.97863 (semantic_loss: 0.02833, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.31517 
Train Epoch: 14 [155/250 19840/32000 (62%)] Loss: 1.97676 (semantic_loss: 0.02743, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=0.33963 
Train Epoch: 14 [166/250 21248/32000 (66%)] Loss: 1.97653 (semantic_loss: 0.02721, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=0.34888 
Train Epoch: 14 [177/250 22656/32000 (71%)] Loss: 1.97825 (semantic_loss: 0.02892, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=0.35533 
Train Epoch: 14 [188/250 24064/32000 (75%)] Loss: 1.97976 (semantic_loss: 0.03043, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=0.32807 
Train Epoch: 14 [199/250 25472/32000 (80%)] Loss: 1.97810 (semantic_loss: 0.02780, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.31850 
Train Epoch: 14 [210/250 26880/32000 (84%)] Loss: 1.97937 (semantic_loss: 0.02906, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.35218 
Train Epoch: 14 [221/250 28288/32000 (88%)] Loss: 1.97897 (semantic_loss: 0.02867, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=1.15031 
Train Epoch: 14 [232/250 29696/32000 (93%)] Loss: 1.97830 (semantic_loss: 0.02799, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.32439 
Train Epoch: 14 [243/250 31104/32000 (97%)] Loss: 1.97767 (semantic_loss: 0.02835, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=0.32386 
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/DCMH_LSMDC/checkpoint-epoch14.pth ...
Done in 14.080s
Updating 'best' checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/DCMH_LSMDC/checkpoint-epoch14.pth ...
Done in 18.843s
removing stale ckpt [epoch 13] [took 0.01s]
 epoch          : 14
 loss           : 1.9774825377464293
 learning_rate  : 2.566710416397524e-05
 n_samples      : 448000
 n_steps        : 3500
 LSMDC_full_test/t2v_metrics/R1: 7.9
 LSMDC_full_test/t2v_metrics/R5: 21.6
 LSMDC_full_test/t2v_metrics/R10: 32.2
 LSMDC_full_test/t2v_metrics/R50: 60.5
 LSMDC_full_test/t2v_metrics/MedR: 30.0
 LSMDC_full_test/t2v_metrics/MeanR: 83.201
 LSMDC_full_test/t2v_metrics/geometric_mean_R1-R5-R10: 17.64597141534845
 LSMDC_full_test/v2t_metrics/R1: 8.3
 LSMDC_full_test/v2t_metrics/R5: 21.2
 LSMDC_full_test/v2t_metrics/R10: 30.9
 LSMDC_full_test/v2t_metrics/R50: 61.3
 LSMDC_full_test/v2t_metrics/MedR: 29.75
 LSMDC_full_test/v2t_metrics/MeanR: 82.8445
 LSMDC_full_test/v2t_metrics/geometric_mean_R1-R5-R10: 17.5842619297005
 mnt_best       : 17.64597141534845
 not_improved_count: 0
Train Epoch: 15 [1/250 128/32000 (0%)] Loss: 1.97558 (semantic_loss: 0.02625, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=20.37625 
Train Epoch: 15 [12/250 1536/32000 (5%)] Loss: 1.97736 (semantic_loss: 0.02706, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.32046 
Train Epoch: 15 [23/250 2944/32000 (9%)] Loss: 1.97901 (semantic_loss: 0.02968, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=0.33906 
Train Epoch: 15 [34/250 4352/32000 (14%)] Loss: 1.97692 (semantic_loss: 0.02662, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.32545 
Train Epoch: 15 [45/250 5760/32000 (18%)] Loss: 1.97834 (semantic_loss: 0.02804, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.31592 
Train Epoch: 15 [56/250 7168/32000 (22%)] Loss: 1.97844 (semantic_loss: 0.02911, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=0.31955 
Train Epoch: 15 [67/250 8576/32000 (27%)] Loss: 1.97691 (semantic_loss: 0.02661, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.33160 
Train Epoch: 15 [78/250 9984/32000 (31%)] Loss: 1.97814 (semantic_loss: 0.02881, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=0.31772 
Train Epoch: 15 [89/250 11392/32000 (36%)] Loss: 1.97698 (semantic_loss: 0.02765, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=0.35795 
Train Epoch: 15 [100/250 12800/32000 (40%)] Loss: 1.97744 (semantic_loss: 0.02811, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=0.32113 
Train Epoch: 15 [111/250 14208/32000 (44%)] Loss: 1.97652 (semantic_loss: 0.02720, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=0.31822 
Train Epoch: 15 [122/250 15616/32000 (49%)] Loss: 1.97816 (semantic_loss: 0.02688, quant_loss: 1.95117, bit_balance_loss: 0.00011) batch_time=0.33307 
Train Epoch: 15 [133/250 17024/32000 (53%)] Loss: 1.97602 (semantic_loss: 0.02669, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=0.31697 
Train Epoch: 15 [144/250 18432/32000 (58%)] Loss: 1.97658 (semantic_loss: 0.02627, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=3.51689 
Train Epoch: 15 [155/250 19840/32000 (62%)] Loss: 1.97652 (semantic_loss: 0.02621, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.31422 
Train Epoch: 15 [166/250 21248/32000 (66%)] Loss: 1.97831 (semantic_loss: 0.02800, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.32827 
Train Epoch: 15 [177/250 22656/32000 (71%)] Loss: 1.97706 (semantic_loss: 0.02773, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=0.34631 
Train Epoch: 15 [188/250 24064/32000 (75%)] Loss: 1.97582 (semantic_loss: 0.02552, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.34353 
Train Epoch: 15 [199/250 25472/32000 (80%)] Loss: 1.97633 (semantic_loss: 0.02603, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.32795 
Train Epoch: 15 [210/250 26880/32000 (84%)] Loss: 1.97625 (semantic_loss: 0.02692, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=0.33194 
Train Epoch: 15 [221/250 28288/32000 (88%)] Loss: 1.97851 (semantic_loss: 0.02820, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.34437 
Train Epoch: 15 [232/250 29696/32000 (93%)] Loss: 1.97566 (semantic_loss: 0.02634, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=0.34452 
Train Epoch: 15 [243/250 31104/32000 (97%)] Loss: 1.97490 (semantic_loss: 0.02557, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=0.32919 
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/DCMH_LSMDC/checkpoint-epoch15.pth ...
Done in 5.611s
removing stale ckpt [epoch 14] [took 0.01s]
 epoch          : 15
 loss           : 1.9770954070091247
 learning_rate  : 2.4383748955776477e-05
 n_samples      : 480000
 n_steps        : 3750
 LSMDC_full_test/t2v_metrics/R1: 7.9
 LSMDC_full_test/t2v_metrics/R5: 21.4
 LSMDC_full_test/t2v_metrics/R10: 30.9
 LSMDC_full_test/t2v_metrics/R50: 62.0
 LSMDC_full_test/t2v_metrics/MedR: 27.0
 LSMDC_full_test/t2v_metrics/MeanR: 81.955
 LSMDC_full_test/t2v_metrics/geometric_mean_R1-R5-R10: 17.351343787709645
 LSMDC_full_test/v2t_metrics/R1: 7.8
 LSMDC_full_test/v2t_metrics/R5: 21.7
 LSMDC_full_test/v2t_metrics/R10: 30.1
 LSMDC_full_test/v2t_metrics/R50: 63.1
 LSMDC_full_test/v2t_metrics/MedR: 28.5
 LSMDC_full_test/v2t_metrics/MeanR: 80.8345
 LSMDC_full_test/v2t_metrics/geometric_mean_R1-R5-R10: 17.207070736308363
 mnt_best       : 17.64597141534845
 not_improved_count: 1
Train Epoch: 16 [1/250 128/32000 (0%)] Loss: 1.97833 (semantic_loss: 0.02803, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=16.36202 
Train Epoch: 16 [12/250 1536/32000 (5%)] Loss: 1.97862 (semantic_loss: 0.02929, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=0.34620 
Train Epoch: 16 [23/250 2944/32000 (9%)] Loss: 1.97836 (semantic_loss: 0.02806, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.32762 
Train Epoch: 16 [34/250 4352/32000 (14%)] Loss: 1.97707 (semantic_loss: 0.02677, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.33335 
Train Epoch: 16 [45/250 5760/32000 (18%)] Loss: 1.97585 (semantic_loss: 0.02652, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=0.36114 
Train Epoch: 16 [56/250 7168/32000 (22%)] Loss: 1.97697 (semantic_loss: 0.02667, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.34381 
Train Epoch: 16 [67/250 8576/32000 (27%)] Loss: 1.97432 (semantic_loss: 0.02499, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=0.33321 
Train Epoch: 16 [78/250 9984/32000 (31%)] Loss: 1.97746 (semantic_loss: 0.02813, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=0.34827 
Train Epoch: 16 [89/250 11392/32000 (36%)] Loss: 1.97543 (semantic_loss: 0.02610, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=0.32996 
Train Epoch: 16 [100/250 12800/32000 (40%)] Loss: 1.97717 (semantic_loss: 0.02784, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=0.35783 
Train Epoch: 16 [111/250 14208/32000 (44%)] Loss: 1.97752 (semantic_loss: 0.02623, quant_loss: 1.95117, bit_balance_loss: 0.00011) batch_time=0.35960 
Train Epoch: 16 [122/250 15616/32000 (49%)] Loss: 1.97624 (semantic_loss: 0.02692, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=0.37713 
Train Epoch: 16 [133/250 17024/32000 (53%)] Loss: 1.97531 (semantic_loss: 0.02500, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.32788 
Train Epoch: 16 [144/250 18432/32000 (58%)] Loss: 1.97563 (semantic_loss: 0.02532, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.34421 
Train Epoch: 16 [155/250 19840/32000 (62%)] Loss: 1.97995 (semantic_loss: 0.02965, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.32537 
Train Epoch: 16 [166/250 21248/32000 (66%)] Loss: 1.97656 (semantic_loss: 0.02626, quant_loss: 1.95020, bit_balance_loss: 0.00010) batch_time=0.32796 
Train Epoch: 16 [177/250 22656/32000 (71%)] Loss: 1.97817 (semantic_loss: 0.02787, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.35130 
Train Epoch: 16 [188/250 24064/32000 (75%)] Loss: 1.97646 (semantic_loss: 0.02615, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.33837 
Train Epoch: 16 [199/250 25472/32000 (80%)] Loss: 1.97623 (semantic_loss: 0.02593, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.32813 
Train Epoch: 16 [210/250 26880/32000 (84%)] Loss: 1.97616 (semantic_loss: 0.02683, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=0.32598 
Train Epoch: 16 [221/250 28288/32000 (88%)] Loss: 1.97459 (semantic_loss: 0.02429, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.32910 
Train Epoch: 16 [232/250 29696/32000 (93%)] Loss: 1.97471 (semantic_loss: 0.02441, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.32344 
Train Epoch: 16 [243/250 31104/32000 (97%)] Loss: 1.97781 (semantic_loss: 0.02848, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=0.32619 
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/DCMH_LSMDC/checkpoint-epoch16.pth ...
Done in 5.103s
Updating 'best' checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/DCMH_LSMDC/checkpoint-epoch16.pth ...
Done in 11.543s
removing stale ckpt [epoch 15] [took 0.02s]
 epoch          : 16
 loss           : 1.9765352864265442
 learning_rate  : 2.3164561507987653e-05
 n_samples      : 512000
 n_steps        : 4000
 LSMDC_full_test/t2v_metrics/R1: 8.9
 LSMDC_full_test/t2v_metrics/R5: 22.6
 LSMDC_full_test/t2v_metrics/R10: 32.6
 LSMDC_full_test/t2v_metrics/R50: 60.1
 LSMDC_full_test/t2v_metrics/MedR: 29.75
 LSMDC_full_test/t2v_metrics/MeanR: 82.7885
 LSMDC_full_test/t2v_metrics/geometric_mean_R1-R5-R10: 18.717105227261804
 LSMDC_full_test/v2t_metrics/R1: 8.4
 LSMDC_full_test/v2t_metrics/R5: 22.4
 LSMDC_full_test/v2t_metrics/R10: 32.7
 LSMDC_full_test/v2t_metrics/R50: 59.0
 LSMDC_full_test/v2t_metrics/MedR: 30.75
 LSMDC_full_test/v2t_metrics/MeanR: 83.806
 LSMDC_full_test/v2t_metrics/geometric_mean_R1-R5-R10: 18.324199821499718
 mnt_best       : 18.717105227261804
 not_improved_count: 0
Train Epoch: 17 [1/250 128/32000 (0%)] Loss: 1.97678 (semantic_loss: 0.02648, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=15.56201 
Train Epoch: 17 [12/250 1536/32000 (5%)] Loss: 1.97491 (semantic_loss: 0.02559, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=0.32226 
Train Epoch: 17 [23/250 2944/32000 (9%)] Loss: 1.97849 (semantic_loss: 0.02819, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.34786 
Train Epoch: 17 [34/250 4352/32000 (14%)] Loss: 1.97672 (semantic_loss: 0.02642, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.38105 
Train Epoch: 17 [45/250 5760/32000 (18%)] Loss: 1.97586 (semantic_loss: 0.02653, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=0.32855 
Train Epoch: 17 [56/250 7168/32000 (22%)] Loss: 1.97717 (semantic_loss: 0.02687, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.35532 
Train Epoch: 17 [67/250 8576/32000 (27%)] Loss: 1.97724 (semantic_loss: 0.02693, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=1.05198 
Train Epoch: 17 [78/250 9984/32000 (31%)] Loss: 1.97522 (semantic_loss: 0.02589, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=0.31842 
Train Epoch: 17 [89/250 11392/32000 (36%)] Loss: 1.97614 (semantic_loss: 0.02584, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.33394 
Train Epoch: 17 [100/250 12800/32000 (40%)] Loss: 1.97608 (semantic_loss: 0.02675, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=0.33202 
Train Epoch: 17 [111/250 14208/32000 (44%)] Loss: 1.97723 (semantic_loss: 0.02692, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.33715 
Train Epoch: 17 [122/250 15616/32000 (49%)] Loss: 1.97533 (semantic_loss: 0.02601, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=0.31290 
Train Epoch: 17 [133/250 17024/32000 (53%)] Loss: 1.97635 (semantic_loss: 0.02702, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=0.31513 
Train Epoch: 17 [144/250 18432/32000 (58%)] Loss: 1.97661 (semantic_loss: 0.02630, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.31428 
Train Epoch: 17 [155/250 19840/32000 (62%)] Loss: 1.97752 (semantic_loss: 0.02722, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.33443 
Train Epoch: 17 [166/250 21248/32000 (66%)] Loss: 1.97478 (semantic_loss: 0.02350, quant_loss: 1.95117, bit_balance_loss: 0.00011) batch_time=0.34132 
Train Epoch: 17 [177/250 22656/32000 (71%)] Loss: 1.97549 (semantic_loss: 0.02616, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=0.33455 
Train Epoch: 17 [188/250 24064/32000 (75%)] Loss: 1.97515 (semantic_loss: 0.02484, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.32864 
Train Epoch: 17 [199/250 25472/32000 (80%)] Loss: 1.97509 (semantic_loss: 0.02479, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.33640 
Train Epoch: 17 [210/250 26880/32000 (84%)] Loss: 1.97523 (semantic_loss: 0.02493, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.34621 
Train Epoch: 17 [221/250 28288/32000 (88%)] Loss: 1.97745 (semantic_loss: 0.02714, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.34231 
Train Epoch: 17 [232/250 29696/32000 (93%)] Loss: 1.97524 (semantic_loss: 0.02493, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.33171 
Train Epoch: 17 [243/250 31104/32000 (97%)] Loss: 1.97545 (semantic_loss: 0.02514, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.31751 
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/DCMH_LSMDC/checkpoint-epoch17.pth ...
Done in 17.741s
removing stale ckpt [epoch 16] [took 0.00s]
 epoch          : 17
 loss           : 1.9761022744178771
 learning_rate  : 2.2006333432588268e-05
 n_samples      : 544000
 n_steps        : 4250
 LSMDC_full_test/t2v_metrics/R1: 8.7
 LSMDC_full_test/t2v_metrics/R5: 22.8
 LSMDC_full_test/t2v_metrics/R10: 31.2
 LSMDC_full_test/t2v_metrics/R50: 61.1
 LSMDC_full_test/t2v_metrics/MedR: 29.0
 LSMDC_full_test/t2v_metrics/MeanR: 81.9455
 LSMDC_full_test/t2v_metrics/geometric_mean_R1-R5-R10: 18.3598684257306
 LSMDC_full_test/v2t_metrics/R1: 7.6
 LSMDC_full_test/v2t_metrics/R5: 23.2
 LSMDC_full_test/v2t_metrics/R10: 33.1
 LSMDC_full_test/v2t_metrics/R50: 59.5
 LSMDC_full_test/v2t_metrics/MedR: 29.0
 LSMDC_full_test/v2t_metrics/MeanR: 81.838
 LSMDC_full_test/v2t_metrics/geometric_mean_R1-R5-R10: 18.004311724287724
 mnt_best       : 18.717105227261804
 not_improved_count: 1
Train Epoch: 18 [1/250 128/32000 (0%)] Loss: 1.97571 (semantic_loss: 0.02638, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=15.99519 
Train Epoch: 18 [12/250 1536/32000 (5%)] Loss: 1.97836 (semantic_loss: 0.02805, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.33015 
Train Epoch: 18 [23/250 2944/32000 (9%)] Loss: 1.97748 (semantic_loss: 0.02815, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=0.32234 
Train Epoch: 18 [34/250 4352/32000 (14%)] Loss: 1.97330 (semantic_loss: 0.02398, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=0.33849 
Train Epoch: 18 [45/250 5760/32000 (18%)] Loss: 1.97588 (semantic_loss: 0.02656, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=0.32177 
Train Epoch: 18 [56/250 7168/32000 (22%)] Loss: 1.97539 (semantic_loss: 0.02509, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.32705 
Train Epoch: 18 [67/250 8576/32000 (27%)] Loss: 1.97611 (semantic_loss: 0.02580, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=1.02328 
Train Epoch: 18 [78/250 9984/32000 (31%)] Loss: 1.97486 (semantic_loss: 0.02554, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=0.32889 
Train Epoch: 18 [89/250 11392/32000 (36%)] Loss: 1.97719 (semantic_loss: 0.02787, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=0.32868 
Train Epoch: 18 [100/250 12800/32000 (40%)] Loss: 1.97358 (semantic_loss: 0.02426, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=0.34579 
Train Epoch: 18 [111/250 14208/32000 (44%)] Loss: 1.97399 (semantic_loss: 0.02369, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.31753 
Train Epoch: 18 [122/250 15616/32000 (49%)] Loss: 1.97527 (semantic_loss: 0.02594, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=0.34994 
Train Epoch: 18 [133/250 17024/32000 (53%)] Loss: 1.97669 (semantic_loss: 0.02541, quant_loss: 1.95117, bit_balance_loss: 0.00011) batch_time=0.34140 
Train Epoch: 18 [144/250 18432/32000 (58%)] Loss: 1.97684 (semantic_loss: 0.02654, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=1.61830 
Train Epoch: 18 [155/250 19840/32000 (62%)] Loss: 1.97506 (semantic_loss: 0.02475, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.34274 
Train Epoch: 18 [166/250 21248/32000 (66%)] Loss: 1.97584 (semantic_loss: 0.02652, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=0.34832 
Train Epoch: 18 [177/250 22656/32000 (71%)] Loss: 1.97672 (semantic_loss: 0.02642, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.34753 
Train Epoch: 18 [188/250 24064/32000 (75%)] Loss: 1.97728 (semantic_loss: 0.02697, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.37911 
Train Epoch: 18 [199/250 25472/32000 (80%)] Loss: 1.97709 (semantic_loss: 0.02776, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=0.33458 
Train Epoch: 18 [210/250 26880/32000 (84%)] Loss: 1.97394 (semantic_loss: 0.02461, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=0.56088 
Train Epoch: 18 [221/250 28288/32000 (88%)] Loss: 1.97707 (semantic_loss: 0.02677, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.33141 
Train Epoch: 18 [232/250 29696/32000 (93%)] Loss: 1.97463 (semantic_loss: 0.02531, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=0.45674 
Train Epoch: 18 [243/250 31104/32000 (97%)] Loss: 1.97622 (semantic_loss: 0.02591, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.31493 
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/DCMH_LSMDC/checkpoint-epoch18.pth ...
Done in 5.578s
Updating 'best' checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/DCMH_LSMDC/checkpoint-epoch18.pth ...
Done in 10.297s
removing stale ckpt [epoch 17] [took 0.01s]
 epoch          : 18
 loss           : 1.975825765609741
 learning_rate  : 2.0906016760958855e-05
 n_samples      : 576000
 n_steps        : 4500
 LSMDC_full_test/t2v_metrics/R1: 9.2
 LSMDC_full_test/t2v_metrics/R5: 24.4
 LSMDC_full_test/t2v_metrics/R10: 32.1
 LSMDC_full_test/t2v_metrics/R50: 61.7
 LSMDC_full_test/t2v_metrics/MedR: 28.0
 LSMDC_full_test/t2v_metrics/MeanR: 81.2265
 LSMDC_full_test/t2v_metrics/geometric_mean_R1-R5-R10: 19.314978483973647
 LSMDC_full_test/v2t_metrics/R1: 8.6
 LSMDC_full_test/v2t_metrics/R5: 22.5
 LSMDC_full_test/v2t_metrics/R10: 32.7
 LSMDC_full_test/v2t_metrics/R50: 60.5
 LSMDC_full_test/v2t_metrics/MedR: 28.0
 LSMDC_full_test/v2t_metrics/MeanR: 84.9115
 LSMDC_full_test/v2t_metrics/geometric_mean_R1-R5-R10: 18.49593287754064
 mnt_best       : 19.314978483973647
 not_improved_count: 0
Train Epoch: 19 [1/250 128/32000 (0%)] Loss: 1.97656 (semantic_loss: 0.02626, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=17.98389 
Train Epoch: 19 [12/250 1536/32000 (5%)] Loss: 1.97411 (semantic_loss: 0.02478, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=0.36818 
Train Epoch: 19 [23/250 2944/32000 (9%)] Loss: 1.97657 (semantic_loss: 0.02627, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=1.27866 
Train Epoch: 19 [34/250 4352/32000 (14%)] Loss: 1.97519 (semantic_loss: 0.02488, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.35017 
Train Epoch: 19 [45/250 5760/32000 (18%)] Loss: 1.97567 (semantic_loss: 0.02537, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.32774 
Train Epoch: 19 [56/250 7168/32000 (22%)] Loss: 1.97485 (semantic_loss: 0.02552, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=0.31396 
Train Epoch: 19 [67/250 8576/32000 (27%)] Loss: 1.97663 (semantic_loss: 0.02633, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=1.03434 
Train Epoch: 19 [78/250 9984/32000 (31%)] Loss: 1.97391 (semantic_loss: 0.02458, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=1.29240 
Train Epoch: 19 [89/250 11392/32000 (36%)] Loss: 1.97537 (semantic_loss: 0.02507, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.32564 
Train Epoch: 19 [100/250 12800/32000 (40%)] Loss: 1.97423 (semantic_loss: 0.02393, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.33576 
Train Epoch: 19 [111/250 14208/32000 (44%)] Loss: 1.97559 (semantic_loss: 0.02528, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.43211 
Train Epoch: 19 [122/250 15616/32000 (49%)] Loss: 1.97696 (semantic_loss: 0.02665, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.31956 
Train Epoch: 19 [133/250 17024/32000 (53%)] Loss: 1.97433 (semantic_loss: 0.02500, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=0.35584 
Train Epoch: 19 [144/250 18432/32000 (58%)] Loss: 1.97805 (semantic_loss: 0.02872, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=4.53412 
Train Epoch: 19 [155/250 19840/32000 (62%)] Loss: 1.97524 (semantic_loss: 0.02592, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=0.32581 
Train Epoch: 19 [166/250 21248/32000 (66%)] Loss: 1.97312 (semantic_loss: 0.02380, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=0.32659 
Train Epoch: 19 [177/250 22656/32000 (71%)] Loss: 1.97549 (semantic_loss: 0.02518, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.32699 
Train Epoch: 19 [188/250 24064/32000 (75%)] Loss: 1.97326 (semantic_loss: 0.02393, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=0.31277 
Train Epoch: 19 [199/250 25472/32000 (80%)] Loss: 1.97525 (semantic_loss: 0.02494, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.32305 
Train Epoch: 19 [210/250 26880/32000 (84%)] Loss: 1.97671 (semantic_loss: 0.02640, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.33725 
Train Epoch: 19 [221/250 28288/32000 (88%)] Loss: 1.97527 (semantic_loss: 0.02594, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=0.71755 
Train Epoch: 19 [232/250 29696/32000 (93%)] Loss: 1.97341 (semantic_loss: 0.02409, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=0.32082 
Train Epoch: 19 [243/250 31104/32000 (97%)] Loss: 1.97487 (semantic_loss: 0.02555, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=0.34665 
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/DCMH_LSMDC/checkpoint-epoch19.pth ...
Done in 4.703s
removing stale ckpt [epoch 18] [took 0.00s]
 epoch          : 19
 loss           : 1.975301742553711
 learning_rate  : 1.986071592291091e-05
 n_samples      : 608000
 n_steps        : 4750
 LSMDC_full_test/t2v_metrics/R1: 7.9
 LSMDC_full_test/t2v_metrics/R5: 23.2
 LSMDC_full_test/t2v_metrics/R10: 32.3
 LSMDC_full_test/t2v_metrics/R50: 60.8
 LSMDC_full_test/t2v_metrics/MedR: 28.0
 LSMDC_full_test/t2v_metrics/MeanR: 81.742
 LSMDC_full_test/t2v_metrics/geometric_mean_R1-R5-R10: 18.090026352037203
 LSMDC_full_test/v2t_metrics/R1: 7.2
 LSMDC_full_test/v2t_metrics/R5: 22.9
 LSMDC_full_test/v2t_metrics/R10: 32.4
 LSMDC_full_test/v2t_metrics/R50: 60.7
 LSMDC_full_test/v2t_metrics/MedR: 29.0
 LSMDC_full_test/v2t_metrics/MeanR: 82.6845
 LSMDC_full_test/v2t_metrics/geometric_mean_R1-R5-R10: 17.481190129595486
 mnt_best       : 19.314978483973647
 not_improved_count: 1
Train Epoch: 20 [1/250 128/32000 (0%)] Loss: 1.97662 (semantic_loss: 0.02631, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=14.16026 
Train Epoch: 20 [12/250 1536/32000 (5%)] Loss: 1.97430 (semantic_loss: 0.02497, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=0.32915 
Train Epoch: 20 [23/250 2944/32000 (9%)] Loss: 1.97522 (semantic_loss: 0.02589, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=0.34657 
Train Epoch: 20 [34/250 4352/32000 (14%)] Loss: 1.97356 (semantic_loss: 0.02424, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=0.43581 
Train Epoch: 20 [45/250 5760/32000 (18%)] Loss: 1.97510 (semantic_loss: 0.02479, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.33522 
Train Epoch: 20 [56/250 7168/32000 (22%)] Loss: 1.97512 (semantic_loss: 0.02482, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.33143 
Train Epoch: 20 [67/250 8576/32000 (27%)] Loss: 1.97498 (semantic_loss: 0.02468, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=1.89509 
Train Epoch: 20 [78/250 9984/32000 (31%)] Loss: 1.97502 (semantic_loss: 0.02472, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.34604 
Train Epoch: 20 [89/250 11392/32000 (36%)] Loss: 1.97524 (semantic_loss: 0.02494, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.32314 
Train Epoch: 20 [100/250 12800/32000 (40%)] Loss: 1.97494 (semantic_loss: 0.02561, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=0.34409 
Train Epoch: 20 [111/250 14208/32000 (44%)] Loss: 1.97489 (semantic_loss: 0.02459, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.33595 
Train Epoch: 20 [122/250 15616/32000 (49%)] Loss: 1.97665 (semantic_loss: 0.02732, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=0.31224 
Train Epoch: 20 [133/250 17024/32000 (53%)] Loss: 1.97390 (semantic_loss: 0.02458, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=0.32636 
Train Epoch: 20 [144/250 18432/32000 (58%)] Loss: 1.97493 (semantic_loss: 0.02463, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=5.24059 
Train Epoch: 20 [155/250 19840/32000 (62%)] Loss: 1.97411 (semantic_loss: 0.02381, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.32649 
Train Epoch: 20 [166/250 21248/32000 (66%)] Loss: 1.97399 (semantic_loss: 0.02466, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=0.32802 
Train Epoch: 20 [177/250 22656/32000 (71%)] Loss: 1.97650 (semantic_loss: 0.02620, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.31981 
Train Epoch: 20 [188/250 24064/32000 (75%)] Loss: 1.97582 (semantic_loss: 0.02552, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.32805 
Train Epoch: 20 [199/250 25472/32000 (80%)] Loss: 1.97579 (semantic_loss: 0.02548, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=1.40518 
Train Epoch: 20 [210/250 26880/32000 (84%)] Loss: 1.97532 (semantic_loss: 0.02502, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.54616 
Train Epoch: 20 [221/250 28288/32000 (88%)] Loss: 1.97475 (semantic_loss: 0.02542, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=0.32831 
Train Epoch: 20 [232/250 29696/32000 (93%)] Loss: 1.97526 (semantic_loss: 0.02495, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.31773 
Train Epoch: 20 [243/250 31104/32000 (97%)] Loss: 1.97681 (semantic_loss: 0.02651, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.33120 
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/DCMH_LSMDC/checkpoint-epoch20.pth ...
Done in 5.071s
Updating 'best' checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/DCMH_LSMDC/checkpoint-epoch20.pth ...
Done in 9.642s
removing stale ckpt [epoch 19] [took 0.01s]
 epoch          : 20
 loss           : 1.9751146955490113
 learning_rate  : 1.8867680126765363e-05
 n_samples      : 640000
 n_steps        : 5000
 LSMDC_full_test/t2v_metrics/R1: 9.8
 LSMDC_full_test/t2v_metrics/R5: 23.6
 LSMDC_full_test/t2v_metrics/R10: 33.9
 LSMDC_full_test/t2v_metrics/R50: 62.8
 LSMDC_full_test/t2v_metrics/MedR: 26.25
 LSMDC_full_test/t2v_metrics/MeanR: 78.722
 LSMDC_full_test/t2v_metrics/geometric_mean_R1-R5-R10: 19.866098858196718
 LSMDC_full_test/v2t_metrics/R1: 8.4
 LSMDC_full_test/v2t_metrics/R5: 23.7
 LSMDC_full_test/v2t_metrics/R10: 34.4
 LSMDC_full_test/v2t_metrics/R50: 62.4
 LSMDC_full_test/v2t_metrics/MedR: 27.5
 LSMDC_full_test/v2t_metrics/MeanR: 80.999
 LSMDC_full_test/v2t_metrics/geometric_mean_R1-R5-R10: 18.99016295956799
 mnt_best       : 19.866098858196718
 not_improved_count: 0
Train Epoch: 21 [1/250 128/32000 (0%)] Loss: 1.97505 (semantic_loss: 0.02475, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=15.88974 
Train Epoch: 21 [12/250 1536/32000 (5%)] Loss: 1.97379 (semantic_loss: 0.02446, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=0.34934 
Train Epoch: 21 [23/250 2944/32000 (9%)] Loss: 1.97555 (semantic_loss: 0.02524, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.32662 
Train Epoch: 21 [34/250 4352/32000 (14%)] Loss: 1.97514 (semantic_loss: 0.02484, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.31767 
Train Epoch: 21 [45/250 5760/32000 (18%)] Loss: 1.97450 (semantic_loss: 0.02420, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.33324 
Train Epoch: 21 [56/250 7168/32000 (22%)] Loss: 1.97669 (semantic_loss: 0.02639, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.33917 
Train Epoch: 21 [67/250 8576/32000 (27%)] Loss: 1.97350 (semantic_loss: 0.02320, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.32649 
Train Epoch: 21 [78/250 9984/32000 (31%)] Loss: 1.97520 (semantic_loss: 0.02489, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.34189 
Train Epoch: 21 [89/250 11392/32000 (36%)] Loss: 1.97416 (semantic_loss: 0.02483, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=0.32081 
Train Epoch: 21 [100/250 12800/32000 (40%)] Loss: 1.97479 (semantic_loss: 0.02449, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.36254 
Train Epoch: 21 [111/250 14208/32000 (44%)] Loss: 1.97456 (semantic_loss: 0.02523, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=0.32435 
Train Epoch: 21 [122/250 15616/32000 (49%)] Loss: 1.97616 (semantic_loss: 0.02586, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.32700 
Train Epoch: 21 [133/250 17024/32000 (53%)] Loss: 1.97408 (semantic_loss: 0.02377, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.32193 
Train Epoch: 21 [144/250 18432/32000 (58%)] Loss: 1.97466 (semantic_loss: 0.02436, quant_loss: 1.95020, bit_balance_loss: 0.00010) batch_time=0.34791 
Train Epoch: 21 [155/250 19840/32000 (62%)] Loss: 1.97432 (semantic_loss: 0.02499, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=0.35275 
Train Epoch: 21 [166/250 21248/32000 (66%)] Loss: 1.97553 (semantic_loss: 0.02523, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.36438 
Train Epoch: 21 [177/250 22656/32000 (71%)] Loss: 1.97254 (semantic_loss: 0.02321, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=0.35851 
Train Epoch: 21 [188/250 24064/32000 (75%)] Loss: 1.97271 (semantic_loss: 0.02337, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=0.35080 
Train Epoch: 21 [199/250 25472/32000 (80%)] Loss: 1.97226 (semantic_loss: 0.02293, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=0.31521 
Train Epoch: 21 [210/250 26880/32000 (84%)] Loss: 1.97398 (semantic_loss: 0.02368, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.32264 
Train Epoch: 21 [221/250 28288/32000 (88%)] Loss: 1.97556 (semantic_loss: 0.02525, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.33064 
Train Epoch: 21 [232/250 29696/32000 (93%)] Loss: 1.97478 (semantic_loss: 0.02448, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.46159 
Train Epoch: 21 [243/250 31104/32000 (97%)] Loss: 1.97277 (semantic_loss: 0.02344, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=0.32980 
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/DCMH_LSMDC/checkpoint-epoch21.pth ...
Done in 4.586s
removing stale ckpt [epoch 20] [took 0.00s]
 epoch          : 21
 loss           : 1.9746108498573303
 learning_rate  : 1.7924296120427095e-05
 n_samples      : 672000
 n_steps        : 5250
 LSMDC_full_test/t2v_metrics/R1: 8.6
 LSMDC_full_test/t2v_metrics/R5: 23.2
 LSMDC_full_test/t2v_metrics/R10: 33.7
 LSMDC_full_test/t2v_metrics/R50: 63.3
 LSMDC_full_test/t2v_metrics/MedR: 26.25
 LSMDC_full_test/t2v_metrics/MeanR: 78.0085
 LSMDC_full_test/t2v_metrics/geometric_mean_R1-R5-R10: 18.874354699222792
 LSMDC_full_test/v2t_metrics/R1: 9.1
 LSMDC_full_test/v2t_metrics/R5: 24.7
 LSMDC_full_test/v2t_metrics/R10: 33.3
 LSMDC_full_test/v2t_metrics/R50: 62.5
 LSMDC_full_test/v2t_metrics/MedR: 27.0
 LSMDC_full_test/v2t_metrics/MeanR: 81.2365
 LSMDC_full_test/v2t_metrics/geometric_mean_R1-R5-R10: 19.5611414266095
 mnt_best       : 19.866098858196718
 not_improved_count: 1
Train Epoch: 22 [1/250 128/32000 (0%)] Loss: 1.97490 (semantic_loss: 0.02557, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=13.29323 
Train Epoch: 22 [12/250 1536/32000 (5%)] Loss: 1.97472 (semantic_loss: 0.02441, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.32796 
Train Epoch: 22 [23/250 2944/32000 (9%)] Loss: 1.97435 (semantic_loss: 0.02502, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=0.34228 
Train Epoch: 22 [34/250 4352/32000 (14%)] Loss: 1.97504 (semantic_loss: 0.02376, quant_loss: 1.95117, bit_balance_loss: 0.00011) batch_time=0.36442 
Train Epoch: 22 [45/250 5760/32000 (18%)] Loss: 1.97490 (semantic_loss: 0.02460, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.34585 
Train Epoch: 22 [56/250 7168/32000 (22%)] Loss: 1.97450 (semantic_loss: 0.02517, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=0.34098 
Train Epoch: 22 [67/250 8576/32000 (27%)] Loss: 1.97688 (semantic_loss: 0.02657, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=2.55209 
Train Epoch: 22 [78/250 9984/32000 (31%)] Loss: 1.97584 (semantic_loss: 0.02553, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.32840 
Train Epoch: 22 [89/250 11392/32000 (36%)] Loss: 1.97398 (semantic_loss: 0.02368, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.31903 
Train Epoch: 22 [100/250 12800/32000 (40%)] Loss: 1.97457 (semantic_loss: 0.02524, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=0.31957 
Train Epoch: 22 [111/250 14208/32000 (44%)] Loss: 1.97690 (semantic_loss: 0.02660, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.32543 
Train Epoch: 22 [122/250 15616/32000 (49%)] Loss: 1.97386 (semantic_loss: 0.02356, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.31617 
Train Epoch: 22 [133/250 17024/32000 (53%)] Loss: 1.97648 (semantic_loss: 0.02617, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.32700 
Train Epoch: 22 [144/250 18432/32000 (58%)] Loss: 1.97368 (semantic_loss: 0.02435, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=0.32741 
Train Epoch: 22 [155/250 19840/32000 (62%)] Loss: 1.97272 (semantic_loss: 0.02340, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=0.32994 
Train Epoch: 22 [166/250 21248/32000 (66%)] Loss: 1.97373 (semantic_loss: 0.02342, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.52951 
Train Epoch: 22 [177/250 22656/32000 (71%)] Loss: 1.97647 (semantic_loss: 0.02714, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=0.34274 
Train Epoch: 22 [188/250 24064/32000 (75%)] Loss: 1.97375 (semantic_loss: 0.02442, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=0.35204 
Train Epoch: 22 [199/250 25472/32000 (80%)] Loss: 1.97526 (semantic_loss: 0.02496, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.33346 
Train Epoch: 22 [210/250 26880/32000 (84%)] Loss: 1.97348 (semantic_loss: 0.02416, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=0.51917 
Train Epoch: 22 [221/250 28288/32000 (88%)] Loss: 1.97205 (semantic_loss: 0.02273, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=2.89015 
Train Epoch: 22 [232/250 29696/32000 (93%)] Loss: 1.97246 (semantic_loss: 0.02313, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=1.91856 
Train Epoch: 22 [243/250 31104/32000 (97%)] Loss: 1.97721 (semantic_loss: 0.02690, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.55597 
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/DCMH_LSMDC/checkpoint-epoch22.pth ...
Done in 4.527s
removing stale ckpt [epoch 21] [took 0.00s]
 epoch          : 22
 loss           : 1.974446780204773
 learning_rate  : 1.702808131440574e-05
 n_samples      : 704000
 n_steps        : 5500
 LSMDC_full_test/t2v_metrics/R1: 8.7
 LSMDC_full_test/t2v_metrics/R5: 23.7
 LSMDC_full_test/t2v_metrics/R10: 35.1
 LSMDC_full_test/t2v_metrics/R50: 62.9
 LSMDC_full_test/t2v_metrics/MedR: 24.0
 LSMDC_full_test/t2v_metrics/MeanR: 77.525
 LSMDC_full_test/t2v_metrics/geometric_mean_R1-R5-R10: 19.343047799923337
 LSMDC_full_test/v2t_metrics/R1: 8.1
 LSMDC_full_test/v2t_metrics/R5: 24.8
 LSMDC_full_test/v2t_metrics/R10: 34.5
 LSMDC_full_test/v2t_metrics/R50: 63.0
 LSMDC_full_test/v2t_metrics/MedR: 27.5
 LSMDC_full_test/v2t_metrics/MeanR: 79.541
 LSMDC_full_test/v2t_metrics/geometric_mean_R1-R5-R10: 19.0656638482359
 mnt_best       : 19.866098858196718
 not_improved_count: 2
Train Epoch: 23 [1/250 128/32000 (0%)] Loss: 1.97371 (semantic_loss: 0.02439, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=30.51264 
Train Epoch: 23 [12/250 1536/32000 (5%)] Loss: 1.97272 (semantic_loss: 0.02339, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=0.32979 
Train Epoch: 23 [23/250 2944/32000 (9%)] Loss: 1.97425 (semantic_loss: 0.02492, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=0.34677 
Train Epoch: 23 [34/250 4352/32000 (14%)] Loss: 1.97355 (semantic_loss: 0.02325, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.33007 
Train Epoch: 23 [45/250 5760/32000 (18%)] Loss: 1.97374 (semantic_loss: 0.02343, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.33693 
Train Epoch: 23 [56/250 7168/32000 (22%)] Loss: 1.97156 (semantic_loss: 0.02223, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=0.32743 
Train Epoch: 23 [67/250 8576/32000 (27%)] Loss: 1.97376 (semantic_loss: 0.02346, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.32443 
Train Epoch: 23 [78/250 9984/32000 (31%)] Loss: 1.97335 (semantic_loss: 0.02304, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.32404 
Train Epoch: 23 [89/250 11392/32000 (36%)] Loss: 1.97322 (semantic_loss: 0.02389, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=0.33686 
Train Epoch: 23 [100/250 12800/32000 (40%)] Loss: 1.97400 (semantic_loss: 0.02369, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.36056 
Train Epoch: 23 [111/250 14208/32000 (44%)] Loss: 1.97382 (semantic_loss: 0.02450, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=0.35093 
Train Epoch: 23 [122/250 15616/32000 (49%)] Loss: 1.97413 (semantic_loss: 0.02480, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=0.33299 
Train Epoch: 23 [133/250 17024/32000 (53%)] Loss: 1.97765 (semantic_loss: 0.02734, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.32162 
Train Epoch: 23 [144/250 18432/32000 (58%)] Loss: 1.97317 (semantic_loss: 0.02384, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=0.35809 
Train Epoch: 23 [155/250 19840/32000 (62%)] Loss: 1.97446 (semantic_loss: 0.02415, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.33247 
Train Epoch: 23 [166/250 21248/32000 (66%)] Loss: 1.97156 (semantic_loss: 0.02223, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=0.32452 
Train Epoch: 23 [177/250 22656/32000 (71%)] Loss: 1.97269 (semantic_loss: 0.02336, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=0.35553 
Train Epoch: 23 [188/250 24064/32000 (75%)] Loss: 1.97448 (semantic_loss: 0.02418, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.35161 
Train Epoch: 23 [199/250 25472/32000 (80%)] Loss: 1.97247 (semantic_loss: 0.02314, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=0.33603 
Train Epoch: 23 [210/250 26880/32000 (84%)] Loss: 1.97220 (semantic_loss: 0.02288, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=0.32860 
Train Epoch: 23 [221/250 28288/32000 (88%)] Loss: 1.97461 (semantic_loss: 0.02430, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.32847 
Train Epoch: 23 [232/250 29696/32000 (93%)] Loss: 1.97542 (semantic_loss: 0.02511, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.32347 
Train Epoch: 23 [243/250 31104/32000 (97%)] Loss: 1.97556 (semantic_loss: 0.02525, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.33612 
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/DCMH_LSMDC/checkpoint-epoch23.pth ...
Done in 4.099s
removing stale ckpt [epoch 22] [took 0.00s]
 epoch          : 23
 loss           : 1.9741441144943237
 learning_rate  : 1.6176677248685452e-05
 n_samples      : 736000
 n_steps        : 5750
 LSMDC_full_test/t2v_metrics/R1: 9.2
 LSMDC_full_test/t2v_metrics/R5: 23.8
 LSMDC_full_test/t2v_metrics/R10: 34.5
 LSMDC_full_test/t2v_metrics/R50: 64.1
 LSMDC_full_test/t2v_metrics/MedR: 23.75
 LSMDC_full_test/t2v_metrics/MeanR: 77.7555
 LSMDC_full_test/t2v_metrics/geometric_mean_R1-R5-R10: 19.621308215994347
 LSMDC_full_test/v2t_metrics/R1: 8.3
 LSMDC_full_test/v2t_metrics/R5: 25.1
 LSMDC_full_test/v2t_metrics/R10: 35.5
 LSMDC_full_test/v2t_metrics/R50: 63.4
 LSMDC_full_test/v2t_metrics/MedR: 25.0
 LSMDC_full_test/v2t_metrics/MeanR: 79.7315
 LSMDC_full_test/v2t_metrics/geometric_mean_R1-R5-R10: 19.483189544732173
 mnt_best       : 19.866098858196718
 not_improved_count: 3
Train Epoch: 24 [1/250 128/32000 (0%)] Loss: 1.97419 (semantic_loss: 0.02389, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=18.16262 
Train Epoch: 24 [12/250 1536/32000 (5%)] Loss: 1.97406 (semantic_loss: 0.02474, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=0.32752 
Train Epoch: 24 [23/250 2944/32000 (9%)] Loss: 1.97415 (semantic_loss: 0.02385, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.33604 
Train Epoch: 24 [34/250 4352/32000 (14%)] Loss: 1.97551 (semantic_loss: 0.02423, quant_loss: 1.95117, bit_balance_loss: 0.00011) batch_time=0.32558 
Train Epoch: 24 [45/250 5760/32000 (18%)] Loss: 1.97250 (semantic_loss: 0.02317, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=0.32286 
Train Epoch: 24 [56/250 7168/32000 (22%)] Loss: 1.97265 (semantic_loss: 0.02332, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=0.31534 
Train Epoch: 24 [67/250 8576/32000 (27%)] Loss: 1.97296 (semantic_loss: 0.02266, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=1.73615 
Train Epoch: 24 [78/250 9984/32000 (31%)] Loss: 1.97552 (semantic_loss: 0.02522, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.31472 
Train Epoch: 24 [89/250 11392/32000 (36%)] Loss: 1.97418 (semantic_loss: 0.02388, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.34059 
Train Epoch: 24 [100/250 12800/32000 (40%)] Loss: 1.97367 (semantic_loss: 0.02434, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=0.33171 
Train Epoch: 24 [111/250 14208/32000 (44%)] Loss: 1.97436 (semantic_loss: 0.02406, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.31840 
Train Epoch: 24 [122/250 15616/32000 (49%)] Loss: 1.97625 (semantic_loss: 0.02595, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.31533 
Train Epoch: 24 [133/250 17024/32000 (53%)] Loss: 1.97337 (semantic_loss: 0.02404, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=0.31944 
Train Epoch: 24 [144/250 18432/32000 (58%)] Loss: 1.97466 (semantic_loss: 0.02533, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=0.31522 
Train Epoch: 24 [155/250 19840/32000 (62%)] Loss: 1.97511 (semantic_loss: 0.02480, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.33394 
Train Epoch: 24 [166/250 21248/32000 (66%)] Loss: 1.97484 (semantic_loss: 0.02453, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.33030 
Train Epoch: 24 [177/250 22656/32000 (71%)] Loss: 1.97186 (semantic_loss: 0.02253, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=0.32844 
Train Epoch: 24 [188/250 24064/32000 (75%)] Loss: 1.97353 (semantic_loss: 0.02420, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=0.31669 
Train Epoch: 24 [199/250 25472/32000 (80%)] Loss: 1.97154 (semantic_loss: 0.02222, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=3.40243 
Train Epoch: 24 [210/250 26880/32000 (84%)] Loss: 1.97371 (semantic_loss: 0.02439, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=1.70321 
Train Epoch: 24 [221/250 28288/32000 (88%)] Loss: 1.97543 (semantic_loss: 0.02513, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.33883 
Train Epoch: 24 [232/250 29696/32000 (93%)] Loss: 1.97569 (semantic_loss: 0.02539, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.32435 
Train Epoch: 24 [243/250 31104/32000 (97%)] Loss: 1.97583 (semantic_loss: 0.02455, quant_loss: 1.95117, bit_balance_loss: 0.00011) batch_time=0.32954 
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/DCMH_LSMDC/checkpoint-epoch24.pth ...
Done in 4.838s
removing stale ckpt [epoch 23] [took 0.00s]
 epoch          : 24
 loss           : 1.9738741731643676
 learning_rate  : 1.5367843386251178e-05
 n_samples      : 768000
 n_steps        : 6000
 LSMDC_full_test/t2v_metrics/R1: 7.9
 LSMDC_full_test/t2v_metrics/R5: 24.7
 LSMDC_full_test/t2v_metrics/R10: 36.1
 LSMDC_full_test/t2v_metrics/R50: 63.5
 LSMDC_full_test/t2v_metrics/MedR: 22.0
 LSMDC_full_test/t2v_metrics/MeanR: 76.8235
 LSMDC_full_test/t2v_metrics/geometric_mean_R1-R5-R10: 19.169483677528408
 LSMDC_full_test/v2t_metrics/R1: 8.1
 LSMDC_full_test/v2t_metrics/R5: 24.7
 LSMDC_full_test/v2t_metrics/R10: 35.3
 LSMDC_full_test/v2t_metrics/R50: 63.5
 LSMDC_full_test/v2t_metrics/MedR: 25.0
 LSMDC_full_test/v2t_metrics/MeanR: 79.5505
 LSMDC_full_test/v2t_metrics/geometric_mean_R1-R5-R10: 19.186049436401632
 mnt_best       : 19.866098858196718
 not_improved_count: 4
Train Epoch: 25 [1/250 128/32000 (0%)] Loss: 1.97269 (semantic_loss: 0.02337, quant_loss: 1.94922, bit_balance_loss: 0.00010) batch_time=13.23652 
Train Epoch: 25 [12/250 1536/32000 (5%)] Loss: 1.97499 (semantic_loss: 0.02566, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=0.32678 
Train Epoch: 25 [23/250 2944/32000 (9%)] Loss: 1.97520 (semantic_loss: 0.02490, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.37053 
Train Epoch: 25 [34/250 4352/32000 (14%)] Loss: 1.97308 (semantic_loss: 0.02375, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=0.33642 
Train Epoch: 25 [45/250 5760/32000 (18%)] Loss: 1.97484 (semantic_loss: 0.02454, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.36634 
Train Epoch: 25 [56/250 7168/32000 (22%)] Loss: 1.97443 (semantic_loss: 0.02413, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.33208 
Train Epoch: 25 [67/250 8576/32000 (27%)] Loss: 1.97084 (semantic_loss: 0.02152, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=0.31876 
Train Epoch: 25 [78/250 9984/32000 (31%)] Loss: 1.97367 (semantic_loss: 0.02434, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=0.52411 
Train Epoch: 25 [89/250 11392/32000 (36%)] Loss: 1.97410 (semantic_loss: 0.02477, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=0.31412 
Train Epoch: 25 [100/250 12800/32000 (40%)] Loss: 1.97218 (semantic_loss: 0.02286, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=0.34340 
Train Epoch: 25 [111/250 14208/32000 (44%)] Loss: 1.97406 (semantic_loss: 0.02376, quant_loss: 1.95020, bit_balance_loss: 0.00010) batch_time=0.32834 
Train Epoch: 25 [122/250 15616/32000 (49%)] Loss: 1.97412 (semantic_loss: 0.02381, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.31680 
Train Epoch: 25 [133/250 17024/32000 (53%)] Loss: 1.97296 (semantic_loss: 0.02266, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=2.62105 
Train Epoch: 25 [144/250 18432/32000 (58%)] Loss: 1.97352 (semantic_loss: 0.02321, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=2.30611 
Train Epoch: 25 [155/250 19840/32000 (62%)] Loss: 1.97484 (semantic_loss: 0.02454, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.31439 
Train Epoch: 25 [166/250 21248/32000 (66%)] Loss: 1.97608 (semantic_loss: 0.02675, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=0.32784 
Train Epoch: 25 [177/250 22656/32000 (71%)] Loss: 1.97649 (semantic_loss: 0.02521, quant_loss: 1.95117, bit_balance_loss: 0.00011) batch_time=0.32842 
Train Epoch: 25 [188/250 24064/32000 (75%)] Loss: 1.97454 (semantic_loss: 0.02424, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.32775 
Train Epoch: 25 [199/250 25472/32000 (80%)] Loss: 1.97233 (semantic_loss: 0.02300, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=0.32986 
Train Epoch: 25 [210/250 26880/32000 (84%)] Loss: 1.97322 (semantic_loss: 0.02390, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=0.33761 
Train Epoch: 25 [221/250 28288/32000 (88%)] Loss: 1.97139 (semantic_loss: 0.02207, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=0.32862 
Train Epoch: 25 [232/250 29696/32000 (93%)] Loss: 1.97289 (semantic_loss: 0.02357, quant_loss: 1.94922, bit_balance_loss: 0.00010) batch_time=0.32555 
Train Epoch: 25 [243/250 31104/32000 (97%)] Loss: 1.97477 (semantic_loss: 0.02544, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=0.32939 
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/DCMH_LSMDC/checkpoint-epoch25.pth ...
Done in 4.413s
removing stale ckpt [epoch 24] [took 0.04s]
 epoch          : 25
 loss           : 1.9736288962364197
 learning_rate  : 1.4599451216938618e-05
 n_samples      : 800000
 n_steps        : 6250
 LSMDC_full_test/t2v_metrics/R1: 8.4
 LSMDC_full_test/t2v_metrics/R5: 24.7
 LSMDC_full_test/t2v_metrics/R10: 33.6
 LSMDC_full_test/t2v_metrics/R50: 64.2
 LSMDC_full_test/t2v_metrics/MedR: 23.5
 LSMDC_full_test/t2v_metrics/MeanR: 79.5315
 LSMDC_full_test/t2v_metrics/geometric_mean_R1-R5-R10: 19.103158199652245
 LSMDC_full_test/v2t_metrics/R1: 9.3
 LSMDC_full_test/v2t_metrics/R5: 23.4
 LSMDC_full_test/v2t_metrics/R10: 33.7
 LSMDC_full_test/v2t_metrics/R50: 64.6
 LSMDC_full_test/v2t_metrics/MedR: 25.0
 LSMDC_full_test/v2t_metrics/MeanR: 78.8505
 LSMDC_full_test/v2t_metrics/geometric_mean_R1-R5-R10: 19.428662418217797
 mnt_best       : 19.866098858196718
 not_improved_count: 5
Train Epoch: 26 [1/250 128/32000 (0%)] Loss: 1.97272 (semantic_loss: 0.02339, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=11.91114 
Train Epoch: 26 [12/250 1536/32000 (5%)] Loss: 1.97423 (semantic_loss: 0.02393, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.35958 
Train Epoch: 26 [23/250 2944/32000 (9%)] Loss: 1.97223 (semantic_loss: 0.02192, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.32531 
Train Epoch: 26 [34/250 4352/32000 (14%)] Loss: 1.97428 (semantic_loss: 0.02397, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.32866 
Train Epoch: 26 [45/250 5760/32000 (18%)] Loss: 1.97418 (semantic_loss: 0.02485, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=0.34282 
Train Epoch: 26 [56/250 7168/32000 (22%)] Loss: 1.97371 (semantic_loss: 0.02438, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=0.31676 
Train Epoch: 26 [67/250 8576/32000 (27%)] Loss: 1.97300 (semantic_loss: 0.02269, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.33733 
Train Epoch: 26 [78/250 9984/32000 (31%)] Loss: 1.97178 (semantic_loss: 0.02246, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=0.35353 
Train Epoch: 26 [89/250 11392/32000 (36%)] Loss: 1.97364 (semantic_loss: 0.02431, quant_loss: 1.94922, bit_balance_loss: 0.00010) batch_time=0.33702 
Train Epoch: 26 [100/250 12800/32000 (40%)] Loss: 1.97331 (semantic_loss: 0.02203, quant_loss: 1.95117, bit_balance_loss: 0.00011) batch_time=0.32854 
Train Epoch: 26 [111/250 14208/32000 (44%)] Loss: 1.97344 (semantic_loss: 0.02314, quant_loss: 1.95020, bit_balance_loss: 0.00010) batch_time=0.32620 
Train Epoch: 26 [122/250 15616/32000 (49%)] Loss: 1.97214 (semantic_loss: 0.02281, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=0.33067 
Train Epoch: 26 [133/250 17024/32000 (53%)] Loss: 1.97470 (semantic_loss: 0.02440, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.33173 
Train Epoch: 26 [144/250 18432/32000 (58%)] Loss: 1.97346 (semantic_loss: 0.02414, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=2.39083 
Train Epoch: 26 [155/250 19840/32000 (62%)] Loss: 1.97300 (semantic_loss: 0.02270, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.31515 
Train Epoch: 26 [166/250 21248/32000 (66%)] Loss: 1.97399 (semantic_loss: 0.02369, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.35716 
Train Epoch: 26 [177/250 22656/32000 (71%)] Loss: 1.97245 (semantic_loss: 0.02313, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=0.33278 
Train Epoch: 26 [188/250 24064/32000 (75%)] Loss: 1.97020 (semantic_loss: 0.02088, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=0.31841 
Train Epoch: 26 [199/250 25472/32000 (80%)] Loss: 1.97161 (semantic_loss: 0.02229, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=0.32514 
Train Epoch: 26 [210/250 26880/32000 (84%)] Loss: 1.97334 (semantic_loss: 0.02304, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.32451 
Train Epoch: 26 [221/250 28288/32000 (88%)] Loss: 1.97131 (semantic_loss: 0.02198, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=0.31829 
Train Epoch: 26 [232/250 29696/32000 (93%)] Loss: 1.97276 (semantic_loss: 0.02343, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=0.33203 
Train Epoch: 26 [243/250 31104/32000 (97%)] Loss: 1.97503 (semantic_loss: 0.02473, quant_loss: 1.95020, bit_balance_loss: 0.00010) batch_time=0.33773 
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/DCMH_LSMDC/checkpoint-epoch26.pth ...
Done in 4.675s
Updating 'best' checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/DCMH_LSMDC/checkpoint-epoch26.pth ...
Done in 9.582s
removing stale ckpt [epoch 25] [took 0.00s]
 epoch          : 26
 loss           : 1.9732945055961608
 learning_rate  : 1.3869478656091687e-05
 n_samples      : 832000
 n_steps        : 6500
 LSMDC_full_test/t2v_metrics/R1: 8.9
 LSMDC_full_test/t2v_metrics/R5: 24.6
 LSMDC_full_test/t2v_metrics/R10: 36.1
 LSMDC_full_test/t2v_metrics/R50: 64.0
 LSMDC_full_test/t2v_metrics/MedR: 23.0
 LSMDC_full_test/t2v_metrics/MeanR: 78.0135
 LSMDC_full_test/t2v_metrics/geometric_mean_R1-R5-R10: 19.919454389017016
 LSMDC_full_test/v2t_metrics/R1: 8.4
 LSMDC_full_test/v2t_metrics/R5: 25.4
 LSMDC_full_test/v2t_metrics/R10: 35.0
 LSMDC_full_test/v2t_metrics/R50: 64.3
 LSMDC_full_test/v2t_metrics/MedR: 24.0
 LSMDC_full_test/v2t_metrics/MeanR: 78.66
 LSMDC_full_test/v2t_metrics/geometric_mean_R1-R5-R10: 19.546110471784313
 mnt_best       : 19.919454389017016
 not_improved_count: 0
Train Epoch: 27 [1/250 128/32000 (0%)] Loss: 1.97419 (semantic_loss: 0.02486, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=13.44806 
Train Epoch: 27 [12/250 1536/32000 (5%)] Loss: 1.97178 (semantic_loss: 0.02245, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=0.33975 
Train Epoch: 27 [23/250 2944/32000 (9%)] Loss: 1.97480 (semantic_loss: 0.02450, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.33285 
Train Epoch: 27 [34/250 4352/32000 (14%)] Loss: 1.97308 (semantic_loss: 0.02278, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.34855 
Train Epoch: 27 [45/250 5760/32000 (18%)] Loss: 1.97281 (semantic_loss: 0.02348, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=0.34260 
Train Epoch: 27 [56/250 7168/32000 (22%)] Loss: 1.97461 (semantic_loss: 0.02430, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.33446 
Train Epoch: 27 [67/250 8576/32000 (27%)] Loss: 1.97503 (semantic_loss: 0.02472, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=1.81478 
Train Epoch: 27 [78/250 9984/32000 (31%)] Loss: 1.97416 (semantic_loss: 0.02386, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.32828 
Train Epoch: 27 [89/250 11392/32000 (36%)] Loss: 1.97233 (semantic_loss: 0.02300, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=0.34313 
Train Epoch: 27 [100/250 12800/32000 (40%)] Loss: 1.97411 (semantic_loss: 0.02381, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.32883 
Train Epoch: 27 [111/250 14208/32000 (44%)] Loss: 1.97338 (semantic_loss: 0.02308, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.55111 
Train Epoch: 27 [122/250 15616/32000 (49%)] Loss: 1.97382 (semantic_loss: 0.02352, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.32976 
Train Epoch: 27 [133/250 17024/32000 (53%)] Loss: 1.97176 (semantic_loss: 0.02244, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=0.32450 
Train Epoch: 27 [144/250 18432/32000 (58%)] Loss: 1.97102 (semantic_loss: 0.02170, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=0.47909 
Train Epoch: 27 [155/250 19840/32000 (62%)] Loss: 1.97388 (semantic_loss: 0.02358, quant_loss: 1.95020, bit_balance_loss: 0.00010) batch_time=0.35886 
Train Epoch: 27 [166/250 21248/32000 (66%)] Loss: 1.97209 (semantic_loss: 0.02277, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=0.37529 
Train Epoch: 27 [177/250 22656/32000 (71%)] Loss: 1.97257 (semantic_loss: 0.02227, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.43936 
Train Epoch: 27 [188/250 24064/32000 (75%)] Loss: 1.97301 (semantic_loss: 0.02271, quant_loss: 1.95020, bit_balance_loss: 0.00010) batch_time=0.32900 
Train Epoch: 27 [199/250 25472/32000 (80%)] Loss: 1.97469 (semantic_loss: 0.02439, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.31348 
Train Epoch: 27 [210/250 26880/32000 (84%)] Loss: 1.97351 (semantic_loss: 0.02321, quant_loss: 1.95020, bit_balance_loss: 0.00010) batch_time=0.86618 
Train Epoch: 27 [221/250 28288/32000 (88%)] Loss: 1.97220 (semantic_loss: 0.02190, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.32710 
Train Epoch: 27 [232/250 29696/32000 (93%)] Loss: 1.97293 (semantic_loss: 0.02360, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=0.33001 
Train Epoch: 27 [243/250 31104/32000 (97%)] Loss: 1.97492 (semantic_loss: 0.02461, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.38027 
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/DCMH_LSMDC/checkpoint-epoch27.pth ...
Done in 4.558s
removing stale ckpt [epoch 26] [took 0.00s]
 epoch          : 27
 loss           : 1.9730830993652344
 learning_rate  : 1.3176004723287102e-05
 n_samples      : 864000
 n_steps        : 6750
 LSMDC_full_test/t2v_metrics/R1: 8.2
 LSMDC_full_test/t2v_metrics/R5: 23.5
 LSMDC_full_test/t2v_metrics/R10: 35.1
 LSMDC_full_test/t2v_metrics/R50: 64.1
 LSMDC_full_test/t2v_metrics/MedR: 24.0
 LSMDC_full_test/t2v_metrics/MeanR: 76.6425
 LSMDC_full_test/t2v_metrics/geometric_mean_R1-R5-R10: 18.91165821421017
 LSMDC_full_test/v2t_metrics/R1: 8.4
 LSMDC_full_test/v2t_metrics/R5: 25.7
 LSMDC_full_test/v2t_metrics/R10: 35.6
 LSMDC_full_test/v2t_metrics/R50: 64.6
 LSMDC_full_test/v2t_metrics/MedR: 24.75
 LSMDC_full_test/v2t_metrics/MeanR: 78.753
 LSMDC_full_test/v2t_metrics/geometric_mean_R1-R5-R10: 19.734258032311384
 mnt_best       : 19.919454389017016
 not_improved_count: 1
Train Epoch: 28 [1/250 128/32000 (0%)] Loss: 1.97307 (semantic_loss: 0.02277, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=15.34008 
Train Epoch: 28 [12/250 1536/32000 (5%)] Loss: 1.97288 (semantic_loss: 0.02355, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=0.32611 
Train Epoch: 28 [23/250 2944/32000 (9%)] Loss: 1.97122 (semantic_loss: 0.02190, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=0.32679 
Train Epoch: 28 [34/250 4352/32000 (14%)] Loss: 1.97367 (semantic_loss: 0.02434, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=0.32662 
Train Epoch: 28 [45/250 5760/32000 (18%)] Loss: 1.97474 (semantic_loss: 0.02443, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.33804 
Train Epoch: 28 [56/250 7168/32000 (22%)] Loss: 1.97283 (semantic_loss: 0.02252, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.35967 
Train Epoch: 28 [67/250 8576/32000 (27%)] Loss: 1.97186 (semantic_loss: 0.02254, quant_loss: 1.94922, bit_balance_loss: 0.00010) batch_time=0.66890 
Train Epoch: 28 [78/250 9984/32000 (31%)] Loss: 1.97491 (semantic_loss: 0.02460, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.32870 
Train Epoch: 28 [89/250 11392/32000 (36%)] Loss: 1.97226 (semantic_loss: 0.02294, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=0.34155 
Train Epoch: 28 [100/250 12800/32000 (40%)] Loss: 1.97190 (semantic_loss: 0.02257, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=0.33068 
Train Epoch: 28 [111/250 14208/32000 (44%)] Loss: 1.97152 (semantic_loss: 0.02220, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=0.35823 
Train Epoch: 28 [122/250 15616/32000 (49%)] Loss: 1.97373 (semantic_loss: 0.02343, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.34230 
Train Epoch: 28 [133/250 17024/32000 (53%)] Loss: 1.97233 (semantic_loss: 0.02300, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=0.33131 
Train Epoch: 28 [144/250 18432/32000 (58%)] Loss: 1.97286 (semantic_loss: 0.02353, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=1.68325 
Train Epoch: 28 [155/250 19840/32000 (62%)] Loss: 1.97254 (semantic_loss: 0.02321, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=0.32221 
Train Epoch: 28 [166/250 21248/32000 (66%)] Loss: 1.97350 (semantic_loss: 0.02320, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.32845 
Train Epoch: 28 [177/250 22656/32000 (71%)] Loss: 1.97487 (semantic_loss: 0.02555, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=0.36581 
Train Epoch: 28 [188/250 24064/32000 (75%)] Loss: 1.97395 (semantic_loss: 0.02463, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=0.33353 
Train Epoch: 28 [199/250 25472/32000 (80%)] Loss: 1.97274 (semantic_loss: 0.02342, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=0.81277 
Train Epoch: 28 [210/250 26880/32000 (84%)] Loss: 1.97367 (semantic_loss: 0.02336, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.34527 
Train Epoch: 28 [221/250 28288/32000 (88%)] Loss: 1.97214 (semantic_loss: 0.02281, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=1.76503 
Train Epoch: 28 [232/250 29696/32000 (93%)] Loss: 1.97248 (semantic_loss: 0.02316, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=0.34922 
Train Epoch: 28 [243/250 31104/32000 (97%)] Loss: 1.97286 (semantic_loss: 0.02256, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.32836 
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/DCMH_LSMDC/checkpoint-epoch28.pth ...
Done in 14.771s
removing stale ckpt [epoch 27] [took 0.03s]
 epoch          : 28
 loss           : 1.9729018392562867
 learning_rate  : 1.2517204487122746e-05
 n_samples      : 896000
 n_steps        : 7000
 LSMDC_full_test/t2v_metrics/R1: 8.6
 LSMDC_full_test/t2v_metrics/R5: 24.8
 LSMDC_full_test/t2v_metrics/R10: 35.9
 LSMDC_full_test/t2v_metrics/R50: 63.7
 LSMDC_full_test/t2v_metrics/MedR: 24.0
 LSMDC_full_test/t2v_metrics/MeanR: 75.5615
 LSMDC_full_test/t2v_metrics/geometric_mean_R1-R5-R10: 19.709768661347628
 LSMDC_full_test/v2t_metrics/R1: 8.8
 LSMDC_full_test/v2t_metrics/R5: 25.7
 LSMDC_full_test/v2t_metrics/R10: 35.0
 LSMDC_full_test/v2t_metrics/R50: 64.2
 LSMDC_full_test/v2t_metrics/MedR: 25.0
 LSMDC_full_test/v2t_metrics/MeanR: 77.9055
 LSMDC_full_test/v2t_metrics/geometric_mean_R1-R5-R10: 19.92941786782145
 mnt_best       : 19.919454389017016
 not_improved_count: 2
Train Epoch: 29 [1/250 128/32000 (0%)] Loss: 1.97398 (semantic_loss: 0.02368, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=14.07403 
Train Epoch: 29 [12/250 1536/32000 (5%)] Loss: 1.97392 (semantic_loss: 0.02361, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.31634 
Train Epoch: 29 [23/250 2944/32000 (9%)] Loss: 1.97302 (semantic_loss: 0.02272, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.33582 
Train Epoch: 29 [34/250 4352/32000 (14%)] Loss: 1.97391 (semantic_loss: 0.02360, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.33605 
Train Epoch: 29 [45/250 5760/32000 (18%)] Loss: 1.97528 (semantic_loss: 0.02498, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.33230 
Train Epoch: 29 [56/250 7168/32000 (22%)] Loss: 1.97234 (semantic_loss: 0.02301, quant_loss: 1.94922, bit_balance_loss: 0.00010) batch_time=0.32631 
Train Epoch: 29 [67/250 8576/32000 (27%)] Loss: 1.97310 (semantic_loss: 0.02280, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=1.52123 
Train Epoch: 29 [78/250 9984/32000 (31%)] Loss: 1.97327 (semantic_loss: 0.02394, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=0.33303 
Train Epoch: 29 [89/250 11392/32000 (36%)] Loss: 1.97138 (semantic_loss: 0.02205, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=0.32698 
Train Epoch: 29 [100/250 12800/32000 (40%)] Loss: 1.97206 (semantic_loss: 0.02176, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.35013 
Train Epoch: 29 [111/250 14208/32000 (44%)] Loss: 1.97528 (semantic_loss: 0.02497, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.34737 
Train Epoch: 29 [122/250 15616/32000 (49%)] Loss: 1.97405 (semantic_loss: 0.02473, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=0.33095 
Train Epoch: 29 [133/250 17024/32000 (53%)] Loss: 1.97161 (semantic_loss: 0.02228, quant_loss: 1.94922, bit_balance_loss: 0.00010) batch_time=0.31938 
Train Epoch: 29 [144/250 18432/32000 (58%)] Loss: 1.97219 (semantic_loss: 0.02189, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.76661 
Train Epoch: 29 [155/250 19840/32000 (62%)] Loss: 1.97348 (semantic_loss: 0.02318, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.32449 
Train Epoch: 29 [166/250 21248/32000 (66%)] Loss: 1.97202 (semantic_loss: 0.02172, quant_loss: 1.95020, bit_balance_loss: 0.00010) batch_time=0.33303 
Train Epoch: 29 [177/250 22656/32000 (71%)] Loss: 1.97403 (semantic_loss: 0.02372, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.33686 
Train Epoch: 29 [188/250 24064/32000 (75%)] Loss: 1.97159 (semantic_loss: 0.02226, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=0.32291 
Train Epoch: 29 [199/250 25472/32000 (80%)] Loss: 1.97467 (semantic_loss: 0.02437, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.33003 
Train Epoch: 29 [210/250 26880/32000 (84%)] Loss: 1.97360 (semantic_loss: 0.02427, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=0.32094 
Train Epoch: 29 [221/250 28288/32000 (88%)] Loss: 1.97082 (semantic_loss: 0.02149, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=0.31550 
Train Epoch: 29 [232/250 29696/32000 (93%)] Loss: 1.97336 (semantic_loss: 0.02306, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.31333 
Train Epoch: 29 [243/250 31104/32000 (97%)] Loss: 1.97274 (semantic_loss: 0.02342, quant_loss: 1.94922, bit_balance_loss: 0.00010) batch_time=0.37026 
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/DCMH_LSMDC/checkpoint-epoch29.pth ...
Done in 13.920s
Updating 'best' checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/DCMH_LSMDC/checkpoint-epoch29.pth ...
Done in 18.497s
removing stale ckpt [epoch 28] [took 0.00s]
 epoch          : 29
 loss           : 1.9727437090873718
 learning_rate  : 1.1891344262766608e-05
 n_samples      : 928000
 n_steps        : 7250
 LSMDC_full_test/t2v_metrics/R1: 9.2
 LSMDC_full_test/t2v_metrics/R5: 25.5
 LSMDC_full_test/t2v_metrics/R10: 36.9
 LSMDC_full_test/t2v_metrics/R50: 64.0
 LSMDC_full_test/t2v_metrics/MedR: 24.5
 LSMDC_full_test/t2v_metrics/MeanR: 75.4945
 LSMDC_full_test/t2v_metrics/geometric_mean_R1-R5-R10: 20.532955124121944
 LSMDC_full_test/v2t_metrics/R1: 9.0
 LSMDC_full_test/v2t_metrics/R5: 26.1
 LSMDC_full_test/v2t_metrics/R10: 35.4
 LSMDC_full_test/v2t_metrics/R50: 64.5
 LSMDC_full_test/v2t_metrics/MedR: 25.0
 LSMDC_full_test/v2t_metrics/MeanR: 77.9505
 LSMDC_full_test/v2t_metrics/geometric_mean_R1-R5-R10: 20.259501713743955
 mnt_best       : 20.532955124121944
 not_improved_count: 0
Train Epoch: 30 [1/250 128/32000 (0%)] Loss: 1.97362 (semantic_loss: 0.02332, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=17.62286 
Train Epoch: 30 [12/250 1536/32000 (5%)] Loss: 1.97153 (semantic_loss: 0.02220, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=0.32687 
Train Epoch: 30 [23/250 2944/32000 (9%)] Loss: 1.97172 (semantic_loss: 0.02239, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=0.35691 
Train Epoch: 30 [34/250 4352/32000 (14%)] Loss: 1.97167 (semantic_loss: 0.02137, quant_loss: 1.95020, bit_balance_loss: 0.00010) batch_time=0.33079 
Train Epoch: 30 [45/250 5760/32000 (18%)] Loss: 1.97162 (semantic_loss: 0.02132, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.33704 
Train Epoch: 30 [56/250 7168/32000 (22%)] Loss: 1.97130 (semantic_loss: 0.02100, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.31948 
Train Epoch: 30 [67/250 8576/32000 (27%)] Loss: 1.97231 (semantic_loss: 0.02201, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=2.97725 
Train Epoch: 30 [78/250 9984/32000 (31%)] Loss: 1.97237 (semantic_loss: 0.02207, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=1.21949 
Train Epoch: 30 [89/250 11392/32000 (36%)] Loss: 1.97253 (semantic_loss: 0.02321, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=0.32340 
Train Epoch: 30 [100/250 12800/32000 (40%)] Loss: 1.97175 (semantic_loss: 0.02242, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=0.35025 
Train Epoch: 30 [111/250 14208/32000 (44%)] Loss: 1.97217 (semantic_loss: 0.02186, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.33741 
Train Epoch: 30 [122/250 15616/32000 (49%)] Loss: 1.97273 (semantic_loss: 0.02243, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.34404 
Train Epoch: 30 [133/250 17024/32000 (53%)] Loss: 1.97267 (semantic_loss: 0.02236, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.31897 
Train Epoch: 30 [144/250 18432/32000 (58%)] Loss: 1.97344 (semantic_loss: 0.02314, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.34197 
Train Epoch: 30 [155/250 19840/32000 (62%)] Loss: 1.97275 (semantic_loss: 0.02245, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.34119 
Train Epoch: 30 [166/250 21248/32000 (66%)] Loss: 1.97262 (semantic_loss: 0.02232, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.32846 
Train Epoch: 30 [177/250 22656/32000 (71%)] Loss: 1.97152 (semantic_loss: 0.02219, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=0.34033 
Train Epoch: 30 [188/250 24064/32000 (75%)] Loss: 1.97267 (semantic_loss: 0.02335, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=0.44592 
Train Epoch: 30 [199/250 25472/32000 (80%)] Loss: 1.96942 (semantic_loss: 0.02010, quant_loss: 1.94922, bit_balance_loss: 0.00010) batch_time=0.32717 
Train Epoch: 30 [210/250 26880/32000 (84%)] Loss: 1.97225 (semantic_loss: 0.02195, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.36019 
Train Epoch: 30 [221/250 28288/32000 (88%)] Loss: 1.97137 (semantic_loss: 0.02107, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.34633 
Train Epoch: 30 [232/250 29696/32000 (93%)] Loss: 1.97325 (semantic_loss: 0.02294, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.31865 
Train Epoch: 30 [243/250 31104/32000 (97%)] Loss: 1.97224 (semantic_loss: 0.02194, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.32745 
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/DCMH_LSMDC/checkpoint-epoch30.pth ...
Done in 3.882s
Updating 'best' checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/DCMH_LSMDC/checkpoint-epoch30.pth ...
Done in 7.839s
removing stale ckpt [epoch 29] [took 0.00s]
 epoch          : 30
 loss           : 1.9724928216934203
 learning_rate  : 1.1296777049628277e-05
 n_samples      : 960000
 n_steps        : 7500
 LSMDC_full_test/t2v_metrics/R1: 9.5
 LSMDC_full_test/t2v_metrics/R5: 25.5
 LSMDC_full_test/t2v_metrics/R10: 36.0
 LSMDC_full_test/t2v_metrics/R50: 64.0
 LSMDC_full_test/t2v_metrics/MedR: 23.0
 LSMDC_full_test/t2v_metrics/MeanR: 76.8585
 LSMDC_full_test/t2v_metrics/geometric_mean_R1-R5-R10: 20.583636107522466
 LSMDC_full_test/v2t_metrics/R1: 8.0
 LSMDC_full_test/v2t_metrics/R5: 26.7
 LSMDC_full_test/v2t_metrics/R10: 34.4
 LSMDC_full_test/v2t_metrics/R50: 63.1
 LSMDC_full_test/v2t_metrics/MedR: 24.75
 LSMDC_full_test/v2t_metrics/MeanR: 77.92
 LSMDC_full_test/v2t_metrics/geometric_mean_R1-R5-R10: 19.44105804669969
 mnt_best       : 20.583636107522466
 not_improved_count: 0
Train Epoch: 31 [1/250 128/32000 (0%)] Loss: 1.97210 (semantic_loss: 0.02277, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=29.24518 
Train Epoch: 31 [12/250 1536/32000 (5%)] Loss: 1.97035 (semantic_loss: 0.02103, quant_loss: 1.94922, bit_balance_loss: 0.00010) batch_time=0.32647 
Train Epoch: 31 [23/250 2944/32000 (9%)] Loss: 1.97211 (semantic_loss: 0.02181, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.31633 
Train Epoch: 31 [34/250 4352/32000 (14%)] Loss: 1.97364 (semantic_loss: 0.02334, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.31686 
Train Epoch: 31 [45/250 5760/32000 (18%)] Loss: 1.97056 (semantic_loss: 0.02123, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=0.33225 
Train Epoch: 31 [56/250 7168/32000 (22%)] Loss: 1.97308 (semantic_loss: 0.02278, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.32297 
Train Epoch: 31 [67/250 8576/32000 (27%)] Loss: 1.97101 (semantic_loss: 0.02071, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.32533 
Train Epoch: 31 [78/250 9984/32000 (31%)] Loss: 1.97176 (semantic_loss: 0.02244, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=0.31684 
Train Epoch: 31 [89/250 11392/32000 (36%)] Loss: 1.97207 (semantic_loss: 0.02177, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.31566 
Train Epoch: 31 [100/250 12800/32000 (40%)] Loss: 1.97106 (semantic_loss: 0.02174, quant_loss: 1.94922, bit_balance_loss: 0.00010) batch_time=0.31987 
Train Epoch: 31 [111/250 14208/32000 (44%)] Loss: 1.97170 (semantic_loss: 0.02140, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=1.21501 
Train Epoch: 31 [122/250 15616/32000 (49%)] Loss: 1.97149 (semantic_loss: 0.02217, quant_loss: 1.94922, bit_balance_loss: 0.00010) batch_time=0.35817 
Train Epoch: 31 [133/250 17024/32000 (53%)] Loss: 1.97086 (semantic_loss: 0.02056, quant_loss: 1.95020, bit_balance_loss: 0.00010) batch_time=0.32228 
Train Epoch: 31 [144/250 18432/32000 (58%)] Loss: 1.97091 (semantic_loss: 0.02158, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=0.31500 
Train Epoch: 31 [155/250 19840/32000 (62%)] Loss: 1.97124 (semantic_loss: 0.02191, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=0.31761 
Train Epoch: 31 [166/250 21248/32000 (66%)] Loss: 1.97249 (semantic_loss: 0.02316, quant_loss: 1.94922, bit_balance_loss: 0.00010) batch_time=0.32743 
Train Epoch: 31 [177/250 22656/32000 (71%)] Loss: 1.97151 (semantic_loss: 0.02219, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=0.32490 
Train Epoch: 31 [188/250 24064/32000 (75%)] Loss: 1.97236 (semantic_loss: 0.02206, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.34240 
Train Epoch: 31 [199/250 25472/32000 (80%)] Loss: 1.97074 (semantic_loss: 0.02142, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=0.31434 
Train Epoch: 31 [210/250 26880/32000 (84%)] Loss: 1.97111 (semantic_loss: 0.02179, quant_loss: 1.94922, bit_balance_loss: 0.00010) batch_time=0.34291 
Train Epoch: 31 [221/250 28288/32000 (88%)] Loss: 1.97217 (semantic_loss: 0.02284, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=0.33788 
Train Epoch: 31 [232/250 29696/32000 (93%)] Loss: 1.97380 (semantic_loss: 0.02350, quant_loss: 1.95020, bit_balance_loss: 0.00010) batch_time=0.34721 
Train Epoch: 31 [243/250 31104/32000 (97%)] Loss: 1.97156 (semantic_loss: 0.02223, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=0.33214 
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/DCMH_LSMDC/checkpoint-epoch31.pth ...
Done in 4.580s
Updating 'best' checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/DCMH_LSMDC/checkpoint-epoch31.pth ...
Done in 9.181s
removing stale ckpt [epoch 30] [took 0.00s]
 epoch          : 31
 loss           : 1.9722078952789306
 learning_rate  : 1.0731938197146863e-05
 n_samples      : 992000
 n_steps        : 7750
 LSMDC_full_test/t2v_metrics/R1: 9.6
 LSMDC_full_test/t2v_metrics/R5: 25.9
 LSMDC_full_test/t2v_metrics/R10: 36.8
 LSMDC_full_test/t2v_metrics/R50: 66.1
 LSMDC_full_test/t2v_metrics/MedR: 21.0
 LSMDC_full_test/t2v_metrics/MeanR: 73.9585
 LSMDC_full_test/t2v_metrics/geometric_mean_R1-R5-R10: 20.915725746859103
 LSMDC_full_test/v2t_metrics/R1: 8.2
 LSMDC_full_test/v2t_metrics/R5: 26.3
 LSMDC_full_test/v2t_metrics/R10: 35.5
 LSMDC_full_test/v2t_metrics/R50: 66.1
 LSMDC_full_test/v2t_metrics/MedR: 22.0
 LSMDC_full_test/v2t_metrics/MeanR: 75.648
 LSMDC_full_test/v2t_metrics/geometric_mean_R1-R5-R10: 19.709063313978024
 mnt_best       : 20.915725746859103
 not_improved_count: 0
Train Epoch: 32 [1/250 128/32000 (0%)] Loss: 1.97110 (semantic_loss: 0.02080, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=14.76559 
Train Epoch: 32 [12/250 1536/32000 (5%)] Loss: 1.97259 (semantic_loss: 0.02327, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=0.36303 
Train Epoch: 32 [23/250 2944/32000 (9%)] Loss: 1.97295 (semantic_loss: 0.02265, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.31936 
Train Epoch: 32 [34/250 4352/32000 (14%)] Loss: 1.97114 (semantic_loss: 0.02182, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=0.32766 
Train Epoch: 32 [45/250 5760/32000 (18%)] Loss: 1.96916 (semantic_loss: 0.01984, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=0.31580 
Train Epoch: 32 [56/250 7168/32000 (22%)] Loss: 1.97178 (semantic_loss: 0.02246, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=0.34378 
Train Epoch: 32 [67/250 8576/32000 (27%)] Loss: 1.97066 (semantic_loss: 0.02036, quant_loss: 1.95020, bit_balance_loss: 0.00010) batch_time=0.66440 
Train Epoch: 32 [78/250 9984/32000 (31%)] Loss: 1.97228 (semantic_loss: 0.02197, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.34507 
Train Epoch: 32 [89/250 11392/32000 (36%)] Loss: 1.97043 (semantic_loss: 0.02110, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=0.33327 
Train Epoch: 32 [100/250 12800/32000 (40%)] Loss: 1.97067 (semantic_loss: 0.02135, quant_loss: 1.94922, bit_balance_loss: 0.00010) batch_time=0.99646 
Train Epoch: 32 [111/250 14208/32000 (44%)] Loss: 1.97277 (semantic_loss: 0.02247, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.33180 
Train Epoch: 32 [122/250 15616/32000 (49%)] Loss: 1.97042 (semantic_loss: 0.02012, quant_loss: 1.95020, bit_balance_loss: 0.00010) batch_time=0.33137 
Train Epoch: 32 [133/250 17024/32000 (53%)] Loss: 1.97202 (semantic_loss: 0.02172, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.80597 
Train Epoch: 32 [144/250 18432/32000 (58%)] Loss: 1.97150 (semantic_loss: 0.02217, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=0.32353 
Train Epoch: 32 [155/250 19840/32000 (62%)] Loss: 1.97491 (semantic_loss: 0.02461, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.32797 
Train Epoch: 32 [166/250 21248/32000 (66%)] Loss: 1.97235 (semantic_loss: 0.02205, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.33306 
Train Epoch: 32 [177/250 22656/32000 (71%)] Loss: 1.97211 (semantic_loss: 0.02181, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.33195 
Train Epoch: 32 [188/250 24064/32000 (75%)] Loss: 1.97275 (semantic_loss: 0.02245, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.33861 
Train Epoch: 32 [199/250 25472/32000 (80%)] Loss: 1.97280 (semantic_loss: 0.02347, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=0.32542 
Train Epoch: 32 [210/250 26880/32000 (84%)] Loss: 1.97380 (semantic_loss: 0.02349, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.35176 
Train Epoch: 32 [221/250 28288/32000 (88%)] Loss: 1.97104 (semantic_loss: 0.02073, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.34046 
Train Epoch: 32 [232/250 29696/32000 (93%)] Loss: 1.97001 (semantic_loss: 0.02068, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=0.33078 
Train Epoch: 32 [243/250 31104/32000 (97%)] Loss: 1.97075 (semantic_loss: 0.02142, quant_loss: 1.94922, bit_balance_loss: 0.00010) batch_time=0.33160 
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/DCMH_LSMDC/checkpoint-epoch32.pth ...
Done in 5.330s
removing stale ckpt [epoch 31] [took 0.00s]
 epoch          : 32
 loss           : 1.9721308832168578
 learning_rate  : 1.019534128728952e-05
 n_samples      : 1024000
 n_steps        : 8000
 LSMDC_full_test/t2v_metrics/R1: 8.5
 LSMDC_full_test/t2v_metrics/R5: 24.3
 LSMDC_full_test/t2v_metrics/R10: 36.1
 LSMDC_full_test/t2v_metrics/R50: 65.0
 LSMDC_full_test/t2v_metrics/MedR: 22.0
 LSMDC_full_test/t2v_metrics/MeanR: 78.036
 LSMDC_full_test/t2v_metrics/geometric_mean_R1-R5-R10: 19.536381783253038
 LSMDC_full_test/v2t_metrics/R1: 8.6
 LSMDC_full_test/v2t_metrics/R5: 23.6
 LSMDC_full_test/v2t_metrics/R10: 34.9
 LSMDC_full_test/v2t_metrics/R50: 65.1
 LSMDC_full_test/v2t_metrics/MedR: 23.5
 LSMDC_full_test/v2t_metrics/MeanR: 78.8155
 LSMDC_full_test/v2t_metrics/geometric_mean_R1-R5-R10: 19.204896031490417
 mnt_best       : 20.915725746859103
 not_improved_count: 1
Train Epoch: 33 [1/250 128/32000 (0%)] Loss: 1.97315 (semantic_loss: 0.02285, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=15.47024 
Train Epoch: 33 [12/250 1536/32000 (5%)] Loss: 1.97289 (semantic_loss: 0.02259, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.33094 
Train Epoch: 33 [23/250 2944/32000 (9%)] Loss: 1.97120 (semantic_loss: 0.02187, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=0.36080 
Train Epoch: 33 [34/250 4352/32000 (14%)] Loss: 1.97265 (semantic_loss: 0.02235, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.32904 
Train Epoch: 33 [45/250 5760/32000 (18%)] Loss: 1.97202 (semantic_loss: 0.02172, quant_loss: 1.95020, bit_balance_loss: 0.00010) batch_time=0.33159 
Train Epoch: 33 [56/250 7168/32000 (22%)] Loss: 1.97273 (semantic_loss: 0.02243, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.36657 
Train Epoch: 33 [67/250 8576/32000 (27%)] Loss: 1.97091 (semantic_loss: 0.02158, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=0.32822 
Train Epoch: 33 [78/250 9984/32000 (31%)] Loss: 1.97054 (semantic_loss: 0.02024, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.32657 
Train Epoch: 33 [89/250 11392/32000 (36%)] Loss: 1.97008 (semantic_loss: 0.02075, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=0.34788 
Train Epoch: 33 [100/250 12800/32000 (40%)] Loss: 1.97280 (semantic_loss: 0.02250, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.34020 
Train Epoch: 33 [111/250 14208/32000 (44%)] Loss: 1.97462 (semantic_loss: 0.02432, quant_loss: 1.95020, bit_balance_loss: 0.00010) batch_time=0.32720 
Train Epoch: 33 [122/250 15616/32000 (49%)] Loss: 1.97060 (semantic_loss: 0.02127, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=0.33655 
Train Epoch: 33 [133/250 17024/32000 (53%)] Loss: 1.97322 (semantic_loss: 0.02292, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.32870 
Train Epoch: 33 [144/250 18432/32000 (58%)] Loss: 1.97161 (semantic_loss: 0.02228, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=0.90840 
Train Epoch: 33 [155/250 19840/32000 (62%)] Loss: 1.97198 (semantic_loss: 0.02167, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.32757 
Train Epoch: 33 [166/250 21248/32000 (66%)] Loss: 1.97253 (semantic_loss: 0.02320, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=0.32752 
Train Epoch: 33 [177/250 22656/32000 (71%)] Loss: 1.97263 (semantic_loss: 0.02330, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=0.33670 
Train Epoch: 33 [188/250 24064/32000 (75%)] Loss: 1.97237 (semantic_loss: 0.02207, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.35685 
Train Epoch: 33 [199/250 25472/32000 (80%)] Loss: 1.97229 (semantic_loss: 0.02199, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.34131 
Train Epoch: 33 [210/250 26880/32000 (84%)] Loss: 1.97141 (semantic_loss: 0.02111, quant_loss: 1.95020, bit_balance_loss: 0.00010) batch_time=0.32970 
Train Epoch: 33 [221/250 28288/32000 (88%)] Loss: 1.97099 (semantic_loss: 0.02167, quant_loss: 1.94922, bit_balance_loss: 0.00010) batch_time=0.34850 
Train Epoch: 33 [232/250 29696/32000 (93%)] Loss: 1.97152 (semantic_loss: 0.02122, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.33468 
Train Epoch: 33 [243/250 31104/32000 (97%)] Loss: 1.97155 (semantic_loss: 0.02125, quant_loss: 1.95020, bit_balance_loss: 0.00010) batch_time=0.32893 
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/DCMH_LSMDC/checkpoint-epoch33.pth ...
Done in 4.345s
removing stale ckpt [epoch 32] [took 0.00s]
 epoch          : 33
 loss           : 1.9718894486427307
 learning_rate  : 9.685574222925043e-06
 n_samples      : 1056000
 n_steps        : 8250
 LSMDC_full_test/t2v_metrics/R1: 8.0
 LSMDC_full_test/t2v_metrics/R5: 26.8
 LSMDC_full_test/t2v_metrics/R10: 36.3
 LSMDC_full_test/t2v_metrics/R50: 65.0
 LSMDC_full_test/t2v_metrics/MedR: 22.5
 LSMDC_full_test/t2v_metrics/MeanR: 76.4475
 LSMDC_full_test/t2v_metrics/geometric_mean_R1-R5-R10: 19.817268884906
 LSMDC_full_test/v2t_metrics/R1: 8.5
 LSMDC_full_test/v2t_metrics/R5: 25.1
 LSMDC_full_test/v2t_metrics/R10: 35.2
 LSMDC_full_test/v2t_metrics/R50: 65.2
 LSMDC_full_test/v2t_metrics/MedR: 22.0
 LSMDC_full_test/v2t_metrics/MeanR: 78.9185
 LSMDC_full_test/v2t_metrics/geometric_mean_R1-R5-R10: 19.582964511941256
 mnt_best       : 20.915725746859103
 not_improved_count: 2
Train Epoch: 34 [1/250 128/32000 (0%)] Loss: 1.97183 (semantic_loss: 0.02251, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=15.50920 
Train Epoch: 34 [12/250 1536/32000 (5%)] Loss: 1.97207 (semantic_loss: 0.02177, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.31606 
Train Epoch: 34 [23/250 2944/32000 (9%)] Loss: 1.97257 (semantic_loss: 0.02227, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.32385 
Train Epoch: 34 [34/250 4352/32000 (14%)] Loss: 1.97023 (semantic_loss: 0.02090, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=0.32302 
Train Epoch: 34 [45/250 5760/32000 (18%)] Loss: 1.96931 (semantic_loss: 0.01902, quant_loss: 1.95020, bit_balance_loss: 0.00010) batch_time=0.34292 
Train Epoch: 34 [56/250 7168/32000 (22%)] Loss: 1.97255 (semantic_loss: 0.02322, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=0.34923 
Train Epoch: 34 [67/250 8576/32000 (27%)] Loss: 1.97180 (semantic_loss: 0.02247, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=0.35615 
Train Epoch: 34 [78/250 9984/32000 (31%)] Loss: 1.97250 (semantic_loss: 0.02219, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.33372 
Train Epoch: 34 [89/250 11392/32000 (36%)] Loss: 1.97069 (semantic_loss: 0.02137, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=0.31709 
Train Epoch: 34 [100/250 12800/32000 (40%)] Loss: 1.97157 (semantic_loss: 0.02127, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.36157 
Train Epoch: 34 [111/250 14208/32000 (44%)] Loss: 1.97146 (semantic_loss: 0.02116, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.33184 
Train Epoch: 34 [122/250 15616/32000 (49%)] Loss: 1.97130 (semantic_loss: 0.02198, quant_loss: 1.94922, bit_balance_loss: 0.00010) batch_time=0.33329 
Train Epoch: 34 [133/250 17024/32000 (53%)] Loss: 1.97108 (semantic_loss: 0.02078, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.32914 
Train Epoch: 34 [144/250 18432/32000 (58%)] Loss: 1.97107 (semantic_loss: 0.02077, quant_loss: 1.95020, bit_balance_loss: 0.00010) batch_time=0.31585 
Train Epoch: 34 [155/250 19840/32000 (62%)] Loss: 1.97166 (semantic_loss: 0.02136, quant_loss: 1.95020, bit_balance_loss: 0.00010) batch_time=0.35005 
Train Epoch: 34 [166/250 21248/32000 (66%)] Loss: 1.97233 (semantic_loss: 0.02203, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.33960 
Train Epoch: 34 [177/250 22656/32000 (71%)] Loss: 1.97408 (semantic_loss: 0.02378, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.35066 
Train Epoch: 34 [188/250 24064/32000 (75%)] Loss: 1.96939 (semantic_loss: 0.02006, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=0.42067 
Train Epoch: 34 [199/250 25472/32000 (80%)] Loss: 1.97072 (semantic_loss: 0.02139, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=0.32692 
Train Epoch: 34 [210/250 26880/32000 (84%)] Loss: 1.97226 (semantic_loss: 0.02293, quant_loss: 1.94922, bit_balance_loss: 0.00010) batch_time=0.32233 
Train Epoch: 34 [221/250 28288/32000 (88%)] Loss: 1.97073 (semantic_loss: 0.02140, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=0.31779 
Train Epoch: 34 [232/250 29696/32000 (93%)] Loss: 1.97085 (semantic_loss: 0.02055, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.32739 
Train Epoch: 34 [243/250 31104/32000 (97%)] Loss: 1.96964 (semantic_loss: 0.01934, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.32646 
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/DCMH_LSMDC/checkpoint-epoch34.pth ...
Done in 18.082s
removing stale ckpt [epoch 33] [took 0.01s]
 epoch          : 34
 loss           : 1.9718144035339356
 learning_rate  : 9.20129551177879e-06
 n_samples      : 1088000
 n_steps        : 8500
 LSMDC_full_test/t2v_metrics/R1: 8.2
 LSMDC_full_test/t2v_metrics/R5: 26.5
 LSMDC_full_test/t2v_metrics/R10: 35.6
 LSMDC_full_test/t2v_metrics/R50: 64.6
 LSMDC_full_test/t2v_metrics/MedR: 23.0
 LSMDC_full_test/t2v_metrics/MeanR: 77.0995
 LSMDC_full_test/t2v_metrics/geometric_mean_R1-R5-R10: 19.77743237016412
 LSMDC_full_test/v2t_metrics/R1: 9.4
 LSMDC_full_test/v2t_metrics/R5: 25.3
 LSMDC_full_test/v2t_metrics/R10: 36.5
 LSMDC_full_test/v2t_metrics/R50: 66.1
 LSMDC_full_test/v2t_metrics/MedR: 23.0
 LSMDC_full_test/v2t_metrics/MeanR: 77.27
 LSMDC_full_test/v2t_metrics/geometric_mean_R1-R5-R10: 20.55166819868884
 mnt_best       : 20.915725746859103
 not_improved_count: 3
Train Epoch: 35 [1/250 128/32000 (0%)] Loss: 1.97265 (semantic_loss: 0.02137, quant_loss: 1.95117, bit_balance_loss: 0.00010) batch_time=19.30437 
Train Epoch: 35 [12/250 1536/32000 (5%)] Loss: 1.97157 (semantic_loss: 0.02225, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=0.34318 
Train Epoch: 35 [23/250 2944/32000 (9%)] Loss: 1.97085 (semantic_loss: 0.02152, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=0.33540 
Train Epoch: 35 [34/250 4352/32000 (14%)] Loss: 1.96998 (semantic_loss: 0.02066, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=0.32335 
Train Epoch: 35 [45/250 5760/32000 (18%)] Loss: 1.97208 (semantic_loss: 0.02276, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=0.32394 
Train Epoch: 35 [56/250 7168/32000 (22%)] Loss: 1.96951 (semantic_loss: 0.01921, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.34364 
Train Epoch: 35 [67/250 8576/32000 (27%)] Loss: 1.97105 (semantic_loss: 0.02075, quant_loss: 1.95020, bit_balance_loss: 0.00010) batch_time=0.32382 
Train Epoch: 35 [78/250 9984/32000 (31%)] Loss: 1.97225 (semantic_loss: 0.02194, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.32053 
Train Epoch: 35 [89/250 11392/32000 (36%)] Loss: 1.97070 (semantic_loss: 0.02138, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=0.32256 
Train Epoch: 35 [100/250 12800/32000 (40%)] Loss: 1.97394 (semantic_loss: 0.02364, quant_loss: 1.95020, bit_balance_loss: 0.00010) batch_time=0.32247 
Train Epoch: 35 [111/250 14208/32000 (44%)] Loss: 1.97231 (semantic_loss: 0.02201, quant_loss: 1.95020, bit_balance_loss: 0.00010) batch_time=0.32400 
Train Epoch: 35 [122/250 15616/32000 (49%)] Loss: 1.97260 (semantic_loss: 0.02327, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=0.32639 
Train Epoch: 35 [133/250 17024/32000 (53%)] Loss: 1.97133 (semantic_loss: 0.02103, quant_loss: 1.95020, bit_balance_loss: 0.00010) batch_time=0.32252 
Train Epoch: 35 [144/250 18432/32000 (58%)] Loss: 1.97087 (semantic_loss: 0.02154, quant_loss: 1.94922, bit_balance_loss: 0.00010) batch_time=0.31786 
Train Epoch: 35 [155/250 19840/32000 (62%)] Loss: 1.97128 (semantic_loss: 0.02098, quant_loss: 1.95020, bit_balance_loss: 0.00010) batch_time=0.33588 
Train Epoch: 35 [166/250 21248/32000 (66%)] Loss: 1.97168 (semantic_loss: 0.02138, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.32630 
Train Epoch: 35 [177/250 22656/32000 (71%)] Loss: 1.97249 (semantic_loss: 0.02218, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.34917 
Train Epoch: 35 [188/250 24064/32000 (75%)] Loss: 1.97225 (semantic_loss: 0.02293, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=0.36263 
Train Epoch: 35 [199/250 25472/32000 (80%)] Loss: 1.97172 (semantic_loss: 0.02240, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=0.34426 
Train Epoch: 35 [210/250 26880/32000 (84%)] Loss: 1.97169 (semantic_loss: 0.02139, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.32322 
Train Epoch: 35 [221/250 28288/32000 (88%)] Loss: 1.97298 (semantic_loss: 0.02268, quant_loss: 1.95020, bit_balance_loss: 0.00010) batch_time=0.33729 
Train Epoch: 35 [232/250 29696/32000 (93%)] Loss: 1.97243 (semantic_loss: 0.02213, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.31834 
Train Epoch: 35 [243/250 31104/32000 (97%)] Loss: 1.97162 (semantic_loss: 0.02132, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.33174 
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/DCMH_LSMDC/checkpoint-epoch35.pth ...
Done in 4.743s
removing stale ckpt [epoch 34] [took 0.01s]
 epoch          : 35
 loss           : 1.971514419555664
 learning_rate  : 8.74123073618985e-06
 n_samples      : 1120000
 n_steps        : 8750
 LSMDC_full_test/t2v_metrics/R1: 8.9
 LSMDC_full_test/t2v_metrics/R5: 25.4
 LSMDC_full_test/t2v_metrics/R10: 36.9
 LSMDC_full_test/t2v_metrics/R50: 64.6
 LSMDC_full_test/t2v_metrics/MedR: 22.75
 LSMDC_full_test/t2v_metrics/MeanR: 76.308
 LSMDC_full_test/t2v_metrics/geometric_mean_R1-R5-R10: 20.280719720498045
 LSMDC_full_test/v2t_metrics/R1: 9.2
 LSMDC_full_test/v2t_metrics/R5: 25.4
 LSMDC_full_test/v2t_metrics/R10: 35.6
 LSMDC_full_test/v2t_metrics/R50: 66.1
 LSMDC_full_test/v2t_metrics/MedR: 23.25
 LSMDC_full_test/v2t_metrics/MeanR: 77.996
 LSMDC_full_test/v2t_metrics/geometric_mean_R1-R5-R10: 20.262382712560843
 mnt_best       : 20.915725746859103
 not_improved_count: 4
Train Epoch: 36 [1/250 128/32000 (0%)] Loss: 1.97098 (semantic_loss: 0.02166, quant_loss: 1.94922, bit_balance_loss: 0.00010) batch_time=14.53773 
Train Epoch: 36 [12/250 1536/32000 (5%)] Loss: 1.96977 (semantic_loss: 0.02045, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=0.33675 
Train Epoch: 36 [23/250 2944/32000 (9%)] Loss: 1.97303 (semantic_loss: 0.02273, quant_loss: 1.95020, bit_balance_loss: 0.00010) batch_time=0.31612 
Train Epoch: 36 [34/250 4352/32000 (14%)] Loss: 1.97105 (semantic_loss: 0.02075, quant_loss: 1.95020, bit_balance_loss: 0.00010) batch_time=0.33332 
Train Epoch: 36 [45/250 5760/32000 (18%)] Loss: 1.97057 (semantic_loss: 0.02027, quant_loss: 1.95020, bit_balance_loss: 0.00010) batch_time=0.33037 
Train Epoch: 36 [56/250 7168/32000 (22%)] Loss: 1.97159 (semantic_loss: 0.02129, quant_loss: 1.95020, bit_balance_loss: 0.00010) batch_time=0.34342 
Train Epoch: 36 [67/250 8576/32000 (27%)] Loss: 1.97116 (semantic_loss: 0.02086, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=2.04516 
Train Epoch: 36 [78/250 9984/32000 (31%)] Loss: 1.97166 (semantic_loss: 0.02233, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=0.32995 
Train Epoch: 36 [89/250 11392/32000 (36%)] Loss: 1.97092 (semantic_loss: 0.02062, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.32996 
Train Epoch: 36 [100/250 12800/32000 (40%)] Loss: 1.97321 (semantic_loss: 0.02291, quant_loss: 1.95020, bit_balance_loss: 0.00010) batch_time=0.35973 
Train Epoch: 36 [111/250 14208/32000 (44%)] Loss: 1.97185 (semantic_loss: 0.02155, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.33311 
Train Epoch: 36 [122/250 15616/32000 (49%)] Loss: 1.97263 (semantic_loss: 0.02233, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.31771 
Train Epoch: 36 [133/250 17024/32000 (53%)] Loss: 1.97207 (semantic_loss: 0.02177, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.34132 
Train Epoch: 36 [144/250 18432/32000 (58%)] Loss: 1.97349 (semantic_loss: 0.02416, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=0.67540 
Train Epoch: 36 [155/250 19840/32000 (62%)] Loss: 1.97097 (semantic_loss: 0.02164, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=0.32822 
Train Epoch: 36 [166/250 21248/32000 (66%)] Loss: 1.97286 (semantic_loss: 0.02256, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.33498 
Train Epoch: 36 [177/250 22656/32000 (71%)] Loss: 1.96969 (semantic_loss: 0.02037, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=0.34016 
Train Epoch: 36 [188/250 24064/32000 (75%)] Loss: 1.97132 (semantic_loss: 0.02200, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=0.32594 
Train Epoch: 36 [199/250 25472/32000 (80%)] Loss: 1.97155 (semantic_loss: 0.02223, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=0.32383 
Train Epoch: 36 [210/250 26880/32000 (84%)] Loss: 1.97135 (semantic_loss: 0.02105, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.80883 
Train Epoch: 36 [221/250 28288/32000 (88%)] Loss: 1.97254 (semantic_loss: 0.02224, quant_loss: 1.95020, bit_balance_loss: 0.00010) batch_time=0.33792 
Train Epoch: 36 [232/250 29696/32000 (93%)] Loss: 1.97186 (semantic_loss: 0.02156, quant_loss: 1.95020, bit_balance_loss: 0.00010) batch_time=0.33086 
Train Epoch: 36 [243/250 31104/32000 (97%)] Loss: 1.96941 (semantic_loss: 0.02009, quant_loss: 1.94922, bit_balance_loss: 0.00010) batch_time=0.34838 
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/DCMH_LSMDC/checkpoint-epoch36.pth ...
Done in 4.354s
removing stale ckpt [epoch 35] [took 0.00s]
 epoch          : 36
 loss           : 1.9715742440223694
 learning_rate  : 8.304169199380357e-06
 n_samples      : 1152000
 n_steps        : 9000
 LSMDC_full_test/t2v_metrics/R1: 8.4
 LSMDC_full_test/t2v_metrics/R5: 25.2
 LSMDC_full_test/t2v_metrics/R10: 35.8
 LSMDC_full_test/t2v_metrics/R50: 65.8
 LSMDC_full_test/t2v_metrics/MedR: 22.25
 LSMDC_full_test/t2v_metrics/MeanR: 76.123
 LSMDC_full_test/t2v_metrics/geometric_mean_R1-R5-R10: 19.64208643524692
 LSMDC_full_test/v2t_metrics/R1: 8.1
 LSMDC_full_test/v2t_metrics/R5: 25.5
 LSMDC_full_test/v2t_metrics/R10: 35.7
 LSMDC_full_test/v2t_metrics/R50: 66.6
 LSMDC_full_test/v2t_metrics/MedR: 24.0
 LSMDC_full_test/v2t_metrics/MeanR: 78.566
 LSMDC_full_test/v2t_metrics/geometric_mean_R1-R5-R10: 19.46395708961365
 mnt_best       : 20.915725746859103
 not_improved_count: 5
Train Epoch: 37 [1/250 128/32000 (0%)] Loss: 1.97078 (semantic_loss: 0.02146, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=22.42091 
Train Epoch: 37 [12/250 1536/32000 (5%)] Loss: 1.97229 (semantic_loss: 0.02199, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.31356 
Train Epoch: 37 [23/250 2944/32000 (9%)] Loss: 1.97192 (semantic_loss: 0.02260, quant_loss: 1.94922, bit_balance_loss: 0.00010) batch_time=0.32164 
Train Epoch: 37 [34/250 4352/32000 (14%)] Loss: 1.97122 (semantic_loss: 0.02190, quant_loss: 1.94922, bit_balance_loss: 0.00010) batch_time=0.34095 
Train Epoch: 37 [45/250 5760/32000 (18%)] Loss: 1.97222 (semantic_loss: 0.02191, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.35294 
Train Epoch: 37 [56/250 7168/32000 (22%)] Loss: 1.96982 (semantic_loss: 0.02050, quant_loss: 1.94922, bit_balance_loss: 0.00010) batch_time=0.35364 
Train Epoch: 37 [67/250 8576/32000 (27%)] Loss: 1.96954 (semantic_loss: 0.02021, quant_loss: 1.94922, bit_balance_loss: 0.00010) batch_time=0.32654 
Train Epoch: 37 [78/250 9984/32000 (31%)] Loss: 1.96951 (semantic_loss: 0.02019, quant_loss: 1.94922, bit_balance_loss: 0.00010) batch_time=0.33904 
Train Epoch: 37 [89/250 11392/32000 (36%)] Loss: 1.97148 (semantic_loss: 0.02118, quant_loss: 1.95020, bit_balance_loss: 0.00010) batch_time=0.32446 
Train Epoch: 37 [100/250 12800/32000 (40%)] Loss: 1.96923 (semantic_loss: 0.01991, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=0.32216 
Train Epoch: 37 [111/250 14208/32000 (44%)] Loss: 1.97197 (semantic_loss: 0.02167, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.34866 
Train Epoch: 37 [122/250 15616/32000 (49%)] Loss: 1.97219 (semantic_loss: 0.02189, quant_loss: 1.95020, bit_balance_loss: 0.00010) batch_time=0.36082 
Train Epoch: 37 [133/250 17024/32000 (53%)] Loss: 1.97061 (semantic_loss: 0.02129, quant_loss: 1.94922, bit_balance_loss: 0.00010) batch_time=0.31754 
Train Epoch: 37 [144/250 18432/32000 (58%)] Loss: 1.97196 (semantic_loss: 0.02263, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=0.31228 
Train Epoch: 37 [155/250 19840/32000 (62%)] Loss: 1.97218 (semantic_loss: 0.02188, quant_loss: 1.95020, bit_balance_loss: 0.00010) batch_time=0.32221 
Train Epoch: 37 [166/250 21248/32000 (66%)] Loss: 1.97157 (semantic_loss: 0.02127, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.31671 
Train Epoch: 37 [177/250 22656/32000 (71%)] Loss: 1.97119 (semantic_loss: 0.02187, quant_loss: 1.94922, bit_balance_loss: 0.00010) batch_time=0.31955 
Train Epoch: 37 [188/250 24064/32000 (75%)] Loss: 1.97238 (semantic_loss: 0.02208, quant_loss: 1.95020, bit_balance_loss: 0.00010) batch_time=0.42425 
Train Epoch: 37 [199/250 25472/32000 (80%)] Loss: 1.97234 (semantic_loss: 0.02302, quant_loss: 1.94922, bit_balance_loss: 0.00010) batch_time=0.32612 
Train Epoch: 37 [210/250 26880/32000 (84%)] Loss: 1.97127 (semantic_loss: 0.02097, quant_loss: 1.95020, bit_balance_loss: 0.00010) batch_time=0.33644 
Train Epoch: 37 [221/250 28288/32000 (88%)] Loss: 1.97200 (semantic_loss: 0.02170, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.33744 
Train Epoch: 37 [232/250 29696/32000 (93%)] Loss: 1.97186 (semantic_loss: 0.02156, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.36236 
Train Epoch: 37 [243/250 31104/32000 (97%)] Loss: 1.97160 (semantic_loss: 0.02129, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.32004 
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/DCMH_LSMDC/checkpoint-epoch37.pth ...
Done in 4.501s
removing stale ckpt [epoch 36] [took 0.00s]
 epoch          : 37
 loss           : 1.9713663625717164
 learning_rate  : 7.888960739411339e-06
 n_samples      : 1184000
 n_steps        : 9250
 LSMDC_full_test/t2v_metrics/R1: 8.6
 LSMDC_full_test/t2v_metrics/R5: 25.7
 LSMDC_full_test/t2v_metrics/R10: 36.6
 LSMDC_full_test/t2v_metrics/R50: 65.2
 LSMDC_full_test/t2v_metrics/MedR: 22.0
 LSMDC_full_test/t2v_metrics/MeanR: 76.38
 LSMDC_full_test/t2v_metrics/geometric_mean_R1-R5-R10: 20.074167949108467
 LSMDC_full_test/v2t_metrics/R1: 9.2
 LSMDC_full_test/v2t_metrics/R5: 25.3
 LSMDC_full_test/v2t_metrics/R10: 36.0
 LSMDC_full_test/v2t_metrics/R50: 64.8
 LSMDC_full_test/v2t_metrics/MedR: 23.25
 LSMDC_full_test/v2t_metrics/MeanR: 78.194
 LSMDC_full_test/v2t_metrics/geometric_mean_R1-R5-R10: 20.311263940563727
 mnt_best       : 20.915725746859103
 not_improved_count: 6
Train Epoch: 38 [1/250 128/32000 (0%)] Loss: 1.97112 (semantic_loss: 0.02179, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=16.42352 
Train Epoch: 38 [12/250 1536/32000 (5%)] Loss: 1.96899 (semantic_loss: 0.01967, quant_loss: 1.94922, bit_balance_loss: 0.00010) batch_time=0.31974 
Train Epoch: 38 [23/250 2944/32000 (9%)] Loss: 1.97327 (semantic_loss: 0.02395, quant_loss: 1.94922, bit_balance_loss: 0.00010) batch_time=0.31917 
Train Epoch: 38 [34/250 4352/32000 (14%)] Loss: 1.97190 (semantic_loss: 0.02160, quant_loss: 1.95020, bit_balance_loss: 0.00010) batch_time=0.43757 
Train Epoch: 38 [45/250 5760/32000 (18%)] Loss: 1.97235 (semantic_loss: 0.02205, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.47485 
Train Epoch: 38 [56/250 7168/32000 (22%)] Loss: 1.96905 (semantic_loss: 0.01973, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=0.33539 
Train Epoch: 38 [67/250 8576/32000 (27%)] Loss: 1.97291 (semantic_loss: 0.02359, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=0.35884 
Train Epoch: 38 [78/250 9984/32000 (31%)] Loss: 1.97095 (semantic_loss: 0.02163, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=0.31454 
Train Epoch: 38 [89/250 11392/32000 (36%)] Loss: 1.97014 (semantic_loss: 0.02081, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=0.33608 
Train Epoch: 38 [100/250 12800/32000 (40%)] Loss: 1.97049 (semantic_loss: 0.02117, quant_loss: 1.94922, bit_balance_loss: 0.00010) batch_time=1.68882 
Train Epoch: 38 [111/250 14208/32000 (44%)] Loss: 1.97048 (semantic_loss: 0.02018, quant_loss: 1.95020, bit_balance_loss: 0.00010) batch_time=0.76145 
Train Epoch: 38 [122/250 15616/32000 (49%)] Loss: 1.97120 (semantic_loss: 0.02187, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=0.34631 
Train Epoch: 38 [133/250 17024/32000 (53%)] Loss: 1.97085 (semantic_loss: 0.02152, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=0.34027 
Train Epoch: 38 [144/250 18432/32000 (58%)] Loss: 1.97100 (semantic_loss: 0.02070, quant_loss: 1.95020, bit_balance_loss: 0.00010) batch_time=0.31923 
Train Epoch: 38 [155/250 19840/32000 (62%)] Loss: 1.97159 (semantic_loss: 0.02227, quant_loss: 1.94922, bit_balance_loss: 0.00010) batch_time=0.31542 
Train Epoch: 38 [166/250 21248/32000 (66%)] Loss: 1.97057 (semantic_loss: 0.02125, quant_loss: 1.94922, bit_balance_loss: 0.00010) batch_time=0.31440 
Train Epoch: 38 [177/250 22656/32000 (71%)] Loss: 1.97204 (semantic_loss: 0.02271, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=0.31400 
Train Epoch: 38 [188/250 24064/32000 (75%)] Loss: 1.97051 (semantic_loss: 0.02119, quant_loss: 1.94922, bit_balance_loss: 0.00010) batch_time=0.33998 
Train Epoch: 38 [199/250 25472/32000 (80%)] Loss: 1.97046 (semantic_loss: 0.02211, quant_loss: 1.94824, bit_balance_loss: 0.00010) batch_time=0.88924 
Train Epoch: 38 [210/250 26880/32000 (84%)] Loss: 1.97179 (semantic_loss: 0.02246, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=0.34715 
Train Epoch: 38 [221/250 28288/32000 (88%)] Loss: 1.97148 (semantic_loss: 0.02021, quant_loss: 1.95117, bit_balance_loss: 0.00010) batch_time=0.33228 
Train Epoch: 38 [232/250 29696/32000 (93%)] Loss: 1.97193 (semantic_loss: 0.02163, quant_loss: 1.95020, bit_balance_loss: 0.00010) batch_time=0.32379 
Train Epoch: 38 [243/250 31104/32000 (97%)] Loss: 1.97107 (semantic_loss: 0.02175, quant_loss: 1.94922, bit_balance_loss: 0.00010) batch_time=0.34051 
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/DCMH_LSMDC/checkpoint-epoch38.pth ...
Done in 4.328s
removing stale ckpt [epoch 37] [took 0.00s]
 epoch          : 38
 loss           : 1.9714195237159728
 learning_rate  : 7.494512702440772e-06
 n_samples      : 1216000
 n_steps        : 9500
 LSMDC_full_test/t2v_metrics/R1: 9.0
 LSMDC_full_test/t2v_metrics/R5: 26.3
 LSMDC_full_test/t2v_metrics/R10: 36.9
 LSMDC_full_test/t2v_metrics/R50: 65.4
 LSMDC_full_test/t2v_metrics/MedR: 22.0
 LSMDC_full_test/t2v_metrics/MeanR: 75.4615
 LSMDC_full_test/t2v_metrics/geometric_mean_R1-R5-R10: 20.59403949838766
 LSMDC_full_test/v2t_metrics/R1: 8.7
 LSMDC_full_test/v2t_metrics/R5: 25.3
 LSMDC_full_test/v2t_metrics/R10: 37.1
 LSMDC_full_test/v2t_metrics/R50: 64.5
 LSMDC_full_test/v2t_metrics/MedR: 21.0
 LSMDC_full_test/v2t_metrics/MeanR: 77.501
 LSMDC_full_test/v2t_metrics/geometric_mean_R1-R5-R10: 20.137453989208716
 mnt_best       : 20.915725746859103
 not_improved_count: 7
Train Epoch: 39 [1/250 128/32000 (0%)] Loss: 1.97122 (semantic_loss: 0.02092, quant_loss: 1.95020, bit_balance_loss: 0.00010) batch_time=12.04954 
Train Epoch: 39 [12/250 1536/32000 (5%)] Loss: 1.97271 (semantic_loss: 0.02241, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.32965 
Train Epoch: 39 [23/250 2944/32000 (9%)] Loss: 1.97020 (semantic_loss: 0.02087, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=0.32506 
Train Epoch: 39 [34/250 4352/32000 (14%)] Loss: 1.97090 (semantic_loss: 0.02060, quant_loss: 1.95020, bit_balance_loss: 0.00010) batch_time=0.32769 
Train Epoch: 39 [45/250 5760/32000 (18%)] Loss: 1.97172 (semantic_loss: 0.02239, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=0.34333 
Train Epoch: 39 [56/250 7168/32000 (22%)] Loss: 1.97150 (semantic_loss: 0.02218, quant_loss: 1.94922, bit_balance_loss: 0.00010) batch_time=0.34314 
Train Epoch: 39 [67/250 8576/32000 (27%)] Loss: 1.97028 (semantic_loss: 0.01998, quant_loss: 1.95020, bit_balance_loss: 0.00010) batch_time=2.48907 
Train Epoch: 39 [78/250 9984/32000 (31%)] Loss: 1.97104 (semantic_loss: 0.02074, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.36407 
Train Epoch: 39 [89/250 11392/32000 (36%)] Loss: 1.97289 (semantic_loss: 0.02259, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.32548 
Train Epoch: 39 [100/250 12800/32000 (40%)] Loss: 1.97133 (semantic_loss: 0.02201, quant_loss: 1.94922, bit_balance_loss: 0.00010) batch_time=0.31419 
Train Epoch: 39 [111/250 14208/32000 (44%)] Loss: 1.97209 (semantic_loss: 0.02179, quant_loss: 1.95020, bit_balance_loss: 0.00010) batch_time=0.32621 
Train Epoch: 39 [122/250 15616/32000 (49%)] Loss: 1.96991 (semantic_loss: 0.02058, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=0.37549 
Train Epoch: 39 [133/250 17024/32000 (53%)] Loss: 1.96994 (semantic_loss: 0.02062, quant_loss: 1.94922, bit_balance_loss: 0.00010) batch_time=0.35471 
Train Epoch: 39 [144/250 18432/32000 (58%)] Loss: 1.97135 (semantic_loss: 0.02105, quant_loss: 1.95020, bit_balance_loss: 0.00010) batch_time=0.32968 
Train Epoch: 39 [155/250 19840/32000 (62%)] Loss: 1.97185 (semantic_loss: 0.02253, quant_loss: 1.94922, bit_balance_loss: 0.00010) batch_time=0.33097 
Train Epoch: 39 [166/250 21248/32000 (66%)] Loss: 1.97054 (semantic_loss: 0.02122, quant_loss: 1.94922, bit_balance_loss: 0.00010) batch_time=0.34968 
Train Epoch: 39 [177/250 22656/32000 (71%)] Loss: 1.97098 (semantic_loss: 0.02165, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=0.38701 
Train Epoch: 39 [188/250 24064/32000 (75%)] Loss: 1.97150 (semantic_loss: 0.02120, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.33304 
Train Epoch: 39 [199/250 25472/32000 (80%)] Loss: 1.96907 (semantic_loss: 0.01975, quant_loss: 1.94922, bit_balance_loss: 0.00010) batch_time=0.35748 
Train Epoch: 39 [210/250 26880/32000 (84%)] Loss: 1.97094 (semantic_loss: 0.02162, quant_loss: 1.94922, bit_balance_loss: 0.00010) batch_time=0.35307 
Train Epoch: 39 [221/250 28288/32000 (88%)] Loss: 1.97318 (semantic_loss: 0.02386, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=0.32801 
Train Epoch: 39 [232/250 29696/32000 (93%)] Loss: 1.97235 (semantic_loss: 0.02205, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.34856 
Train Epoch: 39 [243/250 31104/32000 (97%)] Loss: 1.96985 (semantic_loss: 0.01955, quant_loss: 1.95020, bit_balance_loss: 0.00010) batch_time=0.34527 
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/DCMH_LSMDC/checkpoint-epoch39.pth ...
Done in 4.616s
removing stale ckpt [epoch 38] [took 0.00s]
 epoch          : 39
 loss           : 1.971224838256836
 learning_rate  : 7.119787067318733e-06
 n_samples      : 1248000
 n_steps        : 9750
 LSMDC_full_test/t2v_metrics/R1: 9.2
 LSMDC_full_test/t2v_metrics/R5: 25.9
 LSMDC_full_test/t2v_metrics/R10: 36.3
 LSMDC_full_test/t2v_metrics/R50: 65.0
 LSMDC_full_test/t2v_metrics/MedR: 21.5
 LSMDC_full_test/t2v_metrics/MeanR: 75.8945
 LSMDC_full_test/t2v_metrics/geometric_mean_R1-R5-R10: 20.527279961630377
 LSMDC_full_test/v2t_metrics/R1: 9.3
 LSMDC_full_test/v2t_metrics/R5: 25.0
 LSMDC_full_test/v2t_metrics/R10: 35.6
 LSMDC_full_test/v2t_metrics/R50: 65.3
 LSMDC_full_test/v2t_metrics/MedR: 23.0
 LSMDC_full_test/v2t_metrics/MeanR: 78.3905
 LSMDC_full_test/v2t_metrics/geometric_mean_R1-R5-R10: 20.228219227074852
 mnt_best       : 20.915725746859103
 not_improved_count: 8
Train Epoch: 40 [1/250 128/32000 (0%)] Loss: 1.97019 (semantic_loss: 0.02087, quant_loss: 1.94922, bit_balance_loss: 0.00010) batch_time=14.78865 
Train Epoch: 40 [12/250 1536/32000 (5%)] Loss: 1.97160 (semantic_loss: 0.02130, quant_loss: 1.95020, bit_balance_loss: 0.00010) batch_time=0.33846 
Train Epoch: 40 [23/250 2944/32000 (9%)] Loss: 1.97317 (semantic_loss: 0.02287, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.32410 
Train Epoch: 40 [34/250 4352/32000 (14%)] Loss: 1.97170 (semantic_loss: 0.02140, quant_loss: 1.95020, bit_balance_loss: 0.00010) batch_time=0.33038 
Train Epoch: 40 [45/250 5760/32000 (18%)] Loss: 1.97078 (semantic_loss: 0.02145, quant_loss: 1.94922, bit_balance_loss: 0.00010) batch_time=0.32962 
Train Epoch: 40 [56/250 7168/32000 (22%)] Loss: 1.96825 (semantic_loss: 0.01892, quant_loss: 1.94922, bit_balance_loss: 0.00010) batch_time=0.33641 
Train Epoch: 40 [67/250 8576/32000 (27%)] Loss: 1.97100 (semantic_loss: 0.02070, quant_loss: 1.95020, bit_balance_loss: 0.00010) batch_time=0.31657 
Train Epoch: 40 [78/250 9984/32000 (31%)] Loss: 1.97053 (semantic_loss: 0.02121, quant_loss: 1.94922, bit_balance_loss: 0.00010) batch_time=0.32927 
Train Epoch: 40 [89/250 11392/32000 (36%)] Loss: 1.97243 (semantic_loss: 0.02213, quant_loss: 1.95020, bit_balance_loss: 0.00010) batch_time=0.31833 
Train Epoch: 40 [100/250 12800/32000 (40%)] Loss: 1.97332 (semantic_loss: 0.02302, quant_loss: 1.95020, bit_balance_loss: 0.00010) batch_time=0.33512 
Train Epoch: 40 [111/250 14208/32000 (44%)] Loss: 1.97076 (semantic_loss: 0.02144, quant_loss: 1.94922, bit_balance_loss: 0.00010) batch_time=0.34828 
Train Epoch: 40 [122/250 15616/32000 (49%)] Loss: 1.97125 (semantic_loss: 0.02095, quant_loss: 1.95020, bit_balance_loss: 0.00010) batch_time=0.32296 
Train Epoch: 40 [133/250 17024/32000 (53%)] Loss: 1.96978 (semantic_loss: 0.02046, quant_loss: 1.94922, bit_balance_loss: 0.00010) batch_time=0.32082 
Train Epoch: 40 [144/250 18432/32000 (58%)] Loss: 1.97199 (semantic_loss: 0.02169, quant_loss: 1.95020, bit_balance_loss: 0.00010) batch_time=0.31630 
Train Epoch: 40 [155/250 19840/32000 (62%)] Loss: 1.97205 (semantic_loss: 0.02175, quant_loss: 1.95020, bit_balance_loss: 0.00010) batch_time=0.33582 
Train Epoch: 40 [166/250 21248/32000 (66%)] Loss: 1.96948 (semantic_loss: 0.02015, quant_loss: 1.94922, bit_balance_loss: 0.00010) batch_time=0.32402 
Train Epoch: 40 [177/250 22656/32000 (71%)] Loss: 1.96972 (semantic_loss: 0.02040, quant_loss: 1.94922, bit_balance_loss: 0.00010) batch_time=0.32875 
Train Epoch: 40 [188/250 24064/32000 (75%)] Loss: 1.97043 (semantic_loss: 0.02013, quant_loss: 1.95020, bit_balance_loss: 0.00010) batch_time=0.32828 
Train Epoch: 40 [199/250 25472/32000 (80%)] Loss: 1.97213 (semantic_loss: 0.02183, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.32873 
Train Epoch: 40 [210/250 26880/32000 (84%)] Loss: 1.97425 (semantic_loss: 0.02395, quant_loss: 1.95020, bit_balance_loss: 0.00010) batch_time=0.31720 
Train Epoch: 40 [221/250 28288/32000 (88%)] Loss: 1.97024 (semantic_loss: 0.01994, quant_loss: 1.95020, bit_balance_loss: 0.00010) batch_time=0.31866 
Train Epoch: 40 [232/250 29696/32000 (93%)] Loss: 1.97117 (semantic_loss: 0.02185, quant_loss: 1.94922, bit_balance_loss: 0.00010) batch_time=0.32543 
Train Epoch: 40 [243/250 31104/32000 (97%)] Loss: 1.97051 (semantic_loss: 0.02021, quant_loss: 1.95020, bit_balance_loss: 0.00010) batch_time=0.34109 
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/DCMH_LSMDC/checkpoint-epoch40.pth ...
Done in 16.983s
removing stale ckpt [epoch 39] [took 0.00s]
 epoch          : 40
 loss           : 1.970946249961853
 learning_rate  : 6.763797713952796e-06
 n_samples      : 1280000
 n_steps        : 10000
 LSMDC_full_test/t2v_metrics/R1: 9.0
 LSMDC_full_test/t2v_metrics/R5: 26.3
 LSMDC_full_test/t2v_metrics/R10: 36.2
 LSMDC_full_test/t2v_metrics/R50: 64.5
 LSMDC_full_test/t2v_metrics/MedR: 22.0
 LSMDC_full_test/t2v_metrics/MeanR: 75.194
 LSMDC_full_test/t2v_metrics/geometric_mean_R1-R5-R10: 20.46298297021821
 LSMDC_full_test/v2t_metrics/R1: 8.8
 LSMDC_full_test/v2t_metrics/R5: 25.9
 LSMDC_full_test/v2t_metrics/R10: 35.4
 LSMDC_full_test/v2t_metrics/R50: 64.3
 LSMDC_full_test/v2t_metrics/MedR: 22.0
 LSMDC_full_test/v2t_metrics/MeanR: 76.17
 LSMDC_full_test/v2t_metrics/geometric_mean_R1-R5-R10: 20.05681180149
 mnt_best       : 20.915725746859103
 not_improved_count: 9
Train Epoch: 41 [1/250 128/32000 (0%)] Loss: 1.97047 (semantic_loss: 0.02114, quant_loss: 1.94922, bit_balance_loss: 0.00010) batch_time=16.15623 
Train Epoch: 41 [12/250 1536/32000 (5%)] Loss: 1.97081 (semantic_loss: 0.02051, quant_loss: 1.95020, bit_balance_loss: 0.00010) batch_time=0.32932 
Train Epoch: 41 [23/250 2944/32000 (9%)] Loss: 1.97043 (semantic_loss: 0.02111, quant_loss: 1.94922, bit_balance_loss: 0.00010) batch_time=0.33086 
Train Epoch: 41 [34/250 4352/32000 (14%)] Loss: 1.97096 (semantic_loss: 0.02164, quant_loss: 1.94922, bit_balance_loss: 0.00010) batch_time=0.33553 
Train Epoch: 41 [45/250 5760/32000 (18%)] Loss: 1.97325 (semantic_loss: 0.02295, quant_loss: 1.95020, bit_balance_loss: 0.00010) batch_time=0.32585 
Train Epoch: 41 [56/250 7168/32000 (22%)] Loss: 1.97274 (semantic_loss: 0.02244, quant_loss: 1.95020, bit_balance_loss: 0.00010) batch_time=0.32910 
Train Epoch: 41 [67/250 8576/32000 (27%)] Loss: 1.97191 (semantic_loss: 0.02259, quant_loss: 1.94922, bit_balance_loss: 0.00010) batch_time=0.34280 
Train Epoch: 41 [78/250 9984/32000 (31%)] Loss: 1.97034 (semantic_loss: 0.02005, quant_loss: 1.95020, bit_balance_loss: 0.00010) batch_time=0.33690 
Train Epoch: 41 [89/250 11392/32000 (36%)] Loss: 1.97217 (semantic_loss: 0.02187, quant_loss: 1.95020, bit_balance_loss: 0.00010) batch_time=0.31894 
Train Epoch: 41 [100/250 12800/32000 (40%)] Loss: 1.97050 (semantic_loss: 0.02020, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.32052 
Train Epoch: 41 [111/250 14208/32000 (44%)] Loss: 1.96960 (semantic_loss: 0.01930, quant_loss: 1.95020, bit_balance_loss: 0.00010) batch_time=0.32821 
Train Epoch: 41 [122/250 15616/32000 (49%)] Loss: 1.97051 (semantic_loss: 0.02119, quant_loss: 1.94922, bit_balance_loss: 0.00010) batch_time=0.57083 
Train Epoch: 41 [133/250 17024/32000 (53%)] Loss: 1.97118 (semantic_loss: 0.02185, quant_loss: 1.94922, bit_balance_loss: 0.00010) batch_time=9.02811 
Train Epoch: 41 [144/250 18432/32000 (58%)] Loss: 1.97119 (semantic_loss: 0.02090, quant_loss: 1.95020, bit_balance_loss: 0.00010) batch_time=0.36157 
Train Epoch: 41 [155/250 19840/32000 (62%)] Loss: 1.97041 (semantic_loss: 0.02012, quant_loss: 1.95020, bit_balance_loss: 0.00010) batch_time=0.32615 
Train Epoch: 41 [166/250 21248/32000 (66%)] Loss: 1.97082 (semantic_loss: 0.02052, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.32248 
Train Epoch: 41 [177/250 22656/32000 (71%)] Loss: 1.97061 (semantic_loss: 0.02129, quant_loss: 1.94922, bit_balance_loss: 0.00010) batch_time=0.33668 
Train Epoch: 41 [188/250 24064/32000 (75%)] Loss: 1.97022 (semantic_loss: 0.02089, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=0.34009 
Train Epoch: 41 [199/250 25472/32000 (80%)] Loss: 1.96784 (semantic_loss: 0.01852, quant_loss: 1.94922, bit_balance_loss: 0.00010) batch_time=0.32838 
Train Epoch: 41 [210/250 26880/32000 (84%)] Loss: 1.97028 (semantic_loss: 0.02096, quant_loss: 1.94922, bit_balance_loss: 0.00010) batch_time=0.32426 
Train Epoch: 41 [221/250 28288/32000 (88%)] Loss: 1.97093 (semantic_loss: 0.02063, quant_loss: 1.95020, bit_balance_loss: 0.00010) batch_time=0.32387 
Train Epoch: 41 [232/250 29696/32000 (93%)] Loss: 1.97004 (semantic_loss: 0.02072, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=0.32130 
Train Epoch: 41 [243/250 31104/32000 (97%)] Loss: 1.97092 (semantic_loss: 0.02063, quant_loss: 1.95020, bit_balance_loss: 0.00010) batch_time=0.32216 
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/DCMH_LSMDC/checkpoint-epoch41.pth ...
Done in 4.501s
removing stale ckpt [epoch 40] [took 0.00s]
 epoch          : 41
 loss           : 1.9710141234397889
 learning_rate  : 6.425607828255156e-06
 n_samples      : 1312000
 n_steps        : 10250
 LSMDC_full_test/t2v_metrics/R1: 9.4
 LSMDC_full_test/t2v_metrics/R5: 26.5
 LSMDC_full_test/t2v_metrics/R10: 36.1
 LSMDC_full_test/t2v_metrics/R50: 65.4
 LSMDC_full_test/t2v_metrics/MedR: 23.0
 LSMDC_full_test/t2v_metrics/MeanR: 75.4015
 LSMDC_full_test/t2v_metrics/geometric_mean_R1-R5-R10: 20.79506632244732
 LSMDC_full_test/v2t_metrics/R1: 9.5
 LSMDC_full_test/v2t_metrics/R5: 25.6
 LSMDC_full_test/v2t_metrics/R10: 35.5
 LSMDC_full_test/v2t_metrics/R50: 65.7
 LSMDC_full_test/v2t_metrics/MedR: 23.25
 LSMDC_full_test/v2t_metrics/MeanR: 77.182
 LSMDC_full_test/v2t_metrics/geometric_mean_R1-R5-R10: 20.514643513196525
 mnt_best       : 20.915725746859103
 not_improved_count: 10
Train Epoch: 42 [1/250 128/32000 (0%)] Loss: 1.97227 (semantic_loss: 0.02197, quant_loss: 1.95020, bit_balance_loss: 0.00010) batch_time=18.44703 
Train Epoch: 42 [12/250 1536/32000 (5%)] Loss: 1.97120 (semantic_loss: 0.02090, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.35073 
Train Epoch: 42 [23/250 2944/32000 (9%)] Loss: 1.97133 (semantic_loss: 0.02103, quant_loss: 1.95020, bit_balance_loss: 0.00010) batch_time=0.34817 
Train Epoch: 42 [34/250 4352/32000 (14%)] Loss: 1.97115 (semantic_loss: 0.02182, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=0.33332 
Train Epoch: 42 [45/250 5760/32000 (18%)] Loss: 1.96972 (semantic_loss: 0.02039, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=0.33484 
Train Epoch: 42 [56/250 7168/32000 (22%)] Loss: 1.97198 (semantic_loss: 0.02168, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.33685 
Train Epoch: 42 [67/250 8576/32000 (27%)] Loss: 1.97122 (semantic_loss: 0.02190, quant_loss: 1.94922, bit_balance_loss: 0.00010) batch_time=0.34644 
Train Epoch: 42 [78/250 9984/32000 (31%)] Loss: 1.97373 (semantic_loss: 0.02344, quant_loss: 1.95020, bit_balance_loss: 0.00010) batch_time=0.32819 
Train Epoch: 42 [89/250 11392/32000 (36%)] Loss: 1.97038 (semantic_loss: 0.02008, quant_loss: 1.95020, bit_balance_loss: 0.00010) batch_time=0.35219 
Train Epoch: 42 [100/250 12800/32000 (40%)] Loss: 1.97060 (semantic_loss: 0.02128, quant_loss: 1.94922, bit_balance_loss: 0.00010) batch_time=0.34035 
Train Epoch: 42 [111/250 14208/32000 (44%)] Loss: 1.97116 (semantic_loss: 0.02086, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.32390 
Train Epoch: 42 [122/250 15616/32000 (49%)] Loss: 1.97004 (semantic_loss: 0.01974, quant_loss: 1.95020, bit_balance_loss: 0.00010) batch_time=0.32504 
Train Epoch: 42 [133/250 17024/32000 (53%)] Loss: 1.97060 (semantic_loss: 0.02128, quant_loss: 1.94922, bit_balance_loss: 0.00010) batch_time=0.33437 
Train Epoch: 42 [144/250 18432/32000 (58%)] Loss: 1.97050 (semantic_loss: 0.02118, quant_loss: 1.94922, bit_balance_loss: 0.00010) batch_time=0.33101 
Train Epoch: 42 [155/250 19840/32000 (62%)] Loss: 1.96999 (semantic_loss: 0.02067, quant_loss: 1.94922, bit_balance_loss: 0.00010) batch_time=0.31528 
Train Epoch: 42 [166/250 21248/32000 (66%)] Loss: 1.96973 (semantic_loss: 0.02041, quant_loss: 1.94922, bit_balance_loss: 0.00010) batch_time=0.66276 
Train Epoch: 42 [177/250 22656/32000 (71%)] Loss: 1.97034 (semantic_loss: 0.02102, quant_loss: 1.94922, bit_balance_loss: 0.00010) batch_time=0.34302 
Train Epoch: 42 [188/250 24064/32000 (75%)] Loss: 1.97094 (semantic_loss: 0.02064, quant_loss: 1.95020, bit_balance_loss: 0.00010) batch_time=0.32619 
Train Epoch: 42 [199/250 25472/32000 (80%)] Loss: 1.97225 (semantic_loss: 0.02195, quant_loss: 1.95020, bit_balance_loss: 0.00010) batch_time=0.32998 
Train Epoch: 42 [210/250 26880/32000 (84%)] Loss: 1.97197 (semantic_loss: 0.02167, quant_loss: 1.95020, bit_balance_loss: 0.00010) batch_time=0.31886 
Train Epoch: 42 [221/250 28288/32000 (88%)] Loss: 1.97078 (semantic_loss: 0.02146, quant_loss: 1.94922, bit_balance_loss: 0.00010) batch_time=0.31796 
Train Epoch: 42 [232/250 29696/32000 (93%)] Loss: 1.96906 (semantic_loss: 0.01974, quant_loss: 1.94922, bit_balance_loss: 0.00010) batch_time=0.35812 
Train Epoch: 42 [243/250 31104/32000 (97%)] Loss: 1.97088 (semantic_loss: 0.02058, quant_loss: 1.95020, bit_balance_loss: 0.00010) batch_time=0.44691 
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/DCMH_LSMDC/checkpoint-epoch42.pth ...
Done in 4.489s
removing stale ckpt [epoch 41] [took 0.00s]
 epoch          : 42
 loss           : 1.9708234066963195
 learning_rate  : 6.104327436842398e-06
 n_samples      : 1344000
 n_steps        : 10500
 LSMDC_full_test/t2v_metrics/R1: 8.7
 LSMDC_full_test/t2v_metrics/R5: 25.5
 LSMDC_full_test/t2v_metrics/R10: 36.8
 LSMDC_full_test/t2v_metrics/R50: 65.7
 LSMDC_full_test/t2v_metrics/MedR: 22.5
 LSMDC_full_test/t2v_metrics/MeanR: 76.473
 LSMDC_full_test/t2v_metrics/geometric_mean_R1-R5-R10: 20.13580904115457
 LSMDC_full_test/v2t_metrics/R1: 9.3
 LSMDC_full_test/v2t_metrics/R5: 24.7
 LSMDC_full_test/v2t_metrics/R10: 36.4
 LSMDC_full_test/v2t_metrics/R50: 64.8
 LSMDC_full_test/v2t_metrics/MedR: 22.5
 LSMDC_full_test/v2t_metrics/MeanR: 78.004
 LSMDC_full_test/v2t_metrics/geometric_mean_R1-R5-R10: 20.29677770041794
 mnt_best       : 20.915725746859103
 not_improved_count: 11
Train Epoch: 43 [1/250 128/32000 (0%)] Loss: 1.97209 (semantic_loss: 0.02277, quant_loss: 1.94922, bit_balance_loss: 0.00010) batch_time=13.66470 
Train Epoch: 43 [12/250 1536/32000 (5%)] Loss: 1.97184 (semantic_loss: 0.02252, quant_loss: 1.94922, bit_balance_loss: 0.00010) batch_time=0.32424 
Train Epoch: 43 [23/250 2944/32000 (9%)] Loss: 1.97112 (semantic_loss: 0.02082, quant_loss: 1.95020, bit_balance_loss: 0.00010) batch_time=0.35163 
Train Epoch: 43 [34/250 4352/32000 (14%)] Loss: 1.97165 (semantic_loss: 0.02134, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.33821 
Train Epoch: 43 [45/250 5760/32000 (18%)] Loss: 1.96972 (semantic_loss: 0.02040, quant_loss: 1.94922, bit_balance_loss: 0.00010) batch_time=0.34284 
Train Epoch: 43 [56/250 7168/32000 (22%)] Loss: 1.96942 (semantic_loss: 0.01912, quant_loss: 1.95020, bit_balance_loss: 0.00010) batch_time=0.35487 
Train Epoch: 43 [67/250 8576/32000 (27%)] Loss: 1.97117 (semantic_loss: 0.02185, quant_loss: 1.94922, bit_balance_loss: 0.00010) batch_time=1.84414 
Train Epoch: 43 [78/250 9984/32000 (31%)] Loss: 1.97303 (semantic_loss: 0.02273, quant_loss: 1.95020, bit_balance_loss: 0.00010) batch_time=0.65745 
Train Epoch: 43 [89/250 11392/32000 (36%)] Loss: 1.97057 (semantic_loss: 0.02027, quant_loss: 1.95020, bit_balance_loss: 0.00010) batch_time=1.79928 
Train Epoch: 43 [100/250 12800/32000 (40%)] Loss: 1.96911 (semantic_loss: 0.01881, quant_loss: 1.95020, bit_balance_loss: 0.00010) batch_time=0.32371 
Train Epoch: 43 [111/250 14208/32000 (44%)] Loss: 1.97024 (semantic_loss: 0.01994, quant_loss: 1.95020, bit_balance_loss: 0.00010) batch_time=0.32667 
Train Epoch: 43 [122/250 15616/32000 (49%)] Loss: 1.97045 (semantic_loss: 0.02015, quant_loss: 1.95020, bit_balance_loss: 0.00010) batch_time=0.31909 
Train Epoch: 43 [133/250 17024/32000 (53%)] Loss: 1.97190 (semantic_loss: 0.02258, quant_loss: 1.94922, bit_balance_loss: 0.00010) batch_time=1.24001 
Train Epoch: 43 [144/250 18432/32000 (58%)] Loss: 1.97024 (semantic_loss: 0.01994, quant_loss: 1.95020, bit_balance_loss: 0.00010) batch_time=7.25181 
Train Epoch: 43 [155/250 19840/32000 (62%)] Loss: 1.96905 (semantic_loss: 0.01972, quant_loss: 1.94922, bit_balance_loss: 0.00010) batch_time=0.35395 
Train Epoch: 43 [166/250 21248/32000 (66%)] Loss: 1.97030 (semantic_loss: 0.02000, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.31692 
Train Epoch: 43 [177/250 22656/32000 (71%)] Loss: 1.96794 (semantic_loss: 0.01861, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=0.31912 
Train Epoch: 43 [188/250 24064/32000 (75%)] Loss: 1.97043 (semantic_loss: 0.02111, quant_loss: 1.94922, bit_balance_loss: 0.00010) batch_time=0.33035 
Train Epoch: 43 [199/250 25472/32000 (80%)] Loss: 1.97114 (semantic_loss: 0.02084, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.32367 
Train Epoch: 43 [210/250 26880/32000 (84%)] Loss: 1.96958 (semantic_loss: 0.02026, quant_loss: 1.94922, bit_balance_loss: 0.00010) batch_time=0.32700 
Train Epoch: 43 [221/250 28288/32000 (88%)] Loss: 1.97087 (semantic_loss: 0.02057, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.34860 
Train Epoch: 43 [232/250 29696/32000 (93%)] Loss: 1.97023 (semantic_loss: 0.02091, quant_loss: 1.94922, bit_balance_loss: 0.00010) batch_time=0.33721 
Train Epoch: 43 [243/250 31104/32000 (97%)] Loss: 1.97080 (semantic_loss: 0.02050, quant_loss: 1.95020, bit_balance_loss: 0.00010) batch_time=0.35447 
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/DCMH_LSMDC/checkpoint-epoch43.pth ...
Done in 4.365s
removing stale ckpt [epoch 42] [took 0.00s]
 epoch          : 43
 loss           : 1.970609007358551
 learning_rate  : 5.799111065000278e-06
 n_samples      : 1376000
 n_steps        : 10750
 LSMDC_full_test/t2v_metrics/R1: 9.6
 LSMDC_full_test/t2v_metrics/R5: 25.5
 LSMDC_full_test/t2v_metrics/R10: 35.9
 LSMDC_full_test/t2v_metrics/R50: 65.6
 LSMDC_full_test/t2v_metrics/MedR: 22.0
 LSMDC_full_test/t2v_metrics/MeanR: 75.3415
 LSMDC_full_test/t2v_metrics/geometric_mean_R1-R5-R10: 20.636464150029962
 LSMDC_full_test/v2t_metrics/R1: 8.7
 LSMDC_full_test/v2t_metrics/R5: 25.6
 LSMDC_full_test/v2t_metrics/R10: 36.3
 LSMDC_full_test/v2t_metrics/R50: 65.2
 LSMDC_full_test/v2t_metrics/MedR: 23.0
 LSMDC_full_test/v2t_metrics/MeanR: 76.9915
 LSMDC_full_test/v2t_metrics/geometric_mean_R1-R5-R10: 20.07036547797495
 mnt_best       : 20.915725746859103
 not_improved_count: 12
Train Epoch: 44 [1/250 128/32000 (0%)] Loss: 1.96953 (semantic_loss: 0.01923, quant_loss: 1.95020, bit_balance_loss: 0.00010) batch_time=17.57166 
Train Epoch: 44 [12/250 1536/32000 (5%)] Loss: 1.97125 (semantic_loss: 0.02193, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=0.33179 
Train Epoch: 44 [23/250 2944/32000 (9%)] Loss: 1.97054 (semantic_loss: 0.02024, quant_loss: 1.95020, bit_balance_loss: 0.00010) batch_time=0.31809 
Train Epoch: 44 [34/250 4352/32000 (14%)] Loss: 1.97321 (semantic_loss: 0.02291, quant_loss: 1.95020, bit_balance_loss: 0.00010) batch_time=0.35250 
Train Epoch: 44 [45/250 5760/32000 (18%)] Loss: 1.97247 (semantic_loss: 0.02120, quant_loss: 1.95117, bit_balance_loss: 0.00010) batch_time=0.36300 
Train Epoch: 44 [56/250 7168/32000 (22%)] Loss: 1.97024 (semantic_loss: 0.02092, quant_loss: 1.94922, bit_balance_loss: 0.00010) batch_time=0.32687 
Train Epoch: 44 [67/250 8576/32000 (27%)] Loss: 1.97049 (semantic_loss: 0.02117, quant_loss: 1.94922, bit_balance_loss: 0.00010) batch_time=0.34281 
Train Epoch: 44 [78/250 9984/32000 (31%)] Loss: 1.96898 (semantic_loss: 0.01966, quant_loss: 1.94922, bit_balance_loss: 0.00010) batch_time=0.33031 
Train Epoch: 44 [89/250 11392/32000 (36%)] Loss: 1.97191 (semantic_loss: 0.02161, quant_loss: 1.95020, bit_balance_loss: 0.00010) batch_time=0.33243 
Train Epoch: 44 [100/250 12800/32000 (40%)] Loss: 1.96975 (semantic_loss: 0.02042, quant_loss: 1.94922, bit_balance_loss: 0.00010) batch_time=0.34040 
Train Epoch: 44 [111/250 14208/32000 (44%)] Loss: 1.96969 (semantic_loss: 0.01939, quant_loss: 1.95020, bit_balance_loss: 0.00010) batch_time=0.31644 
Train Epoch: 44 [122/250 15616/32000 (49%)] Loss: 1.97372 (semantic_loss: 0.02244, quant_loss: 1.95117, bit_balance_loss: 0.00010) batch_time=0.34483 
Train Epoch: 44 [133/250 17024/32000 (53%)] Loss: 1.96968 (semantic_loss: 0.02036, quant_loss: 1.94922, bit_balance_loss: 0.00010) batch_time=0.34342 
Train Epoch: 44 [144/250 18432/32000 (58%)] Loss: 1.96988 (semantic_loss: 0.01959, quant_loss: 1.95020, bit_balance_loss: 0.00010) batch_time=0.35127 
Train Epoch: 44 [155/250 19840/32000 (62%)] Loss: 1.97061 (semantic_loss: 0.02031, quant_loss: 1.95020, bit_balance_loss: 0.00010) batch_time=0.32676 
Train Epoch: 44 [166/250 21248/32000 (66%)] Loss: 1.96966 (semantic_loss: 0.02033, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=0.34395 
Train Epoch: 44 [177/250 22656/32000 (71%)] Loss: 1.97209 (semantic_loss: 0.02277, quant_loss: 1.94922, bit_balance_loss: 0.00010) batch_time=0.32282 
Train Epoch: 44 [188/250 24064/32000 (75%)] Loss: 1.97076 (semantic_loss: 0.02143, quant_loss: 1.94922, bit_balance_loss: 0.00010) batch_time=0.31891 
Train Epoch: 44 [199/250 25472/32000 (80%)] Loss: 1.96970 (semantic_loss: 0.02037, quant_loss: 1.94922, bit_balance_loss: 0.00010) batch_time=0.32669 
Train Epoch: 44 [210/250 26880/32000 (84%)] Loss: 1.97040 (semantic_loss: 0.02108, quant_loss: 1.94922, bit_balance_loss: 0.00010) batch_time=0.34657 
Train Epoch: 44 [221/250 28288/32000 (88%)] Loss: 1.96999 (semantic_loss: 0.02066, quant_loss: 1.94922, bit_balance_loss: 0.00010) batch_time=0.32510 
Train Epoch: 44 [232/250 29696/32000 (93%)] Loss: 1.97242 (semantic_loss: 0.02309, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=0.35390 
Train Epoch: 44 [243/250 31104/32000 (97%)] Loss: 1.97202 (semantic_loss: 0.02173, quant_loss: 1.95020, bit_balance_loss: 0.00010) batch_time=0.33148 
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/DCMH_LSMDC/checkpoint-epoch44.pth ...
Done in 4.688s
removing stale ckpt [epoch 43] [took 0.00s]
 epoch          : 44
 loss           : 1.970663477897644
 learning_rate  : 5.5091555117502635e-06
 n_samples      : 1408000
 n_steps        : 11000
 LSMDC_full_test/t2v_metrics/R1: 8.8
 LSMDC_full_test/t2v_metrics/R5: 26.6
 LSMDC_full_test/t2v_metrics/R10: 36.4
 LSMDC_full_test/t2v_metrics/R50: 65.6
 LSMDC_full_test/t2v_metrics/MedR: 22.0
 LSMDC_full_test/t2v_metrics/MeanR: 76.1355
 LSMDC_full_test/t2v_metrics/geometric_mean_R1-R5-R10: 20.42467857890862
 LSMDC_full_test/v2t_metrics/R1: 8.9
 LSMDC_full_test/v2t_metrics/R5: 24.9
 LSMDC_full_test/v2t_metrics/R10: 35.9
 LSMDC_full_test/v2t_metrics/R50: 65.1
 LSMDC_full_test/v2t_metrics/MedR: 22.5
 LSMDC_full_test/v2t_metrics/MeanR: 78.847
 LSMDC_full_test/v2t_metrics/geometric_mean_R1-R5-R10: 19.963097786542473
 mnt_best       : 20.915725746859103
 not_improved_count: 13
Train Epoch: 45 [1/250 128/32000 (0%)] Loss: 1.97061 (semantic_loss: 0.02129, quant_loss: 1.94922, bit_balance_loss: 0.00010) batch_time=13.71336 
Train Epoch: 45 [12/250 1536/32000 (5%)] Loss: 1.96821 (semantic_loss: 0.01987, quant_loss: 1.94824, bit_balance_loss: 0.00010) batch_time=0.33200 
Train Epoch: 45 [23/250 2944/32000 (9%)] Loss: 1.97283 (semantic_loss: 0.02253, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.32582 
Train Epoch: 45 [34/250 4352/32000 (14%)] Loss: 1.97033 (semantic_loss: 0.02100, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=0.32621 
Train Epoch: 45 [45/250 5760/32000 (18%)] Loss: 1.96971 (semantic_loss: 0.02039, quant_loss: 1.94922, bit_balance_loss: 0.00010) batch_time=0.34602 
Train Epoch: 45 [56/250 7168/32000 (22%)] Loss: 1.97096 (semantic_loss: 0.02066, quant_loss: 1.95020, bit_balance_loss: 0.00010) batch_time=0.34438 
Train Epoch: 45 [67/250 8576/32000 (27%)] Loss: 1.97320 (semantic_loss: 0.02290, quant_loss: 1.95020, bit_balance_loss: 0.00010) batch_time=1.53502 
Train Epoch: 45 [78/250 9984/32000 (31%)] Loss: 1.96932 (semantic_loss: 0.02000, quant_loss: 1.94922, bit_balance_loss: 0.00010) batch_time=0.53289 
Train Epoch: 45 [89/250 11392/32000 (36%)] Loss: 1.96903 (semantic_loss: 0.01971, quant_loss: 1.94922, bit_balance_loss: 0.00010) batch_time=0.33238 
Train Epoch: 45 [100/250 12800/32000 (40%)] Loss: 1.96989 (semantic_loss: 0.01959, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.37353 
Train Epoch: 45 [111/250 14208/32000 (44%)] Loss: 1.96869 (semantic_loss: 0.01937, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=0.33028 
Train Epoch: 45 [122/250 15616/32000 (49%)] Loss: 1.96972 (semantic_loss: 0.01942, quant_loss: 1.95020, bit_balance_loss: 0.00010) batch_time=0.33228 
Train Epoch: 45 [133/250 17024/32000 (53%)] Loss: 1.97145 (semantic_loss: 0.02115, quant_loss: 1.95020, bit_balance_loss: 0.00010) batch_time=0.31845 
Train Epoch: 45 [144/250 18432/32000 (58%)] Loss: 1.96952 (semantic_loss: 0.02020, quant_loss: 1.94922, bit_balance_loss: 0.00010) batch_time=0.33043 
Train Epoch: 45 [155/250 19840/32000 (62%)] Loss: 1.97035 (semantic_loss: 0.02005, quant_loss: 1.95020, bit_balance_loss: 0.00010) batch_time=0.31908 
Train Epoch: 45 [166/250 21248/32000 (66%)] Loss: 1.96870 (semantic_loss: 0.01937, quant_loss: 1.94922, bit_balance_loss: 0.00010) batch_time=0.31581 
Train Epoch: 45 [177/250 22656/32000 (71%)] Loss: 1.96876 (semantic_loss: 0.01944, quant_loss: 1.94922, bit_balance_loss: 0.00010) batch_time=0.32989 
Train Epoch: 45 [188/250 24064/32000 (75%)] Loss: 1.96889 (semantic_loss: 0.01956, quant_loss: 1.94922, bit_balance_loss: 0.00010) batch_time=0.32773 
Train Epoch: 45 [199/250 25472/32000 (80%)] Loss: 1.97028 (semantic_loss: 0.01998, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.32533 
Train Epoch: 45 [210/250 26880/32000 (84%)] Loss: 1.97040 (semantic_loss: 0.02107, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=0.77359 
Train Epoch: 45 [221/250 28288/32000 (88%)] Loss: 1.97100 (semantic_loss: 0.02070, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.32444 
Train Epoch: 45 [232/250 29696/32000 (93%)] Loss: 1.96966 (semantic_loss: 0.02034, quant_loss: 1.94922, bit_balance_loss: 0.00010) batch_time=0.32077 
Train Epoch: 45 [243/250 31104/32000 (97%)] Loss: 1.97112 (semantic_loss: 0.02082, quant_loss: 1.95020, bit_balance_loss: 0.00010) batch_time=0.32663 
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/DCMH_LSMDC/checkpoint-epoch45.pth ...
Done in 4.948s
removing stale ckpt [epoch 44] [took 0.00s]
 epoch          : 45
 loss           : 1.9705582313537597
 learning_rate  : 5.23369773616275e-06
 n_samples      : 1440000
 n_steps        : 11250
 LSMDC_full_test/t2v_metrics/R1: 9.4
 LSMDC_full_test/t2v_metrics/R5: 25.7
 LSMDC_full_test/t2v_metrics/R10: 35.8
 LSMDC_full_test/t2v_metrics/R50: 65.5
 LSMDC_full_test/t2v_metrics/MedR: 22.0
 LSMDC_full_test/t2v_metrics/MeanR: 75.4755
 LSMDC_full_test/t2v_metrics/geometric_mean_R1-R5-R10: 20.526488859285635
 LSMDC_full_test/v2t_metrics/R1: 8.5
 LSMDC_full_test/v2t_metrics/R5: 25.1
 LSMDC_full_test/v2t_metrics/R10: 36.3
 LSMDC_full_test/v2t_metrics/R50: 65.7
 LSMDC_full_test/v2t_metrics/MedR: 22.5
 LSMDC_full_test/v2t_metrics/MeanR: 77.5765
 LSMDC_full_test/v2t_metrics/geometric_mean_R1-R5-R10: 19.78486497702027
 mnt_best       : 20.915725746859103
 not_improved_count: 14
Train Epoch: 46 [1/250 128/32000 (0%)] Loss: 1.97056 (semantic_loss: 0.02026, quant_loss: 1.95020, bit_balance_loss: 0.00010) batch_time=17.89875 
Train Epoch: 46 [12/250 1536/32000 (5%)] Loss: 1.96950 (semantic_loss: 0.01920, quant_loss: 1.95020, bit_balance_loss: 0.00010) batch_time=0.34452 
Train Epoch: 46 [23/250 2944/32000 (9%)] Loss: 1.97059 (semantic_loss: 0.02030, quant_loss: 1.95020, bit_balance_loss: 0.00010) batch_time=0.34286 
Train Epoch: 46 [34/250 4352/32000 (14%)] Loss: 1.97130 (semantic_loss: 0.02100, quant_loss: 1.95020, bit_balance_loss: 0.00010) batch_time=0.34390 
Train Epoch: 46 [45/250 5760/32000 (18%)] Loss: 1.97108 (semantic_loss: 0.02176, quant_loss: 1.94922, bit_balance_loss: 0.00010) batch_time=0.34131 
Train Epoch: 46 [56/250 7168/32000 (22%)] Loss: 1.97120 (semantic_loss: 0.02090, quant_loss: 1.95020, bit_balance_loss: 0.00010) batch_time=0.32528 
Train Epoch: 46 [67/250 8576/32000 (27%)] Loss: 1.96989 (semantic_loss: 0.02056, quant_loss: 1.94922, bit_balance_loss: 0.00010) batch_time=0.34635 
Train Epoch: 46 [78/250 9984/32000 (31%)] Loss: 1.97073 (semantic_loss: 0.02141, quant_loss: 1.94922, bit_balance_loss: 0.00010) batch_time=1.17806 
Train Epoch: 46 [89/250 11392/32000 (36%)] Loss: 1.97043 (semantic_loss: 0.02111, quant_loss: 1.94922, bit_balance_loss: 0.00010) batch_time=0.35084 
Train Epoch: 46 [100/250 12800/32000 (40%)] Loss: 1.97237 (semantic_loss: 0.02207, quant_loss: 1.95020, bit_balance_loss: 0.00010) batch_time=0.32900 
Train Epoch: 46 [111/250 14208/32000 (44%)] Loss: 1.97063 (semantic_loss: 0.02033, quant_loss: 1.95020, bit_balance_loss: 0.00010) batch_time=0.32379 
Train Epoch: 46 [122/250 15616/32000 (49%)] Loss: 1.97023 (semantic_loss: 0.01993, quant_loss: 1.95020, bit_balance_loss: 0.00010) batch_time=0.35615 
Train Epoch: 46 [133/250 17024/32000 (53%)] Loss: 1.96904 (semantic_loss: 0.01972, quant_loss: 1.94922, bit_balance_loss: 0.00010) batch_time=0.32550 
Train Epoch: 46 [144/250 18432/32000 (58%)] Loss: 1.97098 (semantic_loss: 0.02068, quant_loss: 1.95020, bit_balance_loss: 0.00010) batch_time=0.32344 
Train Epoch: 46 [155/250 19840/32000 (62%)] Loss: 1.96998 (semantic_loss: 0.02066, quant_loss: 1.94922, bit_balance_loss: 0.00010) batch_time=0.36940 
Train Epoch: 46 [166/250 21248/32000 (66%)] Loss: 1.97189 (semantic_loss: 0.02159, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.33598 
Train Epoch: 46 [177/250 22656/32000 (71%)] Loss: 1.96987 (semantic_loss: 0.02054, quant_loss: 1.94922, bit_balance_loss: 0.00010) batch_time=0.35680 
Train Epoch: 46 [188/250 24064/32000 (75%)] Loss: 1.96881 (semantic_loss: 0.01851, quant_loss: 1.95020, bit_balance_loss: 0.00010) batch_time=0.35220 
Train Epoch: 46 [199/250 25472/32000 (80%)] Loss: 1.97032 (semantic_loss: 0.02003, quant_loss: 1.95020, bit_balance_loss: 0.00010) batch_time=3.83370 
Train Epoch: 46 [210/250 26880/32000 (84%)] Loss: 1.97099 (semantic_loss: 0.02069, quant_loss: 1.95020, bit_balance_loss: 0.00010) batch_time=1.14693 
Train Epoch: 46 [221/250 28288/32000 (88%)] Loss: 1.97011 (semantic_loss: 0.01981, quant_loss: 1.95020, bit_balance_loss: 0.00010) batch_time=0.37053 
Train Epoch: 46 [232/250 29696/32000 (93%)] Loss: 1.97189 (semantic_loss: 0.02159, quant_loss: 1.95020, bit_balance_loss: 0.00010) batch_time=0.32536 
Train Epoch: 46 [243/250 31104/32000 (97%)] Loss: 1.97325 (semantic_loss: 0.02393, quant_loss: 1.94922, bit_balance_loss: 0.00010) batch_time=0.35667 
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/DCMH_LSMDC/checkpoint-epoch46.pth ...
Done in 4.025s
removing stale ckpt [epoch 45] [took 0.00s]
 epoch          : 46
 loss           : 1.9704087505340575
 learning_rate  : 4.972012849354612e-06
 n_samples      : 1472000
 n_steps        : 11500
 LSMDC_full_test/t2v_metrics/R1: 9.7
 LSMDC_full_test/t2v_metrics/R5: 26.1
 LSMDC_full_test/t2v_metrics/R10: 36.0
 LSMDC_full_test/t2v_metrics/R50: 65.7
 LSMDC_full_test/t2v_metrics/MedR: 21.5
 LSMDC_full_test/t2v_metrics/MeanR: 76.6825
 LSMDC_full_test/t2v_metrics/geometric_mean_R1-R5-R10: 20.888387434938483
 LSMDC_full_test/v2t_metrics/R1: 9.3
 LSMDC_full_test/v2t_metrics/R5: 25.8
 LSMDC_full_test/v2t_metrics/R10: 36.3
 LSMDC_full_test/v2t_metrics/R50: 65.6
 LSMDC_full_test/v2t_metrics/MedR: 22.0
 LSMDC_full_test/v2t_metrics/MeanR: 78.66
 LSMDC_full_test/v2t_metrics/geometric_mean_R1-R5-R10: 20.574838100544632
 mnt_best       : 20.915725746859103
 not_improved_count: 15
Train Epoch: 47 [1/250 128/32000 (0%)] Loss: 1.97053 (semantic_loss: 0.02023, quant_loss: 1.95020, bit_balance_loss: 0.00010) batch_time=28.55976 
Train Epoch: 47 [12/250 1536/32000 (5%)] Loss: 1.97092 (semantic_loss: 0.02160, quant_loss: 1.94922, bit_balance_loss: 0.00010) batch_time=0.31515 
Train Epoch: 47 [23/250 2944/32000 (9%)] Loss: 1.97139 (semantic_loss: 0.02109, quant_loss: 1.95020, bit_balance_loss: 0.00010) batch_time=1.10071 
Train Epoch: 47 [34/250 4352/32000 (14%)] Loss: 1.97027 (semantic_loss: 0.02094, quant_loss: 1.94922, bit_balance_loss: 0.00010) batch_time=0.33189 
Train Epoch: 47 [45/250 5760/32000 (18%)] Loss: 1.97104 (semantic_loss: 0.02075, quant_loss: 1.95020, bit_balance_loss: 0.00010) batch_time=0.33341 
Train Epoch: 47 [56/250 7168/32000 (22%)] Loss: 1.97215 (semantic_loss: 0.02283, quant_loss: 1.94922, bit_balance_loss: 0.00010) batch_time=0.34041 
Train Epoch: 47 [67/250 8576/32000 (27%)] Loss: 1.97131 (semantic_loss: 0.02101, quant_loss: 1.95020, bit_balance_loss: 0.00010) batch_time=0.33030 
Train Epoch: 47 [78/250 9984/32000 (31%)] Loss: 1.97125 (semantic_loss: 0.02095, quant_loss: 1.95020, bit_balance_loss: 0.00010) batch_time=0.37125 
Train Epoch: 47 [89/250 11392/32000 (36%)] Loss: 1.97044 (semantic_loss: 0.02112, quant_loss: 1.94922, bit_balance_loss: 0.00010) batch_time=0.46343 
Train Epoch: 47 [100/250 12800/32000 (40%)] Loss: 1.97042 (semantic_loss: 0.02110, quant_loss: 1.94922, bit_balance_loss: 0.00010) batch_time=0.36066 
Train Epoch: 47 [111/250 14208/32000 (44%)] Loss: 1.96897 (semantic_loss: 0.01965, quant_loss: 1.94922, bit_balance_loss: 0.00010) batch_time=0.33983 
Train Epoch: 47 [122/250 15616/32000 (49%)] Loss: 1.97115 (semantic_loss: 0.02183, quant_loss: 1.94922, bit_balance_loss: 0.00010) batch_time=0.32048 
Train Epoch: 47 [133/250 17024/32000 (53%)] Loss: 1.97167 (semantic_loss: 0.02235, quant_loss: 1.94922, bit_balance_loss: 0.00010) batch_time=0.33377 
Train Epoch: 47 [144/250 18432/32000 (58%)] Loss: 1.97178 (semantic_loss: 0.02148, quant_loss: 1.95020, bit_balance_loss: 0.00010) batch_time=0.31868 
Train Epoch: 47 [155/250 19840/32000 (62%)] Loss: 1.96987 (semantic_loss: 0.01957, quant_loss: 1.95020, bit_balance_loss: 0.00010) batch_time=0.31927 
Train Epoch: 47 [166/250 21248/32000 (66%)] Loss: 1.97019 (semantic_loss: 0.02087, quant_loss: 1.94922, bit_balance_loss: 0.00010) batch_time=0.34281 
Train Epoch: 47 [177/250 22656/32000 (71%)] Loss: 1.97018 (semantic_loss: 0.02086, quant_loss: 1.94922, bit_balance_loss: 0.00010) batch_time=0.33874 
Train Epoch: 47 [188/250 24064/32000 (75%)] Loss: 1.96999 (semantic_loss: 0.01970, quant_loss: 1.95020, bit_balance_loss: 0.00010) batch_time=0.37963 
Train Epoch: 47 [199/250 25472/32000 (80%)] Loss: 1.96872 (semantic_loss: 0.01939, quant_loss: 1.94922, bit_balance_loss: 0.00010) batch_time=0.31935 
Train Epoch: 47 [210/250 26880/32000 (84%)] Loss: 1.97072 (semantic_loss: 0.02042, quant_loss: 1.95020, bit_balance_loss: 0.00010) batch_time=0.31756 
Train Epoch: 47 [221/250 28288/32000 (88%)] Loss: 1.97014 (semantic_loss: 0.01984, quant_loss: 1.95020, bit_balance_loss: 0.00010) batch_time=0.32783 
Train Epoch: 47 [232/250 29696/32000 (93%)] Loss: 1.97029 (semantic_loss: 0.01999, quant_loss: 1.95020, bit_balance_loss: 0.00010) batch_time=0.32604 
Train Epoch: 47 [243/250 31104/32000 (97%)] Loss: 1.96897 (semantic_loss: 0.01867, quant_loss: 1.95020, bit_balance_loss: 0.00010) batch_time=0.32481 
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/DCMH_LSMDC/checkpoint-epoch47.pth ...
Done in 4.818s
removing stale ckpt [epoch 46] [took 0.00s]
 epoch          : 47
 loss           : 1.9704121975898743
 learning_rate  : 4.723412206886882e-06
 n_samples      : 1504000
 n_steps        : 11750
 LSMDC_full_test/t2v_metrics/R1: 9.6
 LSMDC_full_test/t2v_metrics/R5: 26.0
 LSMDC_full_test/t2v_metrics/R10: 36.1
 LSMDC_full_test/t2v_metrics/R50: 65.9
 LSMDC_full_test/t2v_metrics/MedR: 22.0
 LSMDC_full_test/t2v_metrics/MeanR: 75.7195
 LSMDC_full_test/t2v_metrics/geometric_mean_R1-R5-R10: 20.808970489683336
 LSMDC_full_test/v2t_metrics/R1: 8.9
 LSMDC_full_test/v2t_metrics/R5: 25.7
 LSMDC_full_test/v2t_metrics/R10: 35.4
 LSMDC_full_test/v2t_metrics/R50: 66.0
 LSMDC_full_test/v2t_metrics/MedR: 23.0
 LSMDC_full_test/v2t_metrics/MeanR: 78.338
 LSMDC_full_test/v2t_metrics/geometric_mean_R1-R5-R10: 20.0805435348605
 mnt_best       : 20.915725746859103
 not_improved_count: 16
Train Epoch: 48 [1/250 128/32000 (0%)] Loss: 1.97025 (semantic_loss: 0.01995, quant_loss: 1.95020, bit_balance_loss: 0.00010) batch_time=12.60103 
Train Epoch: 48 [12/250 1536/32000 (5%)] Loss: 1.96995 (semantic_loss: 0.01965, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=3.02042 
Train Epoch: 48 [23/250 2944/32000 (9%)] Loss: 1.97080 (semantic_loss: 0.02050, quant_loss: 1.95020, bit_balance_loss: 0.00010) batch_time=2.05764 
Train Epoch: 48 [34/250 4352/32000 (14%)] Loss: 1.96930 (semantic_loss: 0.01998, quant_loss: 1.94922, bit_balance_loss: 0.00010) batch_time=0.35424 
Train Epoch: 48 [45/250 5760/32000 (18%)] Loss: 1.97053 (semantic_loss: 0.02023, quant_loss: 1.95020, bit_balance_loss: 0.00010) batch_time=0.33503 
Train Epoch: 48 [56/250 7168/32000 (22%)] Loss: 1.97001 (semantic_loss: 0.01971, quant_loss: 1.95020, bit_balance_loss: 0.00010) batch_time=0.32573 
Train Epoch: 48 [67/250 8576/32000 (27%)] Loss: 1.97332 (semantic_loss: 0.02204, quant_loss: 1.95117, bit_balance_loss: 0.00010) batch_time=0.49095 
Train Epoch: 48 [78/250 9984/32000 (31%)] Loss: 1.97023 (semantic_loss: 0.01992, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.32847 
Train Epoch: 48 [89/250 11392/32000 (36%)] Loss: 1.97030 (semantic_loss: 0.02001, quant_loss: 1.95020, bit_balance_loss: 0.00010) batch_time=0.32601 
Train Epoch: 48 [100/250 12800/32000 (40%)] Loss: 1.97022 (semantic_loss: 0.01992, quant_loss: 1.95020, bit_balance_loss: 0.00010) batch_time=0.33285 
Train Epoch: 48 [111/250 14208/32000 (44%)] Loss: 1.97067 (semantic_loss: 0.02037, quant_loss: 1.95020, bit_balance_loss: 0.00010) batch_time=0.33714 
Train Epoch: 48 [122/250 15616/32000 (49%)] Loss: 1.96906 (semantic_loss: 0.01974, quant_loss: 1.94922, bit_balance_loss: 0.00010) batch_time=0.33653 
Train Epoch: 48 [133/250 17024/32000 (53%)] Loss: 1.97040 (semantic_loss: 0.02010, quant_loss: 1.95020, bit_balance_loss: 0.00010) batch_time=0.34420 
Train Epoch: 48 [144/250 18432/32000 (58%)] Loss: 1.96946 (semantic_loss: 0.02013, quant_loss: 1.94922, bit_balance_loss: 0.00010) batch_time=0.32785 
Train Epoch: 48 [155/250 19840/32000 (62%)] Loss: 1.97044 (semantic_loss: 0.02014, quant_loss: 1.95020, bit_balance_loss: 0.00010) batch_time=0.34820 
Train Epoch: 48 [166/250 21248/32000 (66%)] Loss: 1.97133 (semantic_loss: 0.02103, quant_loss: 1.95020, bit_balance_loss: 0.00010) batch_time=0.35439 
Train Epoch: 48 [177/250 22656/32000 (71%)] Loss: 1.96894 (semantic_loss: 0.01864, quant_loss: 1.95020, bit_balance_loss: 0.00010) batch_time=0.32790 
Train Epoch: 48 [188/250 24064/32000 (75%)] Loss: 1.96834 (semantic_loss: 0.01901, quant_loss: 1.94922, bit_balance_loss: 0.00010) batch_time=0.33168 
Train Epoch: 48 [199/250 25472/32000 (80%)] Loss: 1.97060 (semantic_loss: 0.02031, quant_loss: 1.95020, bit_balance_loss: 0.00010) batch_time=0.33399 
Train Epoch: 48 [210/250 26880/32000 (84%)] Loss: 1.96879 (semantic_loss: 0.01947, quant_loss: 1.94922, bit_balance_loss: 0.00010) batch_time=0.34573 
Train Epoch: 48 [221/250 28288/32000 (88%)] Loss: 1.96954 (semantic_loss: 0.01925, quant_loss: 1.95020, bit_balance_loss: 0.00010) batch_time=0.33187 
Train Epoch: 48 [232/250 29696/32000 (93%)] Loss: 1.96950 (semantic_loss: 0.02018, quant_loss: 1.94922, bit_balance_loss: 0.00010) batch_time=0.54053 
Train Epoch: 48 [243/250 31104/32000 (97%)] Loss: 1.96940 (semantic_loss: 0.02008, quant_loss: 1.94922, bit_balance_loss: 0.00010) batch_time=0.33109 
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/DCMH_LSMDC/checkpoint-epoch48.pth ...
Done in 4.356s
Updating 'best' checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/DCMH_LSMDC/checkpoint-epoch48.pth ...
Done in 9.057s
removing stale ckpt [epoch 47] [took 0.01s]
 epoch          : 48
 loss           : 1.9703529601097107
 learning_rate  : 4.487241596542537e-06
 n_samples      : 1536000
 n_steps        : 12000
 LSMDC_full_test/t2v_metrics/R1: 10.0
 LSMDC_full_test/t2v_metrics/R5: 25.8
 LSMDC_full_test/t2v_metrics/R10: 36.0
 LSMDC_full_test/t2v_metrics/R50: 66.3
 LSMDC_full_test/t2v_metrics/MedR: 22.0
 LSMDC_full_test/t2v_metrics/MeanR: 75.841
 LSMDC_full_test/t2v_metrics/geometric_mean_R1-R5-R10: 21.020388362320357
 LSMDC_full_test/v2t_metrics/R1: 9.6
 LSMDC_full_test/v2t_metrics/R5: 25.8
 LSMDC_full_test/v2t_metrics/R10: 36.4
 LSMDC_full_test/v2t_metrics/R50: 65.4
 LSMDC_full_test/v2t_metrics/MedR: 22.75
 LSMDC_full_test/v2t_metrics/MeanR: 78.365
 LSMDC_full_test/v2t_metrics/geometric_mean_R1-R5-R10: 20.81281261873847
 mnt_best       : 21.020388362320357
 not_improved_count: 0
Train Epoch: 49 [1/250 128/32000 (0%)] Loss: 1.97142 (semantic_loss: 0.02112, quant_loss: 1.95020, bit_balance_loss: 0.00010) batch_time=19.81417 
Train Epoch: 49 [12/250 1536/32000 (5%)] Loss: 1.97021 (semantic_loss: 0.02089, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=0.33133 
Train Epoch: 49 [23/250 2944/32000 (9%)] Loss: 1.96952 (semantic_loss: 0.02020, quant_loss: 1.94922, bit_balance_loss: 0.00010) batch_time=0.32438 
Train Epoch: 49 [34/250 4352/32000 (14%)] Loss: 1.97019 (semantic_loss: 0.01989, quant_loss: 1.95020, bit_balance_loss: 0.00010) batch_time=0.32668 
Train Epoch: 49 [45/250 5760/32000 (18%)] Loss: 1.97086 (semantic_loss: 0.02057, quant_loss: 1.95020, bit_balance_loss: 0.00010) batch_time=0.33343 
Train Epoch: 49 [56/250 7168/32000 (22%)] Loss: 1.97007 (semantic_loss: 0.02172, quant_loss: 1.94824, bit_balance_loss: 0.00010) batch_time=0.31654 
Train Epoch: 49 [67/250 8576/32000 (27%)] Loss: 1.97131 (semantic_loss: 0.02101, quant_loss: 1.95020, bit_balance_loss: 0.00010) batch_time=0.34030 
Train Epoch: 49 [78/250 9984/32000 (31%)] Loss: 1.96971 (semantic_loss: 0.02039, quant_loss: 1.94922, bit_balance_loss: 0.00010) batch_time=0.31945 
Train Epoch: 49 [89/250 11392/32000 (36%)] Loss: 1.96912 (semantic_loss: 0.01980, quant_loss: 1.94922, bit_balance_loss: 0.00010) batch_time=3.25855 
Train Epoch: 49 [100/250 12800/32000 (40%)] Loss: 1.96973 (semantic_loss: 0.02041, quant_loss: 1.94922, bit_balance_loss: 0.00010) batch_time=0.34040 
Train Epoch: 49 [111/250 14208/32000 (44%)] Loss: 1.96861 (semantic_loss: 0.01831, quant_loss: 1.95020, bit_balance_loss: 0.00010) batch_time=0.38118 
Train Epoch: 49 [122/250 15616/32000 (49%)] Loss: 1.97065 (semantic_loss: 0.02035, quant_loss: 1.95020, bit_balance_loss: 0.00010) batch_time=0.31707 
Train Epoch: 49 [133/250 17024/32000 (53%)] Loss: 1.96882 (semantic_loss: 0.01950, quant_loss: 1.94922, bit_balance_loss: 0.00010) batch_time=0.36036 
Train Epoch: 49 [144/250 18432/32000 (58%)] Loss: 1.96908 (semantic_loss: 0.01976, quant_loss: 1.94922, bit_balance_loss: 0.00010) batch_time=1.68840 
Train Epoch: 49 [155/250 19840/32000 (62%)] Loss: 1.96941 (semantic_loss: 0.01911, quant_loss: 1.95020, bit_balance_loss: 0.00010) batch_time=0.37049 
Train Epoch: 49 [166/250 21248/32000 (66%)] Loss: 1.97094 (semantic_loss: 0.02161, quant_loss: 1.94922, bit_balance_loss: 0.00010) batch_time=0.31647 
Train Epoch: 49 [177/250 22656/32000 (71%)] Loss: 1.97168 (semantic_loss: 0.02138, quant_loss: 1.95020, bit_balance_loss: 0.00010) batch_time=0.31690 
Train Epoch: 49 [188/250 24064/32000 (75%)] Loss: 1.97077 (semantic_loss: 0.02048, quant_loss: 1.95020, bit_balance_loss: 0.00010) batch_time=0.33106 
Train Epoch: 49 [199/250 25472/32000 (80%)] Loss: 1.96891 (semantic_loss: 0.01959, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=0.35728 
Train Epoch: 49 [210/250 26880/32000 (84%)] Loss: 1.97107 (semantic_loss: 0.02175, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=0.34347 
Train Epoch: 49 [221/250 28288/32000 (88%)] Loss: 1.96958 (semantic_loss: 0.02026, quant_loss: 1.94922, bit_balance_loss: 0.00010) batch_time=0.80577 
Train Epoch: 49 [232/250 29696/32000 (93%)] Loss: 1.97028 (semantic_loss: 0.01998, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.34676 
Train Epoch: 49 [243/250 31104/32000 (97%)] Loss: 1.97019 (semantic_loss: 0.01990, quant_loss: 1.95020, bit_balance_loss: 0.00010) batch_time=0.34024 
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/DCMH_LSMDC/checkpoint-epoch49.pth ...
Done in 4.331s
removing stale ckpt [epoch 48] [took 0.00s]
 epoch          : 49
 loss           : 1.9701689624786376
 learning_rate  : 4.26287951671541e-06
 n_samples      : 1568000
 n_steps        : 12250
 LSMDC_full_test/t2v_metrics/R1: 9.3
 LSMDC_full_test/t2v_metrics/R5: 26.4
 LSMDC_full_test/t2v_metrics/R10: 35.7
 LSMDC_full_test/t2v_metrics/R50: 66.0
 LSMDC_full_test/t2v_metrics/MedR: 22.5
 LSMDC_full_test/t2v_metrics/MeanR: 75.5825
 LSMDC_full_test/t2v_metrics/geometric_mean_R1-R5-R10: 20.618245060643662
 LSMDC_full_test/v2t_metrics/R1: 9.5
 LSMDC_full_test/v2t_metrics/R5: 26.3
 LSMDC_full_test/v2t_metrics/R10: 36.0
 LSMDC_full_test/v2t_metrics/R50: 65.7
 LSMDC_full_test/v2t_metrics/MedR: 23.0
 LSMDC_full_test/v2t_metrics/MeanR: 77.504
 LSMDC_full_test/v2t_metrics/geometric_mean_R1-R5-R10: 20.796677230561954
 mnt_best       : 21.020388362320357
 not_improved_count: 1
Train Epoch: 50 [1/250 128/32000 (0%)] Loss: 1.96999 (semantic_loss: 0.02164, quant_loss: 1.94824, bit_balance_loss: 0.00010) batch_time=11.97544 
Train Epoch: 50 [12/250 1536/32000 (5%)] Loss: 1.97133 (semantic_loss: 0.02103, quant_loss: 1.95020, bit_balance_loss: 0.00010) batch_time=0.32489 
Train Epoch: 50 [23/250 2944/32000 (9%)] Loss: 1.96999 (semantic_loss: 0.02067, quant_loss: 1.94922, bit_balance_loss: 0.00010) batch_time=0.38843 
Train Epoch: 50 [34/250 4352/32000 (14%)] Loss: 1.97109 (semantic_loss: 0.02079, quant_loss: 1.95020, bit_balance_loss: 0.00010) batch_time=0.36040 
Train Epoch: 50 [45/250 5760/32000 (18%)] Loss: 1.97068 (semantic_loss: 0.02136, quant_loss: 1.94922, bit_balance_loss: 0.00010) batch_time=0.35815 
Train Epoch: 50 [56/250 7168/32000 (22%)] Loss: 1.96993 (semantic_loss: 0.01963, quant_loss: 1.95020, bit_balance_loss: 0.00010) batch_time=0.38239 
Train Epoch: 50 [67/250 8576/32000 (27%)] Loss: 1.97105 (semantic_loss: 0.02075, quant_loss: 1.95020, bit_balance_loss: 0.00010) batch_time=3.97123 
Train Epoch: 50 [78/250 9984/32000 (31%)] Loss: 1.97058 (semantic_loss: 0.02126, quant_loss: 1.94922, bit_balance_loss: 0.00010) batch_time=0.34824 
Train Epoch: 50 [89/250 11392/32000 (36%)] Loss: 1.97140 (semantic_loss: 0.02110, quant_loss: 1.95020, bit_balance_loss: 0.00010) batch_time=0.34020 
Train Epoch: 50 [100/250 12800/32000 (40%)] Loss: 1.96949 (semantic_loss: 0.01919, quant_loss: 1.95020, bit_balance_loss: 0.00010) batch_time=0.35641 
Train Epoch: 50 [111/250 14208/32000 (44%)] Loss: 1.97034 (semantic_loss: 0.02102, quant_loss: 1.94922, bit_balance_loss: 0.00010) batch_time=0.35886 
Train Epoch: 50 [122/250 15616/32000 (49%)] Loss: 1.97034 (semantic_loss: 0.02005, quant_loss: 1.95020, bit_balance_loss: 0.00010) batch_time=0.32739 
Train Epoch: 50 [133/250 17024/32000 (53%)] Loss: 1.97032 (semantic_loss: 0.02003, quant_loss: 1.95020, bit_balance_loss: 0.00010) batch_time=0.34820 
Train Epoch: 50 [144/250 18432/32000 (58%)] Loss: 1.96877 (semantic_loss: 0.01944, quant_loss: 1.94922, bit_balance_loss: 0.00010) batch_time=2.48328 
Train Epoch: 50 [155/250 19840/32000 (62%)] Loss: 1.96889 (semantic_loss: 0.01957, quant_loss: 1.94922, bit_balance_loss: 0.00010) batch_time=0.34886 
Train Epoch: 50 [166/250 21248/32000 (66%)] Loss: 1.97141 (semantic_loss: 0.02111, quant_loss: 1.95020, bit_balance_loss: 0.00010) batch_time=0.75123 
Train Epoch: 50 [177/250 22656/32000 (71%)] Loss: 1.96981 (semantic_loss: 0.01952, quant_loss: 1.95020, bit_balance_loss: 0.00010) batch_time=0.33034 
Train Epoch: 50 [188/250 24064/32000 (75%)] Loss: 1.96926 (semantic_loss: 0.01994, quant_loss: 1.94922, bit_balance_loss: 0.00010) batch_time=0.32901 
Train Epoch: 50 [199/250 25472/32000 (80%)] Loss: 1.96994 (semantic_loss: 0.02062, quant_loss: 1.94922, bit_balance_loss: 0.00010) batch_time=0.34310 
Train Epoch: 50 [210/250 26880/32000 (84%)] Loss: 1.96799 (semantic_loss: 0.01867, quant_loss: 1.94922, bit_balance_loss: 0.00010) batch_time=0.33625 
Train Epoch: 50 [221/250 28288/32000 (88%)] Loss: 1.96889 (semantic_loss: 0.01956, quant_loss: 1.94922, bit_balance_loss: 0.00010) batch_time=0.33669 
Train Epoch: 50 [232/250 29696/32000 (93%)] Loss: 1.96972 (semantic_loss: 0.01942, quant_loss: 1.95020, bit_balance_loss: 0.00010) batch_time=0.31725 
Train Epoch: 50 [243/250 31104/32000 (97%)] Loss: 1.96931 (semantic_loss: 0.01901, quant_loss: 1.95020, bit_balance_loss: 0.00010) batch_time=0.33037 
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/DCMH_LSMDC/checkpoint-epoch50.pth ...
Done in 5.616s
removing stale ckpt [epoch 49] [took 0.01s]
 epoch          : 50
 loss           : 1.9701001238822937
 learning_rate  : 4.04973554087964e-06
 n_samples      : 1600000
 n_steps        : 12500
 LSMDC_full_test/t2v_metrics/R1: 9.3
 LSMDC_full_test/t2v_metrics/R5: 26.2
 LSMDC_full_test/t2v_metrics/R10: 36.5
 LSMDC_full_test/t2v_metrics/R50: 65.4
 LSMDC_full_test/t2v_metrics/MedR: 21.75
 LSMDC_full_test/t2v_metrics/MeanR: 75.616
 LSMDC_full_test/t2v_metrics/geometric_mean_R1-R5-R10: 20.71853459073673
 LSMDC_full_test/v2t_metrics/R1: 8.7
 LSMDC_full_test/v2t_metrics/R5: 26.4
 LSMDC_full_test/v2t_metrics/R10: 35.1
 LSMDC_full_test/v2t_metrics/R50: 65.3
 LSMDC_full_test/v2t_metrics/MedR: 22.0
 LSMDC_full_test/v2t_metrics/MeanR: 79.1905
 LSMDC_full_test/v2t_metrics/geometric_mean_R1-R5-R10: 20.051341423467644
 mnt_best       : 21.020388362320357
 not_improved_count: 2
Final evaluation ...
Loading checkpoint from: /apdcephfs/share_47076/gimwang/HCQ/exps/DCMH_LSMDC/trained_model.pth ...
Ckpt loaded at epoch 48.
Saved v2t similarity matrix to /apdcephfs/share_47076/gimwang/HCQ/exps/DCMH_LSMDC/LSMDC-test-sims.npy
LSMDC_full_test:
 t2v_metrics/R1/final_eval: 10.0
 t2v_metrics/R5/final_eval: 25.8
 t2v_metrics/R10/final_eval: 36.0
 t2v_metrics/R50/final_eval: 66.3
 t2v_metrics/MedR/final_eval: 22.0
 t2v_metrics/MeanR/final_eval: 75.841
 t2v_metrics/geometric_mean_R1-R5-R10/final_eval: 21.020388362320357
 v2t_metrics/R1/final_eval: 9.6
 v2t_metrics/R5/final_eval: 25.8
 v2t_metrics/R10/final_eval: 36.4
 v2t_metrics/R50/final_eval: 65.4
 v2t_metrics/MedR/final_eval: 22.75
 v2t_metrics/MeanR/final_eval: 78.365
 v2t_metrics/geometric_mean_R1-R5-R10/final_eval: 20.81281261873847
Best epoch for the monitored metric: 48
Script took 02h51m24s
The best performing ckpt can be found at /apdcephfs/share_47076/gimwang/HCQ/exps/DCMH_LSMDC/trained_model.pth
