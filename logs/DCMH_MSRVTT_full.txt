Experiment directory: /apdcephfs/share_47076/gimwang/HCQ/exps/DCMH_MSRVTT_full
Preparing the dataloaders ...
Loading dataset MSRVTT_full_train in ram ...
Finish loading dataset MSRVTT_full_train in ram, taking 393.7303788661957 s.
Loading dataset MSRVTT_full_val in ram ...
Finish loading dataset MSRVTT_full_val in ram, taking 30.576141357421875 s.
Loading dataset MSRVTT_full_test in ram ...
Finish loading dataset MSRVTT_full_test in ram, taking 209.3175904750824 s.
Loading dataset MSRVTT_full_test in ram ...
Finish loading dataset MSRVTT_full_test in ram, taking 188.29560327529907 s.
Training ...
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/DCMH_MSRVTT_full/checkpoint-epoch0.pth ...
Done in 6.838s
Updating 'best' checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/DCMH_MSRVTT_full/checkpoint-epoch0.pth ...
Done in 8.268s
 epoch          : 0
 loss           : 0
 learning_rate  : 5e-05
 n_samples      : 0
 n_steps        : 0
 MSRVTT_full_val/t2v_metrics/R1: 0.0
 MSRVTT_full_val/t2v_metrics/R5: 0.8048289738430584
 MSRVTT_full_val/t2v_metrics/R10: 2.0120724346076457
 MSRVTT_full_val/t2v_metrics/R50: 10.462776659959758
 MSRVTT_full_val/t2v_metrics/MedR: 248.0
 MSRVTT_full_val/t2v_metrics/MeanR: 247.14285714285714
 MSRVTT_full_val/t2v_metrics/geometric_mean_R1-R5-R10: 0.0
 MSRVTT_full_val/v2t_metrics/R1: 0.0
 MSRVTT_full_val/v2t_metrics/R5: 0.8048289738430584
 MSRVTT_full_val/v2t_metrics/R10: 1.6096579476861168
 MSRVTT_full_val/v2t_metrics/R50: 10.663983903420522
 MSRVTT_full_val/v2t_metrics/MedR: 252.5
 MSRVTT_full_val/v2t_metrics/MeanR: 248.10965794768612
 MSRVTT_full_val/v2t_metrics/geometric_mean_R1-R5-R10: 0.0
 MSRVTT_full_test/t2v_metrics/R1: 0.033444816053511704
 MSRVTT_full_test/t2v_metrics/R5: 0.16722408026755853
 MSRVTT_full_test/t2v_metrics/R10: 0.36789297658862874
 MSRVTT_full_test/t2v_metrics/R50: 1.6722408026755853
 MSRVTT_full_test/t2v_metrics/MedR: 1497.5
 MSRVTT_full_test/t2v_metrics/MeanR: 1497.7239130434782
 MSRVTT_full_test/t2v_metrics/geometric_mean_R1-R5-R10: 0.12718904551041443
 MSRVTT_full_test/v2t_metrics/R1: 0.033444816053511704
 MSRVTT_full_test/v2t_metrics/R5: 0.23411371237458195
 MSRVTT_full_test/v2t_metrics/R10: 0.36789297658862874
 MSRVTT_full_test/v2t_metrics/R50: 1.4381270903010033
 MSRVTT_full_test/v2t_metrics/MedR: 1496.75
 MSRVTT_full_test/v2t_metrics/MeanR: 1498.9148829431438
 MSRVTT_full_test/v2t_metrics/geometric_mean_R1-R5-R10: 0.14228497876638813
 mnt_best       : 0.12718904551041443
 not_improved_count: 0
Train Epoch: 1 [1/250 128/32000 (0%)] Loss: 2.68995 (semantic_loss: 0.73938, quant_loss: 1.95020, bit_balance_loss: 0.00038) batch_time=26.08887 
Train Epoch: 1 [12/250 1536/32000 (5%)] Loss: 2.00189 (semantic_loss: 0.05027, quant_loss: 1.95117, bit_balance_loss: 0.00045) batch_time=0.33792 
Train Epoch: 1 [23/250 2944/32000 (9%)] Loss: 1.99655 (semantic_loss: 0.04589, quant_loss: 1.95020, bit_balance_loss: 0.00047) batch_time=0.33451 
Train Epoch: 1 [34/250 4352/32000 (14%)] Loss: 1.99659 (semantic_loss: 0.04592, quant_loss: 1.95020, bit_balance_loss: 0.00048) batch_time=0.38526 
Train Epoch: 1 [45/250 5760/32000 (18%)] Loss: 1.99650 (semantic_loss: 0.04582, quant_loss: 1.95020, bit_balance_loss: 0.00048) batch_time=0.36414 
Train Epoch: 1 [56/250 7168/32000 (22%)] Loss: 1.99741 (semantic_loss: 0.04576, quant_loss: 1.95117, bit_balance_loss: 0.00048) batch_time=0.57415 
Train Epoch: 1 [67/250 8576/32000 (27%)] Loss: 1.99642 (semantic_loss: 0.04575, quant_loss: 1.95020, bit_balance_loss: 0.00048) batch_time=0.34764 
Train Epoch: 1 [78/250 9984/32000 (31%)] Loss: 1.99641 (semantic_loss: 0.04573, quant_loss: 1.95020, bit_balance_loss: 0.00048) batch_time=0.37763 
Train Epoch: 1 [89/250 11392/32000 (36%)] Loss: 1.99641 (semantic_loss: 0.04574, quant_loss: 1.95020, bit_balance_loss: 0.00047) batch_time=0.34161 
Train Epoch: 1 [100/250 12800/32000 (40%)] Loss: 1.99641 (semantic_loss: 0.04574, quant_loss: 1.95020, bit_balance_loss: 0.00047) batch_time=0.35712 
Train Epoch: 1 [111/250 14208/32000 (44%)] Loss: 1.99738 (semantic_loss: 0.04573, quant_loss: 1.95117, bit_balance_loss: 0.00047) batch_time=0.34630 
Train Epoch: 1 [122/250 15616/32000 (49%)] Loss: 1.99636 (semantic_loss: 0.04569, quant_loss: 1.95020, bit_balance_loss: 0.00047) batch_time=0.33233 
Train Epoch: 1 [133/250 17024/32000 (53%)] Loss: 1.99737 (semantic_loss: 0.04573, quant_loss: 1.95117, bit_balance_loss: 0.00046) batch_time=0.38578 
Train Epoch: 1 [144/250 18432/32000 (58%)] Loss: 1.99634 (semantic_loss: 0.04568, quant_loss: 1.95020, bit_balance_loss: 0.00046) batch_time=0.34605 
Train Epoch: 1 [155/250 19840/32000 (62%)] Loss: 1.99731 (semantic_loss: 0.04568, quant_loss: 1.95117, bit_balance_loss: 0.00046) batch_time=0.38182 
Train Epoch: 1 [166/250 21248/32000 (66%)] Loss: 1.99635 (semantic_loss: 0.04570, quant_loss: 1.95020, bit_balance_loss: 0.00045) batch_time=0.37321 
Train Epoch: 1 [177/250 22656/32000 (71%)] Loss: 1.99637 (semantic_loss: 0.04572, quant_loss: 1.95020, bit_balance_loss: 0.00045) batch_time=0.41687 
Train Epoch: 1 [188/250 24064/32000 (75%)] Loss: 1.99730 (semantic_loss: 0.04568, quant_loss: 1.95117, bit_balance_loss: 0.00045) batch_time=0.33890 
Train Epoch: 1 [199/250 25472/32000 (80%)] Loss: 1.99729 (semantic_loss: 0.04567, quant_loss: 1.95117, bit_balance_loss: 0.00044) batch_time=0.34236 
Train Epoch: 1 [210/250 26880/32000 (84%)] Loss: 1.99731 (semantic_loss: 0.04570, quant_loss: 1.95117, bit_balance_loss: 0.00044) batch_time=0.33824 
Train Epoch: 1 [221/250 28288/32000 (88%)] Loss: 1.99727 (semantic_loss: 0.04567, quant_loss: 1.95117, bit_balance_loss: 0.00043) batch_time=0.33380 
Train Epoch: 1 [232/250 29696/32000 (93%)] Loss: 1.99720 (semantic_loss: 0.04560, quant_loss: 1.95117, bit_balance_loss: 0.00043) batch_time=0.34787 
Train Epoch: 1 [243/250 31104/32000 (97%)] Loss: 1.99724 (semantic_loss: 0.04564, quant_loss: 1.95117, bit_balance_loss: 0.00042) batch_time=0.37048 
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/DCMH_MSRVTT_full/checkpoint-epoch1.pth ...
Done in 4.320s
 epoch          : 1
 loss           : 2.002866271495819
 learning_rate  : 5e-05
 n_samples      : 32000
 n_steps        : 250
 MSRVTT_full_val/t2v_metrics/R1: 0.2012072434607646
 MSRVTT_full_val/t2v_metrics/R5: 1.2072434607645874
 MSRVTT_full_val/t2v_metrics/R10: 2.0120724346076457
 MSRVTT_full_val/t2v_metrics/R50: 10.865191146881287
 MSRVTT_full_val/t2v_metrics/MedR: 253.0
 MSRVTT_full_val/t2v_metrics/MeanR: 247.76760563380282
 MSRVTT_full_val/t2v_metrics/geometric_mean_R1-R5-R10: 0.7876997265933326
 MSRVTT_full_val/v2t_metrics/R1: 0.2012072434607646
 MSRVTT_full_val/v2t_metrics/R5: 0.6036217303822937
 MSRVTT_full_val/v2t_metrics/R10: 2.414486921529175
 MSRVTT_full_val/v2t_metrics/R50: 10.663983903420522
 MSRVTT_full_val/v2t_metrics/MedR: 249.5
 MSRVTT_full_val/v2t_metrics/MeanR: 246.0472837022133
 MSRVTT_full_val/v2t_metrics/geometric_mean_R1-R5-R10: 0.6643716798580738
 MSRVTT_full_test/t2v_metrics/R1: 0.033444816053511704
 MSRVTT_full_test/t2v_metrics/R5: 0.16722408026755853
 MSRVTT_full_test/t2v_metrics/R10: 0.3010033444816054
 MSRVTT_full_test/t2v_metrics/R50: 1.5384615384615385
 MSRVTT_full_test/t2v_metrics/MedR: 1484.5
 MSRVTT_full_test/t2v_metrics/MeanR: 1490.7245819397992
 MSRVTT_full_test/t2v_metrics/geometric_mean_R1-R5-R10: 0.11895964229063753
 MSRVTT_full_test/v2t_metrics/R1: 0.033444816053511704
 MSRVTT_full_test/v2t_metrics/R5: 0.20066889632107024
 MSRVTT_full_test/v2t_metrics/R10: 0.3010033444816054
 MSRVTT_full_test/v2t_metrics/R50: 1.9063545150501673
 MSRVTT_full_test/v2t_metrics/MedR: 1483.5
 MSRVTT_full_test/v2t_metrics/MeanR: 1489.018227424749
 MSRVTT_full_test/v2t_metrics/geometric_mean_R1-R5-R10: 0.1264134832670441
 mnt_best       : 0.12718904551041443
 not_improved_count: 1
Train Epoch: 2 [1/250 128/32000 (0%)] Loss: 1.99724 (semantic_loss: 0.04565, quant_loss: 1.95117, bit_balance_loss: 0.00042) batch_time=29.64642 
Train Epoch: 2 [12/250 1536/32000 (5%)] Loss: 1.99719 (semantic_loss: 0.04560, quant_loss: 1.95117, bit_balance_loss: 0.00042) batch_time=0.32946 
Train Epoch: 2 [23/250 2944/32000 (9%)] Loss: 1.99620 (semantic_loss: 0.04559, quant_loss: 1.95020, bit_balance_loss: 0.00041) batch_time=0.35022 
Train Epoch: 2 [34/250 4352/32000 (14%)] Loss: 1.99713 (semantic_loss: 0.04555, quant_loss: 1.95117, bit_balance_loss: 0.00041) batch_time=0.33705 
Train Epoch: 2 [45/250 5760/32000 (18%)] Loss: 1.99697 (semantic_loss: 0.04539, quant_loss: 1.95117, bit_balance_loss: 0.00040) batch_time=0.39033 
Train Epoch: 2 [56/250 7168/32000 (22%)] Loss: 1.99683 (semantic_loss: 0.04526, quant_loss: 1.95117, bit_balance_loss: 0.00040) batch_time=0.34449 
Train Epoch: 2 [67/250 8576/32000 (27%)] Loss: 1.99695 (semantic_loss: 0.04539, quant_loss: 1.95117, bit_balance_loss: 0.00039) batch_time=0.38385 
Train Epoch: 2 [78/250 9984/32000 (31%)] Loss: 1.99717 (semantic_loss: 0.04560, quant_loss: 1.95117, bit_balance_loss: 0.00040) batch_time=0.34097 
Train Epoch: 2 [89/250 11392/32000 (36%)] Loss: 1.99694 (semantic_loss: 0.04538, quant_loss: 1.95117, bit_balance_loss: 0.00039) batch_time=0.33587 
Train Epoch: 2 [100/250 12800/32000 (40%)] Loss: 1.99578 (semantic_loss: 0.04520, quant_loss: 1.95020, bit_balance_loss: 0.00038) batch_time=0.33670 
Train Epoch: 2 [111/250 14208/32000 (44%)] Loss: 1.99636 (semantic_loss: 0.04481, quant_loss: 1.95117, bit_balance_loss: 0.00037) batch_time=0.36001 
Train Epoch: 2 [122/250 15616/32000 (49%)] Loss: 1.99491 (semantic_loss: 0.04434, quant_loss: 1.95020, bit_balance_loss: 0.00037) batch_time=0.35023 
Train Epoch: 2 [133/250 17024/32000 (53%)] Loss: 1.99516 (semantic_loss: 0.04459, quant_loss: 1.95020, bit_balance_loss: 0.00037) batch_time=0.36451 
Train Epoch: 2 [144/250 18432/32000 (58%)] Loss: 1.99618 (semantic_loss: 0.04464, quant_loss: 1.95117, bit_balance_loss: 0.00036) batch_time=0.34205 
Train Epoch: 2 [155/250 19840/32000 (62%)] Loss: 1.99425 (semantic_loss: 0.04370, quant_loss: 1.95020, bit_balance_loss: 0.00035) batch_time=0.37609 
Train Epoch: 2 [166/250 21248/32000 (66%)] Loss: 1.99552 (semantic_loss: 0.04399, quant_loss: 1.95117, bit_balance_loss: 0.00035) batch_time=0.34919 
Train Epoch: 2 [177/250 22656/32000 (71%)] Loss: 1.99533 (semantic_loss: 0.04381, quant_loss: 1.95117, bit_balance_loss: 0.00035) batch_time=0.33309 
Train Epoch: 2 [188/250 24064/32000 (75%)] Loss: 1.99449 (semantic_loss: 0.04298, quant_loss: 1.95117, bit_balance_loss: 0.00034) batch_time=0.33277 
Train Epoch: 2 [199/250 25472/32000 (80%)] Loss: 1.99416 (semantic_loss: 0.04362, quant_loss: 1.95020, bit_balance_loss: 0.00034) batch_time=0.33149 
Train Epoch: 2 [210/250 26880/32000 (84%)] Loss: 1.99378 (semantic_loss: 0.04325, quant_loss: 1.95020, bit_balance_loss: 0.00034) batch_time=9.13466 
Train Epoch: 2 [221/250 28288/32000 (88%)] Loss: 1.99367 (semantic_loss: 0.04314, quant_loss: 1.95020, bit_balance_loss: 0.00033) batch_time=0.33319 
Train Epoch: 2 [232/250 29696/32000 (93%)] Loss: 1.99291 (semantic_loss: 0.04239, quant_loss: 1.95020, bit_balance_loss: 0.00033) batch_time=0.34405 
Train Epoch: 2 [243/250 31104/32000 (97%)] Loss: 1.99284 (semantic_loss: 0.04232, quant_loss: 1.95020, bit_balance_loss: 0.00032) batch_time=0.33422 
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/DCMH_MSRVTT_full/checkpoint-epoch2.pth ...
Done in 3.901s
Updating 'best' checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/DCMH_MSRVTT_full/checkpoint-epoch2.pth ...
Done in 7.875s
removing stale ckpt [epoch 1] [took 0.00s]
removing stale ckpt [epoch 0] [took 0.00s]
 epoch          : 2
 loss           : 1.9953700456619263
 learning_rate  : 4.75e-05
 n_samples      : 64000
 n_steps        : 500
 MSRVTT_full_val/t2v_metrics/R1: 1.0060362173038229
 MSRVTT_full_val/t2v_metrics/R5: 5.4325955734406435
 MSRVTT_full_val/t2v_metrics/R10: 9.054325955734406
 MSRVTT_full_val/t2v_metrics/R50: 37.42454728370221
 MSRVTT_full_val/t2v_metrics/MedR: 72.0
 MSRVTT_full_val/t2v_metrics/MeanR: 102.24245472837022
 MSRVTT_full_val/t2v_metrics/geometric_mean_R1-R5-R10: 3.6713492931026557
 MSRVTT_full_val/v2t_metrics/R1: 0.2012072434607646
 MSRVTT_full_val/v2t_metrics/R5: 4.0241448692152915
 MSRVTT_full_val/v2t_metrics/R10: 7.645875251509055
 MSRVTT_full_val/v2t_metrics/R50: 37.42454728370221
 MSRVTT_full_val/v2t_metrics/MedR: 69.5
 MSRVTT_full_val/v2t_metrics/MeanR: 94.33802816901408
 MSRVTT_full_val/v2t_metrics/geometric_mean_R1-R5-R10: 1.8361781228921394
 MSRVTT_full_test/t2v_metrics/R1: 0.13377926421404682
 MSRVTT_full_test/t2v_metrics/R5: 0.9364548494983278
 MSRVTT_full_test/t2v_metrics/R10: 1.605351170568562
 MSRVTT_full_test/t2v_metrics/R50: 8.494983277591974
 MSRVTT_full_test/t2v_metrics/MedR: 449.75
 MSRVTT_full_test/t2v_metrics/MeanR: 632.0481605351171
 MSRVTT_full_test/t2v_metrics/geometric_mean_R1-R5-R10: 0.585888848145537
 MSRVTT_full_test/v2t_metrics/R1: 0.16722408026755853
 MSRVTT_full_test/v2t_metrics/R5: 0.9698996655518395
 MSRVTT_full_test/v2t_metrics/R10: 1.5050167224080269
 MSRVTT_full_test/v2t_metrics/R50: 6.8561872909699
 MSRVTT_full_test/v2t_metrics/MedR: 428.75
 MSRVTT_full_test/v2t_metrics/MeanR: 585.9797658862876
 MSRVTT_full_test/v2t_metrics/geometric_mean_R1-R5-R10: 0.6249649340541872
 mnt_best       : 0.585888848145537
 not_improved_count: 0
Train Epoch: 3 [1/250 128/32000 (0%)] Loss: 1.99200 (semantic_loss: 0.04149, quant_loss: 1.95020, bit_balance_loss: 0.00032) batch_time=30.28709 
Train Epoch: 3 [12/250 1536/32000 (5%)] Loss: 1.99178 (semantic_loss: 0.04127, quant_loss: 1.95020, bit_balance_loss: 0.00031) batch_time=0.34835 
Train Epoch: 3 [23/250 2944/32000 (9%)] Loss: 1.99193 (semantic_loss: 0.04143, quant_loss: 1.95020, bit_balance_loss: 0.00031) batch_time=0.33878 
Train Epoch: 3 [34/250 4352/32000 (14%)] Loss: 1.99165 (semantic_loss: 0.04115, quant_loss: 1.95020, bit_balance_loss: 0.00031) batch_time=0.35745 
Train Epoch: 3 [45/250 5760/32000 (18%)] Loss: 1.99085 (semantic_loss: 0.04036, quant_loss: 1.95020, bit_balance_loss: 0.00030) batch_time=0.33453 
Train Epoch: 3 [56/250 7168/32000 (22%)] Loss: 1.98904 (semantic_loss: 0.03953, quant_loss: 1.94922, bit_balance_loss: 0.00030) batch_time=0.34739 
Train Epoch: 3 [67/250 8576/32000 (27%)] Loss: 1.98974 (semantic_loss: 0.03925, quant_loss: 1.95020, bit_balance_loss: 0.00029) batch_time=0.34280 
Train Epoch: 3 [78/250 9984/32000 (31%)] Loss: 1.98893 (semantic_loss: 0.03845, quant_loss: 1.95020, bit_balance_loss: 0.00029) batch_time=0.37447 
Train Epoch: 3 [89/250 11392/32000 (36%)] Loss: 1.98923 (semantic_loss: 0.03874, quant_loss: 1.95020, bit_balance_loss: 0.00029) batch_time=0.34134 
Train Epoch: 3 [100/250 12800/32000 (40%)] Loss: 1.98837 (semantic_loss: 0.03887, quant_loss: 1.94922, bit_balance_loss: 0.00028) batch_time=0.35172 
Train Epoch: 3 [111/250 14208/32000 (44%)] Loss: 1.98893 (semantic_loss: 0.03845, quant_loss: 1.95020, bit_balance_loss: 0.00028) batch_time=0.35852 
Train Epoch: 3 [122/250 15616/32000 (49%)] Loss: 1.98808 (semantic_loss: 0.03761, quant_loss: 1.95020, bit_balance_loss: 0.00028) batch_time=0.34807 
Train Epoch: 3 [133/250 17024/32000 (53%)] Loss: 1.98791 (semantic_loss: 0.03744, quant_loss: 1.95020, bit_balance_loss: 0.00027) batch_time=0.33686 
Train Epoch: 3 [144/250 18432/32000 (58%)] Loss: 1.98632 (semantic_loss: 0.03585, quant_loss: 1.95020, bit_balance_loss: 0.00027) batch_time=0.35561 
Train Epoch: 3 [155/250 19840/32000 (62%)] Loss: 1.98634 (semantic_loss: 0.03685, quant_loss: 1.94922, bit_balance_loss: 0.00027) batch_time=0.32573 
Train Epoch: 3 [166/250 21248/32000 (66%)] Loss: 1.98539 (semantic_loss: 0.03590, quant_loss: 1.94922, bit_balance_loss: 0.00027) batch_time=0.34143 
Train Epoch: 3 [177/250 22656/32000 (71%)] Loss: 1.98685 (semantic_loss: 0.03640, quant_loss: 1.95020, bit_balance_loss: 0.00026) batch_time=0.36701 
Train Epoch: 3 [188/250 24064/32000 (75%)] Loss: 1.98597 (semantic_loss: 0.03551, quant_loss: 1.95020, bit_balance_loss: 0.00026) batch_time=0.33286 
Train Epoch: 3 [199/250 25472/32000 (80%)] Loss: 1.98598 (semantic_loss: 0.03650, quant_loss: 1.94922, bit_balance_loss: 0.00026) batch_time=0.36483 
Train Epoch: 3 [210/250 26880/32000 (84%)] Loss: 1.98507 (semantic_loss: 0.03559, quant_loss: 1.94922, bit_balance_loss: 0.00026) batch_time=2.70443 
Train Epoch: 3 [221/250 28288/32000 (88%)] Loss: 1.98550 (semantic_loss: 0.03505, quant_loss: 1.95020, bit_balance_loss: 0.00025) batch_time=0.35194 
Train Epoch: 3 [232/250 29696/32000 (93%)] Loss: 1.98538 (semantic_loss: 0.03493, quant_loss: 1.95020, bit_balance_loss: 0.00025) batch_time=0.39445 
Train Epoch: 3 [243/250 31104/32000 (97%)] Loss: 1.98415 (semantic_loss: 0.03371, quant_loss: 1.95020, bit_balance_loss: 0.00025) batch_time=0.34545 
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/DCMH_MSRVTT_full/checkpoint-epoch3.pth ...
Done in 18.073s
Updating 'best' checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/DCMH_MSRVTT_full/checkpoint-epoch3.pth ...
Done in 22.142s
removing stale ckpt [epoch 2] [took 0.00s]
 epoch          : 3
 loss           : 1.9879206166267396
 learning_rate  : 4.5125e-05
 n_samples      : 96000
 n_steps        : 750
 MSRVTT_full_val/t2v_metrics/R1: 4.627766599597585
 MSRVTT_full_val/t2v_metrics/R5: 19.718309859154928
 MSRVTT_full_val/t2v_metrics/R10: 32.99798792756539
 MSRVTT_full_val/t2v_metrics/R50: 79.87927565392354
 MSRVTT_full_val/t2v_metrics/MedR: 18.5
 MSRVTT_full_val/t2v_metrics/MeanR: 34.783702213279675
 MSRVTT_full_val/t2v_metrics/geometric_mean_R1-R5-R10: 14.440299400640399
 MSRVTT_full_val/v2t_metrics/R1: 3.8229376257545273
 MSRVTT_full_val/v2t_metrics/R5: 18.309859154929576
 MSRVTT_full_val/v2t_metrics/R10: 33.40040241448692
 MSRVTT_full_val/v2t_metrics/R50: 80.28169014084507
 MSRVTT_full_val/v2t_metrics/MedR: 20.5
 MSRVTT_full_val/v2t_metrics/MeanR: 32.87122736418511
 MSRVTT_full_val/v2t_metrics/geometric_mean_R1-R5-R10: 13.272252590903882
 MSRVTT_full_test/t2v_metrics/R1: 0.7023411371237458
 MSRVTT_full_test/t2v_metrics/R5: 3.4448160535117056
 MSRVTT_full_test/t2v_metrics/R10: 7.25752508361204
 MSRVTT_full_test/t2v_metrics/R50: 28.729096989966557
 MSRVTT_full_test/t2v_metrics/MedR: 117.5
 MSRVTT_full_test/t2v_metrics/MeanR: 216.80969899665553
 MSRVTT_full_test/t2v_metrics/geometric_mean_R1-R5-R10: 2.5991672695074564
 MSRVTT_full_test/v2t_metrics/R1: 0.6354515050167224
 MSRVTT_full_test/v2t_metrics/R5: 3.7123745819397995
 MSRVTT_full_test/v2t_metrics/R10: 6.989966555183947
 MSRVTT_full_test/v2t_metrics/R50: 29.23076923076923
 MSRVTT_full_test/v2t_metrics/MedR: 107.5
 MSRVTT_full_test/v2t_metrics/MeanR: 206.86254180602006
 MSRVTT_full_test/v2t_metrics/geometric_mean_R1-R5-R10: 2.545285090957286
 mnt_best       : 2.5991672695074564
 not_improved_count: 0
Train Epoch: 4 [1/250 128/32000 (0%)] Loss: 1.98320 (semantic_loss: 0.03373, quant_loss: 1.94922, bit_balance_loss: 0.00025) batch_time=30.88091 
Train Epoch: 4 [12/250 1536/32000 (5%)] Loss: 1.98299 (semantic_loss: 0.03353, quant_loss: 1.94922, bit_balance_loss: 0.00025) batch_time=0.35681 
Train Epoch: 4 [23/250 2944/32000 (9%)] Loss: 1.98373 (semantic_loss: 0.03427, quant_loss: 1.94922, bit_balance_loss: 0.00024) batch_time=0.35605 
Train Epoch: 4 [34/250 4352/32000 (14%)] Loss: 1.98373 (semantic_loss: 0.03427, quant_loss: 1.94922, bit_balance_loss: 0.00024) batch_time=0.34194 
Train Epoch: 4 [45/250 5760/32000 (18%)] Loss: 1.98312 (semantic_loss: 0.03366, quant_loss: 1.94922, bit_balance_loss: 0.00024) batch_time=0.36047 
Train Epoch: 4 [56/250 7168/32000 (22%)] Loss: 1.98378 (semantic_loss: 0.03335, quant_loss: 1.95020, bit_balance_loss: 0.00023) batch_time=0.36644 
Train Epoch: 4 [67/250 8576/32000 (27%)] Loss: 1.98406 (semantic_loss: 0.03461, quant_loss: 1.94922, bit_balance_loss: 0.00023) batch_time=1.80795 
Train Epoch: 4 [78/250 9984/32000 (31%)] Loss: 1.98124 (semantic_loss: 0.03179, quant_loss: 1.94922, bit_balance_loss: 0.00023) batch_time=0.34707 
Train Epoch: 4 [89/250 11392/32000 (36%)] Loss: 1.98078 (semantic_loss: 0.03133, quant_loss: 1.94922, bit_balance_loss: 0.00023) batch_time=0.34196 
Train Epoch: 4 [100/250 12800/32000 (40%)] Loss: 1.98209 (semantic_loss: 0.03264, quant_loss: 1.94922, bit_balance_loss: 0.00022) batch_time=0.36813 
Train Epoch: 4 [111/250 14208/32000 (44%)] Loss: 1.98153 (semantic_loss: 0.03209, quant_loss: 1.94922, bit_balance_loss: 0.00022) batch_time=0.38684 
Train Epoch: 4 [122/250 15616/32000 (49%)] Loss: 1.98300 (semantic_loss: 0.03259, quant_loss: 1.95020, bit_balance_loss: 0.00022) batch_time=0.43110 
Train Epoch: 4 [133/250 17024/32000 (53%)] Loss: 1.98204 (semantic_loss: 0.03163, quant_loss: 1.95020, bit_balance_loss: 0.00022) batch_time=0.58454 
Train Epoch: 4 [144/250 18432/32000 (58%)] Loss: 1.98173 (semantic_loss: 0.03229, quant_loss: 1.94922, bit_balance_loss: 0.00022) batch_time=0.34559 
Train Epoch: 4 [155/250 19840/32000 (62%)] Loss: 1.98109 (semantic_loss: 0.03165, quant_loss: 1.94922, bit_balance_loss: 0.00022) batch_time=0.35049 
Train Epoch: 4 [166/250 21248/32000 (66%)] Loss: 1.97992 (semantic_loss: 0.03048, quant_loss: 1.94922, bit_balance_loss: 0.00022) batch_time=0.35154 
Train Epoch: 4 [177/250 22656/32000 (71%)] Loss: 1.98079 (semantic_loss: 0.03136, quant_loss: 1.94922, bit_balance_loss: 0.00021) batch_time=0.36151 
Train Epoch: 4 [188/250 24064/32000 (75%)] Loss: 1.98055 (semantic_loss: 0.03112, quant_loss: 1.94922, bit_balance_loss: 0.00021) batch_time=0.36025 
Train Epoch: 4 [199/250 25472/32000 (80%)] Loss: 1.97908 (semantic_loss: 0.02966, quant_loss: 1.94922, bit_balance_loss: 0.00021) batch_time=11.41206 
Train Epoch: 4 [210/250 26880/32000 (84%)] Loss: 1.97929 (semantic_loss: 0.02986, quant_loss: 1.94922, bit_balance_loss: 0.00020) batch_time=0.34213 
Train Epoch: 4 [221/250 28288/32000 (88%)] Loss: 1.97957 (semantic_loss: 0.03015, quant_loss: 1.94922, bit_balance_loss: 0.00020) batch_time=0.33568 
Train Epoch: 4 [232/250 29696/32000 (93%)] Loss: 1.98094 (semantic_loss: 0.03152, quant_loss: 1.94922, bit_balance_loss: 0.00020) batch_time=0.36028 
Train Epoch: 4 [243/250 31104/32000 (97%)] Loss: 1.97967 (semantic_loss: 0.03025, quant_loss: 1.94922, bit_balance_loss: 0.00020) batch_time=0.36185 
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/DCMH_MSRVTT_full/checkpoint-epoch4.pth ...
Done in 3.964s
Updating 'best' checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/DCMH_MSRVTT_full/checkpoint-epoch4.pth ...
Done in 7.993s
removing stale ckpt [epoch 3] [took 0.00s]
 epoch          : 4
 loss           : 1.981800720691681
 learning_rate  : 4.2868749999999995e-05
 n_samples      : 128000
 n_steps        : 1000
 MSRVTT_full_val/t2v_metrics/R1: 7.847082494969819
 MSRVTT_full_val/t2v_metrics/R5: 31.790744466800806
 MSRVTT_full_val/t2v_metrics/R10: 47.88732394366197
 MSRVTT_full_val/t2v_metrics/R50: 89.738430583501
 MSRVTT_full_val/t2v_metrics/MedR: 11.0
 MSRVTT_full_val/t2v_metrics/MeanR: 23.00301810865191
 MSRVTT_full_val/t2v_metrics/geometric_mean_R1-R5-R10: 22.860014153411303
 MSRVTT_full_val/v2t_metrics/R1: 8.249496981891348
 MSRVTT_full_val/v2t_metrics/R5: 32.19315895372233
 MSRVTT_full_val/v2t_metrics/R10: 51.30784708249497
 MSRVTT_full_val/v2t_metrics/R50: 89.33601609657947
 MSRVTT_full_val/v2t_metrics/MedR: 10.0
 MSRVTT_full_val/v2t_metrics/MeanR: 22.096579476861166
 MSRVTT_full_val/v2t_metrics/geometric_mean_R1-R5-R10: 23.884983807927465
 MSRVTT_full_test/t2v_metrics/R1: 1.939799331103679
 MSRVTT_full_test/t2v_metrics/R5: 8.528428093645484
 MSRVTT_full_test/t2v_metrics/R10: 14.749163879598662
 MSRVTT_full_test/t2v_metrics/R50: 46.187290969899664
 MSRVTT_full_test/t2v_metrics/MedR: 59.5
 MSRVTT_full_test/t2v_metrics/MeanR: 131.4670568561873
 MSRVTT_full_test/t2v_metrics/geometric_mean_R1-R5-R10: 6.248815942833558
 MSRVTT_full_test/v2t_metrics/R1: 1.6387959866220736
 MSRVTT_full_test/v2t_metrics/R5: 8.294314381270903
 MSRVTT_full_test/v2t_metrics/R10: 15.384615384615385
 MSRVTT_full_test/v2t_metrics/R50: 46.42140468227425
 MSRVTT_full_test/v2t_metrics/MedR: 59.5
 MSRVTT_full_test/v2t_metrics/MeanR: 126.68645484949833
 MSRVTT_full_test/v2t_metrics/geometric_mean_R1-R5-R10: 5.935591567733011
 mnt_best       : 6.248815942833558
 not_improved_count: 0
Train Epoch: 5 [1/250 128/32000 (0%)] Loss: 1.97853 (semantic_loss: 0.02911, quant_loss: 1.94922, bit_balance_loss: 0.00020) batch_time=31.82514 
Train Epoch: 5 [12/250 1536/32000 (5%)] Loss: 1.98001 (semantic_loss: 0.02962, quant_loss: 1.95020, bit_balance_loss: 0.00019) batch_time=0.35429 
Train Epoch: 5 [23/250 2944/32000 (9%)] Loss: 1.97944 (semantic_loss: 0.02905, quant_loss: 1.95020, bit_balance_loss: 0.00019) batch_time=0.35861 
Train Epoch: 5 [34/250 4352/32000 (14%)] Loss: 1.97944 (semantic_loss: 0.02905, quant_loss: 1.95020, bit_balance_loss: 0.00019) batch_time=0.36076 
Train Epoch: 5 [45/250 5760/32000 (18%)] Loss: 1.97968 (semantic_loss: 0.02929, quant_loss: 1.95020, bit_balance_loss: 0.00019) batch_time=0.33256 
Train Epoch: 5 [56/250 7168/32000 (22%)] Loss: 1.97907 (semantic_loss: 0.02869, quant_loss: 1.95020, bit_balance_loss: 0.00019) batch_time=0.34480 
Train Epoch: 5 [67/250 8576/32000 (27%)] Loss: 1.97925 (semantic_loss: 0.02985, quant_loss: 1.94922, bit_balance_loss: 0.00019) batch_time=0.34551 
Train Epoch: 5 [78/250 9984/32000 (31%)] Loss: 1.97671 (semantic_loss: 0.02731, quant_loss: 1.94922, bit_balance_loss: 0.00018) batch_time=2.03563 
Train Epoch: 5 [89/250 11392/32000 (36%)] Loss: 1.97932 (semantic_loss: 0.02894, quant_loss: 1.95020, bit_balance_loss: 0.00018) batch_time=0.41573 
Train Epoch: 5 [100/250 12800/32000 (40%)] Loss: 1.97995 (semantic_loss: 0.02957, quant_loss: 1.95020, bit_balance_loss: 0.00018) batch_time=0.36758 
Train Epoch: 5 [111/250 14208/32000 (44%)] Loss: 1.97977 (semantic_loss: 0.02939, quant_loss: 1.95020, bit_balance_loss: 0.00018) batch_time=0.33191 
Train Epoch: 5 [122/250 15616/32000 (49%)] Loss: 1.97934 (semantic_loss: 0.02896, quant_loss: 1.95020, bit_balance_loss: 0.00018) batch_time=0.34735 
Train Epoch: 5 [133/250 17024/32000 (53%)] Loss: 1.98062 (semantic_loss: 0.03024, quant_loss: 1.95020, bit_balance_loss: 0.00018) batch_time=0.33431 
Train Epoch: 5 [144/250 18432/32000 (58%)] Loss: 1.97802 (semantic_loss: 0.02764, quant_loss: 1.95020, bit_balance_loss: 0.00018) batch_time=3.69417 
Train Epoch: 5 [155/250 19840/32000 (62%)] Loss: 1.97851 (semantic_loss: 0.02813, quant_loss: 1.95020, bit_balance_loss: 0.00018) batch_time=0.34629 
Train Epoch: 5 [166/250 21248/32000 (66%)] Loss: 1.97867 (semantic_loss: 0.02830, quant_loss: 1.95020, bit_balance_loss: 0.00017) batch_time=0.39615 
Train Epoch: 5 [177/250 22656/32000 (71%)] Loss: 1.97715 (semantic_loss: 0.02775, quant_loss: 1.94922, bit_balance_loss: 0.00018) batch_time=0.40368 
Train Epoch: 5 [188/250 24064/32000 (75%)] Loss: 1.97826 (semantic_loss: 0.02788, quant_loss: 1.95020, bit_balance_loss: 0.00018) batch_time=0.36848 
Train Epoch: 5 [199/250 25472/32000 (80%)] Loss: 1.97751 (semantic_loss: 0.02714, quant_loss: 1.95020, bit_balance_loss: 0.00017) batch_time=0.38557 
Train Epoch: 5 [210/250 26880/32000 (84%)] Loss: 1.97690 (semantic_loss: 0.02751, quant_loss: 1.94922, bit_balance_loss: 0.00017) batch_time=0.33105 
Train Epoch: 5 [221/250 28288/32000 (88%)] Loss: 1.97816 (semantic_loss: 0.02779, quant_loss: 1.95020, bit_balance_loss: 0.00017) batch_time=0.33467 
Train Epoch: 5 [232/250 29696/32000 (93%)] Loss: 1.97807 (semantic_loss: 0.02868, quant_loss: 1.94922, bit_balance_loss: 0.00017) batch_time=0.35748 
Train Epoch: 5 [243/250 31104/32000 (97%)] Loss: 1.97668 (semantic_loss: 0.02729, quant_loss: 1.94922, bit_balance_loss: 0.00017) batch_time=0.34886 
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/DCMH_MSRVTT_full/checkpoint-epoch5.pth ...
Done in 4.512s
Updating 'best' checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/DCMH_MSRVTT_full/checkpoint-epoch5.pth ...
Done in 8.919s
removing stale ckpt [epoch 4] [took 0.00s]
 epoch          : 5
 loss           : 1.9788992266654968
 learning_rate  : 4.072531249999999e-05
 n_samples      : 160000
 n_steps        : 1250
 MSRVTT_full_val/t2v_metrics/R1: 10.663983903420522
 MSRVTT_full_val/t2v_metrics/R5: 37.625754527162975
 MSRVTT_full_val/t2v_metrics/R10: 56.94164989939638
 MSRVTT_full_val/t2v_metrics/R50: 90.3420523138833
 MSRVTT_full_val/t2v_metrics/MedR: 9.0
 MSRVTT_full_val/t2v_metrics/MeanR: 19.180080482897385
 MSRVTT_full_val/t2v_metrics/geometric_mean_R1-R5-R10: 28.37559096584382
 MSRVTT_full_val/v2t_metrics/R1: 11.267605633802816
 MSRVTT_full_val/v2t_metrics/R5: 34.80885311871227
 MSRVTT_full_val/v2t_metrics/R10: 55.734406438631794
 MSRVTT_full_val/v2t_metrics/R50: 91.75050301810865
 MSRVTT_full_val/v2t_metrics/MedR: 9.0
 MSRVTT_full_val/v2t_metrics/MeanR: 19.10764587525151
 MSRVTT_full_val/v2t_metrics/geometric_mean_R1-R5-R10: 27.960713166154818
 MSRVTT_full_test/t2v_metrics/R1: 2.508361204013378
 MSRVTT_full_test/t2v_metrics/R5: 11.471571906354516
 MSRVTT_full_test/t2v_metrics/R10: 19.598662207357858
 MSRVTT_full_test/t2v_metrics/R50: 54.11371237458194
 MSRVTT_full_test/t2v_metrics/MedR: 43.0
 MSRVTT_full_test/t2v_metrics/MeanR: 104.01003344481606
 MSRVTT_full_test/t2v_metrics/geometric_mean_R1-R5-R10: 8.261897667957863
 MSRVTT_full_test/v2t_metrics/R1: 2.6421404682274248
 MSRVTT_full_test/v2t_metrics/R5: 11.103678929765886
 MSRVTT_full_test/v2t_metrics/R10: 19.36454849498328
 MSRVTT_full_test/v2t_metrics/R50: 55.919732441471574
 MSRVTT_full_test/v2t_metrics/MedR: 40.5
 MSRVTT_full_test/v2t_metrics/MeanR: 103.30200668896322
 MSRVTT_full_test/v2t_metrics/geometric_mean_R1-R5-R10: 8.282155709679547
 mnt_best       : 8.261897667957863
 not_improved_count: 0
Train Epoch: 6 [1/250 128/32000 (0%)] Loss: 1.97648 (semantic_loss: 0.02612, quant_loss: 1.95020, bit_balance_loss: 0.00017) batch_time=29.45428 
Train Epoch: 6 [12/250 1536/32000 (5%)] Loss: 1.97656 (semantic_loss: 0.02620, quant_loss: 1.95020, bit_balance_loss: 0.00016) batch_time=0.35568 
Train Epoch: 6 [23/250 2944/32000 (9%)] Loss: 1.97700 (semantic_loss: 0.02761, quant_loss: 1.94922, bit_balance_loss: 0.00017) batch_time=0.34420 
Train Epoch: 6 [34/250 4352/32000 (14%)] Loss: 1.97773 (semantic_loss: 0.02834, quant_loss: 1.94922, bit_balance_loss: 0.00017) batch_time=0.34012 
Train Epoch: 6 [45/250 5760/32000 (18%)] Loss: 1.97644 (semantic_loss: 0.02705, quant_loss: 1.94922, bit_balance_loss: 0.00017) batch_time=0.36547 
Train Epoch: 6 [56/250 7168/32000 (22%)] Loss: 1.97789 (semantic_loss: 0.02851, quant_loss: 1.94922, bit_balance_loss: 0.00016) batch_time=0.33875 
Train Epoch: 6 [67/250 8576/32000 (27%)] Loss: 1.97893 (semantic_loss: 0.02856, quant_loss: 1.95020, bit_balance_loss: 0.00017) batch_time=0.34837 
Train Epoch: 6 [78/250 9984/32000 (31%)] Loss: 1.97774 (semantic_loss: 0.02836, quant_loss: 1.94922, bit_balance_loss: 0.00016) batch_time=0.35085 
Train Epoch: 6 [89/250 11392/32000 (36%)] Loss: 1.97811 (semantic_loss: 0.02872, quant_loss: 1.94922, bit_balance_loss: 0.00017) batch_time=0.33158 
Train Epoch: 6 [100/250 12800/32000 (40%)] Loss: 1.97794 (semantic_loss: 0.02758, quant_loss: 1.95020, bit_balance_loss: 0.00016) batch_time=0.38993 
Train Epoch: 6 [111/250 14208/32000 (44%)] Loss: 1.97794 (semantic_loss: 0.02759, quant_loss: 1.95020, bit_balance_loss: 0.00016) batch_time=0.34195 
Train Epoch: 6 [122/250 15616/32000 (49%)] Loss: 1.97740 (semantic_loss: 0.02704, quant_loss: 1.95020, bit_balance_loss: 0.00016) batch_time=0.35524 
Train Epoch: 6 [133/250 17024/32000 (53%)] Loss: 1.97673 (semantic_loss: 0.02638, quant_loss: 1.95020, bit_balance_loss: 0.00016) batch_time=0.34024 
Train Epoch: 6 [144/250 18432/32000 (58%)] Loss: 1.97866 (semantic_loss: 0.02830, quant_loss: 1.95020, bit_balance_loss: 0.00016) batch_time=0.36063 
Train Epoch: 6 [155/250 19840/32000 (62%)] Loss: 1.97687 (semantic_loss: 0.02749, quant_loss: 1.94922, bit_balance_loss: 0.00016) batch_time=0.33578 
Train Epoch: 6 [166/250 21248/32000 (66%)] Loss: 1.97788 (semantic_loss: 0.02753, quant_loss: 1.95020, bit_balance_loss: 0.00016) batch_time=0.34097 
Train Epoch: 6 [177/250 22656/32000 (71%)] Loss: 1.97718 (semantic_loss: 0.02683, quant_loss: 1.95020, bit_balance_loss: 0.00016) batch_time=0.34022 
Train Epoch: 6 [188/250 24064/32000 (75%)] Loss: 1.97478 (semantic_loss: 0.02443, quant_loss: 1.95020, bit_balance_loss: 0.00015) batch_time=0.37531 
Train Epoch: 6 [199/250 25472/32000 (80%)] Loss: 1.97517 (semantic_loss: 0.02580, quant_loss: 1.94922, bit_balance_loss: 0.00015) batch_time=0.38872 
Train Epoch: 6 [210/250 26880/32000 (84%)] Loss: 1.97631 (semantic_loss: 0.02694, quant_loss: 1.94922, bit_balance_loss: 0.00015) batch_time=0.33514 
Train Epoch: 6 [221/250 28288/32000 (88%)] Loss: 1.97674 (semantic_loss: 0.02737, quant_loss: 1.94922, bit_balance_loss: 0.00015) batch_time=1.07921 
Train Epoch: 6 [232/250 29696/32000 (93%)] Loss: 1.97440 (semantic_loss: 0.02503, quant_loss: 1.94922, bit_balance_loss: 0.00015) batch_time=0.46266 
Train Epoch: 6 [243/250 31104/32000 (97%)] Loss: 1.97891 (semantic_loss: 0.02857, quant_loss: 1.95020, bit_balance_loss: 0.00015) batch_time=0.33183 
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/DCMH_MSRVTT_full/checkpoint-epoch6.pth ...
Done in 4.294s
Updating 'best' checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/DCMH_MSRVTT_full/checkpoint-epoch6.pth ...
Done in 8.285s
removing stale ckpt [epoch 5] [took 0.00s]
 epoch          : 6
 loss           : 1.9769243006706239
 learning_rate  : 3.868904687499999e-05
 n_samples      : 192000
 n_steps        : 1500
 MSRVTT_full_val/t2v_metrics/R1: 12.273641851106639
 MSRVTT_full_val/t2v_metrics/R5: 42.454728370221325
 MSRVTT_full_val/t2v_metrics/R10: 59.55734406438632
 MSRVTT_full_val/t2v_metrics/R50: 91.54929577464789
 MSRVTT_full_val/t2v_metrics/MedR: 8.0
 MSRVTT_full_val/t2v_metrics/MeanR: 18.046277665995976
 MSRVTT_full_val/t2v_metrics/geometric_mean_R1-R5-R10: 31.425216500338678
 MSRVTT_full_val/v2t_metrics/R1: 12.072434607645874
 MSRVTT_full_val/v2t_metrics/R5: 46.07645875251509
 MSRVTT_full_val/v2t_metrics/R10: 62.374245472837025
 MSRVTT_full_val/v2t_metrics/R50: 92.5553319919517
 MSRVTT_full_val/v2t_metrics/MedR: 6.0
 MSRVTT_full_val/v2t_metrics/MeanR: 16.78672032193159
 MSRVTT_full_val/v2t_metrics/geometric_mean_R1-R5-R10: 32.6156786946158
 MSRVTT_full_test/t2v_metrics/R1: 4.247491638795987
 MSRVTT_full_test/t2v_metrics/R5: 15.217391304347826
 MSRVTT_full_test/t2v_metrics/R10: 25.85284280936455
 MSRVTT_full_test/t2v_metrics/R50: 60.869565217391305
 MSRVTT_full_test/t2v_metrics/MedR: 32.0
 MSRVTT_full_test/t2v_metrics/MeanR: 88.52959866220736
 MSRVTT_full_test/t2v_metrics/geometric_mean_R1-R5-R10: 11.866619458144127
 MSRVTT_full_test/v2t_metrics/R1: 3.678929765886288
 MSRVTT_full_test/v2t_metrics/R5: 15.852842809364548
 MSRVTT_full_test/v2t_metrics/R10: 25.953177257525084
 MSRVTT_full_test/v2t_metrics/R50: 62.508361204013376
 MSRVTT_full_test/v2t_metrics/MedR: 30.5
 MSRVTT_full_test/v2t_metrics/MeanR: 84.85752508361205
 MSRVTT_full_test/v2t_metrics/geometric_mean_R1-R5-R10: 11.48170526560581
 mnt_best       : 11.866619458144127
 not_improved_count: 0
Train Epoch: 7 [1/250 128/32000 (0%)] Loss: 1.97444 (semantic_loss: 0.02507, quant_loss: 1.94922, bit_balance_loss: 0.00015) batch_time=28.10122 
Train Epoch: 7 [12/250 1536/32000 (5%)] Loss: 1.97502 (semantic_loss: 0.02467, quant_loss: 1.95020, bit_balance_loss: 0.00015) batch_time=0.36254 
Train Epoch: 7 [23/250 2944/32000 (9%)] Loss: 1.97558 (semantic_loss: 0.02621, quant_loss: 1.94922, bit_balance_loss: 0.00015) batch_time=0.34553 
Train Epoch: 7 [34/250 4352/32000 (14%)] Loss: 1.97528 (semantic_loss: 0.02493, quant_loss: 1.95020, bit_balance_loss: 0.00015) batch_time=0.34276 
Train Epoch: 7 [45/250 5760/32000 (18%)] Loss: 1.97659 (semantic_loss: 0.02624, quant_loss: 1.95020, bit_balance_loss: 0.00015) batch_time=0.34612 
Train Epoch: 7 [56/250 7168/32000 (22%)] Loss: 1.97507 (semantic_loss: 0.02472, quant_loss: 1.95020, bit_balance_loss: 0.00015) batch_time=0.36783 
Train Epoch: 7 [67/250 8576/32000 (27%)] Loss: 1.97549 (semantic_loss: 0.02612, quant_loss: 1.94922, bit_balance_loss: 0.00015) batch_time=0.45175 
Train Epoch: 7 [78/250 9984/32000 (31%)] Loss: 1.97513 (semantic_loss: 0.02576, quant_loss: 1.94922, bit_balance_loss: 0.00015) batch_time=3.77321 
Train Epoch: 7 [89/250 11392/32000 (36%)] Loss: 1.97397 (semantic_loss: 0.02461, quant_loss: 1.94922, bit_balance_loss: 0.00015) batch_time=0.37438 
Train Epoch: 7 [100/250 12800/32000 (40%)] Loss: 1.97724 (semantic_loss: 0.02690, quant_loss: 1.95020, bit_balance_loss: 0.00015) batch_time=0.36891 
Train Epoch: 7 [111/250 14208/32000 (44%)] Loss: 1.97495 (semantic_loss: 0.02461, quant_loss: 1.95020, bit_balance_loss: 0.00015) batch_time=0.33957 
Train Epoch: 7 [122/250 15616/32000 (49%)] Loss: 1.97612 (semantic_loss: 0.02577, quant_loss: 1.95020, bit_balance_loss: 0.00015) batch_time=0.34689 
Train Epoch: 7 [133/250 17024/32000 (53%)] Loss: 1.97371 (semantic_loss: 0.02434, quant_loss: 1.94922, bit_balance_loss: 0.00015) batch_time=0.47549 
Train Epoch: 7 [144/250 18432/32000 (58%)] Loss: 1.97519 (semantic_loss: 0.02582, quant_loss: 1.94922, bit_balance_loss: 0.00015) batch_time=3.31274 
Train Epoch: 7 [155/250 19840/32000 (62%)] Loss: 1.97343 (semantic_loss: 0.02406, quant_loss: 1.94922, bit_balance_loss: 0.00015) batch_time=0.38191 
Train Epoch: 7 [166/250 21248/32000 (66%)] Loss: 1.97391 (semantic_loss: 0.02455, quant_loss: 1.94922, bit_balance_loss: 0.00015) batch_time=0.32741 
Train Epoch: 7 [177/250 22656/32000 (71%)] Loss: 1.97699 (semantic_loss: 0.02664, quant_loss: 1.95020, bit_balance_loss: 0.00015) batch_time=0.34110 
Train Epoch: 7 [188/250 24064/32000 (75%)] Loss: 1.97384 (semantic_loss: 0.02448, quant_loss: 1.94922, bit_balance_loss: 0.00015) batch_time=0.45855 
Train Epoch: 7 [199/250 25472/32000 (80%)] Loss: 1.97457 (semantic_loss: 0.02423, quant_loss: 1.95020, bit_balance_loss: 0.00015) batch_time=0.35592 
Train Epoch: 7 [210/250 26880/32000 (84%)] Loss: 1.97518 (semantic_loss: 0.02484, quant_loss: 1.95020, bit_balance_loss: 0.00015) batch_time=1.36500 
Train Epoch: 7 [221/250 28288/32000 (88%)] Loss: 1.97523 (semantic_loss: 0.02489, quant_loss: 1.95020, bit_balance_loss: 0.00015) batch_time=0.34089 
Train Epoch: 7 [232/250 29696/32000 (93%)] Loss: 1.97430 (semantic_loss: 0.02493, quant_loss: 1.94922, bit_balance_loss: 0.00015) batch_time=0.33147 
Train Epoch: 7 [243/250 31104/32000 (97%)] Loss: 1.97597 (semantic_loss: 0.02660, quant_loss: 1.94922, bit_balance_loss: 0.00015) batch_time=0.34283 
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/DCMH_MSRVTT_full/checkpoint-epoch7.pth ...
Done in 4.032s
Updating 'best' checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/DCMH_MSRVTT_full/checkpoint-epoch7.pth ...
Done in 8.043s
removing stale ckpt [epoch 6] [took 0.01s]
 epoch          : 7
 loss           : 1.9751533880233765
 learning_rate  : 3.675459453124999e-05
 n_samples      : 224000
 n_steps        : 1750
 MSRVTT_full_val/t2v_metrics/R1: 14.084507042253522
 MSRVTT_full_val/t2v_metrics/R5: 49.899396378269614
 MSRVTT_full_val/t2v_metrics/R10: 67.20321931589537
 MSRVTT_full_val/t2v_metrics/R50: 92.35412474849095
 MSRVTT_full_val/t2v_metrics/MedR: 6.0
 MSRVTT_full_val/t2v_metrics/MeanR: 15.927565392354126
 MSRVTT_full_val/t2v_metrics/geometric_mean_R1-R5-R10: 36.14728421338337
 MSRVTT_full_val/v2t_metrics/R1: 15.090543259557345
 MSRVTT_full_val/v2t_metrics/R5: 51.10663983903421
 MSRVTT_full_val/v2t_metrics/R10: 69.01408450704226
 MSRVTT_full_val/v2t_metrics/R50: 93.158953722334
 MSRVTT_full_val/v2t_metrics/MedR: 5.5
 MSRVTT_full_val/v2t_metrics/MeanR: 14.87625754527163
 MSRVTT_full_val/v2t_metrics/geometric_mean_R1-R5-R10: 37.61606058691163
 MSRVTT_full_test/t2v_metrics/R1: 4.414715719063545
 MSRVTT_full_test/t2v_metrics/R5: 16.354515050167223
 MSRVTT_full_test/t2v_metrics/R10: 26.989966555183948
 MSRVTT_full_test/t2v_metrics/R50: 64.18060200668896
 MSRVTT_full_test/t2v_metrics/MedR: 28.0
 MSRVTT_full_test/t2v_metrics/MeanR: 80.58277591973244
 MSRVTT_full_test/t2v_metrics/geometric_mean_R1-R5-R10: 12.490531530457323
 MSRVTT_full_test/v2t_metrics/R1: 4.381270903010034
 MSRVTT_full_test/v2t_metrics/R5: 18.294314381270905
 MSRVTT_full_test/v2t_metrics/R10: 28.963210702341136
 MSRVTT_full_test/v2t_metrics/R50: 65.41806020066889
 MSRVTT_full_test/v2t_metrics/MedR: 27.0
 MSRVTT_full_test/v2t_metrics/MeanR: 76.74280936454849
 MSRVTT_full_test/v2t_metrics/geometric_mean_R1-R5-R10: 13.241006019901905
 mnt_best       : 12.490531530457323
 not_improved_count: 0
Train Epoch: 8 [1/250 128/32000 (0%)] Loss: 1.97396 (semantic_loss: 0.02460, quant_loss: 1.94922, bit_balance_loss: 0.00015) batch_time=34.75777 
Train Epoch: 8 [12/250 1536/32000 (5%)] Loss: 1.97592 (semantic_loss: 0.02655, quant_loss: 1.94922, bit_balance_loss: 0.00015) batch_time=0.35870 
Train Epoch: 8 [23/250 2944/32000 (9%)] Loss: 1.97432 (semantic_loss: 0.02398, quant_loss: 1.95020, bit_balance_loss: 0.00015) batch_time=0.34477 
Train Epoch: 8 [34/250 4352/32000 (14%)] Loss: 1.97494 (semantic_loss: 0.02558, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.33931 
Train Epoch: 8 [45/250 5760/32000 (18%)] Loss: 1.97302 (semantic_loss: 0.02366, quant_loss: 1.94922, bit_balance_loss: 0.00015) batch_time=0.35312 
Train Epoch: 8 [56/250 7168/32000 (22%)] Loss: 1.97482 (semantic_loss: 0.02448, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.37888 
Train Epoch: 8 [67/250 8576/32000 (27%)] Loss: 1.97355 (semantic_loss: 0.02419, quant_loss: 1.94922, bit_balance_loss: 0.00015) batch_time=0.36390 
Train Epoch: 8 [78/250 9984/32000 (31%)] Loss: 1.97585 (semantic_loss: 0.02649, quant_loss: 1.94922, bit_balance_loss: 0.00015) batch_time=0.37229 
Train Epoch: 8 [89/250 11392/32000 (36%)] Loss: 1.97508 (semantic_loss: 0.02474, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.33683 
Train Epoch: 8 [100/250 12800/32000 (40%)] Loss: 1.97491 (semantic_loss: 0.02457, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.35116 
Train Epoch: 8 [111/250 14208/32000 (44%)] Loss: 1.97570 (semantic_loss: 0.02536, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.33270 
Train Epoch: 8 [122/250 15616/32000 (49%)] Loss: 1.97251 (semantic_loss: 0.02217, quant_loss: 1.95020, bit_balance_loss: 0.00015) batch_time=0.36716 
Train Epoch: 8 [133/250 17024/32000 (53%)] Loss: 1.97336 (semantic_loss: 0.02399, quant_loss: 1.94922, bit_balance_loss: 0.00015) batch_time=0.36934 
Train Epoch: 8 [144/250 18432/32000 (58%)] Loss: 1.97387 (semantic_loss: 0.02353, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.37638 
Train Epoch: 8 [155/250 19840/32000 (62%)] Loss: 1.97591 (semantic_loss: 0.02556, quant_loss: 1.95020, bit_balance_loss: 0.00015) batch_time=0.34041 
Train Epoch: 8 [166/250 21248/32000 (66%)] Loss: 1.97295 (semantic_loss: 0.02358, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.34557 
Train Epoch: 8 [177/250 22656/32000 (71%)] Loss: 1.97451 (semantic_loss: 0.02514, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.34627 
Train Epoch: 8 [188/250 24064/32000 (75%)] Loss: 1.97211 (semantic_loss: 0.02274, quant_loss: 1.94922, bit_balance_loss: 0.00015) batch_time=0.37927 
Train Epoch: 8 [199/250 25472/32000 (80%)] Loss: 1.97212 (semantic_loss: 0.02275, quant_loss: 1.94922, bit_balance_loss: 0.00015) batch_time=0.37334 
Train Epoch: 8 [210/250 26880/32000 (84%)] Loss: 1.97631 (semantic_loss: 0.02597, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=4.56336 
Train Epoch: 8 [221/250 28288/32000 (88%)] Loss: 1.97428 (semantic_loss: 0.02394, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.37028 
Train Epoch: 8 [232/250 29696/32000 (93%)] Loss: 1.97361 (semantic_loss: 0.02327, quant_loss: 1.95020, bit_balance_loss: 0.00015) batch_time=0.34190 
Train Epoch: 8 [243/250 31104/32000 (97%)] Loss: 1.97339 (semantic_loss: 0.02304, quant_loss: 1.95020, bit_balance_loss: 0.00015) batch_time=0.33536 
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/DCMH_MSRVTT_full/checkpoint-epoch8.pth ...
Done in 4.039s
Updating 'best' checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/DCMH_MSRVTT_full/checkpoint-epoch8.pth ...
Done in 7.759s
removing stale ckpt [epoch 7] [took 0.00s]
 epoch          : 8
 loss           : 1.9740591506958007
 learning_rate  : 3.4916864804687486e-05
 n_samples      : 256000
 n_steps        : 2000
 MSRVTT_full_val/t2v_metrics/R1: 17.303822937625753
 MSRVTT_full_val/t2v_metrics/R5: 51.10663983903421
 MSRVTT_full_val/t2v_metrics/R10: 68.41046277665995
 MSRVTT_full_val/t2v_metrics/R50: 92.75653923541248
 MSRVTT_full_val/t2v_metrics/MedR: 5.0
 MSRVTT_full_val/t2v_metrics/MeanR: 15.16297786720322
 MSRVTT_full_val/t2v_metrics/geometric_mean_R1-R5-R10: 39.25671661427181
 MSRVTT_full_val/v2t_metrics/R1: 16.29778672032193
 MSRVTT_full_val/v2t_metrics/R5: 54.12474849094568
 MSRVTT_full_val/v2t_metrics/R10: 71.62977867203219
 MSRVTT_full_val/v2t_metrics/R50: 92.5553319919517
 MSRVTT_full_val/v2t_metrics/MedR: 5.0
 MSRVTT_full_val/v2t_metrics/MeanR: 13.88128772635815
 MSRVTT_full_val/v2t_metrics/geometric_mean_R1-R5-R10: 39.82960904683676
 MSRVTT_full_test/t2v_metrics/R1: 4.448160535117057
 MSRVTT_full_test/t2v_metrics/R5: 18.99665551839465
 MSRVTT_full_test/t2v_metrics/R10: 31.204013377926422
 MSRVTT_full_test/t2v_metrics/R50: 66.25418060200668
 MSRVTT_full_test/t2v_metrics/MedR: 25.0
 MSRVTT_full_test/t2v_metrics/MeanR: 76.18578595317726
 MSRVTT_full_test/t2v_metrics/geometric_mean_R1-R5-R10: 13.815163162902147
 MSRVTT_full_test/v2t_metrics/R1: 5.317725752508361
 MSRVTT_full_test/v2t_metrics/R5: 21.103678929765888
 MSRVTT_full_test/v2t_metrics/R10: 32.90969899665552
 MSRVTT_full_test/v2t_metrics/R50: 68.56187290969899
 MSRVTT_full_test/v2t_metrics/MedR: 23.0
 MSRVTT_full_test/v2t_metrics/MeanR: 70.58043478260869
 MSRVTT_full_test/v2t_metrics/geometric_mean_R1-R5-R10: 15.457384343666748
 mnt_best       : 13.815163162902147
 not_improved_count: 0
Train Epoch: 9 [1/250 128/32000 (0%)] Loss: 1.97515 (semantic_loss: 0.02578, quant_loss: 1.94922, bit_balance_loss: 0.00015) batch_time=32.85489 
Train Epoch: 9 [12/250 1536/32000 (5%)] Loss: 1.97281 (semantic_loss: 0.02247, quant_loss: 1.95020, bit_balance_loss: 0.00015) batch_time=0.33819 
Train Epoch: 9 [23/250 2944/32000 (9%)] Loss: 1.97244 (semantic_loss: 0.02308, quant_loss: 1.94922, bit_balance_loss: 0.00015) batch_time=0.34938 
Train Epoch: 9 [34/250 4352/32000 (14%)] Loss: 1.97305 (semantic_loss: 0.02271, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.36190 
Train Epoch: 9 [45/250 5760/32000 (18%)] Loss: 1.97264 (semantic_loss: 0.02328, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.37223 
Train Epoch: 9 [56/250 7168/32000 (22%)] Loss: 1.97323 (semantic_loss: 0.02387, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.33159 
Train Epoch: 9 [67/250 8576/32000 (27%)] Loss: 1.97417 (semantic_loss: 0.02383, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.34012 
Train Epoch: 9 [78/250 9984/32000 (31%)] Loss: 1.97267 (semantic_loss: 0.02330, quant_loss: 1.94922, bit_balance_loss: 0.00015) batch_time=7.08008 
Train Epoch: 9 [89/250 11392/32000 (36%)] Loss: 1.97249 (semantic_loss: 0.02215, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.36193 
Train Epoch: 9 [100/250 12800/32000 (40%)] Loss: 1.97280 (semantic_loss: 0.02246, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.35073 
Train Epoch: 9 [111/250 14208/32000 (44%)] Loss: 1.97480 (semantic_loss: 0.02446, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.33929 
Train Epoch: 9 [122/250 15616/32000 (49%)] Loss: 1.97358 (semantic_loss: 0.02324, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.33674 
Train Epoch: 9 [133/250 17024/32000 (53%)] Loss: 1.97418 (semantic_loss: 0.02482, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.34165 
Train Epoch: 9 [144/250 18432/32000 (58%)] Loss: 1.97325 (semantic_loss: 0.02292, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.37140 
Train Epoch: 9 [155/250 19840/32000 (62%)] Loss: 1.97279 (semantic_loss: 0.02342, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.33560 
Train Epoch: 9 [166/250 21248/32000 (66%)] Loss: 1.97037 (semantic_loss: 0.02101, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.36886 
Train Epoch: 9 [177/250 22656/32000 (71%)] Loss: 1.97139 (semantic_loss: 0.02203, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.37724 
Train Epoch: 9 [188/250 24064/32000 (75%)] Loss: 1.97406 (semantic_loss: 0.02372, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.38089 
Train Epoch: 9 [199/250 25472/32000 (80%)] Loss: 1.97433 (semantic_loss: 0.02497, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.35925 
Train Epoch: 9 [210/250 26880/32000 (84%)] Loss: 1.97318 (semantic_loss: 0.02284, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.35096 
Train Epoch: 9 [221/250 28288/32000 (88%)] Loss: 1.97236 (semantic_loss: 0.02300, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.35844 
Train Epoch: 9 [232/250 29696/32000 (93%)] Loss: 1.97327 (semantic_loss: 0.02391, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.35376 
Train Epoch: 9 [243/250 31104/32000 (97%)] Loss: 1.97130 (semantic_loss: 0.02194, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.34648 
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/DCMH_MSRVTT_full/checkpoint-epoch9.pth ...
Done in 6.962s
Updating 'best' checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/DCMH_MSRVTT_full/checkpoint-epoch9.pth ...
Done in 10.816s
removing stale ckpt [epoch 8] [took 0.01s]
 epoch          : 9
 loss           : 1.9731301808357238
 learning_rate  : 3.317102156445311e-05
 n_samples      : 288000
 n_steps        : 2250
 MSRVTT_full_val/t2v_metrics/R1: 15.895372233400403
 MSRVTT_full_val/t2v_metrics/R5: 51.10663983903421
 MSRVTT_full_val/t2v_metrics/R10: 66.80080482897384
 MSRVTT_full_val/t2v_metrics/R50: 92.5553319919517
 MSRVTT_full_val/t2v_metrics/MedR: 5.0
 MSRVTT_full_val/t2v_metrics/MeanR: 14.995975855130785
 MSRVTT_full_val/t2v_metrics/geometric_mean_R1-R5-R10: 37.859648291482884
 MSRVTT_full_val/v2t_metrics/R1: 14.285714285714286
 MSRVTT_full_val/v2t_metrics/R5: 52.91750503018109
 MSRVTT_full_val/v2t_metrics/R10: 70.62374245472837
 MSRVTT_full_val/v2t_metrics/R50: 93.36016096579476
 MSRVTT_full_val/v2t_metrics/MedR: 5.0
 MSRVTT_full_val/v2t_metrics/MeanR: 13.545271629778671
 MSRVTT_full_val/v2t_metrics/geometric_mean_R1-R5-R10: 37.65454023148374
 MSRVTT_full_test/t2v_metrics/R1: 5.384615384615385
 MSRVTT_full_test/t2v_metrics/R5: 19.297658862876254
 MSRVTT_full_test/t2v_metrics/R10: 31.270903010033443
 MSRVTT_full_test/t2v_metrics/R50: 67.32441471571906
 MSRVTT_full_test/t2v_metrics/MedR: 25.0
 MSRVTT_full_test/t2v_metrics/MeanR: 74.58896321070235
 MSRVTT_full_test/t2v_metrics/geometric_mean_R1-R5-R10: 14.81152962988078
 MSRVTT_full_test/v2t_metrics/R1: 5.384615384615385
 MSRVTT_full_test/v2t_metrics/R5: 20.066889632107024
 MSRVTT_full_test/v2t_metrics/R10: 31.77257525083612
 MSRVTT_full_test/v2t_metrics/R50: 68.62876254180603
 MSRVTT_full_test/v2t_metrics/MedR: 23.0
 MSRVTT_full_test/v2t_metrics/MeanR: 70.24013377926421
 MSRVTT_full_test/v2t_metrics/geometric_mean_R1-R5-R10: 15.085593082316395
 mnt_best       : 14.81152962988078
 not_improved_count: 0
Train Epoch: 10 [1/250 128/32000 (0%)] Loss: 1.97240 (semantic_loss: 0.02206, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=31.74078 
Train Epoch: 10 [12/250 1536/32000 (5%)] Loss: 1.97277 (semantic_loss: 0.02243, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=3.19361 
Train Epoch: 10 [23/250 2944/32000 (9%)] Loss: 1.97282 (semantic_loss: 0.02346, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=1.04536 
Train Epoch: 10 [34/250 4352/32000 (14%)] Loss: 1.97405 (semantic_loss: 0.02371, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.34694 
Train Epoch: 10 [45/250 5760/32000 (18%)] Loss: 1.97367 (semantic_loss: 0.02333, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.34413 
Train Epoch: 10 [56/250 7168/32000 (22%)] Loss: 1.97157 (semantic_loss: 0.02221, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.33709 
Train Epoch: 10 [67/250 8576/32000 (27%)] Loss: 1.97265 (semantic_loss: 0.02329, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.34402 
Train Epoch: 10 [78/250 9984/32000 (31%)] Loss: 1.97191 (semantic_loss: 0.02158, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.33395 
Train Epoch: 10 [89/250 11392/32000 (36%)] Loss: 1.97185 (semantic_loss: 0.02151, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.33448 
Train Epoch: 10 [100/250 12800/32000 (40%)] Loss: 1.97019 (semantic_loss: 0.02083, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.33371 
Train Epoch: 10 [111/250 14208/32000 (44%)] Loss: 1.96975 (semantic_loss: 0.02039, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.33864 
Train Epoch: 10 [122/250 15616/32000 (49%)] Loss: 1.97459 (semantic_loss: 0.02328, quant_loss: 1.95117, bit_balance_loss: 0.00014) batch_time=0.36273 
Train Epoch: 10 [133/250 17024/32000 (53%)] Loss: 1.97258 (semantic_loss: 0.02322, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.34495 
Train Epoch: 10 [144/250 18432/32000 (58%)] Loss: 1.97313 (semantic_loss: 0.02279, quant_loss: 1.95020, bit_balance_loss: 0.00015) batch_time=2.39725 
Train Epoch: 10 [155/250 19840/32000 (62%)] Loss: 1.97129 (semantic_loss: 0.02095, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.34853 
Train Epoch: 10 [166/250 21248/32000 (66%)] Loss: 1.97055 (semantic_loss: 0.02119, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.36199 
Train Epoch: 10 [177/250 22656/32000 (71%)] Loss: 1.97235 (semantic_loss: 0.02202, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.39321 
Train Epoch: 10 [188/250 24064/32000 (75%)] Loss: 1.97018 (semantic_loss: 0.02082, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.34234 
Train Epoch: 10 [199/250 25472/32000 (80%)] Loss: 1.97114 (semantic_loss: 0.02080, quant_loss: 1.95020, bit_balance_loss: 0.00015) batch_time=0.33292 
Train Epoch: 10 [210/250 26880/32000 (84%)] Loss: 1.97488 (semantic_loss: 0.02455, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.38122 
Train Epoch: 10 [221/250 28288/32000 (88%)] Loss: 1.97254 (semantic_loss: 0.02318, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.35268 
Train Epoch: 10 [232/250 29696/32000 (93%)] Loss: 1.97222 (semantic_loss: 0.02189, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.56155 
Train Epoch: 10 [243/250 31104/32000 (97%)] Loss: 1.97267 (semantic_loss: 0.02233, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.34966 
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/DCMH_MSRVTT_full/checkpoint-epoch10.pth ...
Done in 4.566s
Updating 'best' checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/DCMH_MSRVTT_full/checkpoint-epoch10.pth ...
Done in 8.653s
removing stale ckpt [epoch 9] [took 0.00s]
 epoch          : 10
 loss           : 1.9722250061035156
 learning_rate  : 3.151247048623045e-05
 n_samples      : 320000
 n_steps        : 2500
 MSRVTT_full_val/t2v_metrics/R1: 15.694164989939638
 MSRVTT_full_val/t2v_metrics/R5: 48.69215291750503
 MSRVTT_full_val/t2v_metrics/R10: 67.6056338028169
 MSRVTT_full_val/t2v_metrics/R50: 94.36619718309859
 MSRVTT_full_val/t2v_metrics/MedR: 6.0
 MSRVTT_full_val/t2v_metrics/MeanR: 14.777665995975855
 MSRVTT_full_val/t2v_metrics/geometric_mean_R1-R5-R10: 37.244318045316845
 MSRVTT_full_val/v2t_metrics/R1: 16.29778672032193
 MSRVTT_full_val/v2t_metrics/R5: 53.118712273641854
 MSRVTT_full_val/v2t_metrics/R10: 70.02012072434607
 MSRVTT_full_val/v2t_metrics/R50: 94.56740442655935
 MSRVTT_full_val/v2t_metrics/MedR: 5.0
 MSRVTT_full_val/v2t_metrics/MeanR: 12.714285714285714
 MSRVTT_full_val/v2t_metrics/geometric_mean_R1-R5-R10: 39.28255022953261
 MSRVTT_full_test/t2v_metrics/R1: 5.351170568561873
 MSRVTT_full_test/t2v_metrics/R5: 20.03344481605351
 MSRVTT_full_test/t2v_metrics/R10: 30.869565217391305
 MSRVTT_full_test/t2v_metrics/R50: 66.92307692307692
 MSRVTT_full_test/t2v_metrics/MedR: 25.0
 MSRVTT_full_test/t2v_metrics/MeanR: 77.8314381270903
 MSRVTT_full_test/t2v_metrics/geometric_mean_R1-R5-R10: 14.902014456276266
 MSRVTT_full_test/v2t_metrics/R1: 5.217391304347826
 MSRVTT_full_test/v2t_metrics/R5: 21.270903010033443
 MSRVTT_full_test/v2t_metrics/R10: 32.07357859531773
 MSRVTT_full_test/v2t_metrics/R50: 68.29431438127091
 MSRVTT_full_test/v2t_metrics/MedR: 23.0
 MSRVTT_full_test/v2t_metrics/MeanR: 69.61488294314381
 MSRVTT_full_test/v2t_metrics/geometric_mean_R1-R5-R10: 15.268472295576558
 mnt_best       : 14.902014456276266
 not_improved_count: 0
Train Epoch: 11 [1/250 128/32000 (0%)] Loss: 1.97218 (semantic_loss: 0.02185, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=34.23220 
Train Epoch: 11 [12/250 1536/32000 (5%)] Loss: 1.97282 (semantic_loss: 0.02248, quant_loss: 1.95020, bit_balance_loss: 0.00015) batch_time=0.39298 
Train Epoch: 11 [23/250 2944/32000 (9%)] Loss: 1.97067 (semantic_loss: 0.02131, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.35307 
Train Epoch: 11 [34/250 4352/32000 (14%)] Loss: 1.97232 (semantic_loss: 0.02199, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.37068 
Train Epoch: 11 [45/250 5760/32000 (18%)] Loss: 1.96858 (semantic_loss: 0.02019, quant_loss: 1.94824, bit_balance_loss: 0.00014) batch_time=0.34110 
Train Epoch: 11 [56/250 7168/32000 (22%)] Loss: 1.97203 (semantic_loss: 0.02169, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.34754 
Train Epoch: 11 [67/250 8576/32000 (27%)] Loss: 1.96819 (semantic_loss: 0.01882, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.35905 
Train Epoch: 11 [78/250 9984/32000 (31%)] Loss: 1.97304 (semantic_loss: 0.02172, quant_loss: 1.95117, bit_balance_loss: 0.00014) batch_time=0.32928 
Train Epoch: 11 [89/250 11392/32000 (36%)] Loss: 1.97272 (semantic_loss: 0.02335, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.34007 
Train Epoch: 11 [100/250 12800/32000 (40%)] Loss: 1.97342 (semantic_loss: 0.02308, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.33310 
Train Epoch: 11 [111/250 14208/32000 (44%)] Loss: 1.97102 (semantic_loss: 0.02166, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.35619 
Train Epoch: 11 [122/250 15616/32000 (49%)] Loss: 1.97187 (semantic_loss: 0.02153, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.36933 
Train Epoch: 11 [133/250 17024/32000 (53%)] Loss: 1.97202 (semantic_loss: 0.02168, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.32800 
Train Epoch: 11 [144/250 18432/32000 (58%)] Loss: 1.97240 (semantic_loss: 0.02206, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.35474 
Train Epoch: 11 [155/250 19840/32000 (62%)] Loss: 1.97162 (semantic_loss: 0.02226, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.38055 
Train Epoch: 11 [166/250 21248/32000 (66%)] Loss: 1.97183 (semantic_loss: 0.02150, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.38986 
Train Epoch: 11 [177/250 22656/32000 (71%)] Loss: 1.97097 (semantic_loss: 0.02161, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.34697 
Train Epoch: 11 [188/250 24064/32000 (75%)] Loss: 1.97369 (semantic_loss: 0.02237, quant_loss: 1.95117, bit_balance_loss: 0.00014) batch_time=0.34811 
Train Epoch: 11 [199/250 25472/32000 (80%)] Loss: 1.97481 (semantic_loss: 0.02448, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.35140 
Train Epoch: 11 [210/250 26880/32000 (84%)] Loss: 1.97118 (semantic_loss: 0.02182, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.33276 
Train Epoch: 11 [221/250 28288/32000 (88%)] Loss: 1.97162 (semantic_loss: 0.02129, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.34076 
Train Epoch: 11 [232/250 29696/32000 (93%)] Loss: 1.97246 (semantic_loss: 0.02212, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.34741 
Train Epoch: 11 [243/250 31104/32000 (97%)] Loss: 1.97055 (semantic_loss: 0.02119, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.34644 
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/DCMH_MSRVTT_full/checkpoint-epoch11.pth ...
Done in 18.228s
Updating 'best' checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/DCMH_MSRVTT_full/checkpoint-epoch11.pth ...
Done in 22.306s
removing stale ckpt [epoch 10] [took 0.00s]
 epoch          : 11
 loss           : 1.9714753336906432
 learning_rate  : 2.993684696191893e-05
 n_samples      : 352000
 n_steps        : 2750
 MSRVTT_full_val/t2v_metrics/R1: 17.706237424547282
 MSRVTT_full_val/t2v_metrics/R5: 53.31991951710262
 MSRVTT_full_val/t2v_metrics/R10: 68.41046277665995
 MSRVTT_full_val/t2v_metrics/R50: 93.56136820925553
 MSRVTT_full_val/t2v_metrics/MedR: 5.0
 MSRVTT_full_val/t2v_metrics/MeanR: 14.396378269617706
 MSRVTT_full_val/t2v_metrics/geometric_mean_R1-R5-R10: 40.12170979660853
 MSRVTT_full_val/v2t_metrics/R1: 16.498993963782695
 MSRVTT_full_val/v2t_metrics/R5: 55.1307847082495
 MSRVTT_full_val/v2t_metrics/R10: 69.61770623742454
 MSRVTT_full_val/v2t_metrics/R50: 93.36016096579476
 MSRVTT_full_val/v2t_metrics/MedR: 5.0
 MSRVTT_full_val/v2t_metrics/MeanR: 12.938631790744466
 MSRVTT_full_val/v2t_metrics/geometric_mean_R1-R5-R10: 39.85875989537627
 MSRVTT_full_test/t2v_metrics/R1: 6.187290969899665
 MSRVTT_full_test/t2v_metrics/R5: 21.337792642140467
 MSRVTT_full_test/t2v_metrics/R10: 33.47826086956522
 MSRVTT_full_test/t2v_metrics/R50: 68.29431438127091
 MSRVTT_full_test/t2v_metrics/MedR: 22.0
 MSRVTT_full_test/t2v_metrics/MeanR: 74.83578595317725
 MSRVTT_full_test/t2v_metrics/geometric_mean_R1-R5-R10: 16.411098036630644
 MSRVTT_full_test/v2t_metrics/R1: 5.919732441471572
 MSRVTT_full_test/v2t_metrics/R5: 23.244147157190636
 MSRVTT_full_test/v2t_metrics/R10: 34.81605351170568
 MSRVTT_full_test/v2t_metrics/R50: 69.93311036789298
 MSRVTT_full_test/v2t_metrics/MedR: 21.5
 MSRVTT_full_test/v2t_metrics/MeanR: 67.8953177257525
 MSRVTT_full_test/v2t_metrics/geometric_mean_R1-R5-R10: 16.857703531288102
 mnt_best       : 16.411098036630644
 not_improved_count: 0
Train Epoch: 12 [1/250 128/32000 (0%)] Loss: 1.97078 (semantic_loss: 0.02142, quant_loss: 1.94922, bit_balance_loss: 0.00015) batch_time=29.48307 
Train Epoch: 12 [12/250 1536/32000 (5%)] Loss: 1.97242 (semantic_loss: 0.02305, quant_loss: 1.94922, bit_balance_loss: 0.00015) batch_time=0.34048 
Train Epoch: 12 [23/250 2944/32000 (9%)] Loss: 1.97043 (semantic_loss: 0.02107, quant_loss: 1.94922, bit_balance_loss: 0.00015) batch_time=0.34299 
Train Epoch: 12 [34/250 4352/32000 (14%)] Loss: 1.97048 (semantic_loss: 0.02112, quant_loss: 1.94922, bit_balance_loss: 0.00015) batch_time=0.34763 
Train Epoch: 12 [45/250 5760/32000 (18%)] Loss: 1.97197 (semantic_loss: 0.02163, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.37887 
Train Epoch: 12 [56/250 7168/32000 (22%)] Loss: 1.97152 (semantic_loss: 0.02119, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.34872 
Train Epoch: 12 [67/250 8576/32000 (27%)] Loss: 1.97007 (semantic_loss: 0.02071, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.36886 
Train Epoch: 12 [78/250 9984/32000 (31%)] Loss: 1.97133 (semantic_loss: 0.02099, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.33002 
Train Epoch: 12 [89/250 11392/32000 (36%)] Loss: 1.97102 (semantic_loss: 0.02068, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.33059 
Train Epoch: 12 [100/250 12800/32000 (40%)] Loss: 1.97129 (semantic_loss: 0.02096, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.33796 
Train Epoch: 12 [111/250 14208/32000 (44%)] Loss: 1.97111 (semantic_loss: 0.02078, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.36189 
Train Epoch: 12 [122/250 15616/32000 (49%)] Loss: 1.97136 (semantic_loss: 0.02200, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.34265 
Train Epoch: 12 [133/250 17024/32000 (53%)] Loss: 1.97031 (semantic_loss: 0.02094, quant_loss: 1.94922, bit_balance_loss: 0.00015) batch_time=0.33285 
Train Epoch: 12 [144/250 18432/32000 (58%)] Loss: 1.96926 (semantic_loss: 0.01989, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.36877 
Train Epoch: 12 [155/250 19840/32000 (62%)] Loss: 1.97021 (semantic_loss: 0.02085, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.37035 
Train Epoch: 12 [166/250 21248/32000 (66%)] Loss: 1.96906 (semantic_loss: 0.01970, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.33351 
Train Epoch: 12 [177/250 22656/32000 (71%)] Loss: 1.97020 (semantic_loss: 0.02084, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.34093 
Train Epoch: 12 [188/250 24064/32000 (75%)] Loss: 1.96914 (semantic_loss: 0.01978, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.34833 
Train Epoch: 12 [199/250 25472/32000 (80%)] Loss: 1.97087 (semantic_loss: 0.02053, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.33680 
Train Epoch: 12 [210/250 26880/32000 (84%)] Loss: 1.96978 (semantic_loss: 0.01944, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=3.70390 
Train Epoch: 12 [221/250 28288/32000 (88%)] Loss: 1.97070 (semantic_loss: 0.02036, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.36555 
Train Epoch: 12 [232/250 29696/32000 (93%)] Loss: 1.96978 (semantic_loss: 0.02042, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.35053 
Train Epoch: 12 [243/250 31104/32000 (97%)] Loss: 1.97088 (semantic_loss: 0.02152, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.38595 
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/DCMH_MSRVTT_full/checkpoint-epoch12.pth ...
Done in 18.046s
Updating 'best' checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/DCMH_MSRVTT_full/checkpoint-epoch12.pth ...
Done in 22.189s
removing stale ckpt [epoch 11] [took 0.01s]
 epoch          : 12
 loss           : 1.9707341833114624
 learning_rate  : 2.844000461382298e-05
 n_samples      : 384000
 n_steps        : 3000
 MSRVTT_full_val/t2v_metrics/R1: 20.72434607645875
 MSRVTT_full_val/t2v_metrics/R5: 56.94164989939638
 MSRVTT_full_val/t2v_metrics/R10: 72.23340040241449
 MSRVTT_full_val/t2v_metrics/R50: 94.76861167002012
 MSRVTT_full_val/t2v_metrics/MedR: 5.0
 MSRVTT_full_val/t2v_metrics/MeanR: 12.486921529175051
 MSRVTT_full_val/t2v_metrics/geometric_mean_R1-R5-R10: 44.00982559702672
 MSRVTT_full_val/v2t_metrics/R1: 18.91348088531187
 MSRVTT_full_val/v2t_metrics/R5: 58.14889336016097
 MSRVTT_full_val/v2t_metrics/R10: 73.2394366197183
 MSRVTT_full_val/v2t_metrics/R50: 94.36619718309859
 MSRVTT_full_val/v2t_metrics/MedR: 4.0
 MSRVTT_full_val/v2t_metrics/MeanR: 11.94466800804829
 MSRVTT_full_val/v2t_metrics/geometric_mean_R1-R5-R10: 43.186960348349544
 MSRVTT_full_test/t2v_metrics/R1: 5.88628762541806
 MSRVTT_full_test/t2v_metrics/R5: 22.775919732441473
 MSRVTT_full_test/t2v_metrics/R10: 35.65217391304348
 MSRVTT_full_test/t2v_metrics/R50: 71.23745819397993
 MSRVTT_full_test/t2v_metrics/MedR: 20.0
 MSRVTT_full_test/t2v_metrics/MeanR: 65.57307692307693
 MSRVTT_full_test/t2v_metrics/geometric_mean_R1-R5-R10: 16.844875539200718
 MSRVTT_full_test/v2t_metrics/R1: 6.321070234113712
 MSRVTT_full_test/v2t_metrics/R5: 23.54515050167224
 MSRVTT_full_test/v2t_metrics/R10: 36.65551839464883
 MSRVTT_full_test/v2t_metrics/R50: 71.97324414715719
 MSRVTT_full_test/v2t_metrics/MedR: 18.5
 MSRVTT_full_test/v2t_metrics/MeanR: 62.45836120401338
 MSRVTT_full_test/v2t_metrics/geometric_mean_R1-R5-R10: 17.603964502679943
 mnt_best       : 16.844875539200718
 not_improved_count: 0
Train Epoch: 13 [1/250 128/32000 (0%)] Loss: 1.97172 (semantic_loss: 0.02236, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=33.15875 
Train Epoch: 13 [12/250 1536/32000 (5%)] Loss: 1.97003 (semantic_loss: 0.02067, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.35023 
Train Epoch: 13 [23/250 2944/32000 (9%)] Loss: 1.96972 (semantic_loss: 0.02134, quant_loss: 1.94824, bit_balance_loss: 0.00014) batch_time=0.38180 
Train Epoch: 13 [34/250 4352/32000 (14%)] Loss: 1.97013 (semantic_loss: 0.01979, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.37153 
Train Epoch: 13 [45/250 5760/32000 (18%)] Loss: 1.97053 (semantic_loss: 0.02019, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.37127 
Train Epoch: 13 [56/250 7168/32000 (22%)] Loss: 1.96978 (semantic_loss: 0.02042, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.33735 
Train Epoch: 13 [67/250 8576/32000 (27%)] Loss: 1.96803 (semantic_loss: 0.01867, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.33932 
Train Epoch: 13 [78/250 9984/32000 (31%)] Loss: 1.96926 (semantic_loss: 0.01990, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.34761 
Train Epoch: 13 [89/250 11392/32000 (36%)] Loss: 1.97059 (semantic_loss: 0.02026, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.34849 
Train Epoch: 13 [100/250 12800/32000 (40%)] Loss: 1.97087 (semantic_loss: 0.02053, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.34284 
Train Epoch: 13 [111/250 14208/32000 (44%)] Loss: 1.96945 (semantic_loss: 0.01911, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.36142 
Train Epoch: 13 [122/250 15616/32000 (49%)] Loss: 1.97094 (semantic_loss: 0.02061, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.40638 
Train Epoch: 13 [133/250 17024/32000 (53%)] Loss: 1.96948 (semantic_loss: 0.01914, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.35133 
Train Epoch: 13 [144/250 18432/32000 (58%)] Loss: 1.97062 (semantic_loss: 0.02028, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=2.73428 
Train Epoch: 13 [155/250 19840/32000 (62%)] Loss: 1.96914 (semantic_loss: 0.01978, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.38852 
Train Epoch: 13 [166/250 21248/32000 (66%)] Loss: 1.97008 (semantic_loss: 0.02072, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.34396 
Train Epoch: 13 [177/250 22656/32000 (71%)] Loss: 1.96984 (semantic_loss: 0.02047, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.32936 
Train Epoch: 13 [188/250 24064/32000 (75%)] Loss: 1.97048 (semantic_loss: 0.02015, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.33931 
Train Epoch: 13 [199/250 25472/32000 (80%)] Loss: 1.96859 (semantic_loss: 0.01923, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=1.97124 
Train Epoch: 13 [210/250 26880/32000 (84%)] Loss: 1.96970 (semantic_loss: 0.02034, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.34053 
Train Epoch: 13 [221/250 28288/32000 (88%)] Loss: 1.97099 (semantic_loss: 0.02066, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.36918 
Train Epoch: 13 [232/250 29696/32000 (93%)] Loss: 1.97090 (semantic_loss: 0.02154, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.86897 
Train Epoch: 13 [243/250 31104/32000 (97%)] Loss: 1.97136 (semantic_loss: 0.02102, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.33735 
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/DCMH_MSRVTT_full/checkpoint-epoch13.pth ...
Done in 4.545s
Updating 'best' checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/DCMH_MSRVTT_full/checkpoint-epoch13.pth ...
Done in 8.437s
removing stale ckpt [epoch 12] [took 0.00s]
 epoch          : 13
 loss           : 1.9701430792808532
 learning_rate  : 2.7018004383131832e-05
 n_samples      : 416000
 n_steps        : 3250
 MSRVTT_full_val/t2v_metrics/R1: 19.114688128772634
 MSRVTT_full_val/t2v_metrics/R5: 55.734406438631794
 MSRVTT_full_val/t2v_metrics/R10: 71.42857142857143
 MSRVTT_full_val/t2v_metrics/R50: 94.16498993963782
 MSRVTT_full_val/t2v_metrics/MedR: 4.0
 MSRVTT_full_val/t2v_metrics/MeanR: 12.203219315895373
 MSRVTT_full_val/t2v_metrics/geometric_mean_R1-R5-R10: 42.37608721287829
 MSRVTT_full_val/v2t_metrics/R1: 20.523138832997986
 MSRVTT_full_val/v2t_metrics/R5: 60.160965794768615
 MSRVTT_full_val/v2t_metrics/R10: 73.44064386317908
 MSRVTT_full_val/v2t_metrics/R50: 95.17102615694165
 MSRVTT_full_val/v2t_metrics/MedR: 4.0
 MSRVTT_full_val/v2t_metrics/MeanR: 11.299798792756539
 MSRVTT_full_val/v2t_metrics/geometric_mean_R1-R5-R10: 44.926062068350376
 MSRVTT_full_test/t2v_metrics/R1: 6.086956521739131
 MSRVTT_full_test/t2v_metrics/R5: 24.08026755852843
 MSRVTT_full_test/t2v_metrics/R10: 35.585284280936456
 MSRVTT_full_test/t2v_metrics/R50: 72.10702341137124
 MSRVTT_full_test/t2v_metrics/MedR: 20.0
 MSRVTT_full_test/t2v_metrics/MeanR: 65.13294314381271
 MSRVTT_full_test/t2v_metrics/geometric_mean_R1-R5-R10: 17.34245790961053
 MSRVTT_full_test/v2t_metrics/R1: 7.357859531772576
 MSRVTT_full_test/v2t_metrics/R5: 25.953177257525084
 MSRVTT_full_test/v2t_metrics/R10: 39.63210702341137
 MSRVTT_full_test/v2t_metrics/R50: 75.25083612040133
 MSRVTT_full_test/v2t_metrics/MedR: 16.5
 MSRVTT_full_test/v2t_metrics/MeanR: 57.671571906354515
 MSRVTT_full_test/v2t_metrics/geometric_mean_R1-R5-R10: 19.633439831017117
 mnt_best       : 17.34245790961053
 not_improved_count: 0
Train Epoch: 14 [1/250 128/32000 (0%)] Loss: 1.96999 (semantic_loss: 0.02063, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=40.18106 
Train Epoch: 14 [12/250 1536/32000 (5%)] Loss: 1.96999 (semantic_loss: 0.02063, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.33476 
Train Epoch: 14 [23/250 2944/32000 (9%)] Loss: 1.97107 (semantic_loss: 0.02074, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.33745 
Train Epoch: 14 [34/250 4352/32000 (14%)] Loss: 1.96941 (semantic_loss: 0.02005, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.35067 
Train Epoch: 14 [45/250 5760/32000 (18%)] Loss: 1.96932 (semantic_loss: 0.01899, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.34775 
Train Epoch: 14 [56/250 7168/32000 (22%)] Loss: 1.97051 (semantic_loss: 0.02115, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.34777 
Train Epoch: 14 [67/250 8576/32000 (27%)] Loss: 1.96886 (semantic_loss: 0.01950, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.35218 
Train Epoch: 14 [78/250 9984/32000 (31%)] Loss: 1.97085 (semantic_loss: 0.02052, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.33039 
Train Epoch: 14 [89/250 11392/32000 (36%)] Loss: 1.96953 (semantic_loss: 0.02017, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.38448 
Train Epoch: 14 [100/250 12800/32000 (40%)] Loss: 1.97148 (semantic_loss: 0.02115, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.33253 
Train Epoch: 14 [111/250 14208/32000 (44%)] Loss: 1.96887 (semantic_loss: 0.01854, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.44364 
Train Epoch: 14 [122/250 15616/32000 (49%)] Loss: 1.96827 (semantic_loss: 0.01891, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.33555 
Train Epoch: 14 [133/250 17024/32000 (53%)] Loss: 1.96971 (semantic_loss: 0.01937, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.37228 
Train Epoch: 14 [144/250 18432/32000 (58%)] Loss: 1.97252 (semantic_loss: 0.02218, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.34981 
Train Epoch: 14 [155/250 19840/32000 (62%)] Loss: 1.97068 (semantic_loss: 0.02034, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.35826 
Train Epoch: 14 [166/250 21248/32000 (66%)] Loss: 1.96797 (semantic_loss: 0.01861, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.47345 
Train Epoch: 14 [177/250 22656/32000 (71%)] Loss: 1.97020 (semantic_loss: 0.01985, quant_loss: 1.95020, bit_balance_loss: 0.00015) batch_time=0.34218 
Train Epoch: 14 [188/250 24064/32000 (75%)] Loss: 1.96762 (semantic_loss: 0.01826, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.33970 
Train Epoch: 14 [199/250 25472/32000 (80%)] Loss: 1.97018 (semantic_loss: 0.01984, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.38331 
Train Epoch: 14 [210/250 26880/32000 (84%)] Loss: 1.96831 (semantic_loss: 0.01895, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.32934 
Train Epoch: 14 [221/250 28288/32000 (88%)] Loss: 1.96985 (semantic_loss: 0.01951, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.33266 
Train Epoch: 14 [232/250 29696/32000 (93%)] Loss: 1.97039 (semantic_loss: 0.02102, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.32945 
Train Epoch: 14 [243/250 31104/32000 (97%)] Loss: 1.96962 (semantic_loss: 0.01928, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.34751 
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/DCMH_MSRVTT_full/checkpoint-epoch14.pth ...
Done in 4.114s
Updating 'best' checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/DCMH_MSRVTT_full/checkpoint-epoch14.pth ...
Done in 8.917s
removing stale ckpt [epoch 13] [took 0.00s]
 epoch          : 14
 loss           : 1.9695526356697082
 learning_rate  : 2.566710416397524e-05
 n_samples      : 448000
 n_steps        : 3500
 MSRVTT_full_val/t2v_metrics/R1: 17.505030181086518
 MSRVTT_full_val/t2v_metrics/R5: 56.74044265593562
 MSRVTT_full_val/t2v_metrics/R10: 70.62374245472837
 MSRVTT_full_val/t2v_metrics/R50: 93.36016096579476
 MSRVTT_full_val/t2v_metrics/MedR: 5.0
 MSRVTT_full_val/t2v_metrics/MeanR: 13.8158953722334
 MSRVTT_full_val/t2v_metrics/geometric_mean_R1-R5-R10: 41.24159347959206
 MSRVTT_full_val/v2t_metrics/R1: 21.327967806841045
 MSRVTT_full_val/v2t_metrics/R5: 58.75251509054326
 MSRVTT_full_val/v2t_metrics/R10: 73.03822937625755
 MSRVTT_full_val/v2t_metrics/R50: 94.56740442655935
 MSRVTT_full_val/v2t_metrics/MedR: 4.0
 MSRVTT_full_val/v2t_metrics/MeanR: 11.865191146881287
 MSRVTT_full_val/v2t_metrics/geometric_mean_R1-R5-R10: 45.06527841685346
 MSRVTT_full_test/t2v_metrics/R1: 6.521739130434782
 MSRVTT_full_test/t2v_metrics/R5: 23.17725752508361
 MSRVTT_full_test/t2v_metrics/R10: 35.11705685618729
 MSRVTT_full_test/t2v_metrics/R50: 70.5685618729097
 MSRVTT_full_test/t2v_metrics/MedR: 20.75
 MSRVTT_full_test/t2v_metrics/MeanR: 72.27140468227425
 MSRVTT_full_test/t2v_metrics/geometric_mean_R1-R5-R10: 17.44407157737787
 MSRVTT_full_test/v2t_metrics/R1: 6.7558528428093645
 MSRVTT_full_test/v2t_metrics/R5: 24.347826086956523
 MSRVTT_full_test/v2t_metrics/R10: 37.357859531772576
 MSRVTT_full_test/v2t_metrics/R50: 72.3076923076923
 MSRVTT_full_test/v2t_metrics/MedR: 18.0
 MSRVTT_full_test/v2t_metrics/MeanR: 65.59749163879599
 MSRVTT_full_test/v2t_metrics/geometric_mean_R1-R5-R10: 18.316428105436536
 mnt_best       : 17.44407157737787
 not_improved_count: 0
Train Epoch: 15 [1/250 128/32000 (0%)] Loss: 1.97179 (semantic_loss: 0.02146, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=32.77202 
Train Epoch: 15 [12/250 1536/32000 (5%)] Loss: 1.96953 (semantic_loss: 0.01920, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.35121 
Train Epoch: 15 [23/250 2944/32000 (9%)] Loss: 1.97126 (semantic_loss: 0.02093, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.38289 
Train Epoch: 15 [34/250 4352/32000 (14%)] Loss: 1.96801 (semantic_loss: 0.01864, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.34288 
Train Epoch: 15 [45/250 5760/32000 (18%)] Loss: 1.96913 (semantic_loss: 0.01977, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.34920 
Train Epoch: 15 [56/250 7168/32000 (22%)] Loss: 1.96953 (semantic_loss: 0.01920, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.37347 
Train Epoch: 15 [67/250 8576/32000 (27%)] Loss: 1.96944 (semantic_loss: 0.01911, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.34354 
Train Epoch: 15 [78/250 9984/32000 (31%)] Loss: 1.97071 (semantic_loss: 0.01940, quant_loss: 1.95117, bit_balance_loss: 0.00014) batch_time=0.36537 
Train Epoch: 15 [89/250 11392/32000 (36%)] Loss: 1.97005 (semantic_loss: 0.01971, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.34690 
Train Epoch: 15 [100/250 12800/32000 (40%)] Loss: 1.96870 (semantic_loss: 0.01836, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.33870 
Train Epoch: 15 [111/250 14208/32000 (44%)] Loss: 1.96991 (semantic_loss: 0.01957, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.38632 
Train Epoch: 15 [122/250 15616/32000 (49%)] Loss: 1.96752 (semantic_loss: 0.01816, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.33836 
Train Epoch: 15 [133/250 17024/32000 (53%)] Loss: 1.97072 (semantic_loss: 0.02038, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.36839 
Train Epoch: 15 [144/250 18432/32000 (58%)] Loss: 1.96988 (semantic_loss: 0.01955, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.35068 
Train Epoch: 15 [155/250 19840/32000 (62%)] Loss: 1.96927 (semantic_loss: 0.01894, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.34753 
Train Epoch: 15 [166/250 21248/32000 (66%)] Loss: 1.96651 (semantic_loss: 0.01715, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.34780 
Train Epoch: 15 [177/250 22656/32000 (71%)] Loss: 1.97049 (semantic_loss: 0.01918, quant_loss: 1.95117, bit_balance_loss: 0.00015) batch_time=0.38041 
Train Epoch: 15 [188/250 24064/32000 (75%)] Loss: 1.97012 (semantic_loss: 0.02076, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.34772 
Train Epoch: 15 [199/250 25472/32000 (80%)] Loss: 1.97116 (semantic_loss: 0.02180, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.33049 
Train Epoch: 15 [210/250 26880/32000 (84%)] Loss: 1.96978 (semantic_loss: 0.02042, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.34599 
Train Epoch: 15 [221/250 28288/32000 (88%)] Loss: 1.96897 (semantic_loss: 0.01863, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.34211 
Train Epoch: 15 [232/250 29696/32000 (93%)] Loss: 1.96837 (semantic_loss: 0.01901, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.36693 
Train Epoch: 15 [243/250 31104/32000 (97%)] Loss: 1.96779 (semantic_loss: 0.01843, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.54816 
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/DCMH_MSRVTT_full/checkpoint-epoch15.pth ...
Done in 4.034s
Updating 'best' checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/DCMH_MSRVTT_full/checkpoint-epoch15.pth ...
Done in 8.334s
removing stale ckpt [epoch 14] [took 0.02s]
 epoch          : 15
 loss           : 1.9691570582389832
 learning_rate  : 2.4383748955776477e-05
 n_samples      : 480000
 n_steps        : 3750
 MSRVTT_full_val/t2v_metrics/R1: 21.327967806841045
 MSRVTT_full_val/t2v_metrics/R5: 56.33802816901409
 MSRVTT_full_val/t2v_metrics/R10: 71.42857142857143
 MSRVTT_full_val/t2v_metrics/R50: 94.56740442655935
 MSRVTT_full_val/t2v_metrics/MedR: 4.0
 MSRVTT_full_val/t2v_metrics/MeanR: 13.030181086519114
 MSRVTT_full_val/t2v_metrics/geometric_mean_R1-R5-R10: 44.11040322724108
 MSRVTT_full_val/v2t_metrics/R1: 22.93762575452716
 MSRVTT_full_val/v2t_metrics/R5: 59.758551307847085
 MSRVTT_full_val/v2t_metrics/R10: 73.03822937625755
 MSRVTT_full_val/v2t_metrics/R50: 95.17102615694165
 MSRVTT_full_val/v2t_metrics/MedR: 4.0
 MSRVTT_full_val/v2t_metrics/MeanR: 11.800804828973844
 MSRVTT_full_val/v2t_metrics/geometric_mean_R1-R5-R10: 46.43366029918887
 MSRVTT_full_test/t2v_metrics/R1: 6.923076923076923
 MSRVTT_full_test/t2v_metrics/R5: 24.214046822742475
 MSRVTT_full_test/t2v_metrics/R10: 37.290969899665555
 MSRVTT_full_test/t2v_metrics/R50: 72.14046822742475
 MSRVTT_full_test/t2v_metrics/MedR: 18.0
 MSRVTT_full_test/t2v_metrics/MeanR: 66.21270903010033
 MSRVTT_full_test/t2v_metrics/geometric_mean_R1-R5-R10: 18.421432737983213
 MSRVTT_full_test/v2t_metrics/R1: 7.6923076923076925
 MSRVTT_full_test/v2t_metrics/R5: 26.588628762541806
 MSRVTT_full_test/v2t_metrics/R10: 39.7324414715719
 MSRVTT_full_test/v2t_metrics/R50: 73.67892976588628
 MSRVTT_full_test/v2t_metrics/MedR: 17.0
 MSRVTT_full_test/v2t_metrics/MeanR: 62.97458193979933
 MSRVTT_full_test/v2t_metrics/geometric_mean_R1-R5-R10: 20.104777916454005
 mnt_best       : 18.421432737983213
 not_improved_count: 0
Train Epoch: 16 [1/250 128/32000 (0%)] Loss: 1.96868 (semantic_loss: 0.01933, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=31.68989 
Train Epoch: 16 [12/250 1536/32000 (5%)] Loss: 1.96745 (semantic_loss: 0.01809, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.33824 
Train Epoch: 16 [23/250 2944/32000 (9%)] Loss: 1.96891 (semantic_loss: 0.01954, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.34738 
Train Epoch: 16 [34/250 4352/32000 (14%)] Loss: 1.96822 (semantic_loss: 0.01886, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.35562 
Train Epoch: 16 [45/250 5760/32000 (18%)] Loss: 1.96878 (semantic_loss: 0.01942, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.35744 
Train Epoch: 16 [56/250 7168/32000 (22%)] Loss: 1.96825 (semantic_loss: 0.01889, quant_loss: 1.94922, bit_balance_loss: 0.00015) batch_time=0.35561 
Train Epoch: 16 [67/250 8576/32000 (27%)] Loss: 1.96865 (semantic_loss: 0.01831, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.33167 
Train Epoch: 16 [78/250 9984/32000 (31%)] Loss: 1.97007 (semantic_loss: 0.01973, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.33536 
Train Epoch: 16 [89/250 11392/32000 (36%)] Loss: 1.96787 (semantic_loss: 0.01850, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.33186 
Train Epoch: 16 [100/250 12800/32000 (40%)] Loss: 1.96807 (semantic_loss: 0.01773, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.33960 
Train Epoch: 16 [111/250 14208/32000 (44%)] Loss: 1.96866 (semantic_loss: 0.01930, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.35138 
Train Epoch: 16 [122/250 15616/32000 (49%)] Loss: 1.97041 (semantic_loss: 0.02007, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.34140 
Train Epoch: 16 [133/250 17024/32000 (53%)] Loss: 1.96877 (semantic_loss: 0.01844, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.33211 
Train Epoch: 16 [144/250 18432/32000 (58%)] Loss: 1.96704 (semantic_loss: 0.01768, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.34825 
Train Epoch: 16 [155/250 19840/32000 (62%)] Loss: 1.96878 (semantic_loss: 0.01941, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.35190 
Train Epoch: 16 [166/250 21248/32000 (66%)] Loss: 1.96949 (semantic_loss: 0.01915, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.35971 
Train Epoch: 16 [177/250 22656/32000 (71%)] Loss: 1.96744 (semantic_loss: 0.01807, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.37683 
Train Epoch: 16 [188/250 24064/32000 (75%)] Loss: 1.96851 (semantic_loss: 0.01915, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.33125 
Train Epoch: 16 [199/250 25472/32000 (80%)] Loss: 1.97083 (semantic_loss: 0.02049, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=1.97499 
Train Epoch: 16 [210/250 26880/32000 (84%)] Loss: 1.96898 (semantic_loss: 0.01865, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.33705 
Train Epoch: 16 [221/250 28288/32000 (88%)] Loss: 1.96881 (semantic_loss: 0.01945, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.33271 
Train Epoch: 16 [232/250 29696/32000 (93%)] Loss: 1.96786 (semantic_loss: 0.01850, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.34894 
Train Epoch: 16 [243/250 31104/32000 (97%)] Loss: 1.97026 (semantic_loss: 0.01992, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.36467 
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/DCMH_MSRVTT_full/checkpoint-epoch16.pth ...
Done in 4.418s
removing stale ckpt [epoch 15] [took 0.01s]
 epoch          : 16
 loss           : 1.9687350430488586
 learning_rate  : 2.3164561507987653e-05
 n_samples      : 512000
 n_steps        : 4000
 MSRVTT_full_val/t2v_metrics/R1: 21.93158953722334
 MSRVTT_full_val/t2v_metrics/R5: 58.5513078470825
 MSRVTT_full_val/t2v_metrics/R10: 73.03822937625755
 MSRVTT_full_val/t2v_metrics/R50: 95.57344064386318
 MSRVTT_full_val/t2v_metrics/MedR: 4.0
 MSRVTT_full_val/t2v_metrics/MeanR: 11.954728370221329
 MSRVTT_full_val/t2v_metrics/geometric_mean_R1-R5-R10: 45.43448906960718
 MSRVTT_full_val/v2t_metrics/R1: 24.949698189134807
 MSRVTT_full_val/v2t_metrics/R5: 59.55734406438632
 MSRVTT_full_val/v2t_metrics/R10: 74.64788732394366
 MSRVTT_full_val/v2t_metrics/R50: 95.17102615694165
 MSRVTT_full_val/v2t_metrics/MedR: 3.5
 MSRVTT_full_val/v2t_metrics/MeanR: 11.169014084507042
 MSRVTT_full_val/v2t_metrics/geometric_mean_R1-R5-R10: 48.04771216912589
 MSRVTT_full_test/t2v_metrics/R1: 7.1237458193979935
 MSRVTT_full_test/t2v_metrics/R5: 23.745819397993312
 MSRVTT_full_test/t2v_metrics/R10: 36.12040133779264
 MSRVTT_full_test/t2v_metrics/R50: 73.27759197324414
 MSRVTT_full_test/t2v_metrics/MedR: 18.5
 MSRVTT_full_test/t2v_metrics/MeanR: 63.538127090301
 MSRVTT_full_test/t2v_metrics/geometric_mean_R1-R5-R10: 18.28167767276693
 MSRVTT_full_test/v2t_metrics/R1: 8.127090301003344
 MSRVTT_full_test/v2t_metrics/R5: 26.555183946488295
 MSRVTT_full_test/v2t_metrics/R10: 40.23411371237458
 MSRVTT_full_test/v2t_metrics/R50: 75.15050167224081
 MSRVTT_full_test/v2t_metrics/MedR: 16.25
 MSRVTT_full_test/v2t_metrics/MeanR: 57.50267558528428
 MSRVTT_full_test/v2t_metrics/geometric_mean_R1-R5-R10: 20.553838800843153
 mnt_best       : 18.421432737983213
 not_improved_count: 1
Train Epoch: 17 [1/250 128/32000 (0%)] Loss: 1.96852 (semantic_loss: 0.01819, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=33.53284 
Train Epoch: 17 [12/250 1536/32000 (5%)] Loss: 1.97002 (semantic_loss: 0.02066, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.33763 
Train Epoch: 17 [23/250 2944/32000 (9%)] Loss: 1.97094 (semantic_loss: 0.02061, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.34765 
Train Epoch: 17 [34/250 4352/32000 (14%)] Loss: 1.96808 (semantic_loss: 0.01774, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=1.02090 
Train Epoch: 17 [45/250 5760/32000 (18%)] Loss: 1.96827 (semantic_loss: 0.01793, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.33109 
Train Epoch: 17 [56/250 7168/32000 (22%)] Loss: 1.96972 (semantic_loss: 0.01938, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.34830 
Train Epoch: 17 [67/250 8576/32000 (27%)] Loss: 1.96794 (semantic_loss: 0.01761, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.33189 
Train Epoch: 17 [78/250 9984/32000 (31%)] Loss: 1.96961 (semantic_loss: 0.01830, quant_loss: 1.95117, bit_balance_loss: 0.00014) batch_time=0.34054 
Train Epoch: 17 [89/250 11392/32000 (36%)] Loss: 1.96652 (semantic_loss: 0.01716, quant_loss: 1.94922, bit_balance_loss: 0.00015) batch_time=0.34108 
Train Epoch: 17 [100/250 12800/32000 (40%)] Loss: 1.96794 (semantic_loss: 0.01858, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.34034 
Train Epoch: 17 [111/250 14208/32000 (44%)] Loss: 1.96964 (semantic_loss: 0.01931, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.34109 
Train Epoch: 17 [122/250 15616/32000 (49%)] Loss: 1.96933 (semantic_loss: 0.01900, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.39967 
Train Epoch: 17 [133/250 17024/32000 (53%)] Loss: 1.96775 (semantic_loss: 0.01741, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.34078 
Train Epoch: 17 [144/250 18432/32000 (58%)] Loss: 1.96784 (semantic_loss: 0.01751, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=4.03724 
Train Epoch: 17 [155/250 19840/32000 (62%)] Loss: 1.96901 (semantic_loss: 0.01867, quant_loss: 1.95020, bit_balance_loss: 0.00015) batch_time=0.34846 
Train Epoch: 17 [166/250 21248/32000 (66%)] Loss: 1.96864 (semantic_loss: 0.01830, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.36611 
Train Epoch: 17 [177/250 22656/32000 (71%)] Loss: 1.96996 (semantic_loss: 0.02060, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.33472 
Train Epoch: 17 [188/250 24064/32000 (75%)] Loss: 1.96644 (semantic_loss: 0.01708, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.34320 
Train Epoch: 17 [199/250 25472/32000 (80%)] Loss: 1.96662 (semantic_loss: 0.01628, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.34281 
Train Epoch: 17 [210/250 26880/32000 (84%)] Loss: 1.97028 (semantic_loss: 0.01994, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.34219 
Train Epoch: 17 [221/250 28288/32000 (88%)] Loss: 1.96929 (semantic_loss: 0.01896, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.33008 
Train Epoch: 17 [232/250 29696/32000 (93%)] Loss: 1.96794 (semantic_loss: 0.01858, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.34184 
Train Epoch: 17 [243/250 31104/32000 (97%)] Loss: 1.96809 (semantic_loss: 0.01775, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.33218 
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/DCMH_MSRVTT_full/checkpoint-epoch17.pth ...
Done in 4.828s
removing stale ckpt [epoch 16] [took 0.01s]
 epoch          : 17
 loss           : 1.968494870185852
 learning_rate  : 2.2006333432588268e-05
 n_samples      : 544000
 n_steps        : 4250
 MSRVTT_full_val/t2v_metrics/R1: 22.736418511066397
 MSRVTT_full_val/t2v_metrics/R5: 57.34406438631791
 MSRVTT_full_val/t2v_metrics/R10: 72.83702213279678
 MSRVTT_full_val/t2v_metrics/R50: 95.37223340040241
 MSRVTT_full_val/t2v_metrics/MedR: 4.0
 MSRVTT_full_val/t2v_metrics/MeanR: 12.180080482897385
 MSRVTT_full_val/t2v_metrics/geometric_mean_R1-R5-R10: 45.62339181968526
 MSRVTT_full_val/v2t_metrics/R1: 21.52917505030181
 MSRVTT_full_val/v2t_metrics/R5: 61.3682092555332
 MSRVTT_full_val/v2t_metrics/R10: 75.45271629778672
 MSRVTT_full_val/v2t_metrics/R50: 95.77464788732394
 MSRVTT_full_val/v2t_metrics/MedR: 4.0
 MSRVTT_full_val/v2t_metrics/MeanR: 11.091549295774648
 MSRVTT_full_val/v2t_metrics/geometric_mean_R1-R5-R10: 46.36766643443383
 MSRVTT_full_test/t2v_metrics/R1: 7.023411371237458
 MSRVTT_full_test/t2v_metrics/R5: 23.745819397993312
 MSRVTT_full_test/t2v_metrics/R10: 35.88628762541806
 MSRVTT_full_test/t2v_metrics/R50: 72.97658862876254
 MSRVTT_full_test/t2v_metrics/MedR: 19.0
 MSRVTT_full_test/t2v_metrics/MeanR: 62.72458193979933
 MSRVTT_full_test/t2v_metrics/geometric_mean_R1-R5-R10: 18.156045683040535
 MSRVTT_full_test/v2t_metrics/R1: 7.8595317725752505
 MSRVTT_full_test/v2t_metrics/R5: 27.65886287625418
 MSRVTT_full_test/v2t_metrics/R10: 40.43478260869565
 MSRVTT_full_test/v2t_metrics/R50: 75.7190635451505
 MSRVTT_full_test/v2t_metrics/MedR: 16.0
 MSRVTT_full_test/v2t_metrics/MeanR: 56.02943143812709
 MSRVTT_full_test/v2t_metrics/geometric_mean_R1-R5-R10: 20.637735205923324
 mnt_best       : 18.421432737983213
 not_improved_count: 2
Train Epoch: 18 [1/250 128/32000 (0%)] Loss: 1.96955 (semantic_loss: 0.02020, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=31.36899 
Train Epoch: 18 [12/250 1536/32000 (5%)] Loss: 1.96826 (semantic_loss: 0.01793, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.38176 
Train Epoch: 18 [23/250 2944/32000 (9%)] Loss: 1.96752 (semantic_loss: 0.01718, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.41008 
Train Epoch: 18 [34/250 4352/32000 (14%)] Loss: 1.96948 (semantic_loss: 0.01914, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.34658 
Train Epoch: 18 [45/250 5760/32000 (18%)] Loss: 1.96912 (semantic_loss: 0.01878, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.35798 
Train Epoch: 18 [56/250 7168/32000 (22%)] Loss: 1.96765 (semantic_loss: 0.01732, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.34215 
Train Epoch: 18 [67/250 8576/32000 (27%)] Loss: 1.96699 (semantic_loss: 0.01861, quant_loss: 1.94824, bit_balance_loss: 0.00014) batch_time=0.36905 
Train Epoch: 18 [78/250 9984/32000 (31%)] Loss: 1.96743 (semantic_loss: 0.01807, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.33646 
Train Epoch: 18 [89/250 11392/32000 (36%)] Loss: 1.96816 (semantic_loss: 0.01782, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.34443 
Train Epoch: 18 [100/250 12800/32000 (40%)] Loss: 1.96666 (semantic_loss: 0.01730, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.39812 
Train Epoch: 18 [111/250 14208/32000 (44%)] Loss: 1.96915 (semantic_loss: 0.01979, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.34574 
Train Epoch: 18 [122/250 15616/32000 (49%)] Loss: 1.96669 (semantic_loss: 0.01733, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.35631 
Train Epoch: 18 [133/250 17024/32000 (53%)] Loss: 1.96915 (semantic_loss: 0.01881, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.33652 
Train Epoch: 18 [144/250 18432/32000 (58%)] Loss: 1.96662 (semantic_loss: 0.01726, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=1.46452 
Train Epoch: 18 [155/250 19840/32000 (62%)] Loss: 1.96668 (semantic_loss: 0.01732, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.37429 
Train Epoch: 18 [166/250 21248/32000 (66%)] Loss: 1.96659 (semantic_loss: 0.01626, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.34315 
Train Epoch: 18 [177/250 22656/32000 (71%)] Loss: 1.96831 (semantic_loss: 0.01797, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.33803 
Train Epoch: 18 [188/250 24064/32000 (75%)] Loss: 1.96681 (semantic_loss: 0.01647, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.33992 
Train Epoch: 18 [199/250 25472/32000 (80%)] Loss: 1.96776 (semantic_loss: 0.01743, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.32993 
Train Epoch: 18 [210/250 26880/32000 (84%)] Loss: 1.96712 (semantic_loss: 0.01678, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.35861 
Train Epoch: 18 [221/250 28288/32000 (88%)] Loss: 1.96781 (semantic_loss: 0.01747, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.35594 
Train Epoch: 18 [232/250 29696/32000 (93%)] Loss: 1.96925 (semantic_loss: 0.01892, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.33560 
Train Epoch: 18 [243/250 31104/32000 (97%)] Loss: 1.96820 (semantic_loss: 0.01786, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.33797 
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/DCMH_MSRVTT_full/checkpoint-epoch18.pth ...
Done in 3.882s
removing stale ckpt [epoch 17] [took 0.01s]
 epoch          : 18
 loss           : 1.9680484418869018
 learning_rate  : 2.0906016760958855e-05
 n_samples      : 576000
 n_steps        : 4500
 MSRVTT_full_val/t2v_metrics/R1: 20.321931589537222
 MSRVTT_full_val/t2v_metrics/R5: 56.74044265593562
 MSRVTT_full_val/t2v_metrics/R10: 73.44064386317908
 MSRVTT_full_val/t2v_metrics/R50: 93.56136820925553
 MSRVTT_full_val/t2v_metrics/MedR: 4.0
 MSRVTT_full_val/t2v_metrics/MeanR: 13.840040241448692
 MSRVTT_full_val/t2v_metrics/geometric_mean_R1-R5-R10: 43.91350075181507
 MSRVTT_full_val/v2t_metrics/R1: 22.535211267605632
 MSRVTT_full_val/v2t_metrics/R5: 59.95975855130785
 MSRVTT_full_val/v2t_metrics/R10: 75.45271629778672
 MSRVTT_full_val/v2t_metrics/R50: 93.96378269617706
 MSRVTT_full_val/v2t_metrics/MedR: 4.0
 MSRVTT_full_val/v2t_metrics/MeanR: 12.1579476861167
 MSRVTT_full_val/v2t_metrics/geometric_mean_R1-R5-R10: 46.71597988403775
 MSRVTT_full_test/t2v_metrics/R1: 7.290969899665551
 MSRVTT_full_test/t2v_metrics/R5: 23.54515050167224
 MSRVTT_full_test/t2v_metrics/R10: 35.585284280936456
 MSRVTT_full_test/t2v_metrics/R50: 70.23411371237458
 MSRVTT_full_test/t2v_metrics/MedR: 20.0
 MSRVTT_full_test/t2v_metrics/MeanR: 71.66404682274248
 MSRVTT_full_test/t2v_metrics/geometric_mean_R1-R5-R10: 18.28040185719597
 MSRVTT_full_test/v2t_metrics/R1: 7.6923076923076925
 MSRVTT_full_test/v2t_metrics/R5: 26.722408026755854
 MSRVTT_full_test/v2t_metrics/R10: 39.163879598662206
 MSRVTT_full_test/v2t_metrics/R50: 73.77926421404682
 MSRVTT_full_test/v2t_metrics/MedR: 17.0
 MSRVTT_full_test/v2t_metrics/MeanR: 61.753846153846155
 MSRVTT_full_test/v2t_metrics/geometric_mean_R1-R5-R10: 20.04191957955769
 mnt_best       : 18.421432737983213
 not_improved_count: 3
Train Epoch: 19 [1/250 128/32000 (0%)] Loss: 1.96754 (semantic_loss: 0.01720, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=35.31952 
Train Epoch: 19 [12/250 1536/32000 (5%)] Loss: 1.96741 (semantic_loss: 0.01708, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.33075 
Train Epoch: 19 [23/250 2944/32000 (9%)] Loss: 1.96894 (semantic_loss: 0.01860, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.34635 
Train Epoch: 19 [34/250 4352/32000 (14%)] Loss: 1.96883 (semantic_loss: 0.01947, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.34208 
Train Epoch: 19 [45/250 5760/32000 (18%)] Loss: 1.96686 (semantic_loss: 0.01653, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.34890 
Train Epoch: 19 [56/250 7168/32000 (22%)] Loss: 1.96749 (semantic_loss: 0.01813, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.35140 
Train Epoch: 19 [67/250 8576/32000 (27%)] Loss: 1.96651 (semantic_loss: 0.01715, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.34259 
Train Epoch: 19 [78/250 9984/32000 (31%)] Loss: 1.96878 (semantic_loss: 0.01844, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.38152 
Train Epoch: 19 [89/250 11392/32000 (36%)] Loss: 1.96935 (semantic_loss: 0.01902, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.33695 
Train Epoch: 19 [100/250 12800/32000 (40%)] Loss: 1.96645 (semantic_loss: 0.01709, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.33236 
Train Epoch: 19 [111/250 14208/32000 (44%)] Loss: 1.96765 (semantic_loss: 0.01829, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.33953 
Train Epoch: 19 [122/250 15616/32000 (49%)] Loss: 1.96923 (semantic_loss: 0.01889, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.33616 
Train Epoch: 19 [133/250 17024/32000 (53%)] Loss: 1.96574 (semantic_loss: 0.01638, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.34624 
Train Epoch: 19 [144/250 18432/32000 (58%)] Loss: 1.96655 (semantic_loss: 0.01720, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.91123 
Train Epoch: 19 [155/250 19840/32000 (62%)] Loss: 1.96639 (semantic_loss: 0.01703, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.35597 
Train Epoch: 19 [166/250 21248/32000 (66%)] Loss: 1.96937 (semantic_loss: 0.02001, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.35323 
Train Epoch: 19 [177/250 22656/32000 (71%)] Loss: 1.96694 (semantic_loss: 0.01660, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.33974 
Train Epoch: 19 [188/250 24064/32000 (75%)] Loss: 1.96800 (semantic_loss: 0.01864, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.34724 
Train Epoch: 19 [199/250 25472/32000 (80%)] Loss: 1.96712 (semantic_loss: 0.01678, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.34792 
Train Epoch: 19 [210/250 26880/32000 (84%)] Loss: 1.96877 (semantic_loss: 0.01844, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.60616 
Train Epoch: 19 [221/250 28288/32000 (88%)] Loss: 1.96728 (semantic_loss: 0.01695, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.33746 
Train Epoch: 19 [232/250 29696/32000 (93%)] Loss: 1.96757 (semantic_loss: 0.01723, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.34221 
Train Epoch: 19 [243/250 31104/32000 (97%)] Loss: 1.96846 (semantic_loss: 0.01910, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.33239 
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/DCMH_MSRVTT_full/checkpoint-epoch19.pth ...
Done in 12.530s
Updating 'best' checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/DCMH_MSRVTT_full/checkpoint-epoch19.pth ...
Done in 16.403s
removing stale ckpt [epoch 18] [took 0.00s]
 epoch          : 19
 loss           : 1.9677289638519286
 learning_rate  : 1.986071592291091e-05
 n_samples      : 608000
 n_steps        : 4750
 MSRVTT_full_val/t2v_metrics/R1: 21.12676056338028
 MSRVTT_full_val/t2v_metrics/R5: 59.55734406438632
 MSRVTT_full_val/t2v_metrics/R10: 74.04426559356136
 MSRVTT_full_val/t2v_metrics/R50: 95.77464788732394
 MSRVTT_full_val/t2v_metrics/MedR: 4.0
 MSRVTT_full_val/t2v_metrics/MeanR: 11.916498993963783
 MSRVTT_full_val/t2v_metrics/geometric_mean_R1-R5-R10: 45.33356651531817
 MSRVTT_full_val/v2t_metrics/R1: 22.535211267605632
 MSRVTT_full_val/v2t_metrics/R5: 62.57545271629779
 MSRVTT_full_val/v2t_metrics/R10: 77.06237424547284
 MSRVTT_full_val/v2t_metrics/R50: 95.17102615694165
 MSRVTT_full_val/v2t_metrics/MedR: 4.0
 MSRVTT_full_val/v2t_metrics/MeanR: 10.955734406438632
 MSRVTT_full_val/v2t_metrics/geometric_mean_R1-R5-R10: 47.720245927884065
 MSRVTT_full_test/t2v_metrics/R1: 7.1237458193979935
 MSRVTT_full_test/t2v_metrics/R5: 24.548494983277592
 MSRVTT_full_test/t2v_metrics/R10: 37.65886287625418
 MSRVTT_full_test/t2v_metrics/R50: 73.11036789297658
 MSRVTT_full_test/t2v_metrics/MedR: 18.0
 MSRVTT_full_test/t2v_metrics/MeanR: 63.67341137123746
 MSRVTT_full_test/t2v_metrics/geometric_mean_R1-R5-R10: 18.744196551971406
 MSRVTT_full_test/v2t_metrics/R1: 8.66220735785953
 MSRVTT_full_test/v2t_metrics/R5: 28.82943143812709
 MSRVTT_full_test/v2t_metrics/R10: 42.17391304347826
 MSRVTT_full_test/v2t_metrics/R50: 75.81939799331104
 MSRVTT_full_test/v2t_metrics/MedR: 15.0
 MSRVTT_full_test/v2t_metrics/MeanR: 55.33645484949833
 MSRVTT_full_test/v2t_metrics/geometric_mean_R1-R5-R10: 21.91977963860809
 mnt_best       : 18.744196551971406
 not_improved_count: 0
Train Epoch: 20 [1/250 128/32000 (0%)] Loss: 1.96951 (semantic_loss: 0.02015, quant_loss: 1.94922, bit_balance_loss: 0.00015) batch_time=29.34497 
Train Epoch: 20 [12/250 1536/32000 (5%)] Loss: 1.96697 (semantic_loss: 0.01761, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.39222 
Train Epoch: 20 [23/250 2944/32000 (9%)] Loss: 1.96777 (semantic_loss: 0.01841, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.34380 
Train Epoch: 20 [34/250 4352/32000 (14%)] Loss: 1.96634 (semantic_loss: 0.01600, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.57909 
Train Epoch: 20 [45/250 5760/32000 (18%)] Loss: 1.96690 (semantic_loss: 0.01755, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.34285 
Train Epoch: 20 [56/250 7168/32000 (22%)] Loss: 1.96673 (semantic_loss: 0.01640, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.34263 
Train Epoch: 20 [67/250 8576/32000 (27%)] Loss: 1.96800 (semantic_loss: 0.01865, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.33552 
Train Epoch: 20 [78/250 9984/32000 (31%)] Loss: 1.96876 (semantic_loss: 0.01843, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=2.53848 
Train Epoch: 20 [89/250 11392/32000 (36%)] Loss: 1.96755 (semantic_loss: 0.01721, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.35435 
Train Epoch: 20 [100/250 12800/32000 (40%)] Loss: 1.96597 (semantic_loss: 0.01564, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.39283 
Train Epoch: 20 [111/250 14208/32000 (44%)] Loss: 1.96767 (semantic_loss: 0.01734, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.35013 
Train Epoch: 20 [122/250 15616/32000 (49%)] Loss: 1.96897 (semantic_loss: 0.01863, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.34007 
Train Epoch: 20 [133/250 17024/32000 (53%)] Loss: 1.96638 (semantic_loss: 0.01605, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.40083 
Train Epoch: 20 [144/250 18432/32000 (58%)] Loss: 1.96810 (semantic_loss: 0.01777, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.34342 
Train Epoch: 20 [155/250 19840/32000 (62%)] Loss: 1.96718 (semantic_loss: 0.01685, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.34820 
Train Epoch: 20 [166/250 21248/32000 (66%)] Loss: 1.96520 (semantic_loss: 0.01584, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.34582 
Train Epoch: 20 [177/250 22656/32000 (71%)] Loss: 1.96616 (semantic_loss: 0.01583, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.37230 
Train Epoch: 20 [188/250 24064/32000 (75%)] Loss: 1.96824 (semantic_loss: 0.01790, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.72750 
Train Epoch: 20 [199/250 25472/32000 (80%)] Loss: 1.96740 (semantic_loss: 0.01805, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.34049 
Train Epoch: 20 [210/250 26880/32000 (84%)] Loss: 1.96881 (semantic_loss: 0.01750, quant_loss: 1.95117, bit_balance_loss: 0.00014) batch_time=0.34678 
Train Epoch: 20 [221/250 28288/32000 (88%)] Loss: 1.96769 (semantic_loss: 0.01736, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.35331 
Train Epoch: 20 [232/250 29696/32000 (93%)] Loss: 1.96552 (semantic_loss: 0.01616, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.35034 
Train Epoch: 20 [243/250 31104/32000 (97%)] Loss: 1.96720 (semantic_loss: 0.01686, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.36749 
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/DCMH_MSRVTT_full/checkpoint-epoch20.pth ...
Done in 17.503s
Updating 'best' checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/DCMH_MSRVTT_full/checkpoint-epoch20.pth ...
Done in 22.389s
removing stale ckpt [epoch 19] [took 0.01s]
 epoch          : 20
 loss           : 1.9673787593841552
 learning_rate  : 1.8867680126765363e-05
 n_samples      : 640000
 n_steps        : 5000
 MSRVTT_full_val/t2v_metrics/R1: 21.93158953722334
 MSRVTT_full_val/t2v_metrics/R5: 58.35010060362173
 MSRVTT_full_val/t2v_metrics/R10: 75.45271629778672
 MSRVTT_full_val/t2v_metrics/R50: 95.37223340040241
 MSRVTT_full_val/t2v_metrics/MedR: 4.0
 MSRVTT_full_val/t2v_metrics/MeanR: 12.640845070422536
 MSRVTT_full_val/t2v_metrics/geometric_mean_R1-R5-R10: 45.877055119573384
 MSRVTT_full_val/v2t_metrics/R1: 22.93762575452716
 MSRVTT_full_val/v2t_metrics/R5: 62.17303822937626
 MSRVTT_full_val/v2t_metrics/R10: 78.06841046277665
 MSRVTT_full_val/v2t_metrics/R50: 95.37223340040241
 MSRVTT_full_val/v2t_metrics/MedR: 3.5
 MSRVTT_full_val/v2t_metrics/MeanR: 11.16599597585513
 MSRVTT_full_val/v2t_metrics/geometric_mean_R1-R5-R10: 48.1070393609008
 MSRVTT_full_test/t2v_metrics/R1: 7.625418060200669
 MSRVTT_full_test/t2v_metrics/R5: 25.351170568561873
 MSRVTT_full_test/t2v_metrics/R10: 39.197324414715716
 MSRVTT_full_test/t2v_metrics/R50: 74.08026755852843
 MSRVTT_full_test/t2v_metrics/MedR: 17.0
 MSRVTT_full_test/t2v_metrics/MeanR: 62.691471571906355
 MSRVTT_full_test/t2v_metrics/geometric_mean_R1-R5-R10: 19.64141173966355
 MSRVTT_full_test/v2t_metrics/R1: 9.23076923076923
 MSRVTT_full_test/v2t_metrics/R5: 28.494983277591974
 MSRVTT_full_test/v2t_metrics/R10: 42.575250836120404
 MSRVTT_full_test/v2t_metrics/R50: 76.82274247491638
 MSRVTT_full_test/v2t_metrics/MedR: 14.0
 MSRVTT_full_test/v2t_metrics/MeanR: 55.03846153846154
 MSRVTT_full_test/v2t_metrics/geometric_mean_R1-R5-R10: 22.3728428364999
 mnt_best       : 19.64141173966355
 not_improved_count: 0
Train Epoch: 21 [1/250 128/32000 (0%)] Loss: 1.96604 (semantic_loss: 0.01571, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=29.49881 
Train Epoch: 21 [12/250 1536/32000 (5%)] Loss: 1.96651 (semantic_loss: 0.01715, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.36990 
Train Epoch: 21 [23/250 2944/32000 (9%)] Loss: 1.96722 (semantic_loss: 0.01786, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.37547 
Train Epoch: 21 [34/250 4352/32000 (14%)] Loss: 1.96503 (semantic_loss: 0.01567, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.34398 
Train Epoch: 21 [45/250 5760/32000 (18%)] Loss: 1.96693 (semantic_loss: 0.01758, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.34683 
Train Epoch: 21 [56/250 7168/32000 (22%)] Loss: 1.96541 (semantic_loss: 0.01605, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.34831 
Train Epoch: 21 [67/250 8576/32000 (27%)] Loss: 1.96552 (semantic_loss: 0.01616, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.33041 
Train Epoch: 21 [78/250 9984/32000 (31%)] Loss: 1.96872 (semantic_loss: 0.01838, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.69976 
Train Epoch: 21 [89/250 11392/32000 (36%)] Loss: 1.96599 (semantic_loss: 0.01663, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.34159 
Train Epoch: 21 [100/250 12800/32000 (40%)] Loss: 1.96831 (semantic_loss: 0.01798, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.38038 
Train Epoch: 21 [111/250 14208/32000 (44%)] Loss: 1.96645 (semantic_loss: 0.01612, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.33728 
Train Epoch: 21 [122/250 15616/32000 (49%)] Loss: 1.96734 (semantic_loss: 0.01798, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.33420 
Train Epoch: 21 [133/250 17024/32000 (53%)] Loss: 1.96592 (semantic_loss: 0.01559, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.34286 
Train Epoch: 21 [144/250 18432/32000 (58%)] Loss: 1.96793 (semantic_loss: 0.01760, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.34258 
Train Epoch: 21 [155/250 19840/32000 (62%)] Loss: 1.96662 (semantic_loss: 0.01628, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.37710 
Train Epoch: 21 [166/250 21248/32000 (66%)] Loss: 1.96714 (semantic_loss: 0.01778, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.35875 
Train Epoch: 21 [177/250 22656/32000 (71%)] Loss: 1.96584 (semantic_loss: 0.01551, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.38647 
Train Epoch: 21 [188/250 24064/32000 (75%)] Loss: 1.96712 (semantic_loss: 0.01679, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.36513 
Train Epoch: 21 [199/250 25472/32000 (80%)] Loss: 1.96774 (semantic_loss: 0.01838, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.36719 
Train Epoch: 21 [210/250 26880/32000 (84%)] Loss: 1.96782 (semantic_loss: 0.01749, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.34858 
Train Epoch: 21 [221/250 28288/32000 (88%)] Loss: 1.96629 (semantic_loss: 0.01694, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.35715 
Train Epoch: 21 [232/250 29696/32000 (93%)] Loss: 1.96539 (semantic_loss: 0.01603, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.33720 
Train Epoch: 21 [243/250 31104/32000 (97%)] Loss: 1.96701 (semantic_loss: 0.01765, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.34123 
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/DCMH_MSRVTT_full/checkpoint-epoch21.pth ...
Done in 4.641s
removing stale ckpt [epoch 20] [took 0.01s]
 epoch          : 21
 loss           : 1.967178340435028
 learning_rate  : 1.7924296120427095e-05
 n_samples      : 672000
 n_steps        : 5250
 MSRVTT_full_val/t2v_metrics/R1: 22.132796780684103
 MSRVTT_full_val/t2v_metrics/R5: 59.15492957746479
 MSRVTT_full_val/t2v_metrics/R10: 74.84909456740442
 MSRVTT_full_val/t2v_metrics/R50: 94.76861167002012
 MSRVTT_full_val/t2v_metrics/MedR: 4.0
 MSRVTT_full_val/t2v_metrics/MeanR: 12.256539235412475
 MSRVTT_full_val/t2v_metrics/geometric_mean_R1-R5-R10: 46.10392814966962
 MSRVTT_full_val/v2t_metrics/R1: 24.547283702213278
 MSRVTT_full_val/v2t_metrics/R5: 62.57545271629779
 MSRVTT_full_val/v2t_metrics/R10: 77.46478873239437
 MSRVTT_full_val/v2t_metrics/R50: 94.56740442655935
 MSRVTT_full_val/v2t_metrics/MedR: 4.0
 MSRVTT_full_val/v2t_metrics/MeanR: 11.085513078470825
 MSRVTT_full_val/v2t_metrics/geometric_mean_R1-R5-R10: 49.18551929765164
 MSRVTT_full_test/t2v_metrics/R1: 7.357859531772576
 MSRVTT_full_test/t2v_metrics/R5: 26.08695652173913
 MSRVTT_full_test/t2v_metrics/R10: 38.02675585284281
 MSRVTT_full_test/t2v_metrics/R50: 73.24414715719064
 MSRVTT_full_test/t2v_metrics/MedR: 17.0
 MSRVTT_full_test/t2v_metrics/MeanR: 64.55217391304348
 MSRVTT_full_test/t2v_metrics/geometric_mean_R1-R5-R10: 19.397900518792532
 MSRVTT_full_test/v2t_metrics/R1: 9.464882943143813
 MSRVTT_full_test/v2t_metrics/R5: 28.59531772575251
 MSRVTT_full_test/v2t_metrics/R10: 42.77591973244147
 MSRVTT_full_test/v2t_metrics/R50: 77.1571906354515
 MSRVTT_full_test/v2t_metrics/MedR: 14.0
 MSRVTT_full_test/v2t_metrics/MeanR: 56.02073578595318
 MSRVTT_full_test/v2t_metrics/geometric_mean_R1-R5-R10: 22.622287110000798
 mnt_best       : 19.64141173966355
 not_improved_count: 1
Train Epoch: 22 [1/250 128/32000 (0%)] Loss: 1.96697 (semantic_loss: 0.01664, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=27.99737 
Train Epoch: 22 [12/250 1536/32000 (5%)] Loss: 1.96738 (semantic_loss: 0.01705, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.34568 
Train Epoch: 22 [23/250 2944/32000 (9%)] Loss: 1.96609 (semantic_loss: 0.01575, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.35075 
Train Epoch: 22 [34/250 4352/32000 (14%)] Loss: 1.96535 (semantic_loss: 0.01600, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.39186 
Train Epoch: 22 [45/250 5760/32000 (18%)] Loss: 1.96651 (semantic_loss: 0.01715, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.35302 
Train Epoch: 22 [56/250 7168/32000 (22%)] Loss: 1.96962 (semantic_loss: 0.01928, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.33822 
Train Epoch: 22 [67/250 8576/32000 (27%)] Loss: 1.96681 (semantic_loss: 0.01745, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.85624 
Train Epoch: 22 [78/250 9984/32000 (31%)] Loss: 1.96585 (semantic_loss: 0.01650, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.34210 
Train Epoch: 22 [89/250 11392/32000 (36%)] Loss: 1.96694 (semantic_loss: 0.01759, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.36152 
Train Epoch: 22 [100/250 12800/32000 (40%)] Loss: 1.96617 (semantic_loss: 0.01583, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.34005 
Train Epoch: 22 [111/250 14208/32000 (44%)] Loss: 1.96764 (semantic_loss: 0.01731, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.34461 
Train Epoch: 22 [122/250 15616/32000 (49%)] Loss: 1.96586 (semantic_loss: 0.01650, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.37748 
Train Epoch: 22 [133/250 17024/32000 (53%)] Loss: 1.96785 (semantic_loss: 0.01751, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.33885 
Train Epoch: 22 [144/250 18432/32000 (58%)] Loss: 1.96676 (semantic_loss: 0.01740, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.35353 
Train Epoch: 22 [155/250 19840/32000 (62%)] Loss: 1.96653 (semantic_loss: 0.01620, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.33851 
Train Epoch: 22 [166/250 21248/32000 (66%)] Loss: 1.96658 (semantic_loss: 0.01625, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.36440 
Train Epoch: 22 [177/250 22656/32000 (71%)] Loss: 1.96777 (semantic_loss: 0.01842, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.36599 
Train Epoch: 22 [188/250 24064/32000 (75%)] Loss: 1.96658 (semantic_loss: 0.01722, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.36742 
Train Epoch: 22 [199/250 25472/32000 (80%)] Loss: 1.96620 (semantic_loss: 0.01586, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=3.13358 
Train Epoch: 22 [210/250 26880/32000 (84%)] Loss: 1.96726 (semantic_loss: 0.01692, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.63169 
Train Epoch: 22 [221/250 28288/32000 (88%)] Loss: 1.96784 (semantic_loss: 0.01750, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.35677 
Train Epoch: 22 [232/250 29696/32000 (93%)] Loss: 1.96663 (semantic_loss: 0.01727, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.36050 
Train Epoch: 22 [243/250 31104/32000 (97%)] Loss: 1.96750 (semantic_loss: 0.01619, quant_loss: 1.95117, bit_balance_loss: 0.00014) batch_time=0.36533 
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/DCMH_MSRVTT_full/checkpoint-epoch22.pth ...
Done in 4.012s
removing stale ckpt [epoch 21] [took 0.00s]
 epoch          : 22
 loss           : 1.9668078169822694
 learning_rate  : 1.702808131440574e-05
 n_samples      : 704000
 n_steps        : 5500
 MSRVTT_full_val/t2v_metrics/R1: 25.75452716297787
 MSRVTT_full_val/t2v_metrics/R5: 60.76458752515091
 MSRVTT_full_val/t2v_metrics/R10: 74.04426559356136
 MSRVTT_full_val/t2v_metrics/R50: 94.76861167002012
 MSRVTT_full_val/t2v_metrics/MedR: 4.0
 MSRVTT_full_val/t2v_metrics/MeanR: 12.596579476861168
 MSRVTT_full_val/t2v_metrics/geometric_mean_R1-R5-R10: 48.75268305943257
 MSRVTT_full_val/v2t_metrics/R1: 25.553319919517104
 MSRVTT_full_val/v2t_metrics/R5: 62.776659959758554
 MSRVTT_full_val/v2t_metrics/R10: 78.06841046277665
 MSRVTT_full_val/v2t_metrics/R50: 94.76861167002012
 MSRVTT_full_val/v2t_metrics/MedR: 3.0
 MSRVTT_full_val/v2t_metrics/MeanR: 11.168008048289739
 MSRVTT_full_val/v2t_metrics/geometric_mean_R1-R5-R10: 50.03112763996848
 MSRVTT_full_test/t2v_metrics/R1: 6.923076923076923
 MSRVTT_full_test/t2v_metrics/R5: 26.02006688963211
 MSRVTT_full_test/t2v_metrics/R10: 39.23076923076923
 MSRVTT_full_test/t2v_metrics/R50: 73.64548494983278
 MSRVTT_full_test/t2v_metrics/MedR: 17.0
 MSRVTT_full_test/t2v_metrics/MeanR: 63.735284280936455
 MSRVTT_full_test/t2v_metrics/geometric_mean_R1-R5-R10: 19.190139414887252
 MSRVTT_full_test/v2t_metrics/R1: 8.394648829431437
 MSRVTT_full_test/v2t_metrics/R5: 28.896321070234112
 MSRVTT_full_test/v2t_metrics/R10: 42.14046822742475
 MSRVTT_full_test/v2t_metrics/R50: 76.42140468227424
 MSRVTT_full_test/v2t_metrics/MedR: 15.0
 MSRVTT_full_test/v2t_metrics/MeanR: 56.452341137123746
 MSRVTT_full_test/v2t_metrics/geometric_mean_R1-R5-R10: 21.70275234974521
 mnt_best       : 19.64141173966355
 not_improved_count: 2
Train Epoch: 23 [1/250 128/32000 (0%)] Loss: 1.96690 (semantic_loss: 0.01755, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=28.09587 
Train Epoch: 23 [12/250 1536/32000 (5%)] Loss: 1.96728 (semantic_loss: 0.01793, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.33055 
Train Epoch: 23 [23/250 2944/32000 (9%)] Loss: 1.96639 (semantic_loss: 0.01606, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.33786 
Train Epoch: 23 [34/250 4352/32000 (14%)] Loss: 1.96452 (semantic_loss: 0.01517, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.34244 
Train Epoch: 23 [45/250 5760/32000 (18%)] Loss: 1.96859 (semantic_loss: 0.01825, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.33982 
Train Epoch: 23 [56/250 7168/32000 (22%)] Loss: 1.96552 (semantic_loss: 0.01616, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.40010 
Train Epoch: 23 [67/250 8576/32000 (27%)] Loss: 1.96592 (semantic_loss: 0.01656, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.89925 
Train Epoch: 23 [78/250 9984/32000 (31%)] Loss: 1.96708 (semantic_loss: 0.01772, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.34581 
Train Epoch: 23 [89/250 11392/32000 (36%)] Loss: 1.96744 (semantic_loss: 0.01710, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.86210 
Train Epoch: 23 [100/250 12800/32000 (40%)] Loss: 1.96600 (semantic_loss: 0.01567, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.33667 
Train Epoch: 23 [111/250 14208/32000 (44%)] Loss: 1.96688 (semantic_loss: 0.01753, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.34343 
Train Epoch: 23 [122/250 15616/32000 (49%)] Loss: 1.96646 (semantic_loss: 0.01711, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.36814 
Train Epoch: 23 [133/250 17024/32000 (53%)] Loss: 1.96572 (semantic_loss: 0.01539, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.34553 
Train Epoch: 23 [144/250 18432/32000 (58%)] Loss: 1.96684 (semantic_loss: 0.01748, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=2.18276 
Train Epoch: 23 [155/250 19840/32000 (62%)] Loss: 1.96559 (semantic_loss: 0.01623, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.33763 
Train Epoch: 23 [166/250 21248/32000 (66%)] Loss: 1.96595 (semantic_loss: 0.01659, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.33318 
Train Epoch: 23 [177/250 22656/32000 (71%)] Loss: 1.96718 (semantic_loss: 0.01685, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.33100 
Train Epoch: 23 [188/250 24064/32000 (75%)] Loss: 1.96851 (semantic_loss: 0.01817, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.33650 
Train Epoch: 23 [199/250 25472/32000 (80%)] Loss: 1.96774 (semantic_loss: 0.01740, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.64119 
Train Epoch: 23 [210/250 26880/32000 (84%)] Loss: 1.96699 (semantic_loss: 0.01665, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.97355 
Train Epoch: 23 [221/250 28288/32000 (88%)] Loss: 1.96653 (semantic_loss: 0.01620, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.33903 
Train Epoch: 23 [232/250 29696/32000 (93%)] Loss: 1.96681 (semantic_loss: 0.01648, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.35125 
Train Epoch: 23 [243/250 31104/32000 (97%)] Loss: 1.96616 (semantic_loss: 0.01583, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.33585 
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/DCMH_MSRVTT_full/checkpoint-epoch23.pth ...
Done in 10.570s
Updating 'best' checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/DCMH_MSRVTT_full/checkpoint-epoch23.pth ...
Done in 14.272s
removing stale ckpt [epoch 22] [took 0.00s]
 epoch          : 23
 loss           : 1.9665173506736755
 learning_rate  : 1.6176677248685452e-05
 n_samples      : 736000
 n_steps        : 5750
 MSRVTT_full_val/t2v_metrics/R1: 23.34004024144869
 MSRVTT_full_val/t2v_metrics/R5: 62.97786720321932
 MSRVTT_full_val/t2v_metrics/R10: 74.64788732394366
 MSRVTT_full_val/t2v_metrics/R50: 94.16498993963782
 MSRVTT_full_val/t2v_metrics/MedR: 3.0
 MSRVTT_full_val/t2v_metrics/MeanR: 12.523138832997988
 MSRVTT_full_val/t2v_metrics/geometric_mean_R1-R5-R10: 47.87429115883614
 MSRVTT_full_val/v2t_metrics/R1: 26.156941649899398
 MSRVTT_full_val/v2t_metrics/R5: 64.1851106639839
 MSRVTT_full_val/v2t_metrics/R10: 78.67203219315896
 MSRVTT_full_val/v2t_metrics/R50: 95.77464788732394
 MSRVTT_full_val/v2t_metrics/MedR: 3.0
 MSRVTT_full_val/v2t_metrics/MeanR: 10.70824949698189
 MSRVTT_full_val/v2t_metrics/geometric_mean_R1-R5-R10: 50.92689625418649
 MSRVTT_full_test/t2v_metrics/R1: 7.525083612040134
 MSRVTT_full_test/t2v_metrics/R5: 27.023411371237458
 MSRVTT_full_test/t2v_metrics/R10: 39.66555183946488
 MSRVTT_full_test/t2v_metrics/R50: 73.7123745819398
 MSRVTT_full_test/t2v_metrics/MedR: 16.0
 MSRVTT_full_test/t2v_metrics/MeanR: 63.42775919732441
 MSRVTT_full_test/t2v_metrics/geometric_mean_R1-R5-R10: 20.054953883093965
 MSRVTT_full_test/v2t_metrics/R1: 9.464882943143813
 MSRVTT_full_test/v2t_metrics/R5: 30.668896321070235
 MSRVTT_full_test/v2t_metrics/R10: 43.67892976588629
 MSRVTT_full_test/v2t_metrics/R50: 77.49163879598662
 MSRVTT_full_test/v2t_metrics/MedR: 14.0
 MSRVTT_full_test/v2t_metrics/MeanR: 53.08561872909699
 MSRVTT_full_test/v2t_metrics/geometric_mean_R1-R5-R10: 23.318205626903243
 mnt_best       : 20.054953883093965
 not_improved_count: 0
Train Epoch: 24 [1/250 128/32000 (0%)] Loss: 1.96602 (semantic_loss: 0.01568, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=25.82774 
Train Epoch: 24 [12/250 1536/32000 (5%)] Loss: 1.96699 (semantic_loss: 0.01666, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.36653 
Train Epoch: 24 [23/250 2944/32000 (9%)] Loss: 1.96588 (semantic_loss: 0.01652, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.33507 
Train Epoch: 24 [34/250 4352/32000 (14%)] Loss: 1.96670 (semantic_loss: 0.01735, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.36901 
Train Epoch: 24 [45/250 5760/32000 (18%)] Loss: 1.96676 (semantic_loss: 0.01740, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.34636 
Train Epoch: 24 [56/250 7168/32000 (22%)] Loss: 1.96771 (semantic_loss: 0.01738, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.36474 
Train Epoch: 24 [67/250 8576/32000 (27%)] Loss: 1.96478 (semantic_loss: 0.01542, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.33639 
Train Epoch: 24 [78/250 9984/32000 (31%)] Loss: 1.96707 (semantic_loss: 0.01771, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.33641 
Train Epoch: 24 [89/250 11392/32000 (36%)] Loss: 1.96725 (semantic_loss: 0.01692, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.34081 
Train Epoch: 24 [100/250 12800/32000 (40%)] Loss: 1.96843 (semantic_loss: 0.01810, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.34220 
Train Epoch: 24 [111/250 14208/32000 (44%)] Loss: 1.96579 (semantic_loss: 0.01546, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.34940 
Train Epoch: 24 [122/250 15616/32000 (49%)] Loss: 1.96697 (semantic_loss: 0.01663, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.32984 
Train Epoch: 24 [133/250 17024/32000 (53%)] Loss: 1.96581 (semantic_loss: 0.01548, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.35985 
Train Epoch: 24 [144/250 18432/32000 (58%)] Loss: 1.96514 (semantic_loss: 0.01579, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=4.97129 
Train Epoch: 24 [155/250 19840/32000 (62%)] Loss: 1.96575 (semantic_loss: 0.01639, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.34406 
Train Epoch: 24 [166/250 21248/32000 (66%)] Loss: 1.96577 (semantic_loss: 0.01641, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.34985 
Train Epoch: 24 [177/250 22656/32000 (71%)] Loss: 1.96851 (semantic_loss: 0.01818, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.88785 
Train Epoch: 24 [188/250 24064/32000 (75%)] Loss: 1.96736 (semantic_loss: 0.01703, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.33383 
Train Epoch: 24 [199/250 25472/32000 (80%)] Loss: 1.96671 (semantic_loss: 0.01637, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.34912 
Train Epoch: 24 [210/250 26880/32000 (84%)] Loss: 1.96524 (semantic_loss: 0.01588, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.33274 
Train Epoch: 24 [221/250 28288/32000 (88%)] Loss: 1.96578 (semantic_loss: 0.01544, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.34068 
Train Epoch: 24 [232/250 29696/32000 (93%)] Loss: 1.96675 (semantic_loss: 0.01739, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.37445 
Train Epoch: 24 [243/250 31104/32000 (97%)] Loss: 1.96647 (semantic_loss: 0.01614, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.35338 
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/DCMH_MSRVTT_full/checkpoint-epoch24.pth ...
Done in 12.686s
removing stale ckpt [epoch 23] [took 0.00s]
 epoch          : 24
 loss           : 1.966418803691864
 learning_rate  : 1.5367843386251178e-05
 n_samples      : 768000
 n_steps        : 6000
 MSRVTT_full_val/t2v_metrics/R1: 23.541247484909455
 MSRVTT_full_val/t2v_metrics/R5: 60.96579476861167
 MSRVTT_full_val/t2v_metrics/R10: 74.44668008048289
 MSRVTT_full_val/t2v_metrics/R50: 94.16498993963782
 MSRVTT_full_val/t2v_metrics/MedR: 3.0
 MSRVTT_full_val/t2v_metrics/MeanR: 12.560362173038229
 MSRVTT_full_val/t2v_metrics/geometric_mean_R1-R5-R10: 47.451908326355166
 MSRVTT_full_val/v2t_metrics/R1: 27.364185110663986
 MSRVTT_full_val/v2t_metrics/R5: 64.78873239436619
 MSRVTT_full_val/v2t_metrics/R10: 78.67203219315896
 MSRVTT_full_val/v2t_metrics/R50: 95.37223340040241
 MSRVTT_full_val/v2t_metrics/MedR: 3.0
 MSRVTT_full_val/v2t_metrics/MeanR: 11.06338028169014
 MSRVTT_full_val/v2t_metrics/geometric_mean_R1-R5-R10: 51.86019241147863
 MSRVTT_full_test/t2v_metrics/R1: 7.290969899665551
 MSRVTT_full_test/t2v_metrics/R5: 26.254180602006688
 MSRVTT_full_test/t2v_metrics/R10: 38.69565217391305
 MSRVTT_full_test/t2v_metrics/R50: 73.34448160535118
 MSRVTT_full_test/t2v_metrics/MedR: 18.0
 MSRVTT_full_test/t2v_metrics/MeanR: 63.67274247491639
 MSRVTT_full_test/t2v_metrics/geometric_mean_R1-R5-R10: 19.493148058235274
 MSRVTT_full_test/v2t_metrics/R1: 8.66220735785953
 MSRVTT_full_test/v2t_metrics/R5: 29.765886287625417
 MSRVTT_full_test/v2t_metrics/R10: 43.21070234113712
 MSRVTT_full_test/v2t_metrics/R50: 77.92642140468227
 MSRVTT_full_test/v2t_metrics/MedR: 14.0
 MSRVTT_full_test/v2t_metrics/MeanR: 53.966722408026754
 MSRVTT_full_test/v2t_metrics/geometric_mean_R1-R5-R10: 22.33467170148446
 mnt_best       : 20.054953883093965
 not_improved_count: 1
Train Epoch: 25 [1/250 128/32000 (0%)] Loss: 1.96714 (semantic_loss: 0.01778, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=35.35150 
Train Epoch: 25 [12/250 1536/32000 (5%)] Loss: 1.96530 (semantic_loss: 0.01594, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.34015 
Train Epoch: 25 [23/250 2944/32000 (9%)] Loss: 1.96521 (semantic_loss: 0.01585, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.33065 
Train Epoch: 25 [34/250 4352/32000 (14%)] Loss: 1.96617 (semantic_loss: 0.01584, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.34623 
Train Epoch: 25 [45/250 5760/32000 (18%)] Loss: 1.96655 (semantic_loss: 0.01622, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.33570 
Train Epoch: 25 [56/250 7168/32000 (22%)] Loss: 1.96700 (semantic_loss: 0.01667, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.33685 
Train Epoch: 25 [67/250 8576/32000 (27%)] Loss: 1.96580 (semantic_loss: 0.01547, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.34110 
Train Epoch: 25 [78/250 9984/32000 (31%)] Loss: 1.96457 (semantic_loss: 0.01424, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.33308 
Train Epoch: 25 [89/250 11392/32000 (36%)] Loss: 1.96469 (semantic_loss: 0.01533, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.33828 
Train Epoch: 25 [100/250 12800/32000 (40%)] Loss: 1.96580 (semantic_loss: 0.01548, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.33088 
Train Epoch: 25 [111/250 14208/32000 (44%)] Loss: 1.96580 (semantic_loss: 0.01644, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.34701 
Train Epoch: 25 [122/250 15616/32000 (49%)] Loss: 1.96563 (semantic_loss: 0.01627, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.33837 
Train Epoch: 25 [133/250 17024/32000 (53%)] Loss: 1.96521 (semantic_loss: 0.01586, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.37191 
Train Epoch: 25 [144/250 18432/32000 (58%)] Loss: 1.96645 (semantic_loss: 0.01611, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=2.37067 
Train Epoch: 25 [155/250 19840/32000 (62%)] Loss: 1.96688 (semantic_loss: 0.01655, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.34561 
Train Epoch: 25 [166/250 21248/32000 (66%)] Loss: 1.96700 (semantic_loss: 0.01667, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.35203 
Train Epoch: 25 [177/250 22656/32000 (71%)] Loss: 1.96756 (semantic_loss: 0.01722, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.36020 
Train Epoch: 25 [188/250 24064/32000 (75%)] Loss: 1.96667 (semantic_loss: 0.01731, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.33836 
Train Epoch: 25 [199/250 25472/32000 (80%)] Loss: 1.96588 (semantic_loss: 0.01652, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.37119 
Train Epoch: 25 [210/250 26880/32000 (84%)] Loss: 1.96680 (semantic_loss: 0.01647, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.34858 
Train Epoch: 25 [221/250 28288/32000 (88%)] Loss: 1.96672 (semantic_loss: 0.01638, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.33393 
Train Epoch: 25 [232/250 29696/32000 (93%)] Loss: 1.96502 (semantic_loss: 0.01567, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.34676 
Train Epoch: 25 [243/250 31104/32000 (97%)] Loss: 1.96728 (semantic_loss: 0.01694, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.34114 
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/DCMH_MSRVTT_full/checkpoint-epoch25.pth ...
Done in 3.898s
removing stale ckpt [epoch 24] [took 0.00s]
 epoch          : 25
 loss           : 1.9661517958641053
 learning_rate  : 1.4599451216938618e-05
 n_samples      : 800000
 n_steps        : 6250
 MSRVTT_full_val/t2v_metrics/R1: 23.74245472837022
 MSRVTT_full_val/t2v_metrics/R5: 62.17303822937626
 MSRVTT_full_val/t2v_metrics/R10: 74.24547283702213
 MSRVTT_full_val/t2v_metrics/R50: 94.36619718309859
 MSRVTT_full_val/t2v_metrics/MedR: 3.0
 MSRVTT_full_val/t2v_metrics/MeanR: 12.24446680080483
 MSRVTT_full_val/t2v_metrics/geometric_mean_R1-R5-R10: 47.85557758358113
 MSRVTT_full_val/v2t_metrics/R1: 27.56539235412475
 MSRVTT_full_val/v2t_metrics/R5: 64.98993963782696
 MSRVTT_full_val/v2t_metrics/R10: 77.66599597585513
 MSRVTT_full_val/v2t_metrics/R50: 95.97585513078471
 MSRVTT_full_val/v2t_metrics/MedR: 3.0
 MSRVTT_full_val/v2t_metrics/MeanR: 10.895372233400403
 MSRVTT_full_val/v2t_metrics/geometric_mean_R1-R5-R10: 51.81797168032351
 MSRVTT_full_test/t2v_metrics/R1: 7.290969899665551
 MSRVTT_full_test/t2v_metrics/R5: 27.25752508361204
 MSRVTT_full_test/t2v_metrics/R10: 39.69899665551839
 MSRVTT_full_test/t2v_metrics/R50: 74.54849498327759
 MSRVTT_full_test/t2v_metrics/MedR: 17.0
 MSRVTT_full_test/t2v_metrics/MeanR: 61.964548494983276
 MSRVTT_full_test/t2v_metrics/geometric_mean_R1-R5-R10: 19.90751654978389
 MSRVTT_full_test/v2t_metrics/R1: 9.096989966555183
 MSRVTT_full_test/v2t_metrics/R5: 29.698996655518396
 MSRVTT_full_test/v2t_metrics/R10: 44.381270903010034
 MSRVTT_full_test/v2t_metrics/R50: 78.16053511705685
 MSRVTT_full_test/v2t_metrics/MedR: 13.5
 MSRVTT_full_test/v2t_metrics/MeanR: 53.24581939799331
 MSRVTT_full_test/v2t_metrics/geometric_mean_R1-R5-R10: 22.888275689047227
 mnt_best       : 20.054953883093965
 not_improved_count: 2
Train Epoch: 26 [1/250 128/32000 (0%)] Loss: 1.96450 (semantic_loss: 0.01514, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=28.31091 
Train Epoch: 26 [12/250 1536/32000 (5%)] Loss: 1.96709 (semantic_loss: 0.01773, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.33719 
Train Epoch: 26 [23/250 2944/32000 (9%)] Loss: 1.96667 (semantic_loss: 0.01634, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.34180 
Train Epoch: 26 [34/250 4352/32000 (14%)] Loss: 1.96658 (semantic_loss: 0.01722, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=1.72868 
Train Epoch: 26 [45/250 5760/32000 (18%)] Loss: 1.96462 (semantic_loss: 0.01526, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.33574 
Train Epoch: 26 [56/250 7168/32000 (22%)] Loss: 1.96789 (semantic_loss: 0.01756, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.33685 
Train Epoch: 26 [67/250 8576/32000 (27%)] Loss: 1.96413 (semantic_loss: 0.01478, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.34145 
Train Epoch: 26 [78/250 9984/32000 (31%)] Loss: 1.96549 (semantic_loss: 0.01613, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.33346 
Train Epoch: 26 [89/250 11392/32000 (36%)] Loss: 1.96705 (semantic_loss: 0.01671, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.33322 
Train Epoch: 26 [100/250 12800/32000 (40%)] Loss: 1.96589 (semantic_loss: 0.01654, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.33763 
Train Epoch: 26 [111/250 14208/32000 (44%)] Loss: 1.96731 (semantic_loss: 0.01698, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.35530 
Train Epoch: 26 [122/250 15616/32000 (49%)] Loss: 1.96484 (semantic_loss: 0.01548, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.35128 
Train Epoch: 26 [133/250 17024/32000 (53%)] Loss: 1.96564 (semantic_loss: 0.01531, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.34392 
Train Epoch: 26 [144/250 18432/32000 (58%)] Loss: 1.96700 (semantic_loss: 0.01667, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.33615 
Train Epoch: 26 [155/250 19840/32000 (62%)] Loss: 1.96707 (semantic_loss: 0.01673, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.34644 
Train Epoch: 26 [166/250 21248/32000 (66%)] Loss: 1.96585 (semantic_loss: 0.01551, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.55457 
Train Epoch: 26 [177/250 22656/32000 (71%)] Loss: 1.96520 (semantic_loss: 0.01584, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.35631 
Train Epoch: 26 [188/250 24064/32000 (75%)] Loss: 1.96703 (semantic_loss: 0.01670, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.33952 
Train Epoch: 26 [199/250 25472/32000 (80%)] Loss: 1.96501 (semantic_loss: 0.01468, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.33315 
Train Epoch: 26 [210/250 26880/32000 (84%)] Loss: 1.96540 (semantic_loss: 0.01605, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.34439 
Train Epoch: 26 [221/250 28288/32000 (88%)] Loss: 1.96410 (semantic_loss: 0.01475, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.33197 
Train Epoch: 26 [232/250 29696/32000 (93%)] Loss: 1.96633 (semantic_loss: 0.01697, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.33377 
Train Epoch: 26 [243/250 31104/32000 (97%)] Loss: 1.96493 (semantic_loss: 0.01558, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.34046 
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/DCMH_MSRVTT_full/checkpoint-epoch26.pth ...
Done in 9.835s
removing stale ckpt [epoch 25] [took 0.00s]
 epoch          : 26
 loss           : 1.9659072499275208
 learning_rate  : 1.3869478656091687e-05
 n_samples      : 832000
 n_steps        : 6500
 MSRVTT_full_val/t2v_metrics/R1: 21.93158953722334
 MSRVTT_full_val/t2v_metrics/R5: 60.563380281690144
 MSRVTT_full_val/t2v_metrics/R10: 72.83702213279678
 MSRVTT_full_val/t2v_metrics/R50: 93.76257545271629
 MSRVTT_full_val/t2v_metrics/MedR: 4.0
 MSRVTT_full_val/t2v_metrics/MeanR: 13.62374245472837
 MSRVTT_full_val/t2v_metrics/geometric_mean_R1-R5-R10: 45.906847066013576
 MSRVTT_full_val/v2t_metrics/R1: 24.14486921529175
 MSRVTT_full_val/v2t_metrics/R5: 61.56941649899397
 MSRVTT_full_val/v2t_metrics/R10: 76.25754527162978
 MSRVTT_full_val/v2t_metrics/R50: 93.96378269617706
 MSRVTT_full_val/v2t_metrics/MedR: 4.0
 MSRVTT_full_val/v2t_metrics/MeanR: 11.810865191146881
 MSRVTT_full_val/v2t_metrics/geometric_mean_R1-R5-R10: 48.39764601553161
 MSRVTT_full_test/t2v_metrics/R1: 6.923076923076923
 MSRVTT_full_test/t2v_metrics/R5: 24.849498327759196
 MSRVTT_full_test/t2v_metrics/R10: 37.792642140468224
 MSRVTT_full_test/t2v_metrics/R50: 71.33779264214047
 MSRVTT_full_test/t2v_metrics/MedR: 18.0
 MSRVTT_full_test/t2v_metrics/MeanR: 70.09498327759198
 MSRVTT_full_test/t2v_metrics/geometric_mean_R1-R5-R10: 18.664141251815476
 MSRVTT_full_test/v2t_metrics/R1: 8.79598662207358
 MSRVTT_full_test/v2t_metrics/R5: 28.494983277591974
 MSRVTT_full_test/v2t_metrics/R10: 42.240802675585286
 MSRVTT_full_test/v2t_metrics/R50: 75.65217391304348
 MSRVTT_full_test/v2t_metrics/MedR: 15.0
 MSRVTT_full_test/v2t_metrics/MeanR: 60.84030100334448
 MSRVTT_full_test/v2t_metrics/geometric_mean_R1-R5-R10: 21.958114377543875
 mnt_best       : 20.054953883093965
 not_improved_count: 3
Train Epoch: 27 [1/250 128/32000 (0%)] Loss: 1.96626 (semantic_loss: 0.01690, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=36.86026 
Train Epoch: 27 [12/250 1536/32000 (5%)] Loss: 1.96443 (semantic_loss: 0.01507, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.33280 
Train Epoch: 27 [23/250 2944/32000 (9%)] Loss: 1.96690 (semantic_loss: 0.01657, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.33534 
Train Epoch: 27 [34/250 4352/32000 (14%)] Loss: 1.96534 (semantic_loss: 0.01598, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.57303 
Train Epoch: 27 [45/250 5760/32000 (18%)] Loss: 1.96502 (semantic_loss: 0.01566, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.33936 
Train Epoch: 27 [56/250 7168/32000 (22%)] Loss: 1.96677 (semantic_loss: 0.01644, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.33337 
Train Epoch: 27 [67/250 8576/32000 (27%)] Loss: 1.96677 (semantic_loss: 0.01643, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.34416 
Train Epoch: 27 [78/250 9984/32000 (31%)] Loss: 1.96558 (semantic_loss: 0.01525, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.33548 
Train Epoch: 27 [89/250 11392/32000 (36%)] Loss: 1.96551 (semantic_loss: 0.01517, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.33950 
Train Epoch: 27 [100/250 12800/32000 (40%)] Loss: 1.96774 (semantic_loss: 0.01741, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.68769 
Train Epoch: 27 [111/250 14208/32000 (44%)] Loss: 1.96608 (semantic_loss: 0.01575, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.33573 
Train Epoch: 27 [122/250 15616/32000 (49%)] Loss: 1.96359 (semantic_loss: 0.01423, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.33912 
Train Epoch: 27 [133/250 17024/32000 (53%)] Loss: 1.96643 (semantic_loss: 0.01609, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.36506 
Train Epoch: 27 [144/250 18432/32000 (58%)] Loss: 1.96395 (semantic_loss: 0.01459, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.33425 
Train Epoch: 27 [155/250 19840/32000 (62%)] Loss: 1.96532 (semantic_loss: 0.01499, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.33532 
Train Epoch: 27 [166/250 21248/32000 (66%)] Loss: 1.96655 (semantic_loss: 0.01622, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.34449 
Train Epoch: 27 [177/250 22656/32000 (71%)] Loss: 1.96738 (semantic_loss: 0.01705, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.34037 
Train Epoch: 27 [188/250 24064/32000 (75%)] Loss: 1.96663 (semantic_loss: 0.01630, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.36773 
Train Epoch: 27 [199/250 25472/32000 (80%)] Loss: 1.96587 (semantic_loss: 0.01554, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.36645 
Train Epoch: 27 [210/250 26880/32000 (84%)] Loss: 1.96580 (semantic_loss: 0.01547, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.36270 
Train Epoch: 27 [221/250 28288/32000 (88%)] Loss: 1.96603 (semantic_loss: 0.01667, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.36809 
Train Epoch: 27 [232/250 29696/32000 (93%)] Loss: 1.96586 (semantic_loss: 0.01553, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.34873 
Train Epoch: 27 [243/250 31104/32000 (97%)] Loss: 1.96583 (semantic_loss: 0.01550, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.33717 
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/DCMH_MSRVTT_full/checkpoint-epoch27.pth ...
Done in 4.223s
removing stale ckpt [epoch 26] [took 0.00s]
 epoch          : 27
 loss           : 1.9658518753051757
 learning_rate  : 1.3176004723287102e-05
 n_samples      : 864000
 n_steps        : 6750
 MSRVTT_full_val/t2v_metrics/R1: 24.547283702213278
 MSRVTT_full_val/t2v_metrics/R5: 61.3682092555332
 MSRVTT_full_val/t2v_metrics/R10: 75.25150905432595
 MSRVTT_full_val/t2v_metrics/R50: 93.158953722334
 MSRVTT_full_val/t2v_metrics/MedR: 3.0
 MSRVTT_full_val/t2v_metrics/MeanR: 13.264587525150905
 MSRVTT_full_val/t2v_metrics/geometric_mean_R1-R5-R10: 48.39725188184523
 MSRVTT_full_val/v2t_metrics/R1: 26.559356136820927
 MSRVTT_full_val/v2t_metrics/R5: 64.58752515090544
 MSRVTT_full_val/v2t_metrics/R10: 77.8672032193159
 MSRVTT_full_val/v2t_metrics/R50: 94.56740442655935
 MSRVTT_full_val/v2t_metrics/MedR: 3.0
 MSRVTT_full_val/v2t_metrics/MeanR: 11.392354124748492
 MSRVTT_full_val/v2t_metrics/geometric_mean_R1-R5-R10: 51.117968671504705
 MSRVTT_full_test/t2v_metrics/R1: 6.989966555183947
 MSRVTT_full_test/t2v_metrics/R5: 25.85284280936455
 MSRVTT_full_test/t2v_metrics/R10: 39.49832775919732
 MSRVTT_full_test/t2v_metrics/R50: 72.40802675585284
 MSRVTT_full_test/t2v_metrics/MedR: 17.0
 MSRVTT_full_test/t2v_metrics/MeanR: 68.12809364548495
 MSRVTT_full_test/t2v_metrics/geometric_mean_R1-R5-R10: 19.253988328821432
 MSRVTT_full_test/v2t_metrics/R1: 8.461538461538462
 MSRVTT_full_test/v2t_metrics/R5: 29.732441471571907
 MSRVTT_full_test/v2t_metrics/R10: 43.84615384615385
 MSRVTT_full_test/v2t_metrics/R50: 76.65551839464882
 MSRVTT_full_test/v2t_metrics/MedR: 14.0
 MSRVTT_full_test/v2t_metrics/MeanR: 56.25267558528428
 MSRVTT_full_test/v2t_metrics/geometric_mean_R1-R5-R10: 22.260613859669686
 mnt_best       : 20.054953883093965
 not_improved_count: 4
Train Epoch: 28 [1/250 128/32000 (0%)] Loss: 1.96396 (semantic_loss: 0.01461, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=25.60560 
Train Epoch: 28 [12/250 1536/32000 (5%)] Loss: 1.96599 (semantic_loss: 0.01664, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.34026 
Train Epoch: 28 [23/250 2944/32000 (9%)] Loss: 1.96373 (semantic_loss: 0.01437, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=3.00192 
Train Epoch: 28 [34/250 4352/32000 (14%)] Loss: 1.96589 (semantic_loss: 0.01556, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.35577 
Train Epoch: 28 [45/250 5760/32000 (18%)] Loss: 1.96694 (semantic_loss: 0.01661, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.34708 
Train Epoch: 28 [56/250 7168/32000 (22%)] Loss: 1.96529 (semantic_loss: 0.01594, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.33831 
Train Epoch: 28 [67/250 8576/32000 (27%)] Loss: 1.96627 (semantic_loss: 0.01692, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.34602 
Train Epoch: 28 [78/250 9984/32000 (31%)] Loss: 1.96490 (semantic_loss: 0.01554, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.35127 
Train Epoch: 28 [89/250 11392/32000 (36%)] Loss: 1.96764 (semantic_loss: 0.01730, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.33690 
Train Epoch: 28 [100/250 12800/32000 (40%)] Loss: 1.96597 (semantic_loss: 0.01564, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.33750 
Train Epoch: 28 [111/250 14208/32000 (44%)] Loss: 1.96344 (semantic_loss: 0.01408, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.34198 
Train Epoch: 28 [122/250 15616/32000 (49%)] Loss: 1.96450 (semantic_loss: 0.01515, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.33224 
Train Epoch: 28 [133/250 17024/32000 (53%)] Loss: 1.96492 (semantic_loss: 0.01459, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.90426 
Train Epoch: 28 [144/250 18432/32000 (58%)] Loss: 1.96408 (semantic_loss: 0.01374, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.37130 
Train Epoch: 28 [155/250 19840/32000 (62%)] Loss: 1.96518 (semantic_loss: 0.01485, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.33491 
Train Epoch: 28 [166/250 21248/32000 (66%)] Loss: 1.96491 (semantic_loss: 0.01555, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.33688 
Train Epoch: 28 [177/250 22656/32000 (71%)] Loss: 1.96679 (semantic_loss: 0.01645, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.34266 
Train Epoch: 28 [188/250 24064/32000 (75%)] Loss: 1.96589 (semantic_loss: 0.01653, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.34011 
Train Epoch: 28 [199/250 25472/32000 (80%)] Loss: 1.96383 (semantic_loss: 0.01448, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.33075 
Train Epoch: 28 [210/250 26880/32000 (84%)] Loss: 1.96442 (semantic_loss: 0.01506, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=1.14358 
Train Epoch: 28 [221/250 28288/32000 (88%)] Loss: 1.96555 (semantic_loss: 0.01619, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.33598 
Train Epoch: 28 [232/250 29696/32000 (93%)] Loss: 1.96589 (semantic_loss: 0.01654, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.33553 
Train Epoch: 28 [243/250 31104/32000 (97%)] Loss: 1.96469 (semantic_loss: 0.01533, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.36620 
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/DCMH_MSRVTT_full/checkpoint-epoch28.pth ...
Done in 3.849s
removing stale ckpt [epoch 27] [took 0.00s]
 epoch          : 28
 loss           : 1.9656860852241516
 learning_rate  : 1.2517204487122746e-05
 n_samples      : 896000
 n_steps        : 7000
 MSRVTT_full_val/t2v_metrics/R1: 23.138832997987926
 MSRVTT_full_val/t2v_metrics/R5: 62.17303822937626
 MSRVTT_full_val/t2v_metrics/R10: 73.64185110663983
 MSRVTT_full_val/t2v_metrics/R50: 94.76861167002012
 MSRVTT_full_val/t2v_metrics/MedR: 3.0
 MSRVTT_full_val/t2v_metrics/MeanR: 12.743460764587525
 MSRVTT_full_val/t2v_metrics/geometric_mean_R1-R5-R10: 47.31760410719379
 MSRVTT_full_val/v2t_metrics/R1: 25.553319919517104
 MSRVTT_full_val/v2t_metrics/R5: 66.19718309859155
 MSRVTT_full_val/v2t_metrics/R10: 78.87323943661971
 MSRVTT_full_val/v2t_metrics/R50: 95.37223340040241
 MSRVTT_full_val/v2t_metrics/MedR: 3.0
 MSRVTT_full_val/v2t_metrics/MeanR: 10.57344064386318
 MSRVTT_full_val/v2t_metrics/geometric_mean_R1-R5-R10: 51.0981887936185
 MSRVTT_full_test/t2v_metrics/R1: 7.45819397993311
 MSRVTT_full_test/t2v_metrics/R5: 25.953177257525084
 MSRVTT_full_test/t2v_metrics/R10: 39.63210702341137
 MSRVTT_full_test/t2v_metrics/R50: 72.77591973244147
 MSRVTT_full_test/t2v_metrics/MedR: 17.0
 MSRVTT_full_test/t2v_metrics/MeanR: 65.46822742474916
 MSRVTT_full_test/t2v_metrics/geometric_mean_R1-R5-R10: 19.72228013519868
 MSRVTT_full_test/v2t_metrics/R1: 8.66220735785953
 MSRVTT_full_test/v2t_metrics/R5: 30.234113712374583
 MSRVTT_full_test/v2t_metrics/R10: 44.448160535117054
 MSRVTT_full_test/v2t_metrics/R50: 77.09030100334448
 MSRVTT_full_test/v2t_metrics/MedR: 13.5
 MSRVTT_full_test/v2t_metrics/MeanR: 54.49598662207358
 MSRVTT_full_test/v2t_metrics/geometric_mean_R1-R5-R10: 22.66347686071001
 mnt_best       : 20.054953883093965
 not_improved_count: 5
Train Epoch: 29 [1/250 128/32000 (0%)] Loss: 1.96703 (semantic_loss: 0.01670, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=27.62276 
Train Epoch: 29 [12/250 1536/32000 (5%)] Loss: 1.96472 (semantic_loss: 0.01439, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.34290 
Train Epoch: 29 [23/250 2944/32000 (9%)] Loss: 1.96450 (semantic_loss: 0.01514, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.33508 
Train Epoch: 29 [34/250 4352/32000 (14%)] Loss: 1.96479 (semantic_loss: 0.01543, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.35017 
Train Epoch: 29 [45/250 5760/32000 (18%)] Loss: 1.96452 (semantic_loss: 0.01516, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.33944 
Train Epoch: 29 [56/250 7168/32000 (22%)] Loss: 1.96547 (semantic_loss: 0.01611, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.37101 
Train Epoch: 29 [67/250 8576/32000 (27%)] Loss: 1.96486 (semantic_loss: 0.01550, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.34135 
Train Epoch: 29 [78/250 9984/32000 (31%)] Loss: 1.96503 (semantic_loss: 0.01470, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.33945 
Train Epoch: 29 [89/250 11392/32000 (36%)] Loss: 1.96647 (semantic_loss: 0.01614, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.34139 
Train Epoch: 29 [100/250 12800/32000 (40%)] Loss: 1.96568 (semantic_loss: 0.01535, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.34324 
Train Epoch: 29 [111/250 14208/32000 (44%)] Loss: 1.96576 (semantic_loss: 0.01543, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.33691 
Train Epoch: 29 [122/250 15616/32000 (49%)] Loss: 1.96569 (semantic_loss: 0.01536, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.34567 
Train Epoch: 29 [133/250 17024/32000 (53%)] Loss: 1.96391 (semantic_loss: 0.01455, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.33100 
Train Epoch: 29 [144/250 18432/32000 (58%)] Loss: 1.96581 (semantic_loss: 0.01548, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.33673 
Train Epoch: 29 [155/250 19840/32000 (62%)] Loss: 1.96595 (semantic_loss: 0.01561, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.33664 
Train Epoch: 29 [166/250 21248/32000 (66%)] Loss: 1.96424 (semantic_loss: 0.01488, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.34190 
Train Epoch: 29 [177/250 22656/32000 (71%)] Loss: 1.96584 (semantic_loss: 0.01550, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.56793 
Train Epoch: 29 [188/250 24064/32000 (75%)] Loss: 1.96231 (semantic_loss: 0.01295, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.33465 
Train Epoch: 29 [199/250 25472/32000 (80%)] Loss: 1.96530 (semantic_loss: 0.01497, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.32973 
Train Epoch: 29 [210/250 26880/32000 (84%)] Loss: 1.96451 (semantic_loss: 0.01418, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=6.10282 
Train Epoch: 29 [221/250 28288/32000 (88%)] Loss: 1.96602 (semantic_loss: 0.01569, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.36181 
Train Epoch: 29 [232/250 29696/32000 (93%)] Loss: 1.96512 (semantic_loss: 0.01577, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.35892 
Train Epoch: 29 [243/250 31104/32000 (97%)] Loss: 1.96431 (semantic_loss: 0.01495, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.37611 
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/DCMH_MSRVTT_full/checkpoint-epoch29.pth ...
Done in 3.857s
removing stale ckpt [epoch 28] [took 0.00s]
 epoch          : 29
 loss           : 1.9652757601737976
 learning_rate  : 1.1891344262766608e-05
 n_samples      : 928000
 n_steps        : 7250
 MSRVTT_full_val/t2v_metrics/R1: 24.14486921529175
 MSRVTT_full_val/t2v_metrics/R5: 62.17303822937626
 MSRVTT_full_val/t2v_metrics/R10: 74.24547283702213
 MSRVTT_full_val/t2v_metrics/R50: 94.56740442655935
 MSRVTT_full_val/t2v_metrics/MedR: 4.0
 MSRVTT_full_val/t2v_metrics/MeanR: 12.954728370221329
 MSRVTT_full_val/t2v_metrics/geometric_mean_R1-R5-R10: 48.12443478435176
 MSRVTT_full_val/v2t_metrics/R1: 27.364185110663986
 MSRVTT_full_val/v2t_metrics/R5: 65.3923541247485
 MSRVTT_full_val/v2t_metrics/R10: 79.47686116700201
 MSRVTT_full_val/v2t_metrics/R50: 94.36619718309859
 MSRVTT_full_val/v2t_metrics/MedR: 3.0
 MSRVTT_full_val/v2t_metrics/MeanR: 11.46881287726358
 MSRVTT_full_val/v2t_metrics/geometric_mean_R1-R5-R10: 52.1975436645688
 MSRVTT_full_test/t2v_metrics/R1: 7.224080267558528
 MSRVTT_full_test/t2v_metrics/R5: 25.652173913043477
 MSRVTT_full_test/t2v_metrics/R10: 39.69899665551839
 MSRVTT_full_test/t2v_metrics/R50: 72.94314381270902
 MSRVTT_full_test/t2v_metrics/MedR: 16.0
 MSRVTT_full_test/t2v_metrics/MeanR: 64.66688963210703
 MSRVTT_full_test/t2v_metrics/geometric_mean_R1-R5-R10: 19.448917004086685
 MSRVTT_full_test/v2t_metrics/R1: 9.732441471571907
 MSRVTT_full_test/v2t_metrics/R5: 30.16722408026756
 MSRVTT_full_test/v2t_metrics/R10: 43.47826086956522
 MSRVTT_full_test/v2t_metrics/R50: 77.65886287625418
 MSRVTT_full_test/v2t_metrics/MedR: 14.0
 MSRVTT_full_test/v2t_metrics/MeanR: 54.60769230769231
 MSRVTT_full_test/v2t_metrics/geometric_mean_R1-R5-R10: 23.370953856990983
 mnt_best       : 20.054953883093965
 not_improved_count: 6
Train Epoch: 30 [1/250 128/32000 (0%)] Loss: 1.96484 (semantic_loss: 0.01451, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=27.46371 
Train Epoch: 30 [12/250 1536/32000 (5%)] Loss: 1.96514 (semantic_loss: 0.01481, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.36681 
Train Epoch: 30 [23/250 2944/32000 (9%)] Loss: 1.96524 (semantic_loss: 0.01589, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.33240 
Train Epoch: 30 [34/250 4352/32000 (14%)] Loss: 1.96637 (semantic_loss: 0.01604, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.34446 
Train Epoch: 30 [45/250 5760/32000 (18%)] Loss: 1.96569 (semantic_loss: 0.01536, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=1.53498 
Train Epoch: 30 [56/250 7168/32000 (22%)] Loss: 1.96429 (semantic_loss: 0.01493, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.33083 
Train Epoch: 30 [67/250 8576/32000 (27%)] Loss: 1.96538 (semantic_loss: 0.01505, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.33518 
Train Epoch: 30 [78/250 9984/32000 (31%)] Loss: 1.96602 (semantic_loss: 0.01667, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.34994 
Train Epoch: 30 [89/250 11392/32000 (36%)] Loss: 1.96583 (semantic_loss: 0.01550, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=1.17085 
Train Epoch: 30 [100/250 12800/32000 (40%)] Loss: 1.96484 (semantic_loss: 0.01451, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.33163 
Train Epoch: 30 [111/250 14208/32000 (44%)] Loss: 1.96440 (semantic_loss: 0.01504, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.33767 
Train Epoch: 30 [122/250 15616/32000 (49%)] Loss: 1.96486 (semantic_loss: 0.01550, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.33804 
Train Epoch: 30 [133/250 17024/32000 (53%)] Loss: 1.96433 (semantic_loss: 0.01497, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.33636 
Train Epoch: 30 [144/250 18432/32000 (58%)] Loss: 1.96525 (semantic_loss: 0.01492, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=5.46683 
Train Epoch: 30 [155/250 19840/32000 (62%)] Loss: 1.96569 (semantic_loss: 0.01634, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.33747 
Train Epoch: 30 [166/250 21248/32000 (66%)] Loss: 1.96515 (semantic_loss: 0.01482, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.33385 
Train Epoch: 30 [177/250 22656/32000 (71%)] Loss: 1.96615 (semantic_loss: 0.01582, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.34791 
Train Epoch: 30 [188/250 24064/32000 (75%)] Loss: 1.96496 (semantic_loss: 0.01462, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.33050 
Train Epoch: 30 [199/250 25472/32000 (80%)] Loss: 1.96722 (semantic_loss: 0.01689, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.33754 
Train Epoch: 30 [210/250 26880/32000 (84%)] Loss: 1.96435 (semantic_loss: 0.01499, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.36978 
Train Epoch: 30 [221/250 28288/32000 (88%)] Loss: 1.96673 (semantic_loss: 0.01738, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.33658 
Train Epoch: 30 [232/250 29696/32000 (93%)] Loss: 1.96566 (semantic_loss: 0.01534, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.33993 
Train Epoch: 30 [243/250 31104/32000 (97%)] Loss: 1.96301 (semantic_loss: 0.01365, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.33271 
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/DCMH_MSRVTT_full/checkpoint-epoch30.pth ...
Done in 4.233s
removing stale ckpt [epoch 29] [took 0.00s]
 epoch          : 30
 loss           : 1.9652294793128968
 learning_rate  : 1.1296777049628277e-05
 n_samples      : 960000
 n_steps        : 7500
 MSRVTT_full_val/t2v_metrics/R1: 23.74245472837022
 MSRVTT_full_val/t2v_metrics/R5: 62.57545271629779
 MSRVTT_full_val/t2v_metrics/R10: 76.05633802816901
 MSRVTT_full_val/t2v_metrics/R50: 94.36619718309859
 MSRVTT_full_val/t2v_metrics/MedR: 3.0
 MSRVTT_full_val/t2v_metrics/MeanR: 13.099597585513079
 MSRVTT_full_val/t2v_metrics/geometric_mean_R1-R5-R10: 48.34538354065407
 MSRVTT_full_val/v2t_metrics/R1: 27.16297786720322
 MSRVTT_full_val/v2t_metrics/R5: 66.80080482897384
 MSRVTT_full_val/v2t_metrics/R10: 78.67203219315896
 MSRVTT_full_val/v2t_metrics/R50: 95.37223340040241
 MSRVTT_full_val/v2t_metrics/MedR: 3.0
 MSRVTT_full_val/v2t_metrics/MeanR: 10.888329979879275
 MSRVTT_full_val/v2t_metrics/geometric_mean_R1-R5-R10: 52.26285707545918
 MSRVTT_full_test/t2v_metrics/R1: 7.25752508361204
 MSRVTT_full_test/t2v_metrics/R5: 26.68896321070234
 MSRVTT_full_test/t2v_metrics/R10: 39.69899665551839
 MSRVTT_full_test/t2v_metrics/R50: 73.64548494983278
 MSRVTT_full_test/t2v_metrics/MedR: 16.75
 MSRVTT_full_test/t2v_metrics/MeanR: 66.65735785953177
 MSRVTT_full_test/t2v_metrics/geometric_mean_R1-R5-R10: 19.737853736439018
 MSRVTT_full_test/v2t_metrics/R1: 8.963210702341136
 MSRVTT_full_test/v2t_metrics/R5: 30.434782608695652
 MSRVTT_full_test/v2t_metrics/R10: 43.87959866220736
 MSRVTT_full_test/v2t_metrics/R50: 77.29096989966555
 MSRVTT_full_test/v2t_metrics/MedR: 13.5
 MSRVTT_full_test/v2t_metrics/MeanR: 55.293645484949835
 MSRVTT_full_test/v2t_metrics/geometric_mean_R1-R5-R10: 22.875230846904525
 mnt_best       : 20.054953883093965
 not_improved_count: 7
Train Epoch: 31 [1/250 128/32000 (0%)] Loss: 1.96581 (semantic_loss: 0.01645, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=27.25496 
Train Epoch: 31 [12/250 1536/32000 (5%)] Loss: 1.96541 (semantic_loss: 0.01605, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.33906 
Train Epoch: 31 [23/250 2944/32000 (9%)] Loss: 1.96569 (semantic_loss: 0.01536, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.33540 
Train Epoch: 31 [34/250 4352/32000 (14%)] Loss: 1.96404 (semantic_loss: 0.01469, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.59470 
Train Epoch: 31 [45/250 5760/32000 (18%)] Loss: 1.96653 (semantic_loss: 0.01717, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.34052 
Train Epoch: 31 [56/250 7168/32000 (22%)] Loss: 1.96552 (semantic_loss: 0.01518, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.34168 
Train Epoch: 31 [67/250 8576/32000 (27%)] Loss: 1.96549 (semantic_loss: 0.01517, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.45430 
Train Epoch: 31 [78/250 9984/32000 (31%)] Loss: 1.96496 (semantic_loss: 0.01463, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.33733 
Train Epoch: 31 [89/250 11392/32000 (36%)] Loss: 1.96518 (semantic_loss: 0.01485, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.33819 
Train Epoch: 31 [100/250 12800/32000 (40%)] Loss: 1.96387 (semantic_loss: 0.01451, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.34047 
Train Epoch: 31 [111/250 14208/32000 (44%)] Loss: 1.96589 (semantic_loss: 0.01654, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.33889 
Train Epoch: 31 [122/250 15616/32000 (49%)] Loss: 1.96476 (semantic_loss: 0.01541, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.35947 
Train Epoch: 31 [133/250 17024/32000 (53%)] Loss: 1.96566 (semantic_loss: 0.01533, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.56979 
Train Epoch: 31 [144/250 18432/32000 (58%)] Loss: 1.96524 (semantic_loss: 0.01588, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.33978 
Train Epoch: 31 [155/250 19840/32000 (62%)] Loss: 1.96492 (semantic_loss: 0.01459, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.33732 
Train Epoch: 31 [166/250 21248/32000 (66%)] Loss: 1.96655 (semantic_loss: 0.01622, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.33399 
Train Epoch: 31 [177/250 22656/32000 (71%)] Loss: 1.96672 (semantic_loss: 0.01639, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.33334 
Train Epoch: 31 [188/250 24064/32000 (75%)] Loss: 1.96492 (semantic_loss: 0.01459, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.33865 
Train Epoch: 31 [199/250 25472/32000 (80%)] Loss: 1.96524 (semantic_loss: 0.01588, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=1.75056 
Train Epoch: 31 [210/250 26880/32000 (84%)] Loss: 1.96384 (semantic_loss: 0.01448, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=5.60053 
Train Epoch: 31 [221/250 28288/32000 (88%)] Loss: 1.96440 (semantic_loss: 0.01406, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.33775 
Train Epoch: 31 [232/250 29696/32000 (93%)] Loss: 1.96381 (semantic_loss: 0.01348, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.33951 
Train Epoch: 31 [243/250 31104/32000 (97%)] Loss: 1.96489 (semantic_loss: 0.01455, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.33521 
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/DCMH_MSRVTT_full/checkpoint-epoch31.pth ...
Done in 4.521s
Updating 'best' checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/DCMH_MSRVTT_full/checkpoint-epoch31.pth ...
Done in 8.165s
removing stale ckpt [epoch 30] [took 0.00s]
 epoch          : 31
 loss           : 1.965028950214386
 learning_rate  : 1.0731938197146863e-05
 n_samples      : 992000
 n_steps        : 7750
 MSRVTT_full_val/t2v_metrics/R1: 24.14486921529175
 MSRVTT_full_val/t2v_metrics/R5: 61.16700201207244
 MSRVTT_full_val/t2v_metrics/R10: 73.2394366197183
 MSRVTT_full_val/t2v_metrics/R50: 95.17102615694165
 MSRVTT_full_val/t2v_metrics/MedR: 3.0
 MSRVTT_full_val/t2v_metrics/MeanR: 12.940643863179075
 MSRVTT_full_val/t2v_metrics/geometric_mean_R1-R5-R10: 47.646281875776985
 MSRVTT_full_val/v2t_metrics/R1: 26.961770623742456
 MSRVTT_full_val/v2t_metrics/R5: 64.78873239436619
 MSRVTT_full_val/v2t_metrics/R10: 77.46478873239437
 MSRVTT_full_val/v2t_metrics/R50: 95.17102615694165
 MSRVTT_full_val/v2t_metrics/MedR: 3.0
 MSRVTT_full_val/v2t_metrics/MeanR: 11.033199195171026
 MSRVTT_full_val/v2t_metrics/geometric_mean_R1-R5-R10: 51.339394758506806
 MSRVTT_full_test/t2v_metrics/R1: 8.26086956521739
 MSRVTT_full_test/t2v_metrics/R5: 27.49163879598662
 MSRVTT_full_test/t2v_metrics/R10: 40.869565217391305
 MSRVTT_full_test/t2v_metrics/R50: 73.81270903010034
 MSRVTT_full_test/t2v_metrics/MedR: 16.0
 MSRVTT_full_test/t2v_metrics/MeanR: 65.36555183946489
 MSRVTT_full_test/t2v_metrics/geometric_mean_R1-R5-R10: 21.015616623152336
 MSRVTT_full_test/v2t_metrics/R1: 9.59866220735786
 MSRVTT_full_test/v2t_metrics/R5: 29.96655518394649
 MSRVTT_full_test/v2t_metrics/R10: 44.5819397993311
 MSRVTT_full_test/v2t_metrics/R50: 78.26086956521739
 MSRVTT_full_test/v2t_metrics/MedR: 13.0
 MSRVTT_full_test/v2t_metrics/MeanR: 55.917391304347824
 MSRVTT_full_test/v2t_metrics/geometric_mean_R1-R5-R10: 23.40644712491938
 mnt_best       : 21.015616623152336
 not_improved_count: 0
Train Epoch: 32 [1/250 128/32000 (0%)] Loss: 1.96414 (semantic_loss: 0.01479, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=28.16743 
Train Epoch: 32 [12/250 1536/32000 (5%)] Loss: 1.96519 (semantic_loss: 0.01584, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.54950 
Train Epoch: 32 [23/250 2944/32000 (9%)] Loss: 1.96477 (semantic_loss: 0.01444, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.34103 
Train Epoch: 32 [34/250 4352/32000 (14%)] Loss: 1.96512 (semantic_loss: 0.01479, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.35000 
Train Epoch: 32 [45/250 5760/32000 (18%)] Loss: 1.96483 (semantic_loss: 0.01450, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.33425 
Train Epoch: 32 [56/250 7168/32000 (22%)] Loss: 1.96506 (semantic_loss: 0.01473, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.34209 
Train Epoch: 32 [67/250 8576/32000 (27%)] Loss: 1.96500 (semantic_loss: 0.01467, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.33303 
Train Epoch: 32 [78/250 9984/32000 (31%)] Loss: 1.96586 (semantic_loss: 0.01553, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.33321 
Train Epoch: 32 [89/250 11392/32000 (36%)] Loss: 1.96349 (semantic_loss: 0.01414, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.35554 
Train Epoch: 32 [100/250 12800/32000 (40%)] Loss: 1.96439 (semantic_loss: 0.01406, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.32618 
Train Epoch: 32 [111/250 14208/32000 (44%)] Loss: 1.96399 (semantic_loss: 0.01464, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.33784 
Train Epoch: 32 [122/250 15616/32000 (49%)] Loss: 1.96482 (semantic_loss: 0.01546, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.34042 
Train Epoch: 32 [133/250 17024/32000 (53%)] Loss: 1.96507 (semantic_loss: 0.01474, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.36805 
Train Epoch: 32 [144/250 18432/32000 (58%)] Loss: 1.96511 (semantic_loss: 0.01575, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.33938 
Train Epoch: 32 [155/250 19840/32000 (62%)] Loss: 1.96512 (semantic_loss: 0.01577, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.34206 
Train Epoch: 32 [166/250 21248/32000 (66%)] Loss: 1.96590 (semantic_loss: 0.01556, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.44518 
Train Epoch: 32 [177/250 22656/32000 (71%)] Loss: 1.96395 (semantic_loss: 0.01459, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.34402 
Train Epoch: 32 [188/250 24064/32000 (75%)] Loss: 1.96472 (semantic_loss: 0.01439, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.34006 
Train Epoch: 32 [199/250 25472/32000 (80%)] Loss: 1.96414 (semantic_loss: 0.01381, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.34396 
Train Epoch: 32 [210/250 26880/32000 (84%)] Loss: 1.96456 (semantic_loss: 0.01521, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=2.51346 
Train Epoch: 32 [221/250 28288/32000 (88%)] Loss: 1.96428 (semantic_loss: 0.01396, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.33852 
Train Epoch: 32 [232/250 29696/32000 (93%)] Loss: 1.96343 (semantic_loss: 0.01408, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.69697 
Train Epoch: 32 [243/250 31104/32000 (97%)] Loss: 1.96453 (semantic_loss: 0.01419, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.36566 
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/DCMH_MSRVTT_full/checkpoint-epoch32.pth ...
Done in 3.859s
removing stale ckpt [epoch 31] [took 0.00s]
 epoch          : 32
 loss           : 1.964919991016388
 learning_rate  : 1.019534128728952e-05
 n_samples      : 1024000
 n_steps        : 8000
 MSRVTT_full_val/t2v_metrics/R1: 25.553319919517104
 MSRVTT_full_val/t2v_metrics/R5: 60.160965794768615
 MSRVTT_full_val/t2v_metrics/R10: 74.44668008048289
 MSRVTT_full_val/t2v_metrics/R50: 94.96981891348088
 MSRVTT_full_val/t2v_metrics/MedR: 3.0
 MSRVTT_full_val/t2v_metrics/MeanR: 12.554325955734406
 MSRVTT_full_val/t2v_metrics/geometric_mean_R1-R5-R10: 48.55148178398524
 MSRVTT_full_val/v2t_metrics/R1: 26.156941649899398
 MSRVTT_full_val/v2t_metrics/R5: 63.98390342052314
 MSRVTT_full_val/v2t_metrics/R10: 78.26961770623743
 MSRVTT_full_val/v2t_metrics/R50: 95.57344064386318
 MSRVTT_full_val/v2t_metrics/MedR: 3.0
 MSRVTT_full_val/v2t_metrics/MeanR: 10.5523138832998
 MSRVTT_full_val/v2t_metrics/geometric_mean_R1-R5-R10: 50.78673603625105
 MSRVTT_full_test/t2v_metrics/R1: 8.02675585284281
 MSRVTT_full_test/t2v_metrics/R5: 27.25752508361204
 MSRVTT_full_test/t2v_metrics/R10: 40.76923076923077
 MSRVTT_full_test/t2v_metrics/R50: 73.64548494983278
 MSRVTT_full_test/t2v_metrics/MedR: 16.0
 MSRVTT_full_test/t2v_metrics/MeanR: 66.43127090301003
 MSRVTT_full_test/t2v_metrics/geometric_mean_R1-R5-R10: 20.738929266169762
 MSRVTT_full_test/v2t_metrics/R1: 8.729096989966555
 MSRVTT_full_test/v2t_metrics/R5: 29.86622073578595
 MSRVTT_full_test/v2t_metrics/R10: 44.81605351170568
 MSRVTT_full_test/v2t_metrics/R50: 77.09030100334448
 MSRVTT_full_test/v2t_metrics/MedR: 13.5
 MSRVTT_full_test/v2t_metrics/MeanR: 55.11772575250836
 MSRVTT_full_test/v2t_metrics/geometric_mean_R1-R5-R10: 22.691388243735755
 mnt_best       : 21.015616623152336
 not_improved_count: 1
Train Epoch: 33 [1/250 128/32000 (0%)] Loss: 1.96345 (semantic_loss: 0.01409, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=33.60076 
Train Epoch: 33 [12/250 1536/32000 (5%)] Loss: 1.96376 (semantic_loss: 0.01343, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.33362 
Train Epoch: 33 [23/250 2944/32000 (9%)] Loss: 1.96445 (semantic_loss: 0.01412, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.33429 
Train Epoch: 33 [34/250 4352/32000 (14%)] Loss: 1.96509 (semantic_loss: 0.01573, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.33170 
Train Epoch: 33 [45/250 5760/32000 (18%)] Loss: 1.96372 (semantic_loss: 0.01436, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.90702 
Train Epoch: 33 [56/250 7168/32000 (22%)] Loss: 1.96538 (semantic_loss: 0.01603, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.33603 
Train Epoch: 33 [67/250 8576/32000 (27%)] Loss: 1.96567 (semantic_loss: 0.01534, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.34200 
Train Epoch: 33 [78/250 9984/32000 (31%)] Loss: 1.96502 (semantic_loss: 0.01469, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.37191 
Train Epoch: 33 [89/250 11392/32000 (36%)] Loss: 1.96494 (semantic_loss: 0.01461, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.35915 
Train Epoch: 33 [100/250 12800/32000 (40%)] Loss: 1.96502 (semantic_loss: 0.01469, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.34492 
Train Epoch: 33 [111/250 14208/32000 (44%)] Loss: 1.96481 (semantic_loss: 0.01546, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.35751 
Train Epoch: 33 [122/250 15616/32000 (49%)] Loss: 1.96531 (semantic_loss: 0.01596, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.33841 
Train Epoch: 33 [133/250 17024/32000 (53%)] Loss: 1.96392 (semantic_loss: 0.01456, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.34256 
Train Epoch: 33 [144/250 18432/32000 (58%)] Loss: 1.96527 (semantic_loss: 0.01494, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.33460 
Train Epoch: 33 [155/250 19840/32000 (62%)] Loss: 1.96308 (semantic_loss: 0.01373, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.33423 
Train Epoch: 33 [166/250 21248/32000 (66%)] Loss: 1.96308 (semantic_loss: 0.01373, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.81048 
Train Epoch: 33 [177/250 22656/32000 (71%)] Loss: 1.96615 (semantic_loss: 0.01582, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.33511 
Train Epoch: 33 [188/250 24064/32000 (75%)] Loss: 1.96419 (semantic_loss: 0.01484, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.33265 
Train Epoch: 33 [199/250 25472/32000 (80%)] Loss: 1.96309 (semantic_loss: 0.01374, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.33211 
Train Epoch: 33 [210/250 26880/32000 (84%)] Loss: 1.96464 (semantic_loss: 0.01431, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.34016 
Train Epoch: 33 [221/250 28288/32000 (88%)] Loss: 1.96470 (semantic_loss: 0.01535, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.33653 
Train Epoch: 33 [232/250 29696/32000 (93%)] Loss: 1.96434 (semantic_loss: 0.01499, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.33476 
Train Epoch: 33 [243/250 31104/32000 (97%)] Loss: 1.96446 (semantic_loss: 0.01510, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.90814 
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/DCMH_MSRVTT_full/checkpoint-epoch33.pth ...
Done in 3.914s
removing stale ckpt [epoch 32] [took 0.00s]
 epoch          : 33
 loss           : 1.9648107590675354
 learning_rate  : 9.685574222925043e-06
 n_samples      : 1056000
 n_steps        : 8250
 MSRVTT_full_val/t2v_metrics/R1: 23.541247484909455
 MSRVTT_full_val/t2v_metrics/R5: 61.56941649899397
 MSRVTT_full_val/t2v_metrics/R10: 73.2394366197183
 MSRVTT_full_val/t2v_metrics/R50: 94.56740442655935
 MSRVTT_full_val/t2v_metrics/MedR: 3.5
 MSRVTT_full_val/t2v_metrics/MeanR: 12.690140845070422
 MSRVTT_full_val/t2v_metrics/geometric_mean_R1-R5-R10: 47.34925700801703
 MSRVTT_full_val/v2t_metrics/R1: 26.358148893360163
 MSRVTT_full_val/v2t_metrics/R5: 64.1851106639839
 MSRVTT_full_val/v2t_metrics/R10: 78.26961770623743
 MSRVTT_full_val/v2t_metrics/R50: 95.57344064386318
 MSRVTT_full_val/v2t_metrics/MedR: 3.0
 MSRVTT_full_val/v2t_metrics/MeanR: 10.502012072434608
 MSRVTT_full_val/v2t_metrics/geometric_mean_R1-R5-R10: 50.969941830061586
 MSRVTT_full_test/t2v_metrics/R1: 7.157190635451505
 MSRVTT_full_test/t2v_metrics/R5: 25.953177257525084
 MSRVTT_full_test/t2v_metrics/R10: 40.0
 MSRVTT_full_test/t2v_metrics/R50: 72.6086956521739
 MSRVTT_full_test/t2v_metrics/MedR: 17.0
 MSRVTT_full_test/t2v_metrics/MeanR: 68.32558528428093
 MSRVTT_full_test/t2v_metrics/geometric_mean_R1-R5-R10: 19.513314150037363
 MSRVTT_full_test/v2t_metrics/R1: 9.665551839464882
 MSRVTT_full_test/v2t_metrics/R5: 30.20066889632107
 MSRVTT_full_test/v2t_metrics/R10: 44.34782608695652
 MSRVTT_full_test/v2t_metrics/R50: 77.35785953177258
 MSRVTT_full_test/v2t_metrics/MedR: 13.0
 MSRVTT_full_test/v2t_metrics/MeanR: 56.26622073578595
 MSRVTT_full_test/v2t_metrics/geometric_mean_R1-R5-R10: 23.480383401832846
 mnt_best       : 21.015616623152336
 not_improved_count: 2
Train Epoch: 34 [1/250 128/32000 (0%)] Loss: 1.96427 (semantic_loss: 0.01492, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=28.20313 
Train Epoch: 34 [12/250 1536/32000 (5%)] Loss: 1.96367 (semantic_loss: 0.01431, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.34213 
Train Epoch: 34 [23/250 2944/32000 (9%)] Loss: 1.96416 (semantic_loss: 0.01481, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.33030 
Train Epoch: 34 [34/250 4352/32000 (14%)] Loss: 1.96535 (semantic_loss: 0.01502, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.32800 
Train Epoch: 34 [45/250 5760/32000 (18%)] Loss: 1.96355 (semantic_loss: 0.01322, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.67143 
Train Epoch: 34 [56/250 7168/32000 (22%)] Loss: 1.96453 (semantic_loss: 0.01420, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.33431 
Train Epoch: 34 [67/250 8576/32000 (27%)] Loss: 1.96518 (semantic_loss: 0.01583, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=1.20155 
Train Epoch: 34 [78/250 9984/32000 (31%)] Loss: 1.96591 (semantic_loss: 0.01558, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.32600 
Train Epoch: 34 [89/250 11392/32000 (36%)] Loss: 1.96382 (semantic_loss: 0.01447, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.37960 
Train Epoch: 34 [100/250 12800/32000 (40%)] Loss: 1.96555 (semantic_loss: 0.01522, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.34246 
Train Epoch: 34 [111/250 14208/32000 (44%)] Loss: 1.96309 (semantic_loss: 0.01374, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.34022 
Train Epoch: 34 [122/250 15616/32000 (49%)] Loss: 1.96595 (semantic_loss: 0.01562, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.34290 
Train Epoch: 34 [133/250 17024/32000 (53%)] Loss: 1.96456 (semantic_loss: 0.01520, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.33130 
Train Epoch: 34 [144/250 18432/32000 (58%)] Loss: 1.96644 (semantic_loss: 0.01611, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=3.85551 
Train Epoch: 34 [155/250 19840/32000 (62%)] Loss: 1.96358 (semantic_loss: 0.01423, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.68070 
Train Epoch: 34 [166/250 21248/32000 (66%)] Loss: 1.96514 (semantic_loss: 0.01481, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.34283 
Train Epoch: 34 [177/250 22656/32000 (71%)] Loss: 1.96412 (semantic_loss: 0.01477, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.32854 
Train Epoch: 34 [188/250 24064/32000 (75%)] Loss: 1.96433 (semantic_loss: 0.01498, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.34318 
Train Epoch: 34 [199/250 25472/32000 (80%)] Loss: 1.96520 (semantic_loss: 0.01486, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.32711 
Train Epoch: 34 [210/250 26880/32000 (84%)] Loss: 1.96519 (semantic_loss: 0.01486, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.33642 
Train Epoch: 34 [221/250 28288/32000 (88%)] Loss: 1.96487 (semantic_loss: 0.01454, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.36768 
Train Epoch: 34 [232/250 29696/32000 (93%)] Loss: 1.96593 (semantic_loss: 0.01462, quant_loss: 1.95117, bit_balance_loss: 0.00013) batch_time=0.68857 
Train Epoch: 34 [243/250 31104/32000 (97%)] Loss: 1.96538 (semantic_loss: 0.01505, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.33789 
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/DCMH_MSRVTT_full/checkpoint-epoch34.pth ...
Done in 3.783s
removing stale ckpt [epoch 33] [took 0.00s]
 epoch          : 34
 loss           : 1.9647414736747741
 learning_rate  : 9.20129551177879e-06
 n_samples      : 1088000
 n_steps        : 8500
 MSRVTT_full_val/t2v_metrics/R1: 27.56539235412475
 MSRVTT_full_val/t2v_metrics/R5: 60.76458752515091
 MSRVTT_full_val/t2v_metrics/R10: 74.04426559356136
 MSRVTT_full_val/t2v_metrics/R50: 94.76861167002012
 MSRVTT_full_val/t2v_metrics/MedR: 3.0
 MSRVTT_full_val/t2v_metrics/MeanR: 12.5261569416499
 MSRVTT_full_val/t2v_metrics/geometric_mean_R1-R5-R10: 49.86954289986241
 MSRVTT_full_val/v2t_metrics/R1: 28.169014084507044
 MSRVTT_full_val/v2t_metrics/R5: 66.39839034205231
 MSRVTT_full_val/v2t_metrics/R10: 77.8672032193159
 MSRVTT_full_val/v2t_metrics/R50: 95.77464788732394
 MSRVTT_full_val/v2t_metrics/MedR: 3.0
 MSRVTT_full_val/v2t_metrics/MeanR: 10.486921529175051
 MSRVTT_full_val/v2t_metrics/geometric_mean_R1-R5-R10: 52.613184799706076
 MSRVTT_full_test/t2v_metrics/R1: 7.224080267558528
 MSRVTT_full_test/t2v_metrics/R5: 26.923076923076923
 MSRVTT_full_test/t2v_metrics/R10: 40.96989966555184
 MSRVTT_full_test/t2v_metrics/R50: 73.7123745819398
 MSRVTT_full_test/t2v_metrics/MedR: 15.5
 MSRVTT_full_test/t2v_metrics/MeanR: 66.22274247491639
 MSRVTT_full_test/t2v_metrics/geometric_mean_R1-R5-R10: 19.973647684576207
 MSRVTT_full_test/v2t_metrics/R1: 9.632107023411372
 MSRVTT_full_test/v2t_metrics/R5: 31.237458193979933
 MSRVTT_full_test/v2t_metrics/R10: 44.48160535117057
 MSRVTT_full_test/v2t_metrics/R50: 77.62541806020067
 MSRVTT_full_test/v2t_metrics/MedR: 13.0
 MSRVTT_full_test/v2t_metrics/MeanR: 54.78511705685619
 MSRVTT_full_test/v2t_metrics/geometric_mean_R1-R5-R10: 23.742465375433333
 mnt_best       : 21.015616623152336
 not_improved_count: 3
Train Epoch: 35 [1/250 128/32000 (0%)] Loss: 1.96440 (semantic_loss: 0.01505, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=29.76292 
Train Epoch: 35 [12/250 1536/32000 (5%)] Loss: 1.96480 (semantic_loss: 0.01446, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.34692 
Train Epoch: 35 [23/250 2944/32000 (9%)] Loss: 1.96700 (semantic_loss: 0.01668, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.35210 
Train Epoch: 35 [34/250 4352/32000 (14%)] Loss: 1.96603 (semantic_loss: 0.01668, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.33098 
Train Epoch: 35 [45/250 5760/32000 (18%)] Loss: 1.96437 (semantic_loss: 0.01404, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.34592 
Train Epoch: 35 [56/250 7168/32000 (22%)] Loss: 1.96562 (semantic_loss: 0.01529, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.33455 
Train Epoch: 35 [67/250 8576/32000 (27%)] Loss: 1.96554 (semantic_loss: 0.01521, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.33090 
Train Epoch: 35 [78/250 9984/32000 (31%)] Loss: 1.96502 (semantic_loss: 0.01567, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.33009 
Train Epoch: 35 [89/250 11392/32000 (36%)] Loss: 1.96557 (semantic_loss: 0.01524, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.35433 
Train Epoch: 35 [100/250 12800/32000 (40%)] Loss: 1.96396 (semantic_loss: 0.01461, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.35510 
Train Epoch: 35 [111/250 14208/32000 (44%)] Loss: 1.96446 (semantic_loss: 0.01511, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.33701 
Train Epoch: 35 [122/250 15616/32000 (49%)] Loss: 1.96467 (semantic_loss: 0.01532, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.45135 
Train Epoch: 35 [133/250 17024/32000 (53%)] Loss: 1.96538 (semantic_loss: 0.01505, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.33555 
Train Epoch: 35 [144/250 18432/32000 (58%)] Loss: 1.96583 (semantic_loss: 0.01551, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=3.88733 
Train Epoch: 35 [155/250 19840/32000 (62%)] Loss: 1.96500 (semantic_loss: 0.01467, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.33131 
Train Epoch: 35 [166/250 21248/32000 (66%)] Loss: 1.96523 (semantic_loss: 0.01490, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.34229 
Train Epoch: 35 [177/250 22656/32000 (71%)] Loss: 1.96541 (semantic_loss: 0.01508, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.33911 
Train Epoch: 35 [188/250 24064/32000 (75%)] Loss: 1.96638 (semantic_loss: 0.01605, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.34603 
Train Epoch: 35 [199/250 25472/32000 (80%)] Loss: 1.96200 (semantic_loss: 0.01362, quant_loss: 1.94824, bit_balance_loss: 0.00013) batch_time=0.34137 
Train Epoch: 35 [210/250 26880/32000 (84%)] Loss: 1.96312 (semantic_loss: 0.01377, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.33540 
Train Epoch: 35 [221/250 28288/32000 (88%)] Loss: 1.96530 (semantic_loss: 0.01497, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.34928 
Train Epoch: 35 [232/250 29696/32000 (93%)] Loss: 1.96541 (semantic_loss: 0.01508, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.33376 
Train Epoch: 35 [243/250 31104/32000 (97%)] Loss: 1.96502 (semantic_loss: 0.01567, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.33482 
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/DCMH_MSRVTT_full/checkpoint-epoch35.pth ...
Done in 3.933s
removing stale ckpt [epoch 34] [took 0.00s]
 epoch          : 35
 loss           : 1.9646300659179687
 learning_rate  : 8.74123073618985e-06
 n_samples      : 1120000
 n_steps        : 8750
 MSRVTT_full_val/t2v_metrics/R1: 25.955734406438633
 MSRVTT_full_val/t2v_metrics/R5: 61.77062374245473
 MSRVTT_full_val/t2v_metrics/R10: 75.45271629778672
 MSRVTT_full_val/t2v_metrics/R50: 94.76861167002012
 MSRVTT_full_val/t2v_metrics/MedR: 3.0
 MSRVTT_full_val/t2v_metrics/MeanR: 12.455734406438632
 MSRVTT_full_val/t2v_metrics/geometric_mean_R1-R5-R10: 49.45726116756159
 MSRVTT_full_val/v2t_metrics/R1: 26.156941649899398
 MSRVTT_full_val/v2t_metrics/R5: 65.3923541247485
 MSRVTT_full_val/v2t_metrics/R10: 77.8672032193159
 MSRVTT_full_val/v2t_metrics/R50: 95.57344064386318
 MSRVTT_full_val/v2t_metrics/MedR: 4.0
 MSRVTT_full_val/v2t_metrics/MeanR: 10.678068410462776
 MSRVTT_full_val/v2t_metrics/geometric_mean_R1-R5-R10: 51.06886087100388
 MSRVTT_full_test/t2v_metrics/R1: 7.826086956521739
 MSRVTT_full_test/t2v_metrics/R5: 27.792642140468228
 MSRVTT_full_test/t2v_metrics/R10: 40.702341137123746
 MSRVTT_full_test/t2v_metrics/R50: 74.34782608695652
 MSRVTT_full_test/t2v_metrics/MedR: 16.0
 MSRVTT_full_test/t2v_metrics/MeanR: 62.788628762541805
 MSRVTT_full_test/t2v_metrics/geometric_mean_R1-R5-R10: 20.687021452623323
 MSRVTT_full_test/v2t_metrics/R1: 10.066889632107024
 MSRVTT_full_test/v2t_metrics/R5: 31.036789297658864
 MSRVTT_full_test/v2t_metrics/R10: 45.05016722408027
 MSRVTT_full_test/v2t_metrics/R50: 78.89632107023411
 MSRVTT_full_test/v2t_metrics/MedR: 13.0
 MSRVTT_full_test/v2t_metrics/MeanR: 53.13528428093645
 MSRVTT_full_test/v2t_metrics/geometric_mean_R1-R5-R10: 24.14475673857178
 mnt_best       : 21.015616623152336
 not_improved_count: 4
Train Epoch: 36 [1/250 128/32000 (0%)] Loss: 1.96594 (semantic_loss: 0.01560, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=32.52311 
Train Epoch: 36 [12/250 1536/32000 (5%)] Loss: 1.96498 (semantic_loss: 0.01562, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.32680 
Train Epoch: 36 [23/250 2944/32000 (9%)] Loss: 1.96410 (semantic_loss: 0.01475, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.32186 
Train Epoch: 36 [34/250 4352/32000 (14%)] Loss: 1.96626 (semantic_loss: 0.01594, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.34285 
Train Epoch: 36 [45/250 5760/32000 (18%)] Loss: 1.96409 (semantic_loss: 0.01376, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.33119 
Train Epoch: 36 [56/250 7168/32000 (22%)] Loss: 1.96402 (semantic_loss: 0.01369, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.34432 
Train Epoch: 36 [67/250 8576/32000 (27%)] Loss: 1.96457 (semantic_loss: 0.01522, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.36246 
Train Epoch: 36 [78/250 9984/32000 (31%)] Loss: 1.96448 (semantic_loss: 0.01513, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.33674 
Train Epoch: 36 [89/250 11392/32000 (36%)] Loss: 1.96553 (semantic_loss: 0.01617, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.32913 
Train Epoch: 36 [100/250 12800/32000 (40%)] Loss: 1.96215 (semantic_loss: 0.01280, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.32874 
Train Epoch: 36 [111/250 14208/32000 (44%)] Loss: 1.96438 (semantic_loss: 0.01405, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.32902 
Train Epoch: 36 [122/250 15616/32000 (49%)] Loss: 1.96356 (semantic_loss: 0.01421, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.33708 
Train Epoch: 36 [133/250 17024/32000 (53%)] Loss: 1.96553 (semantic_loss: 0.01520, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.34335 
Train Epoch: 36 [144/250 18432/32000 (58%)] Loss: 1.96394 (semantic_loss: 0.01459, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=3.05367 
Train Epoch: 36 [155/250 19840/32000 (62%)] Loss: 1.96453 (semantic_loss: 0.01420, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.33937 
Train Epoch: 36 [166/250 21248/32000 (66%)] Loss: 1.96312 (semantic_loss: 0.01377, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.34136 
Train Epoch: 36 [177/250 22656/32000 (71%)] Loss: 1.96316 (semantic_loss: 0.01381, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.34705 
Train Epoch: 36 [188/250 24064/32000 (75%)] Loss: 1.96406 (semantic_loss: 0.01373, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.34087 
Train Epoch: 36 [199/250 25472/32000 (80%)] Loss: 1.96307 (semantic_loss: 0.01372, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.33418 
Train Epoch: 36 [210/250 26880/32000 (84%)] Loss: 1.96362 (semantic_loss: 0.01427, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.34505 
Train Epoch: 36 [221/250 28288/32000 (88%)] Loss: 1.96420 (semantic_loss: 0.01387, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.34032 
Train Epoch: 36 [232/250 29696/32000 (93%)] Loss: 1.96551 (semantic_loss: 0.01518, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.33449 
Train Epoch: 36 [243/250 31104/32000 (97%)] Loss: 1.96483 (semantic_loss: 0.01450, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.33067 
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/DCMH_MSRVTT_full/checkpoint-epoch36.pth ...
Done in 3.997s
removing stale ckpt [epoch 35] [took 0.00s]
 epoch          : 36
 loss           : 1.9646267814636231
 learning_rate  : 8.304169199380357e-06
 n_samples      : 1152000
 n_steps        : 9000
 MSRVTT_full_val/t2v_metrics/R1: 24.949698189134807
 MSRVTT_full_val/t2v_metrics/R5: 61.77062374245473
 MSRVTT_full_val/t2v_metrics/R10: 75.25150905432595
 MSRVTT_full_val/t2v_metrics/R50: 94.56740442655935
 MSRVTT_full_val/t2v_metrics/MedR: 3.0
 MSRVTT_full_val/t2v_metrics/MeanR: 12.964788732394366
 MSRVTT_full_val/t2v_metrics/geometric_mean_R1-R5-R10: 48.766415229750415
 MSRVTT_full_val/v2t_metrics/R1: 26.961770623742456
 MSRVTT_full_val/v2t_metrics/R5: 64.98993963782696
 MSRVTT_full_val/v2t_metrics/R10: 77.8672032193159
 MSRVTT_full_val/v2t_metrics/R50: 95.17102615694165
 MSRVTT_full_val/v2t_metrics/MedR: 3.0
 MSRVTT_full_val/v2t_metrics/MeanR: 10.913480885311872
 MSRVTT_full_val/v2t_metrics/geometric_mean_R1-R5-R10: 51.48132387145055
 MSRVTT_full_test/t2v_metrics/R1: 7.993311036789297
 MSRVTT_full_test/t2v_metrics/R5: 27.959866220735787
 MSRVTT_full_test/t2v_metrics/R10: 41.27090301003344
 MSRVTT_full_test/t2v_metrics/R50: 73.64548494983278
 MSRVTT_full_test/t2v_metrics/MedR: 16.0
 MSRVTT_full_test/t2v_metrics/MeanR: 65.62541806020067
 MSRVTT_full_test/t2v_metrics/geometric_mean_R1-R5-R10: 20.971778286311828
 MSRVTT_full_test/v2t_metrics/R1: 9.966555183946488
 MSRVTT_full_test/v2t_metrics/R5: 30.668896321070235
 MSRVTT_full_test/v2t_metrics/R10: 45.551839464882946
 MSRVTT_full_test/v2t_metrics/R50: 77.92642140468227
 MSRVTT_full_test/v2t_metrics/MedR: 13.0
 MSRVTT_full_test/v2t_metrics/MeanR: 54.28678929765886
 MSRVTT_full_test/v2t_metrics/geometric_mean_R1-R5-R10: 24.057456773010802
 mnt_best       : 21.015616623152336
 not_improved_count: 5
Train Epoch: 37 [1/250 128/32000 (0%)] Loss: 1.96428 (semantic_loss: 0.01395, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=28.58254 
Train Epoch: 37 [12/250 1536/32000 (5%)] Loss: 1.96419 (semantic_loss: 0.01484, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.33362 
Train Epoch: 37 [23/250 2944/32000 (9%)] Loss: 1.96376 (semantic_loss: 0.01441, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.33340 
Train Epoch: 37 [34/250 4352/32000 (14%)] Loss: 1.96321 (semantic_loss: 0.01386, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.33385 
Train Epoch: 37 [45/250 5760/32000 (18%)] Loss: 1.96398 (semantic_loss: 0.01462, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.32857 
Train Epoch: 37 [56/250 7168/32000 (22%)] Loss: 1.96215 (semantic_loss: 0.01279, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.32910 
Train Epoch: 37 [67/250 8576/32000 (27%)] Loss: 1.96493 (semantic_loss: 0.01558, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=1.92927 
Train Epoch: 37 [78/250 9984/32000 (31%)] Loss: 1.96368 (semantic_loss: 0.01432, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.35152 
Train Epoch: 37 [89/250 11392/32000 (36%)] Loss: 1.96364 (semantic_loss: 0.01331, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.44730 
Train Epoch: 37 [100/250 12800/32000 (40%)] Loss: 1.96394 (semantic_loss: 0.01459, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.43958 
Train Epoch: 37 [111/250 14208/32000 (44%)] Loss: 1.96294 (semantic_loss: 0.01359, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.34466 
Train Epoch: 37 [122/250 15616/32000 (49%)] Loss: 1.96563 (semantic_loss: 0.01530, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.34037 
Train Epoch: 37 [133/250 17024/32000 (53%)] Loss: 1.96481 (semantic_loss: 0.01448, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=1.85553 
Train Epoch: 37 [144/250 18432/32000 (58%)] Loss: 1.96432 (semantic_loss: 0.01496, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.33294 
Train Epoch: 37 [155/250 19840/32000 (62%)] Loss: 1.96522 (semantic_loss: 0.01489, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.33572 
Train Epoch: 37 [166/250 21248/32000 (66%)] Loss: 1.96321 (semantic_loss: 0.01385, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.33907 
Train Epoch: 37 [177/250 22656/32000 (71%)] Loss: 1.96389 (semantic_loss: 0.01453, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.46639 
Train Epoch: 37 [188/250 24064/32000 (75%)] Loss: 1.96555 (semantic_loss: 0.01522, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.33366 
Train Epoch: 37 [199/250 25472/32000 (80%)] Loss: 1.96431 (semantic_loss: 0.01398, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.33371 
Train Epoch: 37 [210/250 26880/32000 (84%)] Loss: 1.96421 (semantic_loss: 0.01485, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.33129 
Train Epoch: 37 [221/250 28288/32000 (88%)] Loss: 1.96180 (semantic_loss: 0.01244, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.32858 
Train Epoch: 37 [232/250 29696/32000 (93%)] Loss: 1.96527 (semantic_loss: 0.01494, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.33605 
Train Epoch: 37 [243/250 31104/32000 (97%)] Loss: 1.96503 (semantic_loss: 0.01470, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.33814 
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/DCMH_MSRVTT_full/checkpoint-epoch37.pth ...
Done in 3.738s
removing stale ckpt [epoch 36] [took 0.00s]
 epoch          : 37
 loss           : 1.964471444606781
 learning_rate  : 7.888960739411339e-06
 n_samples      : 1184000
 n_steps        : 9250
 MSRVTT_full_val/t2v_metrics/R1: 25.553319919517104
 MSRVTT_full_val/t2v_metrics/R5: 61.56941649899397
 MSRVTT_full_val/t2v_metrics/R10: 74.24547283702213
 MSRVTT_full_val/t2v_metrics/R50: 94.96981891348088
 MSRVTT_full_val/t2v_metrics/MedR: 4.0
 MSRVTT_full_val/t2v_metrics/MeanR: 12.843058350100604
 MSRVTT_full_val/t2v_metrics/geometric_mean_R1-R5-R10: 48.883329941805144
 MSRVTT_full_val/v2t_metrics/R1: 27.16297786720322
 MSRVTT_full_val/v2t_metrics/R5: 66.19718309859155
 MSRVTT_full_val/v2t_metrics/R10: 77.46478873239437
 MSRVTT_full_val/v2t_metrics/R50: 95.37223340040241
 MSRVTT_full_val/v2t_metrics/MedR: 3.0
 MSRVTT_full_val/v2t_metrics/MeanR: 10.859154929577464
 MSRVTT_full_val/v2t_metrics/geometric_mean_R1-R5-R10: 51.83706571499347
 MSRVTT_full_test/t2v_metrics/R1: 7.792642140468227
 MSRVTT_full_test/t2v_metrics/R5: 26.755852842809364
 MSRVTT_full_test/t2v_metrics/R10: 40.23411371237458
 MSRVTT_full_test/t2v_metrics/R50: 72.90969899665552
 MSRVTT_full_test/t2v_metrics/MedR: 16.25
 MSRVTT_full_test/t2v_metrics/MeanR: 68.86020066889633
 MSRVTT_full_test/t2v_metrics/geometric_mean_R1-R5-R10: 20.318859320642616
 MSRVTT_full_test/v2t_metrics/R1: 8.996655518394649
 MSRVTT_full_test/v2t_metrics/R5: 30.0
 MSRVTT_full_test/v2t_metrics/R10: 45.38461538461539
 MSRVTT_full_test/v2t_metrics/R50: 77.45819397993311
 MSRVTT_full_test/v2t_metrics/MedR: 13.0
 MSRVTT_full_test/v2t_metrics/MeanR: 56.10401337792642
 MSRVTT_full_test/v2t_metrics/geometric_mean_R1-R5-R10: 23.051737666523263
 mnt_best       : 21.015616623152336
 not_improved_count: 6
Train Epoch: 38 [1/250 128/32000 (0%)] Loss: 1.96457 (semantic_loss: 0.01425, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=32.47343 
Train Epoch: 38 [12/250 1536/32000 (5%)] Loss: 1.96294 (semantic_loss: 0.01358, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.35027 
Train Epoch: 38 [23/250 2944/32000 (9%)] Loss: 1.96512 (semantic_loss: 0.01480, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.33213 
Train Epoch: 38 [34/250 4352/32000 (14%)] Loss: 1.96467 (semantic_loss: 0.01532, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.34758 
Train Epoch: 38 [45/250 5760/32000 (18%)] Loss: 1.96402 (semantic_loss: 0.01369, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.33294 
Train Epoch: 38 [56/250 7168/32000 (22%)] Loss: 1.96402 (semantic_loss: 0.01467, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.36391 
Train Epoch: 38 [67/250 8576/32000 (27%)] Loss: 1.96355 (semantic_loss: 0.01322, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.33607 
Train Epoch: 38 [78/250 9984/32000 (31%)] Loss: 1.96511 (semantic_loss: 0.01478, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.33795 
Train Epoch: 38 [89/250 11392/32000 (36%)] Loss: 1.96533 (semantic_loss: 0.01402, quant_loss: 1.95117, bit_balance_loss: 0.00013) batch_time=0.34213 
Train Epoch: 38 [100/250 12800/32000 (40%)] Loss: 1.96358 (semantic_loss: 0.01325, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=1.18990 
Train Epoch: 38 [111/250 14208/32000 (44%)] Loss: 1.96618 (semantic_loss: 0.01586, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.79259 
Train Epoch: 38 [122/250 15616/32000 (49%)] Loss: 1.96317 (semantic_loss: 0.01382, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.33601 
Train Epoch: 38 [133/250 17024/32000 (53%)] Loss: 1.96580 (semantic_loss: 0.01547, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.33683 
Train Epoch: 38 [144/250 18432/32000 (58%)] Loss: 1.96526 (semantic_loss: 0.01493, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.54877 
Train Epoch: 38 [155/250 19840/32000 (62%)] Loss: 1.96415 (semantic_loss: 0.01383, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=1.46107 
Train Epoch: 38 [166/250 21248/32000 (66%)] Loss: 1.96536 (semantic_loss: 0.01503, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.57763 
Train Epoch: 38 [177/250 22656/32000 (71%)] Loss: 1.96521 (semantic_loss: 0.01488, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.33114 
Train Epoch: 38 [188/250 24064/32000 (75%)] Loss: 1.96340 (semantic_loss: 0.01405, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.33509 
Train Epoch: 38 [199/250 25472/32000 (80%)] Loss: 1.96304 (semantic_loss: 0.01369, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.34128 
Train Epoch: 38 [210/250 26880/32000 (84%)] Loss: 1.96349 (semantic_loss: 0.01414, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.33099 
Train Epoch: 38 [221/250 28288/32000 (88%)] Loss: 1.96471 (semantic_loss: 0.01438, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.34007 
Train Epoch: 38 [232/250 29696/32000 (93%)] Loss: 1.96390 (semantic_loss: 0.01455, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.33537 
Train Epoch: 38 [243/250 31104/32000 (97%)] Loss: 1.96472 (semantic_loss: 0.01537, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.33039 
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/DCMH_MSRVTT_full/checkpoint-epoch38.pth ...
Done in 13.198s
removing stale ckpt [epoch 37] [took 0.00s]
 epoch          : 38
 loss           : 1.9642890396118164
 learning_rate  : 7.494512702440772e-06
 n_samples      : 1216000
 n_steps        : 9500
 MSRVTT_full_val/t2v_metrics/R1: 25.553319919517104
 MSRVTT_full_val/t2v_metrics/R5: 62.374245472837025
 MSRVTT_full_val/t2v_metrics/R10: 75.85513078470825
 MSRVTT_full_val/t2v_metrics/R50: 94.16498993963782
 MSRVTT_full_val/t2v_metrics/MedR: 3.0
 MSRVTT_full_val/t2v_metrics/MeanR: 12.364185110663984
 MSRVTT_full_val/t2v_metrics/geometric_mean_R1-R5-R10: 49.44767387485586
 MSRVTT_full_val/v2t_metrics/R1: 27.364185110663986
 MSRVTT_full_val/v2t_metrics/R5: 64.58752515090544
 MSRVTT_full_val/v2t_metrics/R10: 78.47082494969818
 MSRVTT_full_val/v2t_metrics/R50: 95.57344064386318
 MSRVTT_full_val/v2t_metrics/MedR: 3.0
 MSRVTT_full_val/v2t_metrics/MeanR: 10.380281690140846
 MSRVTT_full_val/v2t_metrics/geometric_mean_R1-R5-R10: 51.76224776279913
 MSRVTT_full_test/t2v_metrics/R1: 8.02675585284281
 MSRVTT_full_test/t2v_metrics/R5: 27.558528428093645
 MSRVTT_full_test/t2v_metrics/R10: 40.702341137123746
 MSRVTT_full_test/t2v_metrics/R50: 74.31438127090301
 MSRVTT_full_test/t2v_metrics/MedR: 15.0
 MSRVTT_full_test/t2v_metrics/MeanR: 65.93729096989966
 MSRVTT_full_test/t2v_metrics/geometric_mean_R1-R5-R10: 20.803599716282367
 MSRVTT_full_test/v2t_metrics/R1: 9.565217391304348
 MSRVTT_full_test/v2t_metrics/R5: 31.505016722408026
 MSRVTT_full_test/v2t_metrics/R10: 46.35451505016722
 MSRVTT_full_test/v2t_metrics/R50: 78.52842809364549
 MSRVTT_full_test/v2t_metrics/MedR: 12.0
 MSRVTT_full_test/v2t_metrics/MeanR: 53.26672240802676
 MSRVTT_full_test/v2t_metrics/geometric_mean_R1-R5-R10: 24.08364408245043
 mnt_best       : 21.015616623152336
 not_improved_count: 7
Train Epoch: 39 [1/250 128/32000 (0%)] Loss: 1.96502 (semantic_loss: 0.01566, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=32.41248 
Train Epoch: 39 [12/250 1536/32000 (5%)] Loss: 1.96457 (semantic_loss: 0.01424, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.34378 
Train Epoch: 39 [23/250 2944/32000 (9%)] Loss: 1.96463 (semantic_loss: 0.01430, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.33292 
Train Epoch: 39 [34/250 4352/32000 (14%)] Loss: 1.96511 (semantic_loss: 0.01478, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.33262 
Train Epoch: 39 [45/250 5760/32000 (18%)] Loss: 1.96530 (semantic_loss: 0.01497, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.33167 
Train Epoch: 39 [56/250 7168/32000 (22%)] Loss: 1.96439 (semantic_loss: 0.01406, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.33162 
Train Epoch: 39 [67/250 8576/32000 (27%)] Loss: 1.96335 (semantic_loss: 0.01400, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=1.49589 
Train Epoch: 39 [78/250 9984/32000 (31%)] Loss: 1.96357 (semantic_loss: 0.01422, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.33090 
Train Epoch: 39 [89/250 11392/32000 (36%)] Loss: 1.96334 (semantic_loss: 0.01399, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.33908 
Train Epoch: 39 [100/250 12800/32000 (40%)] Loss: 1.96464 (semantic_loss: 0.01431, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.35854 
Train Epoch: 39 [111/250 14208/32000 (44%)] Loss: 1.96382 (semantic_loss: 0.01447, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.33730 
Train Epoch: 39 [122/250 15616/32000 (49%)] Loss: 1.96309 (semantic_loss: 0.01373, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.33885 
Train Epoch: 39 [133/250 17024/32000 (53%)] Loss: 1.96537 (semantic_loss: 0.01504, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.33368 
Train Epoch: 39 [144/250 18432/32000 (58%)] Loss: 1.96546 (semantic_loss: 0.01513, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.47381 
Train Epoch: 39 [155/250 19840/32000 (62%)] Loss: 1.96358 (semantic_loss: 0.01326, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.33310 
Train Epoch: 39 [166/250 21248/32000 (66%)] Loss: 1.96349 (semantic_loss: 0.01414, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=3.63044 
Train Epoch: 39 [177/250 22656/32000 (71%)] Loss: 1.96361 (semantic_loss: 0.01328, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.33218 
Train Epoch: 39 [188/250 24064/32000 (75%)] Loss: 1.96216 (semantic_loss: 0.01281, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.33133 
Train Epoch: 39 [199/250 25472/32000 (80%)] Loss: 1.96526 (semantic_loss: 0.01395, quant_loss: 1.95117, bit_balance_loss: 0.00013) batch_time=0.33488 
Train Epoch: 39 [210/250 26880/32000 (84%)] Loss: 1.96550 (semantic_loss: 0.01517, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=1.31692 
Train Epoch: 39 [221/250 28288/32000 (88%)] Loss: 1.96450 (semantic_loss: 0.01417, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.35477 
Train Epoch: 39 [232/250 29696/32000 (93%)] Loss: 1.96570 (semantic_loss: 0.01537, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.33695 
Train Epoch: 39 [243/250 31104/32000 (97%)] Loss: 1.96455 (semantic_loss: 0.01422, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.33891 
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/DCMH_MSRVTT_full/checkpoint-epoch39.pth ...
Done in 3.642s
removing stale ckpt [epoch 38] [took 0.00s]
 epoch          : 39
 loss           : 1.9641715111732483
 learning_rate  : 7.119787067318733e-06
 n_samples      : 1248000
 n_steps        : 9750
 MSRVTT_full_val/t2v_metrics/R1: 25.955734406438633
 MSRVTT_full_val/t2v_metrics/R5: 61.3682092555332
 MSRVTT_full_val/t2v_metrics/R10: 74.44668008048289
 MSRVTT_full_val/t2v_metrics/R50: 93.96378269617706
 MSRVTT_full_val/t2v_metrics/MedR: 3.0
 MSRVTT_full_val/t2v_metrics/MeanR: 13.532193158953723
 MSRVTT_full_val/t2v_metrics/geometric_mean_R1-R5-R10: 49.12931427674206
 MSRVTT_full_val/v2t_metrics/R1: 27.56539235412475
 MSRVTT_full_val/v2t_metrics/R5: 63.78269617706238
 MSRVTT_full_val/v2t_metrics/R10: 76.65995975855131
 MSRVTT_full_val/v2t_metrics/R50: 95.37223340040241
 MSRVTT_full_val/v2t_metrics/MedR: 3.0
 MSRVTT_full_val/v2t_metrics/MeanR: 11.226358148893361
 MSRVTT_full_val/v2t_metrics/geometric_mean_R1-R5-R10: 51.27179785029634
 MSRVTT_full_test/t2v_metrics/R1: 7.926421404682274
 MSRVTT_full_test/t2v_metrics/R5: 25.88628762541806
 MSRVTT_full_test/t2v_metrics/R10: 39.297658862876254
 MSRVTT_full_test/t2v_metrics/R50: 71.47157190635451
 MSRVTT_full_test/t2v_metrics/MedR: 17.0
 MSRVTT_full_test/t2v_metrics/MeanR: 72.77759197324414
 MSRVTT_full_test/t2v_metrics/geometric_mean_R1-R5-R10: 20.052623639660332
 MSRVTT_full_test/v2t_metrics/R1: 9.130434782608695
 MSRVTT_full_test/v2t_metrics/R5: 29.264214046822744
 MSRVTT_full_test/v2t_metrics/R10: 44.54849498327759
 MSRVTT_full_test/v2t_metrics/R50: 76.92307692307692
 MSRVTT_full_test/v2t_metrics/MedR: 13.0
 MSRVTT_full_test/v2t_metrics/MeanR: 57.55769230769231
 MSRVTT_full_test/v2t_metrics/geometric_mean_R1-R5-R10: 22.832516840511552
 mnt_best       : 21.015616623152336
 not_improved_count: 8
Train Epoch: 40 [1/250 128/32000 (0%)] Loss: 1.96359 (semantic_loss: 0.01326, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=25.57677 
Train Epoch: 40 [12/250 1536/32000 (5%)] Loss: 1.96356 (semantic_loss: 0.01421, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.32893 
Train Epoch: 40 [23/250 2944/32000 (9%)] Loss: 1.96319 (semantic_loss: 0.01384, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.33400 
Train Epoch: 40 [34/250 4352/32000 (14%)] Loss: 1.96394 (semantic_loss: 0.01459, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.34326 
Train Epoch: 40 [45/250 5760/32000 (18%)] Loss: 1.96514 (semantic_loss: 0.01579, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.56371 
Train Epoch: 40 [56/250 7168/32000 (22%)] Loss: 1.96489 (semantic_loss: 0.01456, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.34835 
Train Epoch: 40 [67/250 8576/32000 (27%)] Loss: 1.96307 (semantic_loss: 0.01372, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.38145 
Train Epoch: 40 [78/250 9984/32000 (31%)] Loss: 1.96418 (semantic_loss: 0.01385, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.33356 
Train Epoch: 40 [89/250 11392/32000 (36%)] Loss: 1.96559 (semantic_loss: 0.01526, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.33215 
Train Epoch: 40 [100/250 12800/32000 (40%)] Loss: 1.96310 (semantic_loss: 0.01375, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.33490 
Train Epoch: 40 [111/250 14208/32000 (44%)] Loss: 1.96432 (semantic_loss: 0.01497, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.56118 
Train Epoch: 40 [122/250 15616/32000 (49%)] Loss: 1.96405 (semantic_loss: 0.01470, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.32760 
Train Epoch: 40 [133/250 17024/32000 (53%)] Loss: 1.96559 (semantic_loss: 0.01526, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.33636 
Train Epoch: 40 [144/250 18432/32000 (58%)] Loss: 1.96474 (semantic_loss: 0.01441, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.33253 
Train Epoch: 40 [155/250 19840/32000 (62%)] Loss: 1.96488 (semantic_loss: 0.01552, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.33195 
Train Epoch: 40 [166/250 21248/32000 (66%)] Loss: 1.96317 (semantic_loss: 0.01284, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.33695 
Train Epoch: 40 [177/250 22656/32000 (71%)] Loss: 1.96483 (semantic_loss: 0.01450, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.45000 
Train Epoch: 40 [188/250 24064/32000 (75%)] Loss: 1.96380 (semantic_loss: 0.01347, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.33692 
Train Epoch: 40 [199/250 25472/32000 (80%)] Loss: 1.96395 (semantic_loss: 0.01460, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.34082 
Train Epoch: 40 [210/250 26880/32000 (84%)] Loss: 1.96414 (semantic_loss: 0.01479, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=3.75607 
Train Epoch: 40 [221/250 28288/32000 (88%)] Loss: 1.96210 (semantic_loss: 0.01275, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.33288 
Train Epoch: 40 [232/250 29696/32000 (93%)] Loss: 1.96631 (semantic_loss: 0.01696, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.47137 
Train Epoch: 40 [243/250 31104/32000 (97%)] Loss: 1.96515 (semantic_loss: 0.01482, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.33476 
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/DCMH_MSRVTT_full/checkpoint-epoch40.pth ...
Done in 3.988s
removing stale ckpt [epoch 39] [took 0.00s]
 epoch          : 40
 loss           : 1.9641270666122437
 learning_rate  : 6.763797713952796e-06
 n_samples      : 1280000
 n_steps        : 10000
 MSRVTT_full_val/t2v_metrics/R1: 24.547283702213278
 MSRVTT_full_val/t2v_metrics/R5: 61.3682092555332
 MSRVTT_full_val/t2v_metrics/R10: 75.25150905432595
 MSRVTT_full_val/t2v_metrics/R50: 94.56740442655935
 MSRVTT_full_val/t2v_metrics/MedR: 3.0
 MSRVTT_full_val/t2v_metrics/MeanR: 12.681086519114688
 MSRVTT_full_val/t2v_metrics/geometric_mean_R1-R5-R10: 48.39725188184523
 MSRVTT_full_val/v2t_metrics/R1: 26.559356136820927
 MSRVTT_full_val/v2t_metrics/R5: 64.1851106639839
 MSRVTT_full_val/v2t_metrics/R10: 77.46478873239437
 MSRVTT_full_val/v2t_metrics/R50: 95.37223340040241
 MSRVTT_full_val/v2t_metrics/MedR: 3.0
 MSRVTT_full_val/v2t_metrics/MeanR: 10.980885311871228
 MSRVTT_full_val/v2t_metrics/geometric_mean_R1-R5-R10: 50.92355634754953
 MSRVTT_full_test/t2v_metrics/R1: 7.759197324414716
 MSRVTT_full_test/t2v_metrics/R5: 27.4247491638796
 MSRVTT_full_test/t2v_metrics/R10: 40.43478260869565
 MSRVTT_full_test/t2v_metrics/R50: 73.04347826086956
 MSRVTT_full_test/t2v_metrics/MedR: 16.0
 MSRVTT_full_test/t2v_metrics/MeanR: 67.92391304347827
 MSRVTT_full_test/t2v_metrics/geometric_mean_R1-R5-R10: 20.491394969780856
 MSRVTT_full_test/v2t_metrics/R1: 9.364548494983278
 MSRVTT_full_test/v2t_metrics/R5: 30.60200668896321
 MSRVTT_full_test/v2t_metrics/R10: 45.35117056856188
 MSRVTT_full_test/v2t_metrics/R50: 77.19063545150502
 MSRVTT_full_test/v2t_metrics/MedR: 13.0
 MSRVTT_full_test/v2t_metrics/MeanR: 56.05953177257525
 MSRVTT_full_test/v2t_metrics/geometric_mean_R1-R5-R10: 23.51121556189481
 mnt_best       : 21.015616623152336
 not_improved_count: 9
Train Epoch: 41 [1/250 128/32000 (0%)] Loss: 1.96431 (semantic_loss: 0.01399, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=30.29057 
Train Epoch: 41 [12/250 1536/32000 (5%)] Loss: 1.96333 (semantic_loss: 0.01300, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.33630 
Train Epoch: 41 [23/250 2944/32000 (9%)] Loss: 1.96354 (semantic_loss: 0.01419, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=1.95467 
Train Epoch: 41 [34/250 4352/32000 (14%)] Loss: 1.96395 (semantic_loss: 0.01362, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.33752 
Train Epoch: 41 [45/250 5760/32000 (18%)] Loss: 1.96349 (semantic_loss: 0.01316, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.40557 
Train Epoch: 41 [56/250 7168/32000 (22%)] Loss: 1.96448 (semantic_loss: 0.01416, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.35734 
Train Epoch: 41 [67/250 8576/32000 (27%)] Loss: 1.96414 (semantic_loss: 0.01381, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.33523 
Train Epoch: 41 [78/250 9984/32000 (31%)] Loss: 1.96543 (semantic_loss: 0.01608, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.33180 
Train Epoch: 41 [89/250 11392/32000 (36%)] Loss: 1.96420 (semantic_loss: 0.01485, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.33938 
Train Epoch: 41 [100/250 12800/32000 (40%)] Loss: 1.96203 (semantic_loss: 0.01268, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.33834 
Train Epoch: 41 [111/250 14208/32000 (44%)] Loss: 1.96353 (semantic_loss: 0.01417, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.36083 
Train Epoch: 41 [122/250 15616/32000 (49%)] Loss: 1.96432 (semantic_loss: 0.01398, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.33309 
Train Epoch: 41 [133/250 17024/32000 (53%)] Loss: 1.96508 (semantic_loss: 0.01475, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.33733 
Train Epoch: 41 [144/250 18432/32000 (58%)] Loss: 1.96375 (semantic_loss: 0.01343, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.66524 
Train Epoch: 41 [155/250 19840/32000 (62%)] Loss: 1.96269 (semantic_loss: 0.01334, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.33961 
Train Epoch: 41 [166/250 21248/32000 (66%)] Loss: 1.96798 (semantic_loss: 0.01765, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.35758 
Train Epoch: 41 [177/250 22656/32000 (71%)] Loss: 1.96411 (semantic_loss: 0.01476, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.33331 
Train Epoch: 41 [188/250 24064/32000 (75%)] Loss: 1.96518 (semantic_loss: 0.01485, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.34776 
Train Epoch: 41 [199/250 25472/32000 (80%)] Loss: 1.96325 (semantic_loss: 0.01389, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.32932 
Train Epoch: 41 [210/250 26880/32000 (84%)] Loss: 1.96541 (semantic_loss: 0.01509, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=2.81053 
Train Epoch: 41 [221/250 28288/32000 (88%)] Loss: 1.96302 (semantic_loss: 0.01367, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.34732 
Train Epoch: 41 [232/250 29696/32000 (93%)] Loss: 1.96410 (semantic_loss: 0.01377, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.34000 
Train Epoch: 41 [243/250 31104/32000 (97%)] Loss: 1.96448 (semantic_loss: 0.01513, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.36660 
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/DCMH_MSRVTT_full/checkpoint-epoch41.pth ...
Done in 3.859s
removing stale ckpt [epoch 40] [took 0.00s]
 epoch          : 41
 loss           : 1.964223892211914
 learning_rate  : 6.425607828255156e-06
 n_samples      : 1312000
 n_steps        : 10250
 MSRVTT_full_val/t2v_metrics/R1: 24.547283702213278
 MSRVTT_full_val/t2v_metrics/R5: 59.758551307847085
 MSRVTT_full_val/t2v_metrics/R10: 74.04426559356136
 MSRVTT_full_val/t2v_metrics/R50: 94.36619718309859
 MSRVTT_full_val/t2v_metrics/MedR: 3.0
 MSRVTT_full_val/t2v_metrics/MeanR: 12.986921529175051
 MSRVTT_full_val/t2v_metrics/geometric_mean_R1-R5-R10: 47.71244190474238
 MSRVTT_full_val/v2t_metrics/R1: 27.56539235412475
 MSRVTT_full_val/v2t_metrics/R5: 64.38631790744466
 MSRVTT_full_val/v2t_metrics/R10: 77.46478873239437
 MSRVTT_full_val/v2t_metrics/R50: 94.76861167002012
 MSRVTT_full_val/v2t_metrics/MedR: 3.0
 MSRVTT_full_val/v2t_metrics/MeanR: 11.050301810865191
 MSRVTT_full_val/v2t_metrics/geometric_mean_R1-R5-R10: 51.61239784085522
 MSRVTT_full_test/t2v_metrics/R1: 7.190635451505017
 MSRVTT_full_test/t2v_metrics/R5: 26.45484949832776
 MSRVTT_full_test/t2v_metrics/R10: 39.364548494983275
 MSRVTT_full_test/t2v_metrics/R50: 72.44147157190635
 MSRVTT_full_test/t2v_metrics/MedR: 16.5
 MSRVTT_full_test/t2v_metrics/MeanR: 70.12709030100335
 MSRVTT_full_test/t2v_metrics/geometric_mean_R1-R5-R10: 19.564073260367643
 MSRVTT_full_test/v2t_metrics/R1: 8.896321070234114
 MSRVTT_full_test/v2t_metrics/R5: 29.39799331103679
 MSRVTT_full_test/v2t_metrics/R10: 44.94983277591973
 MSRVTT_full_test/v2t_metrics/R50: 77.05685618729098
 MSRVTT_full_test/v2t_metrics/MedR: 13.0
 MSRVTT_full_test/v2t_metrics/MeanR: 57.78394648829431
 MSRVTT_full_test/v2t_metrics/geometric_mean_R1-R5-R10: 22.737990034992617
 mnt_best       : 21.015616623152336
 not_improved_count: 10
Train Epoch: 42 [1/250 128/32000 (0%)] Loss: 1.96480 (semantic_loss: 0.01448, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=24.59872 
Train Epoch: 42 [12/250 1536/32000 (5%)] Loss: 1.96448 (semantic_loss: 0.01416, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.34091 
Train Epoch: 42 [23/250 2944/32000 (9%)] Loss: 1.96350 (semantic_loss: 0.01415, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.33488 
Train Epoch: 42 [34/250 4352/32000 (14%)] Loss: 1.96524 (semantic_loss: 0.01491, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.33211 
Train Epoch: 42 [45/250 5760/32000 (18%)] Loss: 1.96475 (semantic_loss: 0.01442, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.34370 
Train Epoch: 42 [56/250 7168/32000 (22%)] Loss: 1.96326 (semantic_loss: 0.01391, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.35147 
Train Epoch: 42 [67/250 8576/32000 (27%)] Loss: 1.96548 (semantic_loss: 0.01515, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.68788 
Train Epoch: 42 [78/250 9984/32000 (31%)] Loss: 1.96429 (semantic_loss: 0.01396, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.32874 
Train Epoch: 42 [89/250 11392/32000 (36%)] Loss: 1.96344 (semantic_loss: 0.01409, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.34578 
Train Epoch: 42 [100/250 12800/32000 (40%)] Loss: 1.96427 (semantic_loss: 0.01492, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.33720 
Train Epoch: 42 [111/250 14208/32000 (44%)] Loss: 1.96425 (semantic_loss: 0.01392, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.45789 
Train Epoch: 42 [122/250 15616/32000 (49%)] Loss: 1.96401 (semantic_loss: 0.01368, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.35572 
Train Epoch: 42 [133/250 17024/32000 (53%)] Loss: 1.96501 (semantic_loss: 0.01468, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.33254 
Train Epoch: 42 [144/250 18432/32000 (58%)] Loss: 1.96395 (semantic_loss: 0.01362, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.33360 
Train Epoch: 42 [155/250 19840/32000 (62%)] Loss: 1.96429 (semantic_loss: 0.01494, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.35163 
Train Epoch: 42 [166/250 21248/32000 (66%)] Loss: 1.96274 (semantic_loss: 0.01339, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.33576 
Train Epoch: 42 [177/250 22656/32000 (71%)] Loss: 1.96347 (semantic_loss: 0.01315, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.33650 
Train Epoch: 42 [188/250 24064/32000 (75%)] Loss: 1.96429 (semantic_loss: 0.01397, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.32833 
Train Epoch: 42 [199/250 25472/32000 (80%)] Loss: 1.96495 (semantic_loss: 0.01463, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.32844 
Train Epoch: 42 [210/250 26880/32000 (84%)] Loss: 1.96566 (semantic_loss: 0.01534, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=1.69682 
Train Epoch: 42 [221/250 28288/32000 (88%)] Loss: 1.96455 (semantic_loss: 0.01422, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.34155 
Train Epoch: 42 [232/250 29696/32000 (93%)] Loss: 1.96429 (semantic_loss: 0.01397, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.33065 
Train Epoch: 42 [243/250 31104/32000 (97%)] Loss: 1.96301 (semantic_loss: 0.01366, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.33476 
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/DCMH_MSRVTT_full/checkpoint-epoch42.pth ...
Done in 3.839s
removing stale ckpt [epoch 41] [took 0.00s]
 epoch          : 42
 loss           : 1.9642555408477784
 learning_rate  : 6.104327436842398e-06
 n_samples      : 1344000
 n_steps        : 10500
 MSRVTT_full_val/t2v_metrics/R1: 27.16297786720322
 MSRVTT_full_val/t2v_metrics/R5: 60.96579476861167
 MSRVTT_full_val/t2v_metrics/R10: 75.0503018108652
 MSRVTT_full_val/t2v_metrics/R50: 94.56740442655935
 MSRVTT_full_val/t2v_metrics/MedR: 3.0
 MSRVTT_full_val/t2v_metrics/MeanR: 12.427565392354126
 MSRVTT_full_val/t2v_metrics/geometric_mean_R1-R5-R10: 49.90438265984398
 MSRVTT_full_val/v2t_metrics/R1: 29.37625754527163
 MSRVTT_full_val/v2t_metrics/R5: 65.59356136820925
 MSRVTT_full_val/v2t_metrics/R10: 78.26961770623743
 MSRVTT_full_val/v2t_metrics/R50: 95.37223340040241
 MSRVTT_full_val/v2t_metrics/MedR: 3.0
 MSRVTT_full_val/v2t_metrics/MeanR: 10.650905432595573
 MSRVTT_full_val/v2t_metrics/geometric_mean_R1-R5-R10: 53.22924386991808
 MSRVTT_full_test/t2v_metrics/R1: 8.02675585284281
 MSRVTT_full_test/t2v_metrics/R5: 27.157190635451506
 MSRVTT_full_test/t2v_metrics/R10: 41.137123745819395
 MSRVTT_full_test/t2v_metrics/R50: 73.31103678929766
 MSRVTT_full_test/t2v_metrics/MedR: 15.75
 MSRVTT_full_test/t2v_metrics/MeanR: 67.54280936454849
 MSRVTT_full_test/t2v_metrics/geometric_mean_R1-R5-R10: 20.77556957836334
 MSRVTT_full_test/v2t_metrics/R1: 9.264214046822742
 MSRVTT_full_test/v2t_metrics/R5: 30.702341137123746
 MSRVTT_full_test/v2t_metrics/R10: 46.187290969899664
 MSRVTT_full_test/v2t_metrics/R50: 77.9933110367893
 MSRVTT_full_test/v2t_metrics/MedR: 12.5
 MSRVTT_full_test/v2t_metrics/MeanR: 55.32759197324415
 MSRVTT_full_test/v2t_metrics/geometric_mean_R1-R5-R10: 23.59577183253943
 mnt_best       : 21.015616623152336
 not_improved_count: 11
Train Epoch: 43 [1/250 128/32000 (0%)] Loss: 1.96375 (semantic_loss: 0.01440, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=32.29876 
Train Epoch: 43 [12/250 1536/32000 (5%)] Loss: 1.96353 (semantic_loss: 0.01418, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.33256 
Train Epoch: 43 [23/250 2944/32000 (9%)] Loss: 1.96428 (semantic_loss: 0.01396, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.33104 
Train Epoch: 43 [34/250 4352/32000 (14%)] Loss: 1.96228 (semantic_loss: 0.01293, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.34813 
Train Epoch: 43 [45/250 5760/32000 (18%)] Loss: 1.96512 (semantic_loss: 0.01479, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.33343 
Train Epoch: 43 [56/250 7168/32000 (22%)] Loss: 1.96471 (semantic_loss: 0.01536, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.34618 
Train Epoch: 43 [67/250 8576/32000 (27%)] Loss: 1.96353 (semantic_loss: 0.01321, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=4.07900 
Train Epoch: 43 [78/250 9984/32000 (31%)] Loss: 1.96310 (semantic_loss: 0.01375, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.34888 
Train Epoch: 43 [89/250 11392/32000 (36%)] Loss: 1.96365 (semantic_loss: 0.01430, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.33858 
Train Epoch: 43 [100/250 12800/32000 (40%)] Loss: 1.96511 (semantic_loss: 0.01478, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.33165 
Train Epoch: 43 [111/250 14208/32000 (44%)] Loss: 1.96149 (semantic_loss: 0.01214, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.32889 
Train Epoch: 43 [122/250 15616/32000 (49%)] Loss: 1.96451 (semantic_loss: 0.01515, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.33522 
Train Epoch: 43 [133/250 17024/32000 (53%)] Loss: 1.96400 (semantic_loss: 0.01367, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.33678 
Train Epoch: 43 [144/250 18432/32000 (58%)] Loss: 1.96363 (semantic_loss: 0.01427, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=1.74651 
Train Epoch: 43 [155/250 19840/32000 (62%)] Loss: 1.96484 (semantic_loss: 0.01452, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.34070 
Train Epoch: 43 [166/250 21248/32000 (66%)] Loss: 1.96314 (semantic_loss: 0.01281, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.35243 
Train Epoch: 43 [177/250 22656/32000 (71%)] Loss: 1.96422 (semantic_loss: 0.01389, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.33776 
Train Epoch: 43 [188/250 24064/32000 (75%)] Loss: 1.96452 (semantic_loss: 0.01419, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.33255 
Train Epoch: 43 [199/250 25472/32000 (80%)] Loss: 1.96367 (semantic_loss: 0.01334, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.33601 
Train Epoch: 43 [210/250 26880/32000 (84%)] Loss: 1.96367 (semantic_loss: 0.01432, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.33124 
Train Epoch: 43 [221/250 28288/32000 (88%)] Loss: 1.96317 (semantic_loss: 0.01284, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.35211 
Train Epoch: 43 [232/250 29696/32000 (93%)] Loss: 1.96386 (semantic_loss: 0.01353, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.34128 
Train Epoch: 43 [243/250 31104/32000 (97%)] Loss: 1.96345 (semantic_loss: 0.01312, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.33198 
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/DCMH_MSRVTT_full/checkpoint-epoch43.pth ...
Done in 3.765s
removing stale ckpt [epoch 42] [took 0.00s]
 epoch          : 43
 loss           : 1.9639739027023315
 learning_rate  : 5.799111065000278e-06
 n_samples      : 1376000
 n_steps        : 10750
 MSRVTT_full_val/t2v_metrics/R1: 26.961770623742456
 MSRVTT_full_val/t2v_metrics/R5: 60.36217303822938
 MSRVTT_full_val/t2v_metrics/R10: 75.65392354124748
 MSRVTT_full_val/t2v_metrics/R50: 94.96981891348088
 MSRVTT_full_val/t2v_metrics/MedR: 4.0
 MSRVTT_full_val/t2v_metrics/MeanR: 12.779678068410464
 MSRVTT_full_val/t2v_metrics/geometric_mean_R1-R5-R10: 49.74868175618699
 MSRVTT_full_val/v2t_metrics/R1: 28.772635814889338
 MSRVTT_full_val/v2t_metrics/R5: 64.38631790744466
 MSRVTT_full_val/v2t_metrics/R10: 78.06841046277665
 MSRVTT_full_val/v2t_metrics/R50: 95.57344064386318
 MSRVTT_full_val/v2t_metrics/MedR: 3.0
 MSRVTT_full_val/v2t_metrics/MeanR: 10.903420523138832
 MSRVTT_full_val/v2t_metrics/geometric_mean_R1-R5-R10: 52.4907597030433
 MSRVTT_full_test/t2v_metrics/R1: 8.193979933110368
 MSRVTT_full_test/t2v_metrics/R5: 27.023411371237458
 MSRVTT_full_test/t2v_metrics/R10: 40.20066889632107
 MSRVTT_full_test/t2v_metrics/R50: 72.876254180602
 MSRVTT_full_test/t2v_metrics/MedR: 16.0
 MSRVTT_full_test/t2v_metrics/MeanR: 69.31270903010034
 MSRVTT_full_test/t2v_metrics/geometric_mean_R1-R5-R10: 20.724757103780743
 MSRVTT_full_test/v2t_metrics/R1: 9.297658862876254
 MSRVTT_full_test/v2t_metrics/R5: 30.60200668896321
 MSRVTT_full_test/v2t_metrics/R10: 45.4180602006689
 MSRVTT_full_test/v2t_metrics/R50: 78.26086956521739
 MSRVTT_full_test/v2t_metrics/MedR: 13.0
 MSRVTT_full_test/v2t_metrics/MeanR: 55.38344481605351
 MSRVTT_full_test/v2t_metrics/geometric_mean_R1-R5-R10: 23.466628513083027
 mnt_best       : 21.015616623152336
 not_improved_count: 12
Train Epoch: 44 [1/250 128/32000 (0%)] Loss: 1.96305 (semantic_loss: 0.01370, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=29.22399 
Train Epoch: 44 [12/250 1536/32000 (5%)] Loss: 1.96362 (semantic_loss: 0.01427, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.33668 
Train Epoch: 44 [23/250 2944/32000 (9%)] Loss: 1.96337 (semantic_loss: 0.01304, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.95967 
Train Epoch: 44 [34/250 4352/32000 (14%)] Loss: 1.96394 (semantic_loss: 0.01459, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.33622 
Train Epoch: 44 [45/250 5760/32000 (18%)] Loss: 1.96381 (semantic_loss: 0.01348, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.34149 
Train Epoch: 44 [56/250 7168/32000 (22%)] Loss: 1.96451 (semantic_loss: 0.01419, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.33543 
Train Epoch: 44 [67/250 8576/32000 (27%)] Loss: 1.96287 (semantic_loss: 0.01352, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.35400 
Train Epoch: 44 [78/250 9984/32000 (31%)] Loss: 1.96604 (semantic_loss: 0.01571, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=1.52437 
Train Epoch: 44 [89/250 11392/32000 (36%)] Loss: 1.96421 (semantic_loss: 0.01486, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.33225 
Train Epoch: 44 [100/250 12800/32000 (40%)] Loss: 1.96548 (semantic_loss: 0.01516, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.62252 
Train Epoch: 44 [111/250 14208/32000 (44%)] Loss: 1.96400 (semantic_loss: 0.01465, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.33438 
Train Epoch: 44 [122/250 15616/32000 (49%)] Loss: 1.96354 (semantic_loss: 0.01418, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.33845 
Train Epoch: 44 [133/250 17024/32000 (53%)] Loss: 1.96295 (semantic_loss: 0.01262, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.32558 
Train Epoch: 44 [144/250 18432/32000 (58%)] Loss: 1.96479 (semantic_loss: 0.01446, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=1.77168 
Train Epoch: 44 [155/250 19840/32000 (62%)] Loss: 1.96371 (semantic_loss: 0.01436, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.33943 
Train Epoch: 44 [166/250 21248/32000 (66%)] Loss: 1.96367 (semantic_loss: 0.01334, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.33673 
Train Epoch: 44 [177/250 22656/32000 (71%)] Loss: 1.96413 (semantic_loss: 0.01478, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.33873 
Train Epoch: 44 [188/250 24064/32000 (75%)] Loss: 1.96320 (semantic_loss: 0.01483, quant_loss: 1.94824, bit_balance_loss: 0.00013) batch_time=0.34517 
Train Epoch: 44 [199/250 25472/32000 (80%)] Loss: 1.96288 (semantic_loss: 0.01255, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=1.42854 
Train Epoch: 44 [210/250 26880/32000 (84%)] Loss: 1.96335 (semantic_loss: 0.01302, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.34139 
Train Epoch: 44 [221/250 28288/32000 (88%)] Loss: 1.96341 (semantic_loss: 0.01309, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.34708 
Train Epoch: 44 [232/250 29696/32000 (93%)] Loss: 1.96410 (semantic_loss: 0.01377, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.33073 
Train Epoch: 44 [243/250 31104/32000 (97%)] Loss: 1.96404 (semantic_loss: 0.01371, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.33242 
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/DCMH_MSRVTT_full/checkpoint-epoch44.pth ...
Done in 3.942s
Updating 'best' checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/DCMH_MSRVTT_full/checkpoint-epoch44.pth ...
Done in 7.921s
removing stale ckpt [epoch 43] [took 0.00s]
 epoch          : 44
 loss           : 1.9638419647216796
 learning_rate  : 5.5091555117502635e-06
 n_samples      : 1408000
 n_steps        : 11000
 MSRVTT_full_val/t2v_metrics/R1: 26.156941649899398
 MSRVTT_full_val/t2v_metrics/R5: 61.77062374245473
 MSRVTT_full_val/t2v_metrics/R10: 76.65995975855131
 MSRVTT_full_val/t2v_metrics/R50: 95.17102615694165
 MSRVTT_full_val/t2v_metrics/MedR: 3.0
 MSRVTT_full_val/t2v_metrics/MeanR: 12.242454728370221
 MSRVTT_full_val/t2v_metrics/geometric_mean_R1-R5-R10: 49.84778278146773
 MSRVTT_full_val/v2t_metrics/R1: 27.96780684104628
 MSRVTT_full_val/v2t_metrics/R5: 65.19114688128772
 MSRVTT_full_val/v2t_metrics/R10: 79.27565392354124
 MSRVTT_full_val/v2t_metrics/R50: 95.37223340040241
 MSRVTT_full_val/v2t_metrics/MedR: 3.0
 MSRVTT_full_val/v2t_metrics/MeanR: 10.600603621730382
 MSRVTT_full_val/v2t_metrics/geometric_mean_R1-R5-R10: 52.48021698754256
 MSRVTT_full_test/t2v_metrics/R1: 8.26086956521739
 MSRVTT_full_test/t2v_metrics/R5: 27.391304347826086
 MSRVTT_full_test/t2v_metrics/R10: 41.73913043478261
 MSRVTT_full_test/t2v_metrics/R50: 74.41471571906355
 MSRVTT_full_test/t2v_metrics/MedR: 15.5
 MSRVTT_full_test/t2v_metrics/MeanR: 65.79966555183947
 MSRVTT_full_test/t2v_metrics/geometric_mean_R1-R5-R10: 21.13784091924494
 MSRVTT_full_test/v2t_metrics/R1: 10.167224080267559
 MSRVTT_full_test/v2t_metrics/R5: 30.401337792642142
 MSRVTT_full_test/v2t_metrics/R10: 46.95652173913044
 MSRVTT_full_test/v2t_metrics/R50: 78.19397993311037
 MSRVTT_full_test/v2t_metrics/MedR: 12.0
 MSRVTT_full_test/v2t_metrics/MeanR: 55.449498327759194
 MSRVTT_full_test/v2t_metrics/geometric_mean_R1-R5-R10: 24.392913171629417
 mnt_best       : 21.13784091924494
 not_improved_count: 0
Train Epoch: 45 [1/250 128/32000 (0%)] Loss: 1.96469 (semantic_loss: 0.01436, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=28.15771 
Train Epoch: 45 [12/250 1536/32000 (5%)] Loss: 1.96228 (semantic_loss: 0.01293, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.34239 
Train Epoch: 45 [23/250 2944/32000 (9%)] Loss: 1.96469 (semantic_loss: 0.01534, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.35743 
Train Epoch: 45 [34/250 4352/32000 (14%)] Loss: 1.96504 (semantic_loss: 0.01472, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.84723 
Train Epoch: 45 [45/250 5760/32000 (18%)] Loss: 1.96785 (semantic_loss: 0.01753, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.35035 
Train Epoch: 45 [56/250 7168/32000 (22%)] Loss: 1.96475 (semantic_loss: 0.01540, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.33836 
Train Epoch: 45 [67/250 8576/32000 (27%)] Loss: 1.96407 (semantic_loss: 0.01374, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.57884 
Train Epoch: 45 [78/250 9984/32000 (31%)] Loss: 1.96514 (semantic_loss: 0.01482, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.33778 
Train Epoch: 45 [89/250 11392/32000 (36%)] Loss: 1.96373 (semantic_loss: 0.01340, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.33182 
Train Epoch: 45 [100/250 12800/32000 (40%)] Loss: 1.96371 (semantic_loss: 0.01339, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.32916 
Train Epoch: 45 [111/250 14208/32000 (44%)] Loss: 1.96322 (semantic_loss: 0.01290, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.32980 
Train Epoch: 45 [122/250 15616/32000 (49%)] Loss: 1.96497 (semantic_loss: 0.01464, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.33851 
Train Epoch: 45 [133/250 17024/32000 (53%)] Loss: 1.96346 (semantic_loss: 0.01411, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.55552 
Train Epoch: 45 [144/250 18432/32000 (58%)] Loss: 1.96114 (semantic_loss: 0.01277, quant_loss: 1.94824, bit_balance_loss: 0.00013) batch_time=2.27399 
Train Epoch: 45 [155/250 19840/32000 (62%)] Loss: 1.96323 (semantic_loss: 0.01388, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.32915 
Train Epoch: 45 [166/250 21248/32000 (66%)] Loss: 1.96231 (semantic_loss: 0.01296, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.33921 
Train Epoch: 45 [177/250 22656/32000 (71%)] Loss: 1.96530 (semantic_loss: 0.01498, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.34815 
Train Epoch: 45 [188/250 24064/32000 (75%)] Loss: 1.96510 (semantic_loss: 0.01477, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.33828 
Train Epoch: 45 [199/250 25472/32000 (80%)] Loss: 1.96435 (semantic_loss: 0.01402, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.33786 
Train Epoch: 45 [210/250 26880/32000 (84%)] Loss: 1.96469 (semantic_loss: 0.01437, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.33541 
Train Epoch: 45 [221/250 28288/32000 (88%)] Loss: 1.96440 (semantic_loss: 0.01505, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.32747 
Train Epoch: 45 [232/250 29696/32000 (93%)] Loss: 1.96322 (semantic_loss: 0.01386, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.33532 
Train Epoch: 45 [243/250 31104/32000 (97%)] Loss: 1.96336 (semantic_loss: 0.01401, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.33824 
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/DCMH_MSRVTT_full/checkpoint-epoch45.pth ...
Done in 13.726s
Updating 'best' checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/DCMH_MSRVTT_full/checkpoint-epoch45.pth ...
Done in 17.552s
removing stale ckpt [epoch 44] [took 0.00s]
 epoch          : 45
 loss           : 1.9638596363067626
 learning_rate  : 5.23369773616275e-06
 n_samples      : 1440000
 n_steps        : 11250
 MSRVTT_full_val/t2v_metrics/R1: 27.364185110663986
 MSRVTT_full_val/t2v_metrics/R5: 61.56941649899397
 MSRVTT_full_val/t2v_metrics/R10: 74.44668008048289
 MSRVTT_full_val/t2v_metrics/R50: 94.36619718309859
 MSRVTT_full_val/t2v_metrics/MedR: 3.0
 MSRVTT_full_val/t2v_metrics/MeanR: 12.751509054325956
 MSRVTT_full_val/t2v_metrics/geometric_mean_R1-R5-R10: 50.05694000899694
 MSRVTT_full_val/v2t_metrics/R1: 27.364185110663986
 MSRVTT_full_val/v2t_metrics/R5: 65.99597585513078
 MSRVTT_full_val/v2t_metrics/R10: 78.87323943661971
 MSRVTT_full_val/v2t_metrics/R50: 95.57344064386318
 MSRVTT_full_val/v2t_metrics/MedR: 3.0
 MSRVTT_full_val/v2t_metrics/MeanR: 10.982897384305835
 MSRVTT_full_val/v2t_metrics/geometric_mean_R1-R5-R10: 52.22477179913358
 MSRVTT_full_test/t2v_metrics/R1: 8.461538461538462
 MSRVTT_full_test/t2v_metrics/R5: 28.160535117056856
 MSRVTT_full_test/t2v_metrics/R10: 41.50501672240803
 MSRVTT_full_test/t2v_metrics/R50: 73.47826086956522
 MSRVTT_full_test/t2v_metrics/MedR: 15.75
 MSRVTT_full_test/t2v_metrics/MeanR: 67.90133779264214
 MSRVTT_full_test/t2v_metrics/geometric_mean_R1-R5-R10: 21.464969533709365
 MSRVTT_full_test/v2t_metrics/R1: 9.565217391304348
 MSRVTT_full_test/v2t_metrics/R5: 31.304347826086957
 MSRVTT_full_test/v2t_metrics/R10: 46.62207357859532
 MSRVTT_full_test/v2t_metrics/R50: 78.12709030100335
 MSRVTT_full_test/v2t_metrics/MedR: 12.0
 MSRVTT_full_test/v2t_metrics/MeanR: 55.299498327759196
 MSRVTT_full_test/v2t_metrics/geometric_mean_R1-R5-R10: 24.07855184109272
 mnt_best       : 21.464969533709365
 not_improved_count: 0
Train Epoch: 46 [1/250 128/32000 (0%)] Loss: 1.96346 (semantic_loss: 0.01411, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=27.48884 
Train Epoch: 46 [12/250 1536/32000 (5%)] Loss: 1.96508 (semantic_loss: 0.01475, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.34156 
Train Epoch: 46 [23/250 2944/32000 (9%)] Loss: 1.96339 (semantic_loss: 0.01306, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.33740 
Train Epoch: 46 [34/250 4352/32000 (14%)] Loss: 1.96345 (semantic_loss: 0.01312, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.33828 
Train Epoch: 46 [45/250 5760/32000 (18%)] Loss: 1.96388 (semantic_loss: 0.01355, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=1.05825 
Train Epoch: 46 [56/250 7168/32000 (22%)] Loss: 1.96387 (semantic_loss: 0.01355, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.35320 
Train Epoch: 46 [67/250 8576/32000 (27%)] Loss: 1.96427 (semantic_loss: 0.01395, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.33202 
Train Epoch: 46 [78/250 9984/32000 (31%)] Loss: 1.96341 (semantic_loss: 0.01309, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.33030 
Train Epoch: 46 [89/250 11392/32000 (36%)] Loss: 1.96454 (semantic_loss: 0.01422, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.33682 
Train Epoch: 46 [100/250 12800/32000 (40%)] Loss: 1.96365 (semantic_loss: 0.01333, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.69107 
Train Epoch: 46 [111/250 14208/32000 (44%)] Loss: 1.96391 (semantic_loss: 0.01358, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.34929 
Train Epoch: 46 [122/250 15616/32000 (49%)] Loss: 1.96250 (semantic_loss: 0.01315, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.34512 
Train Epoch: 46 [133/250 17024/32000 (53%)] Loss: 1.96377 (semantic_loss: 0.01344, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.33790 
Train Epoch: 46 [144/250 18432/32000 (58%)] Loss: 1.96389 (semantic_loss: 0.01357, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.35332 
Train Epoch: 46 [155/250 19840/32000 (62%)] Loss: 1.96502 (semantic_loss: 0.01469, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.32931 
Train Epoch: 46 [166/250 21248/32000 (66%)] Loss: 1.96233 (semantic_loss: 0.01299, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.45283 
Train Epoch: 46 [177/250 22656/32000 (71%)] Loss: 1.96516 (semantic_loss: 0.01483, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.33975 
Train Epoch: 46 [188/250 24064/32000 (75%)] Loss: 1.96451 (semantic_loss: 0.01419, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.35462 
Train Epoch: 46 [199/250 25472/32000 (80%)] Loss: 1.96308 (semantic_loss: 0.01275, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.34421 
Train Epoch: 46 [210/250 26880/32000 (84%)] Loss: 1.96537 (semantic_loss: 0.01505, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.33634 
Train Epoch: 46 [221/250 28288/32000 (88%)] Loss: 1.96316 (semantic_loss: 0.01283, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.33214 
Train Epoch: 46 [232/250 29696/32000 (93%)] Loss: 1.96324 (semantic_loss: 0.01292, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.33701 
Train Epoch: 46 [243/250 31104/32000 (97%)] Loss: 1.96323 (semantic_loss: 0.01291, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.34017 
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/DCMH_MSRVTT_full/checkpoint-epoch46.pth ...
Done in 3.892s
removing stale ckpt [epoch 45] [took 0.00s]
 epoch          : 46
 loss           : 1.9637423930168152
 learning_rate  : 4.972012849354612e-06
 n_samples      : 1472000
 n_steps        : 11500
 MSRVTT_full_val/t2v_metrics/R1: 25.955734406438633
 MSRVTT_full_val/t2v_metrics/R5: 61.56941649899397
 MSRVTT_full_val/t2v_metrics/R10: 75.85513078470825
 MSRVTT_full_val/t2v_metrics/R50: 94.36619718309859
 MSRVTT_full_val/t2v_metrics/MedR: 3.0
 MSRVTT_full_val/t2v_metrics/MeanR: 12.928571428571429
 MSRVTT_full_val/t2v_metrics/geometric_mean_R1-R5-R10: 49.49117600434397
 MSRVTT_full_val/v2t_metrics/R1: 26.961770623742456
 MSRVTT_full_val/v2t_metrics/R5: 64.58752515090544
 MSRVTT_full_val/v2t_metrics/R10: 77.2635814889336
 MSRVTT_full_val/v2t_metrics/R50: 94.96981891348088
 MSRVTT_full_val/v2t_metrics/MedR: 3.0
 MSRVTT_full_val/v2t_metrics/MeanR: 11.232394366197184
 MSRVTT_full_val/v2t_metrics/geometric_mean_R1-R5-R10: 51.2417511442394
 MSRVTT_full_test/t2v_metrics/R1: 8.093645484949834
 MSRVTT_full_test/t2v_metrics/R5: 27.725752508361204
 MSRVTT_full_test/t2v_metrics/R10: 40.668896321070235
 MSRVTT_full_test/t2v_metrics/R50: 73.61204013377926
 MSRVTT_full_test/t2v_metrics/MedR: 15.5
 MSRVTT_full_test/t2v_metrics/MeanR: 67.31304347826087
 MSRVTT_full_test/t2v_metrics/geometric_mean_R1-R5-R10: 20.897610749065148
 MSRVTT_full_test/v2t_metrics/R1: 9.832775919732441
 MSRVTT_full_test/v2t_metrics/R5: 31.237458193979933
 MSRVTT_full_test/v2t_metrics/R10: 46.65551839464883
 MSRVTT_full_test/v2t_metrics/R50: 77.82608695652173
 MSRVTT_full_test/v2t_metrics/MedR: 12.0
 MSRVTT_full_test/v2t_metrics/MeanR: 55.73411371237458
 MSRVTT_full_test/v2t_metrics/geometric_mean_R1-R5-R10: 24.289483677741412
 mnt_best       : 21.464969533709365
 not_improved_count: 1
Train Epoch: 47 [1/250 128/32000 (0%)] Loss: 1.96236 (semantic_loss: 0.01301, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=31.82315 
Train Epoch: 47 [12/250 1536/32000 (5%)] Loss: 1.96233 (semantic_loss: 0.01298, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.33785 
Train Epoch: 47 [23/250 2944/32000 (9%)] Loss: 1.96346 (semantic_loss: 0.01313, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.33198 
Train Epoch: 47 [34/250 4352/32000 (14%)] Loss: 1.96423 (semantic_loss: 0.01390, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.33229 
Train Epoch: 47 [45/250 5760/32000 (18%)] Loss: 1.96404 (semantic_loss: 0.01469, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.33132 
Train Epoch: 47 [56/250 7168/32000 (22%)] Loss: 1.96482 (semantic_loss: 0.01449, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.34017 
Train Epoch: 47 [67/250 8576/32000 (27%)] Loss: 1.96376 (semantic_loss: 0.01441, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.34100 
Train Epoch: 47 [78/250 9984/32000 (31%)] Loss: 1.96301 (semantic_loss: 0.01366, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.36302 
Train Epoch: 47 [89/250 11392/32000 (36%)] Loss: 1.96359 (semantic_loss: 0.01424, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.33352 
Train Epoch: 47 [100/250 12800/32000 (40%)] Loss: 1.96366 (semantic_loss: 0.01334, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.33425 
Train Epoch: 47 [111/250 14208/32000 (44%)] Loss: 1.96366 (semantic_loss: 0.01431, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.33696 
Train Epoch: 47 [122/250 15616/32000 (49%)] Loss: 1.96273 (semantic_loss: 0.01338, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.33904 
Train Epoch: 47 [133/250 17024/32000 (53%)] Loss: 1.96398 (semantic_loss: 0.01365, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.33711 
Train Epoch: 47 [144/250 18432/32000 (58%)] Loss: 1.96285 (semantic_loss: 0.01253, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.44266 
Train Epoch: 47 [155/250 19840/32000 (62%)] Loss: 1.96390 (semantic_loss: 0.01358, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.33127 
Train Epoch: 47 [166/250 21248/32000 (66%)] Loss: 1.96536 (semantic_loss: 0.01405, quant_loss: 1.95117, bit_balance_loss: 0.00013) batch_time=0.33153 
Train Epoch: 47 [177/250 22656/32000 (71%)] Loss: 1.96200 (semantic_loss: 0.01167, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.33555 
Train Epoch: 47 [188/250 24064/32000 (75%)] Loss: 1.96196 (semantic_loss: 0.01261, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=1.27439 
Train Epoch: 47 [199/250 25472/32000 (80%)] Loss: 1.96282 (semantic_loss: 0.01249, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.33080 
Train Epoch: 47 [210/250 26880/32000 (84%)] Loss: 1.96376 (semantic_loss: 0.01441, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=3.14219 
Train Epoch: 47 [221/250 28288/32000 (88%)] Loss: 1.96482 (semantic_loss: 0.01450, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.33603 
Train Epoch: 47 [232/250 29696/32000 (93%)] Loss: 1.96494 (semantic_loss: 0.01462, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.36373 
Train Epoch: 47 [243/250 31104/32000 (97%)] Loss: 1.96319 (semantic_loss: 0.01287, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.33347 
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/DCMH_MSRVTT_full/checkpoint-epoch47.pth ...
Done in 3.825s
removing stale ckpt [epoch 46] [took 0.00s]
 epoch          : 47
 loss           : 1.9637260937690735
 learning_rate  : 4.723412206886882e-06
 n_samples      : 1504000
 n_steps        : 11750
 MSRVTT_full_val/t2v_metrics/R1: 27.16297786720322
 MSRVTT_full_val/t2v_metrics/R5: 61.77062374245473
 MSRVTT_full_val/t2v_metrics/R10: 74.84909456740442
 MSRVTT_full_val/t2v_metrics/R50: 94.56740442655935
 MSRVTT_full_val/t2v_metrics/MedR: 3.0
 MSRVTT_full_val/t2v_metrics/MeanR: 12.745472837022133
 MSRVTT_full_val/t2v_metrics/geometric_mean_R1-R5-R10: 50.07819180406074
 MSRVTT_full_val/v2t_metrics/R1: 28.37022132796781
 MSRVTT_full_val/v2t_metrics/R5: 66.80080482897384
 MSRVTT_full_val/v2t_metrics/R10: 78.67203219315896
 MSRVTT_full_val/v2t_metrics/R50: 95.57344064386318
 MSRVTT_full_val/v2t_metrics/MedR: 3.0
 MSRVTT_full_val/v2t_metrics/MeanR: 10.811871227364184
 MSRVTT_full_val/v2t_metrics/geometric_mean_R1-R5-R10: 53.025926135706236
 MSRVTT_full_test/t2v_metrics/R1: 8.127090301003344
 MSRVTT_full_test/t2v_metrics/R5: 27.959866220735787
 MSRVTT_full_test/t2v_metrics/R10: 41.37123745819398
 MSRVTT_full_test/t2v_metrics/R50: 73.9799331103679
 MSRVTT_full_test/t2v_metrics/MedR: 15.0
 MSRVTT_full_test/t2v_metrics/MeanR: 65.70284280936455
 MSRVTT_full_test/t2v_metrics/geometric_mean_R1-R5-R10: 21.105204367207836
 MSRVTT_full_test/v2t_metrics/R1: 9.933110367892976
 MSRVTT_full_test/v2t_metrics/R5: 32.14046822742475
 MSRVTT_full_test/v2t_metrics/R10: 47.05685618729097
 MSRVTT_full_test/v2t_metrics/R50: 78.79598662207358
 MSRVTT_full_test/v2t_metrics/MedR: 12.0
 MSRVTT_full_test/v2t_metrics/MeanR: 54.607859531772576
 MSRVTT_full_test/v2t_metrics/geometric_mean_R1-R5-R10: 24.67478950454966
 mnt_best       : 21.464969533709365
 not_improved_count: 2
Train Epoch: 48 [1/250 128/32000 (0%)] Loss: 1.96382 (semantic_loss: 0.01350, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=26.74367 
Train Epoch: 48 [12/250 1536/32000 (5%)] Loss: 1.96510 (semantic_loss: 0.01477, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.33809 
Train Epoch: 48 [23/250 2944/32000 (9%)] Loss: 1.96414 (semantic_loss: 0.01381, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.33800 
Train Epoch: 48 [34/250 4352/32000 (14%)] Loss: 1.96502 (semantic_loss: 0.01470, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.35396 
Train Epoch: 48 [45/250 5760/32000 (18%)] Loss: 1.96509 (semantic_loss: 0.01476, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.34208 
Train Epoch: 48 [56/250 7168/32000 (22%)] Loss: 1.96320 (semantic_loss: 0.01385, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.34946 
Train Epoch: 48 [67/250 8576/32000 (27%)] Loss: 1.96363 (semantic_loss: 0.01330, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=1.05752 
Train Epoch: 48 [78/250 9984/32000 (31%)] Loss: 1.96466 (semantic_loss: 0.01433, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.32531 
Train Epoch: 48 [89/250 11392/32000 (36%)] Loss: 1.96410 (semantic_loss: 0.01378, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=1.94334 
Train Epoch: 48 [100/250 12800/32000 (40%)] Loss: 1.96415 (semantic_loss: 0.01382, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.45481 
Train Epoch: 48 [111/250 14208/32000 (44%)] Loss: 1.96460 (semantic_loss: 0.01427, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=1.01376 
Train Epoch: 48 [122/250 15616/32000 (49%)] Loss: 1.96377 (semantic_loss: 0.01344, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.34161 
Train Epoch: 48 [133/250 17024/32000 (53%)] Loss: 1.96354 (semantic_loss: 0.01419, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=1.56853 
Train Epoch: 48 [144/250 18432/32000 (58%)] Loss: 1.96283 (semantic_loss: 0.01348, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.33787 
Train Epoch: 48 [155/250 19840/32000 (62%)] Loss: 1.96279 (semantic_loss: 0.01247, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.33131 
Train Epoch: 48 [166/250 21248/32000 (66%)] Loss: 1.96419 (semantic_loss: 0.01387, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.33650 
Train Epoch: 48 [177/250 22656/32000 (71%)] Loss: 1.96456 (semantic_loss: 0.01423, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.33922 
Train Epoch: 48 [188/250 24064/32000 (75%)] Loss: 1.96316 (semantic_loss: 0.01381, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.32711 
Train Epoch: 48 [199/250 25472/32000 (80%)] Loss: 1.96384 (semantic_loss: 0.01351, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.32902 
Train Epoch: 48 [210/250 26880/32000 (84%)] Loss: 1.96403 (semantic_loss: 0.01468, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.33917 
Train Epoch: 48 [221/250 28288/32000 (88%)] Loss: 1.96475 (semantic_loss: 0.01443, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.34936 
Train Epoch: 48 [232/250 29696/32000 (93%)] Loss: 1.96536 (semantic_loss: 0.01405, quant_loss: 1.95117, bit_balance_loss: 0.00013) batch_time=0.33647 
Train Epoch: 48 [243/250 31104/32000 (97%)] Loss: 1.96439 (semantic_loss: 0.01406, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.33651 
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/DCMH_MSRVTT_full/checkpoint-epoch48.pth ...
Done in 3.702s
removing stale ckpt [epoch 47] [took 0.00s]
 epoch          : 48
 loss           : 1.9636575512886048
 learning_rate  : 4.487241596542537e-06
 n_samples      : 1536000
 n_steps        : 12000
 MSRVTT_full_val/t2v_metrics/R1: 27.766599597585515
 MSRVTT_full_val/t2v_metrics/R5: 60.160965794768615
 MSRVTT_full_val/t2v_metrics/R10: 74.44668008048289
 MSRVTT_full_val/t2v_metrics/R50: 93.96378269617706
 MSRVTT_full_val/t2v_metrics/MedR: 3.0
 MSRVTT_full_val/t2v_metrics/MeanR: 12.82394366197183
 MSRVTT_full_val/t2v_metrics/geometric_mean_R1-R5-R10: 49.914601804598995
 MSRVTT_full_val/v2t_metrics/R1: 27.16297786720322
 MSRVTT_full_val/v2t_metrics/R5: 64.58752515090544
 MSRVTT_full_val/v2t_metrics/R10: 77.46478873239437
 MSRVTT_full_val/v2t_metrics/R50: 95.57344064386318
 MSRVTT_full_val/v2t_metrics/MedR: 3.0
 MSRVTT_full_val/v2t_metrics/MeanR: 11.106639839034205
 MSRVTT_full_val/v2t_metrics/geometric_mean_R1-R5-R10: 51.413454822296494
 MSRVTT_full_test/t2v_metrics/R1: 7.993311036789297
 MSRVTT_full_test/t2v_metrics/R5: 27.65886287625418
 MSRVTT_full_test/t2v_metrics/R10: 41.27090301003344
 MSRVTT_full_test/t2v_metrics/R50: 73.54515050167224
 MSRVTT_full_test/t2v_metrics/MedR: 15.0
 MSRVTT_full_test/t2v_metrics/MeanR: 67.49882943143812
 MSRVTT_full_test/t2v_metrics/geometric_mean_R1-R5-R10: 20.896249018757416
 MSRVTT_full_test/v2t_metrics/R1: 10.066889632107024
 MSRVTT_full_test/v2t_metrics/R5: 32.17391304347826
 MSRVTT_full_test/v2t_metrics/R10: 46.72240802675585
 MSRVTT_full_test/v2t_metrics/R50: 77.65886287625418
 MSRVTT_full_test/v2t_metrics/MedR: 12.25
 MSRVTT_full_test/v2t_metrics/MeanR: 56.134949832775916
 MSRVTT_full_test/v2t_metrics/geometric_mean_R1-R5-R10: 24.734784801840416
 mnt_best       : 21.464969533709365
 not_improved_count: 3
Train Epoch: 49 [1/250 128/32000 (0%)] Loss: 1.96257 (semantic_loss: 0.01323, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=27.38544 
Train Epoch: 49 [12/250 1536/32000 (5%)] Loss: 1.96514 (semantic_loss: 0.01481, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.34290 
Train Epoch: 49 [23/250 2944/32000 (9%)] Loss: 1.96441 (semantic_loss: 0.01408, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.78892 
Train Epoch: 49 [34/250 4352/32000 (14%)] Loss: 1.96339 (semantic_loss: 0.01307, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.33824 
Train Epoch: 49 [45/250 5760/32000 (18%)] Loss: 1.96276 (semantic_loss: 0.01341, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.33565 
Train Epoch: 49 [56/250 7168/32000 (22%)] Loss: 1.96309 (semantic_loss: 0.01374, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.57961 
Train Epoch: 49 [67/250 8576/32000 (27%)] Loss: 1.96478 (semantic_loss: 0.01445, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.34342 
Train Epoch: 49 [78/250 9984/32000 (31%)] Loss: 1.96312 (semantic_loss: 0.01377, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.57135 
Train Epoch: 49 [89/250 11392/32000 (36%)] Loss: 1.96543 (semantic_loss: 0.01510, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=2.13362 
Train Epoch: 49 [100/250 12800/32000 (40%)] Loss: 1.96488 (semantic_loss: 0.01455, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.33533 
Train Epoch: 49 [111/250 14208/32000 (44%)] Loss: 1.96464 (semantic_loss: 0.01431, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.33112 
Train Epoch: 49 [122/250 15616/32000 (49%)] Loss: 1.96531 (semantic_loss: 0.01498, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.33345 
Train Epoch: 49 [133/250 17024/32000 (53%)] Loss: 1.96238 (semantic_loss: 0.01205, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.34109 
Train Epoch: 49 [144/250 18432/32000 (58%)] Loss: 1.96228 (semantic_loss: 0.01293, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.66376 
Train Epoch: 49 [155/250 19840/32000 (62%)] Loss: 1.96313 (semantic_loss: 0.01378, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.34348 
Train Epoch: 49 [166/250 21248/32000 (66%)] Loss: 1.96377 (semantic_loss: 0.01345, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.33090 
Train Epoch: 49 [177/250 22656/32000 (71%)] Loss: 1.96612 (semantic_loss: 0.01482, quant_loss: 1.95117, bit_balance_loss: 0.00013) batch_time=0.33830 
Train Epoch: 49 [188/250 24064/32000 (75%)] Loss: 1.96322 (semantic_loss: 0.01289, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.39991 
Train Epoch: 49 [199/250 25472/32000 (80%)] Loss: 1.96387 (semantic_loss: 0.01452, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.33661 
Train Epoch: 49 [210/250 26880/32000 (84%)] Loss: 1.96251 (semantic_loss: 0.01219, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.33556 
Train Epoch: 49 [221/250 28288/32000 (88%)] Loss: 1.96506 (semantic_loss: 0.01474, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.34307 
Train Epoch: 49 [232/250 29696/32000 (93%)] Loss: 1.96285 (semantic_loss: 0.01351, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.33570 
Train Epoch: 49 [243/250 31104/32000 (97%)] Loss: 1.96315 (semantic_loss: 0.01380, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.34008 
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/DCMH_MSRVTT_full/checkpoint-epoch49.pth ...
Done in 3.777s
removing stale ckpt [epoch 48] [took 0.00s]
 epoch          : 49
 loss           : 1.9636134133338927
 learning_rate  : 4.26287951671541e-06
 n_samples      : 1568000
 n_steps        : 12250
 MSRVTT_full_val/t2v_metrics/R1: 26.559356136820927
 MSRVTT_full_val/t2v_metrics/R5: 61.971830985915496
 MSRVTT_full_val/t2v_metrics/R10: 75.25150905432595
 MSRVTT_full_val/t2v_metrics/R50: 94.76861167002012
 MSRVTT_full_val/t2v_metrics/MedR: 3.0
 MSRVTT_full_val/t2v_metrics/MeanR: 12.811871227364184
 MSRVTT_full_val/t2v_metrics/geometric_mean_R1-R5-R10: 49.84738283445484
 MSRVTT_full_val/v2t_metrics/R1: 28.973843058350102
 MSRVTT_full_val/v2t_metrics/R5: 64.98993963782696
 MSRVTT_full_val/v2t_metrics/R10: 78.06841046277665
 MSRVTT_full_val/v2t_metrics/R50: 95.57344064386318
 MSRVTT_full_val/v2t_metrics/MedR: 3.0
 MSRVTT_full_val/v2t_metrics/MeanR: 10.830985915492958
 MSRVTT_full_val/v2t_metrics/geometric_mean_R1-R5-R10: 52.77673563808539
 MSRVTT_full_test/t2v_metrics/R1: 8.294314381270903
 MSRVTT_full_test/t2v_metrics/R5: 27.82608695652174
 MSRVTT_full_test/t2v_metrics/R10: 41.30434782608695
 MSRVTT_full_test/t2v_metrics/R50: 73.64548494983278
 MSRVTT_full_test/t2v_metrics/MedR: 15.0
 MSRVTT_full_test/t2v_metrics/MeanR: 67.8066889632107
 MSRVTT_full_test/t2v_metrics/geometric_mean_R1-R5-R10: 21.203593349923832
 MSRVTT_full_test/v2t_metrics/R1: 9.632107023411372
 MSRVTT_full_test/v2t_metrics/R5: 30.903010033444815
 MSRVTT_full_test/v2t_metrics/R10: 46.45484949832776
 MSRVTT_full_test/v2t_metrics/R50: 77.72575250836121
 MSRVTT_full_test/v2t_metrics/MedR: 12.0
 MSRVTT_full_test/v2t_metrics/MeanR: 56.440969899665554
 MSRVTT_full_test/v2t_metrics/geometric_mean_R1-R5-R10: 24.002199799194493
 mnt_best       : 21.464969533709365
 not_improved_count: 4
Train Epoch: 50 [1/250 128/32000 (0%)] Loss: 1.96545 (semantic_loss: 0.01513, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=28.82523 
Train Epoch: 50 [12/250 1536/32000 (5%)] Loss: 1.96264 (semantic_loss: 0.01329, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.32851 
Train Epoch: 50 [23/250 2944/32000 (9%)] Loss: 1.96286 (semantic_loss: 0.01351, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.34313 
Train Epoch: 50 [34/250 4352/32000 (14%)] Loss: 1.96294 (semantic_loss: 0.01358, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.34038 
Train Epoch: 50 [45/250 5760/32000 (18%)] Loss: 1.96498 (semantic_loss: 0.01465, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.33122 
Train Epoch: 50 [56/250 7168/32000 (22%)] Loss: 1.96344 (semantic_loss: 0.01311, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.33185 
Train Epoch: 50 [67/250 8576/32000 (27%)] Loss: 1.96310 (semantic_loss: 0.01375, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.32880 
Train Epoch: 50 [78/250 9984/32000 (31%)] Loss: 1.96382 (semantic_loss: 0.01447, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.33137 
Train Epoch: 50 [89/250 11392/32000 (36%)] Loss: 1.96203 (semantic_loss: 0.01268, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.32842 
Train Epoch: 50 [100/250 12800/32000 (40%)] Loss: 1.96293 (semantic_loss: 0.01358, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.33128 
Train Epoch: 50 [111/250 14208/32000 (44%)] Loss: 1.96390 (semantic_loss: 0.01357, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.33430 
Train Epoch: 50 [122/250 15616/32000 (49%)] Loss: 1.96496 (semantic_loss: 0.01464, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.33904 
Train Epoch: 50 [133/250 17024/32000 (53%)] Loss: 1.96344 (semantic_loss: 0.01409, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.33804 
Train Epoch: 50 [144/250 18432/32000 (58%)] Loss: 1.96308 (semantic_loss: 0.01276, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.35150 
Train Epoch: 50 [155/250 19840/32000 (62%)] Loss: 1.96357 (semantic_loss: 0.01325, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.33837 
Train Epoch: 50 [166/250 21248/32000 (66%)] Loss: 1.96426 (semantic_loss: 0.01394, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.33070 
Train Epoch: 50 [177/250 22656/32000 (71%)] Loss: 1.96226 (semantic_loss: 0.01291, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.33203 
Train Epoch: 50 [188/250 24064/32000 (75%)] Loss: 1.96379 (semantic_loss: 0.01347, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.33496 
Train Epoch: 50 [199/250 25472/32000 (80%)] Loss: 1.96435 (semantic_loss: 0.01500, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.33297 
Train Epoch: 50 [210/250 26880/32000 (84%)] Loss: 1.96321 (semantic_loss: 0.01387, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.33675 
Train Epoch: 50 [221/250 28288/32000 (88%)] Loss: 1.96380 (semantic_loss: 0.01348, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.36454 
Train Epoch: 50 [232/250 29696/32000 (93%)] Loss: 1.96345 (semantic_loss: 0.01410, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.76615 
Train Epoch: 50 [243/250 31104/32000 (97%)] Loss: 1.96340 (semantic_loss: 0.01307, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.36161 
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/DCMH_MSRVTT_full/checkpoint-epoch50.pth ...
Done in 3.800s
removing stale ckpt [epoch 49] [took 0.00s]
 epoch          : 50
 loss           : 1.9636910190582275
 learning_rate  : 4.04973554087964e-06
 n_samples      : 1600000
 n_steps        : 12500
 MSRVTT_full_val/t2v_metrics/R1: 25.955734406438633
 MSRVTT_full_val/t2v_metrics/R5: 61.56941649899397
 MSRVTT_full_val/t2v_metrics/R10: 75.85513078470825
 MSRVTT_full_val/t2v_metrics/R50: 93.76257545271629
 MSRVTT_full_val/t2v_metrics/MedR: 3.0
 MSRVTT_full_val/t2v_metrics/MeanR: 13.147887323943662
 MSRVTT_full_val/t2v_metrics/geometric_mean_R1-R5-R10: 49.49117600434397
 MSRVTT_full_val/v2t_metrics/R1: 27.16297786720322
 MSRVTT_full_val/v2t_metrics/R5: 66.19718309859155
 MSRVTT_full_val/v2t_metrics/R10: 79.87927565392354
 MSRVTT_full_val/v2t_metrics/R50: 94.76861167002012
 MSRVTT_full_val/v2t_metrics/MedR: 3.0
 MSRVTT_full_val/v2t_metrics/MeanR: 11.411468812877263
 MSRVTT_full_val/v2t_metrics/geometric_mean_R1-R5-R10: 52.37013205445905
 MSRVTT_full_test/t2v_metrics/R1: 7.65886287625418
 MSRVTT_full_test/t2v_metrics/R5: 27.692307692307693
 MSRVTT_full_test/t2v_metrics/R10: 41.03678929765886
 MSRVTT_full_test/t2v_metrics/R50: 73.37792642140468
 MSRVTT_full_test/t2v_metrics/MedR: 16.0
 MSRVTT_full_test/t2v_metrics/MeanR: 69.60602006688963
 MSRVTT_full_test/t2v_metrics/geometric_mean_R1-R5-R10: 20.569904352916836
 MSRVTT_full_test/v2t_metrics/R1: 9.665551839464882
 MSRVTT_full_test/v2t_metrics/R5: 31.036789297658864
 MSRVTT_full_test/v2t_metrics/R10: 45.65217391304348
 MSRVTT_full_test/v2t_metrics/R50: 77.49163879598662
 MSRVTT_full_test/v2t_metrics/MedR: 12.5
 MSRVTT_full_test/v2t_metrics/MeanR: 57.5010033444816
 MSRVTT_full_test/v2t_metrics/geometric_mean_R1-R5-R10: 23.9251664811822
 mnt_best       : 21.464969533709365
 not_improved_count: 5
Final evaluation ...
Loading checkpoint from: /apdcephfs/share_47076/gimwang/HCQ/exps/DCMH_MSRVTT_full/trained_model.pth ...
Ckpt loaded at epoch 45.
Saved v2t similarity matrix to /apdcephfs/share_47076/gimwang/HCQ/exps/DCMH_MSRVTT_full/MSRVTT-test-sims.npy
MSRVTT_full_test:
 t2v_metrics/R1/final_eval: 8.461538461538462
 t2v_metrics/R5/final_eval: 28.160535117056856
 t2v_metrics/R10/final_eval: 41.50501672240803
 t2v_metrics/R50/final_eval: 73.47826086956522
 t2v_metrics/MedR/final_eval: 15.75
 t2v_metrics/MeanR/final_eval: 67.90133779264214
 t2v_metrics/geometric_mean_R1-R5-R10/final_eval: 21.464969533709365
 v2t_metrics/R1/final_eval: 9.565217391304348
 v2t_metrics/R5/final_eval: 31.304347826086957
 v2t_metrics/R10/final_eval: 46.62207357859532
 v2t_metrics/R50/final_eval: 78.12709030100335
 v2t_metrics/MedR/final_eval: 12.0
 v2t_metrics/MeanR/final_eval: 55.299498327759196
 v2t_metrics/geometric_mean_R1-R5-R10/final_eval: 24.07855184109272
Best epoch for the monitored metric: 45
Script took 03h25m43s
The best performing ckpt can be found at /apdcephfs/share_47076/gimwang/HCQ/exps/DCMH_MSRVTT_full/trained_model.pth
