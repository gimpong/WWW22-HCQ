Experiment directory: /apdcephfs/share_47076/gimwang/HCQ/exps/DCMH_MSRVTT_1kB
Preparing the dataloaders ...
Loading dataset MSRVTT_miech_trainval in ram ...
Finish loading dataset MSRVTT_miech_trainval in ram, taking 423.86139369010925 s.
Loading dataset MSRVTT_miech_test in ram ...
Finish loading dataset MSRVTT_miech_test in ram, taking 74.02873539924622 s.
Loading dataset MSRVTT_miech_test in ram ...
Finish loading dataset MSRVTT_miech_test in ram, taking 63.347338914871216 s.
Training ...
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/DCMH_MSRVTT_1kB/checkpoint-epoch0.pth ...
Done in 2.452s
Updating 'best' checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/DCMH_MSRVTT_1kB/checkpoint-epoch0.pth ...
Done in 4.256s
 epoch          : 0
 loss           : 0
 learning_rate  : 5e-05
 n_samples      : 0
 n_steps        : 0
 MSRVTT_miech_test/t2v_metrics/R1: 0.1
 MSRVTT_miech_test/t2v_metrics/R5: 0.5
 MSRVTT_miech_test/t2v_metrics/R10: 1.2
 MSRVTT_miech_test/t2v_metrics/R50: 4.9
 MSRVTT_miech_test/t2v_metrics/MedR: 510.25
 MSRVTT_miech_test/t2v_metrics/MeanR: 501.134
 MSRVTT_miech_test/t2v_metrics/geometric_mean_R1-R5-R10: 0.3914867641168864
 MSRVTT_miech_test/v2t_metrics/R1: 0.1
 MSRVTT_miech_test/v2t_metrics/R5: 0.5
 MSRVTT_miech_test/v2t_metrics/R10: 1.0
 MSRVTT_miech_test/v2t_metrics/R50: 4.6
 MSRVTT_miech_test/v2t_metrics/MedR: 504.5
 MSRVTT_miech_test/v2t_metrics/MeanR: 500.816
 MSRVTT_miech_test/v2t_metrics/geometric_mean_R1-R5-R10: 0.3684031498640387
 mnt_best       : 0.3914867641168864
 not_improved_count: 0
Train Epoch: 1 [1/250 128/32000 (0%)] Loss: 2.68444 (semantic_loss: 0.73484, quant_loss: 1.94922, bit_balance_loss: 0.00038) batch_time=21.32117 
Train Epoch: 1 [12/250 1536/32000 (5%)] Loss: 2.00520 (semantic_loss: 0.05357, quant_loss: 1.95117, bit_balance_loss: 0.00046) batch_time=0.43014 
Train Epoch: 1 [23/250 2944/32000 (9%)] Loss: 1.99657 (semantic_loss: 0.04589, quant_loss: 1.95020, bit_balance_loss: 0.00048) batch_time=0.32972 
Train Epoch: 1 [34/250 4352/32000 (14%)] Loss: 1.99651 (semantic_loss: 0.04582, quant_loss: 1.95020, bit_balance_loss: 0.00049) batch_time=0.32953 
Train Epoch: 1 [45/250 5760/32000 (18%)] Loss: 1.99653 (semantic_loss: 0.04584, quant_loss: 1.95020, bit_balance_loss: 0.00049) batch_time=0.34498 
Train Epoch: 1 [56/250 7168/32000 (22%)] Loss: 1.99645 (semantic_loss: 0.04576, quant_loss: 1.95020, bit_balance_loss: 0.00049) batch_time=0.35019 
Train Epoch: 1 [67/250 8576/32000 (27%)] Loss: 1.99642 (semantic_loss: 0.04574, quant_loss: 1.95020, bit_balance_loss: 0.00049) batch_time=1.42093 
Train Epoch: 1 [78/250 9984/32000 (31%)] Loss: 1.99642 (semantic_loss: 0.04574, quant_loss: 1.95020, bit_balance_loss: 0.00049) batch_time=0.43618 
Train Epoch: 1 [89/250 11392/32000 (36%)] Loss: 1.99740 (semantic_loss: 0.04574, quant_loss: 1.95117, bit_balance_loss: 0.00049) batch_time=0.33149 
Train Epoch: 1 [100/250 12800/32000 (40%)] Loss: 1.99641 (semantic_loss: 0.04573, quant_loss: 1.95020, bit_balance_loss: 0.00048) batch_time=0.33800 
Train Epoch: 1 [111/250 14208/32000 (44%)] Loss: 1.99738 (semantic_loss: 0.04573, quant_loss: 1.95117, bit_balance_loss: 0.00048) batch_time=0.32124 
Train Epoch: 1 [122/250 15616/32000 (49%)] Loss: 1.99737 (semantic_loss: 0.04572, quant_loss: 1.95117, bit_balance_loss: 0.00048) batch_time=0.34034 
Train Epoch: 1 [133/250 17024/32000 (53%)] Loss: 1.99738 (semantic_loss: 0.04573, quant_loss: 1.95117, bit_balance_loss: 0.00047) batch_time=0.36320 
Train Epoch: 1 [144/250 18432/32000 (58%)] Loss: 1.99737 (semantic_loss: 0.04572, quant_loss: 1.95117, bit_balance_loss: 0.00047) batch_time=0.35492 
Train Epoch: 1 [155/250 19840/32000 (62%)] Loss: 1.99735 (semantic_loss: 0.04571, quant_loss: 1.95117, bit_balance_loss: 0.00047) batch_time=0.34546 
Train Epoch: 1 [166/250 21248/32000 (66%)] Loss: 1.99737 (semantic_loss: 0.04573, quant_loss: 1.95117, bit_balance_loss: 0.00046) batch_time=0.39390 
Train Epoch: 1 [177/250 22656/32000 (71%)] Loss: 1.99735 (semantic_loss: 0.04571, quant_loss: 1.95117, bit_balance_loss: 0.00046) batch_time=0.36777 
Train Epoch: 1 [188/250 24064/32000 (75%)] Loss: 1.99734 (semantic_loss: 0.04572, quant_loss: 1.95117, bit_balance_loss: 0.00046) batch_time=0.37710 
Train Epoch: 1 [199/250 25472/32000 (80%)] Loss: 1.99734 (semantic_loss: 0.04571, quant_loss: 1.95117, bit_balance_loss: 0.00045) batch_time=0.34751 
Train Epoch: 1 [210/250 26880/32000 (84%)] Loss: 1.99731 (semantic_loss: 0.04569, quant_loss: 1.95117, bit_balance_loss: 0.00045) batch_time=0.36994 
Train Epoch: 1 [221/250 28288/32000 (88%)] Loss: 1.99735 (semantic_loss: 0.04573, quant_loss: 1.95117, bit_balance_loss: 0.00045) batch_time=0.32255 
Train Epoch: 1 [232/250 29696/32000 (93%)] Loss: 1.99732 (semantic_loss: 0.04571, quant_loss: 1.95117, bit_balance_loss: 0.00044) batch_time=0.36898 
Train Epoch: 1 [243/250 31104/32000 (97%)] Loss: 1.99733 (semantic_loss: 0.04572, quant_loss: 1.95117, bit_balance_loss: 0.00044) batch_time=0.33653 
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/DCMH_MSRVTT_1kB/checkpoint-epoch1.pth ...
Done in 4.850s
Updating 'best' checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/DCMH_MSRVTT_1kB/checkpoint-epoch1.pth ...
Done in 8.952s
 epoch          : 1
 loss           : 2.0031395673751833
 learning_rate  : 5e-05
 n_samples      : 32000
 n_steps        : 250
 MSRVTT_miech_test/t2v_metrics/R1: 0.1
 MSRVTT_miech_test/t2v_metrics/R5: 0.5
 MSRVTT_miech_test/t2v_metrics/R10: 1.3
 MSRVTT_miech_test/t2v_metrics/R50: 5.0
 MSRVTT_miech_test/t2v_metrics/MedR: 499.0
 MSRVTT_miech_test/t2v_metrics/MeanR: 497.5375
 MSRVTT_miech_test/t2v_metrics/geometric_mean_R1-R5-R10: 0.40207257585890577
 MSRVTT_miech_test/v2t_metrics/R1: 0.0
 MSRVTT_miech_test/v2t_metrics/R5: 0.4
 MSRVTT_miech_test/v2t_metrics/R10: 0.9
 MSRVTT_miech_test/v2t_metrics/R50: 4.8
 MSRVTT_miech_test/v2t_metrics/MedR: 496.75
 MSRVTT_miech_test/v2t_metrics/MeanR: 497.147
 MSRVTT_miech_test/v2t_metrics/geometric_mean_R1-R5-R10: 0.0
 mnt_best       : 0.40207257585890577
 not_improved_count: 0
Train Epoch: 2 [1/250 128/32000 (0%)] Loss: 1.99730 (semantic_loss: 0.04569, quant_loss: 1.95117, bit_balance_loss: 0.00043) batch_time=29.05234 
Train Epoch: 2 [12/250 1536/32000 (5%)] Loss: 1.99728 (semantic_loss: 0.04567, quant_loss: 1.95117, bit_balance_loss: 0.00043) batch_time=8.63816 
Train Epoch: 2 [23/250 2944/32000 (9%)] Loss: 1.99730 (semantic_loss: 0.04570, quant_loss: 1.95117, bit_balance_loss: 0.00043) batch_time=0.35929 
Train Epoch: 2 [34/250 4352/32000 (14%)] Loss: 1.99826 (semantic_loss: 0.04569, quant_loss: 1.95215, bit_balance_loss: 0.00042) batch_time=0.37759 
Train Epoch: 2 [45/250 5760/32000 (18%)] Loss: 1.99727 (semantic_loss: 0.04568, quant_loss: 1.95117, bit_balance_loss: 0.00042) batch_time=0.32532 
Train Epoch: 2 [56/250 7168/32000 (22%)] Loss: 1.99724 (semantic_loss: 0.04565, quant_loss: 1.95117, bit_balance_loss: 0.00041) batch_time=0.32677 
Train Epoch: 2 [67/250 8576/32000 (27%)] Loss: 1.99622 (semantic_loss: 0.04562, quant_loss: 1.95020, bit_balance_loss: 0.00041) batch_time=0.32107 
Train Epoch: 2 [78/250 9984/32000 (31%)] Loss: 1.99715 (semantic_loss: 0.04557, quant_loss: 1.95117, bit_balance_loss: 0.00041) batch_time=0.46456 
Train Epoch: 2 [89/250 11392/32000 (36%)] Loss: 1.99624 (semantic_loss: 0.04564, quant_loss: 1.95020, bit_balance_loss: 0.00040) batch_time=0.41616 
Train Epoch: 2 [100/250 12800/32000 (40%)] Loss: 1.99691 (semantic_loss: 0.04535, quant_loss: 1.95117, bit_balance_loss: 0.00039) batch_time=0.36084 
Train Epoch: 2 [111/250 14208/32000 (44%)] Loss: 1.99569 (semantic_loss: 0.04510, quant_loss: 1.95020, bit_balance_loss: 0.00039) batch_time=0.32639 
Train Epoch: 2 [122/250 15616/32000 (49%)] Loss: 1.99643 (semantic_loss: 0.04487, quant_loss: 1.95117, bit_balance_loss: 0.00038) batch_time=0.44972 
Train Epoch: 2 [133/250 17024/32000 (53%)] Loss: 1.99618 (semantic_loss: 0.04463, quant_loss: 1.95117, bit_balance_loss: 0.00037) batch_time=0.32707 
Train Epoch: 2 [144/250 18432/32000 (58%)] Loss: 1.99596 (semantic_loss: 0.04442, quant_loss: 1.95117, bit_balance_loss: 0.00037) batch_time=0.42063 
Train Epoch: 2 [155/250 19840/32000 (62%)] Loss: 1.99586 (semantic_loss: 0.04433, quant_loss: 1.95117, bit_balance_loss: 0.00036) batch_time=0.36242 
Train Epoch: 2 [166/250 21248/32000 (66%)] Loss: 1.99444 (semantic_loss: 0.04388, quant_loss: 1.95020, bit_balance_loss: 0.00036) batch_time=0.46004 
Train Epoch: 2 [177/250 22656/32000 (71%)] Loss: 1.99496 (semantic_loss: 0.04344, quant_loss: 1.95117, bit_balance_loss: 0.00035) batch_time=0.34631 
Train Epoch: 2 [188/250 24064/32000 (75%)] Loss: 1.99507 (semantic_loss: 0.04355, quant_loss: 1.95117, bit_balance_loss: 0.00035) batch_time=0.34771 
Train Epoch: 2 [199/250 25472/32000 (80%)] Loss: 1.99521 (semantic_loss: 0.04369, quant_loss: 1.95117, bit_balance_loss: 0.00035) batch_time=0.33595 
Train Epoch: 2 [210/250 26880/32000 (84%)] Loss: 1.99476 (semantic_loss: 0.04324, quant_loss: 1.95117, bit_balance_loss: 0.00035) batch_time=0.45148 
Train Epoch: 2 [221/250 28288/32000 (88%)] Loss: 1.99443 (semantic_loss: 0.04292, quant_loss: 1.95117, bit_balance_loss: 0.00034) batch_time=0.33578 
Train Epoch: 2 [232/250 29696/32000 (93%)] Loss: 1.99419 (semantic_loss: 0.04268, quant_loss: 1.95117, bit_balance_loss: 0.00034) batch_time=0.33839 
Train Epoch: 2 [243/250 31104/32000 (97%)] Loss: 1.99456 (semantic_loss: 0.04305, quant_loss: 1.95117, bit_balance_loss: 0.00033) batch_time=0.37949 
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/DCMH_MSRVTT_1kB/checkpoint-epoch2.pth ...
Done in 9.146s
Updating 'best' checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/DCMH_MSRVTT_1kB/checkpoint-epoch2.pth ...
Done in 12.690s
removing stale ckpt [epoch 1] [took 0.00s]
removing stale ckpt [epoch 0] [took 0.00s]
 epoch          : 2
 loss           : 1.995931456565857
 learning_rate  : 4.75e-05
 n_samples      : 64000
 n_steps        : 500
 MSRVTT_miech_test/t2v_metrics/R1: 0.3
 MSRVTT_miech_test/t2v_metrics/R5: 1.2
 MSRVTT_miech_test/t2v_metrics/R10: 2.8
 MSRVTT_miech_test/t2v_metrics/R50: 12.4
 MSRVTT_miech_test/t2v_metrics/MedR: 224.25
 MSRVTT_miech_test/t2v_metrics/MeanR: 285.037
 MSRVTT_miech_test/t2v_metrics/geometric_mean_R1-R5-R10: 1.002659586992917
 MSRVTT_miech_test/v2t_metrics/R1: 0.3
 MSRVTT_miech_test/v2t_metrics/R5: 1.6
 MSRVTT_miech_test/v2t_metrics/R10: 3.3
 MSRVTT_miech_test/v2t_metrics/R50: 12.8
 MSRVTT_miech_test/v2t_metrics/MedR: 226.5
 MSRVTT_miech_test/v2t_metrics/MeanR: 269.8695
 MSRVTT_miech_test/v2t_metrics/geometric_mean_R1-R5-R10: 1.1656953366502911
 mnt_best       : 1.002659586992917
 not_improved_count: 0
Train Epoch: 3 [1/250 128/32000 (0%)] Loss: 1.99304 (semantic_loss: 0.04251, quant_loss: 1.95020, bit_balance_loss: 0.00033) batch_time=27.44628 
Train Epoch: 3 [12/250 1536/32000 (5%)] Loss: 1.99308 (semantic_loss: 0.04255, quant_loss: 1.95020, bit_balance_loss: 0.00033) batch_time=0.32548 
Train Epoch: 3 [23/250 2944/32000 (9%)] Loss: 1.99288 (semantic_loss: 0.04236, quant_loss: 1.95020, bit_balance_loss: 0.00033) batch_time=0.35179 
Train Epoch: 3 [34/250 4352/32000 (14%)] Loss: 1.99308 (semantic_loss: 0.04256, quant_loss: 1.95020, bit_balance_loss: 0.00032) batch_time=0.33652 
Train Epoch: 3 [45/250 5760/32000 (18%)] Loss: 1.99163 (semantic_loss: 0.04112, quant_loss: 1.95020, bit_balance_loss: 0.00032) batch_time=0.33339 
Train Epoch: 3 [56/250 7168/32000 (22%)] Loss: 1.99231 (semantic_loss: 0.04181, quant_loss: 1.95020, bit_balance_loss: 0.00031) batch_time=0.34304 
Train Epoch: 3 [67/250 8576/32000 (27%)] Loss: 1.99143 (semantic_loss: 0.04093, quant_loss: 1.95020, bit_balance_loss: 0.00030) batch_time=1.62922 
Train Epoch: 3 [78/250 9984/32000 (31%)] Loss: 1.99059 (semantic_loss: 0.04107, quant_loss: 1.94922, bit_balance_loss: 0.00030) batch_time=0.35135 
Train Epoch: 3 [89/250 11392/32000 (36%)] Loss: 1.99037 (semantic_loss: 0.03988, quant_loss: 1.95020, bit_balance_loss: 0.00030) batch_time=0.34029 
Train Epoch: 3 [100/250 12800/32000 (40%)] Loss: 1.99018 (semantic_loss: 0.03970, quant_loss: 1.95020, bit_balance_loss: 0.00029) batch_time=0.32891 
Train Epoch: 3 [111/250 14208/32000 (44%)] Loss: 1.98989 (semantic_loss: 0.03941, quant_loss: 1.95020, bit_balance_loss: 0.00029) batch_time=0.33834 
Train Epoch: 3 [122/250 15616/32000 (49%)] Loss: 1.98959 (semantic_loss: 0.03911, quant_loss: 1.95020, bit_balance_loss: 0.00029) batch_time=0.32685 
Train Epoch: 3 [133/250 17024/32000 (53%)] Loss: 1.98794 (semantic_loss: 0.03844, quant_loss: 1.94922, bit_balance_loss: 0.00028) batch_time=0.56182 
Train Epoch: 3 [144/250 18432/32000 (58%)] Loss: 1.98914 (semantic_loss: 0.03866, quant_loss: 1.95020, bit_balance_loss: 0.00028) batch_time=7.59578 
Train Epoch: 3 [155/250 19840/32000 (62%)] Loss: 1.98899 (semantic_loss: 0.03852, quant_loss: 1.95020, bit_balance_loss: 0.00028) batch_time=0.33693 
Train Epoch: 3 [166/250 21248/32000 (66%)] Loss: 1.98757 (semantic_loss: 0.03711, quant_loss: 1.95020, bit_balance_loss: 0.00027) batch_time=0.35141 
Train Epoch: 3 [177/250 22656/32000 (71%)] Loss: 1.98613 (semantic_loss: 0.03664, quant_loss: 1.94922, bit_balance_loss: 0.00027) batch_time=0.36042 
Train Epoch: 3 [188/250 24064/32000 (75%)] Loss: 1.98883 (semantic_loss: 0.03837, quant_loss: 1.95020, bit_balance_loss: 0.00027) batch_time=0.34620 
Train Epoch: 3 [199/250 25472/32000 (80%)] Loss: 1.98642 (semantic_loss: 0.03693, quant_loss: 1.94922, bit_balance_loss: 0.00027) batch_time=0.34604 
Train Epoch: 3 [210/250 26880/32000 (84%)] Loss: 1.98719 (semantic_loss: 0.03673, quant_loss: 1.95020, bit_balance_loss: 0.00026) batch_time=0.40602 
Train Epoch: 3 [221/250 28288/32000 (88%)] Loss: 1.98778 (semantic_loss: 0.03733, quant_loss: 1.95020, bit_balance_loss: 0.00026) batch_time=0.33351 
Train Epoch: 3 [232/250 29696/32000 (93%)] Loss: 1.98660 (semantic_loss: 0.03712, quant_loss: 1.94922, bit_balance_loss: 0.00026) batch_time=0.33489 
Train Epoch: 3 [243/250 31104/32000 (97%)] Loss: 1.98616 (semantic_loss: 0.03669, quant_loss: 1.94922, bit_balance_loss: 0.00025) batch_time=0.37778 
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/DCMH_MSRVTT_1kB/checkpoint-epoch3.pth ...
Done in 3.709s
Updating 'best' checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/DCMH_MSRVTT_1kB/checkpoint-epoch3.pth ...
Done in 7.528s
removing stale ckpt [epoch 2] [took 0.00s]
 epoch          : 3
 loss           : 1.9896398954391479
 learning_rate  : 4.5125e-05
 n_samples      : 96000
 n_steps        : 750
 MSRVTT_miech_test/t2v_metrics/R1: 1.4
 MSRVTT_miech_test/t2v_metrics/R5: 6.6
 MSRVTT_miech_test/t2v_metrics/R10: 11.7
 MSRVTT_miech_test/t2v_metrics/R50: 40.2
 MSRVTT_miech_test/t2v_metrics/MedR: 72.0
 MSRVTT_miech_test/t2v_metrics/MeanR: 125.5495
 MSRVTT_miech_test/t2v_metrics/geometric_mean_R1-R5-R10: 4.7637900281166505
 MSRVTT_miech_test/v2t_metrics/R1: 1.3
 MSRVTT_miech_test/v2t_metrics/R5: 5.7
 MSRVTT_miech_test/v2t_metrics/R10: 12.5
 MSRVTT_miech_test/v2t_metrics/R50: 43.6
 MSRVTT_miech_test/v2t_metrics/MedR: 64.0
 MSRVTT_miech_test/v2t_metrics/MeanR: 118.175
 MSRVTT_miech_test/v2t_metrics/geometric_mean_R1-R5-R10: 4.5245571028518645
 mnt_best       : 4.7637900281166505
 not_improved_count: 0
Train Epoch: 4 [1/250 128/32000 (0%)] Loss: 1.98740 (semantic_loss: 0.03694, quant_loss: 1.95020, bit_balance_loss: 0.00026) batch_time=28.57283 
Train Epoch: 4 [12/250 1536/32000 (5%)] Loss: 1.98622 (semantic_loss: 0.03675, quant_loss: 1.94922, bit_balance_loss: 0.00025) batch_time=1.52478 
Train Epoch: 4 [23/250 2944/32000 (9%)] Loss: 1.98640 (semantic_loss: 0.03595, quant_loss: 1.95020, bit_balance_loss: 0.00025) batch_time=0.33723 
Train Epoch: 4 [34/250 4352/32000 (14%)] Loss: 1.98455 (semantic_loss: 0.03410, quant_loss: 1.95020, bit_balance_loss: 0.00025) batch_time=0.32284 
Train Epoch: 4 [45/250 5760/32000 (18%)] Loss: 1.98636 (semantic_loss: 0.03591, quant_loss: 1.95020, bit_balance_loss: 0.00025) batch_time=0.40834 
Train Epoch: 4 [56/250 7168/32000 (22%)] Loss: 1.98463 (semantic_loss: 0.03516, quant_loss: 1.94922, bit_balance_loss: 0.00025) batch_time=0.32551 
Train Epoch: 4 [67/250 8576/32000 (27%)] Loss: 1.98441 (semantic_loss: 0.03396, quant_loss: 1.95020, bit_balance_loss: 0.00025) batch_time=0.32997 
Train Epoch: 4 [78/250 9984/32000 (31%)] Loss: 1.98498 (semantic_loss: 0.03454, quant_loss: 1.95020, bit_balance_loss: 0.00025) batch_time=0.46704 
Train Epoch: 4 [89/250 11392/32000 (36%)] Loss: 1.98345 (semantic_loss: 0.03301, quant_loss: 1.95020, bit_balance_loss: 0.00025) batch_time=0.36052 
Train Epoch: 4 [100/250 12800/32000 (40%)] Loss: 1.98368 (semantic_loss: 0.03324, quant_loss: 1.95020, bit_balance_loss: 0.00024) batch_time=0.33313 
Train Epoch: 4 [111/250 14208/32000 (44%)] Loss: 1.98539 (semantic_loss: 0.03495, quant_loss: 1.95020, bit_balance_loss: 0.00024) batch_time=0.35484 
Train Epoch: 4 [122/250 15616/32000 (49%)] Loss: 1.98368 (semantic_loss: 0.03325, quant_loss: 1.95020, bit_balance_loss: 0.00024) batch_time=0.33014 
Train Epoch: 4 [133/250 17024/32000 (53%)] Loss: 1.98561 (semantic_loss: 0.03518, quant_loss: 1.95020, bit_balance_loss: 0.00024) batch_time=1.04606 
Train Epoch: 4 [144/250 18432/32000 (58%)] Loss: 1.98579 (semantic_loss: 0.03536, quant_loss: 1.95020, bit_balance_loss: 0.00024) batch_time=0.40164 
Train Epoch: 4 [155/250 19840/32000 (62%)] Loss: 1.98296 (semantic_loss: 0.03252, quant_loss: 1.95020, bit_balance_loss: 0.00024) batch_time=0.35322 
Train Epoch: 4 [166/250 21248/32000 (66%)] Loss: 1.98179 (semantic_loss: 0.03234, quant_loss: 1.94922, bit_balance_loss: 0.00023) batch_time=0.32169 
Train Epoch: 4 [177/250 22656/32000 (71%)] Loss: 1.98447 (semantic_loss: 0.03404, quant_loss: 1.95020, bit_balance_loss: 0.00023) batch_time=0.33524 
Train Epoch: 4 [188/250 24064/32000 (75%)] Loss: 1.98364 (semantic_loss: 0.03321, quant_loss: 1.95020, bit_balance_loss: 0.00023) batch_time=0.32692 
Train Epoch: 4 [199/250 25472/32000 (80%)] Loss: 1.98261 (semantic_loss: 0.03219, quant_loss: 1.95020, bit_balance_loss: 0.00023) batch_time=0.32003 
Train Epoch: 4 [210/250 26880/32000 (84%)] Loss: 1.98543 (semantic_loss: 0.03501, quant_loss: 1.95020, bit_balance_loss: 0.00022) batch_time=0.33083 
Train Epoch: 4 [221/250 28288/32000 (88%)] Loss: 1.98188 (semantic_loss: 0.03244, quant_loss: 1.94922, bit_balance_loss: 0.00023) batch_time=0.42734 
Train Epoch: 4 [232/250 29696/32000 (93%)] Loss: 1.98197 (semantic_loss: 0.03252, quant_loss: 1.94922, bit_balance_loss: 0.00023) batch_time=0.42452 
Train Epoch: 4 [243/250 31104/32000 (97%)] Loss: 1.98341 (semantic_loss: 0.03299, quant_loss: 1.95020, bit_balance_loss: 0.00022) batch_time=0.32032 
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/DCMH_MSRVTT_1kB/checkpoint-epoch4.pth ...
Done in 3.910s
Updating 'best' checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/DCMH_MSRVTT_1kB/checkpoint-epoch4.pth ...
Done in 7.826s
removing stale ckpt [epoch 3] [took 0.00s]
 epoch          : 4
 loss           : 1.9847099151611327
 learning_rate  : 4.2868749999999995e-05
 n_samples      : 128000
 n_steps        : 1000
 MSRVTT_miech_test/t2v_metrics/R1: 2.4
 MSRVTT_miech_test/t2v_metrics/R5: 10.3
 MSRVTT_miech_test/t2v_metrics/R10: 17.6
 MSRVTT_miech_test/t2v_metrics/R50: 55.0
 MSRVTT_miech_test/t2v_metrics/MedR: 43.0
 MSRVTT_miech_test/t2v_metrics/MeanR: 88.924
 MSRVTT_miech_test/t2v_metrics/geometric_mean_R1-R5-R10: 7.5774028691564554
 MSRVTT_miech_test/v2t_metrics/R1: 2.8
 MSRVTT_miech_test/v2t_metrics/R5: 12.3
 MSRVTT_miech_test/v2t_metrics/R10: 20.4
 MSRVTT_miech_test/v2t_metrics/R50: 56.6
 MSRVTT_miech_test/v2t_metrics/MedR: 40.0
 MSRVTT_miech_test/v2t_metrics/MeanR: 85.338
 MSRVTT_miech_test/v2t_metrics/geometric_mean_R1-R5-R10: 8.889918306704956
 mnt_best       : 7.5774028691564554
 not_improved_count: 0
Train Epoch: 5 [1/250 128/32000 (0%)] Loss: 1.98386 (semantic_loss: 0.03344, quant_loss: 1.95020, bit_balance_loss: 0.00022) batch_time=27.44430 
Train Epoch: 5 [12/250 1536/32000 (5%)] Loss: 1.98521 (semantic_loss: 0.03479, quant_loss: 1.95020, bit_balance_loss: 0.00022) batch_time=0.35834 
Train Epoch: 5 [23/250 2944/32000 (9%)] Loss: 1.98372 (semantic_loss: 0.03331, quant_loss: 1.95020, bit_balance_loss: 0.00022) batch_time=0.33147 
Train Epoch: 5 [34/250 4352/32000 (14%)] Loss: 1.98146 (semantic_loss: 0.03203, quant_loss: 1.94922, bit_balance_loss: 0.00022) batch_time=0.33513 
Train Epoch: 5 [45/250 5760/32000 (18%)] Loss: 1.98391 (semantic_loss: 0.03350, quant_loss: 1.95020, bit_balance_loss: 0.00022) batch_time=0.36263 
Train Epoch: 5 [56/250 7168/32000 (22%)] Loss: 1.98249 (semantic_loss: 0.03208, quant_loss: 1.95020, bit_balance_loss: 0.00021) batch_time=0.39391 
Train Epoch: 5 [67/250 8576/32000 (27%)] Loss: 1.98365 (semantic_loss: 0.03227, quant_loss: 1.95117, bit_balance_loss: 0.00021) batch_time=1.94447 
Train Epoch: 5 [78/250 9984/32000 (31%)] Loss: 1.98067 (semantic_loss: 0.03125, quant_loss: 1.94922, bit_balance_loss: 0.00021) batch_time=0.33272 
Train Epoch: 5 [89/250 11392/32000 (36%)] Loss: 1.98144 (semantic_loss: 0.03104, quant_loss: 1.95020, bit_balance_loss: 0.00021) batch_time=0.34063 
Train Epoch: 5 [100/250 12800/32000 (40%)] Loss: 1.98068 (semantic_loss: 0.03029, quant_loss: 1.95020, bit_balance_loss: 0.00020) batch_time=0.32995 
Train Epoch: 5 [111/250 14208/32000 (44%)] Loss: 1.98219 (semantic_loss: 0.03180, quant_loss: 1.95020, bit_balance_loss: 0.00020) batch_time=0.37149 
Train Epoch: 5 [122/250 15616/32000 (49%)] Loss: 1.98276 (semantic_loss: 0.03236, quant_loss: 1.95020, bit_balance_loss: 0.00020) batch_time=0.38624 
Train Epoch: 5 [133/250 17024/32000 (53%)] Loss: 1.98218 (semantic_loss: 0.03276, quant_loss: 1.94922, bit_balance_loss: 0.00020) batch_time=0.35529 
Train Epoch: 5 [144/250 18432/32000 (58%)] Loss: 1.98413 (semantic_loss: 0.03276, quant_loss: 1.95117, bit_balance_loss: 0.00019) batch_time=1.86230 
Train Epoch: 5 [155/250 19840/32000 (62%)] Loss: 1.98150 (semantic_loss: 0.03111, quant_loss: 1.95020, bit_balance_loss: 0.00019) batch_time=0.33533 
Train Epoch: 5 [166/250 21248/32000 (66%)] Loss: 1.98066 (semantic_loss: 0.03027, quant_loss: 1.95020, bit_balance_loss: 0.00019) batch_time=0.32766 
Train Epoch: 5 [177/250 22656/32000 (71%)] Loss: 1.98268 (semantic_loss: 0.03229, quant_loss: 1.95020, bit_balance_loss: 0.00019) batch_time=0.33464 
Train Epoch: 5 [188/250 24064/32000 (75%)] Loss: 1.98176 (semantic_loss: 0.03137, quant_loss: 1.95020, bit_balance_loss: 0.00019) batch_time=0.45243 
Train Epoch: 5 [199/250 25472/32000 (80%)] Loss: 1.98012 (semantic_loss: 0.02974, quant_loss: 1.95020, bit_balance_loss: 0.00019) batch_time=0.32618 
Train Epoch: 5 [210/250 26880/32000 (84%)] Loss: 1.97956 (semantic_loss: 0.02918, quant_loss: 1.95020, bit_balance_loss: 0.00018) batch_time=0.34339 
Train Epoch: 5 [221/250 28288/32000 (88%)] Loss: 1.98097 (semantic_loss: 0.03059, quant_loss: 1.95020, bit_balance_loss: 0.00018) batch_time=0.32516 
Train Epoch: 5 [232/250 29696/32000 (93%)] Loss: 1.98174 (semantic_loss: 0.03137, quant_loss: 1.95020, bit_balance_loss: 0.00018) batch_time=0.33007 
Train Epoch: 5 [243/250 31104/32000 (97%)] Loss: 1.98138 (semantic_loss: 0.03101, quant_loss: 1.95020, bit_balance_loss: 0.00018) batch_time=0.36600 
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/DCMH_MSRVTT_1kB/checkpoint-epoch5.pth ...
Done in 3.842s
Updating 'best' checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/DCMH_MSRVTT_1kB/checkpoint-epoch5.pth ...
Done in 8.679s
removing stale ckpt [epoch 4] [took 0.00s]
 epoch          : 5
 loss           : 1.9816745376586915
 learning_rate  : 4.072531249999999e-05
 n_samples      : 160000
 n_steps        : 1250
 MSRVTT_miech_test/t2v_metrics/R1: 3.7
 MSRVTT_miech_test/t2v_metrics/R5: 14.6
 MSRVTT_miech_test/t2v_metrics/R10: 25.1
 MSRVTT_miech_test/t2v_metrics/R50: 65.2
 MSRVTT_miech_test/t2v_metrics/MedR: 29.0
 MSRVTT_miech_test/t2v_metrics/MeanR: 69.724
 MSRVTT_miech_test/t2v_metrics/geometric_mean_R1-R5-R10: 11.068177121618358
 MSRVTT_miech_test/v2t_metrics/R1: 3.0
 MSRVTT_miech_test/v2t_metrics/R5: 15.7
 MSRVTT_miech_test/v2t_metrics/R10: 27.9
 MSRVTT_miech_test/v2t_metrics/R50: 66.7
 MSRVTT_miech_test/v2t_metrics/MedR: 29.0
 MSRVTT_miech_test/v2t_metrics/MeanR: 66.0795
 MSRVTT_miech_test/v2t_metrics/geometric_mean_R1-R5-R10: 10.953217294431978
 mnt_best       : 11.068177121618358
 not_improved_count: 0
Train Epoch: 6 [1/250 128/32000 (0%)] Loss: 1.98014 (semantic_loss: 0.02977, quant_loss: 1.95020, bit_balance_loss: 0.00018) batch_time=28.82492 
Train Epoch: 6 [12/250 1536/32000 (5%)] Loss: 1.98133 (semantic_loss: 0.03095, quant_loss: 1.95020, bit_balance_loss: 0.00018) batch_time=0.32540 
Train Epoch: 6 [23/250 2944/32000 (9%)] Loss: 1.98055 (semantic_loss: 0.03018, quant_loss: 1.95020, bit_balance_loss: 0.00017) batch_time=0.33090 
Train Epoch: 6 [34/250 4352/32000 (14%)] Loss: 1.97909 (semantic_loss: 0.02970, quant_loss: 1.94922, bit_balance_loss: 0.00017) batch_time=0.32413 
Train Epoch: 6 [45/250 5760/32000 (18%)] Loss: 1.98000 (semantic_loss: 0.02964, quant_loss: 1.95020, bit_balance_loss: 0.00017) batch_time=0.32351 
Train Epoch: 6 [56/250 7168/32000 (22%)] Loss: 1.97879 (semantic_loss: 0.02842, quant_loss: 1.95020, bit_balance_loss: 0.00017) batch_time=0.75729 
Train Epoch: 6 [67/250 8576/32000 (27%)] Loss: 1.98028 (semantic_loss: 0.02991, quant_loss: 1.95020, bit_balance_loss: 0.00017) batch_time=0.40074 
Train Epoch: 6 [78/250 9984/32000 (31%)] Loss: 1.97900 (semantic_loss: 0.02961, quant_loss: 1.94922, bit_balance_loss: 0.00017) batch_time=0.34017 
Train Epoch: 6 [89/250 11392/32000 (36%)] Loss: 1.97954 (semantic_loss: 0.02918, quant_loss: 1.95020, bit_balance_loss: 0.00017) batch_time=0.33153 
Train Epoch: 6 [100/250 12800/32000 (40%)] Loss: 1.97851 (semantic_loss: 0.02815, quant_loss: 1.95020, bit_balance_loss: 0.00017) batch_time=0.34016 
Train Epoch: 6 [111/250 14208/32000 (44%)] Loss: 1.98029 (semantic_loss: 0.02895, quant_loss: 1.95117, bit_balance_loss: 0.00017) batch_time=0.33446 
Train Epoch: 6 [122/250 15616/32000 (49%)] Loss: 1.97936 (semantic_loss: 0.02998, quant_loss: 1.94922, bit_balance_loss: 0.00016) batch_time=0.34097 
Train Epoch: 6 [133/250 17024/32000 (53%)] Loss: 1.97916 (semantic_loss: 0.02881, quant_loss: 1.95020, bit_balance_loss: 0.00016) batch_time=0.33592 
Train Epoch: 6 [144/250 18432/32000 (58%)] Loss: 1.97835 (semantic_loss: 0.02897, quant_loss: 1.94922, bit_balance_loss: 0.00016) batch_time=0.39954 
Train Epoch: 6 [155/250 19840/32000 (62%)] Loss: 1.97629 (semantic_loss: 0.02691, quant_loss: 1.94922, bit_balance_loss: 0.00016) batch_time=0.33099 
Train Epoch: 6 [166/250 21248/32000 (66%)] Loss: 1.97975 (semantic_loss: 0.02939, quant_loss: 1.95020, bit_balance_loss: 0.00016) batch_time=0.33916 
Train Epoch: 6 [177/250 22656/32000 (71%)] Loss: 1.97843 (semantic_loss: 0.02906, quant_loss: 1.94922, bit_balance_loss: 0.00016) batch_time=0.33563 
Train Epoch: 6 [188/250 24064/32000 (75%)] Loss: 1.97631 (semantic_loss: 0.02693, quant_loss: 1.94922, bit_balance_loss: 0.00016) batch_time=0.34055 
Train Epoch: 6 [199/250 25472/32000 (80%)] Loss: 1.97852 (semantic_loss: 0.02816, quant_loss: 1.95020, bit_balance_loss: 0.00016) batch_time=3.86169 
Train Epoch: 6 [210/250 26880/32000 (84%)] Loss: 1.97782 (semantic_loss: 0.02747, quant_loss: 1.95020, bit_balance_loss: 0.00016) batch_time=0.33959 
Train Epoch: 6 [221/250 28288/32000 (88%)] Loss: 1.97677 (semantic_loss: 0.02740, quant_loss: 1.94922, bit_balance_loss: 0.00016) batch_time=0.33328 
Train Epoch: 6 [232/250 29696/32000 (93%)] Loss: 1.97757 (semantic_loss: 0.02819, quant_loss: 1.94922, bit_balance_loss: 0.00016) batch_time=0.33673 
Train Epoch: 6 [243/250 31104/32000 (97%)] Loss: 1.97934 (semantic_loss: 0.02899, quant_loss: 1.95020, bit_balance_loss: 0.00015) batch_time=0.34835 
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/DCMH_MSRVTT_1kB/checkpoint-epoch6.pth ...
Done in 3.747s
Updating 'best' checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/DCMH_MSRVTT_1kB/checkpoint-epoch6.pth ...
Done in 7.187s
removing stale ckpt [epoch 5] [took 0.00s]
 epoch          : 6
 loss           : 1.9792327456474303
 learning_rate  : 3.868904687499999e-05
 n_samples      : 192000
 n_steps        : 1500
 MSRVTT_miech_test/t2v_metrics/R1: 5.5
 MSRVTT_miech_test/t2v_metrics/R5: 19.0
 MSRVTT_miech_test/t2v_metrics/R10: 32.4
 MSRVTT_miech_test/t2v_metrics/R50: 68.3
 MSRVTT_miech_test/t2v_metrics/MedR: 22.0
 MSRVTT_miech_test/t2v_metrics/MeanR: 64.464
 MSRVTT_miech_test/t2v_metrics/geometric_mean_R1-R5-R10: 15.015982963609499
 MSRVTT_miech_test/v2t_metrics/R1: 4.6
 MSRVTT_miech_test/v2t_metrics/R5: 21.5
 MSRVTT_miech_test/v2t_metrics/R10: 31.9
 MSRVTT_miech_test/v2t_metrics/R50: 70.0
 MSRVTT_miech_test/v2t_metrics/MedR: 22.5
 MSRVTT_miech_test/v2t_metrics/MeanR: 63.7125
 MSRVTT_miech_test/v2t_metrics/geometric_mean_R1-R5-R10: 14.666584595500344
 mnt_best       : 15.015982963609499
 not_improved_count: 0
Train Epoch: 7 [1/250 128/32000 (0%)] Loss: 1.97864 (semantic_loss: 0.02829, quant_loss: 1.95020, bit_balance_loss: 0.00015) batch_time=26.83498 
Train Epoch: 7 [12/250 1536/32000 (5%)] Loss: 1.97811 (semantic_loss: 0.02874, quant_loss: 1.94922, bit_balance_loss: 0.00016) batch_time=0.45352 
Train Epoch: 7 [23/250 2944/32000 (9%)] Loss: 1.97919 (semantic_loss: 0.02884, quant_loss: 1.95020, bit_balance_loss: 0.00016) batch_time=0.33302 
Train Epoch: 7 [34/250 4352/32000 (14%)] Loss: 1.97627 (semantic_loss: 0.02690, quant_loss: 1.94922, bit_balance_loss: 0.00015) batch_time=0.32911 
Train Epoch: 7 [45/250 5760/32000 (18%)] Loss: 1.97796 (semantic_loss: 0.02762, quant_loss: 1.95020, bit_balance_loss: 0.00015) batch_time=0.42130 
Train Epoch: 7 [56/250 7168/32000 (22%)] Loss: 1.97594 (semantic_loss: 0.02657, quant_loss: 1.94922, bit_balance_loss: 0.00015) batch_time=0.34212 
Train Epoch: 7 [67/250 8576/32000 (27%)] Loss: 1.97913 (semantic_loss: 0.02878, quant_loss: 1.95020, bit_balance_loss: 0.00015) batch_time=0.73416 
Train Epoch: 7 [78/250 9984/32000 (31%)] Loss: 1.97815 (semantic_loss: 0.02780, quant_loss: 1.95020, bit_balance_loss: 0.00015) batch_time=0.32989 
Train Epoch: 7 [89/250 11392/32000 (36%)] Loss: 1.97903 (semantic_loss: 0.02869, quant_loss: 1.95020, bit_balance_loss: 0.00015) batch_time=0.33166 
Train Epoch: 7 [100/250 12800/32000 (40%)] Loss: 1.97696 (semantic_loss: 0.02759, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.33757 
Train Epoch: 7 [111/250 14208/32000 (44%)] Loss: 1.97837 (semantic_loss: 0.02803, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.41604 
Train Epoch: 7 [122/250 15616/32000 (49%)] Loss: 1.97526 (semantic_loss: 0.02590, quant_loss: 1.94922, bit_balance_loss: 0.00015) batch_time=0.36190 
Train Epoch: 7 [133/250 17024/32000 (53%)] Loss: 1.97639 (semantic_loss: 0.02605, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.32694 
Train Epoch: 7 [144/250 18432/32000 (58%)] Loss: 1.97867 (semantic_loss: 0.02833, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=1.41662 
Train Epoch: 7 [155/250 19840/32000 (62%)] Loss: 1.97747 (semantic_loss: 0.02713, quant_loss: 1.95020, bit_balance_loss: 0.00015) batch_time=0.34625 
Train Epoch: 7 [166/250 21248/32000 (66%)] Loss: 1.97737 (semantic_loss: 0.02703, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.32040 
Train Epoch: 7 [177/250 22656/32000 (71%)] Loss: 1.97706 (semantic_loss: 0.02672, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.32737 
Train Epoch: 7 [188/250 24064/32000 (75%)] Loss: 1.97730 (semantic_loss: 0.02696, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.60257 
Train Epoch: 7 [199/250 25472/32000 (80%)] Loss: 1.97703 (semantic_loss: 0.02669, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.33347 
Train Epoch: 7 [210/250 26880/32000 (84%)] Loss: 1.97566 (semantic_loss: 0.02630, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=1.71779 
Train Epoch: 7 [221/250 28288/32000 (88%)] Loss: 1.97506 (semantic_loss: 0.02570, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.32163 
Train Epoch: 7 [232/250 29696/32000 (93%)] Loss: 1.97576 (semantic_loss: 0.02542, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=2.03827 
Train Epoch: 7 [243/250 31104/32000 (97%)] Loss: 1.97709 (semantic_loss: 0.02773, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.32250 
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/DCMH_MSRVTT_1kB/checkpoint-epoch7.pth ...
Done in 3.754s
Updating 'best' checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/DCMH_MSRVTT_1kB/checkpoint-epoch7.pth ...
Done in 7.601s
removing stale ckpt [epoch 6] [took 0.00s]
 epoch          : 7
 loss           : 1.9771827626228333
 learning_rate  : 3.675459453124999e-05
 n_samples      : 224000
 n_steps        : 1750
 MSRVTT_miech_test/t2v_metrics/R1: 6.1
 MSRVTT_miech_test/t2v_metrics/R5: 23.0
 MSRVTT_miech_test/t2v_metrics/R10: 34.5
 MSRVTT_miech_test/t2v_metrics/R50: 71.7
 MSRVTT_miech_test/t2v_metrics/MedR: 19.0
 MSRVTT_miech_test/t2v_metrics/MeanR: 59.4705
 MSRVTT_miech_test/t2v_metrics/geometric_mean_R1-R5-R10: 16.91578884630474
 MSRVTT_miech_test/v2t_metrics/R1: 5.6
 MSRVTT_miech_test/v2t_metrics/R5: 22.2
 MSRVTT_miech_test/v2t_metrics/R10: 35.1
 MSRVTT_miech_test/v2t_metrics/R50: 72.1
 MSRVTT_miech_test/v2t_metrics/MedR: 21.0
 MSRVTT_miech_test/v2t_metrics/MeanR: 58.734
 MSRVTT_miech_test/v2t_metrics/geometric_mean_R1-R5-R10: 16.34115336581012
 mnt_best       : 16.91578884630474
 not_improved_count: 0
Train Epoch: 8 [1/250 128/32000 (0%)] Loss: 1.97636 (semantic_loss: 0.02602, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=28.09230 
Train Epoch: 8 [12/250 1536/32000 (5%)] Loss: 1.97418 (semantic_loss: 0.02483, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.43139 
Train Epoch: 8 [23/250 2944/32000 (9%)] Loss: 1.97716 (semantic_loss: 0.02683, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.37239 
Train Epoch: 8 [34/250 4352/32000 (14%)] Loss: 1.97674 (semantic_loss: 0.02640, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.35502 
Train Epoch: 8 [45/250 5760/32000 (18%)] Loss: 1.97836 (semantic_loss: 0.02900, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.32248 
Train Epoch: 8 [56/250 7168/32000 (22%)] Loss: 1.97327 (semantic_loss: 0.02391, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.32956 
Train Epoch: 8 [67/250 8576/32000 (27%)] Loss: 1.97595 (semantic_loss: 0.02561, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.32241 
Train Epoch: 8 [78/250 9984/32000 (31%)] Loss: 1.97671 (semantic_loss: 0.02638, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.77330 
Train Epoch: 8 [89/250 11392/32000 (36%)] Loss: 1.97624 (semantic_loss: 0.02591, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.57754 
Train Epoch: 8 [100/250 12800/32000 (40%)] Loss: 1.97624 (semantic_loss: 0.02592, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.38009 
Train Epoch: 8 [111/250 14208/32000 (44%)] Loss: 1.97589 (semantic_loss: 0.02458, quant_loss: 1.95117, bit_balance_loss: 0.00014) batch_time=0.35574 
Train Epoch: 8 [122/250 15616/32000 (49%)] Loss: 1.97525 (semantic_loss: 0.02492, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.32446 
Train Epoch: 8 [133/250 17024/32000 (53%)] Loss: 1.97595 (semantic_loss: 0.02562, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.32704 
Train Epoch: 8 [144/250 18432/32000 (58%)] Loss: 1.97624 (semantic_loss: 0.02591, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.42192 
Train Epoch: 8 [155/250 19840/32000 (62%)] Loss: 1.97550 (semantic_loss: 0.02517, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.33316 
Train Epoch: 8 [166/250 21248/32000 (66%)] Loss: 1.97578 (semantic_loss: 0.02545, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.35310 
Train Epoch: 8 [177/250 22656/32000 (71%)] Loss: 1.97490 (semantic_loss: 0.02554, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.32454 
Train Epoch: 8 [188/250 24064/32000 (75%)] Loss: 1.97484 (semantic_loss: 0.02548, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.46667 
Train Epoch: 8 [199/250 25472/32000 (80%)] Loss: 1.97462 (semantic_loss: 0.02429, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.39477 
Train Epoch: 8 [210/250 26880/32000 (84%)] Loss: 1.97502 (semantic_loss: 0.02469, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.33774 
Train Epoch: 8 [221/250 28288/32000 (88%)] Loss: 1.97436 (semantic_loss: 0.02403, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.33991 
Train Epoch: 8 [232/250 29696/32000 (93%)] Loss: 1.97644 (semantic_loss: 0.02611, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.32474 
Train Epoch: 8 [243/250 31104/32000 (97%)] Loss: 1.97466 (semantic_loss: 0.02531, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.33718 
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/DCMH_MSRVTT_1kB/checkpoint-epoch8.pth ...
Done in 4.079s
Updating 'best' checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/DCMH_MSRVTT_1kB/checkpoint-epoch8.pth ...
Done in 8.486s
removing stale ckpt [epoch 7] [took 0.00s]
 epoch          : 8
 loss           : 1.9756141562461853
 learning_rate  : 3.4916864804687486e-05
 n_samples      : 256000
 n_steps        : 2000
 MSRVTT_miech_test/t2v_metrics/R1: 8.1
 MSRVTT_miech_test/t2v_metrics/R5: 25.6
 MSRVTT_miech_test/t2v_metrics/R10: 39.3
 MSRVTT_miech_test/t2v_metrics/R50: 73.0
 MSRVTT_miech_test/t2v_metrics/MedR: 17.25
 MSRVTT_miech_test/t2v_metrics/MeanR: 53.8865
 MSRVTT_miech_test/t2v_metrics/geometric_mean_R1-R5-R10: 20.123607814912585
 MSRVTT_miech_test/v2t_metrics/R1: 6.7
 MSRVTT_miech_test/v2t_metrics/R5: 25.4
 MSRVTT_miech_test/v2t_metrics/R10: 40.2
 MSRVTT_miech_test/v2t_metrics/R50: 73.8
 MSRVTT_miech_test/v2t_metrics/MedR: 16.0
 MSRVTT_miech_test/v2t_metrics/MeanR: 52.505
 MSRVTT_miech_test/v2t_metrics/geometric_mean_R1-R5-R10: 18.983583233926698
 mnt_best       : 20.123607814912585
 not_improved_count: 0
Train Epoch: 9 [1/250 128/32000 (0%)] Loss: 1.97491 (semantic_loss: 0.02458, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=26.15884 
Train Epoch: 9 [12/250 1536/32000 (5%)] Loss: 1.97361 (semantic_loss: 0.02426, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.32647 
Train Epoch: 9 [23/250 2944/32000 (9%)] Loss: 1.97373 (semantic_loss: 0.02341, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.33879 
Train Epoch: 9 [34/250 4352/32000 (14%)] Loss: 1.97419 (semantic_loss: 0.02484, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.93620 
Train Epoch: 9 [45/250 5760/32000 (18%)] Loss: 1.97336 (semantic_loss: 0.02303, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.41430 
Train Epoch: 9 [56/250 7168/32000 (22%)] Loss: 1.97469 (semantic_loss: 0.02436, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.33938 
Train Epoch: 9 [67/250 8576/32000 (27%)] Loss: 1.97521 (semantic_loss: 0.02488, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.32884 
Train Epoch: 9 [78/250 9984/32000 (31%)] Loss: 1.97673 (semantic_loss: 0.02738, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.47275 
Train Epoch: 9 [89/250 11392/32000 (36%)] Loss: 1.97298 (semantic_loss: 0.02363, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.33151 
Train Epoch: 9 [100/250 12800/32000 (40%)] Loss: 1.97448 (semantic_loss: 0.02415, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.79724 
Train Epoch: 9 [111/250 14208/32000 (44%)] Loss: 1.97436 (semantic_loss: 0.02403, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.48197 
Train Epoch: 9 [122/250 15616/32000 (49%)] Loss: 1.97525 (semantic_loss: 0.02492, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.38972 
Train Epoch: 9 [133/250 17024/32000 (53%)] Loss: 1.97596 (semantic_loss: 0.02562, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.32165 
Train Epoch: 9 [144/250 18432/32000 (58%)] Loss: 1.97329 (semantic_loss: 0.02297, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=1.44163 
Train Epoch: 9 [155/250 19840/32000 (62%)] Loss: 1.97268 (semantic_loss: 0.02235, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.33974 
Train Epoch: 9 [166/250 21248/32000 (66%)] Loss: 1.97237 (semantic_loss: 0.02302, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.32156 
Train Epoch: 9 [177/250 22656/32000 (71%)] Loss: 1.97504 (semantic_loss: 0.02472, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.32607 
Train Epoch: 9 [188/250 24064/32000 (75%)] Loss: 1.97597 (semantic_loss: 0.02564, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.42381 
Train Epoch: 9 [199/250 25472/32000 (80%)] Loss: 1.97515 (semantic_loss: 0.02483, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.61017 
Train Epoch: 9 [210/250 26880/32000 (84%)] Loss: 1.97379 (semantic_loss: 0.02346, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.32149 
Train Epoch: 9 [221/250 28288/32000 (88%)] Loss: 1.97502 (semantic_loss: 0.02469, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.33077 
Train Epoch: 9 [232/250 29696/32000 (93%)] Loss: 1.97348 (semantic_loss: 0.02316, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.78573 
Train Epoch: 9 [243/250 31104/32000 (97%)] Loss: 1.97644 (semantic_loss: 0.02611, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.33028 
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/DCMH_MSRVTT_1kB/checkpoint-epoch9.pth ...
Done in 17.824s
Updating 'best' checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/DCMH_MSRVTT_1kB/checkpoint-epoch9.pth ...
Done in 21.407s
removing stale ckpt [epoch 8] [took 0.00s]
 epoch          : 9
 loss           : 1.9744027829170228
 learning_rate  : 3.317102156445311e-05
 n_samples      : 288000
 n_steps        : 2250
 MSRVTT_miech_test/t2v_metrics/R1: 8.9
 MSRVTT_miech_test/t2v_metrics/R5: 26.9
 MSRVTT_miech_test/t2v_metrics/R10: 42.5
 MSRVTT_miech_test/t2v_metrics/R50: 76.2
 MSRVTT_miech_test/t2v_metrics/MedR: 15.0
 MSRVTT_miech_test/t2v_metrics/MeanR: 48.63
 MSRVTT_miech_test/t2v_metrics/geometric_mean_R1-R5-R10: 21.669242954665286
 MSRVTT_miech_test/v2t_metrics/R1: 9.2
 MSRVTT_miech_test/v2t_metrics/R5: 28.0
 MSRVTT_miech_test/v2t_metrics/R10: 43.0
 MSRVTT_miech_test/v2t_metrics/R50: 77.8
 MSRVTT_miech_test/v2t_metrics/MedR: 14.0
 MSRVTT_miech_test/v2t_metrics/MeanR: 47.5145
 MSRVTT_miech_test/v2t_metrics/geometric_mean_R1-R5-R10: 22.291438997684477
 mnt_best       : 21.669242954665286
 not_improved_count: 0
Train Epoch: 10 [1/250 128/32000 (0%)] Loss: 1.97411 (semantic_loss: 0.02378, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=27.97152 
Train Epoch: 10 [12/250 1536/32000 (5%)] Loss: 1.97340 (semantic_loss: 0.02405, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.32505 
Train Epoch: 10 [23/250 2944/32000 (9%)] Loss: 1.97372 (semantic_loss: 0.02339, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.34738 
Train Epoch: 10 [34/250 4352/32000 (14%)] Loss: 1.97477 (semantic_loss: 0.02542, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.33489 
Train Epoch: 10 [45/250 5760/32000 (18%)] Loss: 1.97488 (semantic_loss: 0.02455, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.41686 
Train Epoch: 10 [56/250 7168/32000 (22%)] Loss: 1.97247 (semantic_loss: 0.02214, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.40547 
Train Epoch: 10 [67/250 8576/32000 (27%)] Loss: 1.97206 (semantic_loss: 0.02174, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.33877 
Train Epoch: 10 [78/250 9984/32000 (31%)] Loss: 1.97458 (semantic_loss: 0.02425, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.32130 
Train Epoch: 10 [89/250 11392/32000 (36%)] Loss: 1.97350 (semantic_loss: 0.02317, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.32567 
Train Epoch: 10 [100/250 12800/32000 (40%)] Loss: 1.97322 (semantic_loss: 0.02387, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.34558 
Train Epoch: 10 [111/250 14208/32000 (44%)] Loss: 1.97279 (semantic_loss: 0.02344, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.51554 
Train Epoch: 10 [122/250 15616/32000 (49%)] Loss: 1.97166 (semantic_loss: 0.02134, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.39044 
Train Epoch: 10 [133/250 17024/32000 (53%)] Loss: 1.97475 (semantic_loss: 0.02442, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.35006 
Train Epoch: 10 [144/250 18432/32000 (58%)] Loss: 1.97357 (semantic_loss: 0.02325, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.33367 
Train Epoch: 10 [155/250 19840/32000 (62%)] Loss: 1.97535 (semantic_loss: 0.02502, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.33751 
Train Epoch: 10 [166/250 21248/32000 (66%)] Loss: 1.97127 (semantic_loss: 0.02094, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.36631 
Train Epoch: 10 [177/250 22656/32000 (71%)] Loss: 1.97319 (semantic_loss: 0.02286, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.48377 
Train Epoch: 10 [188/250 24064/32000 (75%)] Loss: 1.97383 (semantic_loss: 0.02350, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.37025 
Train Epoch: 10 [199/250 25472/32000 (80%)] Loss: 1.97330 (semantic_loss: 0.02297, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.32181 
Train Epoch: 10 [210/250 26880/32000 (84%)] Loss: 1.97572 (semantic_loss: 0.02539, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.32310 
Train Epoch: 10 [221/250 28288/32000 (88%)] Loss: 1.97539 (semantic_loss: 0.02507, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.36372 
Train Epoch: 10 [232/250 29696/32000 (93%)] Loss: 1.97238 (semantic_loss: 0.02205, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.32987 
Train Epoch: 10 [243/250 31104/32000 (97%)] Loss: 1.97479 (semantic_loss: 0.02447, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.48286 
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/DCMH_MSRVTT_1kB/checkpoint-epoch10.pth ...
Done in 4.127s
Updating 'best' checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/DCMH_MSRVTT_1kB/checkpoint-epoch10.pth ...
Done in 8.952s
removing stale ckpt [epoch 9] [took 0.00s]
 epoch          : 10
 loss           : 1.9735737257003785
 learning_rate  : 3.151247048623045e-05
 n_samples      : 320000
 n_steps        : 2500
 MSRVTT_miech_test/t2v_metrics/R1: 8.8
 MSRVTT_miech_test/t2v_metrics/R5: 29.6
 MSRVTT_miech_test/t2v_metrics/R10: 43.9
 MSRVTT_miech_test/t2v_metrics/R50: 77.5
 MSRVTT_miech_test/t2v_metrics/MedR: 13.0
 MSRVTT_miech_test/t2v_metrics/MeanR: 47.6155
 MSRVTT_miech_test/t2v_metrics/geometric_mean_R1-R5-R10: 22.52922753135977
 MSRVTT_miech_test/v2t_metrics/R1: 8.4
 MSRVTT_miech_test/v2t_metrics/R5: 29.9
 MSRVTT_miech_test/v2t_metrics/R10: 43.2
 MSRVTT_miech_test/v2t_metrics/R50: 78.4
 MSRVTT_miech_test/v2t_metrics/MedR: 14.0
 MSRVTT_miech_test/v2t_metrics/MeanR: 45.744
 MSRVTT_miech_test/v2t_metrics/geometric_mean_R1-R5-R10: 22.138324062885335
 mnt_best       : 22.52922753135977
 not_improved_count: 0
Train Epoch: 11 [1/250 128/32000 (0%)] Loss: 1.97272 (semantic_loss: 0.02337, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=32.29093 
Train Epoch: 11 [12/250 1536/32000 (5%)] Loss: 1.97118 (semantic_loss: 0.02183, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.37555 
Train Epoch: 11 [23/250 2944/32000 (9%)] Loss: 1.97436 (semantic_loss: 0.02403, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.34113 
Train Epoch: 11 [34/250 4352/32000 (14%)] Loss: 1.97240 (semantic_loss: 0.02207, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.32908 
Train Epoch: 11 [45/250 5760/32000 (18%)] Loss: 1.97169 (semantic_loss: 0.02233, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.33105 
Train Epoch: 11 [56/250 7168/32000 (22%)] Loss: 1.97236 (semantic_loss: 0.02203, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.35535 
Train Epoch: 11 [67/250 8576/32000 (27%)] Loss: 1.97161 (semantic_loss: 0.02128, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.47707 
Train Epoch: 11 [78/250 9984/32000 (31%)] Loss: 1.97063 (semantic_loss: 0.02128, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.39049 
Train Epoch: 11 [89/250 11392/32000 (36%)] Loss: 1.97130 (semantic_loss: 0.02097, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.34773 
Train Epoch: 11 [100/250 12800/32000 (40%)] Loss: 1.97255 (semantic_loss: 0.02320, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.32480 
Train Epoch: 11 [111/250 14208/32000 (44%)] Loss: 1.97337 (semantic_loss: 0.02304, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.33855 
Train Epoch: 11 [122/250 15616/32000 (49%)] Loss: 1.97093 (semantic_loss: 0.02158, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.32935 
Train Epoch: 11 [133/250 17024/32000 (53%)] Loss: 1.97317 (semantic_loss: 0.02285, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.47394 
Train Epoch: 11 [144/250 18432/32000 (58%)] Loss: 1.97270 (semantic_loss: 0.02335, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.36320 
Train Epoch: 11 [155/250 19840/32000 (62%)] Loss: 1.97444 (semantic_loss: 0.02509, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.33343 
Train Epoch: 11 [166/250 21248/32000 (66%)] Loss: 1.97231 (semantic_loss: 0.02198, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.32550 
Train Epoch: 11 [177/250 22656/32000 (71%)] Loss: 1.97204 (semantic_loss: 0.02269, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.32774 
Train Epoch: 11 [188/250 24064/32000 (75%)] Loss: 1.97119 (semantic_loss: 0.02184, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.33639 
Train Epoch: 11 [199/250 25472/32000 (80%)] Loss: 1.97332 (semantic_loss: 0.02300, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.34488 
Train Epoch: 11 [210/250 26880/32000 (84%)] Loss: 1.97206 (semantic_loss: 0.02173, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.37958 
Train Epoch: 11 [221/250 28288/32000 (88%)] Loss: 1.97268 (semantic_loss: 0.02235, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.32954 
Train Epoch: 11 [232/250 29696/32000 (93%)] Loss: 1.97444 (semantic_loss: 0.02313, quant_loss: 1.95117, bit_balance_loss: 0.00013) batch_time=0.35236 
Train Epoch: 11 [243/250 31104/32000 (97%)] Loss: 1.97296 (semantic_loss: 0.02360, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.33275 
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/DCMH_MSRVTT_1kB/checkpoint-epoch11.pth ...
Done in 4.393s
Updating 'best' checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/DCMH_MSRVTT_1kB/checkpoint-epoch11.pth ...
Done in 7.987s
removing stale ckpt [epoch 10] [took 0.00s]
 epoch          : 11
 loss           : 1.9725894932746888
 learning_rate  : 2.993684696191893e-05
 n_samples      : 352000
 n_steps        : 2750
 MSRVTT_miech_test/t2v_metrics/R1: 8.0
 MSRVTT_miech_test/t2v_metrics/R5: 31.9
 MSRVTT_miech_test/t2v_metrics/R10: 46.4
 MSRVTT_miech_test/t2v_metrics/R50: 78.7
 MSRVTT_miech_test/t2v_metrics/MedR: 12.0
 MSRVTT_miech_test/t2v_metrics/MeanR: 46.4735
 MSRVTT_miech_test/t2v_metrics/geometric_mean_R1-R5-R10: 22.792898167727444
 MSRVTT_miech_test/v2t_metrics/R1: 9.0
 MSRVTT_miech_test/v2t_metrics/R5: 29.4
 MSRVTT_miech_test/v2t_metrics/R10: 45.2
 MSRVTT_miech_test/v2t_metrics/R50: 78.8
 MSRVTT_miech_test/v2t_metrics/MedR: 13.0
 MSRVTT_miech_test/v2t_metrics/MeanR: 45.152
 MSRVTT_miech_test/v2t_metrics/geometric_mean_R1-R5-R10: 22.868767450104688
 mnt_best       : 22.792898167727444
 not_improved_count: 0
Train Epoch: 12 [1/250 128/32000 (0%)] Loss: 1.97298 (semantic_loss: 0.02265, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=25.78851 
Train Epoch: 12 [12/250 1536/32000 (5%)] Loss: 1.97391 (semantic_loss: 0.02358, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.98380 
Train Epoch: 12 [23/250 2944/32000 (9%)] Loss: 1.96988 (semantic_loss: 0.02053, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.32717 
Train Epoch: 12 [34/250 4352/32000 (14%)] Loss: 1.97147 (semantic_loss: 0.02114, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.33154 
Train Epoch: 12 [45/250 5760/32000 (18%)] Loss: 1.97354 (semantic_loss: 0.02321, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.37157 
Train Epoch: 12 [56/250 7168/32000 (22%)] Loss: 1.97205 (semantic_loss: 0.02172, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.39099 
Train Epoch: 12 [67/250 8576/32000 (27%)] Loss: 1.97180 (semantic_loss: 0.02147, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.33678 
Train Epoch: 12 [78/250 9984/32000 (31%)] Loss: 1.97272 (semantic_loss: 0.02239, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=1.94126 
Train Epoch: 12 [89/250 11392/32000 (36%)] Loss: 1.97177 (semantic_loss: 0.02145, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.42609 
Train Epoch: 12 [100/250 12800/32000 (40%)] Loss: 1.97142 (semantic_loss: 0.02110, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.34460 
Train Epoch: 12 [111/250 14208/32000 (44%)] Loss: 1.97232 (semantic_loss: 0.02200, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.32124 
Train Epoch: 12 [122/250 15616/32000 (49%)] Loss: 1.97120 (semantic_loss: 0.02184, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.39690 
Train Epoch: 12 [133/250 17024/32000 (53%)] Loss: 1.97225 (semantic_loss: 0.02192, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.41562 
Train Epoch: 12 [144/250 18432/32000 (58%)] Loss: 1.97239 (semantic_loss: 0.02206, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.49810 
Train Epoch: 12 [155/250 19840/32000 (62%)] Loss: 1.97253 (semantic_loss: 0.02220, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.32708 
Train Epoch: 12 [166/250 21248/32000 (66%)] Loss: 1.97301 (semantic_loss: 0.02268, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.32251 
Train Epoch: 12 [177/250 22656/32000 (71%)] Loss: 1.97384 (semantic_loss: 0.02351, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.32994 
Train Epoch: 12 [188/250 24064/32000 (75%)] Loss: 1.97225 (semantic_loss: 0.02192, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.32183 
Train Epoch: 12 [199/250 25472/32000 (80%)] Loss: 1.97364 (semantic_loss: 0.02332, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=1.06544 
Train Epoch: 12 [210/250 26880/32000 (84%)] Loss: 1.97056 (semantic_loss: 0.02121, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=1.39819 
Train Epoch: 12 [221/250 28288/32000 (88%)] Loss: 1.97100 (semantic_loss: 0.02165, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=0.35846 
Train Epoch: 12 [232/250 29696/32000 (93%)] Loss: 1.97321 (semantic_loss: 0.02289, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.33089 
Train Epoch: 12 [243/250 31104/32000 (97%)] Loss: 1.97092 (semantic_loss: 0.02157, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.32005 
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/DCMH_MSRVTT_1kB/checkpoint-epoch12.pth ...
Done in 4.679s
Updating 'best' checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/DCMH_MSRVTT_1kB/checkpoint-epoch12.pth ...
Done in 8.709s
removing stale ckpt [epoch 11] [took 0.00s]
 epoch          : 12
 loss           : 1.9719723215103149
 learning_rate  : 2.844000461382298e-05
 n_samples      : 384000
 n_steps        : 3000
 MSRVTT_miech_test/t2v_metrics/R1: 9.3
 MSRVTT_miech_test/t2v_metrics/R5: 34.0
 MSRVTT_miech_test/t2v_metrics/R10: 48.0
 MSRVTT_miech_test/t2v_metrics/R50: 78.0
 MSRVTT_miech_test/t2v_metrics/MedR: 12.0
 MSRVTT_miech_test/t2v_metrics/MeanR: 45.471
 MSRVTT_miech_test/t2v_metrics/geometric_mean_R1-R5-R10: 24.759072278619197
 MSRVTT_miech_test/v2t_metrics/R1: 9.2
 MSRVTT_miech_test/v2t_metrics/R5: 32.0
 MSRVTT_miech_test/v2t_metrics/R10: 46.1
 MSRVTT_miech_test/v2t_metrics/R50: 79.9
 MSRVTT_miech_test/v2t_metrics/MedR: 12.5
 MSRVTT_miech_test/v2t_metrics/MeanR: 43.36
 MSRVTT_miech_test/v2t_metrics/geometric_mean_R1-R5-R10: 23.853177706266948
 mnt_best       : 24.759072278619197
 not_improved_count: 0
Train Epoch: 13 [1/250 128/32000 (0%)] Loss: 1.97115 (semantic_loss: 0.02082, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=31.11162 
Train Epoch: 13 [12/250 1536/32000 (5%)] Loss: 1.97287 (semantic_loss: 0.02255, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.39862 
Train Epoch: 13 [23/250 2944/32000 (9%)] Loss: 1.97021 (semantic_loss: 0.01988, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.40814 
Train Epoch: 13 [34/250 4352/32000 (14%)] Loss: 1.97070 (semantic_loss: 0.02038, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.34990 
Train Epoch: 13 [45/250 5760/32000 (18%)] Loss: 1.97121 (semantic_loss: 0.02187, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.39229 
Train Epoch: 13 [56/250 7168/32000 (22%)] Loss: 1.97105 (semantic_loss: 0.02170, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.35933 
Train Epoch: 13 [67/250 8576/32000 (27%)] Loss: 1.97078 (semantic_loss: 0.02045, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.32792 
Train Epoch: 13 [78/250 9984/32000 (31%)] Loss: 1.97055 (semantic_loss: 0.02120, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.33645 
Train Epoch: 13 [89/250 11392/32000 (36%)] Loss: 1.97162 (semantic_loss: 0.02129, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.41574 
Train Epoch: 13 [100/250 12800/32000 (40%)] Loss: 1.97340 (semantic_loss: 0.02308, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.34034 
Train Epoch: 13 [111/250 14208/32000 (44%)] Loss: 1.97132 (semantic_loss: 0.02099, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.34061 
Train Epoch: 13 [122/250 15616/32000 (49%)] Loss: 1.97148 (semantic_loss: 0.02115, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.33555 
Train Epoch: 13 [133/250 17024/32000 (53%)] Loss: 1.97160 (semantic_loss: 0.02127, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.61017 
Train Epoch: 13 [144/250 18432/32000 (58%)] Loss: 1.97108 (semantic_loss: 0.02173, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=2.58174 
Train Epoch: 13 [155/250 19840/32000 (62%)] Loss: 1.97085 (semantic_loss: 0.02052, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.39252 
Train Epoch: 13 [166/250 21248/32000 (66%)] Loss: 1.97025 (semantic_loss: 0.02090, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.40233 
Train Epoch: 13 [177/250 22656/32000 (71%)] Loss: 1.97289 (semantic_loss: 0.02158, quant_loss: 1.95117, bit_balance_loss: 0.00013) batch_time=0.37250 
Train Epoch: 13 [188/250 24064/32000 (75%)] Loss: 1.97272 (semantic_loss: 0.02239, quant_loss: 1.95020, bit_balance_loss: 0.00014) batch_time=0.35900 
Train Epoch: 13 [199/250 25472/32000 (80%)] Loss: 1.97182 (semantic_loss: 0.02247, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=2.04965 
Train Epoch: 13 [210/250 26880/32000 (84%)] Loss: 1.97265 (semantic_loss: 0.02233, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.32829 
Train Epoch: 13 [221/250 28288/32000 (88%)] Loss: 1.97117 (semantic_loss: 0.02085, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.40577 
Train Epoch: 13 [232/250 29696/32000 (93%)] Loss: 1.96964 (semantic_loss: 0.01931, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.42797 
Train Epoch: 13 [243/250 31104/32000 (97%)] Loss: 1.97014 (semantic_loss: 0.01982, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.33581 
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/DCMH_MSRVTT_1kB/checkpoint-epoch13.pth ...
Done in 3.962s
Updating 'best' checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/DCMH_MSRVTT_1kB/checkpoint-epoch13.pth ...
Done in 7.863s
removing stale ckpt [epoch 12] [took 0.00s]
 epoch          : 13
 loss           : 1.9713735547065734
 learning_rate  : 2.7018004383131832e-05
 n_samples      : 416000
 n_steps        : 3250
 MSRVTT_miech_test/t2v_metrics/R1: 10.8
 MSRVTT_miech_test/t2v_metrics/R5: 33.5
 MSRVTT_miech_test/t2v_metrics/R10: 49.0
 MSRVTT_miech_test/t2v_metrics/R50: 79.2
 MSRVTT_miech_test/t2v_metrics/MedR: 11.0
 MSRVTT_miech_test/t2v_metrics/MeanR: 45.3075
 MSRVTT_miech_test/t2v_metrics/geometric_mean_R1-R5-R10: 26.074833715138542
 MSRVTT_miech_test/v2t_metrics/R1: 11.4
 MSRVTT_miech_test/v2t_metrics/R5: 33.8
 MSRVTT_miech_test/v2t_metrics/R10: 47.8
 MSRVTT_miech_test/v2t_metrics/R50: 80.9
 MSRVTT_miech_test/v2t_metrics/MedR: 12.0
 MSRVTT_miech_test/v2t_metrics/MeanR: 43.2615
 MSRVTT_miech_test/v2t_metrics/geometric_mean_R1-R5-R10: 26.40886983868912
 mnt_best       : 26.074833715138542
 not_improved_count: 0
Train Epoch: 14 [1/250 128/32000 (0%)] Loss: 1.96951 (semantic_loss: 0.01918, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=40.80997 
Train Epoch: 14 [12/250 1536/32000 (5%)] Loss: 1.97216 (semantic_loss: 0.02184, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.32393 
Train Epoch: 14 [23/250 2944/32000 (9%)] Loss: 1.97165 (semantic_loss: 0.02132, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.33337 
Train Epoch: 14 [34/250 4352/32000 (14%)] Loss: 1.97150 (semantic_loss: 0.02117, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.33199 
Train Epoch: 14 [45/250 5760/32000 (18%)] Loss: 1.97032 (semantic_loss: 0.01999, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.45858 
Train Epoch: 14 [56/250 7168/32000 (22%)] Loss: 1.97148 (semantic_loss: 0.02212, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.42401 
Train Epoch: 14 [67/250 8576/32000 (27%)] Loss: 1.97012 (semantic_loss: 0.01979, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.38035 
Train Epoch: 14 [78/250 9984/32000 (31%)] Loss: 1.97127 (semantic_loss: 0.02192, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.33909 
Train Epoch: 14 [89/250 11392/32000 (36%)] Loss: 1.97216 (semantic_loss: 0.02183, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.32976 
Train Epoch: 14 [100/250 12800/32000 (40%)] Loss: 1.97172 (semantic_loss: 0.02140, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.32518 
Train Epoch: 14 [111/250 14208/32000 (44%)] Loss: 1.97198 (semantic_loss: 0.02166, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.34867 
Train Epoch: 14 [122/250 15616/32000 (49%)] Loss: 1.96958 (semantic_loss: 0.02023, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.49641 
Train Epoch: 14 [133/250 17024/32000 (53%)] Loss: 1.97137 (semantic_loss: 0.02104, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.35963 
Train Epoch: 14 [144/250 18432/32000 (58%)] Loss: 1.96983 (semantic_loss: 0.01950, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.38423 
Train Epoch: 14 [155/250 19840/32000 (62%)] Loss: 1.97245 (semantic_loss: 0.02212, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.32452 
Train Epoch: 14 [166/250 21248/32000 (66%)] Loss: 1.97112 (semantic_loss: 0.02080, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.32558 
Train Epoch: 14 [177/250 22656/32000 (71%)] Loss: 1.97155 (semantic_loss: 0.02122, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.36438 
Train Epoch: 14 [188/250 24064/32000 (75%)] Loss: 1.96963 (semantic_loss: 0.02027, quant_loss: 1.94922, bit_balance_loss: 0.00014) batch_time=1.25540 
Train Epoch: 14 [199/250 25472/32000 (80%)] Loss: 1.97156 (semantic_loss: 0.02124, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.36561 
Train Epoch: 14 [210/250 26880/32000 (84%)] Loss: 1.97088 (semantic_loss: 0.02055, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.39697 
Train Epoch: 14 [221/250 28288/32000 (88%)] Loss: 1.97010 (semantic_loss: 0.02075, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.32807 
Train Epoch: 14 [232/250 29696/32000 (93%)] Loss: 1.97191 (semantic_loss: 0.02158, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.33462 
Train Epoch: 14 [243/250 31104/32000 (97%)] Loss: 1.97108 (semantic_loss: 0.02075, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.33644 
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/DCMH_MSRVTT_1kB/checkpoint-epoch14.pth ...
Done in 3.725s
removing stale ckpt [epoch 13] [took 0.00s]
 epoch          : 14
 loss           : 1.970765868663788
 learning_rate  : 2.566710416397524e-05
 n_samples      : 448000
 n_steps        : 3500
 MSRVTT_miech_test/t2v_metrics/R1: 9.9
 MSRVTT_miech_test/t2v_metrics/R5: 33.5
 MSRVTT_miech_test/t2v_metrics/R10: 49.0
 MSRVTT_miech_test/t2v_metrics/R50: 80.4
 MSRVTT_miech_test/t2v_metrics/MedR: 11.0
 MSRVTT_miech_test/t2v_metrics/MeanR: 44.9635
 MSRVTT_miech_test/t2v_metrics/geometric_mean_R1-R5-R10: 25.329426721390664
 MSRVTT_miech_test/v2t_metrics/R1: 10.9
 MSRVTT_miech_test/v2t_metrics/R5: 34.3
 MSRVTT_miech_test/v2t_metrics/R10: 48.2
 MSRVTT_miech_test/v2t_metrics/R50: 79.5
 MSRVTT_miech_test/v2t_metrics/MedR: 11.25
 MSRVTT_miech_test/v2t_metrics/MeanR: 42.662
 MSRVTT_miech_test/v2t_metrics/geometric_mean_R1-R5-R10: 26.21737576678536
 mnt_best       : 26.074833715138542
 not_improved_count: 1
Train Epoch: 15 [1/250 128/32000 (0%)] Loss: 1.96830 (semantic_loss: 0.01895, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=31.74883 
Train Epoch: 15 [12/250 1536/32000 (5%)] Loss: 1.97265 (semantic_loss: 0.02233, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.32720 
Train Epoch: 15 [23/250 2944/32000 (9%)] Loss: 1.97085 (semantic_loss: 0.02150, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.37567 
Train Epoch: 15 [34/250 4352/32000 (14%)] Loss: 1.96952 (semantic_loss: 0.01919, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.33343 
Train Epoch: 15 [45/250 5760/32000 (18%)] Loss: 1.97111 (semantic_loss: 0.02078, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.34776 
Train Epoch: 15 [56/250 7168/32000 (22%)] Loss: 1.96902 (semantic_loss: 0.01967, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.59541 
Train Epoch: 15 [67/250 8576/32000 (27%)] Loss: 1.96949 (semantic_loss: 0.01917, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.33447 
Train Epoch: 15 [78/250 9984/32000 (31%)] Loss: 1.97226 (semantic_loss: 0.02194, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.32367 
Train Epoch: 15 [89/250 11392/32000 (36%)] Loss: 1.96917 (semantic_loss: 0.01983, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.40750 
Train Epoch: 15 [100/250 12800/32000 (40%)] Loss: 1.97019 (semantic_loss: 0.02084, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.32283 
Train Epoch: 15 [111/250 14208/32000 (44%)] Loss: 1.96976 (semantic_loss: 0.01944, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.58504 
Train Epoch: 15 [122/250 15616/32000 (49%)] Loss: 1.97116 (semantic_loss: 0.01986, quant_loss: 1.95117, bit_balance_loss: 0.00013) batch_time=0.33305 
Train Epoch: 15 [133/250 17024/32000 (53%)] Loss: 1.97059 (semantic_loss: 0.02026, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.34837 
Train Epoch: 15 [144/250 18432/32000 (58%)] Loss: 1.97067 (semantic_loss: 0.02035, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.33147 
Train Epoch: 15 [155/250 19840/32000 (62%)] Loss: 1.97018 (semantic_loss: 0.02083, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.40776 
Train Epoch: 15 [166/250 21248/32000 (66%)] Loss: 1.97049 (semantic_loss: 0.02016, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.34308 
Train Epoch: 15 [177/250 22656/32000 (71%)] Loss: 1.96853 (semantic_loss: 0.01918, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.34707 
Train Epoch: 15 [188/250 24064/32000 (75%)] Loss: 1.97165 (semantic_loss: 0.02133, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.33950 
Train Epoch: 15 [199/250 25472/32000 (80%)] Loss: 1.97044 (semantic_loss: 0.02012, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.33290 
Train Epoch: 15 [210/250 26880/32000 (84%)] Loss: 1.96992 (semantic_loss: 0.01959, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.33055 
Train Epoch: 15 [221/250 28288/32000 (88%)] Loss: 1.97146 (semantic_loss: 0.02211, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.43616 
Train Epoch: 15 [232/250 29696/32000 (93%)] Loss: 1.97155 (semantic_loss: 0.02123, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.36746 
Train Epoch: 15 [243/250 31104/32000 (97%)] Loss: 1.97095 (semantic_loss: 0.02160, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.32728 
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/DCMH_MSRVTT_1kB/checkpoint-epoch15.pth ...
Done in 4.391s
removing stale ckpt [epoch 14] [took 0.01s]
 epoch          : 15
 loss           : 1.97039026594162
 learning_rate  : 2.4383748955776477e-05
 n_samples      : 480000
 n_steps        : 3750
 MSRVTT_miech_test/t2v_metrics/R1: 9.8
 MSRVTT_miech_test/t2v_metrics/R5: 35.7
 MSRVTT_miech_test/t2v_metrics/R10: 49.8
 MSRVTT_miech_test/t2v_metrics/R50: 80.2
 MSRVTT_miech_test/t2v_metrics/MedR: 11.0
 MSRVTT_miech_test/t2v_metrics/MeanR: 43.3645
 MSRVTT_miech_test/t2v_metrics/geometric_mean_R1-R5-R10: 25.92435012150689
 MSRVTT_miech_test/v2t_metrics/R1: 10.7
 MSRVTT_miech_test/v2t_metrics/R5: 34.0
 MSRVTT_miech_test/v2t_metrics/R10: 48.9
 MSRVTT_miech_test/v2t_metrics/R50: 81.2
 MSRVTT_miech_test/v2t_metrics/MedR: 11.0
 MSRVTT_miech_test/v2t_metrics/MeanR: 41.789
 MSRVTT_miech_test/v2t_metrics/geometric_mean_R1-R5-R10: 26.10500924097413
 mnt_best       : 26.074833715138542
 not_improved_count: 2
Train Epoch: 16 [1/250 128/32000 (0%)] Loss: 1.96929 (semantic_loss: 0.01896, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=30.86122 
Train Epoch: 16 [12/250 1536/32000 (5%)] Loss: 1.97031 (semantic_loss: 0.01998, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.32998 
Train Epoch: 16 [23/250 2944/32000 (9%)] Loss: 1.97022 (semantic_loss: 0.01990, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.34120 
Train Epoch: 16 [34/250 4352/32000 (14%)] Loss: 1.96987 (semantic_loss: 0.01955, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.32595 
Train Epoch: 16 [45/250 5760/32000 (18%)] Loss: 1.97013 (semantic_loss: 0.01980, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.47427 
Train Epoch: 16 [56/250 7168/32000 (22%)] Loss: 1.96975 (semantic_loss: 0.02040, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.40131 
Train Epoch: 16 [67/250 8576/32000 (27%)] Loss: 1.96938 (semantic_loss: 0.02003, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=1.02665 
Train Epoch: 16 [78/250 9984/32000 (31%)] Loss: 1.97037 (semantic_loss: 0.02103, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.35007 
Train Epoch: 16 [89/250 11392/32000 (36%)] Loss: 1.97196 (semantic_loss: 0.02163, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.35366 
Train Epoch: 16 [100/250 12800/32000 (40%)] Loss: 1.97118 (semantic_loss: 0.02086, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.64794 
Train Epoch: 16 [111/250 14208/32000 (44%)] Loss: 1.97084 (semantic_loss: 0.02052, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.40484 
Train Epoch: 16 [122/250 15616/32000 (49%)] Loss: 1.97059 (semantic_loss: 0.02027, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.37889 
Train Epoch: 16 [133/250 17024/32000 (53%)] Loss: 1.96995 (semantic_loss: 0.02060, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.33688 
Train Epoch: 16 [144/250 18432/32000 (58%)] Loss: 1.97024 (semantic_loss: 0.01992, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=1.56281 
Train Epoch: 16 [155/250 19840/32000 (62%)] Loss: 1.97007 (semantic_loss: 0.01975, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.32295 
Train Epoch: 16 [166/250 21248/32000 (66%)] Loss: 1.97270 (semantic_loss: 0.02238, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.34678 
Train Epoch: 16 [177/250 22656/32000 (71%)] Loss: 1.96920 (semantic_loss: 0.01985, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.33039 
Train Epoch: 16 [188/250 24064/32000 (75%)] Loss: 1.96744 (semantic_loss: 0.01809, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.48878 
Train Epoch: 16 [199/250 25472/32000 (80%)] Loss: 1.96921 (semantic_loss: 0.01987, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.35155 
Train Epoch: 16 [210/250 26880/32000 (84%)] Loss: 1.97169 (semantic_loss: 0.02137, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.38816 
Train Epoch: 16 [221/250 28288/32000 (88%)] Loss: 1.96955 (semantic_loss: 0.01922, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.34375 
Train Epoch: 16 [232/250 29696/32000 (93%)] Loss: 1.97139 (semantic_loss: 0.02106, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.33255 
Train Epoch: 16 [243/250 31104/32000 (97%)] Loss: 1.96939 (semantic_loss: 0.02004, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.32111 
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/DCMH_MSRVTT_1kB/checkpoint-epoch16.pth ...
Done in 3.870s
Updating 'best' checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/DCMH_MSRVTT_1kB/checkpoint-epoch16.pth ...
Done in 13.042s
removing stale ckpt [epoch 15] [took 0.02s]
 epoch          : 16
 loss           : 1.9698785276412965
 learning_rate  : 2.3164561507987653e-05
 n_samples      : 512000
 n_steps        : 4000
 MSRVTT_miech_test/t2v_metrics/R1: 11.1
 MSRVTT_miech_test/t2v_metrics/R5: 35.7
 MSRVTT_miech_test/t2v_metrics/R10: 51.0
 MSRVTT_miech_test/t2v_metrics/R50: 80.9
 MSRVTT_miech_test/t2v_metrics/MedR: 10.0
 MSRVTT_miech_test/t2v_metrics/MeanR: 43.172
 MSRVTT_miech_test/t2v_metrics/geometric_mean_R1-R5-R10: 27.238746861562518
 MSRVTT_miech_test/v2t_metrics/R1: 11.0
 MSRVTT_miech_test/v2t_metrics/R5: 37.3
 MSRVTT_miech_test/v2t_metrics/R10: 51.3
 MSRVTT_miech_test/v2t_metrics/R50: 81.3
 MSRVTT_miech_test/v2t_metrics/MedR: 10.0
 MSRVTT_miech_test/v2t_metrics/MeanR: 41.268
 MSRVTT_miech_test/v2t_metrics/geometric_mean_R1-R5-R10: 27.610416673004533
 mnt_best       : 27.238746861562518
 not_improved_count: 0
Train Epoch: 17 [1/250 128/32000 (0%)] Loss: 1.96889 (semantic_loss: 0.01954, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=37.85712 
Train Epoch: 17 [12/250 1536/32000 (5%)] Loss: 1.97082 (semantic_loss: 0.02050, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.34056 
Train Epoch: 17 [23/250 2944/32000 (9%)] Loss: 1.96982 (semantic_loss: 0.01950, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.33896 
Train Epoch: 17 [34/250 4352/32000 (14%)] Loss: 1.96838 (semantic_loss: 0.01903, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.38920 
Train Epoch: 17 [45/250 5760/32000 (18%)] Loss: 1.96916 (semantic_loss: 0.01982, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.39173 
Train Epoch: 17 [56/250 7168/32000 (22%)] Loss: 1.97014 (semantic_loss: 0.01982, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.32602 
Train Epoch: 17 [67/250 8576/32000 (27%)] Loss: 1.97059 (semantic_loss: 0.01929, quant_loss: 1.95117, bit_balance_loss: 0.00013) batch_time=1.36047 
Train Epoch: 17 [78/250 9984/32000 (31%)] Loss: 1.96849 (semantic_loss: 0.01914, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.32536 
Train Epoch: 17 [89/250 11392/32000 (36%)] Loss: 1.96938 (semantic_loss: 0.01906, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.32634 
Train Epoch: 17 [100/250 12800/32000 (40%)] Loss: 1.96906 (semantic_loss: 0.01874, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.32941 
Train Epoch: 17 [111/250 14208/32000 (44%)] Loss: 1.96899 (semantic_loss: 0.01964, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.49917 
Train Epoch: 17 [122/250 15616/32000 (49%)] Loss: 1.97191 (semantic_loss: 0.02159, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.35301 
Train Epoch: 17 [133/250 17024/32000 (53%)] Loss: 1.96888 (semantic_loss: 0.01856, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.38050 
Train Epoch: 17 [144/250 18432/32000 (58%)] Loss: 1.96990 (semantic_loss: 0.02055, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.32289 
Train Epoch: 17 [155/250 19840/32000 (62%)] Loss: 1.97097 (semantic_loss: 0.02065, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.33162 
Train Epoch: 17 [166/250 21248/32000 (66%)] Loss: 1.96868 (semantic_loss: 0.01933, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.33548 
Train Epoch: 17 [177/250 22656/32000 (71%)] Loss: 1.96806 (semantic_loss: 0.01871, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.33818 
Train Epoch: 17 [188/250 24064/32000 (75%)] Loss: 1.97089 (semantic_loss: 0.02056, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.45237 
Train Epoch: 17 [199/250 25472/32000 (80%)] Loss: 1.96827 (semantic_loss: 0.01892, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.35465 
Train Epoch: 17 [210/250 26880/32000 (84%)] Loss: 1.97006 (semantic_loss: 0.01974, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.39198 
Train Epoch: 17 [221/250 28288/32000 (88%)] Loss: 1.96919 (semantic_loss: 0.01886, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.34614 
Train Epoch: 17 [232/250 29696/32000 (93%)] Loss: 1.96974 (semantic_loss: 0.01942, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.37149 
Train Epoch: 17 [243/250 31104/32000 (97%)] Loss: 1.96853 (semantic_loss: 0.01821, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.35796 
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/DCMH_MSRVTT_1kB/checkpoint-epoch17.pth ...
Done in 4.219s
removing stale ckpt [epoch 16] [took 0.00s]
 epoch          : 17
 loss           : 1.9694047727584838
 learning_rate  : 2.2006333432588268e-05
 n_samples      : 544000
 n_steps        : 4250
 MSRVTT_miech_test/t2v_metrics/R1: 10.2
 MSRVTT_miech_test/t2v_metrics/R5: 35.7
 MSRVTT_miech_test/t2v_metrics/R10: 51.7
 MSRVTT_miech_test/t2v_metrics/R50: 79.9
 MSRVTT_miech_test/t2v_metrics/MedR: 10.0
 MSRVTT_miech_test/t2v_metrics/MeanR: 45.23
 MSRVTT_miech_test/t2v_metrics/geometric_mean_R1-R5-R10: 26.602327985146182
 MSRVTT_miech_test/v2t_metrics/R1: 11.6
 MSRVTT_miech_test/v2t_metrics/R5: 36.6
 MSRVTT_miech_test/v2t_metrics/R10: 50.9
 MSRVTT_miech_test/v2t_metrics/R50: 81.1
 MSRVTT_miech_test/v2t_metrics/MedR: 10.0
 MSRVTT_miech_test/v2t_metrics/MeanR: 42.5075
 MSRVTT_miech_test/v2t_metrics/geometric_mean_R1-R5-R10: 27.85387478896971
 mnt_best       : 27.238746861562518
 not_improved_count: 1
Train Epoch: 18 [1/250 128/32000 (0%)] Loss: 1.96893 (semantic_loss: 0.01860, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=30.17766 
Train Epoch: 18 [12/250 1536/32000 (5%)] Loss: 1.96819 (semantic_loss: 0.01884, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.37093 
Train Epoch: 18 [23/250 2944/32000 (9%)] Loss: 1.97009 (semantic_loss: 0.01976, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.36641 
Train Epoch: 18 [34/250 4352/32000 (14%)] Loss: 1.96935 (semantic_loss: 0.01903, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.36577 
Train Epoch: 18 [45/250 5760/32000 (18%)] Loss: 1.96971 (semantic_loss: 0.01939, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.33502 
Train Epoch: 18 [56/250 7168/32000 (22%)] Loss: 1.97213 (semantic_loss: 0.02181, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.32090 
Train Epoch: 18 [67/250 8576/32000 (27%)] Loss: 1.96856 (semantic_loss: 0.01824, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=1.60300 
Train Epoch: 18 [78/250 9984/32000 (31%)] Loss: 1.96784 (semantic_loss: 0.01751, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.51401 
Train Epoch: 18 [89/250 11392/32000 (36%)] Loss: 1.96969 (semantic_loss: 0.01937, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.41997 
Train Epoch: 18 [100/250 12800/32000 (40%)] Loss: 1.96895 (semantic_loss: 0.01863, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.34723 
Train Epoch: 18 [111/250 14208/32000 (44%)] Loss: 1.96951 (semantic_loss: 0.02016, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.35430 
Train Epoch: 18 [122/250 15616/32000 (49%)] Loss: 1.96948 (semantic_loss: 0.01916, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.33733 
Train Epoch: 18 [133/250 17024/32000 (53%)] Loss: 1.96928 (semantic_loss: 0.01993, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=2.37684 
Train Epoch: 18 [144/250 18432/32000 (58%)] Loss: 1.96863 (semantic_loss: 0.01929, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.33740 
Train Epoch: 18 [155/250 19840/32000 (62%)] Loss: 1.97083 (semantic_loss: 0.02051, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.36850 
Train Epoch: 18 [166/250 21248/32000 (66%)] Loss: 1.97057 (semantic_loss: 0.02025, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.35221 
Train Epoch: 18 [177/250 22656/32000 (71%)] Loss: 1.96979 (semantic_loss: 0.01947, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.39222 
Train Epoch: 18 [188/250 24064/32000 (75%)] Loss: 1.96921 (semantic_loss: 0.01889, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.33190 
Train Epoch: 18 [199/250 25472/32000 (80%)] Loss: 1.96805 (semantic_loss: 0.01870, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.35653 
Train Epoch: 18 [210/250 26880/32000 (84%)] Loss: 1.96652 (semantic_loss: 0.01717, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.34284 
Train Epoch: 18 [221/250 28288/32000 (88%)] Loss: 1.96854 (semantic_loss: 0.01822, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.40896 
Train Epoch: 18 [232/250 29696/32000 (93%)] Loss: 1.96850 (semantic_loss: 0.01817, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.33218 
Train Epoch: 18 [243/250 31104/32000 (97%)] Loss: 1.96935 (semantic_loss: 0.02000, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.37032 
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/DCMH_MSRVTT_1kB/checkpoint-epoch18.pth ...
Done in 4.161s
Updating 'best' checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/DCMH_MSRVTT_1kB/checkpoint-epoch18.pth ...
Done in 8.016s
removing stale ckpt [epoch 17] [took 0.00s]
 epoch          : 18
 loss           : 1.9690673909187317
 learning_rate  : 2.0906016760958855e-05
 n_samples      : 576000
 n_steps        : 4500
 MSRVTT_miech_test/t2v_metrics/R1: 11.6
 MSRVTT_miech_test/t2v_metrics/R5: 36.1
 MSRVTT_miech_test/t2v_metrics/R10: 50.2
 MSRVTT_miech_test/t2v_metrics/R50: 80.3
 MSRVTT_miech_test/t2v_metrics/MedR: 10.5
 MSRVTT_miech_test/t2v_metrics/MeanR: 44.4055
 MSRVTT_miech_test/t2v_metrics/geometric_mean_R1-R5-R10: 27.598764209878706
 MSRVTT_miech_test/v2t_metrics/R1: 11.9
 MSRVTT_miech_test/v2t_metrics/R5: 37.4
 MSRVTT_miech_test/v2t_metrics/R10: 52.2
 MSRVTT_miech_test/v2t_metrics/R50: 80.7
 MSRVTT_miech_test/v2t_metrics/MedR: 9.5
 MSRVTT_miech_test/v2t_metrics/MeanR: 41.8815
 MSRVTT_miech_test/v2t_metrics/geometric_mean_R1-R5-R10: 28.534024000420654
 mnt_best       : 27.598764209878706
 not_improved_count: 0
Train Epoch: 19 [1/250 128/32000 (0%)] Loss: 1.97032 (semantic_loss: 0.01902, quant_loss: 1.95117, bit_balance_loss: 0.00013) batch_time=39.52680 
Train Epoch: 19 [12/250 1536/32000 (5%)] Loss: 1.96780 (semantic_loss: 0.01748, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.33611 
Train Epoch: 19 [23/250 2944/32000 (9%)] Loss: 1.96994 (semantic_loss: 0.01962, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.40509 
Train Epoch: 19 [34/250 4352/32000 (14%)] Loss: 1.96853 (semantic_loss: 0.01821, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.41562 
Train Epoch: 19 [45/250 5760/32000 (18%)] Loss: 1.96909 (semantic_loss: 0.01876, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.32936 
Train Epoch: 19 [56/250 7168/32000 (22%)] Loss: 1.96760 (semantic_loss: 0.01727, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.34640 
Train Epoch: 19 [67/250 8576/32000 (27%)] Loss: 1.96940 (semantic_loss: 0.01810, quant_loss: 1.95117, bit_balance_loss: 0.00013) batch_time=0.33740 
Train Epoch: 19 [78/250 9984/32000 (31%)] Loss: 1.96866 (semantic_loss: 0.01834, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.32920 
Train Epoch: 19 [89/250 11392/32000 (36%)] Loss: 1.96940 (semantic_loss: 0.01908, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.35386 
Train Epoch: 19 [100/250 12800/32000 (40%)] Loss: 1.97028 (semantic_loss: 0.01995, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.42203 
Train Epoch: 19 [111/250 14208/32000 (44%)] Loss: 1.96729 (semantic_loss: 0.01697, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.39641 
Train Epoch: 19 [122/250 15616/32000 (49%)] Loss: 1.96825 (semantic_loss: 0.01792, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.36647 
Train Epoch: 19 [133/250 17024/32000 (53%)] Loss: 1.96941 (semantic_loss: 0.01909, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.33147 
Train Epoch: 19 [144/250 18432/32000 (58%)] Loss: 1.96862 (semantic_loss: 0.01830, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.32617 
Train Epoch: 19 [155/250 19840/32000 (62%)] Loss: 1.96886 (semantic_loss: 0.01854, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.36218 
Train Epoch: 19 [166/250 21248/32000 (66%)] Loss: 1.96821 (semantic_loss: 0.01789, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.49087 
Train Epoch: 19 [177/250 22656/32000 (71%)] Loss: 1.96921 (semantic_loss: 0.01889, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.41262 
Train Epoch: 19 [188/250 24064/32000 (75%)] Loss: 1.97031 (semantic_loss: 0.01999, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.68401 
Train Epoch: 19 [199/250 25472/32000 (80%)] Loss: 1.96835 (semantic_loss: 0.01803, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.36030 
Train Epoch: 19 [210/250 26880/32000 (84%)] Loss: 1.96751 (semantic_loss: 0.01718, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.32340 
Train Epoch: 19 [221/250 28288/32000 (88%)] Loss: 1.96838 (semantic_loss: 0.01806, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.32400 
Train Epoch: 19 [232/250 29696/32000 (93%)] Loss: 1.96885 (semantic_loss: 0.01853, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.32796 
Train Epoch: 19 [243/250 31104/32000 (97%)] Loss: 1.97035 (semantic_loss: 0.02003, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.37569 
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/DCMH_MSRVTT_1kB/checkpoint-epoch19.pth ...
Done in 4.711s
Updating 'best' checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/DCMH_MSRVTT_1kB/checkpoint-epoch19.pth ...
Done in 9.181s
removing stale ckpt [epoch 18] [took 0.09s]
 epoch          : 19
 loss           : 1.9687640919685363
 learning_rate  : 1.986071592291091e-05
 n_samples      : 608000
 n_steps        : 4750
 MSRVTT_miech_test/t2v_metrics/R1: 12.3
 MSRVTT_miech_test/t2v_metrics/R5: 36.6
 MSRVTT_miech_test/t2v_metrics/R10: 50.1
 MSRVTT_miech_test/t2v_metrics/R50: 80.2
 MSRVTT_miech_test/t2v_metrics/MedR: 10.25
 MSRVTT_miech_test/t2v_metrics/MeanR: 45.9435
 MSRVTT_miech_test/t2v_metrics/geometric_mean_R1-R5-R10: 28.253655203549297
 MSRVTT_miech_test/v2t_metrics/R1: 11.9
 MSRVTT_miech_test/v2t_metrics/R5: 36.3
 MSRVTT_miech_test/v2t_metrics/R10: 50.8
 MSRVTT_miech_test/v2t_metrics/R50: 81.1
 MSRVTT_miech_test/v2t_metrics/MedR: 10.0
 MSRVTT_miech_test/v2t_metrics/MeanR: 43.3825
 MSRVTT_miech_test/v2t_metrics/geometric_mean_R1-R5-R10: 27.996630546925292
 mnt_best       : 28.253655203549297
 not_improved_count: 0
Train Epoch: 20 [1/250 128/32000 (0%)] Loss: 1.96840 (semantic_loss: 0.01807, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=30.74581 
Train Epoch: 20 [12/250 1536/32000 (5%)] Loss: 1.96894 (semantic_loss: 0.01862, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.32939 
Train Epoch: 20 [23/250 2944/32000 (9%)] Loss: 1.96996 (semantic_loss: 0.01964, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.96987 
Train Epoch: 20 [34/250 4352/32000 (14%)] Loss: 1.96858 (semantic_loss: 0.01826, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.33966 
Train Epoch: 20 [45/250 5760/32000 (18%)] Loss: 1.96750 (semantic_loss: 0.01815, quant_loss: 1.94922, bit_balance_loss: 0.00012) batch_time=0.47149 
Train Epoch: 20 [56/250 7168/32000 (22%)] Loss: 1.96782 (semantic_loss: 0.01750, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.45893 
Train Epoch: 20 [67/250 8576/32000 (27%)] Loss: 1.96919 (semantic_loss: 0.01887, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=2.16162 
Train Epoch: 20 [78/250 9984/32000 (31%)] Loss: 1.96948 (semantic_loss: 0.01916, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.32805 
Train Epoch: 20 [89/250 11392/32000 (36%)] Loss: 1.96827 (semantic_loss: 0.01892, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.58692 
Train Epoch: 20 [100/250 12800/32000 (40%)] Loss: 1.96707 (semantic_loss: 0.01675, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.32394 
Train Epoch: 20 [111/250 14208/32000 (44%)] Loss: 1.96675 (semantic_loss: 0.01741, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.33122 
Train Epoch: 20 [122/250 15616/32000 (49%)] Loss: 1.96674 (semantic_loss: 0.01739, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.45274 
Train Epoch: 20 [133/250 17024/32000 (53%)] Loss: 1.96935 (semantic_loss: 0.01806, quant_loss: 1.95117, bit_balance_loss: 0.00012) batch_time=0.32556 
Train Epoch: 20 [144/250 18432/32000 (58%)] Loss: 1.96709 (semantic_loss: 0.01774, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.38123 
Train Epoch: 20 [155/250 19840/32000 (62%)] Loss: 1.96962 (semantic_loss: 0.01930, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.33435 
Train Epoch: 20 [166/250 21248/32000 (66%)] Loss: 1.96814 (semantic_loss: 0.01879, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.34352 
Train Epoch: 20 [177/250 22656/32000 (71%)] Loss: 1.96858 (semantic_loss: 0.01826, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.32301 
Train Epoch: 20 [188/250 24064/32000 (75%)] Loss: 1.96746 (semantic_loss: 0.01811, quant_loss: 1.94922, bit_balance_loss: 0.00012) batch_time=0.33038 
Train Epoch: 20 [199/250 25472/32000 (80%)] Loss: 1.96932 (semantic_loss: 0.01900, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=2.00731 
Train Epoch: 20 [210/250 26880/32000 (84%)] Loss: 1.96885 (semantic_loss: 0.01853, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.35337 
Train Epoch: 20 [221/250 28288/32000 (88%)] Loss: 1.96867 (semantic_loss: 0.01737, quant_loss: 1.95117, bit_balance_loss: 0.00013) batch_time=0.33059 
Train Epoch: 20 [232/250 29696/32000 (93%)] Loss: 1.96951 (semantic_loss: 0.01920, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.32914 
Train Epoch: 20 [243/250 31104/32000 (97%)] Loss: 1.96765 (semantic_loss: 0.01733, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.33378 
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/DCMH_MSRVTT_1kB/checkpoint-epoch20.pth ...
Done in 3.731s
Updating 'best' checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/DCMH_MSRVTT_1kB/checkpoint-epoch20.pth ...
Done in 7.600s
removing stale ckpt [epoch 19] [took 0.01s]
 epoch          : 20
 loss           : 1.968388485431671
 learning_rate  : 1.8867680126765363e-05
 n_samples      : 640000
 n_steps        : 5000
 MSRVTT_miech_test/t2v_metrics/R1: 13.1
 MSRVTT_miech_test/t2v_metrics/R5: 38.5
 MSRVTT_miech_test/t2v_metrics/R10: 53.8
 MSRVTT_miech_test/t2v_metrics/R50: 82.6
 MSRVTT_miech_test/t2v_metrics/MedR: 9.0
 MSRVTT_miech_test/t2v_metrics/MeanR: 43.9855
 MSRVTT_miech_test/t2v_metrics/geometric_mean_R1-R5-R10: 30.049558826416618
 MSRVTT_miech_test/v2t_metrics/R1: 13.9
 MSRVTT_miech_test/v2t_metrics/R5: 39.5
 MSRVTT_miech_test/v2t_metrics/R10: 52.6
 MSRVTT_miech_test/v2t_metrics/R50: 81.8
 MSRVTT_miech_test/v2t_metrics/MedR: 9.0
 MSRVTT_miech_test/v2t_metrics/MeanR: 41.408
 MSRVTT_miech_test/v2t_metrics/geometric_mean_R1-R5-R10: 30.680743511097106
 mnt_best       : 30.049558826416618
 not_improved_count: 0
Train Epoch: 21 [1/250 128/32000 (0%)] Loss: 1.96826 (semantic_loss: 0.01891, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=31.98014 
Train Epoch: 21 [12/250 1536/32000 (5%)] Loss: 1.96748 (semantic_loss: 0.01814, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.51790 
Train Epoch: 21 [23/250 2944/32000 (9%)] Loss: 1.96706 (semantic_loss: 0.01771, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.33668 
Train Epoch: 21 [34/250 4352/32000 (14%)] Loss: 1.96783 (semantic_loss: 0.01751, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.40239 
Train Epoch: 21 [45/250 5760/32000 (18%)] Loss: 1.96847 (semantic_loss: 0.01913, quant_loss: 1.94922, bit_balance_loss: 0.00012) batch_time=0.32495 
Train Epoch: 21 [56/250 7168/32000 (22%)] Loss: 1.96814 (semantic_loss: 0.01781, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.44057 
Train Epoch: 21 [67/250 8576/32000 (27%)] Loss: 1.96519 (semantic_loss: 0.01585, quant_loss: 1.94922, bit_balance_loss: 0.00012) batch_time=0.33588 
Train Epoch: 21 [78/250 9984/32000 (31%)] Loss: 1.96774 (semantic_loss: 0.01742, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.39342 
Train Epoch: 21 [89/250 11392/32000 (36%)] Loss: 1.96630 (semantic_loss: 0.01696, quant_loss: 1.94922, bit_balance_loss: 0.00012) batch_time=0.33090 
Train Epoch: 21 [100/250 12800/32000 (40%)] Loss: 1.96895 (semantic_loss: 0.01863, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.33164 
Train Epoch: 21 [111/250 14208/32000 (44%)] Loss: 1.96817 (semantic_loss: 0.01785, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.34473 
Train Epoch: 21 [122/250 15616/32000 (49%)] Loss: 1.96836 (semantic_loss: 0.01804, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.32749 
Train Epoch: 21 [133/250 17024/32000 (53%)] Loss: 1.97020 (semantic_loss: 0.01988, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.55698 
Train Epoch: 21 [144/250 18432/32000 (58%)] Loss: 1.96729 (semantic_loss: 0.01697, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=2.22726 
Train Epoch: 21 [155/250 19840/32000 (62%)] Loss: 1.96756 (semantic_loss: 0.01724, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.39283 
Train Epoch: 21 [166/250 21248/32000 (66%)] Loss: 1.96800 (semantic_loss: 0.01866, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.33575 
Train Epoch: 21 [177/250 22656/32000 (71%)] Loss: 1.96901 (semantic_loss: 0.01869, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.32449 
Train Epoch: 21 [188/250 24064/32000 (75%)] Loss: 1.96832 (semantic_loss: 0.01897, quant_loss: 1.94922, bit_balance_loss: 0.00012) batch_time=0.34790 
Train Epoch: 21 [199/250 25472/32000 (80%)] Loss: 1.96771 (semantic_loss: 0.01837, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=1.43908 
Train Epoch: 21 [210/250 26880/32000 (84%)] Loss: 1.96823 (semantic_loss: 0.01790, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.56810 
Train Epoch: 21 [221/250 28288/32000 (88%)] Loss: 1.96831 (semantic_loss: 0.01799, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.42032 
Train Epoch: 21 [232/250 29696/32000 (93%)] Loss: 1.96686 (semantic_loss: 0.01751, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.38476 
Train Epoch: 21 [243/250 31104/32000 (97%)] Loss: 1.96699 (semantic_loss: 0.01667, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.34209 
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/DCMH_MSRVTT_1kB/checkpoint-epoch21.pth ...
Done in 4.284s
removing stale ckpt [epoch 20] [took 0.00s]
 epoch          : 21
 loss           : 1.9680625190734864
 learning_rate  : 1.7924296120427095e-05
 n_samples      : 672000
 n_steps        : 5250
 MSRVTT_miech_test/t2v_metrics/R1: 10.9
 MSRVTT_miech_test/t2v_metrics/R5: 37.4
 MSRVTT_miech_test/t2v_metrics/R10: 53.5
 MSRVTT_miech_test/t2v_metrics/R50: 82.5
 MSRVTT_miech_test/t2v_metrics/MedR: 9.0
 MSRVTT_miech_test/t2v_metrics/MeanR: 43.771
 MSRVTT_miech_test/t2v_metrics/geometric_mean_R1-R5-R10: 27.939414067752743
 MSRVTT_miech_test/v2t_metrics/R1: 12.2
 MSRVTT_miech_test/v2t_metrics/R5: 38.9
 MSRVTT_miech_test/v2t_metrics/R10: 52.8
 MSRVTT_miech_test/v2t_metrics/R50: 82.6
 MSRVTT_miech_test/v2t_metrics/MedR: 9.0
 MSRVTT_miech_test/v2t_metrics/MeanR: 41.1455
 MSRVTT_miech_test/v2t_metrics/geometric_mean_R1-R5-R10: 29.262703810361906
 mnt_best       : 30.049558826416618
 not_improved_count: 1
Train Epoch: 22 [1/250 128/32000 (0%)] Loss: 1.96689 (semantic_loss: 0.01754, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=36.01601 
Train Epoch: 22 [12/250 1536/32000 (5%)] Loss: 1.96821 (semantic_loss: 0.01887, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.33117 
Train Epoch: 22 [23/250 2944/32000 (9%)] Loss: 1.96914 (semantic_loss: 0.01882, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.68344 
Train Epoch: 22 [34/250 4352/32000 (14%)] Loss: 1.96724 (semantic_loss: 0.01692, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.32962 
Train Epoch: 22 [45/250 5760/32000 (18%)] Loss: 1.96769 (semantic_loss: 0.01835, quant_loss: 1.94922, bit_balance_loss: 0.00012) batch_time=0.34085 
Train Epoch: 22 [56/250 7168/32000 (22%)] Loss: 1.96809 (semantic_loss: 0.01777, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.43318 
Train Epoch: 22 [67/250 8576/32000 (27%)] Loss: 1.96924 (semantic_loss: 0.01794, quant_loss: 1.95117, bit_balance_loss: 0.00013) batch_time=0.32512 
Train Epoch: 22 [78/250 9984/32000 (31%)] Loss: 1.96852 (semantic_loss: 0.01820, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.33029 
Train Epoch: 22 [89/250 11392/32000 (36%)] Loss: 1.96809 (semantic_loss: 0.01777, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.32874 
Train Epoch: 22 [100/250 12800/32000 (40%)] Loss: 1.96726 (semantic_loss: 0.01694, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.34275 
Train Epoch: 22 [111/250 14208/32000 (44%)] Loss: 1.96821 (semantic_loss: 0.01789, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.32914 
Train Epoch: 22 [122/250 15616/32000 (49%)] Loss: 1.96815 (semantic_loss: 0.01783, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.39900 
Train Epoch: 22 [133/250 17024/32000 (53%)] Loss: 1.96745 (semantic_loss: 0.01811, quant_loss: 1.94922, bit_balance_loss: 0.00012) batch_time=0.78273 
Train Epoch: 22 [144/250 18432/32000 (58%)] Loss: 1.96660 (semantic_loss: 0.01725, quant_loss: 1.94922, bit_balance_loss: 0.00012) batch_time=0.33827 
Train Epoch: 22 [155/250 19840/32000 (62%)] Loss: 1.96913 (semantic_loss: 0.01881, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.36600 
Train Epoch: 22 [166/250 21248/32000 (66%)] Loss: 1.96843 (semantic_loss: 0.01714, quant_loss: 1.95117, bit_balance_loss: 0.00012) batch_time=0.32527 
Train Epoch: 22 [177/250 22656/32000 (71%)] Loss: 1.96888 (semantic_loss: 0.01857, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.33135 
Train Epoch: 22 [188/250 24064/32000 (75%)] Loss: 1.96841 (semantic_loss: 0.01809, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.45014 
Train Epoch: 22 [199/250 25472/32000 (80%)] Loss: 1.96738 (semantic_loss: 0.01706, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.73427 
Train Epoch: 22 [210/250 26880/32000 (84%)] Loss: 1.96666 (semantic_loss: 0.01634, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.33084 
Train Epoch: 22 [221/250 28288/32000 (88%)] Loss: 1.96754 (semantic_loss: 0.01820, quant_loss: 1.94922, bit_balance_loss: 0.00012) batch_time=0.35651 
Train Epoch: 22 [232/250 29696/32000 (93%)] Loss: 1.96715 (semantic_loss: 0.01683, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.33254 
Train Epoch: 22 [243/250 31104/32000 (97%)] Loss: 1.96601 (semantic_loss: 0.01667, quant_loss: 1.94922, bit_balance_loss: 0.00012) batch_time=0.33325 
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/DCMH_MSRVTT_1kB/checkpoint-epoch22.pth ...
Done in 4.363s
removing stale ckpt [epoch 21] [took 0.01s]
 epoch          : 22
 loss           : 1.967717086315155
 learning_rate  : 1.702808131440574e-05
 n_samples      : 704000
 n_steps        : 5500
 MSRVTT_miech_test/t2v_metrics/R1: 12.4
 MSRVTT_miech_test/t2v_metrics/R5: 38.2
 MSRVTT_miech_test/t2v_metrics/R10: 53.2
 MSRVTT_miech_test/t2v_metrics/R50: 82.6
 MSRVTT_miech_test/t2v_metrics/MedR: 9.0
 MSRVTT_miech_test/t2v_metrics/MeanR: 42.945
 MSRVTT_miech_test/t2v_metrics/geometric_mean_R1-R5-R10: 29.317857309324616
 MSRVTT_miech_test/v2t_metrics/R1: 13.0
 MSRVTT_miech_test/v2t_metrics/R5: 37.8
 MSRVTT_miech_test/v2t_metrics/R10: 52.3
 MSRVTT_miech_test/v2t_metrics/R50: 82.5
 MSRVTT_miech_test/v2t_metrics/MedR: 9.0
 MSRVTT_miech_test/v2t_metrics/MeanR: 39.7865
 MSRVTT_miech_test/v2t_metrics/geometric_mean_R1-R5-R10: 29.51066166385056
 mnt_best       : 30.049558826416618
 not_improved_count: 2
Train Epoch: 23 [1/250 128/32000 (0%)] Loss: 1.96784 (semantic_loss: 0.01752, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=35.24003 
Train Epoch: 23 [12/250 1536/32000 (5%)] Loss: 1.96773 (semantic_loss: 0.01839, quant_loss: 1.94922, bit_balance_loss: 0.00012) batch_time=0.46285 
Train Epoch: 23 [23/250 2944/32000 (9%)] Loss: 1.96694 (semantic_loss: 0.01760, quant_loss: 1.94922, bit_balance_loss: 0.00012) batch_time=0.34873 
Train Epoch: 23 [34/250 4352/32000 (14%)] Loss: 1.96578 (semantic_loss: 0.01644, quant_loss: 1.94922, bit_balance_loss: 0.00012) batch_time=0.36157 
Train Epoch: 23 [45/250 5760/32000 (18%)] Loss: 1.96749 (semantic_loss: 0.01718, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.32560 
Train Epoch: 23 [56/250 7168/32000 (22%)] Loss: 1.96718 (semantic_loss: 0.01686, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.32292 
Train Epoch: 23 [67/250 8576/32000 (27%)] Loss: 1.96771 (semantic_loss: 0.01739, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.33079 
Train Epoch: 23 [78/250 9984/32000 (31%)] Loss: 1.96822 (semantic_loss: 0.01790, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.40325 
Train Epoch: 23 [89/250 11392/32000 (36%)] Loss: 1.96621 (semantic_loss: 0.01686, quant_loss: 1.94922, bit_balance_loss: 0.00012) batch_time=0.33672 
Train Epoch: 23 [100/250 12800/32000 (40%)] Loss: 1.96645 (semantic_loss: 0.01613, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.33127 
Train Epoch: 23 [111/250 14208/32000 (44%)] Loss: 1.96853 (semantic_loss: 0.01821, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.34449 
Train Epoch: 23 [122/250 15616/32000 (49%)] Loss: 1.96680 (semantic_loss: 0.01648, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.38815 
Train Epoch: 23 [133/250 17024/32000 (53%)] Loss: 1.96832 (semantic_loss: 0.01898, quant_loss: 1.94922, bit_balance_loss: 0.00012) batch_time=0.36427 
Train Epoch: 23 [144/250 18432/32000 (58%)] Loss: 1.96866 (semantic_loss: 0.01834, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.33360 
Train Epoch: 23 [155/250 19840/32000 (62%)] Loss: 1.96768 (semantic_loss: 0.01834, quant_loss: 1.94922, bit_balance_loss: 0.00012) batch_time=0.34184 
Train Epoch: 23 [166/250 21248/32000 (66%)] Loss: 1.96793 (semantic_loss: 0.01761, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.34728 
Train Epoch: 23 [177/250 22656/32000 (71%)] Loss: 1.96900 (semantic_loss: 0.01868, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.33021 
Train Epoch: 23 [188/250 24064/32000 (75%)] Loss: 1.96754 (semantic_loss: 0.01819, quant_loss: 1.94922, bit_balance_loss: 0.00012) batch_time=0.32740 
Train Epoch: 23 [199/250 25472/32000 (80%)] Loss: 1.96627 (semantic_loss: 0.01693, quant_loss: 1.94922, bit_balance_loss: 0.00012) batch_time=0.64774 
Train Epoch: 23 [210/250 26880/32000 (84%)] Loss: 1.96727 (semantic_loss: 0.01695, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.34612 
Train Epoch: 23 [221/250 28288/32000 (88%)] Loss: 1.96686 (semantic_loss: 0.01752, quant_loss: 1.94922, bit_balance_loss: 0.00012) batch_time=0.33396 
Train Epoch: 23 [232/250 29696/32000 (93%)] Loss: 1.96936 (semantic_loss: 0.01904, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.33009 
Train Epoch: 23 [243/250 31104/32000 (97%)] Loss: 1.96538 (semantic_loss: 0.01604, quant_loss: 1.94922, bit_balance_loss: 0.00012) batch_time=0.32449 
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/DCMH_MSRVTT_1kB/checkpoint-epoch23.pth ...
Done in 3.954s
Updating 'best' checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/DCMH_MSRVTT_1kB/checkpoint-epoch23.pth ...
Done in 7.892s
removing stale ckpt [epoch 22] [took 0.00s]
 epoch          : 23
 loss           : 1.9674580698013306
 learning_rate  : 1.6176677248685452e-05
 n_samples      : 736000
 n_steps        : 5750
 MSRVTT_miech_test/t2v_metrics/R1: 13.1
 MSRVTT_miech_test/t2v_metrics/R5: 38.7
 MSRVTT_miech_test/t2v_metrics/R10: 53.9
 MSRVTT_miech_test/t2v_metrics/R50: 82.5
 MSRVTT_miech_test/t2v_metrics/MedR: 9.0
 MSRVTT_miech_test/t2v_metrics/MeanR: 42.0175
 MSRVTT_miech_test/t2v_metrics/geometric_mean_R1-R5-R10: 30.12014155793429
 MSRVTT_miech_test/v2t_metrics/R1: 14.4
 MSRVTT_miech_test/v2t_metrics/R5: 40.2
 MSRVTT_miech_test/v2t_metrics/R10: 54.0
 MSRVTT_miech_test/v2t_metrics/R50: 82.4
 MSRVTT_miech_test/v2t_metrics/MedR: 9.0
 MSRVTT_miech_test/v2t_metrics/MeanR: 39.8425
 MSRVTT_miech_test/v2t_metrics/geometric_mean_R1-R5-R10: 31.5012244421998
 mnt_best       : 30.12014155793429
 not_improved_count: 0
Train Epoch: 24 [1/250 128/32000 (0%)] Loss: 1.96701 (semantic_loss: 0.01669, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=33.19881 
Train Epoch: 24 [12/250 1536/32000 (5%)] Loss: 1.96688 (semantic_loss: 0.01656, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.32527 
Train Epoch: 24 [23/250 2944/32000 (9%)] Loss: 1.96740 (semantic_loss: 0.01708, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.43406 
Train Epoch: 24 [34/250 4352/32000 (14%)] Loss: 1.96683 (semantic_loss: 0.01749, quant_loss: 1.94922, bit_balance_loss: 0.00012) batch_time=0.41925 
Train Epoch: 24 [45/250 5760/32000 (18%)] Loss: 1.96830 (semantic_loss: 0.01798, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.33168 
Train Epoch: 24 [56/250 7168/32000 (22%)] Loss: 1.96754 (semantic_loss: 0.01722, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.34674 
Train Epoch: 24 [67/250 8576/32000 (27%)] Loss: 1.96727 (semantic_loss: 0.01696, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.35132 
Train Epoch: 24 [78/250 9984/32000 (31%)] Loss: 1.96939 (semantic_loss: 0.01907, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.36470 
Train Epoch: 24 [89/250 11392/32000 (36%)] Loss: 1.96750 (semantic_loss: 0.01718, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.45554 
Train Epoch: 24 [100/250 12800/32000 (40%)] Loss: 1.96769 (semantic_loss: 0.01737, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.33344 
Train Epoch: 24 [111/250 14208/32000 (44%)] Loss: 1.96839 (semantic_loss: 0.01807, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.33055 
Train Epoch: 24 [122/250 15616/32000 (49%)] Loss: 1.96806 (semantic_loss: 0.01871, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.63300 
Train Epoch: 24 [133/250 17024/32000 (53%)] Loss: 1.96749 (semantic_loss: 0.01815, quant_loss: 1.94922, bit_balance_loss: 0.00012) batch_time=0.34325 
Train Epoch: 24 [144/250 18432/32000 (58%)] Loss: 1.96727 (semantic_loss: 0.01696, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=2.32690 
Train Epoch: 24 [155/250 19840/32000 (62%)] Loss: 1.96501 (semantic_loss: 0.01567, quant_loss: 1.94922, bit_balance_loss: 0.00012) batch_time=0.51873 
Train Epoch: 24 [166/250 21248/32000 (66%)] Loss: 1.96726 (semantic_loss: 0.01693, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.44446 
Train Epoch: 24 [177/250 22656/32000 (71%)] Loss: 1.96821 (semantic_loss: 0.01789, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.32189 
Train Epoch: 24 [188/250 24064/32000 (75%)] Loss: 1.96756 (semantic_loss: 0.01822, quant_loss: 1.94922, bit_balance_loss: 0.00012) batch_time=0.37936 
Train Epoch: 24 [199/250 25472/32000 (80%)] Loss: 1.96885 (semantic_loss: 0.01853, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.32747 
Train Epoch: 24 [210/250 26880/32000 (84%)] Loss: 1.96857 (semantic_loss: 0.01826, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.34540 
Train Epoch: 24 [221/250 28288/32000 (88%)] Loss: 1.96762 (semantic_loss: 0.01731, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.42910 
Train Epoch: 24 [232/250 29696/32000 (93%)] Loss: 1.96620 (semantic_loss: 0.01686, quant_loss: 1.94922, bit_balance_loss: 0.00012) batch_time=0.45188 
Train Epoch: 24 [243/250 31104/32000 (97%)] Loss: 1.96572 (semantic_loss: 0.01638, quant_loss: 1.94922, bit_balance_loss: 0.00012) batch_time=0.33019 
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/DCMH_MSRVTT_1kB/checkpoint-epoch24.pth ...
Done in 4.086s
removing stale ckpt [epoch 23] [took 0.01s]
 epoch          : 24
 loss           : 1.9673700647354126
 learning_rate  : 1.5367843386251178e-05
 n_samples      : 768000
 n_steps        : 6000
 MSRVTT_miech_test/t2v_metrics/R1: 11.5
 MSRVTT_miech_test/t2v_metrics/R5: 38.9
 MSRVTT_miech_test/t2v_metrics/R10: 54.0
 MSRVTT_miech_test/t2v_metrics/R50: 83.6
 MSRVTT_miech_test/t2v_metrics/MedR: 9.0
 MSRVTT_miech_test/t2v_metrics/MeanR: 42.9225
 MSRVTT_miech_test/t2v_metrics/geometric_mean_R1-R5-R10: 28.90771296710613
 MSRVTT_miech_test/v2t_metrics/R1: 14.4
 MSRVTT_miech_test/v2t_metrics/R5: 40.0
 MSRVTT_miech_test/v2t_metrics/R10: 54.5
 MSRVTT_miech_test/v2t_metrics/R50: 83.3
 MSRVTT_miech_test/v2t_metrics/MedR: 8.0
 MSRVTT_miech_test/v2t_metrics/MeanR: 39.994
 MSRVTT_miech_test/v2t_metrics/geometric_mean_R1-R5-R10: 31.545663176420486
 mnt_best       : 30.12014155793429
 not_improved_count: 1
Train Epoch: 25 [1/250 128/32000 (0%)] Loss: 1.96707 (semantic_loss: 0.01675, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=24.88748 
Train Epoch: 25 [12/250 1536/32000 (5%)] Loss: 1.96698 (semantic_loss: 0.01763, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.37383 
Train Epoch: 25 [23/250 2944/32000 (9%)] Loss: 1.96618 (semantic_loss: 0.01683, quant_loss: 1.94922, bit_balance_loss: 0.00012) batch_time=0.35136 
Train Epoch: 25 [34/250 4352/32000 (14%)] Loss: 1.96724 (semantic_loss: 0.01693, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=1.32677 
Train Epoch: 25 [45/250 5760/32000 (18%)] Loss: 1.96587 (semantic_loss: 0.01556, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.32773 
Train Epoch: 25 [56/250 7168/32000 (22%)] Loss: 1.96621 (semantic_loss: 0.01589, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.32074 
Train Epoch: 25 [67/250 8576/32000 (27%)] Loss: 1.96685 (semantic_loss: 0.01653, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.45538 
Train Epoch: 25 [78/250 9984/32000 (31%)] Loss: 1.96742 (semantic_loss: 0.01808, quant_loss: 1.94922, bit_balance_loss: 0.00012) batch_time=0.34571 
Train Epoch: 25 [89/250 11392/32000 (36%)] Loss: 1.96859 (semantic_loss: 0.01827, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.58472 
Train Epoch: 25 [100/250 12800/32000 (40%)] Loss: 1.96688 (semantic_loss: 0.01656, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.32118 
Train Epoch: 25 [111/250 14208/32000 (44%)] Loss: 1.96824 (semantic_loss: 0.01792, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.33382 
Train Epoch: 25 [122/250 15616/32000 (49%)] Loss: 1.96718 (semantic_loss: 0.01783, quant_loss: 1.94922, bit_balance_loss: 0.00012) batch_time=0.33151 
Train Epoch: 25 [133/250 17024/32000 (53%)] Loss: 1.96626 (semantic_loss: 0.01594, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.92036 
Train Epoch: 25 [144/250 18432/32000 (58%)] Loss: 1.96907 (semantic_loss: 0.01875, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.35450 
Train Epoch: 25 [155/250 19840/32000 (62%)] Loss: 1.96588 (semantic_loss: 0.01654, quant_loss: 1.94922, bit_balance_loss: 0.00012) batch_time=0.33146 
Train Epoch: 25 [166/250 21248/32000 (66%)] Loss: 1.96732 (semantic_loss: 0.01700, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.35533 
Train Epoch: 25 [177/250 22656/32000 (71%)] Loss: 1.96816 (semantic_loss: 0.01784, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.33832 
Train Epoch: 25 [188/250 24064/32000 (75%)] Loss: 1.96710 (semantic_loss: 0.01775, quant_loss: 1.94922, bit_balance_loss: 0.00012) batch_time=0.34265 
Train Epoch: 25 [199/250 25472/32000 (80%)] Loss: 1.96748 (semantic_loss: 0.01717, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.34768 
Train Epoch: 25 [210/250 26880/32000 (84%)] Loss: 1.96657 (semantic_loss: 0.01625, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.42268 
Train Epoch: 25 [221/250 28288/32000 (88%)] Loss: 1.96842 (semantic_loss: 0.01810, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=0.33461 
Train Epoch: 25 [232/250 29696/32000 (93%)] Loss: 1.96804 (semantic_loss: 0.01773, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.35700 
Train Epoch: 25 [243/250 31104/32000 (97%)] Loss: 1.96632 (semantic_loss: 0.01601, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.35194 
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/DCMH_MSRVTT_1kB/checkpoint-epoch25.pth ...
Done in 4.306s
removing stale ckpt [epoch 24] [took 0.01s]
 epoch          : 25
 loss           : 1.96693483877182
 learning_rate  : 1.4599451216938618e-05
 n_samples      : 800000
 n_steps        : 6250
 MSRVTT_miech_test/t2v_metrics/R1: 12.6
 MSRVTT_miech_test/t2v_metrics/R5: 38.7
 MSRVTT_miech_test/t2v_metrics/R10: 54.5
 MSRVTT_miech_test/t2v_metrics/R50: 81.9
 MSRVTT_miech_test/t2v_metrics/MedR: 9.0
 MSRVTT_miech_test/t2v_metrics/MeanR: 42.1745
 MSRVTT_miech_test/t2v_metrics/geometric_mean_R1-R5-R10: 29.841867939571237
 MSRVTT_miech_test/v2t_metrics/R1: 13.7
 MSRVTT_miech_test/v2t_metrics/R5: 41.3
 MSRVTT_miech_test/v2t_metrics/R10: 54.6
 MSRVTT_miech_test/v2t_metrics/R50: 82.6
 MSRVTT_miech_test/v2t_metrics/MedR: 9.0
 MSRVTT_miech_test/v2t_metrics/MeanR: 39.768
 MSRVTT_miech_test/v2t_metrics/geometric_mean_R1-R5-R10: 31.377698608641296
 mnt_best       : 30.12014155793429
 not_improved_count: 2
Train Epoch: 26 [1/250 128/32000 (0%)] Loss: 1.96604 (semantic_loss: 0.01573, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=24.07903 
Train Epoch: 26 [12/250 1536/32000 (5%)] Loss: 1.96695 (semantic_loss: 0.01663, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.32766 
Train Epoch: 26 [23/250 2944/32000 (9%)] Loss: 1.96662 (semantic_loss: 0.01631, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.32768 
Train Epoch: 26 [34/250 4352/32000 (14%)] Loss: 1.96593 (semantic_loss: 0.01659, quant_loss: 1.94922, bit_balance_loss: 0.00012) batch_time=0.41702 
Train Epoch: 26 [45/250 5760/32000 (18%)] Loss: 1.96588 (semantic_loss: 0.01654, quant_loss: 1.94922, bit_balance_loss: 0.00012) batch_time=0.44685 
Train Epoch: 26 [56/250 7168/32000 (22%)] Loss: 1.96808 (semantic_loss: 0.01776, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.35011 
Train Epoch: 26 [67/250 8576/32000 (27%)] Loss: 1.96983 (semantic_loss: 0.02049, quant_loss: 1.94922, bit_balance_loss: 0.00012) batch_time=0.33480 
Train Epoch: 26 [78/250 9984/32000 (31%)] Loss: 1.96854 (semantic_loss: 0.01822, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.32613 
Train Epoch: 26 [89/250 11392/32000 (36%)] Loss: 1.96737 (semantic_loss: 0.01803, quant_loss: 1.94922, bit_balance_loss: 0.00012) batch_time=1.40266 
Train Epoch: 26 [100/250 12800/32000 (40%)] Loss: 1.96830 (semantic_loss: 0.01798, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.53207 
Train Epoch: 26 [111/250 14208/32000 (44%)] Loss: 1.96608 (semantic_loss: 0.01577, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.41409 
Train Epoch: 26 [122/250 15616/32000 (49%)] Loss: 1.96557 (semantic_loss: 0.01623, quant_loss: 1.94922, bit_balance_loss: 0.00012) batch_time=0.34782 
Train Epoch: 26 [133/250 17024/32000 (53%)] Loss: 1.96955 (semantic_loss: 0.01924, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.83005 
Train Epoch: 26 [144/250 18432/32000 (58%)] Loss: 1.96648 (semantic_loss: 0.01714, quant_loss: 1.94922, bit_balance_loss: 0.00012) batch_time=0.35129 
Train Epoch: 26 [155/250 19840/32000 (62%)] Loss: 1.96574 (semantic_loss: 0.01640, quant_loss: 1.94922, bit_balance_loss: 0.00012) batch_time=0.33094 
Train Epoch: 26 [166/250 21248/32000 (66%)] Loss: 1.96647 (semantic_loss: 0.01615, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.46519 
Train Epoch: 26 [177/250 22656/32000 (71%)] Loss: 1.96634 (semantic_loss: 0.01603, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.40859 
Train Epoch: 26 [188/250 24064/32000 (75%)] Loss: 1.96719 (semantic_loss: 0.01688, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.34861 
Train Epoch: 26 [199/250 25472/32000 (80%)] Loss: 1.96679 (semantic_loss: 0.01647, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=2.16977 
Train Epoch: 26 [210/250 26880/32000 (84%)] Loss: 1.96695 (semantic_loss: 0.01663, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.32321 
Train Epoch: 26 [221/250 28288/32000 (88%)] Loss: 1.96644 (semantic_loss: 0.01613, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.33141 
Train Epoch: 26 [232/250 29696/32000 (93%)] Loss: 1.96786 (semantic_loss: 0.01754, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.39725 
Train Epoch: 26 [243/250 31104/32000 (97%)] Loss: 1.96550 (semantic_loss: 0.01616, quant_loss: 1.94922, bit_balance_loss: 0.00012) batch_time=0.42971 
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/DCMH_MSRVTT_1kB/checkpoint-epoch26.pth ...
Done in 12.443s
removing stale ckpt [epoch 25] [took 0.02s]
 epoch          : 26
 loss           : 1.966942563533783
 learning_rate  : 1.3869478656091687e-05
 n_samples      : 832000
 n_steps        : 6500
 MSRVTT_miech_test/t2v_metrics/R1: 11.6
 MSRVTT_miech_test/t2v_metrics/R5: 38.5
 MSRVTT_miech_test/t2v_metrics/R10: 52.7
 MSRVTT_miech_test/t2v_metrics/R50: 82.7
 MSRVTT_miech_test/t2v_metrics/MedR: 9.0
 MSRVTT_miech_test/t2v_metrics/MeanR: 41.4675
 MSRVTT_miech_test/t2v_metrics/geometric_mean_R1-R5-R10: 28.657817411581014
 MSRVTT_miech_test/v2t_metrics/R1: 13.0
 MSRVTT_miech_test/v2t_metrics/R5: 38.9
 MSRVTT_miech_test/v2t_metrics/R10: 54.6
 MSRVTT_miech_test/v2t_metrics/R50: 82.6
 MSRVTT_miech_test/v2t_metrics/MedR: 9.0
 MSRVTT_miech_test/v2t_metrics/MeanR: 38.5705
 MSRVTT_miech_test/v2t_metrics/geometric_mean_R1-R5-R10: 30.2246907125248
 mnt_best       : 30.12014155793429
 not_improved_count: 3
Train Epoch: 27 [1/250 128/32000 (0%)] Loss: 1.96564 (semantic_loss: 0.01532, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=26.50232 
Train Epoch: 27 [12/250 1536/32000 (5%)] Loss: 1.96642 (semantic_loss: 0.01611, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.34921 
Train Epoch: 27 [23/250 2944/32000 (9%)] Loss: 1.96867 (semantic_loss: 0.01738, quant_loss: 1.95117, bit_balance_loss: 0.00012) batch_time=0.32353 
Train Epoch: 27 [34/250 4352/32000 (14%)] Loss: 1.96700 (semantic_loss: 0.01669, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.33314 
Train Epoch: 27 [45/250 5760/32000 (18%)] Loss: 1.96733 (semantic_loss: 0.01799, quant_loss: 1.94922, bit_balance_loss: 0.00012) batch_time=0.42784 
Train Epoch: 27 [56/250 7168/32000 (22%)] Loss: 1.96705 (semantic_loss: 0.01674, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.49884 
Train Epoch: 27 [67/250 8576/32000 (27%)] Loss: 1.96655 (semantic_loss: 0.01623, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.33450 
Train Epoch: 27 [78/250 9984/32000 (31%)] Loss: 1.96722 (semantic_loss: 0.01788, quant_loss: 1.94922, bit_balance_loss: 0.00012) batch_time=0.33789 
Train Epoch: 27 [89/250 11392/32000 (36%)] Loss: 1.96619 (semantic_loss: 0.01587, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.32016 
Train Epoch: 27 [100/250 12800/32000 (40%)] Loss: 1.96657 (semantic_loss: 0.01625, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.33708 
Train Epoch: 27 [111/250 14208/32000 (44%)] Loss: 1.96722 (semantic_loss: 0.01691, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.41347 
Train Epoch: 27 [122/250 15616/32000 (49%)] Loss: 1.96678 (semantic_loss: 0.01646, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.41590 
Train Epoch: 27 [133/250 17024/32000 (53%)] Loss: 1.96513 (semantic_loss: 0.01579, quant_loss: 1.94922, bit_balance_loss: 0.00012) batch_time=1.17169 
Train Epoch: 27 [144/250 18432/32000 (58%)] Loss: 1.96565 (semantic_loss: 0.01631, quant_loss: 1.94922, bit_balance_loss: 0.00012) batch_time=1.27927 
Train Epoch: 27 [155/250 19840/32000 (62%)] Loss: 1.96719 (semantic_loss: 0.01687, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.32912 
Train Epoch: 27 [166/250 21248/32000 (66%)] Loss: 1.96620 (semantic_loss: 0.01589, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.41379 
Train Epoch: 27 [177/250 22656/32000 (71%)] Loss: 1.96567 (semantic_loss: 0.01633, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.37527 
Train Epoch: 27 [188/250 24064/32000 (75%)] Loss: 1.96658 (semantic_loss: 0.01626, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.36353 
Train Epoch: 27 [199/250 25472/32000 (80%)] Loss: 1.96510 (semantic_loss: 0.01577, quant_loss: 1.94922, bit_balance_loss: 0.00012) batch_time=2.92821 
Train Epoch: 27 [210/250 26880/32000 (84%)] Loss: 1.96646 (semantic_loss: 0.01712, quant_loss: 1.94922, bit_balance_loss: 0.00012) batch_time=0.33147 
Train Epoch: 27 [221/250 28288/32000 (88%)] Loss: 1.96579 (semantic_loss: 0.01645, quant_loss: 1.94922, bit_balance_loss: 0.00012) batch_time=0.33078 
Train Epoch: 27 [232/250 29696/32000 (93%)] Loss: 1.96542 (semantic_loss: 0.01510, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.33770 
Train Epoch: 27 [243/250 31104/32000 (97%)] Loss: 1.96667 (semantic_loss: 0.01635, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.47018 
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/DCMH_MSRVTT_1kB/checkpoint-epoch27.pth ...
Done in 4.373s
Updating 'best' checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/DCMH_MSRVTT_1kB/checkpoint-epoch27.pth ...
Done in 9.487s
removing stale ckpt [epoch 26] [took 0.01s]
 epoch          : 27
 loss           : 1.9667007412910462
 learning_rate  : 1.3176004723287102e-05
 n_samples      : 864000
 n_steps        : 6750
 MSRVTT_miech_test/t2v_metrics/R1: 13.8
 MSRVTT_miech_test/t2v_metrics/R5: 39.8
 MSRVTT_miech_test/t2v_metrics/R10: 54.3
 MSRVTT_miech_test/t2v_metrics/R50: 83.0
 MSRVTT_miech_test/t2v_metrics/MedR: 8.75
 MSRVTT_miech_test/t2v_metrics/MeanR: 40.9155
 MSRVTT_miech_test/t2v_metrics/geometric_mean_R1-R5-R10: 31.011349295710172
 MSRVTT_miech_test/v2t_metrics/R1: 14.3
 MSRVTT_miech_test/v2t_metrics/R5: 40.2
 MSRVTT_miech_test/v2t_metrics/R10: 53.4
 MSRVTT_miech_test/v2t_metrics/R50: 83.8
 MSRVTT_miech_test/v2t_metrics/MedR: 9.0
 MSRVTT_miech_test/v2t_metrics/MeanR: 37.933
 MSRVTT_miech_test/v2t_metrics/geometric_mean_R1-R5-R10: 31.311301195931915
 mnt_best       : 31.011349295710172
 not_improved_count: 0
Train Epoch: 28 [1/250 128/32000 (0%)] Loss: 1.96835 (semantic_loss: 0.01803, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=32.92076 
Train Epoch: 28 [12/250 1536/32000 (5%)] Loss: 1.96655 (semantic_loss: 0.01623, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.32581 
Train Epoch: 28 [23/250 2944/32000 (9%)] Loss: 1.96557 (semantic_loss: 0.01525, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.38047 
Train Epoch: 28 [34/250 4352/32000 (14%)] Loss: 1.96717 (semantic_loss: 0.01686, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.72432 
Train Epoch: 28 [45/250 5760/32000 (18%)] Loss: 1.96597 (semantic_loss: 0.01565, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.33220 
Train Epoch: 28 [56/250 7168/32000 (22%)] Loss: 1.96577 (semantic_loss: 0.01643, quant_loss: 1.94922, bit_balance_loss: 0.00013) batch_time=0.32931 
Train Epoch: 28 [67/250 8576/32000 (27%)] Loss: 1.96836 (semantic_loss: 0.01805, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.37285 
Train Epoch: 28 [78/250 9984/32000 (31%)] Loss: 1.96611 (semantic_loss: 0.01677, quant_loss: 1.94922, bit_balance_loss: 0.00012) batch_time=0.32933 
Train Epoch: 28 [89/250 11392/32000 (36%)] Loss: 1.96758 (semantic_loss: 0.01629, quant_loss: 1.95117, bit_balance_loss: 0.00012) batch_time=0.36307 
Train Epoch: 28 [100/250 12800/32000 (40%)] Loss: 1.96634 (semantic_loss: 0.01700, quant_loss: 1.94922, bit_balance_loss: 0.00012) batch_time=0.67463 
Train Epoch: 28 [111/250 14208/32000 (44%)] Loss: 1.96612 (semantic_loss: 0.01580, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.32252 
Train Epoch: 28 [122/250 15616/32000 (49%)] Loss: 1.96560 (semantic_loss: 0.01528, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.32585 
Train Epoch: 28 [133/250 17024/32000 (53%)] Loss: 1.96797 (semantic_loss: 0.01765, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=1.42632 
Train Epoch: 28 [144/250 18432/32000 (58%)] Loss: 1.96717 (semantic_loss: 0.01685, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.38626 
Train Epoch: 28 [155/250 19840/32000 (62%)] Loss: 1.96604 (semantic_loss: 0.01573, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.32306 
Train Epoch: 28 [166/250 21248/32000 (66%)] Loss: 1.96552 (semantic_loss: 0.01521, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.33145 
Train Epoch: 28 [177/250 22656/32000 (71%)] Loss: 1.96628 (semantic_loss: 0.01597, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.32780 
Train Epoch: 28 [188/250 24064/32000 (75%)] Loss: 1.96762 (semantic_loss: 0.01828, quant_loss: 1.94922, bit_balance_loss: 0.00012) batch_time=0.37087 
Train Epoch: 28 [199/250 25472/32000 (80%)] Loss: 1.96707 (semantic_loss: 0.01773, quant_loss: 1.94922, bit_balance_loss: 0.00012) batch_time=0.37044 
Train Epoch: 28 [210/250 26880/32000 (84%)] Loss: 1.96629 (semantic_loss: 0.01695, quant_loss: 1.94922, bit_balance_loss: 0.00012) batch_time=0.39570 
Train Epoch: 28 [221/250 28288/32000 (88%)] Loss: 1.96570 (semantic_loss: 0.01538, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.32839 
Train Epoch: 28 [232/250 29696/32000 (93%)] Loss: 1.96577 (semantic_loss: 0.01643, quant_loss: 1.94922, bit_balance_loss: 0.00012) batch_time=1.43306 
Train Epoch: 28 [243/250 31104/32000 (97%)] Loss: 1.96715 (semantic_loss: 0.01684, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.32761 
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/DCMH_MSRVTT_1kB/checkpoint-epoch28.pth ...
Done in 3.746s
removing stale ckpt [epoch 27] [took 0.00s]
 epoch          : 28
 loss           : 1.9665173993110656
 learning_rate  : 1.2517204487122746e-05
 n_samples      : 896000
 n_steps        : 7000
 MSRVTT_miech_test/t2v_metrics/R1: 13.7
 MSRVTT_miech_test/t2v_metrics/R5: 39.8
 MSRVTT_miech_test/t2v_metrics/R10: 54.2
 MSRVTT_miech_test/t2v_metrics/R50: 83.6
 MSRVTT_miech_test/t2v_metrics/MedR: 9.0
 MSRVTT_miech_test/t2v_metrics/MeanR: 40.966
 MSRVTT_miech_test/t2v_metrics/geometric_mean_R1-R5-R10: 30.91725836695278
 MSRVTT_miech_test/v2t_metrics/R1: 13.8
 MSRVTT_miech_test/v2t_metrics/R5: 40.1
 MSRVTT_miech_test/v2t_metrics/R10: 54.7
 MSRVTT_miech_test/v2t_metrics/R50: 84.1
 MSRVTT_miech_test/v2t_metrics/MedR: 9.0
 MSRVTT_miech_test/v2t_metrics/MeanR: 37.371
 MSRVTT_miech_test/v2t_metrics/geometric_mean_R1-R5-R10: 31.16522464977682
 mnt_best       : 31.011349295710172
 not_improved_count: 1
Train Epoch: 29 [1/250 128/32000 (0%)] Loss: 1.96829 (semantic_loss: 0.01699, quant_loss: 1.95117, bit_balance_loss: 0.00012) batch_time=34.47140 
Train Epoch: 29 [12/250 1536/32000 (5%)] Loss: 1.96749 (semantic_loss: 0.01717, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.32697 
Train Epoch: 29 [23/250 2944/32000 (9%)] Loss: 1.96536 (semantic_loss: 0.01602, quant_loss: 1.94922, bit_balance_loss: 0.00012) batch_time=0.32409 
Train Epoch: 29 [34/250 4352/32000 (14%)] Loss: 1.96653 (semantic_loss: 0.01621, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.40996 
Train Epoch: 29 [45/250 5760/32000 (18%)] Loss: 1.96536 (semantic_loss: 0.01504, quant_loss: 1.95020, bit_balance_loss: 0.00013) batch_time=1.32929 
Train Epoch: 29 [56/250 7168/32000 (22%)] Loss: 1.96548 (semantic_loss: 0.01517, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.88397 
Train Epoch: 29 [67/250 8576/32000 (27%)] Loss: 1.96524 (semantic_loss: 0.01493, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.32995 
Train Epoch: 29 [78/250 9984/32000 (31%)] Loss: 1.96501 (semantic_loss: 0.01469, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.32242 
Train Epoch: 29 [89/250 11392/32000 (36%)] Loss: 1.96813 (semantic_loss: 0.01684, quant_loss: 1.95117, bit_balance_loss: 0.00012) batch_time=0.33287 
Train Epoch: 29 [100/250 12800/32000 (40%)] Loss: 1.96608 (semantic_loss: 0.01675, quant_loss: 1.94922, bit_balance_loss: 0.00012) batch_time=0.33046 
Train Epoch: 29 [111/250 14208/32000 (44%)] Loss: 1.96923 (semantic_loss: 0.01891, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.47948 
Train Epoch: 29 [122/250 15616/32000 (49%)] Loss: 1.96395 (semantic_loss: 0.01461, quant_loss: 1.94922, bit_balance_loss: 0.00012) batch_time=0.39072 
Train Epoch: 29 [133/250 17024/32000 (53%)] Loss: 1.96518 (semantic_loss: 0.01584, quant_loss: 1.94922, bit_balance_loss: 0.00012) batch_time=0.34885 
Train Epoch: 29 [144/250 18432/32000 (58%)] Loss: 1.96622 (semantic_loss: 0.01591, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.33545 
Train Epoch: 29 [155/250 19840/32000 (62%)] Loss: 1.96440 (semantic_loss: 0.01506, quant_loss: 1.94922, bit_balance_loss: 0.00012) batch_time=0.32834 
Train Epoch: 29 [166/250 21248/32000 (66%)] Loss: 1.96620 (semantic_loss: 0.01588, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.36053 
Train Epoch: 29 [177/250 22656/32000 (71%)] Loss: 1.96445 (semantic_loss: 0.01511, quant_loss: 1.94922, bit_balance_loss: 0.00012) batch_time=0.33225 
Train Epoch: 29 [188/250 24064/32000 (75%)] Loss: 1.96521 (semantic_loss: 0.01587, quant_loss: 1.94922, bit_balance_loss: 0.00012) batch_time=0.41612 
Train Epoch: 29 [199/250 25472/32000 (80%)] Loss: 1.96552 (semantic_loss: 0.01521, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.32367 
Train Epoch: 29 [210/250 26880/32000 (84%)] Loss: 1.96635 (semantic_loss: 0.01701, quant_loss: 1.94922, bit_balance_loss: 0.00012) batch_time=0.33514 
Train Epoch: 29 [221/250 28288/32000 (88%)] Loss: 1.96725 (semantic_loss: 0.01694, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.32646 
Train Epoch: 29 [232/250 29696/32000 (93%)] Loss: 1.96661 (semantic_loss: 0.01532, quant_loss: 1.95117, bit_balance_loss: 0.00012) batch_time=0.32691 
Train Epoch: 29 [243/250 31104/32000 (97%)] Loss: 1.96437 (semantic_loss: 0.01503, quant_loss: 1.94922, bit_balance_loss: 0.00012) batch_time=0.32745 
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/DCMH_MSRVTT_1kB/checkpoint-epoch29.pth ...
Done in 4.333s
Updating 'best' checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/DCMH_MSRVTT_1kB/checkpoint-epoch29.pth ...
Done in 8.788s
removing stale ckpt [epoch 28] [took 0.00s]
 epoch          : 29
 loss           : 1.9661877264976502
 learning_rate  : 1.1891344262766608e-05
 n_samples      : 928000
 n_steps        : 7250
 MSRVTT_miech_test/t2v_metrics/R1: 14.6
 MSRVTT_miech_test/t2v_metrics/R5: 39.5
 MSRVTT_miech_test/t2v_metrics/R10: 54.9
 MSRVTT_miech_test/t2v_metrics/R50: 84.0
 MSRVTT_miech_test/t2v_metrics/MedR: 9.0
 MSRVTT_miech_test/t2v_metrics/MeanR: 40.0365
 MSRVTT_miech_test/t2v_metrics/geometric_mean_R1-R5-R10: 31.63545598321976
 MSRVTT_miech_test/v2t_metrics/R1: 14.9
 MSRVTT_miech_test/v2t_metrics/R5: 40.2
 MSRVTT_miech_test/v2t_metrics/R10: 55.5
 MSRVTT_miech_test/v2t_metrics/R50: 84.4
 MSRVTT_miech_test/v2t_metrics/MedR: 8.5
 MSRVTT_miech_test/v2t_metrics/MeanR: 37.327
 MSRVTT_miech_test/v2t_metrics/geometric_mean_R1-R5-R10: 32.15400696784192
 mnt_best       : 31.63545598321976
 not_improved_count: 0
Train Epoch: 30 [1/250 128/32000 (0%)] Loss: 1.96547 (semantic_loss: 0.01614, quant_loss: 1.94922, bit_balance_loss: 0.00012) batch_time=26.33202 
Train Epoch: 30 [12/250 1536/32000 (5%)] Loss: 1.96675 (semantic_loss: 0.01643, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.44434 
Train Epoch: 30 [23/250 2944/32000 (9%)] Loss: 1.96406 (semantic_loss: 0.01472, quant_loss: 1.94922, bit_balance_loss: 0.00012) batch_time=0.97343 
Train Epoch: 30 [34/250 4352/32000 (14%)] Loss: 1.96737 (semantic_loss: 0.01705, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.39471 
Train Epoch: 30 [45/250 5760/32000 (18%)] Loss: 1.96616 (semantic_loss: 0.01681, quant_loss: 1.94922, bit_balance_loss: 0.00012) batch_time=0.33683 
Train Epoch: 30 [56/250 7168/32000 (22%)] Loss: 1.96643 (semantic_loss: 0.01612, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.54596 
Train Epoch: 30 [67/250 8576/32000 (27%)] Loss: 1.96685 (semantic_loss: 0.01555, quant_loss: 1.95117, bit_balance_loss: 0.00012) batch_time=0.32522 
Train Epoch: 30 [78/250 9984/32000 (31%)] Loss: 1.96493 (semantic_loss: 0.01558, quant_loss: 1.94922, bit_balance_loss: 0.00012) batch_time=0.41535 
Train Epoch: 30 [89/250 11392/32000 (36%)] Loss: 1.96568 (semantic_loss: 0.01536, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=2.39200 
Train Epoch: 30 [100/250 12800/32000 (40%)] Loss: 1.96703 (semantic_loss: 0.01573, quant_loss: 1.95117, bit_balance_loss: 0.00012) batch_time=0.82375 
Train Epoch: 30 [111/250 14208/32000 (44%)] Loss: 1.96549 (semantic_loss: 0.01615, quant_loss: 1.94922, bit_balance_loss: 0.00012) batch_time=0.34833 
Train Epoch: 30 [122/250 15616/32000 (49%)] Loss: 1.96726 (semantic_loss: 0.01793, quant_loss: 1.94922, bit_balance_loss: 0.00012) batch_time=0.32275 
Train Epoch: 30 [133/250 17024/32000 (53%)] Loss: 1.96430 (semantic_loss: 0.01496, quant_loss: 1.94922, bit_balance_loss: 0.00012) batch_time=0.32853 
Train Epoch: 30 [144/250 18432/32000 (58%)] Loss: 1.96614 (semantic_loss: 0.01582, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.84812 
Train Epoch: 30 [155/250 19840/32000 (62%)] Loss: 1.96817 (semantic_loss: 0.01785, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.44787 
Train Epoch: 30 [166/250 21248/32000 (66%)] Loss: 1.96478 (semantic_loss: 0.01544, quant_loss: 1.94922, bit_balance_loss: 0.00012) batch_time=0.34072 
Train Epoch: 30 [177/250 22656/32000 (71%)] Loss: 1.96797 (semantic_loss: 0.01765, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.38019 
Train Epoch: 30 [188/250 24064/32000 (75%)] Loss: 1.96476 (semantic_loss: 0.01445, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.33197 
Train Epoch: 30 [199/250 25472/32000 (80%)] Loss: 1.96552 (semantic_loss: 0.01521, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.32289 
Train Epoch: 30 [210/250 26880/32000 (84%)] Loss: 1.96569 (semantic_loss: 0.01537, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.44205 
Train Epoch: 30 [221/250 28288/32000 (88%)] Loss: 1.96527 (semantic_loss: 0.01593, quant_loss: 1.94922, bit_balance_loss: 0.00012) batch_time=0.37564 
Train Epoch: 30 [232/250 29696/32000 (93%)] Loss: 1.96613 (semantic_loss: 0.01582, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.42272 
Train Epoch: 30 [243/250 31104/32000 (97%)] Loss: 1.96688 (semantic_loss: 0.01657, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.36790 
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/DCMH_MSRVTT_1kB/checkpoint-epoch30.pth ...
Done in 12.045s
removing stale ckpt [epoch 29] [took 0.05s]
 epoch          : 30
 loss           : 1.965982677936554
 learning_rate  : 1.1296777049628277e-05
 n_samples      : 960000
 n_steps        : 7500
 MSRVTT_miech_test/t2v_metrics/R1: 13.7
 MSRVTT_miech_test/t2v_metrics/R5: 39.8
 MSRVTT_miech_test/t2v_metrics/R10: 54.2
 MSRVTT_miech_test/t2v_metrics/R50: 83.9
 MSRVTT_miech_test/t2v_metrics/MedR: 9.0
 MSRVTT_miech_test/t2v_metrics/MeanR: 40.163
 MSRVTT_miech_test/t2v_metrics/geometric_mean_R1-R5-R10: 30.91725836695278
 MSRVTT_miech_test/v2t_metrics/R1: 16.1
 MSRVTT_miech_test/v2t_metrics/R5: 41.2
 MSRVTT_miech_test/v2t_metrics/R10: 55.9
 MSRVTT_miech_test/v2t_metrics/R50: 83.7
 MSRVTT_miech_test/v2t_metrics/MedR: 9.0
 MSRVTT_miech_test/v2t_metrics/MeanR: 37.3325
 MSRVTT_miech_test/v2t_metrics/geometric_mean_R1-R5-R10: 33.34609373676203
 mnt_best       : 31.63545598321976
 not_improved_count: 1
Train Epoch: 31 [1/250 128/32000 (0%)] Loss: 1.96741 (semantic_loss: 0.01710, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=29.32812 
Train Epoch: 31 [12/250 1536/32000 (5%)] Loss: 1.96571 (semantic_loss: 0.01540, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.33011 
Train Epoch: 31 [23/250 2944/32000 (9%)] Loss: 1.96783 (semantic_loss: 0.01752, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.33070 
Train Epoch: 31 [34/250 4352/32000 (14%)] Loss: 1.96386 (semantic_loss: 0.01452, quant_loss: 1.94922, bit_balance_loss: 0.00012) batch_time=0.44337 
Train Epoch: 31 [45/250 5760/32000 (18%)] Loss: 1.96672 (semantic_loss: 0.01640, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.39071 
Train Epoch: 31 [56/250 7168/32000 (22%)] Loss: 1.96427 (semantic_loss: 0.01493, quant_loss: 1.94922, bit_balance_loss: 0.00012) batch_time=0.33742 
Train Epoch: 31 [67/250 8576/32000 (27%)] Loss: 1.96726 (semantic_loss: 0.01695, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.32841 
Train Epoch: 31 [78/250 9984/32000 (31%)] Loss: 1.96823 (semantic_loss: 0.01694, quant_loss: 1.95117, bit_balance_loss: 0.00012) batch_time=0.32334 
Train Epoch: 31 [89/250 11392/32000 (36%)] Loss: 1.96583 (semantic_loss: 0.01551, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.32789 
Train Epoch: 31 [100/250 12800/32000 (40%)] Loss: 1.96588 (semantic_loss: 0.01654, quant_loss: 1.94922, bit_balance_loss: 0.00012) batch_time=0.32644 
Train Epoch: 31 [111/250 14208/32000 (44%)] Loss: 1.96675 (semantic_loss: 0.01643, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.51641 
Train Epoch: 31 [122/250 15616/32000 (49%)] Loss: 1.96591 (semantic_loss: 0.01462, quant_loss: 1.95117, bit_balance_loss: 0.00012) batch_time=0.38524 
Train Epoch: 31 [133/250 17024/32000 (53%)] Loss: 1.96477 (semantic_loss: 0.01445, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.35841 
Train Epoch: 31 [144/250 18432/32000 (58%)] Loss: 1.96485 (semantic_loss: 0.01551, quant_loss: 1.94922, bit_balance_loss: 0.00012) batch_time=0.34397 
Train Epoch: 31 [155/250 19840/32000 (62%)] Loss: 1.96543 (semantic_loss: 0.01512, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.32401 
Train Epoch: 31 [166/250 21248/32000 (66%)] Loss: 1.96741 (semantic_loss: 0.01807, quant_loss: 1.94922, bit_balance_loss: 0.00012) batch_time=0.33006 
Train Epoch: 31 [177/250 22656/32000 (71%)] Loss: 1.96593 (semantic_loss: 0.01562, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.50088 
Train Epoch: 31 [188/250 24064/32000 (75%)] Loss: 1.96658 (semantic_loss: 0.01627, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.63475 
Train Epoch: 31 [199/250 25472/32000 (80%)] Loss: 1.96575 (semantic_loss: 0.01544, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.34644 
Train Epoch: 31 [210/250 26880/32000 (84%)] Loss: 1.96548 (semantic_loss: 0.01516, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.33350 
Train Epoch: 31 [221/250 28288/32000 (88%)] Loss: 1.96599 (semantic_loss: 0.01665, quant_loss: 1.94922, bit_balance_loss: 0.00012) batch_time=0.32421 
Train Epoch: 31 [232/250 29696/32000 (93%)] Loss: 1.96593 (semantic_loss: 0.01562, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.33439 
Train Epoch: 31 [243/250 31104/32000 (97%)] Loss: 1.96609 (semantic_loss: 0.01675, quant_loss: 1.94922, bit_balance_loss: 0.00012) batch_time=0.32643 
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/DCMH_MSRVTT_1kB/checkpoint-epoch31.pth ...
Done in 3.914s
removing stale ckpt [epoch 30] [took 0.00s]
 epoch          : 31
 loss           : 1.966029459476471
 learning_rate  : 1.0731938197146863e-05
 n_samples      : 992000
 n_steps        : 7750
 MSRVTT_miech_test/t2v_metrics/R1: 13.7
 MSRVTT_miech_test/t2v_metrics/R5: 40.3
 MSRVTT_miech_test/t2v_metrics/R10: 55.8
 MSRVTT_miech_test/t2v_metrics/R50: 83.5
 MSRVTT_miech_test/t2v_metrics/MedR: 8.25
 MSRVTT_miech_test/t2v_metrics/MeanR: 40.7495
 MSRVTT_miech_test/t2v_metrics/geometric_mean_R1-R5-R10: 31.348728991609285
 MSRVTT_miech_test/v2t_metrics/R1: 14.3
 MSRVTT_miech_test/v2t_metrics/R5: 40.7
 MSRVTT_miech_test/v2t_metrics/R10: 55.3
 MSRVTT_miech_test/v2t_metrics/R50: 83.9
 MSRVTT_miech_test/v2t_metrics/MedR: 8.5
 MSRVTT_miech_test/v2t_metrics/MeanR: 37.67
 MSRVTT_miech_test/v2t_metrics/geometric_mean_R1-R5-R10: 31.809135002002012
 mnt_best       : 31.63545598321976
 not_improved_count: 2
Train Epoch: 32 [1/250 128/32000 (0%)] Loss: 1.96589 (semantic_loss: 0.01557, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=26.39375 
Train Epoch: 32 [12/250 1536/32000 (5%)] Loss: 1.96444 (semantic_loss: 0.01510, quant_loss: 1.94922, bit_balance_loss: 0.00012) batch_time=0.33540 
Train Epoch: 32 [23/250 2944/32000 (9%)] Loss: 1.96751 (semantic_loss: 0.01720, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.37741 
Train Epoch: 32 [34/250 4352/32000 (14%)] Loss: 1.96606 (semantic_loss: 0.01672, quant_loss: 1.94922, bit_balance_loss: 0.00012) batch_time=0.34490 
Train Epoch: 32 [45/250 5760/32000 (18%)] Loss: 1.96875 (semantic_loss: 0.01746, quant_loss: 1.95117, bit_balance_loss: 0.00012) batch_time=0.33278 
Train Epoch: 32 [56/250 7168/32000 (22%)] Loss: 1.96582 (semantic_loss: 0.01453, quant_loss: 1.95117, bit_balance_loss: 0.00012) batch_time=0.37852 
Train Epoch: 32 [67/250 8576/32000 (27%)] Loss: 1.96536 (semantic_loss: 0.01505, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.35002 
Train Epoch: 32 [78/250 9984/32000 (31%)] Loss: 1.96529 (semantic_loss: 0.01595, quant_loss: 1.94922, bit_balance_loss: 0.00012) batch_time=0.44391 
Train Epoch: 32 [89/250 11392/32000 (36%)] Loss: 1.96583 (semantic_loss: 0.01551, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.39850 
Train Epoch: 32 [100/250 12800/32000 (40%)] Loss: 1.96667 (semantic_loss: 0.01636, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.35945 
Train Epoch: 32 [111/250 14208/32000 (44%)] Loss: 1.96615 (semantic_loss: 0.01584, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.38633 
Train Epoch: 32 [122/250 15616/32000 (49%)] Loss: 1.96522 (semantic_loss: 0.01588, quant_loss: 1.94922, bit_balance_loss: 0.00012) batch_time=0.35116 
Train Epoch: 32 [133/250 17024/32000 (53%)] Loss: 1.96653 (semantic_loss: 0.01621, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=1.48364 
Train Epoch: 32 [144/250 18432/32000 (58%)] Loss: 1.96558 (semantic_loss: 0.01625, quant_loss: 1.94922, bit_balance_loss: 0.00012) batch_time=0.48839 
Train Epoch: 32 [155/250 19840/32000 (62%)] Loss: 1.96791 (semantic_loss: 0.01760, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.37030 
Train Epoch: 32 [166/250 21248/32000 (66%)] Loss: 1.96498 (semantic_loss: 0.01564, quant_loss: 1.94922, bit_balance_loss: 0.00012) batch_time=0.34047 
Train Epoch: 32 [177/250 22656/32000 (71%)] Loss: 1.96594 (semantic_loss: 0.01562, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.41272 
Train Epoch: 32 [188/250 24064/32000 (75%)] Loss: 1.96414 (semantic_loss: 0.01480, quant_loss: 1.94922, bit_balance_loss: 0.00012) batch_time=0.35726 
Train Epoch: 32 [199/250 25472/32000 (80%)] Loss: 1.96624 (semantic_loss: 0.01592, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.32381 
Train Epoch: 32 [210/250 26880/32000 (84%)] Loss: 1.96661 (semantic_loss: 0.01629, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=1.90996 
Train Epoch: 32 [221/250 28288/32000 (88%)] Loss: 1.96718 (semantic_loss: 0.01686, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.40328 
Train Epoch: 32 [232/250 29696/32000 (93%)] Loss: 1.96629 (semantic_loss: 0.01597, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.33360 
Train Epoch: 32 [243/250 31104/32000 (97%)] Loss: 1.96492 (semantic_loss: 0.01558, quant_loss: 1.94922, bit_balance_loss: 0.00012) batch_time=0.45268 
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/DCMH_MSRVTT_1kB/checkpoint-epoch32.pth ...
Done in 4.343s
Updating 'best' checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/DCMH_MSRVTT_1kB/checkpoint-epoch32.pth ...
Done in 7.851s
removing stale ckpt [epoch 31] [took 0.00s]
 epoch          : 32
 loss           : 1.9658628087043761
 learning_rate  : 1.019534128728952e-05
 n_samples      : 1024000
 n_steps        : 8000
 MSRVTT_miech_test/t2v_metrics/R1: 14.5
 MSRVTT_miech_test/t2v_metrics/R5: 40.4
 MSRVTT_miech_test/t2v_metrics/R10: 54.4
 MSRVTT_miech_test/t2v_metrics/R50: 82.8
 MSRVTT_miech_test/t2v_metrics/MedR: 8.25
 MSRVTT_miech_test/t2v_metrics/MeanR: 40.3255
 MSRVTT_miech_test/t2v_metrics/geometric_mean_R1-R5-R10: 31.70414816995329
 MSRVTT_miech_test/v2t_metrics/R1: 14.9
 MSRVTT_miech_test/v2t_metrics/R5: 40.8
 MSRVTT_miech_test/v2t_metrics/R10: 55.6
 MSRVTT_miech_test/v2t_metrics/R50: 84.1
 MSRVTT_miech_test/v2t_metrics/MedR: 8.0
 MSRVTT_miech_test/v2t_metrics/MeanR: 36.913
 MSRVTT_miech_test/v2t_metrics/geometric_mean_R1-R5-R10: 32.33258349012694
 mnt_best       : 31.70414816995329
 not_improved_count: 0
Train Epoch: 33 [1/250 128/32000 (0%)] Loss: 1.96635 (semantic_loss: 0.01603, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=29.94581 
Train Epoch: 33 [12/250 1536/32000 (5%)] Loss: 1.96613 (semantic_loss: 0.01581, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.32462 
Train Epoch: 33 [23/250 2944/32000 (9%)] Loss: 1.96522 (semantic_loss: 0.01491, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.32577 
Train Epoch: 33 [34/250 4352/32000 (14%)] Loss: 1.96543 (semantic_loss: 0.01512, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.32954 
Train Epoch: 33 [45/250 5760/32000 (18%)] Loss: 1.96615 (semantic_loss: 0.01583, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.36725 
Train Epoch: 33 [56/250 7168/32000 (22%)] Loss: 1.96692 (semantic_loss: 0.01661, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.36074 
Train Epoch: 33 [67/250 8576/32000 (27%)] Loss: 1.96646 (semantic_loss: 0.01614, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.34151 
Train Epoch: 33 [78/250 9984/32000 (31%)] Loss: 1.96486 (semantic_loss: 0.01552, quant_loss: 1.94922, bit_balance_loss: 0.00012) batch_time=0.32585 
Train Epoch: 33 [89/250 11392/32000 (36%)] Loss: 1.96849 (semantic_loss: 0.01818, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.33615 
Train Epoch: 33 [100/250 12800/32000 (40%)] Loss: 1.96478 (semantic_loss: 0.01544, quant_loss: 1.94922, bit_balance_loss: 0.00012) batch_time=0.33406 
Train Epoch: 33 [111/250 14208/32000 (44%)] Loss: 1.96658 (semantic_loss: 0.01529, quant_loss: 1.95117, bit_balance_loss: 0.00012) batch_time=0.41506 
Train Epoch: 33 [122/250 15616/32000 (49%)] Loss: 1.96515 (semantic_loss: 0.01581, quant_loss: 1.94922, bit_balance_loss: 0.00012) batch_time=0.40505 
Train Epoch: 33 [133/250 17024/32000 (53%)] Loss: 1.96702 (semantic_loss: 0.01573, quant_loss: 1.95117, bit_balance_loss: 0.00012) batch_time=0.35966 
Train Epoch: 33 [144/250 18432/32000 (58%)] Loss: 1.96828 (semantic_loss: 0.01797, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.32955 
Train Epoch: 33 [155/250 19840/32000 (62%)] Loss: 1.96604 (semantic_loss: 0.01670, quant_loss: 1.94922, bit_balance_loss: 0.00012) batch_time=0.50652 
Train Epoch: 33 [166/250 21248/32000 (66%)] Loss: 1.96346 (semantic_loss: 0.01412, quant_loss: 1.94922, bit_balance_loss: 0.00012) batch_time=0.33346 
Train Epoch: 33 [177/250 22656/32000 (71%)] Loss: 1.96601 (semantic_loss: 0.01570, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.32963 
Train Epoch: 33 [188/250 24064/32000 (75%)] Loss: 1.96413 (semantic_loss: 0.01479, quant_loss: 1.94922, bit_balance_loss: 0.00012) batch_time=0.53667 
Train Epoch: 33 [199/250 25472/32000 (80%)] Loss: 1.96368 (semantic_loss: 0.01336, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.34624 
Train Epoch: 33 [210/250 26880/32000 (84%)] Loss: 1.96698 (semantic_loss: 0.01764, quant_loss: 1.94922, bit_balance_loss: 0.00012) batch_time=1.54921 
Train Epoch: 33 [221/250 28288/32000 (88%)] Loss: 1.96527 (semantic_loss: 0.01496, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.33181 
Train Epoch: 33 [232/250 29696/32000 (93%)] Loss: 1.96477 (semantic_loss: 0.01445, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.33154 
Train Epoch: 33 [243/250 31104/32000 (97%)] Loss: 1.96581 (semantic_loss: 0.01550, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.37476 
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/DCMH_MSRVTT_1kB/checkpoint-epoch33.pth ...
Done in 16.612s
removing stale ckpt [epoch 32] [took 0.00s]
 epoch          : 33
 loss           : 1.965711618900299
 learning_rate  : 9.685574222925043e-06
 n_samples      : 1056000
 n_steps        : 8250
 MSRVTT_miech_test/t2v_metrics/R1: 13.9
 MSRVTT_miech_test/t2v_metrics/R5: 41.1
 MSRVTT_miech_test/t2v_metrics/R10: 54.2
 MSRVTT_miech_test/t2v_metrics/R50: 82.9
 MSRVTT_miech_test/t2v_metrics/MedR: 8.5
 MSRVTT_miech_test/t2v_metrics/MeanR: 40.64
 MSRVTT_miech_test/t2v_metrics/geometric_mean_R1-R5-R10: 31.401613910852454
 MSRVTT_miech_test/v2t_metrics/R1: 13.8
 MSRVTT_miech_test/v2t_metrics/R5: 41.0
 MSRVTT_miech_test/v2t_metrics/R10: 55.6
 MSRVTT_miech_test/v2t_metrics/R50: 83.8
 MSRVTT_miech_test/v2t_metrics/MedR: 8.0
 MSRVTT_miech_test/v2t_metrics/MeanR: 37.35
 MSRVTT_miech_test/v2t_metrics/geometric_mean_R1-R5-R10: 31.56791594803084
 mnt_best       : 31.70414816995329
 not_improved_count: 1
Train Epoch: 34 [1/250 128/32000 (0%)] Loss: 1.96455 (semantic_loss: 0.01521, quant_loss: 1.94922, bit_balance_loss: 0.00012) batch_time=23.47265 
Train Epoch: 34 [12/250 1536/32000 (5%)] Loss: 1.96443 (semantic_loss: 0.01510, quant_loss: 1.94922, bit_balance_loss: 0.00012) batch_time=0.35449 
Train Epoch: 34 [23/250 2944/32000 (9%)] Loss: 1.96392 (semantic_loss: 0.01458, quant_loss: 1.94922, bit_balance_loss: 0.00012) batch_time=0.34473 
Train Epoch: 34 [34/250 4352/32000 (14%)] Loss: 1.96488 (semantic_loss: 0.01554, quant_loss: 1.94922, bit_balance_loss: 0.00012) batch_time=0.34694 
Train Epoch: 34 [45/250 5760/32000 (18%)] Loss: 1.96520 (semantic_loss: 0.01488, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.33149 
Train Epoch: 34 [56/250 7168/32000 (22%)] Loss: 1.96587 (semantic_loss: 0.01555, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.47599 
Train Epoch: 34 [67/250 8576/32000 (27%)] Loss: 1.96735 (semantic_loss: 0.01606, quant_loss: 1.95117, bit_balance_loss: 0.00012) batch_time=6.96002 
Train Epoch: 34 [78/250 9984/32000 (31%)] Loss: 1.96586 (semantic_loss: 0.01554, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.34734 
Train Epoch: 34 [89/250 11392/32000 (36%)] Loss: 1.96386 (semantic_loss: 0.01355, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.33648 
Train Epoch: 34 [100/250 12800/32000 (40%)] Loss: 1.96620 (semantic_loss: 0.01589, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.32188 
Train Epoch: 34 [111/250 14208/32000 (44%)] Loss: 1.96642 (semantic_loss: 0.01610, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.34093 
Train Epoch: 34 [122/250 15616/32000 (49%)] Loss: 1.96635 (semantic_loss: 0.01604, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.43347 
Train Epoch: 34 [133/250 17024/32000 (53%)] Loss: 1.96556 (semantic_loss: 0.01622, quant_loss: 1.94922, bit_balance_loss: 0.00012) batch_time=1.11863 
Train Epoch: 34 [144/250 18432/32000 (58%)] Loss: 1.96551 (semantic_loss: 0.01520, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.33017 
Train Epoch: 34 [155/250 19840/32000 (62%)] Loss: 1.96500 (semantic_loss: 0.01468, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.33285 
Train Epoch: 34 [166/250 21248/32000 (66%)] Loss: 1.96661 (semantic_loss: 0.01630, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.34314 
Train Epoch: 34 [177/250 22656/32000 (71%)] Loss: 1.96650 (semantic_loss: 0.01619, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.38889 
Train Epoch: 34 [188/250 24064/32000 (75%)] Loss: 1.96510 (semantic_loss: 0.01479, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=1.56686 
Train Epoch: 34 [199/250 25472/32000 (80%)] Loss: 1.96479 (semantic_loss: 0.01447, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.34291 
Train Epoch: 34 [210/250 26880/32000 (84%)] Loss: 1.96573 (semantic_loss: 0.01542, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.37488 
Train Epoch: 34 [221/250 28288/32000 (88%)] Loss: 1.96712 (semantic_loss: 0.01680, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.32090 
Train Epoch: 34 [232/250 29696/32000 (93%)] Loss: 1.96372 (semantic_loss: 0.01438, quant_loss: 1.94922, bit_balance_loss: 0.00012) batch_time=0.32901 
Train Epoch: 34 [243/250 31104/32000 (97%)] Loss: 1.96581 (semantic_loss: 0.01550, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.31883 
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/DCMH_MSRVTT_1kB/checkpoint-epoch34.pth ...
Done in 9.733s
Updating 'best' checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/DCMH_MSRVTT_1kB/checkpoint-epoch34.pth ...
Done in 21.684s
removing stale ckpt [epoch 33] [took 0.00s]
 epoch          : 34
 loss           : 1.9656524090766907
 learning_rate  : 9.20129551177879e-06
 n_samples      : 1088000
 n_steps        : 8500
 MSRVTT_miech_test/t2v_metrics/R1: 14.1
 MSRVTT_miech_test/t2v_metrics/R5: 41.0
 MSRVTT_miech_test/t2v_metrics/R10: 55.4
 MSRVTT_miech_test/t2v_metrics/R50: 83.7
 MSRVTT_miech_test/t2v_metrics/MedR: 8.0
 MSRVTT_miech_test/t2v_metrics/MeanR: 40.4695
 MSRVTT_miech_test/t2v_metrics/geometric_mean_R1-R5-R10: 31.756861724015703
 MSRVTT_miech_test/v2t_metrics/R1: 15.2
 MSRVTT_miech_test/v2t_metrics/R5: 43.1
 MSRVTT_miech_test/v2t_metrics/R10: 56.9
 MSRVTT_miech_test/v2t_metrics/R50: 83.9
 MSRVTT_miech_test/v2t_metrics/MedR: 8.0
 MSRVTT_miech_test/v2t_metrics/MeanR: 37.579
 MSRVTT_miech_test/v2t_metrics/geometric_mean_R1-R5-R10: 33.404966572322444
 mnt_best       : 31.756861724015703
 not_improved_count: 0
Train Epoch: 35 [1/250 128/32000 (0%)] Loss: 1.96483 (semantic_loss: 0.01452, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=32.64384 
Train Epoch: 35 [12/250 1536/32000 (5%)] Loss: 1.96569 (semantic_loss: 0.01537, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.35337 
Train Epoch: 35 [23/250 2944/32000 (9%)] Loss: 1.96668 (semantic_loss: 0.01637, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.33702 
Train Epoch: 35 [34/250 4352/32000 (14%)] Loss: 1.96502 (semantic_loss: 0.01569, quant_loss: 1.94922, bit_balance_loss: 0.00012) batch_time=0.95767 
Train Epoch: 35 [45/250 5760/32000 (18%)] Loss: 1.96714 (semantic_loss: 0.01683, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.39845 
Train Epoch: 35 [56/250 7168/32000 (22%)] Loss: 1.96478 (semantic_loss: 0.01446, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.35334 
Train Epoch: 35 [67/250 8576/32000 (27%)] Loss: 1.96547 (semantic_loss: 0.01614, quant_loss: 1.94922, bit_balance_loss: 0.00012) batch_time=1.07136 
Train Epoch: 35 [78/250 9984/32000 (31%)] Loss: 1.96572 (semantic_loss: 0.01541, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=1.18050 
Train Epoch: 35 [89/250 11392/32000 (36%)] Loss: 1.96559 (semantic_loss: 0.01527, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.33246 
Train Epoch: 35 [100/250 12800/32000 (40%)] Loss: 1.96486 (semantic_loss: 0.01553, quant_loss: 1.94922, bit_balance_loss: 0.00012) batch_time=0.33438 
Train Epoch: 35 [111/250 14208/32000 (44%)] Loss: 1.96680 (semantic_loss: 0.01648, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.55950 
Train Epoch: 35 [122/250 15616/32000 (49%)] Loss: 1.96782 (semantic_loss: 0.01750, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.39232 
Train Epoch: 35 [133/250 17024/32000 (53%)] Loss: 1.96593 (semantic_loss: 0.01561, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.34415 
Train Epoch: 35 [144/250 18432/32000 (58%)] Loss: 1.96496 (semantic_loss: 0.01562, quant_loss: 1.94922, bit_balance_loss: 0.00012) batch_time=0.32558 
Train Epoch: 35 [155/250 19840/32000 (62%)] Loss: 1.96582 (semantic_loss: 0.01551, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.36772 
Train Epoch: 35 [166/250 21248/32000 (66%)] Loss: 1.96744 (semantic_loss: 0.01713, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.36077 
Train Epoch: 35 [177/250 22656/32000 (71%)] Loss: 1.96564 (semantic_loss: 0.01631, quant_loss: 1.94922, bit_balance_loss: 0.00012) batch_time=0.33149 
Train Epoch: 35 [188/250 24064/32000 (75%)] Loss: 1.96736 (semantic_loss: 0.01705, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.43178 
Train Epoch: 35 [199/250 25472/32000 (80%)] Loss: 1.96620 (semantic_loss: 0.01589, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.32391 
Train Epoch: 35 [210/250 26880/32000 (84%)] Loss: 1.96559 (semantic_loss: 0.01527, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=1.53867 
Train Epoch: 35 [221/250 28288/32000 (88%)] Loss: 1.96574 (semantic_loss: 0.01542, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.32802 
Train Epoch: 35 [232/250 29696/32000 (93%)] Loss: 1.96550 (semantic_loss: 0.01519, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.33199 
Train Epoch: 35 [243/250 31104/32000 (97%)] Loss: 1.96583 (semantic_loss: 0.01649, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=0.33615 
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/DCMH_MSRVTT_1kB/checkpoint-epoch35.pth ...
Done in 15.119s
Updating 'best' checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/DCMH_MSRVTT_1kB/checkpoint-epoch35.pth ...
Done in 18.672s
removing stale ckpt [epoch 34] [took 0.00s]
 epoch          : 35
 loss           : 1.9655046463012695
 learning_rate  : 8.74123073618985e-06
 n_samples      : 1120000
 n_steps        : 8750
 MSRVTT_miech_test/t2v_metrics/R1: 14.5
 MSRVTT_miech_test/t2v_metrics/R5: 41.4
 MSRVTT_miech_test/t2v_metrics/R10: 56.7
 MSRVTT_miech_test/t2v_metrics/R50: 83.7
 MSRVTT_miech_test/t2v_metrics/MedR: 8.0
 MSRVTT_miech_test/t2v_metrics/MeanR: 40.594
 MSRVTT_miech_test/t2v_metrics/geometric_mean_R1-R5-R10: 32.407868459331354
 MSRVTT_miech_test/v2t_metrics/R1: 16.5
 MSRVTT_miech_test/v2t_metrics/R5: 41.9
 MSRVTT_miech_test/v2t_metrics/R10: 56.9
 MSRVTT_miech_test/v2t_metrics/R50: 83.6
 MSRVTT_miech_test/v2t_metrics/MedR: 8.0
 MSRVTT_miech_test/v2t_metrics/MeanR: 37.489
 MSRVTT_miech_test/v2t_metrics/geometric_mean_R1-R5-R10: 34.00974778175038
 mnt_best       : 32.407868459331354
 not_improved_count: 0
Train Epoch: 36 [1/250 128/32000 (0%)] Loss: 1.96398 (semantic_loss: 0.01464, quant_loss: 1.94922, bit_balance_loss: 0.00012) batch_time=22.43522 
Train Epoch: 36 [12/250 1536/32000 (5%)] Loss: 1.96455 (semantic_loss: 0.01424, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.33746 
Train Epoch: 36 [23/250 2944/32000 (9%)] Loss: 1.96651 (semantic_loss: 0.01620, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.33342 
Train Epoch: 36 [34/250 4352/32000 (14%)] Loss: 1.96489 (semantic_loss: 0.01457, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.31989 
Train Epoch: 36 [45/250 5760/32000 (18%)] Loss: 1.96542 (semantic_loss: 0.01511, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.35446 
Train Epoch: 36 [56/250 7168/32000 (22%)] Loss: 1.96488 (semantic_loss: 0.01457, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.33262 
Train Epoch: 36 [67/250 8576/32000 (27%)] Loss: 1.96435 (semantic_loss: 0.01404, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.53536 
Train Epoch: 36 [78/250 9984/32000 (31%)] Loss: 1.96511 (semantic_loss: 0.01577, quant_loss: 1.94922, bit_balance_loss: 0.00012) batch_time=3.34426 
Train Epoch: 36 [89/250 11392/32000 (36%)] Loss: 1.96646 (semantic_loss: 0.01712, quant_loss: 1.94922, bit_balance_loss: 0.00012) batch_time=1.05123 
Train Epoch: 36 [100/250 12800/32000 (40%)] Loss: 1.96540 (semantic_loss: 0.01508, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.33387 
Train Epoch: 36 [111/250 14208/32000 (44%)] Loss: 1.96719 (semantic_loss: 0.01590, quant_loss: 1.95117, bit_balance_loss: 0.00012) batch_time=0.32889 
Train Epoch: 36 [122/250 15616/32000 (49%)] Loss: 1.96294 (semantic_loss: 0.01263, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.33819 
Train Epoch: 36 [133/250 17024/32000 (53%)] Loss: 1.96515 (semantic_loss: 0.01484, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.37923 
Train Epoch: 36 [144/250 18432/32000 (58%)] Loss: 1.96495 (semantic_loss: 0.01463, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.34335 
Train Epoch: 36 [155/250 19840/32000 (62%)] Loss: 1.96687 (semantic_loss: 0.01655, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.33549 
Train Epoch: 36 [166/250 21248/32000 (66%)] Loss: 1.96386 (semantic_loss: 0.01453, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=0.59645 
Train Epoch: 36 [177/250 22656/32000 (71%)] Loss: 1.96422 (semantic_loss: 0.01489, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=0.33141 
Train Epoch: 36 [188/250 24064/32000 (75%)] Loss: 1.96453 (semantic_loss: 0.01519, quant_loss: 1.94922, bit_balance_loss: 0.00012) batch_time=0.33313 
Train Epoch: 36 [199/250 25472/32000 (80%)] Loss: 1.96637 (semantic_loss: 0.01606, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.38896 
Train Epoch: 36 [210/250 26880/32000 (84%)] Loss: 1.96606 (semantic_loss: 0.01672, quant_loss: 1.94922, bit_balance_loss: 0.00012) batch_time=0.34240 
Train Epoch: 36 [221/250 28288/32000 (88%)] Loss: 1.96515 (semantic_loss: 0.01483, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.38502 
Train Epoch: 36 [232/250 29696/32000 (93%)] Loss: 1.96567 (semantic_loss: 0.01634, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=0.36729 
Train Epoch: 36 [243/250 31104/32000 (97%)] Loss: 1.96523 (semantic_loss: 0.01491, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.36631 
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/DCMH_MSRVTT_1kB/checkpoint-epoch36.pth ...
Done in 18.081s
Updating 'best' checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/DCMH_MSRVTT_1kB/checkpoint-epoch36.pth ...
Done in 21.654s
removing stale ckpt [epoch 35] [took 0.01s]
 epoch          : 36
 loss           : 1.9653920545578003
 learning_rate  : 8.304169199380357e-06
 n_samples      : 1152000
 n_steps        : 9000
 MSRVTT_miech_test/t2v_metrics/R1: 15.3
 MSRVTT_miech_test/t2v_metrics/R5: 42.2
 MSRVTT_miech_test/t2v_metrics/R10: 55.6
 MSRVTT_miech_test/t2v_metrics/R50: 83.9
 MSRVTT_miech_test/t2v_metrics/MedR: 8.0
 MSRVTT_miech_test/t2v_metrics/MeanR: 41.32
 MSRVTT_miech_test/t2v_metrics/geometric_mean_R1-R5-R10: 32.98827131403981
 MSRVTT_miech_test/v2t_metrics/R1: 13.8
 MSRVTT_miech_test/v2t_metrics/R5: 42.0
 MSRVTT_miech_test/v2t_metrics/R10: 55.8
 MSRVTT_miech_test/v2t_metrics/R50: 83.9
 MSRVTT_miech_test/v2t_metrics/MedR: 8.0
 MSRVTT_miech_test/v2t_metrics/MeanR: 37.8725
 MSRVTT_miech_test/v2t_metrics/geometric_mean_R1-R5-R10: 31.860617733029976
 mnt_best       : 32.98827131403981
 not_improved_count: 0
Train Epoch: 37 [1/250 128/32000 (0%)] Loss: 1.96395 (semantic_loss: 0.01364, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=37.29895 
Train Epoch: 37 [12/250 1536/32000 (5%)] Loss: 1.96359 (semantic_loss: 0.01425, quant_loss: 1.94922, bit_balance_loss: 0.00012) batch_time=0.34261 
Train Epoch: 37 [23/250 2944/32000 (9%)] Loss: 1.96520 (semantic_loss: 0.01488, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.32489 
Train Epoch: 37 [34/250 4352/32000 (14%)] Loss: 1.96526 (semantic_loss: 0.01495, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.56507 
Train Epoch: 37 [45/250 5760/32000 (18%)] Loss: 1.96568 (semantic_loss: 0.01537, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.36193 
Train Epoch: 37 [56/250 7168/32000 (22%)] Loss: 1.96657 (semantic_loss: 0.01626, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.33123 
Train Epoch: 37 [67/250 8576/32000 (27%)] Loss: 1.96535 (semantic_loss: 0.01602, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=0.33266 
Train Epoch: 37 [78/250 9984/32000 (31%)] Loss: 1.96484 (semantic_loss: 0.01453, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.32969 
Train Epoch: 37 [89/250 11392/32000 (36%)] Loss: 1.96591 (semantic_loss: 0.01560, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.35050 
Train Epoch: 37 [100/250 12800/32000 (40%)] Loss: 1.96459 (semantic_loss: 0.01428, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.33368 
Train Epoch: 37 [111/250 14208/32000 (44%)] Loss: 1.96637 (semantic_loss: 0.01605, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.44973 
Train Epoch: 37 [122/250 15616/32000 (49%)] Loss: 1.96633 (semantic_loss: 0.01602, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.36323 
Train Epoch: 37 [133/250 17024/32000 (53%)] Loss: 1.96520 (semantic_loss: 0.01489, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.32421 
Train Epoch: 37 [144/250 18432/32000 (58%)] Loss: 1.96416 (semantic_loss: 0.01482, quant_loss: 1.94922, bit_balance_loss: 0.00012) batch_time=0.33458 
Train Epoch: 37 [155/250 19840/32000 (62%)] Loss: 1.96645 (semantic_loss: 0.01613, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.32366 
Train Epoch: 37 [166/250 21248/32000 (66%)] Loss: 1.96699 (semantic_loss: 0.01668, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.32622 
Train Epoch: 37 [177/250 22656/32000 (71%)] Loss: 1.96539 (semantic_loss: 0.01507, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.48742 
Train Epoch: 37 [188/250 24064/32000 (75%)] Loss: 1.96424 (semantic_loss: 0.01490, quant_loss: 1.94922, bit_balance_loss: 0.00012) batch_time=0.32937 
Train Epoch: 37 [199/250 25472/32000 (80%)] Loss: 1.96509 (semantic_loss: 0.01478, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.36905 
Train Epoch: 37 [210/250 26880/32000 (84%)] Loss: 1.96519 (semantic_loss: 0.01585, quant_loss: 1.94922, bit_balance_loss: 0.00012) batch_time=0.35783 
Train Epoch: 37 [221/250 28288/32000 (88%)] Loss: 1.96669 (semantic_loss: 0.01638, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.34347 
Train Epoch: 37 [232/250 29696/32000 (93%)] Loss: 1.96574 (semantic_loss: 0.01543, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.33385 
Train Epoch: 37 [243/250 31104/32000 (97%)] Loss: 1.96525 (semantic_loss: 0.01493, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.37607 
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/DCMH_MSRVTT_1kB/checkpoint-epoch37.pth ...
Done in 5.003s
removing stale ckpt [epoch 36] [took 0.00s]
 epoch          : 37
 loss           : 1.9652948307991027
 learning_rate  : 7.888960739411339e-06
 n_samples      : 1184000
 n_steps        : 9250
 MSRVTT_miech_test/t2v_metrics/R1: 14.9
 MSRVTT_miech_test/t2v_metrics/R5: 41.0
 MSRVTT_miech_test/t2v_metrics/R10: 56.2
 MSRVTT_miech_test/t2v_metrics/R50: 83.9
 MSRVTT_miech_test/t2v_metrics/MedR: 8.0
 MSRVTT_miech_test/t2v_metrics/MeanR: 41.1455
 MSRVTT_miech_test/t2v_metrics/geometric_mean_R1-R5-R10: 32.501405856345606
 MSRVTT_miech_test/v2t_metrics/R1: 15.0
 MSRVTT_miech_test/v2t_metrics/R5: 43.8
 MSRVTT_miech_test/v2t_metrics/R10: 57.1
 MSRVTT_miech_test/v2t_metrics/R50: 83.4
 MSRVTT_miech_test/v2t_metrics/MedR: 8.0
 MSRVTT_miech_test/v2t_metrics/MeanR: 38.5045
 MSRVTT_miech_test/v2t_metrics/geometric_mean_R1-R5-R10: 33.47602056135264
 mnt_best       : 32.98827131403981
 not_improved_count: 1
Train Epoch: 38 [1/250 128/32000 (0%)] Loss: 1.96439 (semantic_loss: 0.01408, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=26.66389 
Train Epoch: 38 [12/250 1536/32000 (5%)] Loss: 1.96369 (semantic_loss: 0.01436, quant_loss: 1.94922, bit_balance_loss: 0.00012) batch_time=0.33386 
Train Epoch: 38 [23/250 2944/32000 (9%)] Loss: 1.96329 (semantic_loss: 0.01396, quant_loss: 1.94922, bit_balance_loss: 0.00012) batch_time=0.36296 
Train Epoch: 38 [34/250 4352/32000 (14%)] Loss: 1.96508 (semantic_loss: 0.01476, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.34147 
Train Epoch: 38 [45/250 5760/32000 (18%)] Loss: 1.96563 (semantic_loss: 0.01533, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.33231 
Train Epoch: 38 [56/250 7168/32000 (22%)] Loss: 1.96546 (semantic_loss: 0.01514, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.33993 
Train Epoch: 38 [67/250 8576/32000 (27%)] Loss: 1.96646 (semantic_loss: 0.01614, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.45972 
Train Epoch: 38 [78/250 9984/32000 (31%)] Loss: 1.96410 (semantic_loss: 0.01379, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.35793 
Train Epoch: 38 [89/250 11392/32000 (36%)] Loss: 1.96492 (semantic_loss: 0.01461, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.35235 
Train Epoch: 38 [100/250 12800/32000 (40%)] Loss: 1.96524 (semantic_loss: 0.01492, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.33168 
Train Epoch: 38 [111/250 14208/32000 (44%)] Loss: 1.96462 (semantic_loss: 0.01528, quant_loss: 1.94922, bit_balance_loss: 0.00012) batch_time=0.33121 
Train Epoch: 38 [122/250 15616/32000 (49%)] Loss: 1.96322 (semantic_loss: 0.01388, quant_loss: 1.94922, bit_balance_loss: 0.00012) batch_time=0.33266 
Train Epoch: 38 [133/250 17024/32000 (53%)] Loss: 1.96532 (semantic_loss: 0.01501, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.32185 
Train Epoch: 38 [144/250 18432/32000 (58%)] Loss: 1.96539 (semantic_loss: 0.01605, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=0.36123 
Train Epoch: 38 [155/250 19840/32000 (62%)] Loss: 1.96647 (semantic_loss: 0.01615, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.33344 
Train Epoch: 38 [166/250 21248/32000 (66%)] Loss: 1.96458 (semantic_loss: 0.01426, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.33275 
Train Epoch: 38 [177/250 22656/32000 (71%)] Loss: 1.96359 (semantic_loss: 0.01328, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.33410 
Train Epoch: 38 [188/250 24064/32000 (75%)] Loss: 1.96626 (semantic_loss: 0.01595, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.32401 
Train Epoch: 38 [199/250 25472/32000 (80%)] Loss: 1.96555 (semantic_loss: 0.01524, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.33105 
Train Epoch: 38 [210/250 26880/32000 (84%)] Loss: 1.96454 (semantic_loss: 0.01423, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.34711 
Train Epoch: 38 [221/250 28288/32000 (88%)] Loss: 1.96603 (semantic_loss: 0.01572, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.32648 
Train Epoch: 38 [232/250 29696/32000 (93%)] Loss: 1.96333 (semantic_loss: 0.01399, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=0.33177 
Train Epoch: 38 [243/250 31104/32000 (97%)] Loss: 1.96478 (semantic_loss: 0.01545, quant_loss: 1.94922, bit_balance_loss: 0.00012) batch_time=0.35865 
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/DCMH_MSRVTT_1kB/checkpoint-epoch38.pth ...
Done in 4.001s
removing stale ckpt [epoch 37] [took 0.00s]
 epoch          : 38
 loss           : 1.9651184363365173
 learning_rate  : 7.494512702440772e-06
 n_samples      : 1216000
 n_steps        : 9500
 MSRVTT_miech_test/t2v_metrics/R1: 14.1
 MSRVTT_miech_test/t2v_metrics/R5: 41.8
 MSRVTT_miech_test/t2v_metrics/R10: 57.1
 MSRVTT_miech_test/t2v_metrics/R50: 84.6
 MSRVTT_miech_test/t2v_metrics/MedR: 8.0
 MSRVTT_miech_test/t2v_metrics/MeanR: 40.7215
 MSRVTT_miech_test/t2v_metrics/geometric_mean_R1-R5-R10: 32.28572185053654
 MSRVTT_miech_test/v2t_metrics/R1: 15.2
 MSRVTT_miech_test/v2t_metrics/R5: 43.2
 MSRVTT_miech_test/v2t_metrics/R10: 58.3
 MSRVTT_miech_test/v2t_metrics/R50: 84.3
 MSRVTT_miech_test/v2t_metrics/MedR: 7.0
 MSRVTT_miech_test/v2t_metrics/MeanR: 37.3575
 MSRVTT_miech_test/v2t_metrics/geometric_mean_R1-R5-R10: 33.702746711173575
 mnt_best       : 32.98827131403981
 not_improved_count: 2
Train Epoch: 39 [1/250 128/32000 (0%)] Loss: 1.96517 (semantic_loss: 0.01486, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=29.12849 
Train Epoch: 39 [12/250 1536/32000 (5%)] Loss: 1.96478 (semantic_loss: 0.01544, quant_loss: 1.94922, bit_balance_loss: 0.00012) batch_time=3.70077 
Train Epoch: 39 [23/250 2944/32000 (9%)] Loss: 1.96484 (semantic_loss: 0.01550, quant_loss: 1.94922, bit_balance_loss: 0.00012) batch_time=0.33423 
Train Epoch: 39 [34/250 4352/32000 (14%)] Loss: 1.96571 (semantic_loss: 0.01637, quant_loss: 1.94922, bit_balance_loss: 0.00012) batch_time=0.32833 
Train Epoch: 39 [45/250 5760/32000 (18%)] Loss: 1.96539 (semantic_loss: 0.01508, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.42643 
Train Epoch: 39 [56/250 7168/32000 (22%)] Loss: 1.96467 (semantic_loss: 0.01533, quant_loss: 1.94922, bit_balance_loss: 0.00012) batch_time=0.36035 
Train Epoch: 39 [67/250 8576/32000 (27%)] Loss: 1.96411 (semantic_loss: 0.01477, quant_loss: 1.94922, bit_balance_loss: 0.00012) batch_time=0.32340 
Train Epoch: 39 [78/250 9984/32000 (31%)] Loss: 1.96415 (semantic_loss: 0.01384, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.32689 
Train Epoch: 39 [89/250 11392/32000 (36%)] Loss: 1.96566 (semantic_loss: 0.01534, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.32118 
Train Epoch: 39 [100/250 12800/32000 (40%)] Loss: 1.96437 (semantic_loss: 0.01504, quant_loss: 1.94922, bit_balance_loss: 0.00012) batch_time=0.32505 
Train Epoch: 39 [111/250 14208/32000 (44%)] Loss: 1.96448 (semantic_loss: 0.01417, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.32653 
Train Epoch: 39 [122/250 15616/32000 (49%)] Loss: 1.96546 (semantic_loss: 0.01515, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.39046 
Train Epoch: 39 [133/250 17024/32000 (53%)] Loss: 1.96443 (semantic_loss: 0.01412, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.37864 
Train Epoch: 39 [144/250 18432/32000 (58%)] Loss: 1.96640 (semantic_loss: 0.01609, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.32953 
Train Epoch: 39 [155/250 19840/32000 (62%)] Loss: 1.96353 (semantic_loss: 0.01321, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.32128 
Train Epoch: 39 [166/250 21248/32000 (66%)] Loss: 1.96513 (semantic_loss: 0.01482, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.32731 
Train Epoch: 39 [177/250 22656/32000 (71%)] Loss: 1.96353 (semantic_loss: 0.01419, quant_loss: 1.94922, bit_balance_loss: 0.00012) batch_time=0.33148 
Train Epoch: 39 [188/250 24064/32000 (75%)] Loss: 1.96594 (semantic_loss: 0.01563, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.35692 
Train Epoch: 39 [199/250 25472/32000 (80%)] Loss: 1.96436 (semantic_loss: 0.01502, quant_loss: 1.94922, bit_balance_loss: 0.00012) batch_time=0.39651 
Train Epoch: 39 [210/250 26880/32000 (84%)] Loss: 1.96278 (semantic_loss: 0.01344, quant_loss: 1.94922, bit_balance_loss: 0.00012) batch_time=0.32942 
Train Epoch: 39 [221/250 28288/32000 (88%)] Loss: 1.96467 (semantic_loss: 0.01436, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.32345 
Train Epoch: 39 [232/250 29696/32000 (93%)] Loss: 1.96522 (semantic_loss: 0.01491, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.34499 
Train Epoch: 39 [243/250 31104/32000 (97%)] Loss: 1.96478 (semantic_loss: 0.01446, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.32420 
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/DCMH_MSRVTT_1kB/checkpoint-epoch39.pth ...
Done in 4.082s
removing stale ckpt [epoch 38] [took 0.00s]
 epoch          : 39
 loss           : 1.9649918036460876
 learning_rate  : 7.119787067318733e-06
 n_samples      : 1248000
 n_steps        : 9750
 MSRVTT_miech_test/t2v_metrics/R1: 14.6
 MSRVTT_miech_test/t2v_metrics/R5: 40.5
 MSRVTT_miech_test/t2v_metrics/R10: 56.3
 MSRVTT_miech_test/t2v_metrics/R50: 84.1
 MSRVTT_miech_test/t2v_metrics/MedR: 8.0
 MSRVTT_miech_test/t2v_metrics/MeanR: 40.614
 MSRVTT_miech_test/t2v_metrics/geometric_mean_R1-R5-R10: 32.16908868205666
 MSRVTT_miech_test/v2t_metrics/R1: 15.1
 MSRVTT_miech_test/v2t_metrics/R5: 41.9
 MSRVTT_miech_test/v2t_metrics/R10: 56.7
 MSRVTT_miech_test/v2t_metrics/R50: 84.4
 MSRVTT_miech_test/v2t_metrics/MedR: 8.0
 MSRVTT_miech_test/v2t_metrics/MeanR: 37.4935
 MSRVTT_miech_test/v2t_metrics/geometric_mean_R1-R5-R10: 32.9805587968382
 mnt_best       : 32.98827131403981
 not_improved_count: 3
Train Epoch: 40 [1/250 128/32000 (0%)] Loss: 1.96427 (semantic_loss: 0.01493, quant_loss: 1.94922, bit_balance_loss: 0.00012) batch_time=43.33421 
Train Epoch: 40 [12/250 1536/32000 (5%)] Loss: 1.96710 (semantic_loss: 0.01679, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.41114 
Train Epoch: 40 [23/250 2944/32000 (9%)] Loss: 1.96403 (semantic_loss: 0.01470, quant_loss: 1.94922, bit_balance_loss: 0.00012) batch_time=0.33317 
Train Epoch: 40 [34/250 4352/32000 (14%)] Loss: 1.96420 (semantic_loss: 0.01487, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=0.38652 
Train Epoch: 40 [45/250 5760/32000 (18%)] Loss: 1.96526 (semantic_loss: 0.01592, quant_loss: 1.94922, bit_balance_loss: 0.00012) batch_time=0.33441 
Train Epoch: 40 [56/250 7168/32000 (22%)] Loss: 1.96254 (semantic_loss: 0.01320, quant_loss: 1.94922, bit_balance_loss: 0.00012) batch_time=0.37571 
Train Epoch: 40 [67/250 8576/32000 (27%)] Loss: 1.96592 (semantic_loss: 0.01561, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.51194 
Train Epoch: 40 [78/250 9984/32000 (31%)] Loss: 1.96569 (semantic_loss: 0.01538, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.39388 
Train Epoch: 40 [89/250 11392/32000 (36%)] Loss: 1.96346 (semantic_loss: 0.01412, quant_loss: 1.94922, bit_balance_loss: 0.00012) batch_time=0.33206 
Train Epoch: 40 [100/250 12800/32000 (40%)] Loss: 1.96575 (semantic_loss: 0.01544, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.33763 
Train Epoch: 40 [111/250 14208/32000 (44%)] Loss: 1.96300 (semantic_loss: 0.01366, quant_loss: 1.94922, bit_balance_loss: 0.00012) batch_time=0.35422 
Train Epoch: 40 [122/250 15616/32000 (49%)] Loss: 1.96336 (semantic_loss: 0.01403, quant_loss: 1.94922, bit_balance_loss: 0.00012) batch_time=0.63722 
Train Epoch: 40 [133/250 17024/32000 (53%)] Loss: 1.96421 (semantic_loss: 0.01488, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=0.42753 
Train Epoch: 40 [144/250 18432/32000 (58%)] Loss: 1.96494 (semantic_loss: 0.01462, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.43047 
Train Epoch: 40 [155/250 19840/32000 (62%)] Loss: 1.96488 (semantic_loss: 0.01457, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.38215 
Train Epoch: 40 [166/250 21248/32000 (66%)] Loss: 1.96318 (semantic_loss: 0.01384, quant_loss: 1.94922, bit_balance_loss: 0.00012) batch_time=0.32351 
Train Epoch: 40 [177/250 22656/32000 (71%)] Loss: 1.96475 (semantic_loss: 0.01542, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=0.32969 
Train Epoch: 40 [188/250 24064/32000 (75%)] Loss: 1.96547 (semantic_loss: 0.01613, quant_loss: 1.94922, bit_balance_loss: 0.00012) batch_time=0.32386 
Train Epoch: 40 [199/250 25472/32000 (80%)] Loss: 1.96392 (semantic_loss: 0.01458, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=0.33018 
Train Epoch: 40 [210/250 26880/32000 (84%)] Loss: 1.96440 (semantic_loss: 0.01507, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=0.42328 
Train Epoch: 40 [221/250 28288/32000 (88%)] Loss: 1.96384 (semantic_loss: 0.01451, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=0.44716 
Train Epoch: 40 [232/250 29696/32000 (93%)] Loss: 1.96368 (semantic_loss: 0.01435, quant_loss: 1.94922, bit_balance_loss: 0.00012) batch_time=0.74540 
Train Epoch: 40 [243/250 31104/32000 (97%)] Loss: 1.96370 (semantic_loss: 0.01437, quant_loss: 1.94922, bit_balance_loss: 0.00012) batch_time=0.36446 
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/DCMH_MSRVTT_1kB/checkpoint-epoch40.pth ...
Done in 3.827s
removing stale ckpt [epoch 39] [took 0.00s]
 epoch          : 40
 loss           : 1.9649385843276979
 learning_rate  : 6.763797713952796e-06
 n_samples      : 1280000
 n_steps        : 10000
 MSRVTT_miech_test/t2v_metrics/R1: 14.2
 MSRVTT_miech_test/t2v_metrics/R5: 40.6
 MSRVTT_miech_test/t2v_metrics/R10: 56.1
 MSRVTT_miech_test/t2v_metrics/R50: 84.1
 MSRVTT_miech_test/t2v_metrics/MedR: 8.0
 MSRVTT_miech_test/t2v_metrics/MeanR: 41.265
 MSRVTT_miech_test/t2v_metrics/geometric_mean_R1-R5-R10: 31.860976314721867
 MSRVTT_miech_test/v2t_metrics/R1: 15.4
 MSRVTT_miech_test/v2t_metrics/R5: 42.1
 MSRVTT_miech_test/v2t_metrics/R10: 57.1
 MSRVTT_miech_test/v2t_metrics/R50: 84.6
 MSRVTT_miech_test/v2t_metrics/MedR: 8.0
 MSRVTT_miech_test/v2t_metrics/MeanR: 38.263
 MSRVTT_miech_test/v2t_metrics/geometric_mean_R1-R5-R10: 33.32828565788998
 mnt_best       : 32.98827131403981
 not_improved_count: 4
Train Epoch: 41 [1/250 128/32000 (0%)] Loss: 1.96550 (semantic_loss: 0.01617, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=38.90862 
Train Epoch: 41 [12/250 1536/32000 (5%)] Loss: 1.96586 (semantic_loss: 0.01555, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.33853 
Train Epoch: 41 [23/250 2944/32000 (9%)] Loss: 1.96401 (semantic_loss: 0.01370, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=2.23924 
Train Epoch: 41 [34/250 4352/32000 (14%)] Loss: 1.96498 (semantic_loss: 0.01565, quant_loss: 1.94922, bit_balance_loss: 0.00012) batch_time=0.37455 
Train Epoch: 41 [45/250 5760/32000 (18%)] Loss: 1.96404 (semantic_loss: 0.01373, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.32369 
Train Epoch: 41 [56/250 7168/32000 (22%)] Loss: 1.96383 (semantic_loss: 0.01449, quant_loss: 1.94922, bit_balance_loss: 0.00012) batch_time=0.41549 
Train Epoch: 41 [67/250 8576/32000 (27%)] Loss: 1.96609 (semantic_loss: 0.01577, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.33866 
Train Epoch: 41 [78/250 9984/32000 (31%)] Loss: 1.96401 (semantic_loss: 0.01468, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=0.42703 
Train Epoch: 41 [89/250 11392/32000 (36%)] Loss: 1.96384 (semantic_loss: 0.01451, quant_loss: 1.94922, bit_balance_loss: 0.00012) batch_time=0.33802 
Train Epoch: 41 [100/250 12800/32000 (40%)] Loss: 1.96531 (semantic_loss: 0.01500, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.40397 
Train Epoch: 41 [111/250 14208/32000 (44%)] Loss: 1.96519 (semantic_loss: 0.01585, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=0.35947 
Train Epoch: 41 [122/250 15616/32000 (49%)] Loss: 1.96424 (semantic_loss: 0.01392, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.32332 
Train Epoch: 41 [133/250 17024/32000 (53%)] Loss: 1.96491 (semantic_loss: 0.01460, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.38323 
Train Epoch: 41 [144/250 18432/32000 (58%)] Loss: 1.96527 (semantic_loss: 0.01495, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.34067 
Train Epoch: 41 [155/250 19840/32000 (62%)] Loss: 1.96272 (semantic_loss: 0.01337, quant_loss: 1.94922, bit_balance_loss: 0.00012) batch_time=0.33225 
Train Epoch: 41 [166/250 21248/32000 (66%)] Loss: 1.96636 (semantic_loss: 0.01605, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.56458 
Train Epoch: 41 [177/250 22656/32000 (71%)] Loss: 1.96636 (semantic_loss: 0.01604, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.41357 
Train Epoch: 41 [188/250 24064/32000 (75%)] Loss: 1.96681 (semantic_loss: 0.01650, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.34276 
Train Epoch: 41 [199/250 25472/32000 (80%)] Loss: 1.96530 (semantic_loss: 0.01597, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=0.34356 
Train Epoch: 41 [210/250 26880/32000 (84%)] Loss: 1.96603 (semantic_loss: 0.01571, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.33734 
Train Epoch: 41 [221/250 28288/32000 (88%)] Loss: 1.96389 (semantic_loss: 0.01456, quant_loss: 1.94922, bit_balance_loss: 0.00012) batch_time=0.34908 
Train Epoch: 41 [232/250 29696/32000 (93%)] Loss: 1.96407 (semantic_loss: 0.01376, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.32942 
Train Epoch: 41 [243/250 31104/32000 (97%)] Loss: 1.96402 (semantic_loss: 0.01371, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.39412 
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/DCMH_MSRVTT_1kB/checkpoint-epoch41.pth ...
Done in 9.090s
removing stale ckpt [epoch 40] [took 0.00s]
 epoch          : 41
 loss           : 1.9649363865852356
 learning_rate  : 6.425607828255156e-06
 n_samples      : 1312000
 n_steps        : 10250
 MSRVTT_miech_test/t2v_metrics/R1: 14.5
 MSRVTT_miech_test/t2v_metrics/R5: 42.0
 MSRVTT_miech_test/t2v_metrics/R10: 57.0
 MSRVTT_miech_test/t2v_metrics/R50: 83.9
 MSRVTT_miech_test/t2v_metrics/MedR: 8.0
 MSRVTT_miech_test/t2v_metrics/MeanR: 40.487
 MSRVTT_miech_test/t2v_metrics/geometric_mean_R1-R5-R10: 32.62100845164315
 MSRVTT_miech_test/v2t_metrics/R1: 15.9
 MSRVTT_miech_test/v2t_metrics/R5: 42.9
 MSRVTT_miech_test/v2t_metrics/R10: 57.6
 MSRVTT_miech_test/v2t_metrics/R50: 84.0
 MSRVTT_miech_test/v2t_metrics/MedR: 7.5
 MSRVTT_miech_test/v2t_metrics/MeanR: 37.213
 MSRVTT_miech_test/v2t_metrics/geometric_mean_R1-R5-R10: 33.995828784709005
 mnt_best       : 32.98827131403981
 not_improved_count: 5
Train Epoch: 42 [1/250 128/32000 (0%)] Loss: 1.96391 (semantic_loss: 0.01359, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=30.72498 
Train Epoch: 42 [12/250 1536/32000 (5%)] Loss: 1.96344 (semantic_loss: 0.01410, quant_loss: 1.94922, bit_balance_loss: 0.00012) batch_time=0.34346 
Train Epoch: 42 [23/250 2944/32000 (9%)] Loss: 1.96552 (semantic_loss: 0.01521, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=1.69703 
Train Epoch: 42 [34/250 4352/32000 (14%)] Loss: 1.96418 (semantic_loss: 0.01387, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.33606 
Train Epoch: 42 [45/250 5760/32000 (18%)] Loss: 1.96644 (semantic_loss: 0.01613, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.41523 
Train Epoch: 42 [56/250 7168/32000 (22%)] Loss: 1.96513 (semantic_loss: 0.01482, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.41155 
Train Epoch: 42 [67/250 8576/32000 (27%)] Loss: 1.96574 (semantic_loss: 0.01543, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.34851 
Train Epoch: 42 [78/250 9984/32000 (31%)] Loss: 1.96503 (semantic_loss: 0.01472, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.32466 
Train Epoch: 42 [89/250 11392/32000 (36%)] Loss: 1.96564 (semantic_loss: 0.01533, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.32779 
Train Epoch: 42 [100/250 12800/32000 (40%)] Loss: 1.96416 (semantic_loss: 0.01482, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=0.32992 
Train Epoch: 42 [111/250 14208/32000 (44%)] Loss: 1.96408 (semantic_loss: 0.01376, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.32334 
Train Epoch: 42 [122/250 15616/32000 (49%)] Loss: 1.96547 (semantic_loss: 0.01516, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.57590 
Train Epoch: 42 [133/250 17024/32000 (53%)] Loss: 1.96380 (semantic_loss: 0.01349, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.32330 
Train Epoch: 42 [144/250 18432/32000 (58%)] Loss: 1.96364 (semantic_loss: 0.01332, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.39295 
Train Epoch: 42 [155/250 19840/32000 (62%)] Loss: 1.96631 (semantic_loss: 0.01600, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.33317 
Train Epoch: 42 [166/250 21248/32000 (66%)] Loss: 1.96476 (semantic_loss: 0.01445, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.33740 
Train Epoch: 42 [177/250 22656/32000 (71%)] Loss: 1.96473 (semantic_loss: 0.01442, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.32866 
Train Epoch: 42 [188/250 24064/32000 (75%)] Loss: 1.96413 (semantic_loss: 0.01479, quant_loss: 1.94922, bit_balance_loss: 0.00012) batch_time=0.40105 
Train Epoch: 42 [199/250 25472/32000 (80%)] Loss: 1.96477 (semantic_loss: 0.01543, quant_loss: 1.94922, bit_balance_loss: 0.00012) batch_time=0.33480 
Train Epoch: 42 [210/250 26880/32000 (84%)] Loss: 1.96696 (semantic_loss: 0.01665, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.32153 
Train Epoch: 42 [221/250 28288/32000 (88%)] Loss: 1.96594 (semantic_loss: 0.01563, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.33904 
Train Epoch: 42 [232/250 29696/32000 (93%)] Loss: 1.96485 (semantic_loss: 0.01454, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.33508 
Train Epoch: 42 [243/250 31104/32000 (97%)] Loss: 1.96504 (semantic_loss: 0.01472, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.35110 
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/DCMH_MSRVTT_1kB/checkpoint-epoch42.pth ...
Done in 3.534s
removing stale ckpt [epoch 41] [took 0.01s]
 epoch          : 42
 loss           : 1.9648803720474244
 learning_rate  : 6.104327436842398e-06
 n_samples      : 1344000
 n_steps        : 10500
 MSRVTT_miech_test/t2v_metrics/R1: 13.8
 MSRVTT_miech_test/t2v_metrics/R5: 41.1
 MSRVTT_miech_test/t2v_metrics/R10: 56.6
 MSRVTT_miech_test/t2v_metrics/R50: 83.6
 MSRVTT_miech_test/t2v_metrics/MedR: 8.0
 MSRVTT_miech_test/t2v_metrics/MeanR: 41.317
 MSRVTT_miech_test/t2v_metrics/geometric_mean_R1-R5-R10: 31.78184557696754
 MSRVTT_miech_test/v2t_metrics/R1: 15.7
 MSRVTT_miech_test/v2t_metrics/R5: 42.4
 MSRVTT_miech_test/v2t_metrics/R10: 57.8
 MSRVTT_miech_test/v2t_metrics/R50: 83.9
 MSRVTT_miech_test/v2t_metrics/MedR: 7.5
 MSRVTT_miech_test/v2t_metrics/MeanR: 37.8275
 MSRVTT_miech_test/v2t_metrics/geometric_mean_R1-R5-R10: 33.75963810697474
 mnt_best       : 32.98827131403981
 not_improved_count: 6
Train Epoch: 43 [1/250 128/32000 (0%)] Loss: 1.96598 (semantic_loss: 0.01568, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=38.92305 
Train Epoch: 43 [12/250 1536/32000 (5%)] Loss: 1.96443 (semantic_loss: 0.01412, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.39202 
Train Epoch: 43 [23/250 2944/32000 (9%)] Loss: 1.96365 (semantic_loss: 0.01431, quant_loss: 1.94922, bit_balance_loss: 0.00012) batch_time=0.36095 
Train Epoch: 43 [34/250 4352/32000 (14%)] Loss: 1.96551 (semantic_loss: 0.01519, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.38245 
Train Epoch: 43 [45/250 5760/32000 (18%)] Loss: 1.96434 (semantic_loss: 0.01403, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.35458 
Train Epoch: 43 [56/250 7168/32000 (22%)] Loss: 1.96374 (semantic_loss: 0.01440, quant_loss: 1.94922, bit_balance_loss: 0.00012) batch_time=0.33171 
Train Epoch: 43 [67/250 8576/32000 (27%)] Loss: 1.96378 (semantic_loss: 0.01347, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.32796 
Train Epoch: 43 [78/250 9984/32000 (31%)] Loss: 1.96367 (semantic_loss: 0.01434, quant_loss: 1.94922, bit_balance_loss: 0.00012) batch_time=0.40225 
Train Epoch: 43 [89/250 11392/32000 (36%)] Loss: 1.96435 (semantic_loss: 0.01403, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.35331 
Train Epoch: 43 [100/250 12800/32000 (40%)] Loss: 1.96570 (semantic_loss: 0.01539, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.35100 
Train Epoch: 43 [111/250 14208/32000 (44%)] Loss: 1.96437 (semantic_loss: 0.01504, quant_loss: 1.94922, bit_balance_loss: 0.00012) batch_time=0.39344 
Train Epoch: 43 [122/250 15616/32000 (49%)] Loss: 1.96448 (semantic_loss: 0.01417, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.32333 
Train Epoch: 43 [133/250 17024/32000 (53%)] Loss: 1.96249 (semantic_loss: 0.01316, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=0.36207 
Train Epoch: 43 [144/250 18432/32000 (58%)] Loss: 1.96435 (semantic_loss: 0.01502, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=0.37084 
Train Epoch: 43 [155/250 19840/32000 (62%)] Loss: 1.96581 (semantic_loss: 0.01453, quant_loss: 1.95117, bit_balance_loss: 0.00012) batch_time=1.07154 
Train Epoch: 43 [166/250 21248/32000 (66%)] Loss: 1.96533 (semantic_loss: 0.01502, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.34173 
Train Epoch: 43 [177/250 22656/32000 (71%)] Loss: 1.96608 (semantic_loss: 0.01577, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.32797 
Train Epoch: 43 [188/250 24064/32000 (75%)] Loss: 1.96579 (semantic_loss: 0.01548, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.34005 
Train Epoch: 43 [199/250 25472/32000 (80%)] Loss: 1.96504 (semantic_loss: 0.01473, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.33411 
Train Epoch: 43 [210/250 26880/32000 (84%)] Loss: 1.96505 (semantic_loss: 0.01474, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.67806 
Train Epoch: 43 [221/250 28288/32000 (88%)] Loss: 1.96532 (semantic_loss: 0.01501, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.46373 
Train Epoch: 43 [232/250 29696/32000 (93%)] Loss: 1.96648 (semantic_loss: 0.01519, quant_loss: 1.95117, bit_balance_loss: 0.00012) batch_time=0.40826 
Train Epoch: 43 [243/250 31104/32000 (97%)] Loss: 1.96268 (semantic_loss: 0.01335, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=0.33245 
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/DCMH_MSRVTT_1kB/checkpoint-epoch43.pth ...
Done in 4.711s
removing stale ckpt [epoch 42] [took 0.00s]
 epoch          : 43
 loss           : 1.9647033247947694
 learning_rate  : 5.799111065000278e-06
 n_samples      : 1376000
 n_steps        : 10750
 MSRVTT_miech_test/t2v_metrics/R1: 14.2
 MSRVTT_miech_test/t2v_metrics/R5: 42.6
 MSRVTT_miech_test/t2v_metrics/R10: 56.9
 MSRVTT_miech_test/t2v_metrics/R50: 83.0
 MSRVTT_miech_test/t2v_metrics/MedR: 8.0
 MSRVTT_miech_test/t2v_metrics/MeanR: 41.41
 MSRVTT_miech_test/t2v_metrics/geometric_mean_R1-R5-R10: 32.52895187381773
 MSRVTT_miech_test/v2t_metrics/R1: 14.5
 MSRVTT_miech_test/v2t_metrics/R5: 42.6
 MSRVTT_miech_test/v2t_metrics/R10: 56.7
 MSRVTT_miech_test/v2t_metrics/R50: 84.1
 MSRVTT_miech_test/v2t_metrics/MedR: 7.0
 MSRVTT_miech_test/v2t_metrics/MeanR: 38.0385
 MSRVTT_miech_test/v2t_metrics/geometric_mean_R1-R5-R10: 32.71801044707306
 mnt_best       : 32.98827131403981
 not_improved_count: 7
Train Epoch: 44 [1/250 128/32000 (0%)] Loss: 1.96494 (semantic_loss: 0.01463, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=27.38306 
Train Epoch: 44 [12/250 1536/32000 (5%)] Loss: 1.96379 (semantic_loss: 0.01445, quant_loss: 1.94922, bit_balance_loss: 0.00012) batch_time=0.32783 
Train Epoch: 44 [23/250 2944/32000 (9%)] Loss: 1.96502 (semantic_loss: 0.01471, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.45879 
Train Epoch: 44 [34/250 4352/32000 (14%)] Loss: 1.96388 (semantic_loss: 0.01455, quant_loss: 1.94922, bit_balance_loss: 0.00012) batch_time=0.35268 
Train Epoch: 44 [45/250 5760/32000 (18%)] Loss: 1.96489 (semantic_loss: 0.01458, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.32079 
Train Epoch: 44 [56/250 7168/32000 (22%)] Loss: 1.96495 (semantic_loss: 0.01464, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.32469 
Train Epoch: 44 [67/250 8576/32000 (27%)] Loss: 1.96394 (semantic_loss: 0.01461, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=0.43132 
Train Epoch: 44 [78/250 9984/32000 (31%)] Loss: 1.96529 (semantic_loss: 0.01498, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.36533 
Train Epoch: 44 [89/250 11392/32000 (36%)] Loss: 1.96437 (semantic_loss: 0.01504, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=0.32721 
Train Epoch: 44 [100/250 12800/32000 (40%)] Loss: 1.96477 (semantic_loss: 0.01446, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.33033 
Train Epoch: 44 [111/250 14208/32000 (44%)] Loss: 1.96590 (semantic_loss: 0.01559, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.32976 
Train Epoch: 44 [122/250 15616/32000 (49%)] Loss: 1.96559 (semantic_loss: 0.01528, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.32111 
Train Epoch: 44 [133/250 17024/32000 (53%)] Loss: 1.96392 (semantic_loss: 0.01360, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.31960 
Train Epoch: 44 [144/250 18432/32000 (58%)] Loss: 1.96362 (semantic_loss: 0.01428, quant_loss: 1.94922, bit_balance_loss: 0.00012) batch_time=0.43008 
Train Epoch: 44 [155/250 19840/32000 (62%)] Loss: 1.96563 (semantic_loss: 0.01532, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=5.41195 
Train Epoch: 44 [166/250 21248/32000 (66%)] Loss: 1.96451 (semantic_loss: 0.01419, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.34650 
Train Epoch: 44 [177/250 22656/32000 (71%)] Loss: 1.96555 (semantic_loss: 0.01621, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=0.32387 
Train Epoch: 44 [188/250 24064/32000 (75%)] Loss: 1.96499 (semantic_loss: 0.01468, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.32895 
Train Epoch: 44 [199/250 25472/32000 (80%)] Loss: 1.96410 (semantic_loss: 0.01476, quant_loss: 1.94922, bit_balance_loss: 0.00012) batch_time=0.33320 
Train Epoch: 44 [210/250 26880/32000 (84%)] Loss: 1.96518 (semantic_loss: 0.01487, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.32696 
Train Epoch: 44 [221/250 28288/32000 (88%)] Loss: 1.96535 (semantic_loss: 0.01504, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.54514 
Train Epoch: 44 [232/250 29696/32000 (93%)] Loss: 1.96455 (semantic_loss: 0.01522, quant_loss: 1.94922, bit_balance_loss: 0.00012) batch_time=0.34513 
Train Epoch: 44 [243/250 31104/32000 (97%)] Loss: 1.96535 (semantic_loss: 0.01504, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.33501 
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/DCMH_MSRVTT_1kB/checkpoint-epoch44.pth ...
Done in 4.851s
Updating 'best' checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/DCMH_MSRVTT_1kB/checkpoint-epoch44.pth ...
Done in 9.096s
removing stale ckpt [epoch 43] [took 0.00s]
 epoch          : 44
 loss           : 1.9647507996559144
 learning_rate  : 5.5091555117502635e-06
 n_samples      : 1408000
 n_steps        : 11000
 MSRVTT_miech_test/t2v_metrics/R1: 15.8
 MSRVTT_miech_test/t2v_metrics/R5: 41.3
 MSRVTT_miech_test/t2v_metrics/R10: 57.7
 MSRVTT_miech_test/t2v_metrics/R50: 83.3
 MSRVTT_miech_test/t2v_metrics/MedR: 8.0
 MSRVTT_miech_test/t2v_metrics/MeanR: 40.419
 MSRVTT_miech_test/t2v_metrics/geometric_mean_R1-R5-R10: 33.51667930091405
 MSRVTT_miech_test/v2t_metrics/R1: 16.6
 MSRVTT_miech_test/v2t_metrics/R5: 44.1
 MSRVTT_miech_test/v2t_metrics/R10: 58.1
 MSRVTT_miech_test/v2t_metrics/R50: 84.1
 MSRVTT_miech_test/v2t_metrics/MedR: 7.0
 MSRVTT_miech_test/v2t_metrics/MeanR: 37.166
 MSRVTT_miech_test/v2t_metrics/geometric_mean_R1-R5-R10: 34.90660433356837
 mnt_best       : 33.51667930091405
 not_improved_count: 0
Train Epoch: 45 [1/250 128/32000 (0%)] Loss: 1.96402 (semantic_loss: 0.01469, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=26.86401 
Train Epoch: 45 [12/250 1536/32000 (5%)] Loss: 1.96495 (semantic_loss: 0.01463, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.31827 
Train Epoch: 45 [23/250 2944/32000 (9%)] Loss: 1.96450 (semantic_loss: 0.01418, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.72909 
Train Epoch: 45 [34/250 4352/32000 (14%)] Loss: 1.96600 (semantic_loss: 0.01569, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.43344 
Train Epoch: 45 [45/250 5760/32000 (18%)] Loss: 1.96380 (semantic_loss: 0.01447, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=0.36052 
Train Epoch: 45 [56/250 7168/32000 (22%)] Loss: 1.96465 (semantic_loss: 0.01531, quant_loss: 1.94922, bit_balance_loss: 0.00012) batch_time=0.32622 
Train Epoch: 45 [67/250 8576/32000 (27%)] Loss: 1.96371 (semantic_loss: 0.01340, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.35681 
Train Epoch: 45 [78/250 9984/32000 (31%)] Loss: 1.96382 (semantic_loss: 0.01351, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.33469 
Train Epoch: 45 [89/250 11392/32000 (36%)] Loss: 1.96541 (semantic_loss: 0.01510, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.33823 
Train Epoch: 45 [100/250 12800/32000 (40%)] Loss: 1.96543 (semantic_loss: 0.01512, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.45618 
Train Epoch: 45 [111/250 14208/32000 (44%)] Loss: 1.96520 (semantic_loss: 0.01489, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.37812 
Train Epoch: 45 [122/250 15616/32000 (49%)] Loss: 1.96245 (semantic_loss: 0.01311, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=0.33274 
Train Epoch: 45 [133/250 17024/32000 (53%)] Loss: 1.96407 (semantic_loss: 0.01474, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=0.81012 
Train Epoch: 45 [144/250 18432/32000 (58%)] Loss: 1.96432 (semantic_loss: 0.01401, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=3.84688 
Train Epoch: 45 [155/250 19840/32000 (62%)] Loss: 1.96579 (semantic_loss: 0.01548, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.32810 
Train Epoch: 45 [166/250 21248/32000 (66%)] Loss: 1.96420 (semantic_loss: 0.01487, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=0.32931 
Train Epoch: 45 [177/250 22656/32000 (71%)] Loss: 1.96495 (semantic_loss: 0.01464, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.39954 
Train Epoch: 45 [188/250 24064/32000 (75%)] Loss: 1.96293 (semantic_loss: 0.01360, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=0.36102 
Train Epoch: 45 [199/250 25472/32000 (80%)] Loss: 1.96430 (semantic_loss: 0.01496, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=0.32410 
Train Epoch: 45 [210/250 26880/32000 (84%)] Loss: 1.96523 (semantic_loss: 0.01492, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.34262 
Train Epoch: 45 [221/250 28288/32000 (88%)] Loss: 1.96665 (semantic_loss: 0.01634, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.32896 
Train Epoch: 45 [232/250 29696/32000 (93%)] Loss: 1.96429 (semantic_loss: 0.01398, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.32154 
Train Epoch: 45 [243/250 31104/32000 (97%)] Loss: 1.96223 (semantic_loss: 0.01290, quant_loss: 1.94922, bit_balance_loss: 0.00012) batch_time=0.32293 
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/DCMH_MSRVTT_1kB/checkpoint-epoch45.pth ...
Done in 4.549s
removing stale ckpt [epoch 44] [took 0.00s]
 epoch          : 45
 loss           : 1.9645427494049073
 learning_rate  : 5.23369773616275e-06
 n_samples      : 1440000
 n_steps        : 11250
 MSRVTT_miech_test/t2v_metrics/R1: 15.0
 MSRVTT_miech_test/t2v_metrics/R5: 40.1
 MSRVTT_miech_test/t2v_metrics/R10: 56.2
 MSRVTT_miech_test/t2v_metrics/R50: 83.8
 MSRVTT_miech_test/t2v_metrics/MedR: 8.0
 MSRVTT_miech_test/t2v_metrics/MeanR: 41.547
 MSRVTT_miech_test/t2v_metrics/geometric_mean_R1-R5-R10: 32.33384229427578
 MSRVTT_miech_test/v2t_metrics/R1: 15.2
 MSRVTT_miech_test/v2t_metrics/R5: 43.1
 MSRVTT_miech_test/v2t_metrics/R10: 57.7
 MSRVTT_miech_test/v2t_metrics/R50: 83.8
 MSRVTT_miech_test/v2t_metrics/MedR: 8.0
 MSRVTT_miech_test/v2t_metrics/MeanR: 38.564
 MSRVTT_miech_test/v2t_metrics/geometric_mean_R1-R5-R10: 33.5607937445419
 mnt_best       : 33.51667930091405
 not_improved_count: 1
Train Epoch: 46 [1/250 128/32000 (0%)] Loss: 1.96469 (semantic_loss: 0.01437, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=30.40890 
Train Epoch: 46 [12/250 1536/32000 (5%)] Loss: 1.96487 (semantic_loss: 0.01456, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.33008 
Train Epoch: 46 [23/250 2944/32000 (9%)] Loss: 1.96507 (semantic_loss: 0.01476, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.34598 
Train Epoch: 46 [34/250 4352/32000 (14%)] Loss: 1.96553 (semantic_loss: 0.01522, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.34472 
Train Epoch: 46 [45/250 5760/32000 (18%)] Loss: 1.96531 (semantic_loss: 0.01500, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.33195 
Train Epoch: 46 [56/250 7168/32000 (22%)] Loss: 1.96412 (semantic_loss: 0.01381, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.33506 
Train Epoch: 46 [67/250 8576/32000 (27%)] Loss: 1.96417 (semantic_loss: 0.01386, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.32827 
Train Epoch: 46 [78/250 9984/32000 (31%)] Loss: 1.96570 (semantic_loss: 0.01540, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.32777 
Train Epoch: 46 [89/250 11392/32000 (36%)] Loss: 1.96657 (semantic_loss: 0.01626, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.51868 
Train Epoch: 46 [100/250 12800/32000 (40%)] Loss: 1.96521 (semantic_loss: 0.01489, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.34701 
Train Epoch: 46 [111/250 14208/32000 (44%)] Loss: 1.96486 (semantic_loss: 0.01455, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.32602 
Train Epoch: 46 [122/250 15616/32000 (49%)] Loss: 1.96433 (semantic_loss: 0.01402, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.32514 
Train Epoch: 46 [133/250 17024/32000 (53%)] Loss: 1.96435 (semantic_loss: 0.01405, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.35668 
Train Epoch: 46 [144/250 18432/32000 (58%)] Loss: 1.96348 (semantic_loss: 0.01415, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=0.33861 
Train Epoch: 46 [155/250 19840/32000 (62%)] Loss: 1.96441 (semantic_loss: 0.01508, quant_loss: 1.94922, bit_balance_loss: 0.00012) batch_time=0.33086 
Train Epoch: 46 [166/250 21248/32000 (66%)] Loss: 1.96532 (semantic_loss: 0.01501, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.39885 
Train Epoch: 46 [177/250 22656/32000 (71%)] Loss: 1.96404 (semantic_loss: 0.01372, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.32619 
Train Epoch: 46 [188/250 24064/32000 (75%)] Loss: 1.96526 (semantic_loss: 0.01495, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.33953 
Train Epoch: 46 [199/250 25472/32000 (80%)] Loss: 1.96412 (semantic_loss: 0.01381, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.32539 
Train Epoch: 46 [210/250 26880/32000 (84%)] Loss: 1.96410 (semantic_loss: 0.01477, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=0.33463 
Train Epoch: 46 [221/250 28288/32000 (88%)] Loss: 1.96363 (semantic_loss: 0.01332, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.32679 
Train Epoch: 46 [232/250 29696/32000 (93%)] Loss: 1.96401 (semantic_loss: 0.01370, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.38876 
Train Epoch: 46 [243/250 31104/32000 (97%)] Loss: 1.96480 (semantic_loss: 0.01449, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.33087 
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/DCMH_MSRVTT_1kB/checkpoint-epoch46.pth ...
Done in 4.514s
removing stale ckpt [epoch 45] [took 0.00s]
 epoch          : 46
 loss           : 1.9645927166938781
 learning_rate  : 4.972012849354612e-06
 n_samples      : 1472000
 n_steps        : 11500
 MSRVTT_miech_test/t2v_metrics/R1: 15.1
 MSRVTT_miech_test/t2v_metrics/R5: 41.9
 MSRVTT_miech_test/t2v_metrics/R10: 56.5
 MSRVTT_miech_test/t2v_metrics/R50: 84.2
 MSRVTT_miech_test/t2v_metrics/MedR: 8.0
 MSRVTT_miech_test/t2v_metrics/MeanR: 40.6355
 MSRVTT_miech_test/t2v_metrics/geometric_mean_R1-R5-R10: 32.94173526619364
 MSRVTT_miech_test/v2t_metrics/R1: 16.9
 MSRVTT_miech_test/v2t_metrics/R5: 42.4
 MSRVTT_miech_test/v2t_metrics/R10: 57.2
 MSRVTT_miech_test/v2t_metrics/R50: 84.6
 MSRVTT_miech_test/v2t_metrics/MedR: 8.0
 MSRVTT_miech_test/v2t_metrics/MeanR: 37.567
 MSRVTT_miech_test/v2t_metrics/geometric_mean_R1-R5-R10: 34.478592614500734
 mnt_best       : 33.51667930091405
 not_improved_count: 2
Train Epoch: 47 [1/250 128/32000 (0%)] Loss: 1.96428 (semantic_loss: 0.01495, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=26.12055 
Train Epoch: 47 [12/250 1536/32000 (5%)] Loss: 1.96520 (semantic_loss: 0.01586, quant_loss: 1.94922, bit_balance_loss: 0.00012) batch_time=0.41302 
Train Epoch: 47 [23/250 2944/32000 (9%)] Loss: 1.96361 (semantic_loss: 0.01428, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=1.10878 
Train Epoch: 47 [34/250 4352/32000 (14%)] Loss: 1.96520 (semantic_loss: 0.01489, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.32544 
Train Epoch: 47 [45/250 5760/32000 (18%)] Loss: 1.96529 (semantic_loss: 0.01596, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=0.32559 
Train Epoch: 47 [56/250 7168/32000 (22%)] Loss: 1.96536 (semantic_loss: 0.01602, quant_loss: 1.94922, bit_balance_loss: 0.00012) batch_time=0.36815 
Train Epoch: 47 [67/250 8576/32000 (27%)] Loss: 1.96414 (semantic_loss: 0.01383, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.42004 
Train Epoch: 47 [78/250 9984/32000 (31%)] Loss: 1.96509 (semantic_loss: 0.01478, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.34859 
Train Epoch: 47 [89/250 11392/32000 (36%)] Loss: 1.96534 (semantic_loss: 0.01503, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.32550 
Train Epoch: 47 [100/250 12800/32000 (40%)] Loss: 1.96375 (semantic_loss: 0.01442, quant_loss: 1.94922, bit_balance_loss: 0.00012) batch_time=0.32622 
Train Epoch: 47 [111/250 14208/32000 (44%)] Loss: 1.96504 (semantic_loss: 0.01473, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.32402 
Train Epoch: 47 [122/250 15616/32000 (49%)] Loss: 1.96399 (semantic_loss: 0.01368, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.33022 
Train Epoch: 47 [133/250 17024/32000 (53%)] Loss: 1.96592 (semantic_loss: 0.01560, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=1.20408 
Train Epoch: 47 [144/250 18432/32000 (58%)] Loss: 1.96458 (semantic_loss: 0.01427, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.48683 
Train Epoch: 47 [155/250 19840/32000 (62%)] Loss: 1.96346 (semantic_loss: 0.01412, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=1.53817 
Train Epoch: 47 [166/250 21248/32000 (66%)] Loss: 1.96260 (semantic_loss: 0.01229, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.43869 
Train Epoch: 47 [177/250 22656/32000 (71%)] Loss: 1.96327 (semantic_loss: 0.01393, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=0.32757 
Train Epoch: 47 [188/250 24064/32000 (75%)] Loss: 1.96730 (semantic_loss: 0.01699, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.32545 
Train Epoch: 47 [199/250 25472/32000 (80%)] Loss: 1.96387 (semantic_loss: 0.01357, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.33293 
Train Epoch: 47 [210/250 26880/32000 (84%)] Loss: 1.96443 (semantic_loss: 0.01510, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=0.32621 
Train Epoch: 47 [221/250 28288/32000 (88%)] Loss: 1.96283 (semantic_loss: 0.01252, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.40048 
Train Epoch: 47 [232/250 29696/32000 (93%)] Loss: 1.96506 (semantic_loss: 0.01475, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.32972 
Train Epoch: 47 [243/250 31104/32000 (97%)] Loss: 1.96316 (semantic_loss: 0.01382, quant_loss: 1.94922, bit_balance_loss: 0.00012) batch_time=0.35397 
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/DCMH_MSRVTT_1kB/checkpoint-epoch47.pth ...
Done in 3.791s
removing stale ckpt [epoch 46] [took 0.00s]
 epoch          : 47
 loss           : 1.9644531774520875
 learning_rate  : 4.723412206886882e-06
 n_samples      : 1504000
 n_steps        : 11750
 MSRVTT_miech_test/t2v_metrics/R1: 14.4
 MSRVTT_miech_test/t2v_metrics/R5: 42.0
 MSRVTT_miech_test/t2v_metrics/R10: 56.0
 MSRVTT_miech_test/t2v_metrics/R50: 84.0
 MSRVTT_miech_test/t2v_metrics/MedR: 8.0
 MSRVTT_miech_test/t2v_metrics/MeanR: 40.9165
 MSRVTT_miech_test/t2v_metrics/geometric_mean_R1-R5-R10: 32.35439399731021
 MSRVTT_miech_test/v2t_metrics/R1: 16.3
 MSRVTT_miech_test/v2t_metrics/R5: 42.4
 MSRVTT_miech_test/v2t_metrics/R10: 56.1
 MSRVTT_miech_test/v2t_metrics/R50: 83.5
 MSRVTT_miech_test/v2t_metrics/MedR: 8.0
 MSRVTT_miech_test/v2t_metrics/MeanR: 37.9365
 MSRVTT_miech_test/v2t_metrics/geometric_mean_R1-R5-R10: 33.84585119775996
 mnt_best       : 33.51667930091405
 not_improved_count: 3
Train Epoch: 48 [1/250 128/32000 (0%)] Loss: 1.96505 (semantic_loss: 0.01474, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=26.26887 
Train Epoch: 48 [12/250 1536/32000 (5%)] Loss: 1.96482 (semantic_loss: 0.01451, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.31951 
Train Epoch: 48 [23/250 2944/32000 (9%)] Loss: 1.96450 (semantic_loss: 0.01419, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.33127 
Train Epoch: 48 [34/250 4352/32000 (14%)] Loss: 1.96515 (semantic_loss: 0.01582, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=0.45830 
Train Epoch: 48 [45/250 5760/32000 (18%)] Loss: 1.96345 (semantic_loss: 0.01412, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=0.36912 
Train Epoch: 48 [56/250 7168/32000 (22%)] Loss: 1.96546 (semantic_loss: 0.01516, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.33211 
Train Epoch: 48 [67/250 8576/32000 (27%)] Loss: 1.96410 (semantic_loss: 0.01379, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.91935 
Train Epoch: 48 [78/250 9984/32000 (31%)] Loss: 1.96371 (semantic_loss: 0.01340, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.33056 
Train Epoch: 48 [89/250 11392/32000 (36%)] Loss: 1.96570 (semantic_loss: 0.01539, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.40490 
Train Epoch: 48 [100/250 12800/32000 (40%)] Loss: 1.96498 (semantic_loss: 0.01564, quant_loss: 1.94922, bit_balance_loss: 0.00012) batch_time=0.42358 
Train Epoch: 48 [111/250 14208/32000 (44%)] Loss: 1.96493 (semantic_loss: 0.01462, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.42602 
Train Epoch: 48 [122/250 15616/32000 (49%)] Loss: 1.96480 (semantic_loss: 0.01449, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.35519 
Train Epoch: 48 [133/250 17024/32000 (53%)] Loss: 1.96421 (semantic_loss: 0.01488, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=0.35180 
Train Epoch: 48 [144/250 18432/32000 (58%)] Loss: 1.96299 (semantic_loss: 0.01365, quant_loss: 1.94922, bit_balance_loss: 0.00012) batch_time=0.32406 
Train Epoch: 48 [155/250 19840/32000 (62%)] Loss: 1.96325 (semantic_loss: 0.01391, quant_loss: 1.94922, bit_balance_loss: 0.00012) batch_time=0.34628 
Train Epoch: 48 [166/250 21248/32000 (66%)] Loss: 1.96534 (semantic_loss: 0.01405, quant_loss: 1.95117, bit_balance_loss: 0.00011) batch_time=0.34121 
Train Epoch: 48 [177/250 22656/32000 (71%)] Loss: 1.96567 (semantic_loss: 0.01536, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.54207 
Train Epoch: 48 [188/250 24064/32000 (75%)] Loss: 1.96379 (semantic_loss: 0.01446, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=0.44209 
Train Epoch: 48 [199/250 25472/32000 (80%)] Loss: 1.96293 (semantic_loss: 0.01262, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.35143 
Train Epoch: 48 [210/250 26880/32000 (84%)] Loss: 1.96502 (semantic_loss: 0.01471, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.32409 
Train Epoch: 48 [221/250 28288/32000 (88%)] Loss: 1.96559 (semantic_loss: 0.01528, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.33713 
Train Epoch: 48 [232/250 29696/32000 (93%)] Loss: 1.96616 (semantic_loss: 0.01488, quant_loss: 1.95117, bit_balance_loss: 0.00011) batch_time=0.33931 
Train Epoch: 48 [243/250 31104/32000 (97%)] Loss: 1.96394 (semantic_loss: 0.01363, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.45322 
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/DCMH_MSRVTT_1kB/checkpoint-epoch48.pth ...
Done in 5.591s
removing stale ckpt [epoch 47] [took 0.00s]
 epoch          : 48
 loss           : 1.9643847446441651
 learning_rate  : 4.487241596542537e-06
 n_samples      : 1536000
 n_steps        : 12000
 MSRVTT_miech_test/t2v_metrics/R1: 15.0
 MSRVTT_miech_test/t2v_metrics/R5: 41.9
 MSRVTT_miech_test/t2v_metrics/R10: 56.8
 MSRVTT_miech_test/t2v_metrics/R50: 83.7
 MSRVTT_miech_test/t2v_metrics/MedR: 8.0
 MSRVTT_miech_test/t2v_metrics/MeanR: 40.513
 MSRVTT_miech_test/t2v_metrics/geometric_mean_R1-R5-R10: 32.92692738570246
 MSRVTT_miech_test/v2t_metrics/R1: 16.5
 MSRVTT_miech_test/v2t_metrics/R5: 41.9
 MSRVTT_miech_test/v2t_metrics/R10: 57.4
 MSRVTT_miech_test/v2t_metrics/R50: 83.6
 MSRVTT_miech_test/v2t_metrics/MedR: 7.5
 MSRVTT_miech_test/v2t_metrics/MeanR: 37.6195
 MSRVTT_miech_test/v2t_metrics/geometric_mean_R1-R5-R10: 34.109075880163196
 mnt_best       : 33.51667930091405
 not_improved_count: 4
Train Epoch: 49 [1/250 128/32000 (0%)] Loss: 1.96444 (semantic_loss: 0.01511, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=25.94898 
Train Epoch: 49 [12/250 1536/32000 (5%)] Loss: 1.96597 (semantic_loss: 0.01566, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.52909 
Train Epoch: 49 [23/250 2944/32000 (9%)] Loss: 1.96353 (semantic_loss: 0.01419, quant_loss: 1.94922, bit_balance_loss: 0.00012) batch_time=0.36353 
Train Epoch: 49 [34/250 4352/32000 (14%)] Loss: 1.96309 (semantic_loss: 0.01376, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=0.32416 
Train Epoch: 49 [45/250 5760/32000 (18%)] Loss: 1.96352 (semantic_loss: 0.01321, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.35123 
Train Epoch: 49 [56/250 7168/32000 (22%)] Loss: 1.96385 (semantic_loss: 0.01354, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.36209 
Train Epoch: 49 [67/250 8576/32000 (27%)] Loss: 1.96493 (semantic_loss: 0.01461, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.45305 
Train Epoch: 49 [78/250 9984/32000 (31%)] Loss: 1.96392 (semantic_loss: 0.01361, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=4.16583 
Train Epoch: 49 [89/250 11392/32000 (36%)] Loss: 1.96452 (semantic_loss: 0.01421, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.38598 
Train Epoch: 49 [100/250 12800/32000 (40%)] Loss: 1.96454 (semantic_loss: 0.01423, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.36850 
Train Epoch: 49 [111/250 14208/32000 (44%)] Loss: 1.96472 (semantic_loss: 0.01441, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.35079 
Train Epoch: 49 [122/250 15616/32000 (49%)] Loss: 1.96465 (semantic_loss: 0.01532, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=0.34050 
Train Epoch: 49 [133/250 17024/32000 (53%)] Loss: 1.96497 (semantic_loss: 0.01466, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.62049 
Train Epoch: 49 [144/250 18432/32000 (58%)] Loss: 1.96544 (semantic_loss: 0.01415, quant_loss: 1.95117, bit_balance_loss: 0.00011) batch_time=0.32940 
Train Epoch: 49 [155/250 19840/32000 (62%)] Loss: 1.96440 (semantic_loss: 0.01506, quant_loss: 1.94922, bit_balance_loss: 0.00012) batch_time=0.41337 
Train Epoch: 49 [166/250 21248/32000 (66%)] Loss: 1.96385 (semantic_loss: 0.01451, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=0.34186 
Train Epoch: 49 [177/250 22656/32000 (71%)] Loss: 1.96405 (semantic_loss: 0.01472, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=0.40355 
Train Epoch: 49 [188/250 24064/32000 (75%)] Loss: 1.96420 (semantic_loss: 0.01389, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.32524 
Train Epoch: 49 [199/250 25472/32000 (80%)] Loss: 1.96420 (semantic_loss: 0.01487, quant_loss: 1.94922, bit_balance_loss: 0.00012) batch_time=0.48678 
Train Epoch: 49 [210/250 26880/32000 (84%)] Loss: 1.96391 (semantic_loss: 0.01457, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=0.32981 
Train Epoch: 49 [221/250 28288/32000 (88%)] Loss: 1.96639 (semantic_loss: 0.01706, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=0.32887 
Train Epoch: 49 [232/250 29696/32000 (93%)] Loss: 1.96458 (semantic_loss: 0.01427, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.34325 
Train Epoch: 49 [243/250 31104/32000 (97%)] Loss: 1.96377 (semantic_loss: 0.01346, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.37119 
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/DCMH_MSRVTT_1kB/checkpoint-epoch49.pth ...
Done in 3.868s
removing stale ckpt [epoch 48] [took 0.00s]
 epoch          : 49
 loss           : 1.9643377380371094
 learning_rate  : 4.26287951671541e-06
 n_samples      : 1568000
 n_steps        : 12250
 MSRVTT_miech_test/t2v_metrics/R1: 14.8
 MSRVTT_miech_test/t2v_metrics/R5: 42.2
 MSRVTT_miech_test/t2v_metrics/R10: 56.3
 MSRVTT_miech_test/t2v_metrics/R50: 83.9
 MSRVTT_miech_test/t2v_metrics/MedR: 8.0
 MSRVTT_miech_test/t2v_metrics/MeanR: 40.4715
 MSRVTT_miech_test/t2v_metrics/geometric_mean_R1-R5-R10: 32.76127941221606
 MSRVTT_miech_test/v2t_metrics/R1: 16.2
 MSRVTT_miech_test/v2t_metrics/R5: 43.3
 MSRVTT_miech_test/v2t_metrics/R10: 56.3
 MSRVTT_miech_test/v2t_metrics/R50: 83.9
 MSRVTT_miech_test/v2t_metrics/MedR: 8.0
 MSRVTT_miech_test/v2t_metrics/MeanR: 37.8535
 MSRVTT_miech_test/v2t_metrics/geometric_mean_R1-R5-R10: 34.05418062740232
 mnt_best       : 33.51667930091405
 not_improved_count: 5
Train Epoch: 50 [1/250 128/32000 (0%)] Loss: 1.96376 (semantic_loss: 0.01345, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=24.65948 
Train Epoch: 50 [12/250 1536/32000 (5%)] Loss: 1.96508 (semantic_loss: 0.01477, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.46879 
Train Epoch: 50 [23/250 2944/32000 (9%)] Loss: 1.96560 (semantic_loss: 0.01626, quant_loss: 1.94922, bit_balance_loss: 0.00012) batch_time=0.36232 
Train Epoch: 50 [34/250 4352/32000 (14%)] Loss: 1.96498 (semantic_loss: 0.01467, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.36090 
Train Epoch: 50 [45/250 5760/32000 (18%)] Loss: 1.96412 (semantic_loss: 0.01479, quant_loss: 1.94922, bit_balance_loss: 0.00012) batch_time=0.32090 
Train Epoch: 50 [56/250 7168/32000 (22%)] Loss: 1.96297 (semantic_loss: 0.01266, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.35938 
Train Epoch: 50 [67/250 8576/32000 (27%)] Loss: 1.96552 (semantic_loss: 0.01521, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.33880 
Train Epoch: 50 [78/250 9984/32000 (31%)] Loss: 1.96517 (semantic_loss: 0.01388, quant_loss: 1.95117, bit_balance_loss: 0.00011) batch_time=0.32538 
Train Epoch: 50 [89/250 11392/32000 (36%)] Loss: 1.96313 (semantic_loss: 0.01282, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.38681 
Train Epoch: 50 [100/250 12800/32000 (40%)] Loss: 1.96482 (semantic_loss: 0.01451, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.41627 
Train Epoch: 50 [111/250 14208/32000 (44%)] Loss: 1.96426 (semantic_loss: 0.01493, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=0.32566 
Train Epoch: 50 [122/250 15616/32000 (49%)] Loss: 1.96399 (semantic_loss: 0.01368, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.32370 
Train Epoch: 50 [133/250 17024/32000 (53%)] Loss: 1.96436 (semantic_loss: 0.01405, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.36875 
Train Epoch: 50 [144/250 18432/32000 (58%)] Loss: 1.96538 (semantic_loss: 0.01507, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.35487 
Train Epoch: 50 [155/250 19840/32000 (62%)] Loss: 1.96384 (semantic_loss: 0.01353, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.39342 
Train Epoch: 50 [166/250 21248/32000 (66%)] Loss: 1.96515 (semantic_loss: 0.01484, quant_loss: 1.95020, bit_balance_loss: 0.00012) batch_time=0.36767 
Train Epoch: 50 [177/250 22656/32000 (71%)] Loss: 1.96329 (semantic_loss: 0.01395, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=0.32387 
Train Epoch: 50 [188/250 24064/32000 (75%)] Loss: 1.96221 (semantic_loss: 0.01288, quant_loss: 1.94922, bit_balance_loss: 0.00011) batch_time=0.32205 
Train Epoch: 50 [199/250 25472/32000 (80%)] Loss: 1.96614 (semantic_loss: 0.01485, quant_loss: 1.95117, bit_balance_loss: 0.00011) batch_time=0.36039 
Train Epoch: 50 [210/250 26880/32000 (84%)] Loss: 1.96411 (semantic_loss: 0.01380, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.37764 
Train Epoch: 50 [221/250 28288/32000 (88%)] Loss: 1.96393 (semantic_loss: 0.01459, quant_loss: 1.94922, bit_balance_loss: 0.00012) batch_time=0.32336 
Train Epoch: 50 [232/250 29696/32000 (93%)] Loss: 1.96411 (semantic_loss: 0.01380, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.32926 
Train Epoch: 50 [243/250 31104/32000 (97%)] Loss: 1.96448 (semantic_loss: 0.01417, quant_loss: 1.95020, bit_balance_loss: 0.00011) batch_time=0.32171 
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/DCMH_MSRVTT_1kB/checkpoint-epoch50.pth ...
Done in 3.721s
removing stale ckpt [epoch 49] [took 0.00s]
 epoch          : 50
 loss           : 1.9642501525878906
 learning_rate  : 4.04973554087964e-06
 n_samples      : 1600000
 n_steps        : 12500
 MSRVTT_miech_test/t2v_metrics/R1: 13.5
 MSRVTT_miech_test/t2v_metrics/R5: 41.0
 MSRVTT_miech_test/t2v_metrics/R10: 56.7
 MSRVTT_miech_test/t2v_metrics/R50: 83.5
 MSRVTT_miech_test/t2v_metrics/MedR: 8.0
 MSRVTT_miech_test/t2v_metrics/MeanR: 40.8445
 MSRVTT_miech_test/t2v_metrics/geometric_mean_R1-R5-R10: 31.542798965680582
 MSRVTT_miech_test/v2t_metrics/R1: 16.9
 MSRVTT_miech_test/v2t_metrics/R5: 42.9
 MSRVTT_miech_test/v2t_metrics/R10: 57.6
 MSRVTT_miech_test/v2t_metrics/R50: 84.1
 MSRVTT_miech_test/v2t_metrics/MedR: 7.0
 MSRVTT_miech_test/v2t_metrics/MeanR: 37.9465
 MSRVTT_miech_test/v2t_metrics/geometric_mean_R1-R5-R10: 34.69408941288131
 mnt_best       : 33.51667930091405
 not_improved_count: 6
Final evaluation ...
Loading checkpoint from: /apdcephfs/share_47076/gimwang/HCQ/exps/DCMH_MSRVTT_1kB/trained_model.pth ...
Ckpt loaded at epoch 44.
Saved v2t similarity matrix to /apdcephfs/share_47076/gimwang/HCQ/exps/DCMH_MSRVTT_1kB/MSRVTT-test-sims.npy
MSRVTT_miech_test:
 t2v_metrics/R1/final_eval: 15.8
 t2v_metrics/R5/final_eval: 41.3
 t2v_metrics/R10/final_eval: 57.7
 t2v_metrics/R50/final_eval: 83.3
 t2v_metrics/MedR/final_eval: 8.0
 t2v_metrics/MeanR/final_eval: 40.419
 t2v_metrics/geometric_mean_R1-R5-R10/final_eval: 33.51667930091405
 v2t_metrics/R1/final_eval: 16.6
 v2t_metrics/R5/final_eval: 44.1
 v2t_metrics/R10/final_eval: 58.1
 v2t_metrics/R50/final_eval: 84.1
 v2t_metrics/MedR/final_eval: 7.0
 v2t_metrics/MeanR/final_eval: 37.166
 v2t_metrics/geometric_mean_R1-R5-R10/final_eval: 34.90660433356837
Best epoch for the monitored metric: 44
Script took 02h48m33s
The best performing ckpt can be found at /apdcephfs/share_47076/gimwang/HCQ/exps/DCMH_MSRVTT_1kB/trained_model.pth
