Experiment directory: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_MSRVTT_1kA_roberta-large
Preparing the dataloaders ...
Loading dataset MSRVTT_jsfusion_trainval in ram ...
Finish loading dataset MSRVTT_jsfusion_trainval in ram, taking 302.98045659065247 s.
Loading dataset MSRVTT_jsfusion_test in ram ...
Finish loading dataset MSRVTT_jsfusion_test in ram, taking 39.47932505607605 s.
Loading dataset MSRVTT_jsfusion_test in ram ...
Finish loading dataset MSRVTT_jsfusion_test in ram, taking 19.7394437789917 s.
Training ...
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_MSRVTT_1kA_roberta-large/checkpoint-epoch0.pth ...
Done in 4.442s
Updating 'best' checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_MSRVTT_1kA_roberta-large/checkpoint-epoch0.pth ...
Done in 8.588s
 epoch          : 0
 loss           : 0
 learning_rate  : 5e-05
 n_samples      : 0
 n_steps        : 0
 MSRVTT_jsfusion_test/t2v_metrics/R1: 0.1
 MSRVTT_jsfusion_test/t2v_metrics/R5: 0.5
 MSRVTT_jsfusion_test/t2v_metrics/R10: 0.8
 MSRVTT_jsfusion_test/t2v_metrics/R50: 5.1
 MSRVTT_jsfusion_test/t2v_metrics/MedR: 499.0
 MSRVTT_jsfusion_test/t2v_metrics/MeanR: 501.354
 MSRVTT_jsfusion_test/t2v_metrics/geometric_mean_R1-R5-R10: 0.3419951893353394
 MSRVTT_jsfusion_test/v2t_metrics/R1: 0.0
 MSRVTT_jsfusion_test/v2t_metrics/R5: 0.3
 MSRVTT_jsfusion_test/v2t_metrics/R10: 0.8
 MSRVTT_jsfusion_test/v2t_metrics/R50: 4.4
 MSRVTT_jsfusion_test/v2t_metrics/MedR: 504.0
 MSRVTT_jsfusion_test/v2t_metrics/MeanR: 506.6715
 MSRVTT_jsfusion_test/v2t_metrics/geometric_mean_R1-R5-R10: 0.0
 mnt_best       : 0.3419951893353394
 not_improved_count: 0
Train Epoch: 1 [1/250 128/32000 (0%)] Loss: 9.76782 (QuantReg: 22.36271) QuantErr: 22.36271 batch_time=30.43627 
Train Epoch: 1 [12/250 1536/32000 (5%)] Loss: 9.65356 (QuantReg: 22.49701) QuantErr: 22.49701 batch_time=0.65003 
Train Epoch: 1 [23/250 2944/32000 (9%)] Loss: 8.82615 (QuantReg: 22.55971) QuantErr: 22.55971 batch_time=0.70783 
Train Epoch: 1 [34/250 4352/32000 (14%)] Loss: 7.81435 (QuantReg: 22.52109) QuantErr: 22.52109 batch_time=0.65173 
Train Epoch: 1 [45/250 5760/32000 (18%)] Loss: 7.01308 (QuantReg: 22.58470) QuantErr: 22.58470 batch_time=0.65653 
Train Epoch: 1 [56/250 7168/32000 (22%)] Loss: 6.60404 (QuantReg: 22.64503) QuantErr: 22.64503 batch_time=0.67475 
Train Epoch: 1 [67/250 8576/32000 (27%)] Loss: 6.06546 (QuantReg: 22.60925) QuantErr: 22.60925 batch_time=0.65836 
Train Epoch: 1 [78/250 9984/32000 (31%)] Loss: 5.99833 (QuantReg: 22.62748) QuantErr: 22.62748 batch_time=0.64958 
Train Epoch: 1 [89/250 11392/32000 (36%)] Loss: 6.30074 (QuantReg: 22.62539) QuantErr: 22.62539 batch_time=0.65721 
Train Epoch: 1 [100/250 12800/32000 (40%)] Loss: 5.49864 (QuantReg: 22.58223) QuantErr: 22.58223 batch_time=0.65392 
Train Epoch: 1 [111/250 14208/32000 (44%)] Loss: 5.02890 (QuantReg: 22.65191) QuantErr: 22.65191 batch_time=0.64539 
Train Epoch: 1 [122/250 15616/32000 (49%)] Loss: 5.25348 (QuantReg: 22.63950) QuantErr: 22.63950 batch_time=0.67224 
Train Epoch: 1 [133/250 17024/32000 (53%)] Loss: 5.35946 (QuantReg: 22.59830) QuantErr: 22.59830 batch_time=3.97379 
Train Epoch: 1 [144/250 18432/32000 (58%)] Loss: 5.34042 (QuantReg: 22.59918) QuantErr: 22.59918 batch_time=0.65304 
Train Epoch: 1 [155/250 19840/32000 (62%)] Loss: 4.66788 (QuantReg: 22.60771) QuantErr: 22.60771 batch_time=0.67272 
Train Epoch: 1 [166/250 21248/32000 (66%)] Loss: 5.12520 (QuantReg: 22.62438) QuantErr: 22.62438 batch_time=0.66681 
Train Epoch: 1 [177/250 22656/32000 (71%)] Loss: 5.27821 (QuantReg: 22.61075) QuantErr: 22.61075 batch_time=0.65281 
Train Epoch: 1 [188/250 24064/32000 (75%)] Loss: 4.45425 (QuantReg: 22.62991) QuantErr: 22.62991 batch_time=0.64413 
Train Epoch: 1 [199/250 25472/32000 (80%)] Loss: 4.95940 (QuantReg: 22.62210) QuantErr: 22.62210 batch_time=0.65272 
Experiment directory: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_MSRVTT_1kA_roberta-large
Preparing the dataloaders ...
Loading dataset MSRVTT_jsfusion_trainval in ram ...
Finish loading dataset MSRVTT_jsfusion_trainval in ram, taking 404.4636583328247 s.
Loading dataset MSRVTT_jsfusion_test in ram ...
Finish loading dataset MSRVTT_jsfusion_test in ram, taking 32.85805892944336 s.
Loading dataset MSRVTT_jsfusion_test in ram ...
Finish loading dataset MSRVTT_jsfusion_test in ram, taking 29.347679615020752 s.
Training ...
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_MSRVTT_1kA_roberta-large/checkpoint-epoch0.pth ...
Done in 7.424s
Updating 'best' checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_MSRVTT_1kA_roberta-large/checkpoint-epoch0.pth ...
Done in 12.499s
 epoch          : 0
 loss           : 0
 learning_rate  : 5e-05
 n_samples      : 0
 n_steps        : 0
 MSRVTT_jsfusion_test/t2v_metrics/R1: 0.1
 MSRVTT_jsfusion_test/t2v_metrics/R5: 0.5
 MSRVTT_jsfusion_test/t2v_metrics/R10: 0.8
 MSRVTT_jsfusion_test/t2v_metrics/R50: 5.1
 MSRVTT_jsfusion_test/t2v_metrics/MedR: 499.0
 MSRVTT_jsfusion_test/t2v_metrics/MeanR: 501.354
 MSRVTT_jsfusion_test/t2v_metrics/geometric_mean_R1-R5-R10: 0.3419951893353394
 MSRVTT_jsfusion_test/v2t_metrics/R1: 0.0
 MSRVTT_jsfusion_test/v2t_metrics/R5: 0.3
 MSRVTT_jsfusion_test/v2t_metrics/R10: 0.8
 MSRVTT_jsfusion_test/v2t_metrics/R50: 4.4
 MSRVTT_jsfusion_test/v2t_metrics/MedR: 504.0
 MSRVTT_jsfusion_test/v2t_metrics/MeanR: 506.6715
 MSRVTT_jsfusion_test/v2t_metrics/geometric_mean_R1-R5-R10: 0.0
 mnt_best       : 0.3419951893353394
 not_improved_count: 0
Train Epoch: 1 [1/250 128/32000 (0%)] Loss: 9.76909 (QuantReg: 22.36266) QuantErr: 22.36266 batch_time=34.37646 
Train Epoch: 1 [12/250 1536/32000 (5%)] Loss: 9.67585 (QuantReg: 22.48597) QuantErr: 22.48597 batch_time=0.64929 
Train Epoch: 1 [23/250 2944/32000 (9%)] Loss: 9.00726 (QuantReg: 22.52109) QuantErr: 22.52109 batch_time=0.69604 
Train Epoch: 1 [34/250 4352/32000 (14%)] Loss: 7.84041 (QuantReg: 22.59000) QuantErr: 22.59000 batch_time=0.65098 
Train Epoch: 1 [45/250 5760/32000 (18%)] Loss: 7.35815 (QuantReg: 22.62373) QuantErr: 22.62373 batch_time=0.66234 
Train Epoch: 1 [56/250 7168/32000 (22%)] Loss: 6.79918 (QuantReg: 22.66489) QuantErr: 22.66489 batch_time=0.66349 
Train Epoch: 1 [67/250 8576/32000 (27%)] Loss: 5.99776 (QuantReg: 22.65634) QuantErr: 22.65634 batch_time=0.65743 
Train Epoch: 1 [78/250 9984/32000 (31%)] Loss: 6.05924 (QuantReg: 22.67007) QuantErr: 22.67007 batch_time=0.64452 
Train Epoch: 1 [89/250 11392/32000 (36%)] Loss: 6.03330 (QuantReg: 22.61390) QuantErr: 22.61390 batch_time=0.68018 
Train Epoch: 1 [100/250 12800/32000 (40%)] Loss: 5.56706 (QuantReg: 22.62187) QuantErr: 22.62187 batch_time=0.66213 
Train Epoch: 1 [111/250 14208/32000 (44%)] Loss: 5.02449 (QuantReg: 22.63161) QuantErr: 22.63161 batch_time=0.66693 
Train Epoch: 1 [122/250 15616/32000 (49%)] Loss: 5.18993 (QuantReg: 22.62838) QuantErr: 22.62838 batch_time=0.65048 
Train Epoch: 1 [133/250 17024/32000 (53%)] Loss: 5.34551 (QuantReg: 22.64740) QuantErr: 22.64740 batch_time=0.64921 
Train Epoch: 1 [144/250 18432/32000 (58%)] Loss: 5.15832 (QuantReg: 22.62849) QuantErr: 22.62849 batch_time=0.64720 
Train Epoch: 1 [155/250 19840/32000 (62%)] Loss: 4.75132 (QuantReg: 22.61525) QuantErr: 22.61525 batch_time=0.66090 
Train Epoch: 1 [166/250 21248/32000 (66%)] Loss: 4.75677 (QuantReg: 22.63735) QuantErr: 22.63735 batch_time=0.66485 
Train Epoch: 1 [177/250 22656/32000 (71%)] Loss: 4.97633 (QuantReg: 22.62306) QuantErr: 22.62306 batch_time=0.65338 
Train Epoch: 1 [188/250 24064/32000 (75%)] Loss: 4.30936 (QuantReg: 22.62717) QuantErr: 22.62717 batch_time=0.65632 
Train Epoch: 1 [199/250 25472/32000 (80%)] Loss: 4.68645 (QuantReg: 22.62378) QuantErr: 22.62378 batch_time=0.64793 
Train Epoch: 1 [210/250 26880/32000 (84%)] Loss: 4.37750 (QuantReg: 22.62727) QuantErr: 22.62727 batch_time=0.72017 
Train Epoch: 1 [221/250 28288/32000 (88%)] Loss: 4.34833 (QuantReg: 22.63185) QuantErr: 22.63185 batch_time=0.66182 
Train Epoch: 1 [232/250 29696/32000 (93%)] Loss: 4.43315 (QuantReg: 22.62494) QuantErr: 22.62494 batch_time=0.66507 
Train Epoch: 1 [243/250 31104/32000 (97%)] Loss: 4.72529 (QuantReg: 22.62259) QuantErr: 22.62259 batch_time=0.66306 
Train Epoch: 1 codebook_update_time=2.34645
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_MSRVTT_1kA_roberta-large/checkpoint-epoch1.pth ...
Done in 10.895s
Updating 'best' checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_MSRVTT_1kA_roberta-large/checkpoint-epoch1.pth ...
Done in 21.653s
 epoch          : 1
 loss           : 5.825184028625488
 quant_reg      : 22.61285701751709
 quant_err      : 22.61285701751709
 learning_rate  : 5e-05
 n_samples      : 32000
 n_steps        : 250
 MSRVTT_jsfusion_test/t2v_metrics/R1: 10.1
 MSRVTT_jsfusion_test/t2v_metrics/R5: 31.2
 MSRVTT_jsfusion_test/t2v_metrics/R10: 45.7
 MSRVTT_jsfusion_test/t2v_metrics/R50: 76.1
 MSRVTT_jsfusion_test/t2v_metrics/MedR: 13.0
 MSRVTT_jsfusion_test/t2v_metrics/MeanR: 50.525
 MSRVTT_jsfusion_test/t2v_metrics/geometric_mean_R1-R5-R10: 24.32936212585345
 MSRVTT_jsfusion_test/v2t_metrics/R1: 10.4
 MSRVTT_jsfusion_test/v2t_metrics/R5: 32.9
 MSRVTT_jsfusion_test/v2t_metrics/R10: 47.1
 MSRVTT_jsfusion_test/v2t_metrics/R50: 76.9
 MSRVTT_jsfusion_test/v2t_metrics/MedR: 12.0
 MSRVTT_jsfusion_test/v2t_metrics/MeanR: 48.147
 MSRVTT_jsfusion_test/v2t_metrics/geometric_mean_R1-R5-R10: 25.259032679867016
 mnt_best       : 24.32936212585345
 not_improved_count: 0
Train Epoch: 2 [1/250 128/32000 (0%)] Loss: 4.39809 (QuantReg: 11.25940) QuantErr: 11.25940 batch_time=30.75743 
Train Epoch: 2 [12/250 1536/32000 (5%)] Loss: 4.53775 (QuantReg: 11.61384) QuantErr: 11.61384 batch_time=0.66346 
Train Epoch: 2 [23/250 2944/32000 (9%)] Loss: 4.45691 (QuantReg: 12.11482) QuantErr: 12.11482 batch_time=1.81512 
Train Epoch: 2 [34/250 4352/32000 (14%)] Loss: 3.85940 (QuantReg: 12.18584) QuantErr: 12.18584 batch_time=0.65424 
Train Epoch: 2 [45/250 5760/32000 (18%)] Loss: 3.62152 (QuantReg: 12.49013) QuantErr: 12.49013 batch_time=0.66365 
Train Epoch: 2 [56/250 7168/32000 (22%)] Loss: 3.86930 (QuantReg: 12.29909) QuantErr: 12.29909 batch_time=0.65459 
Train Epoch: 2 [67/250 8576/32000 (27%)] Loss: 4.03175 (QuantReg: 12.72881) QuantErr: 12.72881 batch_time=0.70215 
Train Epoch: 2 [78/250 9984/32000 (31%)] Loss: 4.43138 (QuantReg: 12.73931) QuantErr: 12.73931 batch_time=0.63795 
Train Epoch: 2 [89/250 11392/32000 (36%)] Loss: 3.84674 (QuantReg: 13.03551) QuantErr: 13.03551 batch_time=0.65656 
Train Epoch: 2 [100/250 12800/32000 (40%)] Loss: 3.94362 (QuantReg: 12.68318) QuantErr: 12.68318 batch_time=0.65272 
Train Epoch: 2 [111/250 14208/32000 (44%)] Loss: 3.79286 (QuantReg: 13.27025) QuantErr: 13.27025 batch_time=0.65236 
Train Epoch: 2 [122/250 15616/32000 (49%)] Loss: 3.58149 (QuantReg: 12.63090) QuantErr: 12.63090 batch_time=0.65073 
Train Epoch: 2 [133/250 17024/32000 (53%)] Loss: 3.80233 (QuantReg: 14.01289) QuantErr: 14.01289 batch_time=2.55398 
Train Epoch: 2 [144/250 18432/32000 (58%)] Loss: 3.51671 (QuantReg: 13.94413) QuantErr: 13.94413 batch_time=0.66227 
Train Epoch: 2 [155/250 19840/32000 (62%)] Loss: 4.12857 (QuantReg: 13.64366) QuantErr: 13.64366 batch_time=0.65160 
Train Epoch: 2 [166/250 21248/32000 (66%)] Loss: 3.42785 (QuantReg: 13.75103) QuantErr: 13.75103 batch_time=0.77269 
Train Epoch: 2 [177/250 22656/32000 (71%)] Loss: 3.50719 (QuantReg: 14.34418) QuantErr: 14.34418 batch_time=0.67364 
Train Epoch: 2 [188/250 24064/32000 (75%)] Loss: 3.39564 (QuantReg: 14.64650) QuantErr: 14.64650 batch_time=0.65097 
Train Epoch: 2 [199/250 25472/32000 (80%)] Loss: 3.10119 (QuantReg: 14.72090) QuantErr: 14.72090 batch_time=0.66154 
Train Epoch: 2 [210/250 26880/32000 (84%)] Loss: 3.64362 (QuantReg: 14.69646) QuantErr: 14.69646 batch_time=0.70136 
Train Epoch: 2 [221/250 28288/32000 (88%)] Loss: 3.36965 (QuantReg: 14.89790) QuantErr: 14.89790 batch_time=0.90141 
Train Epoch: 2 [232/250 29696/32000 (93%)] Loss: 3.01854 (QuantReg: 14.82698) QuantErr: 14.82698 batch_time=1.33078 
Train Epoch: 2 [243/250 31104/32000 (97%)] Loss: 3.05633 (QuantReg: 14.89367) QuantErr: 14.89367 batch_time=0.67118 
Train Epoch: 2 codebook_update_time=1.67525
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_MSRVTT_1kA_roberta-large/checkpoint-epoch2.pth ...
Done in 10.316s
Updating 'best' checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_MSRVTT_1kA_roberta-large/checkpoint-epoch2.pth ...
Done in 20.242s
removing stale ckpt [epoch 1] [took 0.00s]
removing stale ckpt [epoch 0] [took 0.00s]
 epoch          : 2
 loss           : 3.7586414680480957
 quant_reg      : 13.41098484802246
 quant_err      : 13.41098484802246
 learning_rate  : 4.75e-05
 n_samples      : 64000
 n_steps        : 500
 MSRVTT_jsfusion_test/t2v_metrics/R1: 14.8
 MSRVTT_jsfusion_test/t2v_metrics/R5: 40.9
 MSRVTT_jsfusion_test/t2v_metrics/R10: 53.2
 MSRVTT_jsfusion_test/t2v_metrics/R50: 82.2
 MSRVTT_jsfusion_test/t2v_metrics/MedR: 9.0
 MSRVTT_jsfusion_test/t2v_metrics/MeanR: 38.438
 MSRVTT_jsfusion_test/t2v_metrics/geometric_mean_R1-R5-R10: 31.815021317246565
 MSRVTT_jsfusion_test/v2t_metrics/R1: 16.2
 MSRVTT_jsfusion_test/v2t_metrics/R5: 42.2
 MSRVTT_jsfusion_test/v2t_metrics/R10: 53.2
 MSRVTT_jsfusion_test/v2t_metrics/R50: 81.2
 MSRVTT_jsfusion_test/v2t_metrics/MedR: 9.0
 MSRVTT_jsfusion_test/v2t_metrics/MeanR: 35.528
 MSRVTT_jsfusion_test/v2t_metrics/geometric_mean_R1-R5-R10: 33.131901834666245
 mnt_best       : 31.815021317246565
 not_improved_count: 0
Train Epoch: 3 [1/250 128/32000 (0%)] Loss: 3.33793 (QuantReg: 11.74575) QuantErr: 11.74575 batch_time=27.51015 
Train Epoch: 3 [12/250 1536/32000 (5%)] Loss: 3.08336 (QuantReg: 12.11022) QuantErr: 12.11022 batch_time=0.66114 
Train Epoch: 3 [23/250 2944/32000 (9%)] Loss: 3.24141 (QuantReg: 12.43608) QuantErr: 12.43608 batch_time=0.64869 
Train Epoch: 3 [34/250 4352/32000 (14%)] Loss: 3.31931 (QuantReg: 11.82043) QuantErr: 11.82043 batch_time=0.65088 
Train Epoch: 3 [45/250 5760/32000 (18%)] Loss: 3.01848 (QuantReg: 12.11261) QuantErr: 12.11261 batch_time=0.65386 
Train Epoch: 3 [56/250 7168/32000 (22%)] Loss: 2.83480 (QuantReg: 12.22652) QuantErr: 12.22652 batch_time=0.65846 
Train Epoch: 3 [67/250 8576/32000 (27%)] Loss: 2.88271 (QuantReg: 12.73260) QuantErr: 12.73260 batch_time=2.86358 
Train Epoch: 3 [78/250 9984/32000 (31%)] Loss: 3.35474 (QuantReg: 12.45696) QuantErr: 12.45696 batch_time=0.70522 
Train Epoch: 3 [89/250 11392/32000 (36%)] Loss: 3.07799 (QuantReg: 12.56150) QuantErr: 12.56150 batch_time=0.64893 
Train Epoch: 3 [100/250 12800/32000 (40%)] Loss: 2.66532 (QuantReg: 12.55580) QuantErr: 12.55580 batch_time=0.64952 
Train Epoch: 3 [111/250 14208/32000 (44%)] Loss: 3.17123 (QuantReg: 12.51601) QuantErr: 12.51601 batch_time=0.65804 
Train Epoch: 3 [122/250 15616/32000 (49%)] Loss: 3.44110 (QuantReg: 12.73552) QuantErr: 12.73552 batch_time=0.64739 
Train Epoch: 3 [133/250 17024/32000 (53%)] Loss: 3.52477 (QuantReg: 12.71238) QuantErr: 12.71238 batch_time=0.66012 
Train Epoch: 3 [144/250 18432/32000 (58%)] Loss: 2.81362 (QuantReg: 13.07911) QuantErr: 13.07911 batch_time=0.65064 
Train Epoch: 3 [155/250 19840/32000 (62%)] Loss: 3.20560 (QuantReg: 13.02739) QuantErr: 13.02739 batch_time=0.65453 
Train Epoch: 3 [166/250 21248/32000 (66%)] Loss: 2.84851 (QuantReg: 12.90668) QuantErr: 12.90668 batch_time=0.67078 
Train Epoch: 3 [177/250 22656/32000 (71%)] Loss: 3.43216 (QuantReg: 13.28937) QuantErr: 13.28937 batch_time=0.65091 
Train Epoch: 3 [188/250 24064/32000 (75%)] Loss: 3.33238 (QuantReg: 12.74035) QuantErr: 12.74035 batch_time=0.66976 
Train Epoch: 3 [199/250 25472/32000 (80%)] Loss: 2.81500 (QuantReg: 12.91711) QuantErr: 12.91711 batch_time=1.87527 
Train Epoch: 3 [210/250 26880/32000 (84%)] Loss: 3.51859 (QuantReg: 12.80769) QuantErr: 12.80769 batch_time=1.79450 
Train Epoch: 3 [221/250 28288/32000 (88%)] Loss: 2.65907 (QuantReg: 13.41781) QuantErr: 13.41781 batch_time=0.65441 
Train Epoch: 3 [232/250 29696/32000 (93%)] Loss: 2.92113 (QuantReg: 13.42620) QuantErr: 13.42620 batch_time=0.65638 
Train Epoch: 3 [243/250 31104/32000 (97%)] Loss: 3.06161 (QuantReg: 13.32547) QuantErr: 13.32547 batch_time=0.69242 
Train Epoch: 3 codebook_update_time=1.67773
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_MSRVTT_1kA_roberta-large/checkpoint-epoch3.pth ...
Done in 14.444s
Updating 'best' checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_MSRVTT_1kA_roberta-large/checkpoint-epoch3.pth ...
Done in 24.796s
removing stale ckpt [epoch 2] [took 0.00s]
 epoch          : 3
 loss           : 3.1334662494659424
 quant_reg      : 12.750779304504395
 quant_err      : 12.750779304504395
 learning_rate  : 4.5125e-05
 n_samples      : 96000
 n_steps        : 750
 MSRVTT_jsfusion_test/t2v_metrics/R1: 16.6
 MSRVTT_jsfusion_test/t2v_metrics/R5: 42.2
 MSRVTT_jsfusion_test/t2v_metrics/R10: 56.1
 MSRVTT_jsfusion_test/t2v_metrics/R50: 84.0
 MSRVTT_jsfusion_test/t2v_metrics/MedR: 8.0
 MSRVTT_jsfusion_test/t2v_metrics/MeanR: 33.884
 MSRVTT_jsfusion_test/t2v_metrics/geometric_mean_R1-R5-R10: 33.998607786130414
 MSRVTT_jsfusion_test/v2t_metrics/R1: 16.8
 MSRVTT_jsfusion_test/v2t_metrics/R5: 43.8
 MSRVTT_jsfusion_test/v2t_metrics/R10: 56.7
 MSRVTT_jsfusion_test/v2t_metrics/R50: 84.2
 MSRVTT_jsfusion_test/v2t_metrics/MedR: 7.0
 MSRVTT_jsfusion_test/v2t_metrics/MeanR: 32.3245
 MSRVTT_jsfusion_test/v2t_metrics/geometric_mean_R1-R5-R10: 34.683438794073155
 mnt_best       : 33.998607786130414
 not_improved_count: 0
Train Epoch: 4 [1/250 128/32000 (0%)] Loss: 3.42576 (QuantReg: 11.84745) QuantErr: 11.84745 batch_time=29.44023 
Train Epoch: 4 [12/250 1536/32000 (5%)] Loss: 2.86820 (QuantReg: 11.87786) QuantErr: 11.87786 batch_time=0.67132 
Train Epoch: 4 [23/250 2944/32000 (9%)] Loss: 2.79280 (QuantReg: 12.51691) QuantErr: 12.51691 batch_time=1.46879 
Train Epoch: 4 [34/250 4352/32000 (14%)] Loss: 2.67342 (QuantReg: 12.23338) QuantErr: 12.23338 batch_time=0.67138 
Train Epoch: 4 [45/250 5760/32000 (18%)] Loss: 2.99271 (QuantReg: 12.15680) QuantErr: 12.15680 batch_time=0.69869 
Train Epoch: 4 [56/250 7168/32000 (22%)] Loss: 2.81307 (QuantReg: 12.47948) QuantErr: 12.47948 batch_time=0.65211 
Train Epoch: 4 [67/250 8576/32000 (27%)] Loss: 2.59526 (QuantReg: 12.56120) QuantErr: 12.56120 batch_time=1.11793 
Train Epoch: 4 [78/250 9984/32000 (31%)] Loss: 2.62357 (QuantReg: 12.37715) QuantErr: 12.37715 batch_time=0.64486 
Train Epoch: 4 [89/250 11392/32000 (36%)] Loss: 2.69480 (QuantReg: 12.44868) QuantErr: 12.44868 batch_time=0.67382 
Train Epoch: 4 [100/250 12800/32000 (40%)] Loss: 2.47739 (QuantReg: 12.46146) QuantErr: 12.46146 batch_time=0.67280 
Train Epoch: 4 [111/250 14208/32000 (44%)] Loss: 3.04576 (QuantReg: 12.78158) QuantErr: 12.78158 batch_time=0.69031 
Train Epoch: 4 [122/250 15616/32000 (49%)] Loss: 3.09417 (QuantReg: 12.51769) QuantErr: 12.51769 batch_time=0.66075 
Train Epoch: 4 [133/250 17024/32000 (53%)] Loss: 2.48159 (QuantReg: 12.64845) QuantErr: 12.64845 batch_time=0.67167 
Train Epoch: 4 [144/250 18432/32000 (58%)] Loss: 2.63324 (QuantReg: 12.80123) QuantErr: 12.80123 batch_time=3.06551 
Train Epoch: 4 [155/250 19840/32000 (62%)] Loss: 2.67054 (QuantReg: 12.64628) QuantErr: 12.64628 batch_time=0.66870 
Train Epoch: 4 [166/250 21248/32000 (66%)] Loss: 2.33532 (QuantReg: 12.41361) QuantErr: 12.41361 batch_time=0.69638 
Train Epoch: 4 [177/250 22656/32000 (71%)] Loss: 3.02293 (QuantReg: 12.58691) QuantErr: 12.58691 batch_time=0.66180 
Train Epoch: 4 [188/250 24064/32000 (75%)] Loss: 2.75489 (QuantReg: 12.86849) QuantErr: 12.86849 batch_time=0.65957 
Train Epoch: 4 [199/250 25472/32000 (80%)] Loss: 2.84791 (QuantReg: 13.13184) QuantErr: 13.13184 batch_time=1.06227 
Train Epoch: 4 [210/250 26880/32000 (84%)] Loss: 2.64554 (QuantReg: 12.73939) QuantErr: 12.73939 batch_time=0.66207 
Train Epoch: 4 [221/250 28288/32000 (88%)] Loss: 2.57533 (QuantReg: 12.98299) QuantErr: 12.98299 batch_time=0.65166 
Train Epoch: 4 [232/250 29696/32000 (93%)] Loss: 2.40862 (QuantReg: 12.84515) QuantErr: 12.84515 batch_time=1.33455 
Train Epoch: 4 [243/250 31104/32000 (97%)] Loss: 2.29517 (QuantReg: 12.86559) QuantErr: 12.86559 batch_time=0.70188 
Train Epoch: 4 codebook_update_time=1.79016
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_MSRVTT_1kA_roberta-large/checkpoint-epoch4.pth ...
Done in 10.926s
Updating 'best' checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_MSRVTT_1kA_roberta-large/checkpoint-epoch4.pth ...
Done in 21.170s
removing stale ckpt [epoch 3] [took 0.00s]
 epoch          : 4
 loss           : 2.7517209067344663
 quant_reg      : 12.618667369842528
 quant_err      : 12.618667369842528
 learning_rate  : 4.2868749999999995e-05
 n_samples      : 128000
 n_steps        : 1000
 MSRVTT_jsfusion_test/t2v_metrics/R1: 16.6
 MSRVTT_jsfusion_test/t2v_metrics/R5: 43.6
 MSRVTT_jsfusion_test/t2v_metrics/R10: 59.3
 MSRVTT_jsfusion_test/t2v_metrics/R50: 86.0
 MSRVTT_jsfusion_test/t2v_metrics/MedR: 7.0
 MSRVTT_jsfusion_test/t2v_metrics/MeanR: 30.975
 MSRVTT_jsfusion_test/t2v_metrics/geometric_mean_R1-R5-R10: 35.01195999426819
 MSRVTT_jsfusion_test/v2t_metrics/R1: 17.4
 MSRVTT_jsfusion_test/v2t_metrics/R5: 46.4
 MSRVTT_jsfusion_test/v2t_metrics/R10: 59.3
 MSRVTT_jsfusion_test/v2t_metrics/R50: 85.7
 MSRVTT_jsfusion_test/v2t_metrics/MedR: 7.0
 MSRVTT_jsfusion_test/v2t_metrics/MeanR: 29.3445
 MSRVTT_jsfusion_test/v2t_metrics/geometric_mean_R1-R5-R10: 36.31120327497055
 mnt_best       : 35.01195999426819
 not_improved_count: 0
Train Epoch: 5 [1/250 128/32000 (0%)] Loss: 2.08821 (QuantReg: 12.15757) QuantErr: 12.15757 batch_time=37.93470 
Train Epoch: 5 [12/250 1536/32000 (5%)] Loss: 2.50855 (QuantReg: 12.25694) QuantErr: 12.25694 batch_time=1.23900 
Train Epoch: 5 [23/250 2944/32000 (9%)] Loss: 2.65024 (QuantReg: 12.64763) QuantErr: 12.64763 batch_time=0.67646 
Train Epoch: 5 [34/250 4352/32000 (14%)] Loss: 2.43166 (QuantReg: 12.77713) QuantErr: 12.77713 batch_time=0.89755 
Train Epoch: 5 [45/250 5760/32000 (18%)] Loss: 3.02286 (QuantReg: 12.61595) QuantErr: 12.61595 batch_time=0.66171 
Train Epoch: 5 [56/250 7168/32000 (22%)] Loss: 2.54093 (QuantReg: 12.33778) QuantErr: 12.33778 batch_time=0.65062 
Train Epoch: 5 [67/250 8576/32000 (27%)] Loss: 2.60950 (QuantReg: 13.04116) QuantErr: 13.04116 batch_time=0.65872 
Train Epoch: 5 [78/250 9984/32000 (31%)] Loss: 2.52200 (QuantReg: 12.95210) QuantErr: 12.95210 batch_time=0.66353 
Train Epoch: 5 [89/250 11392/32000 (36%)] Loss: 2.41811 (QuantReg: 12.56912) QuantErr: 12.56912 batch_time=0.70320 
Train Epoch: 5 [100/250 12800/32000 (40%)] Loss: 2.18983 (QuantReg: 13.41571) QuantErr: 13.41571 batch_time=0.69828 
Train Epoch: 5 [111/250 14208/32000 (44%)] Loss: 2.60739 (QuantReg: 12.74454) QuantErr: 12.74454 batch_time=0.71217 
Train Epoch: 5 [122/250 15616/32000 (49%)] Loss: 2.95997 (QuantReg: 12.64476) QuantErr: 12.64476 batch_time=0.66043 
Train Epoch: 5 [133/250 17024/32000 (53%)] Loss: 2.11153 (QuantReg: 12.89103) QuantErr: 12.89103 batch_time=0.81865 
Train Epoch: 5 [144/250 18432/32000 (58%)] Loss: 2.32228 (QuantReg: 12.90726) QuantErr: 12.90726 batch_time=1.29505 
Train Epoch: 5 [155/250 19840/32000 (62%)] Loss: 2.39300 (QuantReg: 13.28794) QuantErr: 13.28794 batch_time=0.73139 
Train Epoch: 5 [166/250 21248/32000 (66%)] Loss: 2.33285 (QuantReg: 13.25522) QuantErr: 13.25522 batch_time=0.67174 
Train Epoch: 5 [177/250 22656/32000 (71%)] Loss: 2.49421 (QuantReg: 12.88857) QuantErr: 12.88857 batch_time=0.66983 
Train Epoch: 5 [188/250 24064/32000 (75%)] Loss: 1.93631 (QuantReg: 13.57724) QuantErr: 13.57724 batch_time=0.67022 
Train Epoch: 5 [199/250 25472/32000 (80%)] Loss: 2.34465 (QuantReg: 13.36282) QuantErr: 13.36282 batch_time=1.02487 
Train Epoch: 5 [210/250 26880/32000 (84%)] Loss: 2.13763 (QuantReg: 13.33301) QuantErr: 13.33301 batch_time=1.43334 
Train Epoch: 5 [221/250 28288/32000 (88%)] Loss: 2.28206 (QuantReg: 13.06593) QuantErr: 13.06593 batch_time=0.68155 
Train Epoch: 5 [232/250 29696/32000 (93%)] Loss: 2.32021 (QuantReg: 12.94831) QuantErr: 12.94831 batch_time=0.69634 
Train Epoch: 5 [243/250 31104/32000 (97%)] Loss: 2.16831 (QuantReg: 13.19892) QuantErr: 13.19892 batch_time=0.69630 
Train Epoch: 5 codebook_update_time=1.93058
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_MSRVTT_1kA_roberta-large/checkpoint-epoch5.pth ...
Done in 11.551s
Updating 'best' checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_MSRVTT_1kA_roberta-large/checkpoint-epoch5.pth ...
Done in 22.706s
removing stale ckpt [epoch 4] [took 0.00s]
 epoch          : 5
 loss           : 2.4899971709251405
 quant_reg      : 12.899170501708983
 quant_err      : 12.899170501708983
 learning_rate  : 4.072531249999999e-05
 n_samples      : 160000
 n_steps        : 1250
 MSRVTT_jsfusion_test/t2v_metrics/R1: 17.7
 MSRVTT_jsfusion_test/t2v_metrics/R5: 45.2
 MSRVTT_jsfusion_test/t2v_metrics/R10: 60.2
 MSRVTT_jsfusion_test/t2v_metrics/R50: 86.7
 MSRVTT_jsfusion_test/t2v_metrics/MedR: 7.0
 MSRVTT_jsfusion_test/t2v_metrics/MeanR: 31.9
 MSRVTT_jsfusion_test/t2v_metrics/geometric_mean_R1-R5-R10: 36.3833538990088
 MSRVTT_jsfusion_test/v2t_metrics/R1: 17.8
 MSRVTT_jsfusion_test/v2t_metrics/R5: 47.6
 MSRVTT_jsfusion_test/v2t_metrics/R10: 60.7
 MSRVTT_jsfusion_test/v2t_metrics/R50: 86.4
 MSRVTT_jsfusion_test/v2t_metrics/MedR: 6.0
 MSRVTT_jsfusion_test/v2t_metrics/MeanR: 29.468
 MSRVTT_jsfusion_test/v2t_metrics/geometric_mean_R1-R5-R10: 37.18820491660969
 mnt_best       : 36.3833538990088
 not_improved_count: 0
Train Epoch: 6 [1/250 128/32000 (0%)] Loss: 2.48162 (QuantReg: 12.63422) QuantErr: 12.63422 batch_time=49.68875 
Train Epoch: 6 [12/250 1536/32000 (5%)] Loss: 2.76200 (QuantReg: 12.50474) QuantErr: 12.50474 batch_time=0.65895 
Train Epoch: 6 [23/250 2944/32000 (9%)] Loss: 1.88031 (QuantReg: 12.45931) QuantErr: 12.45931 batch_time=0.69453 
Train Epoch: 6 [34/250 4352/32000 (14%)] Loss: 2.36475 (QuantReg: 12.96870) QuantErr: 12.96870 batch_time=0.65415 
Train Epoch: 6 [45/250 5760/32000 (18%)] Loss: 2.26797 (QuantReg: 12.95778) QuantErr: 12.95778 batch_time=0.66079 
Train Epoch: 6 [56/250 7168/32000 (22%)] Loss: 2.54908 (QuantReg: 12.92240) QuantErr: 12.92240 batch_time=0.65031 
Train Epoch: 6 [67/250 8576/32000 (27%)] Loss: 1.84331 (QuantReg: 12.91935) QuantErr: 12.91935 batch_time=0.67052 
Train Epoch: 6 [78/250 9984/32000 (31%)] Loss: 2.17165 (QuantReg: 12.91395) QuantErr: 12.91395 batch_time=0.66187 
Train Epoch: 6 [89/250 11392/32000 (36%)] Loss: 1.93122 (QuantReg: 12.90967) QuantErr: 12.90967 batch_time=0.68331 
Train Epoch: 6 [100/250 12800/32000 (40%)] Loss: 2.35458 (QuantReg: 12.92685) QuantErr: 12.92685 batch_time=0.65878 
Train Epoch: 6 [111/250 14208/32000 (44%)] Loss: 2.15979 (QuantReg: 12.61000) QuantErr: 12.61000 batch_time=0.65849 
Train Epoch: 6 [122/250 15616/32000 (49%)] Loss: 2.31996 (QuantReg: 12.97061) QuantErr: 12.97061 batch_time=0.66790 
Train Epoch: 6 [133/250 17024/32000 (53%)] Loss: 1.93840 (QuantReg: 13.10253) QuantErr: 13.10253 batch_time=0.65315 
Train Epoch: 6 [144/250 18432/32000 (58%)] Loss: 2.48135 (QuantReg: 12.77691) QuantErr: 12.77691 batch_time=0.67519 
Train Epoch: 6 [155/250 19840/32000 (62%)] Loss: 2.33151 (QuantReg: 13.14875) QuantErr: 13.14875 batch_time=0.68282 
Train Epoch: 6 [166/250 21248/32000 (66%)] Loss: 2.09545 (QuantReg: 12.95242) QuantErr: 12.95242 batch_time=0.67312 
Train Epoch: 6 [177/250 22656/32000 (71%)] Loss: 1.87533 (QuantReg: 13.32896) QuantErr: 13.32896 batch_time=0.70356 
Train Epoch: 6 [188/250 24064/32000 (75%)] Loss: 2.09684 (QuantReg: 13.47479) QuantErr: 13.47479 batch_time=0.66091 
Train Epoch: 6 [199/250 25472/32000 (80%)] Loss: 2.16203 (QuantReg: 13.34404) QuantErr: 13.34404 batch_time=0.66657 
Train Epoch: 6 [210/250 26880/32000 (84%)] Loss: 2.00670 (QuantReg: 13.37728) QuantErr: 13.37728 batch_time=0.65748 
Train Epoch: 6 [221/250 28288/32000 (88%)] Loss: 2.35059 (QuantReg: 13.06709) QuantErr: 13.06709 batch_time=0.71792 
Train Epoch: 6 [232/250 29696/32000 (93%)] Loss: 2.31507 (QuantReg: 13.26053) QuantErr: 13.26053 batch_time=0.67171 
Train Epoch: 6 [243/250 31104/32000 (97%)] Loss: 2.22287 (QuantReg: 13.35721) QuantErr: 13.35721 batch_time=0.67371 
Train Epoch: 6 codebook_update_time=1.79654
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_MSRVTT_1kA_roberta-large/checkpoint-epoch6.pth ...
Done in 11.247s
Updating 'best' checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_MSRVTT_1kA_roberta-large/checkpoint-epoch6.pth ...
Done in 22.422s
removing stale ckpt [epoch 5] [took 0.00s]
 epoch          : 6
 loss           : 2.251945685863495
 quant_reg      : 12.992550075531005
 quant_err      : 12.992550075531005
 learning_rate  : 3.868904687499999e-05
 n_samples      : 192000
 n_steps        : 1500
 MSRVTT_jsfusion_test/t2v_metrics/R1: 18.9
 MSRVTT_jsfusion_test/t2v_metrics/R5: 46.4
 MSRVTT_jsfusion_test/t2v_metrics/R10: 61.3
 MSRVTT_jsfusion_test/t2v_metrics/R50: 87.4
 MSRVTT_jsfusion_test/t2v_metrics/MedR: 6.0
 MSRVTT_jsfusion_test/t2v_metrics/MeanR: 30.254
 MSRVTT_jsfusion_test/t2v_metrics/geometric_mean_R1-R5-R10: 37.741001436874384
 MSRVTT_jsfusion_test/v2t_metrics/R1: 19.3
 MSRVTT_jsfusion_test/v2t_metrics/R5: 48.3
 MSRVTT_jsfusion_test/v2t_metrics/R10: 61.7
 MSRVTT_jsfusion_test/v2t_metrics/R50: 87.0
 MSRVTT_jsfusion_test/v2t_metrics/MedR: 6.0
 MSRVTT_jsfusion_test/v2t_metrics/MeanR: 28.974
 MSRVTT_jsfusion_test/v2t_metrics/geometric_mean_R1-R5-R10: 38.60082036253023
 mnt_best       : 37.741001436874384
 not_improved_count: 0
Train Epoch: 7 [1/250 128/32000 (0%)] Loss: 2.25870 (QuantReg: 13.11625) QuantErr: 13.11625 batch_time=38.40661 
Train Epoch: 7 [12/250 1536/32000 (5%)] Loss: 2.09904 (QuantReg: 12.92030) QuantErr: 12.92030 batch_time=1.02690 
Train Epoch: 7 [23/250 2944/32000 (9%)] Loss: 2.01562 (QuantReg: 12.97165) QuantErr: 12.97165 batch_time=0.66032 
Train Epoch: 7 [34/250 4352/32000 (14%)] Loss: 2.20108 (QuantReg: 13.17317) QuantErr: 13.17317 batch_time=0.66368 
Train Epoch: 7 [45/250 5760/32000 (18%)] Loss: 2.05260 (QuantReg: 12.73668) QuantErr: 12.73668 batch_time=1.08231 
Train Epoch: 7 [56/250 7168/32000 (22%)] Loss: 2.11078 (QuantReg: 12.97747) QuantErr: 12.97747 batch_time=0.65882 
Train Epoch: 7 [67/250 8576/32000 (27%)] Loss: 1.79118 (QuantReg: 12.64454) QuantErr: 12.64454 batch_time=0.66067 
Train Epoch: 7 [78/250 9984/32000 (31%)] Loss: 1.66335 (QuantReg: 13.29062) QuantErr: 13.29062 batch_time=0.65885 
Train Epoch: 7 [89/250 11392/32000 (36%)] Loss: 2.03597 (QuantReg: 13.14596) QuantErr: 13.14596 batch_time=0.66411 
Train Epoch: 7 [100/250 12800/32000 (40%)] Loss: 2.15312 (QuantReg: 12.35673) QuantErr: 12.35673 batch_time=0.65773 
Train Epoch: 7 [111/250 14208/32000 (44%)] Loss: 2.89971 (QuantReg: 13.06555) QuantErr: 13.06555 batch_time=0.69420 
Train Epoch: 7 [122/250 15616/32000 (49%)] Loss: 2.21757 (QuantReg: 13.13260) QuantErr: 13.13260 batch_time=0.69741 
Train Epoch: 7 [133/250 17024/32000 (53%)] Loss: 1.85571 (QuantReg: 13.24255) QuantErr: 13.24255 batch_time=2.21759 
Train Epoch: 7 [144/250 18432/32000 (58%)] Loss: 1.87171 (QuantReg: 13.22735) QuantErr: 13.22735 batch_time=0.67129 
Train Epoch: 7 [155/250 19840/32000 (62%)] Loss: 1.92620 (QuantReg: 13.52663) QuantErr: 13.52663 batch_time=0.66912 
Train Epoch: 7 [166/250 21248/32000 (66%)] Loss: 2.23182 (QuantReg: 13.38952) QuantErr: 13.38952 batch_time=0.65675 
Train Epoch: 7 [177/250 22656/32000 (71%)] Loss: 1.86195 (QuantReg: 13.31304) QuantErr: 13.31304 batch_time=0.65118 
Train Epoch: 7 [188/250 24064/32000 (75%)] Loss: 2.15889 (QuantReg: 12.92914) QuantErr: 12.92914 batch_time=0.87245 
Train Epoch: 7 [199/250 25472/32000 (80%)] Loss: 1.92387 (QuantReg: 13.11683) QuantErr: 13.11683 batch_time=0.70131 
Train Epoch: 7 [210/250 26880/32000 (84%)] Loss: 1.72478 (QuantReg: 13.40509) QuantErr: 13.40509 batch_time=0.99398 
Train Epoch: 7 [221/250 28288/32000 (88%)] Loss: 1.88393 (QuantReg: 13.28214) QuantErr: 13.28214 batch_time=0.71704 
Train Epoch: 7 [232/250 29696/32000 (93%)] Loss: 2.53620 (QuantReg: 13.02670) QuantErr: 13.02670 batch_time=0.76068 
Train Epoch: 7 [243/250 31104/32000 (97%)] Loss: 1.96673 (QuantReg: 13.16356) QuantErr: 13.16356 batch_time=0.66076 
Train Epoch: 7 codebook_update_time=1.87672
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_MSRVTT_1kA_roberta-large/checkpoint-epoch7.pth ...
Done in 11.621s
Updating 'best' checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_MSRVTT_1kA_roberta-large/checkpoint-epoch7.pth ...
Done in 40.611s
removing stale ckpt [epoch 6] [took 0.00s]
 epoch          : 7
 loss           : 2.071570275306702
 quant_reg      : 13.089737552642822
 quant_err      : 13.089737552642822
 learning_rate  : 3.675459453124999e-05
 n_samples      : 224000
 n_steps        : 1750
 MSRVTT_jsfusion_test/t2v_metrics/R1: 19.8
 MSRVTT_jsfusion_test/t2v_metrics/R5: 47.4
 MSRVTT_jsfusion_test/t2v_metrics/R10: 61.6
 MSRVTT_jsfusion_test/t2v_metrics/R50: 87.9
 MSRVTT_jsfusion_test/t2v_metrics/MedR: 6.0
 MSRVTT_jsfusion_test/t2v_metrics/MeanR: 30.026
 MSRVTT_jsfusion_test/t2v_metrics/geometric_mean_R1-R5-R10: 38.66708336187225
 MSRVTT_jsfusion_test/v2t_metrics/R1: 20.2
 MSRVTT_jsfusion_test/v2t_metrics/R5: 50.0
 MSRVTT_jsfusion_test/v2t_metrics/R10: 63.9
 MSRVTT_jsfusion_test/v2t_metrics/R50: 89.0
 MSRVTT_jsfusion_test/v2t_metrics/MedR: 5.5
 MSRVTT_jsfusion_test/v2t_metrics/MeanR: 28.169
 MSRVTT_jsfusion_test/v2t_metrics/geometric_mean_R1-R5-R10: 40.1119778979061
 mnt_best       : 38.66708336187225
 not_improved_count: 0
Train Epoch: 8 [1/250 128/32000 (0%)] Loss: 1.87101 (QuantReg: 12.90982) QuantErr: 12.90982 batch_time=31.79505 
Train Epoch: 8 [12/250 1536/32000 (5%)] Loss: 2.01726 (QuantReg: 12.95795) QuantErr: 12.95795 batch_time=0.66477 
Train Epoch: 8 [23/250 2944/32000 (9%)] Loss: 1.79586 (QuantReg: 12.87651) QuantErr: 12.87651 batch_time=0.68571 
Train Epoch: 8 [34/250 4352/32000 (14%)] Loss: 1.80046 (QuantReg: 13.08184) QuantErr: 13.08184 batch_time=0.64711 
Train Epoch: 8 [45/250 5760/32000 (18%)] Loss: 2.12310 (QuantReg: 12.94056) QuantErr: 12.94056 batch_time=0.70445 
Train Epoch: 8 [56/250 7168/32000 (22%)] Loss: 1.75172 (QuantReg: 12.95403) QuantErr: 12.95403 batch_time=0.66289 
Train Epoch: 8 [67/250 8576/32000 (27%)] Loss: 1.80211 (QuantReg: 13.45222) QuantErr: 13.45222 batch_time=0.65228 
Train Epoch: 8 [78/250 9984/32000 (31%)] Loss: 2.30597 (QuantReg: 12.86281) QuantErr: 12.86281 batch_time=0.68847 
Train Epoch: 8 [89/250 11392/32000 (36%)] Loss: 1.66162 (QuantReg: 13.00886) QuantErr: 13.00886 batch_time=0.65890 
Train Epoch: 8 [100/250 12800/32000 (40%)] Loss: 1.46371 (QuantReg: 12.94135) QuantErr: 12.94135 batch_time=0.65483 
Train Epoch: 8 [111/250 14208/32000 (44%)] Loss: 1.78425 (QuantReg: 13.36287) QuantErr: 13.36287 batch_time=0.65397 
Train Epoch: 8 [122/250 15616/32000 (49%)] Loss: 2.18508 (QuantReg: 13.28462) QuantErr: 13.28462 batch_time=0.68834 
Train Epoch: 8 [133/250 17024/32000 (53%)] Loss: 2.01732 (QuantReg: 13.27861) QuantErr: 13.27861 batch_time=0.71388 
Train Epoch: 8 [144/250 18432/32000 (58%)] Loss: 2.24374 (QuantReg: 13.10788) QuantErr: 13.10788 batch_time=0.74535 
Train Epoch: 8 [155/250 19840/32000 (62%)] Loss: 1.80890 (QuantReg: 13.11076) QuantErr: 13.11076 batch_time=1.06910 
Train Epoch: 8 [166/250 21248/32000 (66%)] Loss: 1.75062 (QuantReg: 13.15689) QuantErr: 13.15689 batch_time=0.64591 
Train Epoch: 8 [177/250 22656/32000 (71%)] Loss: 1.70814 (QuantReg: 13.56445) QuantErr: 13.56445 batch_time=0.67647 
Train Epoch: 8 [188/250 24064/32000 (75%)] Loss: 2.24211 (QuantReg: 13.29390) QuantErr: 13.29390 batch_time=0.66842 
Train Epoch: 8 [199/250 25472/32000 (80%)] Loss: 1.90585 (QuantReg: 13.36112) QuantErr: 13.36112 batch_time=0.64764 
Train Epoch: 8 [210/250 26880/32000 (84%)] Loss: 2.14052 (QuantReg: 13.49210) QuantErr: 13.49210 batch_time=0.66403 
Train Epoch: 8 [221/250 28288/32000 (88%)] Loss: 2.19592 (QuantReg: 13.37045) QuantErr: 13.37045 batch_time=0.65088 
Train Epoch: 8 [232/250 29696/32000 (93%)] Loss: 1.33659 (QuantReg: 13.41962) QuantErr: 13.41962 batch_time=0.65912 
Train Epoch: 8 [243/250 31104/32000 (97%)] Loss: 1.80703 (QuantReg: 13.43741) QuantErr: 13.43741 batch_time=0.65696 
Train Epoch: 8 codebook_update_time=1.77398
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_MSRVTT_1kA_roberta-large/checkpoint-epoch8.pth ...
Done in 11.904s
Updating 'best' checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_MSRVTT_1kA_roberta-large/checkpoint-epoch8.pth ...
Done in 23.107s
removing stale ckpt [epoch 7] [took 0.00s]
 epoch          : 8
 loss           : 1.9262462091445922
 quant_reg      : 13.169290523529053
 quant_err      : 13.169290523529053
 learning_rate  : 3.4916864804687486e-05
 n_samples      : 256000
 n_steps        : 2000
 MSRVTT_jsfusion_test/t2v_metrics/R1: 20.0
 MSRVTT_jsfusion_test/t2v_metrics/R5: 48.6
 MSRVTT_jsfusion_test/t2v_metrics/R10: 63.6
 MSRVTT_jsfusion_test/t2v_metrics/R50: 87.3
 MSRVTT_jsfusion_test/t2v_metrics/MedR: 6.0
 MSRVTT_jsfusion_test/t2v_metrics/MeanR: 29.326
 MSRVTT_jsfusion_test/t2v_metrics/geometric_mean_R1-R5-R10: 39.54040623049936
 MSRVTT_jsfusion_test/v2t_metrics/R1: 21.2
 MSRVTT_jsfusion_test/v2t_metrics/R5: 52.4
 MSRVTT_jsfusion_test/v2t_metrics/R10: 63.3
 MSRVTT_jsfusion_test/v2t_metrics/R50: 88.1
 MSRVTT_jsfusion_test/v2t_metrics/MedR: 5.0
 MSRVTT_jsfusion_test/v2t_metrics/MeanR: 26.805
 MSRVTT_jsfusion_test/v2t_metrics/geometric_mean_R1-R5-R10: 41.27530451068987
 mnt_best       : 39.54040623049936
 not_improved_count: 0
Train Epoch: 9 [1/250 128/32000 (0%)] Loss: 1.52556 (QuantReg: 13.13043) QuantErr: 13.13043 batch_time=35.48745 
Train Epoch: 9 [12/250 1536/32000 (5%)] Loss: 1.63635 (QuantReg: 13.02589) QuantErr: 13.02589 batch_time=1.14259 
Train Epoch: 9 [23/250 2944/32000 (9%)] Loss: 1.97061 (QuantReg: 13.05903) QuantErr: 13.05903 batch_time=0.69987 
Train Epoch: 9 [34/250 4352/32000 (14%)] Loss: 2.05895 (QuantReg: 12.99905) QuantErr: 12.99905 batch_time=0.65519 
Train Epoch: 9 [45/250 5760/32000 (18%)] Loss: 2.11109 (QuantReg: 12.95880) QuantErr: 12.95880 batch_time=0.66315 
Train Epoch: 9 [56/250 7168/32000 (22%)] Loss: 1.99156 (QuantReg: 13.09224) QuantErr: 13.09224 batch_time=0.66920 
Train Epoch: 9 [67/250 8576/32000 (27%)] Loss: 1.49172 (QuantReg: 13.41415) QuantErr: 13.41415 batch_time=2.12765 
Train Epoch: 9 [78/250 9984/32000 (31%)] Loss: 1.76448 (QuantReg: 13.18389) QuantErr: 13.18389 batch_time=2.52358 
Train Epoch: 9 [89/250 11392/32000 (36%)] Loss: 1.86010 (QuantReg: 13.49360) QuantErr: 13.49360 batch_time=0.66960 
Train Epoch: 9 [100/250 12800/32000 (40%)] Loss: 2.14415 (QuantReg: 13.09294) QuantErr: 13.09294 batch_time=0.67529 
Train Epoch: 9 [111/250 14208/32000 (44%)] Loss: 2.36236 (QuantReg: 13.48940) QuantErr: 13.48940 batch_time=0.66865 
Train Epoch: 9 [122/250 15616/32000 (49%)] Loss: 1.79837 (QuantReg: 13.26653) QuantErr: 13.26653 batch_time=0.78090 
Train Epoch: 9 [133/250 17024/32000 (53%)] Loss: 1.72693 (QuantReg: 13.35003) QuantErr: 13.35003 batch_time=0.70953 
Train Epoch: 9 [144/250 18432/32000 (58%)] Loss: 1.45845 (QuantReg: 13.19032) QuantErr: 13.19032 batch_time=0.66276 
Train Epoch: 9 [155/250 19840/32000 (62%)] Loss: 2.02348 (QuantReg: 13.01085) QuantErr: 13.01085 batch_time=0.67063 
Train Epoch: 9 [166/250 21248/32000 (66%)] Loss: 1.95590 (QuantReg: 13.52434) QuantErr: 13.52434 batch_time=0.67344 
Train Epoch: 9 [177/250 22656/32000 (71%)] Loss: 2.08171 (QuantReg: 13.38512) QuantErr: 13.38512 batch_time=0.67679 
Train Epoch: 9 [188/250 24064/32000 (75%)] Loss: 2.06398 (QuantReg: 13.29409) QuantErr: 13.29409 batch_time=0.68094 
Train Epoch: 9 [199/250 25472/32000 (80%)] Loss: 1.71411 (QuantReg: 13.40487) QuantErr: 13.40487 batch_time=0.65767 
Train Epoch: 9 [210/250 26880/32000 (84%)] Loss: 1.52824 (QuantReg: 13.19520) QuantErr: 13.19520 batch_time=0.66242 
Train Epoch: 9 [221/250 28288/32000 (88%)] Loss: 2.21550 (QuantReg: 13.35225) QuantErr: 13.35225 batch_time=1.94242 
Train Epoch: 9 [232/250 29696/32000 (93%)] Loss: 1.51370 (QuantReg: 13.49828) QuantErr: 13.49828 batch_time=0.70422 
Train Epoch: 9 [243/250 31104/32000 (97%)] Loss: 1.56802 (QuantReg: 13.48171) QuantErr: 13.48171 batch_time=0.66221 
Train Epoch: 9 codebook_update_time=1.67283
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_MSRVTT_1kA_roberta-large/checkpoint-epoch9.pth ...
Done in 10.716s
removing stale ckpt [epoch 8] [took 0.00s]
 epoch          : 9
 loss           : 1.8014201350212098
 quant_reg      : 13.280874732971192
 quant_err      : 13.280874732971192
 learning_rate  : 3.317102156445311e-05
 n_samples      : 288000
 n_steps        : 2250
 MSRVTT_jsfusion_test/t2v_metrics/R1: 20.0
 MSRVTT_jsfusion_test/t2v_metrics/R5: 48.0
 MSRVTT_jsfusion_test/t2v_metrics/R10: 62.6
 MSRVTT_jsfusion_test/t2v_metrics/R50: 87.4
 MSRVTT_jsfusion_test/t2v_metrics/MedR: 6.0
 MSRVTT_jsfusion_test/t2v_metrics/MeanR: 30.023
 MSRVTT_jsfusion_test/t2v_metrics/geometric_mean_R1-R5-R10: 39.16954458003912
 MSRVTT_jsfusion_test/v2t_metrics/R1: 19.4
 MSRVTT_jsfusion_test/v2t_metrics/R5: 52.3
 MSRVTT_jsfusion_test/v2t_metrics/R10: 64.9
 MSRVTT_jsfusion_test/v2t_metrics/R50: 88.3
 MSRVTT_jsfusion_test/v2t_metrics/MedR: 5.0
 MSRVTT_jsfusion_test/v2t_metrics/MeanR: 27.451
 MSRVTT_jsfusion_test/v2t_metrics/geometric_mean_R1-R5-R10: 40.38152399951815
 mnt_best       : 39.54040623049936
 not_improved_count: 1
Train Epoch: 10 [1/250 128/32000 (0%)] Loss: 1.82003 (QuantReg: 13.06542) QuantErr: 13.06542 batch_time=28.88070 
Train Epoch: 10 [12/250 1536/32000 (5%)] Loss: 1.84594 (QuantReg: 13.01998) QuantErr: 13.01998 batch_time=0.65639 
Train Epoch: 10 [23/250 2944/32000 (9%)] Loss: 1.94372 (QuantReg: 13.08697) QuantErr: 13.08697 batch_time=0.69936 
Train Epoch: 10 [34/250 4352/32000 (14%)] Loss: 1.79167 (QuantReg: 13.23608) QuantErr: 13.23608 batch_time=1.75603 
Train Epoch: 10 [45/250 5760/32000 (18%)] Loss: 1.66141 (QuantReg: 13.35734) QuantErr: 13.35734 batch_time=0.68500 
Train Epoch: 10 [56/250 7168/32000 (22%)] Loss: 1.92875 (QuantReg: 13.48288) QuantErr: 13.48288 batch_time=0.72218 
Train Epoch: 10 [67/250 8576/32000 (27%)] Loss: 1.95317 (QuantReg: 12.98320) QuantErr: 12.98320 batch_time=0.65937 
Train Epoch: 10 [78/250 9984/32000 (31%)] Loss: 1.25038 (QuantReg: 13.36190) QuantErr: 13.36190 batch_time=0.67152 
Train Epoch: 10 [89/250 11392/32000 (36%)] Loss: 1.81782 (QuantReg: 13.21548) QuantErr: 13.21548 batch_time=0.66244 
Train Epoch: 10 [100/250 12800/32000 (40%)] Loss: 1.37189 (QuantReg: 13.45844) QuantErr: 13.45844 batch_time=0.67443 
Train Epoch: 10 [111/250 14208/32000 (44%)] Loss: 1.86108 (QuantReg: 13.25869) QuantErr: 13.25869 batch_time=0.67172 
Train Epoch: 10 [122/250 15616/32000 (49%)] Loss: 1.64682 (QuantReg: 13.48801) QuantErr: 13.48801 batch_time=0.66265 
Train Epoch: 10 [133/250 17024/32000 (53%)] Loss: 1.55792 (QuantReg: 13.28144) QuantErr: 13.28144 batch_time=0.66306 
Train Epoch: 10 [144/250 18432/32000 (58%)] Loss: 1.51274 (QuantReg: 13.28653) QuantErr: 13.28653 batch_time=1.57945 
Train Epoch: 10 [155/250 19840/32000 (62%)] Loss: 1.36178 (QuantReg: 13.47135) QuantErr: 13.47135 batch_time=0.66622 
Train Epoch: 10 [166/250 21248/32000 (66%)] Loss: 1.50749 (QuantReg: 13.51989) QuantErr: 13.51989 batch_time=0.67735 
Train Epoch: 10 [177/250 22656/32000 (71%)] Loss: 1.57188 (QuantReg: 13.44793) QuantErr: 13.44793 batch_time=0.67473 
Train Epoch: 10 [188/250 24064/32000 (75%)] Loss: 1.39685 (QuantReg: 13.55948) QuantErr: 13.55948 batch_time=0.67105 
Train Epoch: 10 [199/250 25472/32000 (80%)] Loss: 1.73151 (QuantReg: 13.81938) QuantErr: 13.81938 batch_time=0.69184 
Train Epoch: 10 [210/250 26880/32000 (84%)] Loss: 1.75970 (QuantReg: 13.26334) QuantErr: 13.26334 batch_time=0.68434 
Train Epoch: 10 [221/250 28288/32000 (88%)] Loss: 1.23409 (QuantReg: 13.60370) QuantErr: 13.60370 batch_time=0.69840 
Train Epoch: 10 [232/250 29696/32000 (93%)] Loss: 1.71586 (QuantReg: 13.37436) QuantErr: 13.37436 batch_time=0.69208 
Train Epoch: 10 [243/250 31104/32000 (97%)] Loss: 1.53361 (QuantReg: 13.52200) QuantErr: 13.52200 batch_time=0.82498 
Train Epoch: 10 codebook_update_time=1.80266
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_MSRVTT_1kA_roberta-large/checkpoint-epoch10.pth ...
Done in 13.420s
Updating 'best' checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_MSRVTT_1kA_roberta-large/checkpoint-epoch10.pth ...
Done in 24.363s
removing stale ckpt [epoch 9] [took 0.00s]
 epoch          : 10
 loss           : 1.7021977248191833
 quant_reg      : 13.339704524993897
 quant_err      : 13.339704524993897
 learning_rate  : 3.151247048623045e-05
 n_samples      : 320000
 n_steps        : 2500
 MSRVTT_jsfusion_test/t2v_metrics/R1: 21.6
 MSRVTT_jsfusion_test/t2v_metrics/R5: 47.2
 MSRVTT_jsfusion_test/t2v_metrics/R10: 62.7
 MSRVTT_jsfusion_test/t2v_metrics/R50: 87.4
 MSRVTT_jsfusion_test/t2v_metrics/MedR: 6.0
 MSRVTT_jsfusion_test/t2v_metrics/MeanR: 29.11
 MSRVTT_jsfusion_test/t2v_metrics/geometric_mean_R1-R5-R10: 39.98414037930852
 MSRVTT_jsfusion_test/v2t_metrics/R1: 20.8
 MSRVTT_jsfusion_test/v2t_metrics/R5: 51.0
 MSRVTT_jsfusion_test/v2t_metrics/R10: 64.0
 MSRVTT_jsfusion_test/v2t_metrics/R50: 88.7
 MSRVTT_jsfusion_test/v2t_metrics/MedR: 5.0
 MSRVTT_jsfusion_test/v2t_metrics/MeanR: 26.2715
 MSRVTT_jsfusion_test/v2t_metrics/geometric_mean_R1-R5-R10: 40.79477057159102
 mnt_best       : 39.98414037930852
 not_improved_count: 0
Train Epoch: 11 [1/250 128/32000 (0%)] Loss: 1.43648 (QuantReg: 13.52731) QuantErr: 13.52731 batch_time=31.78048 
Train Epoch: 11 [12/250 1536/32000 (5%)] Loss: 1.39265 (QuantReg: 13.17540) QuantErr: 13.17540 batch_time=0.66872 
Train Epoch: 11 [23/250 2944/32000 (9%)] Loss: 1.46467 (QuantReg: 13.51298) QuantErr: 13.51298 batch_time=0.76144 
Train Epoch: 11 [34/250 4352/32000 (14%)] Loss: 1.85120 (QuantReg: 13.06151) QuantErr: 13.06151 batch_time=0.70764 
Train Epoch: 11 [45/250 5760/32000 (18%)] Loss: 1.59836 (QuantReg: 13.33755) QuantErr: 13.33755 batch_time=0.65381 
Train Epoch: 11 [56/250 7168/32000 (22%)] Loss: 1.43987 (QuantReg: 13.59542) QuantErr: 13.59542 batch_time=0.68704 
Train Epoch: 11 [67/250 8576/32000 (27%)] Loss: 1.51306 (QuantReg: 13.25063) QuantErr: 13.25063 batch_time=6.81163 
Train Epoch: 11 [78/250 9984/32000 (31%)] Loss: 2.14457 (QuantReg: 13.26828) QuantErr: 13.26828 batch_time=0.68202 
Train Epoch: 11 [89/250 11392/32000 (36%)] Loss: 1.38882 (QuantReg: 13.50664) QuantErr: 13.50664 batch_time=0.71408 
Train Epoch: 11 [100/250 12800/32000 (40%)] Loss: 2.07076 (QuantReg: 13.11827) QuantErr: 13.11827 batch_time=0.70788 
Train Epoch: 11 [111/250 14208/32000 (44%)] Loss: 1.78256 (QuantReg: 13.36119) QuantErr: 13.36119 batch_time=0.68516 
Train Epoch: 11 [122/250 15616/32000 (49%)] Loss: 1.62120 (QuantReg: 13.53200) QuantErr: 13.53200 batch_time=0.72628 
Train Epoch: 11 [133/250 17024/32000 (53%)] Loss: 1.45586 (QuantReg: 13.17054) QuantErr: 13.17054 batch_time=0.69745 
Train Epoch: 11 [144/250 18432/32000 (58%)] Loss: 1.74681 (QuantReg: 13.52909) QuantErr: 13.52909 batch_time=1.25635 
Train Epoch: 11 [155/250 19840/32000 (62%)] Loss: 1.91311 (QuantReg: 13.21407) QuantErr: 13.21407 batch_time=1.33694 
Train Epoch: 11 [166/250 21248/32000 (66%)] Loss: 1.64999 (QuantReg: 13.22875) QuantErr: 13.22875 batch_time=0.66092 
Train Epoch: 11 [177/250 22656/32000 (71%)] Loss: 1.54173 (QuantReg: 13.42341) QuantErr: 13.42341 batch_time=0.68833 
Train Epoch: 11 [188/250 24064/32000 (75%)] Loss: 1.52500 (QuantReg: 13.23454) QuantErr: 13.23454 batch_time=0.65372 
Train Epoch: 11 [199/250 25472/32000 (80%)] Loss: 1.46293 (QuantReg: 13.92288) QuantErr: 13.92288 batch_time=0.67834 
Train Epoch: 11 [210/250 26880/32000 (84%)] Loss: 1.47916 (QuantReg: 13.36629) QuantErr: 13.36629 batch_time=0.65899 
Train Epoch: 11 [221/250 28288/32000 (88%)] Loss: 1.72876 (QuantReg: 13.66555) QuantErr: 13.66555 batch_time=0.74755 
Train Epoch: 11 [232/250 29696/32000 (93%)] Loss: 1.26856 (QuantReg: 13.73539) QuantErr: 13.73539 batch_time=0.67432 
Train Epoch: 11 [243/250 31104/32000 (97%)] Loss: 1.71345 (QuantReg: 13.02547) QuantErr: 13.02547 batch_time=0.67846 
Train Epoch: 11 codebook_update_time=1.84713
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_MSRVTT_1kA_roberta-large/checkpoint-epoch11.pth ...
Done in 15.859s
Updating 'best' checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_MSRVTT_1kA_roberta-large/checkpoint-epoch11.pth ...
Done in 36.155s
removing stale ckpt [epoch 10] [took 0.00s]
 epoch          : 11
 loss           : 1.607930206298828
 quant_reg      : 13.359805320739746
 quant_err      : 13.359805320739746
 learning_rate  : 2.993684696191893e-05
 n_samples      : 352000
 n_steps        : 2750
 MSRVTT_jsfusion_test/t2v_metrics/R1: 22.2
 MSRVTT_jsfusion_test/t2v_metrics/R5: 49.0
 MSRVTT_jsfusion_test/t2v_metrics/R10: 64.8
 MSRVTT_jsfusion_test/t2v_metrics/R50: 88.8
 MSRVTT_jsfusion_test/t2v_metrics/MedR: 6.0
 MSRVTT_jsfusion_test/t2v_metrics/MeanR: 29.249
 MSRVTT_jsfusion_test/t2v_metrics/geometric_mean_R1-R5-R10: 41.308683417867805
 MSRVTT_jsfusion_test/v2t_metrics/R1: 23.3
 MSRVTT_jsfusion_test/v2t_metrics/R5: 51.2
 MSRVTT_jsfusion_test/v2t_metrics/R10: 65.8
 MSRVTT_jsfusion_test/v2t_metrics/R50: 89.5
 MSRVTT_jsfusion_test/v2t_metrics/MedR: 5.0
 MSRVTT_jsfusion_test/v2t_metrics/MeanR: 25.5555
 MSRVTT_jsfusion_test/v2t_metrics/geometric_mean_R1-R5-R10: 42.81710091957027
 mnt_best       : 41.308683417867805
 not_improved_count: 0
Train Epoch: 12 [1/250 128/32000 (0%)] Loss: 1.48331 (QuantReg: 12.99961) QuantErr: 12.99961 batch_time=29.82831 
Train Epoch: 12 [12/250 1536/32000 (5%)] Loss: 1.79047 (QuantReg: 13.56208) QuantErr: 13.56208 batch_time=0.67169 
Train Epoch: 12 [23/250 2944/32000 (9%)] Loss: 1.64703 (QuantReg: 13.57298) QuantErr: 13.57298 batch_time=2.50851 
Train Epoch: 12 [34/250 4352/32000 (14%)] Loss: 1.42315 (QuantReg: 13.00154) QuantErr: 13.00154 batch_time=0.63661 
Train Epoch: 12 [45/250 5760/32000 (18%)] Loss: 1.42653 (QuantReg: 13.73501) QuantErr: 13.73501 batch_time=0.69562 
Train Epoch: 12 [56/250 7168/32000 (22%)] Loss: 1.38647 (QuantReg: 13.56740) QuantErr: 13.56740 batch_time=0.63886 
Train Epoch: 12 [67/250 8576/32000 (27%)] Loss: 1.55517 (QuantReg: 13.09123) QuantErr: 13.09123 batch_time=3.09897 
Train Epoch: 12 [78/250 9984/32000 (31%)] Loss: 1.53433 (QuantReg: 13.33111) QuantErr: 13.33111 batch_time=0.65584 
Train Epoch: 12 [89/250 11392/32000 (36%)] Loss: 1.53096 (QuantReg: 13.47641) QuantErr: 13.47641 batch_time=0.66137 
Train Epoch: 12 [100/250 12800/32000 (40%)] Loss: 1.75796 (QuantReg: 13.29938) QuantErr: 13.29938 batch_time=0.69696 
Train Epoch: 12 [111/250 14208/32000 (44%)] Loss: 1.45156 (QuantReg: 13.77416) QuantErr: 13.77416 batch_time=0.69705 
Train Epoch: 12 [122/250 15616/32000 (49%)] Loss: 1.32104 (QuantReg: 13.38738) QuantErr: 13.38738 batch_time=0.66878 
Train Epoch: 12 [133/250 17024/32000 (53%)] Loss: 1.59403 (QuantReg: 13.36352) QuantErr: 13.36352 batch_time=0.78428 
Train Epoch: 12 [144/250 18432/32000 (58%)] Loss: 1.26520 (QuantReg: 13.27565) QuantErr: 13.27565 batch_time=0.65341 
Train Epoch: 12 [155/250 19840/32000 (62%)] Loss: 1.15062 (QuantReg: 13.82791) QuantErr: 13.82791 batch_time=0.66767 
Train Epoch: 12 [166/250 21248/32000 (66%)] Loss: 1.27449 (QuantReg: 13.66372) QuantErr: 13.66372 batch_time=0.69894 
Train Epoch: 12 [177/250 22656/32000 (71%)] Loss: 1.44800 (QuantReg: 13.41560) QuantErr: 13.41560 batch_time=0.70480 
Train Epoch: 12 [188/250 24064/32000 (75%)] Loss: 1.60233 (QuantReg: 13.35867) QuantErr: 13.35867 batch_time=0.74404 
Train Epoch: 12 [199/250 25472/32000 (80%)] Loss: 1.88449 (QuantReg: 13.70960) QuantErr: 13.70960 batch_time=4.03146 
Train Epoch: 12 [210/250 26880/32000 (84%)] Loss: 1.25932 (QuantReg: 13.68826) QuantErr: 13.68826 batch_time=0.69213 
Train Epoch: 12 [221/250 28288/32000 (88%)] Loss: 1.44955 (QuantReg: 13.51648) QuantErr: 13.51648 batch_time=0.74154 
Train Epoch: 12 [232/250 29696/32000 (93%)] Loss: 1.32105 (QuantReg: 13.57793) QuantErr: 13.57793 batch_time=0.70318 
Train Epoch: 12 [243/250 31104/32000 (97%)] Loss: 1.32179 (QuantReg: 13.83147) QuantErr: 13.83147 batch_time=0.67273 
Train Epoch: 12 codebook_update_time=1.76220
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_MSRVTT_1kA_roberta-large/checkpoint-epoch12.pth ...
Done in 11.069s
removing stale ckpt [epoch 11] [took 0.00s]
 epoch          : 12
 loss           : 1.5330995869636537
 quant_reg      : 13.474599723815919
 quant_err      : 13.474599723815919
 learning_rate  : 2.844000461382298e-05
 n_samples      : 384000
 n_steps        : 3000
 MSRVTT_jsfusion_test/t2v_metrics/R1: 21.1
 MSRVTT_jsfusion_test/t2v_metrics/R5: 50.5
 MSRVTT_jsfusion_test/t2v_metrics/R10: 66.0
 MSRVTT_jsfusion_test/t2v_metrics/R50: 89.0
 MSRVTT_jsfusion_test/t2v_metrics/MedR: 5.0
 MSRVTT_jsfusion_test/t2v_metrics/MeanR: 27.187
 MSRVTT_jsfusion_test/t2v_metrics/geometric_mean_R1-R5-R10: 41.276790677274185
 MSRVTT_jsfusion_test/v2t_metrics/R1: 21.1
 MSRVTT_jsfusion_test/v2t_metrics/R5: 51.8
 MSRVTT_jsfusion_test/v2t_metrics/R10: 66.3
 MSRVTT_jsfusion_test/v2t_metrics/R50: 89.4
 MSRVTT_jsfusion_test/v2t_metrics/MedR: 5.0
 MSRVTT_jsfusion_test/v2t_metrics/MeanR: 24.8455
 MSRVTT_jsfusion_test/v2t_metrics/geometric_mean_R1-R5-R10: 41.6909618169206
 mnt_best       : 41.308683417867805
 not_improved_count: 1
Train Epoch: 13 [1/250 128/32000 (0%)] Loss: 1.43200 (QuantReg: 13.39461) QuantErr: 13.39461 batch_time=31.77802 
Train Epoch: 13 [12/250 1536/32000 (5%)] Loss: 1.41558 (QuantReg: 13.12468) QuantErr: 13.12468 batch_time=0.67895 
Train Epoch: 13 [23/250 2944/32000 (9%)] Loss: 1.42784 (QuantReg: 13.41382) QuantErr: 13.41382 batch_time=0.70164 
Train Epoch: 13 [34/250 4352/32000 (14%)] Loss: 1.30405 (QuantReg: 13.44718) QuantErr: 13.44718 batch_time=0.78948 
Train Epoch: 13 [45/250 5760/32000 (18%)] Loss: 1.61807 (QuantReg: 13.65821) QuantErr: 13.65821 batch_time=0.66238 
Train Epoch: 13 [56/250 7168/32000 (22%)] Loss: 1.63970 (QuantReg: 13.46915) QuantErr: 13.46915 batch_time=0.88372 
Train Epoch: 13 [67/250 8576/32000 (27%)] Loss: 1.71311 (QuantReg: 13.84007) QuantErr: 13.84007 batch_time=1.10794 
Train Epoch: 13 [78/250 9984/32000 (31%)] Loss: 1.34363 (QuantReg: 13.81513) QuantErr: 13.81513 batch_time=0.69729 
Train Epoch: 13 [89/250 11392/32000 (36%)] Loss: 1.56127 (QuantReg: 13.48394) QuantErr: 13.48394 batch_time=0.65582 
Train Epoch: 13 [100/250 12800/32000 (40%)] Loss: 1.44860 (QuantReg: 13.75506) QuantErr: 13.75506 batch_time=0.67776 
Train Epoch: 13 [111/250 14208/32000 (44%)] Loss: 1.64500 (QuantReg: 13.24815) QuantErr: 13.24815 batch_time=0.65255 
Train Epoch: 13 [122/250 15616/32000 (49%)] Loss: 1.19502 (QuantReg: 13.90032) QuantErr: 13.90032 batch_time=0.65810 
Train Epoch: 13 [133/250 17024/32000 (53%)] Loss: 1.44363 (QuantReg: 13.63349) QuantErr: 13.63349 batch_time=2.29187 
Train Epoch: 13 [144/250 18432/32000 (58%)] Loss: 1.25262 (QuantReg: 13.32389) QuantErr: 13.32389 batch_time=6.59868 
Train Epoch: 13 [155/250 19840/32000 (62%)] Loss: 1.44916 (QuantReg: 13.74998) QuantErr: 13.74998 batch_time=0.67914 
Train Epoch: 13 [166/250 21248/32000 (66%)] Loss: 1.42846 (QuantReg: 13.90290) QuantErr: 13.90290 batch_time=0.69650 
Train Epoch: 13 [177/250 22656/32000 (71%)] Loss: 1.37011 (QuantReg: 13.70504) QuantErr: 13.70504 batch_time=0.66264 
Train Epoch: 13 [188/250 24064/32000 (75%)] Loss: 1.37756 (QuantReg: 13.35899) QuantErr: 13.35899 batch_time=0.69158 
Train Epoch: 13 [199/250 25472/32000 (80%)] Loss: 1.50527 (QuantReg: 13.60955) QuantErr: 13.60955 batch_time=0.74513 
Train Epoch: 13 [210/250 26880/32000 (84%)] Loss: 1.62860 (QuantReg: 13.36018) QuantErr: 13.36018 batch_time=0.65857 
Train Epoch: 13 [221/250 28288/32000 (88%)] Loss: 1.41984 (QuantReg: 13.71466) QuantErr: 13.71466 batch_time=0.68646 
Train Epoch: 13 [232/250 29696/32000 (93%)] Loss: 1.09490 (QuantReg: 13.91982) QuantErr: 13.91982 batch_time=0.68681 
Train Epoch: 13 [243/250 31104/32000 (97%)] Loss: 1.70161 (QuantReg: 13.61750) QuantErr: 13.61750 batch_time=0.66421 
Train Epoch: 13 codebook_update_time=1.78183
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_MSRVTT_1kA_roberta-large/checkpoint-epoch13.pth ...
Done in 11.094s
Updating 'best' checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_MSRVTT_1kA_roberta-large/checkpoint-epoch13.pth ...
Done in 21.994s
removing stale ckpt [epoch 12] [took 0.00s]
 epoch          : 13
 loss           : 1.4802486577033998
 quant_reg      : 13.522372097015381
 quant_err      : 13.522372097015381
 learning_rate  : 2.7018004383131832e-05
 n_samples      : 416000
 n_steps        : 3250
 MSRVTT_jsfusion_test/t2v_metrics/R1: 21.9
 MSRVTT_jsfusion_test/t2v_metrics/R5: 50.2
 MSRVTT_jsfusion_test/t2v_metrics/R10: 64.8
 MSRVTT_jsfusion_test/t2v_metrics/R50: 88.9
 MSRVTT_jsfusion_test/t2v_metrics/MedR: 5.0
 MSRVTT_jsfusion_test/t2v_metrics/MeanR: 28.515
 MSRVTT_jsfusion_test/t2v_metrics/geometric_mean_R1-R5-R10: 41.454747984404605
 MSRVTT_jsfusion_test/v2t_metrics/R1: 22.0
 MSRVTT_jsfusion_test/v2t_metrics/R5: 54.9
 MSRVTT_jsfusion_test/v2t_metrics/R10: 66.9
 MSRVTT_jsfusion_test/v2t_metrics/R50: 89.6
 MSRVTT_jsfusion_test/v2t_metrics/MedR: 4.0
 MSRVTT_jsfusion_test/v2t_metrics/MeanR: 24.901
 MSRVTT_jsfusion_test/v2t_metrics/geometric_mean_R1-R5-R10: 43.232171252012876
 mnt_best       : 41.454747984404605
 not_improved_count: 0
Train Epoch: 14 [1/250 128/32000 (0%)] Loss: 1.42969 (QuantReg: 13.51307) QuantErr: 13.51307 batch_time=32.60053 
Train Epoch: 14 [12/250 1536/32000 (5%)] Loss: 1.75685 (QuantReg: 13.39105) QuantErr: 13.39105 batch_time=0.69923 
Train Epoch: 14 [23/250 2944/32000 (9%)] Loss: 1.57048 (QuantReg: 13.11016) QuantErr: 13.11016 batch_time=0.66647 
Train Epoch: 14 [34/250 4352/32000 (14%)] Loss: 1.25592 (QuantReg: 13.34387) QuantErr: 13.34387 batch_time=0.65878 
Train Epoch: 14 [45/250 5760/32000 (18%)] Loss: 1.45099 (QuantReg: 13.34859) QuantErr: 13.34859 batch_time=0.71398 
Train Epoch: 14 [56/250 7168/32000 (22%)] Loss: 1.40051 (QuantReg: 13.51556) QuantErr: 13.51556 batch_time=0.66526 
Train Epoch: 14 [67/250 8576/32000 (27%)] Loss: 1.17854 (QuantReg: 13.38540) QuantErr: 13.38540 batch_time=0.65614 
Train Epoch: 14 [78/250 9984/32000 (31%)] Loss: 2.06778 (QuantReg: 13.57257) QuantErr: 13.57257 batch_time=0.69208 
Train Epoch: 14 [89/250 11392/32000 (36%)] Loss: 1.46108 (QuantReg: 13.58277) QuantErr: 13.58277 batch_time=1.24897 
Train Epoch: 14 [100/250 12800/32000 (40%)] Loss: 1.72985 (QuantReg: 13.45620) QuantErr: 13.45620 batch_time=1.58668 
Train Epoch: 14 [111/250 14208/32000 (44%)] Loss: 1.44647 (QuantReg: 13.73777) QuantErr: 13.73777 batch_time=0.72876 
Train Epoch: 14 [122/250 15616/32000 (49%)] Loss: 1.67088 (QuantReg: 13.38900) QuantErr: 13.38900 batch_time=0.81513 
Train Epoch: 14 [133/250 17024/32000 (53%)] Loss: 1.53106 (QuantReg: 13.47215) QuantErr: 13.47215 batch_time=0.64989 
Train Epoch: 14 [144/250 18432/32000 (58%)] Loss: 1.88212 (QuantReg: 13.80937) QuantErr: 13.80937 batch_time=0.65940 
Train Epoch: 14 [155/250 19840/32000 (62%)] Loss: 1.75903 (QuantReg: 13.71489) QuantErr: 13.71489 batch_time=0.65008 
Train Epoch: 14 [166/250 21248/32000 (66%)] Loss: 1.37023 (QuantReg: 13.61047) QuantErr: 13.61047 batch_time=0.71724 
Train Epoch: 14 [177/250 22656/32000 (71%)] Loss: 1.53656 (QuantReg: 13.51280) QuantErr: 13.51280 batch_time=0.66267 
Train Epoch: 14 [188/250 24064/32000 (75%)] Loss: 1.22390 (QuantReg: 13.76628) QuantErr: 13.76628 batch_time=0.65905 
Train Epoch: 14 [199/250 25472/32000 (80%)] Loss: 1.24216 (QuantReg: 13.50550) QuantErr: 13.50550 batch_time=1.30646 
Train Epoch: 14 [210/250 26880/32000 (84%)] Loss: 1.54194 (QuantReg: 13.59399) QuantErr: 13.59399 batch_time=0.66919 
Train Epoch: 14 [221/250 28288/32000 (88%)] Loss: 1.33956 (QuantReg: 13.47973) QuantErr: 13.47973 batch_time=0.68005 
Train Epoch: 14 [232/250 29696/32000 (93%)] Loss: 1.57639 (QuantReg: 13.51877) QuantErr: 13.51877 batch_time=0.66998 
Train Epoch: 14 [243/250 31104/32000 (97%)] Loss: 1.25486 (QuantReg: 13.75838) QuantErr: 13.75838 batch_time=0.68061 
Train Epoch: 14 codebook_update_time=1.75278
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_MSRVTT_1kA_roberta-large/checkpoint-epoch14.pth ...
Done in 27.174s
Updating 'best' checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_MSRVTT_1kA_roberta-large/checkpoint-epoch14.pth ...
Done in 37.949s
removing stale ckpt [epoch 13] [took 0.00s]
 epoch          : 14
 loss           : 1.419533536672592
 quant_reg      : 13.572390232086182
 quant_err      : 13.572390232086182
 learning_rate  : 2.566710416397524e-05
 n_samples      : 448000
 n_steps        : 3500
 MSRVTT_jsfusion_test/t2v_metrics/R1: 21.7
 MSRVTT_jsfusion_test/t2v_metrics/R5: 50.9
 MSRVTT_jsfusion_test/t2v_metrics/R10: 66.4
 MSRVTT_jsfusion_test/t2v_metrics/R50: 88.6
 MSRVTT_jsfusion_test/t2v_metrics/MedR: 5.0
 MSRVTT_jsfusion_test/t2v_metrics/MeanR: 26.868
 MSRVTT_jsfusion_test/t2v_metrics/geometric_mean_R1-R5-R10: 41.85832688270351
 MSRVTT_jsfusion_test/v2t_metrics/R1: 22.7
 MSRVTT_jsfusion_test/v2t_metrics/R5: 52.8
 MSRVTT_jsfusion_test/v2t_metrics/R10: 66.7
 MSRVTT_jsfusion_test/v2t_metrics/R50: 89.0
 MSRVTT_jsfusion_test/v2t_metrics/MedR: 5.0
 MSRVTT_jsfusion_test/v2t_metrics/MeanR: 25.517
 MSRVTT_jsfusion_test/v2t_metrics/geometric_mean_R1-R5-R10: 43.07862880346705
 mnt_best       : 41.85832688270351
 not_improved_count: 0
Train Epoch: 15 [1/250 128/32000 (0%)] Loss: 0.97573 (QuantReg: 13.29281) QuantErr: 13.29281 batch_time=33.85801 
Train Epoch: 15 [12/250 1536/32000 (5%)] Loss: 1.53698 (QuantReg: 13.26563) QuantErr: 13.26563 batch_time=0.66134 
Train Epoch: 15 [23/250 2944/32000 (9%)] Loss: 1.32427 (QuantReg: 13.52860) QuantErr: 13.52860 batch_time=0.66286 
Train Epoch: 15 [34/250 4352/32000 (14%)] Loss: 1.08078 (QuantReg: 13.66179) QuantErr: 13.66179 batch_time=0.71694 
Train Epoch: 15 [45/250 5760/32000 (18%)] Loss: 1.20244 (QuantReg: 13.36855) QuantErr: 13.36855 batch_time=0.68837 
Train Epoch: 15 [56/250 7168/32000 (22%)] Loss: 1.41947 (QuantReg: 13.73359) QuantErr: 13.73359 batch_time=0.66964 
Train Epoch: 15 [67/250 8576/32000 (27%)] Loss: 1.99007 (QuantReg: 13.33196) QuantErr: 13.33196 batch_time=1.45970 
Train Epoch: 15 [78/250 9984/32000 (31%)] Loss: 1.67348 (QuantReg: 13.22276) QuantErr: 13.22276 batch_time=2.17960 
Train Epoch: 15 [89/250 11392/32000 (36%)] Loss: 1.50045 (QuantReg: 13.20578) QuantErr: 13.20578 batch_time=0.66277 
Train Epoch: 15 [100/250 12800/32000 (40%)] Loss: 1.31141 (QuantReg: 13.56923) QuantErr: 13.56923 batch_time=0.65046 
Train Epoch: 15 [111/250 14208/32000 (44%)] Loss: 1.17835 (QuantReg: 13.67442) QuantErr: 13.67442 batch_time=0.67843 
Train Epoch: 15 [122/250 15616/32000 (49%)] Loss: 1.45126 (QuantReg: 13.76441) QuantErr: 13.76441 batch_time=0.66590 
Train Epoch: 15 [133/250 17024/32000 (53%)] Loss: 1.40080 (QuantReg: 13.47635) QuantErr: 13.47635 batch_time=0.92174 
Train Epoch: 15 [144/250 18432/32000 (58%)] Loss: 1.23642 (QuantReg: 13.40327) QuantErr: 13.40327 batch_time=6.45106 
Train Epoch: 15 [155/250 19840/32000 (62%)] Loss: 1.40819 (QuantReg: 13.37731) QuantErr: 13.37731 batch_time=0.65855 
Train Epoch: 15 [166/250 21248/32000 (66%)] Loss: 1.45716 (QuantReg: 13.18453) QuantErr: 13.18453 batch_time=0.78194 
Train Epoch: 15 [177/250 22656/32000 (71%)] Loss: 1.46035 (QuantReg: 13.57556) QuantErr: 13.57556 batch_time=0.79777 
Train Epoch: 15 [188/250 24064/32000 (75%)] Loss: 1.83335 (QuantReg: 13.56655) QuantErr: 13.56655 batch_time=0.67922 
Train Epoch: 15 [199/250 25472/32000 (80%)] Loss: 1.11148 (QuantReg: 13.60664) QuantErr: 13.60664 batch_time=0.65456 
Train Epoch: 15 [210/250 26880/32000 (84%)] Loss: 1.15588 (QuantReg: 14.13127) QuantErr: 14.13127 batch_time=0.64868 
Train Epoch: 15 [221/250 28288/32000 (88%)] Loss: 1.37990 (QuantReg: 13.74224) QuantErr: 13.74224 batch_time=0.73865 
Train Epoch: 15 [232/250 29696/32000 (93%)] Loss: 1.06229 (QuantReg: 13.43198) QuantErr: 13.43198 batch_time=0.71929 
Train Epoch: 15 [243/250 31104/32000 (97%)] Loss: 1.16110 (QuantReg: 13.49090) QuantErr: 13.49090 batch_time=0.69553 
Train Epoch: 15 codebook_update_time=1.70952
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_MSRVTT_1kA_roberta-large/checkpoint-epoch15.pth ...
Done in 11.314s
Updating 'best' checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_MSRVTT_1kA_roberta-large/checkpoint-epoch15.pth ...
Done in 36.475s
removing stale ckpt [epoch 14] [took 0.00s]
 epoch          : 15
 loss           : 1.350037858724594
 quant_reg      : 13.545472583770753
 quant_err      : 13.545472583770753
 learning_rate  : 2.4383748955776477e-05
 n_samples      : 480000
 n_steps        : 3750
 MSRVTT_jsfusion_test/t2v_metrics/R1: 22.9
 MSRVTT_jsfusion_test/t2v_metrics/R5: 50.6
 MSRVTT_jsfusion_test/t2v_metrics/R10: 66.1
 MSRVTT_jsfusion_test/t2v_metrics/R50: 89.1
 MSRVTT_jsfusion_test/t2v_metrics/MedR: 5.0
 MSRVTT_jsfusion_test/t2v_metrics/MeanR: 29.17
 MSRVTT_jsfusion_test/t2v_metrics/geometric_mean_R1-R5-R10: 42.468066253773664
 MSRVTT_jsfusion_test/v2t_metrics/R1: 21.3
 MSRVTT_jsfusion_test/v2t_metrics/R5: 53.7
 MSRVTT_jsfusion_test/v2t_metrics/R10: 66.9
 MSRVTT_jsfusion_test/v2t_metrics/R50: 90.0
 MSRVTT_jsfusion_test/v2t_metrics/MedR: 5.0
 MSRVTT_jsfusion_test/v2t_metrics/MeanR: 26.0505
 MSRVTT_jsfusion_test/v2t_metrics/geometric_mean_R1-R5-R10: 42.45478725867523
 mnt_best       : 42.468066253773664
 not_improved_count: 0
Train Epoch: 16 [1/250 128/32000 (0%)] Loss: 1.20068 (QuantReg: 13.38278) QuantErr: 13.38278 batch_time=33.87227 
Train Epoch: 16 [12/250 1536/32000 (5%)] Loss: 1.60406 (QuantReg: 13.36020) QuantErr: 13.36020 batch_time=0.68507 
Train Epoch: 16 [23/250 2944/32000 (9%)] Loss: 1.13485 (QuantReg: 13.59364) QuantErr: 13.59364 batch_time=0.64839 
Train Epoch: 16 [34/250 4352/32000 (14%)] Loss: 1.48764 (QuantReg: 13.61015) QuantErr: 13.61015 batch_time=0.64728 
Train Epoch: 16 [45/250 5760/32000 (18%)] Loss: 0.97623 (QuantReg: 13.87675) QuantErr: 13.87675 batch_time=0.65533 
Train Epoch: 16 [56/250 7168/32000 (22%)] Loss: 1.34442 (QuantReg: 13.44768) QuantErr: 13.44768 batch_time=0.66026 
Train Epoch: 16 [67/250 8576/32000 (27%)] Loss: 1.18877 (QuantReg: 13.40382) QuantErr: 13.40382 batch_time=0.69071 
Train Epoch: 16 [78/250 9984/32000 (31%)] Loss: 1.45869 (QuantReg: 13.56211) QuantErr: 13.56211 batch_time=0.65544 
Train Epoch: 16 [89/250 11392/32000 (36%)] Loss: 1.30936 (QuantReg: 13.66198) QuantErr: 13.66198 batch_time=0.78287 
Train Epoch: 16 [100/250 12800/32000 (40%)] Loss: 1.24278 (QuantReg: 13.29220) QuantErr: 13.29220 batch_time=0.65704 
Train Epoch: 16 [111/250 14208/32000 (44%)] Loss: 1.22133 (QuantReg: 13.80861) QuantErr: 13.80861 batch_time=0.68115 
Train Epoch: 16 [122/250 15616/32000 (49%)] Loss: 1.19612 (QuantReg: 13.60232) QuantErr: 13.60232 batch_time=0.66608 
Train Epoch: 16 [133/250 17024/32000 (53%)] Loss: 1.11671 (QuantReg: 13.64321) QuantErr: 13.64321 batch_time=0.67553 
Train Epoch: 16 [144/250 18432/32000 (58%)] Loss: 1.28040 (QuantReg: 13.74859) QuantErr: 13.74859 batch_time=0.66181 
Train Epoch: 16 [155/250 19840/32000 (62%)] Loss: 1.51969 (QuantReg: 13.83965) QuantErr: 13.83965 batch_time=0.65763 
Train Epoch: 16 [166/250 21248/32000 (66%)] Loss: 1.43783 (QuantReg: 13.88601) QuantErr: 13.88601 batch_time=0.65116 
Train Epoch: 16 [177/250 22656/32000 (71%)] Loss: 1.30184 (QuantReg: 13.60016) QuantErr: 13.60016 batch_time=0.67519 
Train Epoch: 16 [188/250 24064/32000 (75%)] Loss: 1.29702 (QuantReg: 13.67758) QuantErr: 13.67758 batch_time=0.97205 
Train Epoch: 16 [199/250 25472/32000 (80%)] Loss: 1.18225 (QuantReg: 13.87104) QuantErr: 13.87104 batch_time=0.65880 
Train Epoch: 16 [210/250 26880/32000 (84%)] Loss: 1.08175 (QuantReg: 13.73026) QuantErr: 13.73026 batch_time=0.68907 
Train Epoch: 16 [221/250 28288/32000 (88%)] Loss: 1.85575 (QuantReg: 13.42581) QuantErr: 13.42581 batch_time=0.66054 
Train Epoch: 16 [232/250 29696/32000 (93%)] Loss: 1.23388 (QuantReg: 13.67994) QuantErr: 13.67994 batch_time=0.65285 
Train Epoch: 16 [243/250 31104/32000 (97%)] Loss: 1.01353 (QuantReg: 13.98554) QuantErr: 13.98554 batch_time=0.67390 
Train Epoch: 16 codebook_update_time=2.11549
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_MSRVTT_1kA_roberta-large/checkpoint-epoch16.pth ...
Done in 11.401s
removing stale ckpt [epoch 15] [took 0.00s]
 epoch          : 16
 loss           : 1.2746519272327423
 quant_reg      : 13.647896846771241
 quant_err      : 13.647896846771241
 learning_rate  : 2.3164561507987653e-05
 n_samples      : 512000
 n_steps        : 4000
 MSRVTT_jsfusion_test/t2v_metrics/R1: 20.9
 MSRVTT_jsfusion_test/t2v_metrics/R5: 50.9
 MSRVTT_jsfusion_test/t2v_metrics/R10: 65.2
 MSRVTT_jsfusion_test/t2v_metrics/R50: 88.8
 MSRVTT_jsfusion_test/t2v_metrics/MedR: 5.0
 MSRVTT_jsfusion_test/t2v_metrics/MeanR: 27.484
 MSRVTT_jsfusion_test/t2v_metrics/geometric_mean_R1-R5-R10: 41.086948533970855
 MSRVTT_jsfusion_test/v2t_metrics/R1: 22.2
 MSRVTT_jsfusion_test/v2t_metrics/R5: 53.2
 MSRVTT_jsfusion_test/v2t_metrics/R10: 66.9
 MSRVTT_jsfusion_test/v2t_metrics/R50: 89.7
 MSRVTT_jsfusion_test/v2t_metrics/MedR: 5.0
 MSRVTT_jsfusion_test/v2t_metrics/MeanR: 24.999
 MSRVTT_jsfusion_test/v2t_metrics/geometric_mean_R1-R5-R10: 42.9104999809316
 mnt_best       : 42.468066253773664
 not_improved_count: 1
Train Epoch: 17 [1/250 128/32000 (0%)] Loss: 1.29019 (QuantReg: 13.29553) QuantErr: 13.29553 batch_time=36.11693 
Train Epoch: 17 [12/250 1536/32000 (5%)] Loss: 1.56983 (QuantReg: 13.00229) QuantErr: 13.00229 batch_time=0.65638 
Train Epoch: 17 [23/250 2944/32000 (9%)] Loss: 1.18550 (QuantReg: 13.47025) QuantErr: 13.47025 batch_time=0.67856 
Train Epoch: 17 [34/250 4352/32000 (14%)] Loss: 0.99505 (QuantReg: 13.87357) QuantErr: 13.87357 batch_time=0.67105 
Train Epoch: 17 [45/250 5760/32000 (18%)] Loss: 0.91065 (QuantReg: 14.27183) QuantErr: 14.27183 batch_time=0.65342 
Train Epoch: 17 [56/250 7168/32000 (22%)] Loss: 1.14647 (QuantReg: 13.59805) QuantErr: 13.59805 batch_time=0.68971 
Train Epoch: 17 [67/250 8576/32000 (27%)] Loss: 1.13913 (QuantReg: 13.84344) QuantErr: 13.84344 batch_time=0.70835 
Train Epoch: 17 [78/250 9984/32000 (31%)] Loss: 1.29135 (QuantReg: 13.57633) QuantErr: 13.57633 batch_time=0.65416 
Train Epoch: 17 [89/250 11392/32000 (36%)] Loss: 1.27988 (QuantReg: 13.62901) QuantErr: 13.62901 batch_time=0.64816 
Train Epoch: 17 [100/250 12800/32000 (40%)] Loss: 1.34959 (QuantReg: 13.47436) QuantErr: 13.47436 batch_time=0.66272 
Train Epoch: 17 [111/250 14208/32000 (44%)] Loss: 0.90952 (QuantReg: 13.74181) QuantErr: 13.74181 batch_time=0.68671 
Train Epoch: 17 [122/250 15616/32000 (49%)] Loss: 1.39867 (QuantReg: 13.71536) QuantErr: 13.71536 batch_time=0.65236 
Train Epoch: 17 [133/250 17024/32000 (53%)] Loss: 1.19679 (QuantReg: 13.77260) QuantErr: 13.77260 batch_time=0.65747 
Train Epoch: 17 [144/250 18432/32000 (58%)] Loss: 1.22952 (QuantReg: 13.83451) QuantErr: 13.83451 batch_time=1.07931 
Train Epoch: 17 [155/250 19840/32000 (62%)] Loss: 1.15993 (QuantReg: 13.69444) QuantErr: 13.69444 batch_time=0.68268 
Train Epoch: 17 [166/250 21248/32000 (66%)] Loss: 1.07945 (QuantReg: 14.00143) QuantErr: 14.00143 batch_time=0.68794 
Train Epoch: 17 [177/250 22656/32000 (71%)] Loss: 1.20569 (QuantReg: 14.01400) QuantErr: 14.01400 batch_time=0.67029 
Train Epoch: 17 [188/250 24064/32000 (75%)] Loss: 1.37695 (QuantReg: 13.53988) QuantErr: 13.53988 batch_time=0.89016 
Train Epoch: 17 [199/250 25472/32000 (80%)] Loss: 1.05551 (QuantReg: 13.68895) QuantErr: 13.68895 batch_time=0.66939 
Train Epoch: 17 [210/250 26880/32000 (84%)] Loss: 1.43975 (QuantReg: 13.42564) QuantErr: 13.42564 batch_time=0.65165 
Train Epoch: 17 [221/250 28288/32000 (88%)] Loss: 1.34255 (QuantReg: 13.85077) QuantErr: 13.85077 batch_time=0.64678 
Train Epoch: 17 [232/250 29696/32000 (93%)] Loss: 1.05969 (QuantReg: 13.32149) QuantErr: 13.32149 batch_time=0.66312 
Train Epoch: 17 [243/250 31104/32000 (97%)] Loss: 1.16113 (QuantReg: 13.97775) QuantErr: 13.97775 batch_time=0.68629 
Train Epoch: 17 codebook_update_time=2.18094
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_MSRVTT_1kA_roberta-large/checkpoint-epoch17.pth ...
Done in 10.614s
removing stale ckpt [epoch 16] [took 0.00s]
 epoch          : 17
 loss           : 1.247967843055725
 quant_reg      : 13.675139991760254
 quant_err      : 13.675139991760254
 learning_rate  : 2.2006333432588268e-05
 n_samples      : 544000
 n_steps        : 4250
 MSRVTT_jsfusion_test/t2v_metrics/R1: 22.5
 MSRVTT_jsfusion_test/t2v_metrics/R5: 51.6
 MSRVTT_jsfusion_test/t2v_metrics/R10: 65.6
 MSRVTT_jsfusion_test/t2v_metrics/R50: 89.3
 MSRVTT_jsfusion_test/t2v_metrics/MedR: 5.0
 MSRVTT_jsfusion_test/t2v_metrics/MeanR: 27.389
 MSRVTT_jsfusion_test/t2v_metrics/geometric_mean_R1-R5-R10: 42.38823691722827
 MSRVTT_jsfusion_test/v2t_metrics/R1: 24.1
 MSRVTT_jsfusion_test/v2t_metrics/R5: 53.1
 MSRVTT_jsfusion_test/v2t_metrics/R10: 67.0
 MSRVTT_jsfusion_test/v2t_metrics/R50: 89.9
 MSRVTT_jsfusion_test/v2t_metrics/MedR: 5.0
 MSRVTT_jsfusion_test/v2t_metrics/MeanR: 24.8245
 MSRVTT_jsfusion_test/v2t_metrics/geometric_mean_R1-R5-R10: 44.09562021692595
 mnt_best       : 42.468066253773664
 not_improved_count: 2
Train Epoch: 18 [1/250 128/32000 (0%)] Loss: 1.19796 (QuantReg: 13.76738) QuantErr: 13.76738 batch_time=33.15896 
Train Epoch: 18 [12/250 1536/32000 (5%)] Loss: 0.98049 (QuantReg: 13.53050) QuantErr: 13.53050 batch_time=1.35904 
Train Epoch: 18 [23/250 2944/32000 (9%)] Loss: 1.32969 (QuantReg: 13.70643) QuantErr: 13.70643 batch_time=0.64453 
Train Epoch: 18 [34/250 4352/32000 (14%)] Loss: 1.16818 (QuantReg: 13.51466) QuantErr: 13.51466 batch_time=0.67794 
Train Epoch: 18 [45/250 5760/32000 (18%)] Loss: 1.32005 (QuantReg: 13.45806) QuantErr: 13.45806 batch_time=0.66910 
Train Epoch: 18 [56/250 7168/32000 (22%)] Loss: 1.41074 (QuantReg: 13.51583) QuantErr: 13.51583 batch_time=0.65096 
Train Epoch: 18 [67/250 8576/32000 (27%)] Loss: 1.37208 (QuantReg: 13.64426) QuantErr: 13.64426 batch_time=0.68530 
Train Epoch: 18 [78/250 9984/32000 (31%)] Loss: 1.04197 (QuantReg: 13.66518) QuantErr: 13.66518 batch_time=1.17320 
Train Epoch: 18 [89/250 11392/32000 (36%)] Loss: 1.19714 (QuantReg: 13.73302) QuantErr: 13.73302 batch_time=0.68054 
Train Epoch: 18 [100/250 12800/32000 (40%)] Loss: 0.96007 (QuantReg: 13.90767) QuantErr: 13.90767 batch_time=0.69509 
Train Epoch: 18 [111/250 14208/32000 (44%)] Loss: 1.33743 (QuantReg: 13.36834) QuantErr: 13.36834 batch_time=0.65308 
Train Epoch: 18 [122/250 15616/32000 (49%)] Loss: 1.34110 (QuantReg: 13.78787) QuantErr: 13.78787 batch_time=0.68477 
Train Epoch: 18 [133/250 17024/32000 (53%)] Loss: 1.33801 (QuantReg: 13.89207) QuantErr: 13.89207 batch_time=0.68969 
Train Epoch: 18 [144/250 18432/32000 (58%)] Loss: 1.14135 (QuantReg: 13.91836) QuantErr: 13.91836 batch_time=0.68730 
Train Epoch: 18 [155/250 19840/32000 (62%)] Loss: 1.22587 (QuantReg: 14.01690) QuantErr: 14.01690 batch_time=0.67252 
Train Epoch: 18 [166/250 21248/32000 (66%)] Loss: 1.06972 (QuantReg: 13.68459) QuantErr: 13.68459 batch_time=0.65074 
Train Epoch: 18 [177/250 22656/32000 (71%)] Loss: 1.10694 (QuantReg: 13.83882) QuantErr: 13.83882 batch_time=0.65325 
Train Epoch: 18 [188/250 24064/32000 (75%)] Loss: 1.23145 (QuantReg: 14.00726) QuantErr: 14.00726 batch_time=0.67490 
Train Epoch: 18 [199/250 25472/32000 (80%)] Loss: 1.57568 (QuantReg: 13.60139) QuantErr: 13.60139 batch_time=0.69077 
Train Epoch: 18 [210/250 26880/32000 (84%)] Loss: 1.21628 (QuantReg: 13.64555) QuantErr: 13.64555 batch_time=0.70679 
Train Epoch: 18 [221/250 28288/32000 (88%)] Loss: 1.22297 (QuantReg: 13.87293) QuantErr: 13.87293 batch_time=0.68913 
Train Epoch: 18 [232/250 29696/32000 (93%)] Loss: 1.28264 (QuantReg: 13.88229) QuantErr: 13.88229 batch_time=0.68221 
Train Epoch: 18 [243/250 31104/32000 (97%)] Loss: 1.09777 (QuantReg: 13.93060) QuantErr: 13.93060 batch_time=7.50011 
Train Epoch: 18 codebook_update_time=1.75793
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_MSRVTT_1kA_roberta-large/checkpoint-epoch18.pth ...
Done in 16.249s
Updating 'best' checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_MSRVTT_1kA_roberta-large/checkpoint-epoch18.pth ...
Done in 36.586s
removing stale ckpt [epoch 17] [took 0.00s]
 epoch          : 18
 loss           : 1.203884889125824
 quant_reg      : 13.75698607635498
 quant_err      : 13.75698607635498
 learning_rate  : 2.0906016760958855e-05
 n_samples      : 576000
 n_steps        : 4500
 MSRVTT_jsfusion_test/t2v_metrics/R1: 22.8
 MSRVTT_jsfusion_test/t2v_metrics/R5: 51.9
 MSRVTT_jsfusion_test/t2v_metrics/R10: 65.9
 MSRVTT_jsfusion_test/t2v_metrics/R50: 89.5
 MSRVTT_jsfusion_test/t2v_metrics/MedR: 5.0
 MSRVTT_jsfusion_test/t2v_metrics/MeanR: 27.816
 MSRVTT_jsfusion_test/t2v_metrics/geometric_mean_R1-R5-R10: 42.723078566594005
 MSRVTT_jsfusion_test/v2t_metrics/R1: 23.6
 MSRVTT_jsfusion_test/v2t_metrics/R5: 55.0
 MSRVTT_jsfusion_test/v2t_metrics/R10: 66.7
 MSRVTT_jsfusion_test/v2t_metrics/R50: 89.4
 MSRVTT_jsfusion_test/v2t_metrics/MedR: 5.0
 MSRVTT_jsfusion_test/v2t_metrics/MeanR: 24.7745
 MSRVTT_jsfusion_test/v2t_metrics/geometric_mean_R1-R5-R10: 44.238477853772835
 mnt_best       : 42.723078566594005
 not_improved_count: 0
Train Epoch: 19 [1/250 128/32000 (0%)] Loss: 1.29127 (QuantReg: 13.63641) QuantErr: 13.63641 batch_time=35.59984 
Train Epoch: 19 [12/250 1536/32000 (5%)] Loss: 1.17277 (QuantReg: 13.93118) QuantErr: 13.93118 batch_time=0.69822 
Train Epoch: 19 [23/250 2944/32000 (9%)] Loss: 1.18842 (QuantReg: 13.41776) QuantErr: 13.41776 batch_time=0.67889 
Train Epoch: 19 [34/250 4352/32000 (14%)] Loss: 1.05049 (QuantReg: 13.72716) QuantErr: 13.72716 batch_time=0.70053 
Train Epoch: 19 [45/250 5760/32000 (18%)] Loss: 1.29279 (QuantReg: 13.52985) QuantErr: 13.52985 batch_time=0.66416 
Train Epoch: 19 [56/250 7168/32000 (22%)] Loss: 1.19952 (QuantReg: 13.71388) QuantErr: 13.71388 batch_time=0.65914 
Train Epoch: 19 [67/250 8576/32000 (27%)] Loss: 1.15272 (QuantReg: 13.77349) QuantErr: 13.77349 batch_time=0.65799 
Train Epoch: 19 [78/250 9984/32000 (31%)] Loss: 1.26895 (QuantReg: 13.56936) QuantErr: 13.56936 batch_time=0.67065 
Train Epoch: 19 [89/250 11392/32000 (36%)] Loss: 1.22203 (QuantReg: 13.69135) QuantErr: 13.69135 batch_time=1.07393 
Train Epoch: 19 [100/250 12800/32000 (40%)] Loss: 1.09232 (QuantReg: 13.99354) QuantErr: 13.99354 batch_time=0.68471 
Train Epoch: 19 [111/250 14208/32000 (44%)] Loss: 1.22061 (QuantReg: 13.57177) QuantErr: 13.57177 batch_time=0.68901 
Train Epoch: 19 [122/250 15616/32000 (49%)] Loss: 1.35759 (QuantReg: 13.78608) QuantErr: 13.78608 batch_time=0.66470 
Train Epoch: 19 [133/250 17024/32000 (53%)] Loss: 1.19114 (QuantReg: 13.88069) QuantErr: 13.88069 batch_time=0.66196 
Train Epoch: 19 [144/250 18432/32000 (58%)] Loss: 0.84830 (QuantReg: 13.94106) QuantErr: 13.94106 batch_time=0.66146 
Train Epoch: 19 [155/250 19840/32000 (62%)] Loss: 1.29406 (QuantReg: 13.36978) QuantErr: 13.36978 batch_time=0.68084 
Train Epoch: 19 [166/250 21248/32000 (66%)] Loss: 1.33083 (QuantReg: 13.84346) QuantErr: 13.84346 batch_time=0.66940 
Train Epoch: 19 [177/250 22656/32000 (71%)] Loss: 1.08222 (QuantReg: 13.97199) QuantErr: 13.97199 batch_time=0.70477 
Train Epoch: 19 [188/250 24064/32000 (75%)] Loss: 1.16710 (QuantReg: 13.65836) QuantErr: 13.65836 batch_time=0.68414 
Train Epoch: 19 [199/250 25472/32000 (80%)] Loss: 1.60177 (QuantReg: 13.70759) QuantErr: 13.70759 batch_time=0.66404 
Train Epoch: 19 [210/250 26880/32000 (84%)] Loss: 1.17913 (QuantReg: 13.75093) QuantErr: 13.75093 batch_time=0.65656 
Train Epoch: 19 [221/250 28288/32000 (88%)] Loss: 1.16391 (QuantReg: 13.81628) QuantErr: 13.81628 batch_time=0.73275 
Train Epoch: 19 [232/250 29696/32000 (93%)] Loss: 1.12977 (QuantReg: 14.05485) QuantErr: 14.05485 batch_time=0.66636 
Train Epoch: 19 [243/250 31104/32000 (97%)] Loss: 0.96297 (QuantReg: 14.21688) QuantErr: 14.21688 batch_time=1.03442 
Train Epoch: 19 codebook_update_time=1.81873
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_MSRVTT_1kA_roberta-large/checkpoint-epoch19.pth ...
Done in 12.302s
Updating 'best' checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_MSRVTT_1kA_roberta-large/checkpoint-epoch19.pth ...
Done in 23.375s
removing stale ckpt [epoch 18] [took 0.00s]
 epoch          : 19
 loss           : 1.1743763873577118
 quant_reg      : 13.763316757202148
 quant_err      : 13.763316757202148
 learning_rate  : 1.986071592291091e-05
 n_samples      : 608000
 n_steps        : 4750
 MSRVTT_jsfusion_test/t2v_metrics/R1: 23.3
 MSRVTT_jsfusion_test/t2v_metrics/R5: 51.4
 MSRVTT_jsfusion_test/t2v_metrics/R10: 66.1
 MSRVTT_jsfusion_test/t2v_metrics/R50: 87.5
 MSRVTT_jsfusion_test/t2v_metrics/MedR: 5.0
 MSRVTT_jsfusion_test/t2v_metrics/MeanR: 27.476
 MSRVTT_jsfusion_test/t2v_metrics/geometric_mean_R1-R5-R10: 42.937837346130266
 MSRVTT_jsfusion_test/v2t_metrics/R1: 24.0
 MSRVTT_jsfusion_test/v2t_metrics/R5: 55.5
 MSRVTT_jsfusion_test/v2t_metrics/R10: 67.5
 MSRVTT_jsfusion_test/v2t_metrics/R50: 88.9
 MSRVTT_jsfusion_test/v2t_metrics/MedR: 4.0
 MSRVTT_jsfusion_test/v2t_metrics/MeanR: 24.5545
 MSRVTT_jsfusion_test/v2t_metrics/geometric_mean_R1-R5-R10: 44.799104467643055
 mnt_best       : 42.937837346130266
 not_improved_count: 0
Train Epoch: 20 [1/250 128/32000 (0%)] Loss: 1.31328 (QuantReg: 13.34652) QuantErr: 13.34652 batch_time=31.32929 
Train Epoch: 20 [12/250 1536/32000 (5%)] Loss: 1.33937 (QuantReg: 13.79892) QuantErr: 13.79892 batch_time=0.67384 
Train Epoch: 20 [23/250 2944/32000 (9%)] Loss: 1.21300 (QuantReg: 13.48731) QuantErr: 13.48731 batch_time=0.68534 
Train Epoch: 20 [34/250 4352/32000 (14%)] Loss: 1.26854 (QuantReg: 13.60481) QuantErr: 13.60481 batch_time=0.64891 
Train Epoch: 20 [45/250 5760/32000 (18%)] Loss: 1.16450 (QuantReg: 13.74498) QuantErr: 13.74498 batch_time=0.66241 
Train Epoch: 20 [56/250 7168/32000 (22%)] Loss: 1.30663 (QuantReg: 13.66276) QuantErr: 13.66276 batch_time=0.66313 
Train Epoch: 20 [67/250 8576/32000 (27%)] Loss: 1.33219 (QuantReg: 13.68889) QuantErr: 13.68889 batch_time=1.86487 
Train Epoch: 20 [78/250 9984/32000 (31%)] Loss: 1.12785 (QuantReg: 13.81059) QuantErr: 13.81059 batch_time=0.65876 
Train Epoch: 20 [89/250 11392/32000 (36%)] Loss: 1.28420 (QuantReg: 13.77575) QuantErr: 13.77575 batch_time=0.66870 
Train Epoch: 20 [100/250 12800/32000 (40%)] Loss: 0.91253 (QuantReg: 13.94520) QuantErr: 13.94520 batch_time=0.65976 
Train Epoch: 20 [111/250 14208/32000 (44%)] Loss: 1.31915 (QuantReg: 13.90825) QuantErr: 13.90825 batch_time=0.69699 
Train Epoch: 20 [122/250 15616/32000 (49%)] Loss: 1.04634 (QuantReg: 13.98215) QuantErr: 13.98215 batch_time=0.66409 
Train Epoch: 20 [133/250 17024/32000 (53%)] Loss: 1.21977 (QuantReg: 13.50170) QuantErr: 13.50170 batch_time=0.66150 
Train Epoch: 20 [144/250 18432/32000 (58%)] Loss: 0.91818 (QuantReg: 14.05925) QuantErr: 14.05925 batch_time=0.68455 
Train Epoch: 20 [155/250 19840/32000 (62%)] Loss: 1.14565 (QuantReg: 13.87634) QuantErr: 13.87634 batch_time=0.69356 
Train Epoch: 20 [166/250 21248/32000 (66%)] Loss: 1.14162 (QuantReg: 14.02097) QuantErr: 14.02097 batch_time=0.69677 
Train Epoch: 20 [177/250 22656/32000 (71%)] Loss: 1.13514 (QuantReg: 13.95004) QuantErr: 13.95004 batch_time=0.67310 
Train Epoch: 20 [188/250 24064/32000 (75%)] Loss: 1.29653 (QuantReg: 14.03000) QuantErr: 14.03000 batch_time=0.68195 
Train Epoch: 20 [199/250 25472/32000 (80%)] Loss: 0.83240 (QuantReg: 13.66237) QuantErr: 13.66237 batch_time=0.68800 
Train Epoch: 20 [210/250 26880/32000 (84%)] Loss: 1.03100 (QuantReg: 13.99383) QuantErr: 13.99383 batch_time=0.68584 
Train Epoch: 20 [221/250 28288/32000 (88%)] Loss: 1.03653 (QuantReg: 13.85811) QuantErr: 13.85811 batch_time=0.66985 
Train Epoch: 20 [232/250 29696/32000 (93%)] Loss: 1.15814 (QuantReg: 13.79422) QuantErr: 13.79422 batch_time=0.94293 
Train Epoch: 20 [243/250 31104/32000 (97%)] Loss: 0.92371 (QuantReg: 13.69095) QuantErr: 13.69095 batch_time=0.70999 
Train Epoch: 20 codebook_update_time=2.05421
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_MSRVTT_1kA_roberta-large/checkpoint-epoch20.pth ...
Done in 10.494s
Updating 'best' checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_MSRVTT_1kA_roberta-large/checkpoint-epoch20.pth ...
Done in 21.452s
removing stale ckpt [epoch 19] [took 0.00s]
 epoch          : 20
 loss           : 1.1452600615024566
 quant_reg      : 13.826826736450196
 quant_err      : 13.826826736450196
 learning_rate  : 1.8867680126765363e-05
 n_samples      : 640000
 n_steps        : 5000
 MSRVTT_jsfusion_test/t2v_metrics/R1: 23.1
 MSRVTT_jsfusion_test/t2v_metrics/R5: 52.9
 MSRVTT_jsfusion_test/t2v_metrics/R10: 66.8
 MSRVTT_jsfusion_test/t2v_metrics/R50: 88.0
 MSRVTT_jsfusion_test/t2v_metrics/MedR: 5.0
 MSRVTT_jsfusion_test/t2v_metrics/MeanR: 27.496
 MSRVTT_jsfusion_test/t2v_metrics/geometric_mean_R1-R5-R10: 43.37918331756513
 MSRVTT_jsfusion_test/v2t_metrics/R1: 25.3
 MSRVTT_jsfusion_test/v2t_metrics/R5: 55.3
 MSRVTT_jsfusion_test/v2t_metrics/R10: 68.3
 MSRVTT_jsfusion_test/v2t_metrics/R50: 88.1
 MSRVTT_jsfusion_test/v2t_metrics/MedR: 4.0
 MSRVTT_jsfusion_test/v2t_metrics/MeanR: 25.339
 MSRVTT_jsfusion_test/v2t_metrics/geometric_mean_R1-R5-R10: 45.718164440702125
 mnt_best       : 43.37918331756513
 not_improved_count: 0
Train Epoch: 21 [1/250 128/32000 (0%)] Loss: 1.02744 (QuantReg: 13.67866) QuantErr: 13.67866 batch_time=28.42707 
Train Epoch: 21 [12/250 1536/32000 (5%)] Loss: 1.07364 (QuantReg: 13.74088) QuantErr: 13.74088 batch_time=0.71373 
Train Epoch: 21 [23/250 2944/32000 (9%)] Loss: 1.02056 (QuantReg: 13.76884) QuantErr: 13.76884 batch_time=0.65962 
Train Epoch: 21 [34/250 4352/32000 (14%)] Loss: 1.05611 (QuantReg: 13.88832) QuantErr: 13.88832 batch_time=0.67903 
Train Epoch: 21 [45/250 5760/32000 (18%)] Loss: 1.16368 (QuantReg: 14.11381) QuantErr: 14.11381 batch_time=0.69958 
Train Epoch: 21 [56/250 7168/32000 (22%)] Loss: 1.19364 (QuantReg: 13.74384) QuantErr: 13.74384 batch_time=0.66226 
Train Epoch: 21 [67/250 8576/32000 (27%)] Loss: 1.35243 (QuantReg: 13.26445) QuantErr: 13.26445 batch_time=0.67367 
Train Epoch: 21 [78/250 9984/32000 (31%)] Loss: 0.99665 (QuantReg: 14.01867) QuantErr: 14.01867 batch_time=0.78519 
Train Epoch: 21 [89/250 11392/32000 (36%)] Loss: 0.99792 (QuantReg: 13.70526) QuantErr: 13.70526 batch_time=0.66888 
Train Epoch: 21 [100/250 12800/32000 (40%)] Loss: 1.09114 (QuantReg: 13.59929) QuantErr: 13.59929 batch_time=0.65077 
Train Epoch: 21 [111/250 14208/32000 (44%)] Loss: 0.96420 (QuantReg: 13.86592) QuantErr: 13.86592 batch_time=0.66199 
Train Epoch: 21 [122/250 15616/32000 (49%)] Loss: 1.22269 (QuantReg: 13.75176) QuantErr: 13.75176 batch_time=0.65936 
Train Epoch: 21 [133/250 17024/32000 (53%)] Loss: 1.17458 (QuantReg: 13.84188) QuantErr: 13.84188 batch_time=0.81130 
Train Epoch: 21 [144/250 18432/32000 (58%)] Loss: 0.96591 (QuantReg: 14.17877) QuantErr: 14.17877 batch_time=1.01041 
Train Epoch: 21 [155/250 19840/32000 (62%)] Loss: 1.06605 (QuantReg: 13.95417) QuantErr: 13.95417 batch_time=0.66319 
Train Epoch: 21 [166/250 21248/32000 (66%)] Loss: 0.93702 (QuantReg: 13.80334) QuantErr: 13.80334 batch_time=0.69070 
Train Epoch: 21 [177/250 22656/32000 (71%)] Loss: 0.97613 (QuantReg: 13.79123) QuantErr: 13.79123 batch_time=0.72302 
Train Epoch: 21 [188/250 24064/32000 (75%)] Loss: 0.99050 (QuantReg: 13.71488) QuantErr: 13.71488 batch_time=0.67595 
Train Epoch: 21 [199/250 25472/32000 (80%)] Loss: 0.86173 (QuantReg: 14.17552) QuantErr: 14.17552 batch_time=0.68196 
Train Epoch: 21 [210/250 26880/32000 (84%)] Loss: 1.09358 (QuantReg: 13.87857) QuantErr: 13.87857 batch_time=0.68514 
Train Epoch: 21 [221/250 28288/32000 (88%)] Loss: 0.91127 (QuantReg: 13.76220) QuantErr: 13.76220 batch_time=0.66752 
Train Epoch: 21 [232/250 29696/32000 (93%)] Loss: 0.95139 (QuantReg: 13.88670) QuantErr: 13.88670 batch_time=0.67226 
Train Epoch: 21 [243/250 31104/32000 (97%)] Loss: 1.22054 (QuantReg: 13.78623) QuantErr: 13.78623 batch_time=0.68932 
Train Epoch: 21 codebook_update_time=1.98693
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_MSRVTT_1kA_roberta-large/checkpoint-epoch21.pth ...
Done in 11.603s
Updating 'best' checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_MSRVTT_1kA_roberta-large/checkpoint-epoch21.pth ...
Done in 22.492s
removing stale ckpt [epoch 20] [took 0.00s]
 epoch          : 21
 loss           : 1.0969411823749542
 quant_reg      : 13.851221126556396
 quant_err      : 13.851221126556396
 learning_rate  : 1.7924296120427095e-05
 n_samples      : 672000
 n_steps        : 5250
 MSRVTT_jsfusion_test/t2v_metrics/R1: 22.9
 MSRVTT_jsfusion_test/t2v_metrics/R5: 53.9
 MSRVTT_jsfusion_test/t2v_metrics/R10: 67.1
 MSRVTT_jsfusion_test/t2v_metrics/R50: 89.4
 MSRVTT_jsfusion_test/t2v_metrics/MedR: 5.0
 MSRVTT_jsfusion_test/t2v_metrics/MeanR: 26.531
 MSRVTT_jsfusion_test/t2v_metrics/geometric_mean_R1-R5-R10: 43.58953698514737
 MSRVTT_jsfusion_test/v2t_metrics/R1: 24.7
 MSRVTT_jsfusion_test/v2t_metrics/R5: 55.7
 MSRVTT_jsfusion_test/v2t_metrics/R10: 68.7
 MSRVTT_jsfusion_test/v2t_metrics/R50: 89.0
 MSRVTT_jsfusion_test/v2t_metrics/MedR: 4.0
 MSRVTT_jsfusion_test/v2t_metrics/MeanR: 24.7115
 MSRVTT_jsfusion_test/v2t_metrics/geometric_mean_R1-R5-R10: 45.55152927092534
 mnt_best       : 43.58953698514737
 not_improved_count: 0
Train Epoch: 22 [1/250 128/32000 (0%)] Loss: 0.89250 (QuantReg: 13.74656) QuantErr: 13.74656 batch_time=30.15432 
Train Epoch: 22 [12/250 1536/32000 (5%)] Loss: 0.89003 (QuantReg: 13.83047) QuantErr: 13.83047 batch_time=0.66495 
Train Epoch: 22 [23/250 2944/32000 (9%)] Loss: 1.18628 (QuantReg: 13.77190) QuantErr: 13.77190 batch_time=1.22880 
Train Epoch: 22 [34/250 4352/32000 (14%)] Loss: 0.93438 (QuantReg: 14.01107) QuantErr: 14.01107 batch_time=0.65418 
Train Epoch: 22 [45/250 5760/32000 (18%)] Loss: 1.15195 (QuantReg: 13.73535) QuantErr: 13.73535 batch_time=0.66446 
Train Epoch: 22 [56/250 7168/32000 (22%)] Loss: 1.08065 (QuantReg: 13.68594) QuantErr: 13.68594 batch_time=0.70075 
Train Epoch: 22 [67/250 8576/32000 (27%)] Loss: 1.11004 (QuantReg: 13.65703) QuantErr: 13.65703 batch_time=0.68105 
Train Epoch: 22 [78/250 9984/32000 (31%)] Loss: 0.88757 (QuantReg: 13.97250) QuantErr: 13.97250 batch_time=0.69867 
Train Epoch: 22 [89/250 11392/32000 (36%)] Loss: 1.18608 (QuantReg: 13.61403) QuantErr: 13.61403 batch_time=0.69240 
Train Epoch: 22 [100/250 12800/32000 (40%)] Loss: 0.95958 (QuantReg: 14.14425) QuantErr: 14.14425 batch_time=0.67985 
Train Epoch: 22 [111/250 14208/32000 (44%)] Loss: 1.23585 (QuantReg: 13.50153) QuantErr: 13.50153 batch_time=0.67943 
Train Epoch: 22 [122/250 15616/32000 (49%)] Loss: 0.96639 (QuantReg: 14.06411) QuantErr: 14.06411 batch_time=0.66777 
Train Epoch: 22 [133/250 17024/32000 (53%)] Loss: 1.29419 (QuantReg: 13.65193) QuantErr: 13.65193 batch_time=0.65358 
Train Epoch: 22 [144/250 18432/32000 (58%)] Loss: 1.18180 (QuantReg: 13.63927) QuantErr: 13.63927 batch_time=0.66202 
Train Epoch: 22 [155/250 19840/32000 (62%)] Loss: 1.19000 (QuantReg: 13.97636) QuantErr: 13.97636 batch_time=0.68414 
Train Epoch: 22 [166/250 21248/32000 (66%)] Loss: 1.25695 (QuantReg: 14.19370) QuantErr: 14.19370 batch_time=0.66914 
Train Epoch: 22 [177/250 22656/32000 (71%)] Loss: 1.15584 (QuantReg: 14.09018) QuantErr: 14.09018 batch_time=0.66409 
Train Epoch: 22 [188/250 24064/32000 (75%)] Loss: 1.27328 (QuantReg: 14.06041) QuantErr: 14.06041 batch_time=0.65869 
Train Epoch: 22 [199/250 25472/32000 (80%)] Loss: 0.98558 (QuantReg: 13.74975) QuantErr: 13.74975 batch_time=0.69008 
Train Epoch: 22 [210/250 26880/32000 (84%)] Loss: 0.87477 (QuantReg: 13.66751) QuantErr: 13.66751 batch_time=0.67890 
Train Epoch: 22 [221/250 28288/32000 (88%)] Loss: 1.01602 (QuantReg: 13.95813) QuantErr: 13.95813 batch_time=0.66905 
Train Epoch: 22 [232/250 29696/32000 (93%)] Loss: 1.16392 (QuantReg: 14.16593) QuantErr: 14.16593 batch_time=0.73385 
Train Epoch: 22 [243/250 31104/32000 (97%)] Loss: 1.09903 (QuantReg: 13.51951) QuantErr: 13.51951 batch_time=0.66783 
Train Epoch: 22 codebook_update_time=1.85742
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_MSRVTT_1kA_roberta-large/checkpoint-epoch22.pth ...
Done in 18.628s
Updating 'best' checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_MSRVTT_1kA_roberta-large/checkpoint-epoch22.pth ...
Done in 30.088s
removing stale ckpt [epoch 21] [took 0.00s]
 epoch          : 22
 loss           : 1.0696321082115174
 quant_reg      : 13.88100360107422
 quant_err      : 13.88100360107422
 learning_rate  : 1.702808131440574e-05
 n_samples      : 704000
 n_steps        : 5500
 MSRVTT_jsfusion_test/t2v_metrics/R1: 23.9
 MSRVTT_jsfusion_test/t2v_metrics/R5: 53.4
 MSRVTT_jsfusion_test/t2v_metrics/R10: 68.0
 MSRVTT_jsfusion_test/t2v_metrics/R50: 88.7
 MSRVTT_jsfusion_test/t2v_metrics/MedR: 5.0
 MSRVTT_jsfusion_test/t2v_metrics/MeanR: 26.509
 MSRVTT_jsfusion_test/t2v_metrics/geometric_mean_R1-R5-R10: 44.27406077594835
 MSRVTT_jsfusion_test/v2t_metrics/R1: 26.1
 MSRVTT_jsfusion_test/v2t_metrics/R5: 56.8
 MSRVTT_jsfusion_test/v2t_metrics/R10: 69.4
 MSRVTT_jsfusion_test/v2t_metrics/R50: 88.5
 MSRVTT_jsfusion_test/v2t_metrics/MedR: 4.0
 MSRVTT_jsfusion_test/v2t_metrics/MeanR: 25.0455
 MSRVTT_jsfusion_test/v2t_metrics/geometric_mean_R1-R5-R10: 46.85789460140649
 mnt_best       : 44.27406077594835
 not_improved_count: 0
Train Epoch: 23 [1/250 128/32000 (0%)] Loss: 0.97671 (QuantReg: 14.00731) QuantErr: 14.00731 batch_time=29.91805 
Train Epoch: 23 [12/250 1536/32000 (5%)] Loss: 0.92621 (QuantReg: 13.79410) QuantErr: 13.79410 batch_time=0.65214 
Train Epoch: 23 [23/250 2944/32000 (9%)] Loss: 1.23130 (QuantReg: 13.75466) QuantErr: 13.75466 batch_time=0.65468 
Train Epoch: 23 [34/250 4352/32000 (14%)] Loss: 0.88593 (QuantReg: 13.73959) QuantErr: 13.73959 batch_time=0.66389 
Train Epoch: 23 [45/250 5760/32000 (18%)] Loss: 1.07225 (QuantReg: 13.85489) QuantErr: 13.85489 batch_time=0.65541 
Train Epoch: 23 [56/250 7168/32000 (22%)] Loss: 0.71827 (QuantReg: 13.97443) QuantErr: 13.97443 batch_time=0.65052 
Train Epoch: 23 [67/250 8576/32000 (27%)] Loss: 0.95745 (QuantReg: 14.18136) QuantErr: 14.18136 batch_time=0.66475 
Train Epoch: 23 [78/250 9984/32000 (31%)] Loss: 0.96318 (QuantReg: 13.75861) QuantErr: 13.75861 batch_time=1.45700 
Train Epoch: 23 [89/250 11392/32000 (36%)] Loss: 1.06372 (QuantReg: 13.57549) QuantErr: 13.57549 batch_time=0.73700 
Train Epoch: 23 [100/250 12800/32000 (40%)] Loss: 1.12661 (QuantReg: 13.84743) QuantErr: 13.84743 batch_time=0.65769 
Train Epoch: 23 [111/250 14208/32000 (44%)] Loss: 0.83113 (QuantReg: 14.15593) QuantErr: 14.15593 batch_time=0.68540 
Train Epoch: 23 [122/250 15616/32000 (49%)] Loss: 1.01022 (QuantReg: 13.98009) QuantErr: 13.98009 batch_time=0.67139 
Train Epoch: 23 [133/250 17024/32000 (53%)] Loss: 0.87664 (QuantReg: 14.12524) QuantErr: 14.12524 batch_time=0.69395 
Train Epoch: 23 [144/250 18432/32000 (58%)] Loss: 0.90579 (QuantReg: 13.85744) QuantErr: 13.85744 batch_time=0.88035 
Train Epoch: 23 [155/250 19840/32000 (62%)] Loss: 0.94225 (QuantReg: 13.90262) QuantErr: 13.90262 batch_time=0.65724 
Train Epoch: 23 [166/250 21248/32000 (66%)] Loss: 1.11182 (QuantReg: 13.64226) QuantErr: 13.64226 batch_time=0.65666 
Train Epoch: 23 [177/250 22656/32000 (71%)] Loss: 1.15096 (QuantReg: 13.97831) QuantErr: 13.97831 batch_time=0.66190 
Train Epoch: 23 [188/250 24064/32000 (75%)] Loss: 1.02769 (QuantReg: 13.79998) QuantErr: 13.79998 batch_time=0.77518 
Train Epoch: 23 [199/250 25472/32000 (80%)] Loss: 1.11523 (QuantReg: 13.62399) QuantErr: 13.62399 batch_time=0.70931 
Train Epoch: 23 [210/250 26880/32000 (84%)] Loss: 0.94940 (QuantReg: 13.87737) QuantErr: 13.87737 batch_time=0.66326 
Train Epoch: 23 [221/250 28288/32000 (88%)] Loss: 1.20465 (QuantReg: 14.03246) QuantErr: 14.03246 batch_time=3.39751 
Train Epoch: 23 [232/250 29696/32000 (93%)] Loss: 0.80851 (QuantReg: 14.30308) QuantErr: 14.30308 batch_time=0.65719 
Train Epoch: 23 [243/250 31104/32000 (97%)] Loss: 0.83456 (QuantReg: 14.06028) QuantErr: 14.06028 batch_time=0.68757 
Train Epoch: 23 codebook_update_time=1.74964
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_MSRVTT_1kA_roberta-large/checkpoint-epoch23.pth ...
Done in 25.963s
removing stale ckpt [epoch 22] [took 0.00s]
 epoch          : 23
 loss           : 1.0398150165081024
 quant_reg      : 13.896237701416016
 quant_err      : 13.896237701416016
 learning_rate  : 1.6176677248685452e-05
 n_samples      : 736000
 n_steps        : 5750
 MSRVTT_jsfusion_test/t2v_metrics/R1: 23.7
 MSRVTT_jsfusion_test/t2v_metrics/R5: 52.4
 MSRVTT_jsfusion_test/t2v_metrics/R10: 67.8
 MSRVTT_jsfusion_test/t2v_metrics/R50: 89.3
 MSRVTT_jsfusion_test/t2v_metrics/MedR: 5.0
 MSRVTT_jsfusion_test/t2v_metrics/MeanR: 28.14
 MSRVTT_jsfusion_test/t2v_metrics/geometric_mean_R1-R5-R10: 43.82982893363032
 MSRVTT_jsfusion_test/v2t_metrics/R1: 23.9
 MSRVTT_jsfusion_test/v2t_metrics/R5: 57.3
 MSRVTT_jsfusion_test/v2t_metrics/R10: 69.2
 MSRVTT_jsfusion_test/v2t_metrics/R50: 89.6
 MSRVTT_jsfusion_test/v2t_metrics/MedR: 4.0
 MSRVTT_jsfusion_test/v2t_metrics/MeanR: 25.865
 MSRVTT_jsfusion_test/v2t_metrics/geometric_mean_R1-R5-R10: 45.59174404242338
 mnt_best       : 44.27406077594835
 not_improved_count: 1
Train Epoch: 24 [1/250 128/32000 (0%)] Loss: 0.92285 (QuantReg: 14.09380) QuantErr: 14.09380 batch_time=32.63611 
Train Epoch: 24 [12/250 1536/32000 (5%)] Loss: 1.14270 (QuantReg: 14.03133) QuantErr: 14.03133 batch_time=0.66277 
Train Epoch: 24 [23/250 2944/32000 (9%)] Loss: 1.00347 (QuantReg: 13.92187) QuantErr: 13.92187 batch_time=0.65553 
Train Epoch: 24 [34/250 4352/32000 (14%)] Loss: 0.86347 (QuantReg: 14.14756) QuantErr: 14.14756 batch_time=0.71319 
Train Epoch: 24 [45/250 5760/32000 (18%)] Loss: 1.05900 (QuantReg: 13.84169) QuantErr: 13.84169 batch_time=0.67229 
Train Epoch: 24 [56/250 7168/32000 (22%)] Loss: 1.02516 (QuantReg: 13.74204) QuantErr: 13.74204 batch_time=0.69100 
Train Epoch: 24 [67/250 8576/32000 (27%)] Loss: 1.02543 (QuantReg: 13.83784) QuantErr: 13.83784 batch_time=0.63826 
Train Epoch: 24 [78/250 9984/32000 (31%)] Loss: 0.94850 (QuantReg: 13.86092) QuantErr: 13.86092 batch_time=0.66484 
Train Epoch: 24 [89/250 11392/32000 (36%)] Loss: 1.09329 (QuantReg: 14.06110) QuantErr: 14.06110 batch_time=0.66373 
Train Epoch: 24 [100/250 12800/32000 (40%)] Loss: 1.11571 (QuantReg: 14.10345) QuantErr: 14.10345 batch_time=0.64867 
Train Epoch: 24 [111/250 14208/32000 (44%)] Loss: 1.00271 (QuantReg: 13.74759) QuantErr: 13.74759 batch_time=0.64771 
Train Epoch: 24 [122/250 15616/32000 (49%)] Loss: 0.91738 (QuantReg: 13.94205) QuantErr: 13.94205 batch_time=0.64483 
Train Epoch: 24 [133/250 17024/32000 (53%)] Loss: 0.85542 (QuantReg: 14.05935) QuantErr: 14.05935 batch_time=0.66766 
Train Epoch: 24 [144/250 18432/32000 (58%)] Loss: 0.86405 (QuantReg: 13.62976) QuantErr: 13.62976 batch_time=3.84753 
Train Epoch: 24 [155/250 19840/32000 (62%)] Loss: 1.03273 (QuantReg: 13.98251) QuantErr: 13.98251 batch_time=0.67031 
Train Epoch: 24 [166/250 21248/32000 (66%)] Loss: 1.15753 (QuantReg: 13.87818) QuantErr: 13.87818 batch_time=0.67079 
Train Epoch: 24 [177/250 22656/32000 (71%)] Loss: 1.00328 (QuantReg: 14.05531) QuantErr: 14.05531 batch_time=0.65839 
Train Epoch: 24 [188/250 24064/32000 (75%)] Loss: 0.89516 (QuantReg: 14.22423) QuantErr: 14.22423 batch_time=0.66506 
Train Epoch: 24 [199/250 25472/32000 (80%)] Loss: 0.90015 (QuantReg: 14.15704) QuantErr: 14.15704 batch_time=0.77097 
Train Epoch: 24 [210/250 26880/32000 (84%)] Loss: 0.90281 (QuantReg: 14.08467) QuantErr: 14.08467 batch_time=0.64324 
Train Epoch: 24 [221/250 28288/32000 (88%)] Loss: 1.25693 (QuantReg: 13.93869) QuantErr: 13.93869 batch_time=0.67777 
Train Epoch: 24 [232/250 29696/32000 (93%)] Loss: 0.90198 (QuantReg: 13.87079) QuantErr: 13.87079 batch_time=0.66593 
Train Epoch: 24 [243/250 31104/32000 (97%)] Loss: 0.89731 (QuantReg: 13.87903) QuantErr: 13.87903 batch_time=0.65412 
Train Epoch: 24 codebook_update_time=2.00778
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_MSRVTT_1kA_roberta-large/checkpoint-epoch24.pth ...
Done in 11.366s
removing stale ckpt [epoch 23] [took 0.06s]
 epoch          : 24
 loss           : 0.9993469364643097
 quant_reg      : 13.960660400390625
 quant_err      : 13.960660400390625
 learning_rate  : 1.5367843386251178e-05
 n_samples      : 768000
 n_steps        : 6000
 MSRVTT_jsfusion_test/t2v_metrics/R1: 23.7
 MSRVTT_jsfusion_test/t2v_metrics/R5: 53.6
 MSRVTT_jsfusion_test/t2v_metrics/R10: 68.0
 MSRVTT_jsfusion_test/t2v_metrics/R50: 89.5
 MSRVTT_jsfusion_test/t2v_metrics/MedR: 5.0
 MSRVTT_jsfusion_test/t2v_metrics/MeanR: 27.248
 MSRVTT_jsfusion_test/t2v_metrics/geometric_mean_R1-R5-R10: 44.20526680480738
 MSRVTT_jsfusion_test/v2t_metrics/R1: 25.4
 MSRVTT_jsfusion_test/v2t_metrics/R5: 56.1
 MSRVTT_jsfusion_test/v2t_metrics/R10: 68.7
 MSRVTT_jsfusion_test/v2t_metrics/R50: 88.8
 MSRVTT_jsfusion_test/v2t_metrics/MedR: 4.0
 MSRVTT_jsfusion_test/v2t_metrics/MeanR: 25.807
 MSRVTT_jsfusion_test/v2t_metrics/geometric_mean_R1-R5-R10: 46.08763665118645
 mnt_best       : 44.27406077594835
 not_improved_count: 2
Train Epoch: 25 [1/250 128/32000 (0%)] Loss: 1.32351 (QuantReg: 13.78414) QuantErr: 13.78414 batch_time=32.88682 
Train Epoch: 25 [12/250 1536/32000 (5%)] Loss: 0.89074 (QuantReg: 13.93126) QuantErr: 13.93126 batch_time=0.66281 
Train Epoch: 25 [23/250 2944/32000 (9%)] Loss: 1.24532 (QuantReg: 13.85909) QuantErr: 13.85909 batch_time=0.70720 
Train Epoch: 25 [34/250 4352/32000 (14%)] Loss: 1.07214 (QuantReg: 13.98539) QuantErr: 13.98539 batch_time=0.72167 
Train Epoch: 25 [45/250 5760/32000 (18%)] Loss: 0.88030 (QuantReg: 14.17567) QuantErr: 14.17567 batch_time=0.79487 
Train Epoch: 25 [56/250 7168/32000 (22%)] Loss: 1.08791 (QuantReg: 14.07328) QuantErr: 14.07328 batch_time=0.68558 
Train Epoch: 25 [67/250 8576/32000 (27%)] Loss: 1.16704 (QuantReg: 14.04725) QuantErr: 14.04725 batch_time=0.67212 
Train Epoch: 25 [78/250 9984/32000 (31%)] Loss: 0.96661 (QuantReg: 13.87840) QuantErr: 13.87840 batch_time=0.65025 
Train Epoch: 25 [89/250 11392/32000 (36%)] Loss: 0.88617 (QuantReg: 13.97405) QuantErr: 13.97405 batch_time=0.69878 
Train Epoch: 25 [100/250 12800/32000 (40%)] Loss: 1.35636 (QuantReg: 13.79005) QuantErr: 13.79005 batch_time=0.66303 
Train Epoch: 25 [111/250 14208/32000 (44%)] Loss: 0.89153 (QuantReg: 13.70625) QuantErr: 13.70625 batch_time=0.67139 
Train Epoch: 25 [122/250 15616/32000 (49%)] Loss: 0.81871 (QuantReg: 14.02985) QuantErr: 14.02985 batch_time=0.72693 
Train Epoch: 25 [133/250 17024/32000 (53%)] Loss: 0.74283 (QuantReg: 14.22831) QuantErr: 14.22831 batch_time=0.64896 
Train Epoch: 25 [144/250 18432/32000 (58%)] Loss: 1.14157 (QuantReg: 13.97645) QuantErr: 13.97645 batch_time=0.64197 
Train Epoch: 25 [155/250 19840/32000 (62%)] Loss: 1.16880 (QuantReg: 13.59753) QuantErr: 13.59753 batch_time=1.81776 
Train Epoch: 25 [166/250 21248/32000 (66%)] Loss: 0.87125 (QuantReg: 13.88964) QuantErr: 13.88964 batch_time=0.65658 
Train Epoch: 25 [177/250 22656/32000 (71%)] Loss: 1.08788 (QuantReg: 13.63311) QuantErr: 13.63311 batch_time=0.68247 
Train Epoch: 25 [188/250 24064/32000 (75%)] Loss: 0.79736 (QuantReg: 14.18633) QuantErr: 14.18633 batch_time=0.68929 
Train Epoch: 25 [199/250 25472/32000 (80%)] Loss: 1.12730 (QuantReg: 13.82169) QuantErr: 13.82169 batch_time=0.68479 
Train Epoch: 25 [210/250 26880/32000 (84%)] Loss: 0.72501 (QuantReg: 14.25133) QuantErr: 14.25133 batch_time=0.67632 
Train Epoch: 25 [221/250 28288/32000 (88%)] Loss: 0.71195 (QuantReg: 13.74839) QuantErr: 13.74839 batch_time=0.72333 
Train Epoch: 25 [232/250 29696/32000 (93%)] Loss: 0.99194 (QuantReg: 14.30564) QuantErr: 14.30564 batch_time=0.75464 
Train Epoch: 25 [243/250 31104/32000 (97%)] Loss: 1.00736 (QuantReg: 14.12765) QuantErr: 14.12765 batch_time=0.69145 
Train Epoch: 25 codebook_update_time=1.90868
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_MSRVTT_1kA_roberta-large/checkpoint-epoch25.pth ...
Done in 10.381s
Updating 'best' checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_MSRVTT_1kA_roberta-large/checkpoint-epoch25.pth ...
Done in 21.075s
removing stale ckpt [epoch 24] [took 0.00s]
 epoch          : 25
 loss           : 0.9941364810466766
 quant_reg      : 13.970161254882813
 quant_err      : 13.970161254882813
 learning_rate  : 1.4599451216938618e-05
 n_samples      : 800000
 n_steps        : 6250
 MSRVTT_jsfusion_test/t2v_metrics/R1: 24.0
 MSRVTT_jsfusion_test/t2v_metrics/R5: 54.1
 MSRVTT_jsfusion_test/t2v_metrics/R10: 66.9
 MSRVTT_jsfusion_test/t2v_metrics/R50: 89.3
 MSRVTT_jsfusion_test/t2v_metrics/MedR: 5.0
 MSRVTT_jsfusion_test/t2v_metrics/MeanR: 27.434
 MSRVTT_jsfusion_test/t2v_metrics/geometric_mean_R1-R5-R10: 44.287198443893125
 MSRVTT_jsfusion_test/v2t_metrics/R1: 25.3
 MSRVTT_jsfusion_test/v2t_metrics/R5: 56.3
 MSRVTT_jsfusion_test/v2t_metrics/R10: 70.2
 MSRVTT_jsfusion_test/v2t_metrics/R50: 89.6
 MSRVTT_jsfusion_test/v2t_metrics/MedR: 4.0
 MSRVTT_jsfusion_test/v2t_metrics/MeanR: 25.6745
 MSRVTT_jsfusion_test/v2t_metrics/geometric_mean_R1-R5-R10: 46.41467808764348
 mnt_best       : 44.287198443893125
 not_improved_count: 0
Train Epoch: 26 [1/250 128/32000 (0%)] Loss: 0.90561 (QuantReg: 13.73624) QuantErr: 13.73624 batch_time=30.46802 
Train Epoch: 26 [12/250 1536/32000 (5%)] Loss: 1.09691 (QuantReg: 14.14676) QuantErr: 14.14676 batch_time=0.71825 
Train Epoch: 26 [23/250 2944/32000 (9%)] Loss: 0.95725 (QuantReg: 14.04993) QuantErr: 14.04993 batch_time=0.72592 
Train Epoch: 26 [34/250 4352/32000 (14%)] Loss: 1.03718 (QuantReg: 13.97055) QuantErr: 13.97055 batch_time=0.66098 
Train Epoch: 26 [45/250 5760/32000 (18%)] Loss: 1.45676 (QuantReg: 13.69202) QuantErr: 13.69202 batch_time=0.66762 
Train Epoch: 26 [56/250 7168/32000 (22%)] Loss: 1.24879 (QuantReg: 13.84433) QuantErr: 13.84433 batch_time=0.70028 
Train Epoch: 26 [67/250 8576/32000 (27%)] Loss: 0.80695 (QuantReg: 14.05637) QuantErr: 14.05637 batch_time=0.83520 
Train Epoch: 26 [78/250 9984/32000 (31%)] Loss: 1.22419 (QuantReg: 14.04165) QuantErr: 14.04165 batch_time=0.66963 
Train Epoch: 26 [89/250 11392/32000 (36%)] Loss: 1.12865 (QuantReg: 13.77519) QuantErr: 13.77519 batch_time=0.66644 
Train Epoch: 26 [100/250 12800/32000 (40%)] Loss: 1.17023 (QuantReg: 13.88300) QuantErr: 13.88300 batch_time=0.66615 
Train Epoch: 26 [111/250 14208/32000 (44%)] Loss: 1.00711 (QuantReg: 13.77893) QuantErr: 13.77893 batch_time=0.66475 
Train Epoch: 26 [122/250 15616/32000 (49%)] Loss: 0.98950 (QuantReg: 14.35668) QuantErr: 14.35668 batch_time=0.67843 
Train Epoch: 26 [133/250 17024/32000 (53%)] Loss: 0.91683 (QuantReg: 13.99312) QuantErr: 13.99312 batch_time=0.67759 
Train Epoch: 26 [144/250 18432/32000 (58%)] Loss: 1.31058 (QuantReg: 13.77097) QuantErr: 13.77097 batch_time=0.66615 
Train Epoch: 26 [155/250 19840/32000 (62%)] Loss: 0.88301 (QuantReg: 13.99053) QuantErr: 13.99053 batch_time=0.72902 
Train Epoch: 26 [166/250 21248/32000 (66%)] Loss: 1.01418 (QuantReg: 13.79308) QuantErr: 13.79308 batch_time=0.68224 
Train Epoch: 26 [177/250 22656/32000 (71%)] Loss: 0.95979 (QuantReg: 13.64507) QuantErr: 13.64507 batch_time=1.63856 
Train Epoch: 26 [188/250 24064/32000 (75%)] Loss: 1.37859 (QuantReg: 13.68071) QuantErr: 13.68071 batch_time=0.66011 
Train Epoch: 26 [199/250 25472/32000 (80%)] Loss: 0.99159 (QuantReg: 14.04123) QuantErr: 14.04123 batch_time=0.64928 
Train Epoch: 26 [210/250 26880/32000 (84%)] Loss: 1.02154 (QuantReg: 14.17505) QuantErr: 14.17505 batch_time=0.65820 
Train Epoch: 26 [221/250 28288/32000 (88%)] Loss: 0.92403 (QuantReg: 14.21316) QuantErr: 14.21316 batch_time=0.65836 
Train Epoch: 26 [232/250 29696/32000 (93%)] Loss: 0.91865 (QuantReg: 14.04873) QuantErr: 14.04873 batch_time=0.67719 
Train Epoch: 26 [243/250 31104/32000 (97%)] Loss: 0.85186 (QuantReg: 14.19619) QuantErr: 14.19619 batch_time=0.68713 
Train Epoch: 26 codebook_update_time=2.42451
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_MSRVTT_1kA_roberta-large/checkpoint-epoch26.pth ...
Done in 16.117s
Updating 'best' checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_MSRVTT_1kA_roberta-large/checkpoint-epoch26.pth ...
Done in 37.603s
removing stale ckpt [epoch 25] [took 0.00s]
 epoch          : 26
 loss           : 0.9718073194026947
 quant_reg      : 13.980595642089844
 quant_err      : 13.980595642089844
 learning_rate  : 1.3869478656091687e-05
 n_samples      : 832000
 n_steps        : 6500
 MSRVTT_jsfusion_test/t2v_metrics/R1: 25.0
 MSRVTT_jsfusion_test/t2v_metrics/R5: 53.7
 MSRVTT_jsfusion_test/t2v_metrics/R10: 67.9
 MSRVTT_jsfusion_test/t2v_metrics/R50: 88.9
 MSRVTT_jsfusion_test/t2v_metrics/MedR: 5.0
 MSRVTT_jsfusion_test/t2v_metrics/MeanR: 26.973
 MSRVTT_jsfusion_test/t2v_metrics/geometric_mean_R1-R5-R10: 45.005061159144105
 MSRVTT_jsfusion_test/v2t_metrics/R1: 25.4
 MSRVTT_jsfusion_test/v2t_metrics/R5: 56.9
 MSRVTT_jsfusion_test/v2t_metrics/R10: 69.1
 MSRVTT_jsfusion_test/v2t_metrics/R50: 90.1
 MSRVTT_jsfusion_test/v2t_metrics/MedR: 4.0
 MSRVTT_jsfusion_test/v2t_metrics/MeanR: 24.1955
 MSRVTT_jsfusion_test/v2t_metrics/geometric_mean_R1-R5-R10: 46.39537365933374
 mnt_best       : 45.005061159144105
 not_improved_count: 0
Train Epoch: 27 [1/250 128/32000 (0%)] Loss: 0.85624 (QuantReg: 14.13060) QuantErr: 14.13060 batch_time=29.69773 
Train Epoch: 27 [12/250 1536/32000 (5%)] Loss: 1.12673 (QuantReg: 13.84641) QuantErr: 13.84641 batch_time=0.70503 
Train Epoch: 27 [23/250 2944/32000 (9%)] Loss: 1.09652 (QuantReg: 14.12740) QuantErr: 14.12740 batch_time=0.65829 
Train Epoch: 27 [34/250 4352/32000 (14%)] Loss: 0.79470 (QuantReg: 13.86633) QuantErr: 13.86633 batch_time=0.66159 
Train Epoch: 27 [45/250 5760/32000 (18%)] Loss: 0.78587 (QuantReg: 14.17328) QuantErr: 14.17328 batch_time=0.74763 
Train Epoch: 27 [56/250 7168/32000 (22%)] Loss: 0.92278 (QuantReg: 13.89536) QuantErr: 13.89536 batch_time=1.01187 
Train Epoch: 27 [67/250 8576/32000 (27%)] Loss: 0.92644 (QuantReg: 13.83139) QuantErr: 13.83139 batch_time=0.92098 
Train Epoch: 27 [78/250 9984/32000 (31%)] Loss: 1.15649 (QuantReg: 14.05399) QuantErr: 14.05399 batch_time=0.69520 
Train Epoch: 27 [89/250 11392/32000 (36%)] Loss: 0.81201 (QuantReg: 14.05718) QuantErr: 14.05718 batch_time=0.90212 
Train Epoch: 27 [100/250 12800/32000 (40%)] Loss: 1.21791 (QuantReg: 13.86526) QuantErr: 13.86526 batch_time=0.65626 
Train Epoch: 27 [111/250 14208/32000 (44%)] Loss: 0.68619 (QuantReg: 13.96053) QuantErr: 13.96053 batch_time=0.67231 
Train Epoch: 27 [122/250 15616/32000 (49%)] Loss: 1.16688 (QuantReg: 13.98671) QuantErr: 13.98671 batch_time=0.66225 
Train Epoch: 27 [133/250 17024/32000 (53%)] Loss: 1.14629 (QuantReg: 13.82391) QuantErr: 13.82391 batch_time=0.66042 
Train Epoch: 27 [144/250 18432/32000 (58%)] Loss: 0.85732 (QuantReg: 13.79779) QuantErr: 13.79779 batch_time=0.68198 
Train Epoch: 27 [155/250 19840/32000 (62%)] Loss: 1.04143 (QuantReg: 13.79955) QuantErr: 13.79955 batch_time=0.66256 
Train Epoch: 27 [166/250 21248/32000 (66%)] Loss: 0.87372 (QuantReg: 14.51197) QuantErr: 14.51197 batch_time=0.67063 
Train Epoch: 27 [177/250 22656/32000 (71%)] Loss: 0.69925 (QuantReg: 14.23298) QuantErr: 14.23298 batch_time=0.81552 
Train Epoch: 27 [188/250 24064/32000 (75%)] Loss: 0.64153 (QuantReg: 14.67216) QuantErr: 14.67216 batch_time=0.71898 
Train Epoch: 27 [199/250 25472/32000 (80%)] Loss: 0.95840 (QuantReg: 14.27218) QuantErr: 14.27218 batch_time=0.64004 
Train Epoch: 27 [210/250 26880/32000 (84%)] Loss: 1.11342 (QuantReg: 14.07941) QuantErr: 14.07941 batch_time=0.66333 
Train Epoch: 27 [221/250 28288/32000 (88%)] Loss: 0.84734 (QuantReg: 14.04011) QuantErr: 14.04011 batch_time=0.67037 
Train Epoch: 27 [232/250 29696/32000 (93%)] Loss: 1.03559 (QuantReg: 14.28517) QuantErr: 14.28517 batch_time=0.66530 
Train Epoch: 27 [243/250 31104/32000 (97%)] Loss: 1.10628 (QuantReg: 14.05480) QuantErr: 14.05480 batch_time=0.67298 
Train Epoch: 27 codebook_update_time=1.74698
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_MSRVTT_1kA_roberta-large/checkpoint-epoch27.pth ...
Done in 10.749s
Updating 'best' checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_MSRVTT_1kA_roberta-large/checkpoint-epoch27.pth ...
Done in 21.527s
removing stale ckpt [epoch 26] [took 0.00s]
 epoch          : 27
 loss           : 0.9611935480833054
 quant_reg      : 14.000447219848633
 quant_err      : 14.000447219848633
 learning_rate  : 1.3176004723287102e-05
 n_samples      : 864000
 n_steps        : 6750
 MSRVTT_jsfusion_test/t2v_metrics/R1: 24.2
 MSRVTT_jsfusion_test/t2v_metrics/R5: 55.5
 MSRVTT_jsfusion_test/t2v_metrics/R10: 68.0
 MSRVTT_jsfusion_test/t2v_metrics/R50: 89.1
 MSRVTT_jsfusion_test/t2v_metrics/MedR: 5.0
 MSRVTT_jsfusion_test/t2v_metrics/MeanR: 26.704
 MSRVTT_jsfusion_test/t2v_metrics/geometric_mean_R1-R5-R10: 45.03385107248899
 MSRVTT_jsfusion_test/v2t_metrics/R1: 25.1
 MSRVTT_jsfusion_test/v2t_metrics/R5: 57.8
 MSRVTT_jsfusion_test/v2t_metrics/R10: 70.4
 MSRVTT_jsfusion_test/v2t_metrics/R50: 90.6
 MSRVTT_jsfusion_test/v2t_metrics/MedR: 4.0
 MSRVTT_jsfusion_test/v2t_metrics/MeanR: 24.6975
 MSRVTT_jsfusion_test/v2t_metrics/geometric_mean_R1-R5-R10: 46.74387798622283
 mnt_best       : 45.03385107248899
 not_improved_count: 0
Train Epoch: 28 [1/250 128/32000 (0%)] Loss: 0.85202 (QuantReg: 14.16381) QuantErr: 14.16381 batch_time=34.67479 
Train Epoch: 28 [12/250 1536/32000 (5%)] Loss: 0.89885 (QuantReg: 13.45662) QuantErr: 13.45662 batch_time=0.96113 
Train Epoch: 28 [23/250 2944/32000 (9%)] Loss: 0.88480 (QuantReg: 13.62237) QuantErr: 13.62237 batch_time=0.67350 
Train Epoch: 28 [34/250 4352/32000 (14%)] Loss: 1.00990 (QuantReg: 13.88272) QuantErr: 13.88272 batch_time=0.67313 
Train Epoch: 28 [45/250 5760/32000 (18%)] Loss: 0.94469 (QuantReg: 13.68312) QuantErr: 13.68312 batch_time=0.67897 
Train Epoch: 28 [56/250 7168/32000 (22%)] Loss: 1.11638 (QuantReg: 13.83326) QuantErr: 13.83326 batch_time=0.68737 
Train Epoch: 28 [67/250 8576/32000 (27%)] Loss: 0.68078 (QuantReg: 14.02270) QuantErr: 14.02270 batch_time=0.67554 
Train Epoch: 28 [78/250 9984/32000 (31%)] Loss: 0.98044 (QuantReg: 13.75854) QuantErr: 13.75854 batch_time=0.65925 
Train Epoch: 28 [89/250 11392/32000 (36%)] Loss: 0.99698 (QuantReg: 14.14221) QuantErr: 14.14221 batch_time=0.66911 
Train Epoch: 28 [100/250 12800/32000 (40%)] Loss: 0.91258 (QuantReg: 13.86869) QuantErr: 13.86869 batch_time=0.67913 
Train Epoch: 28 [111/250 14208/32000 (44%)] Loss: 1.11619 (QuantReg: 13.71331) QuantErr: 13.71331 batch_time=0.64938 
Train Epoch: 28 [122/250 15616/32000 (49%)] Loss: 1.38422 (QuantReg: 13.96265) QuantErr: 13.96265 batch_time=0.69056 
Train Epoch: 28 [133/250 17024/32000 (53%)] Loss: 1.12953 (QuantReg: 13.62389) QuantErr: 13.62389 batch_time=0.66694 
Train Epoch: 28 [144/250 18432/32000 (58%)] Loss: 0.68372 (QuantReg: 14.14372) QuantErr: 14.14372 batch_time=0.85731 
Train Epoch: 28 [155/250 19840/32000 (62%)] Loss: 0.75252 (QuantReg: 14.30922) QuantErr: 14.30922 batch_time=0.66509 
Train Epoch: 28 [166/250 21248/32000 (66%)] Loss: 1.00824 (QuantReg: 14.05029) QuantErr: 14.05029 batch_time=0.71662 
Train Epoch: 28 [177/250 22656/32000 (71%)] Loss: 0.88657 (QuantReg: 13.73386) QuantErr: 13.73386 batch_time=0.69371 
Train Epoch: 28 [188/250 24064/32000 (75%)] Loss: 0.92304 (QuantReg: 14.09933) QuantErr: 14.09933 batch_time=0.65497 
Train Epoch: 28 [199/250 25472/32000 (80%)] Loss: 0.76600 (QuantReg: 13.91064) QuantErr: 13.91064 batch_time=0.75188 
Train Epoch: 28 [210/250 26880/32000 (84%)] Loss: 1.00137 (QuantReg: 14.06946) QuantErr: 14.06946 batch_time=0.68518 
Train Epoch: 28 [221/250 28288/32000 (88%)] Loss: 0.70762 (QuantReg: 13.92434) QuantErr: 13.92434 batch_time=0.65524 
Train Epoch: 28 [232/250 29696/32000 (93%)] Loss: 0.94015 (QuantReg: 14.39839) QuantErr: 14.39839 batch_time=0.71054 
Train Epoch: 28 [243/250 31104/32000 (97%)] Loss: 0.65805 (QuantReg: 14.36948) QuantErr: 14.36948 batch_time=0.64536 
Train Epoch: 28 codebook_update_time=1.81577
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_MSRVTT_1kA_roberta-large/checkpoint-epoch28.pth ...
Done in 10.866s
removing stale ckpt [epoch 27] [took 0.00s]
 epoch          : 28
 loss           : 0.9353696875572205
 quant_reg      : 14.02577891921997
 quant_err      : 14.02577891921997
 learning_rate  : 1.2517204487122746e-05
 n_samples      : 896000
 n_steps        : 7000
 MSRVTT_jsfusion_test/t2v_metrics/R1: 24.0
 MSRVTT_jsfusion_test/t2v_metrics/R5: 53.5
 MSRVTT_jsfusion_test/t2v_metrics/R10: 68.3
 MSRVTT_jsfusion_test/t2v_metrics/R50: 89.0
 MSRVTT_jsfusion_test/t2v_metrics/MedR: 5.0
 MSRVTT_jsfusion_test/t2v_metrics/MeanR: 28.504
 MSRVTT_jsfusion_test/t2v_metrics/geometric_mean_R1-R5-R10: 44.42852642918805
 MSRVTT_jsfusion_test/v2t_metrics/R1: 27.1
 MSRVTT_jsfusion_test/v2t_metrics/R5: 57.0
 MSRVTT_jsfusion_test/v2t_metrics/R10: 69.1
 MSRVTT_jsfusion_test/v2t_metrics/R50: 89.9
 MSRVTT_jsfusion_test/v2t_metrics/MedR: 4.0
 MSRVTT_jsfusion_test/v2t_metrics/MeanR: 25.904
 MSRVTT_jsfusion_test/v2t_metrics/geometric_mean_R1-R5-R10: 47.43592764728713
 mnt_best       : 45.03385107248899
 not_improved_count: 1
Train Epoch: 29 [1/250 128/32000 (0%)] Loss: 1.07900 (QuantReg: 13.84627) QuantErr: 13.84627 batch_time=31.41739 
Train Epoch: 29 [12/250 1536/32000 (5%)] Loss: 1.09849 (QuantReg: 13.61611) QuantErr: 13.61611 batch_time=0.68037 
Train Epoch: 29 [23/250 2944/32000 (9%)] Loss: 0.81830 (QuantReg: 13.88348) QuantErr: 13.88348 batch_time=0.66767 
Train Epoch: 29 [34/250 4352/32000 (14%)] Loss: 0.68056 (QuantReg: 13.89429) QuantErr: 13.89429 batch_time=0.67169 
Train Epoch: 29 [45/250 5760/32000 (18%)] Loss: 0.95854 (QuantReg: 14.27531) QuantErr: 14.27531 batch_time=0.67252 
Train Epoch: 29 [56/250 7168/32000 (22%)] Loss: 0.87582 (QuantReg: 14.32817) QuantErr: 14.32817 batch_time=0.65987 
Train Epoch: 29 [67/250 8576/32000 (27%)] Loss: 1.25456 (QuantReg: 14.05743) QuantErr: 14.05743 batch_time=0.65470 
Train Epoch: 29 [78/250 9984/32000 (31%)] Loss: 0.91663 (QuantReg: 14.03671) QuantErr: 14.03671 batch_time=0.65344 
Train Epoch: 29 [89/250 11392/32000 (36%)] Loss: 1.09665 (QuantReg: 13.95092) QuantErr: 13.95092 batch_time=0.67229 
Train Epoch: 29 [100/250 12800/32000 (40%)] Loss: 0.76066 (QuantReg: 14.12911) QuantErr: 14.12911 batch_time=0.65349 
Train Epoch: 29 [111/250 14208/32000 (44%)] Loss: 0.95259 (QuantReg: 14.08559) QuantErr: 14.08559 batch_time=0.66855 
Train Epoch: 29 [122/250 15616/32000 (49%)] Loss: 0.86998 (QuantReg: 14.00715) QuantErr: 14.00715 batch_time=0.68457 
Train Epoch: 29 [133/250 17024/32000 (53%)] Loss: 0.81368 (QuantReg: 13.97243) QuantErr: 13.97243 batch_time=0.67499 
Train Epoch: 29 [144/250 18432/32000 (58%)] Loss: 1.11670 (QuantReg: 14.14256) QuantErr: 14.14256 batch_time=4.40400 
Train Epoch: 29 [155/250 19840/32000 (62%)] Loss: 0.97367 (QuantReg: 14.22821) QuantErr: 14.22821 batch_time=0.65191 
Train Epoch: 29 [166/250 21248/32000 (66%)] Loss: 0.84941 (QuantReg: 14.10440) QuantErr: 14.10440 batch_time=0.66347 
Train Epoch: 29 [177/250 22656/32000 (71%)] Loss: 0.61509 (QuantReg: 14.15289) QuantErr: 14.15289 batch_time=0.65693 
Train Epoch: 29 [188/250 24064/32000 (75%)] Loss: 0.82827 (QuantReg: 13.97105) QuantErr: 13.97105 batch_time=0.65095 
Train Epoch: 29 [199/250 25472/32000 (80%)] Loss: 0.88598 (QuantReg: 14.17013) QuantErr: 14.17013 batch_time=0.66193 
Train Epoch: 29 [210/250 26880/32000 (84%)] Loss: 0.89193 (QuantReg: 14.08597) QuantErr: 14.08597 batch_time=0.68550 
Train Epoch: 29 [221/250 28288/32000 (88%)] Loss: 1.04475 (QuantReg: 14.19856) QuantErr: 14.19856 batch_time=0.66330 
Train Epoch: 29 [232/250 29696/32000 (93%)] Loss: 0.93177 (QuantReg: 13.76038) QuantErr: 13.76038 batch_time=0.66875 
Train Epoch: 29 [243/250 31104/32000 (97%)] Loss: 1.04152 (QuantReg: 14.15691) QuantErr: 14.15691 batch_time=0.97114 
Train Epoch: 29 codebook_update_time=1.82715
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_MSRVTT_1kA_roberta-large/checkpoint-epoch29.pth ...
Done in 11.017s
Updating 'best' checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_MSRVTT_1kA_roberta-large/checkpoint-epoch29.pth ...
Done in 21.933s
removing stale ckpt [epoch 28] [took 0.00s]
 epoch          : 29
 loss           : 0.9292390222549438
 quant_reg      : 14.05436141204834
 quant_err      : 14.05436141204834
 learning_rate  : 1.1891344262766608e-05
 n_samples      : 928000
 n_steps        : 7250
 MSRVTT_jsfusion_test/t2v_metrics/R1: 25.4
 MSRVTT_jsfusion_test/t2v_metrics/R5: 54.2
 MSRVTT_jsfusion_test/t2v_metrics/R10: 68.4
 MSRVTT_jsfusion_test/t2v_metrics/R50: 89.4
 MSRVTT_jsfusion_test/t2v_metrics/MedR: 4.5
 MSRVTT_jsfusion_test/t2v_metrics/MeanR: 28.831
 MSRVTT_jsfusion_test/t2v_metrics/geometric_mean_R1-R5-R10: 45.49493354205404
 MSRVTT_jsfusion_test/v2t_metrics/R1: 27.7
 MSRVTT_jsfusion_test/v2t_metrics/R5: 57.4
 MSRVTT_jsfusion_test/v2t_metrics/R10: 69.3
 MSRVTT_jsfusion_test/v2t_metrics/R50: 88.9
 MSRVTT_jsfusion_test/v2t_metrics/MedR: 4.0
 MSRVTT_jsfusion_test/v2t_metrics/MeanR: 26.203
 MSRVTT_jsfusion_test/v2t_metrics/geometric_mean_R1-R5-R10: 47.94113356582303
 mnt_best       : 45.49493354205404
 not_improved_count: 0
Train Epoch: 30 [1/250 128/32000 (0%)] Loss: 0.67249 (QuantReg: 14.03898) QuantErr: 14.03898 batch_time=29.63388 
Train Epoch: 30 [12/250 1536/32000 (5%)] Loss: 1.08090 (QuantReg: 13.91463) QuantErr: 13.91463 batch_time=3.85188 
Train Epoch: 30 [23/250 2944/32000 (9%)] Loss: 1.04316 (QuantReg: 14.17005) QuantErr: 14.17005 batch_time=0.70389 
Train Epoch: 30 [34/250 4352/32000 (14%)] Loss: 0.88155 (QuantReg: 14.21491) QuantErr: 14.21491 batch_time=0.65660 
Train Epoch: 30 [45/250 5760/32000 (18%)] Loss: 0.78978 (QuantReg: 14.00349) QuantErr: 14.00349 batch_time=0.65749 
Train Epoch: 30 [56/250 7168/32000 (22%)] Loss: 0.90702 (QuantReg: 13.85968) QuantErr: 13.85968 batch_time=0.65867 
Train Epoch: 30 [67/250 8576/32000 (27%)] Loss: 0.89046 (QuantReg: 13.79292) QuantErr: 13.79292 batch_time=0.65757 
Train Epoch: 30 [78/250 9984/32000 (31%)] Loss: 1.11502 (QuantReg: 13.72691) QuantErr: 13.72691 batch_time=0.66699 
Train Epoch: 30 [89/250 11392/32000 (36%)] Loss: 0.95977 (QuantReg: 14.18988) QuantErr: 14.18988 batch_time=0.69161 
Train Epoch: 30 [100/250 12800/32000 (40%)] Loss: 0.68809 (QuantReg: 14.17305) QuantErr: 14.17305 batch_time=0.68865 
Train Epoch: 30 [111/250 14208/32000 (44%)] Loss: 0.72065 (QuantReg: 14.43814) QuantErr: 14.43814 batch_time=0.81599 
Train Epoch: 30 [122/250 15616/32000 (49%)] Loss: 0.96695 (QuantReg: 14.05775) QuantErr: 14.05775 batch_time=0.67415 
Train Epoch: 30 [133/250 17024/32000 (53%)] Loss: 0.86937 (QuantReg: 14.27618) QuantErr: 14.27618 batch_time=0.66017 
Train Epoch: 30 [144/250 18432/32000 (58%)] Loss: 0.88020 (QuantReg: 14.06241) QuantErr: 14.06241 batch_time=0.66060 
Train Epoch: 30 [155/250 19840/32000 (62%)] Loss: 0.89382 (QuantReg: 13.96041) QuantErr: 13.96041 batch_time=0.66723 
Train Epoch: 30 [166/250 21248/32000 (66%)] Loss: 1.09761 (QuantReg: 14.31542) QuantErr: 14.31542 batch_time=0.67659 
Train Epoch: 30 [177/250 22656/32000 (71%)] Loss: 0.92593 (QuantReg: 14.02330) QuantErr: 14.02330 batch_time=0.66884 
Train Epoch: 30 [188/250 24064/32000 (75%)] Loss: 0.95912 (QuantReg: 14.00267) QuantErr: 14.00267 batch_time=0.75966 
Train Epoch: 30 [199/250 25472/32000 (80%)] Loss: 1.07752 (QuantReg: 13.88127) QuantErr: 13.88127 batch_time=0.71652 
Train Epoch: 30 [210/250 26880/32000 (84%)] Loss: 0.98504 (QuantReg: 14.06689) QuantErr: 14.06689 batch_time=0.67141 
Train Epoch: 30 [221/250 28288/32000 (88%)] Loss: 0.71523 (QuantReg: 13.91119) QuantErr: 13.91119 batch_time=0.65871 
Train Epoch: 30 [232/250 29696/32000 (93%)] Loss: 0.70007 (QuantReg: 14.20292) QuantErr: 14.20292 batch_time=0.66007 
Train Epoch: 30 [243/250 31104/32000 (97%)] Loss: 0.96907 (QuantReg: 14.39722) QuantErr: 14.39722 batch_time=0.69911 
Train Epoch: 30 codebook_update_time=1.74426
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_MSRVTT_1kA_roberta-large/checkpoint-epoch30.pth ...
Done in 11.780s
removing stale ckpt [epoch 29] [took 0.00s]
 epoch          : 30
 loss           : 0.8912012510299683
 quant_reg      : 14.07056662750244
 quant_err      : 14.07056662750244
 learning_rate  : 1.1296777049628277e-05
 n_samples      : 960000
 n_steps        : 7500
 MSRVTT_jsfusion_test/t2v_metrics/R1: 25.6
 MSRVTT_jsfusion_test/t2v_metrics/R5: 53.6
 MSRVTT_jsfusion_test/t2v_metrics/R10: 67.9
 MSRVTT_jsfusion_test/t2v_metrics/R50: 88.2
 MSRVTT_jsfusion_test/t2v_metrics/MedR: 5.0
 MSRVTT_jsfusion_test/t2v_metrics/MeanR: 29.353
 MSRVTT_jsfusion_test/t2v_metrics/geometric_mean_R1-R5-R10: 45.334083801494074
 MSRVTT_jsfusion_test/v2t_metrics/R1: 27.8
 MSRVTT_jsfusion_test/v2t_metrics/R5: 56.2
 MSRVTT_jsfusion_test/v2t_metrics/R10: 69.3
 MSRVTT_jsfusion_test/v2t_metrics/R50: 88.9
 MSRVTT_jsfusion_test/v2t_metrics/MedR: 4.0
 MSRVTT_jsfusion_test/v2t_metrics/MeanR: 26.2585
 MSRVTT_jsfusion_test/v2t_metrics/geometric_mean_R1-R5-R10: 47.66191070832265
 mnt_best       : 45.49493354205404
 not_improved_count: 1
Train Epoch: 31 [1/250 128/32000 (0%)] Loss: 0.70950 (QuantReg: 14.21126) QuantErr: 14.21126 batch_time=28.05060 
Train Epoch: 31 [12/250 1536/32000 (5%)] Loss: 0.97527 (QuantReg: 14.14245) QuantErr: 14.14245 batch_time=0.64416 
Train Epoch: 31 [23/250 2944/32000 (9%)] Loss: 1.03006 (QuantReg: 14.04702) QuantErr: 14.04702 batch_time=0.64557 
Train Epoch: 31 [34/250 4352/32000 (14%)] Loss: 0.70677 (QuantReg: 14.44056) QuantErr: 14.44056 batch_time=0.68473 
Train Epoch: 31 [45/250 5760/32000 (18%)] Loss: 0.92962 (QuantReg: 13.87065) QuantErr: 13.87065 batch_time=0.64512 
Train Epoch: 31 [56/250 7168/32000 (22%)] Loss: 0.62908 (QuantReg: 13.98184) QuantErr: 13.98184 batch_time=0.65387 
Train Epoch: 31 [67/250 8576/32000 (27%)] Loss: 0.76655 (QuantReg: 14.23463) QuantErr: 14.23463 batch_time=1.24897 
Train Epoch: 31 [78/250 9984/32000 (31%)] Loss: 0.65375 (QuantReg: 14.01979) QuantErr: 14.01979 batch_time=0.70250 
Train Epoch: 31 [89/250 11392/32000 (36%)] Loss: 0.86838 (QuantReg: 13.96503) QuantErr: 13.96503 batch_time=0.68251 
Train Epoch: 31 [100/250 12800/32000 (40%)] Loss: 1.05173 (QuantReg: 14.13950) QuantErr: 14.13950 batch_time=0.65654 
Train Epoch: 31 [111/250 14208/32000 (44%)] Loss: 0.87903 (QuantReg: 14.26720) QuantErr: 14.26720 batch_time=0.65788 
Train Epoch: 31 [122/250 15616/32000 (49%)] Loss: 0.93138 (QuantReg: 13.95081) QuantErr: 13.95081 batch_time=0.65641 
Train Epoch: 31 [133/250 17024/32000 (53%)] Loss: 1.10264 (QuantReg: 13.81190) QuantErr: 13.81190 batch_time=0.64781 
Train Epoch: 31 [144/250 18432/32000 (58%)] Loss: 0.88772 (QuantReg: 13.89292) QuantErr: 13.89292 batch_time=0.66717 
Train Epoch: 31 [155/250 19840/32000 (62%)] Loss: 0.73686 (QuantReg: 14.34992) QuantErr: 14.34992 batch_time=0.69806 
Train Epoch: 31 [166/250 21248/32000 (66%)] Loss: 0.84639 (QuantReg: 14.34136) QuantErr: 14.34136 batch_time=0.65429 
Train Epoch: 31 [177/250 22656/32000 (71%)] Loss: 0.76772 (QuantReg: 13.93620) QuantErr: 13.93620 batch_time=0.66328 
Train Epoch: 31 [188/250 24064/32000 (75%)] Loss: 0.68313 (QuantReg: 14.27965) QuantErr: 14.27965 batch_time=0.65186 
Train Epoch: 31 [199/250 25472/32000 (80%)] Loss: 0.69812 (QuantReg: 14.24115) QuantErr: 14.24115 batch_time=6.55154 
Train Epoch: 31 [210/250 26880/32000 (84%)] Loss: 1.08629 (QuantReg: 14.18771) QuantErr: 14.18771 batch_time=4.45282 
Train Epoch: 31 [221/250 28288/32000 (88%)] Loss: 0.77252 (QuantReg: 14.20700) QuantErr: 14.20700 batch_time=0.68213 
Train Epoch: 31 [232/250 29696/32000 (93%)] Loss: 0.59461 (QuantReg: 13.89050) QuantErr: 13.89050 batch_time=0.66632 
Train Epoch: 31 [243/250 31104/32000 (97%)] Loss: 0.80612 (QuantReg: 14.08011) QuantErr: 14.08011 batch_time=0.67252 
Train Epoch: 31 codebook_update_time=1.74814
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_MSRVTT_1kA_roberta-large/checkpoint-epoch31.pth ...
Done in 11.363s
Updating 'best' checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_MSRVTT_1kA_roberta-large/checkpoint-epoch31.pth ...
Done in 22.139s
removing stale ckpt [epoch 30] [took 0.00s]
 epoch          : 31
 loss           : 0.8892185500860215
 quant_reg      : 14.117315059661864
 quant_err      : 14.117315059661864
 learning_rate  : 1.0731938197146863e-05
 n_samples      : 992000
 n_steps        : 7750
 MSRVTT_jsfusion_test/t2v_metrics/R1: 26.1
 MSRVTT_jsfusion_test/t2v_metrics/R5: 55.1
 MSRVTT_jsfusion_test/t2v_metrics/R10: 68.8
 MSRVTT_jsfusion_test/t2v_metrics/R50: 88.2
 MSRVTT_jsfusion_test/t2v_metrics/MedR: 4.0
 MSRVTT_jsfusion_test/t2v_metrics/MeanR: 28.717
 MSRVTT_jsfusion_test/t2v_metrics/geometric_mean_R1-R5-R10: 46.251609274415934
 MSRVTT_jsfusion_test/v2t_metrics/R1: 26.2
 MSRVTT_jsfusion_test/v2t_metrics/R5: 58.2
 MSRVTT_jsfusion_test/v2t_metrics/R10: 70.5
 MSRVTT_jsfusion_test/v2t_metrics/R50: 89.6
 MSRVTT_jsfusion_test/v2t_metrics/MedR: 4.0
 MSRVTT_jsfusion_test/v2t_metrics/MeanR: 25.3285
 MSRVTT_jsfusion_test/v2t_metrics/geometric_mean_R1-R5-R10: 47.54860693772976
 mnt_best       : 46.251609274415934
 not_improved_count: 0
Train Epoch: 32 [1/250 128/32000 (0%)] Loss: 1.04784 (QuantReg: 14.10489) QuantErr: 14.10489 batch_time=38.88744 
Train Epoch: 32 [12/250 1536/32000 (5%)] Loss: 1.04784 (QuantReg: 13.92056) QuantErr: 13.92056 batch_time=0.64671 
Train Epoch: 32 [23/250 2944/32000 (9%)] Loss: 0.69431 (QuantReg: 13.86405) QuantErr: 13.86405 batch_time=0.64654 
Train Epoch: 32 [34/250 4352/32000 (14%)] Loss: 0.85362 (QuantReg: 14.28830) QuantErr: 14.28830 batch_time=0.65659 
Train Epoch: 32 [45/250 5760/32000 (18%)] Loss: 0.90486 (QuantReg: 14.34973) QuantErr: 14.34973 batch_time=0.65749 
Train Epoch: 32 [56/250 7168/32000 (22%)] Loss: 0.70413 (QuantReg: 14.20066) QuantErr: 14.20066 batch_time=0.65994 
Train Epoch: 32 [67/250 8576/32000 (27%)] Loss: 0.92708 (QuantReg: 14.20733) QuantErr: 14.20733 batch_time=0.72309 
Train Epoch: 32 [78/250 9984/32000 (31%)] Loss: 0.85388 (QuantReg: 13.97289) QuantErr: 13.97289 batch_time=0.65896 
Train Epoch: 32 [89/250 11392/32000 (36%)] Loss: 1.12419 (QuantReg: 13.87903) QuantErr: 13.87903 batch_time=0.67060 
Train Epoch: 32 [100/250 12800/32000 (40%)] Loss: 0.61869 (QuantReg: 14.11891) QuantErr: 14.11891 batch_time=0.66683 
Train Epoch: 32 [111/250 14208/32000 (44%)] Loss: 0.67619 (QuantReg: 14.01268) QuantErr: 14.01268 batch_time=0.99045 
Train Epoch: 32 [122/250 15616/32000 (49%)] Loss: 1.19958 (QuantReg: 14.07174) QuantErr: 14.07174 batch_time=0.63831 
Train Epoch: 32 [133/250 17024/32000 (53%)] Loss: 0.69019 (QuantReg: 14.27598) QuantErr: 14.27598 batch_time=0.64739 
Train Epoch: 32 [144/250 18432/32000 (58%)] Loss: 0.68289 (QuantReg: 14.11633) QuantErr: 14.11633 batch_time=0.66503 
Train Epoch: 32 [155/250 19840/32000 (62%)] Loss: 0.67428 (QuantReg: 14.36437) QuantErr: 14.36437 batch_time=0.64463 
Train Epoch: 32 [166/250 21248/32000 (66%)] Loss: 1.00125 (QuantReg: 14.13092) QuantErr: 14.13092 batch_time=0.66727 
Train Epoch: 32 [177/250 22656/32000 (71%)] Loss: 1.04132 (QuantReg: 13.93390) QuantErr: 13.93390 batch_time=0.65496 
Train Epoch: 32 [188/250 24064/32000 (75%)] Loss: 1.24438 (QuantReg: 14.10752) QuantErr: 14.10752 batch_time=0.74096 
Train Epoch: 32 [199/250 25472/32000 (80%)] Loss: 0.77090 (QuantReg: 14.04478) QuantErr: 14.04478 batch_time=2.73895 
Train Epoch: 32 [210/250 26880/32000 (84%)] Loss: 1.03264 (QuantReg: 13.95292) QuantErr: 13.95292 batch_time=0.65905 
Train Epoch: 32 [221/250 28288/32000 (88%)] Loss: 0.86632 (QuantReg: 13.83544) QuantErr: 13.83544 batch_time=0.68535 
Train Epoch: 32 [232/250 29696/32000 (93%)] Loss: 0.91378 (QuantReg: 14.12409) QuantErr: 14.12409 batch_time=0.65693 
Train Epoch: 32 [243/250 31104/32000 (97%)] Loss: 0.79004 (QuantReg: 13.97319) QuantErr: 13.97319 batch_time=0.69024 
Train Epoch: 32 codebook_update_time=1.98454
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_MSRVTT_1kA_roberta-large/checkpoint-epoch32.pth ...
Done in 25.353s
removing stale ckpt [epoch 31] [took 0.00s]
 epoch          : 32
 loss           : 0.8719220206737518
 quant_reg      : 14.112850257873536
 quant_err      : 14.112850257873536
 learning_rate  : 1.019534128728952e-05
 n_samples      : 1024000
 n_steps        : 8000
 MSRVTT_jsfusion_test/t2v_metrics/R1: 25.3
 MSRVTT_jsfusion_test/t2v_metrics/R5: 55.0
 MSRVTT_jsfusion_test/t2v_metrics/R10: 68.8
 MSRVTT_jsfusion_test/t2v_metrics/R50: 88.7
 MSRVTT_jsfusion_test/t2v_metrics/MedR: 4.0
 MSRVTT_jsfusion_test/t2v_metrics/MeanR: 29.343
 MSRVTT_jsfusion_test/t2v_metrics/geometric_mean_R1-R5-R10: 45.746430888021436
 MSRVTT_jsfusion_test/v2t_metrics/R1: 27.0
 MSRVTT_jsfusion_test/v2t_metrics/R5: 58.5
 MSRVTT_jsfusion_test/v2t_metrics/R10: 70.5
 MSRVTT_jsfusion_test/v2t_metrics/R50: 89.8
 MSRVTT_jsfusion_test/v2t_metrics/MedR: 4.0
 MSRVTT_jsfusion_test/v2t_metrics/MeanR: 25.5195
 MSRVTT_jsfusion_test/v2t_metrics/geometric_mean_R1-R5-R10: 48.11009883289591
 mnt_best       : 46.251609274415934
 not_improved_count: 1
Train Epoch: 33 [1/250 128/32000 (0%)] Loss: 0.77958 (QuantReg: 13.79444) QuantErr: 13.79444 batch_time=29.49505 
Train Epoch: 33 [12/250 1536/32000 (5%)] Loss: 0.81201 (QuantReg: 13.93879) QuantErr: 13.93879 batch_time=0.65337 
Train Epoch: 33 [23/250 2944/32000 (9%)] Loss: 1.09813 (QuantReg: 14.25964) QuantErr: 14.25964 batch_time=0.66021 
Train Epoch: 33 [34/250 4352/32000 (14%)] Loss: 0.70020 (QuantReg: 14.30583) QuantErr: 14.30583 batch_time=0.67378 
Train Epoch: 33 [45/250 5760/32000 (18%)] Loss: 0.83662 (QuantReg: 14.17718) QuantErr: 14.17718 batch_time=0.65676 
Train Epoch: 33 [56/250 7168/32000 (22%)] Loss: 1.05524 (QuantReg: 13.99104) QuantErr: 13.99104 batch_time=0.65195 
Train Epoch: 33 [67/250 8576/32000 (27%)] Loss: 0.98473 (QuantReg: 13.84519) QuantErr: 13.84519 batch_time=0.64945 
Train Epoch: 33 [78/250 9984/32000 (31%)] Loss: 0.87979 (QuantReg: 14.15930) QuantErr: 14.15930 batch_time=0.65882 
Train Epoch: 33 [89/250 11392/32000 (36%)] Loss: 1.01591 (QuantReg: 14.22873) QuantErr: 14.22873 batch_time=0.65137 
Train Epoch: 33 [100/250 12800/32000 (40%)] Loss: 0.69540 (QuantReg: 14.26118) QuantErr: 14.26118 batch_time=0.64984 
Train Epoch: 33 [111/250 14208/32000 (44%)] Loss: 0.92385 (QuantReg: 14.27235) QuantErr: 14.27235 batch_time=0.69346 
Train Epoch: 33 [122/250 15616/32000 (49%)] Loss: 0.83241 (QuantReg: 14.28418) QuantErr: 14.28418 batch_time=0.65738 
Train Epoch: 33 [133/250 17024/32000 (53%)] Loss: 1.02131 (QuantReg: 14.21483) QuantErr: 14.21483 batch_time=0.66283 
Train Epoch: 33 [144/250 18432/32000 (58%)] Loss: 0.89676 (QuantReg: 14.48684) QuantErr: 14.48684 batch_time=4.30960 
Train Epoch: 33 [155/250 19840/32000 (62%)] Loss: 0.77839 (QuantReg: 14.45330) QuantErr: 14.45330 batch_time=0.65702 
Train Epoch: 33 [166/250 21248/32000 (66%)] Loss: 0.98089 (QuantReg: 14.04138) QuantErr: 14.04138 batch_time=1.34931 
Train Epoch: 33 [177/250 22656/32000 (71%)] Loss: 0.83608 (QuantReg: 14.12783) QuantErr: 14.12783 batch_time=0.66603 
Train Epoch: 33 [188/250 24064/32000 (75%)] Loss: 0.98290 (QuantReg: 14.27877) QuantErr: 14.27877 batch_time=0.76966 
Train Epoch: 33 [199/250 25472/32000 (80%)] Loss: 0.88859 (QuantReg: 14.04830) QuantErr: 14.04830 batch_time=0.65354 
Train Epoch: 33 [210/250 26880/32000 (84%)] Loss: 0.85305 (QuantReg: 14.18897) QuantErr: 14.18897 batch_time=0.67510 
Train Epoch: 33 [221/250 28288/32000 (88%)] Loss: 0.73518 (QuantReg: 14.08747) QuantErr: 14.08747 batch_time=0.81501 
Train Epoch: 33 [232/250 29696/32000 (93%)] Loss: 0.82247 (QuantReg: 14.50987) QuantErr: 14.50987 batch_time=1.48134 
Train Epoch: 33 [243/250 31104/32000 (97%)] Loss: 0.85165 (QuantReg: 14.35721) QuantErr: 14.35721 batch_time=0.68812 
Train Epoch: 33 codebook_update_time=1.74914
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_MSRVTT_1kA_roberta-large/checkpoint-epoch33.pth ...
Done in 11.118s
removing stale ckpt [epoch 32] [took 0.00s]
 epoch          : 33
 loss           : 0.8783265699148178
 quant_reg      : 14.16140311050415
 quant_err      : 14.16140311050415
 learning_rate  : 9.685574222925043e-06
 n_samples      : 1056000
 n_steps        : 8250
 MSRVTT_jsfusion_test/t2v_metrics/R1: 24.7
 MSRVTT_jsfusion_test/t2v_metrics/R5: 54.7
 MSRVTT_jsfusion_test/t2v_metrics/R10: 68.8
 MSRVTT_jsfusion_test/t2v_metrics/R50: 88.7
 MSRVTT_jsfusion_test/t2v_metrics/MedR: 4.0
 MSRVTT_jsfusion_test/t2v_metrics/MeanR: 28.972
 MSRVTT_jsfusion_test/t2v_metrics/geometric_mean_R1-R5-R10: 45.299238974458994
 MSRVTT_jsfusion_test/v2t_metrics/R1: 27.3
 MSRVTT_jsfusion_test/v2t_metrics/R5: 58.0
 MSRVTT_jsfusion_test/v2t_metrics/R10: 69.4
 MSRVTT_jsfusion_test/v2t_metrics/R50: 89.2
 MSRVTT_jsfusion_test/v2t_metrics/MedR: 4.0
 MSRVTT_jsfusion_test/v2t_metrics/MeanR: 25.806
 MSRVTT_jsfusion_test/v2t_metrics/geometric_mean_R1-R5-R10: 47.89792544801754
 mnt_best       : 46.251609274415934
 not_improved_count: 2
Train Epoch: 34 [1/250 128/32000 (0%)] Loss: 0.78033 (QuantReg: 14.02022) QuantErr: 14.02022 batch_time=31.14555 
Train Epoch: 34 [12/250 1536/32000 (5%)] Loss: 0.75935 (QuantReg: 14.00322) QuantErr: 14.00322 batch_time=0.66689 
Train Epoch: 34 [23/250 2944/32000 (9%)] Loss: 1.04771 (QuantReg: 14.05688) QuantErr: 14.05688 batch_time=0.66704 
Train Epoch: 34 [34/250 4352/32000 (14%)] Loss: 1.08661 (QuantReg: 14.01334) QuantErr: 14.01334 batch_time=0.70456 
Train Epoch: 34 [45/250 5760/32000 (18%)] Loss: 0.85812 (QuantReg: 14.12140) QuantErr: 14.12140 batch_time=0.74704 
Train Epoch: 34 [56/250 7168/32000 (22%)] Loss: 0.97389 (QuantReg: 13.87976) QuantErr: 13.87976 batch_time=0.79066 
Train Epoch: 34 [67/250 8576/32000 (27%)] Loss: 1.23405 (QuantReg: 13.74416) QuantErr: 13.74416 batch_time=0.65486 
Train Epoch: 34 [78/250 9984/32000 (31%)] Loss: 0.87285 (QuantReg: 14.26467) QuantErr: 14.26467 batch_time=0.69391 
Train Epoch: 34 [89/250 11392/32000 (36%)] Loss: 0.94198 (QuantReg: 14.11576) QuantErr: 14.11576 batch_time=0.66881 
Train Epoch: 34 [100/250 12800/32000 (40%)] Loss: 0.90456 (QuantReg: 14.12618) QuantErr: 14.12618 batch_time=0.65946 
Train Epoch: 34 [111/250 14208/32000 (44%)] Loss: 0.85696 (QuantReg: 14.12420) QuantErr: 14.12420 batch_time=0.66742 
Train Epoch: 34 [122/250 15616/32000 (49%)] Loss: 0.97060 (QuantReg: 14.26801) QuantErr: 14.26801 batch_time=0.67359 
Train Epoch: 34 [133/250 17024/32000 (53%)] Loss: 0.67147 (QuantReg: 14.04831) QuantErr: 14.04831 batch_time=0.65986 
Train Epoch: 34 [144/250 18432/32000 (58%)] Loss: 1.02005 (QuantReg: 14.00928) QuantErr: 14.00928 batch_time=0.66554 
Train Epoch: 34 [155/250 19840/32000 (62%)] Loss: 0.88715 (QuantReg: 14.34216) QuantErr: 14.34216 batch_time=0.65132 
Train Epoch: 34 [166/250 21248/32000 (66%)] Loss: 1.33735 (QuantReg: 13.97691) QuantErr: 13.97691 batch_time=0.91570 
Train Epoch: 34 [177/250 22656/32000 (71%)] Loss: 0.83188 (QuantReg: 14.06021) QuantErr: 14.06021 batch_time=0.66725 
Train Epoch: 34 [188/250 24064/32000 (75%)] Loss: 0.92430 (QuantReg: 14.22025) QuantErr: 14.22025 batch_time=0.69131 
Train Epoch: 34 [199/250 25472/32000 (80%)] Loss: 0.82287 (QuantReg: 14.16337) QuantErr: 14.16337 batch_time=0.66717 
Train Epoch: 34 [210/250 26880/32000 (84%)] Loss: 1.00567 (QuantReg: 14.15559) QuantErr: 14.15559 batch_time=0.69012 
Train Epoch: 34 [221/250 28288/32000 (88%)] Loss: 1.03344 (QuantReg: 14.07754) QuantErr: 14.07754 batch_time=0.67223 
Train Epoch: 34 [232/250 29696/32000 (93%)] Loss: 0.94361 (QuantReg: 14.11509) QuantErr: 14.11509 batch_time=0.78749 
Train Epoch: 34 [243/250 31104/32000 (97%)] Loss: 0.95471 (QuantReg: 13.83370) QuantErr: 13.83370 batch_time=0.66657 
Train Epoch: 34 codebook_update_time=1.89312
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_MSRVTT_1kA_roberta-large/checkpoint-epoch34.pth ...
Done in 12.004s
removing stale ckpt [epoch 33] [took 0.13s]
 epoch          : 34
 loss           : 0.8715668196678161
 quant_reg      : 14.139566837310792
 quant_err      : 14.139566837310792
 learning_rate  : 9.20129551177879e-06
 n_samples      : 1088000
 n_steps        : 8500
 MSRVTT_jsfusion_test/t2v_metrics/R1: 26.3
 MSRVTT_jsfusion_test/t2v_metrics/R5: 54.7
 MSRVTT_jsfusion_test/t2v_metrics/R10: 68.4
 MSRVTT_jsfusion_test/t2v_metrics/R50: 88.5
 MSRVTT_jsfusion_test/t2v_metrics/MedR: 4.0
 MSRVTT_jsfusion_test/t2v_metrics/MeanR: 29.968
 MSRVTT_jsfusion_test/t2v_metrics/geometric_mean_R1-R5-R10: 46.16714930109826
 MSRVTT_jsfusion_test/v2t_metrics/R1: 25.6
 MSRVTT_jsfusion_test/v2t_metrics/R5: 56.8
 MSRVTT_jsfusion_test/v2t_metrics/R10: 69.8
 MSRVTT_jsfusion_test/v2t_metrics/R50: 89.0
 MSRVTT_jsfusion_test/v2t_metrics/MedR: 4.0
 MSRVTT_jsfusion_test/v2t_metrics/MeanR: 26.7245
 MSRVTT_jsfusion_test/v2t_metrics/geometric_mean_R1-R5-R10: 46.64601789428743
 mnt_best       : 46.251609274415934
 not_improved_count: 3
Train Epoch: 35 [1/250 128/32000 (0%)] Loss: 1.19537 (QuantReg: 13.65107) QuantErr: 13.65107 batch_time=31.87944 
Train Epoch: 35 [12/250 1536/32000 (5%)] Loss: 1.02535 (QuantReg: 13.99407) QuantErr: 13.99407 batch_time=0.64460 
Train Epoch: 35 [23/250 2944/32000 (9%)] Loss: 0.90291 (QuantReg: 14.31842) QuantErr: 14.31842 batch_time=0.68773 
Train Epoch: 35 [34/250 4352/32000 (14%)] Loss: 1.15214 (QuantReg: 13.68616) QuantErr: 13.68616 batch_time=0.67588 
Train Epoch: 35 [45/250 5760/32000 (18%)] Loss: 0.84807 (QuantReg: 14.05616) QuantErr: 14.05616 batch_time=0.67236 
Train Epoch: 35 [56/250 7168/32000 (22%)] Loss: 0.70395 (QuantReg: 13.91035) QuantErr: 13.91035 batch_time=0.69323 
Train Epoch: 35 [67/250 8576/32000 (27%)] Loss: 1.13288 (QuantReg: 13.91247) QuantErr: 13.91247 batch_time=0.67203 
Train Epoch: 35 [78/250 9984/32000 (31%)] Loss: 0.81466 (QuantReg: 14.19923) QuantErr: 14.19923 batch_time=0.66078 
Train Epoch: 35 [89/250 11392/32000 (36%)] Loss: 0.78859 (QuantReg: 14.39786) QuantErr: 14.39786 batch_time=0.69159 
Train Epoch: 35 [100/250 12800/32000 (40%)] Loss: 0.95619 (QuantReg: 14.02520) QuantErr: 14.02520 batch_time=0.68129 
Train Epoch: 35 [111/250 14208/32000 (44%)] Loss: 0.79994 (QuantReg: 13.99042) QuantErr: 13.99042 batch_time=0.92547 
Train Epoch: 35 [122/250 15616/32000 (49%)] Loss: 0.67083 (QuantReg: 14.27563) QuantErr: 14.27563 batch_time=0.70249 
Train Epoch: 35 [133/250 17024/32000 (53%)] Loss: 0.72650 (QuantReg: 14.10200) QuantErr: 14.10200 batch_time=0.75743 
Train Epoch: 35 [144/250 18432/32000 (58%)] Loss: 1.25867 (QuantReg: 13.91776) QuantErr: 13.91776 batch_time=0.72816 
Train Epoch: 35 [155/250 19840/32000 (62%)] Loss: 0.79906 (QuantReg: 14.11065) QuantErr: 14.11065 batch_time=0.72517 
Train Epoch: 35 [166/250 21248/32000 (66%)] Loss: 0.94489 (QuantReg: 14.15660) QuantErr: 14.15660 batch_time=0.66185 
Train Epoch: 35 [177/250 22656/32000 (71%)] Loss: 0.75181 (QuantReg: 14.34331) QuantErr: 14.34331 batch_time=0.65716 
Train Epoch: 35 [188/250 24064/32000 (75%)] Loss: 0.86571 (QuantReg: 14.33136) QuantErr: 14.33136 batch_time=0.66946 
Train Epoch: 35 [199/250 25472/32000 (80%)] Loss: 0.73114 (QuantReg: 14.16726) QuantErr: 14.16726 batch_time=0.75013 
Train Epoch: 35 [210/250 26880/32000 (84%)] Loss: 0.74740 (QuantReg: 14.35625) QuantErr: 14.35625 batch_time=1.39281 
Train Epoch: 35 [221/250 28288/32000 (88%)] Loss: 0.81822 (QuantReg: 14.34870) QuantErr: 14.34870 batch_time=0.64803 
Train Epoch: 35 [232/250 29696/32000 (93%)] Loss: 1.07870 (QuantReg: 14.05384) QuantErr: 14.05384 batch_time=0.65654 
Train Epoch: 35 [243/250 31104/32000 (97%)] Loss: 0.66233 (QuantReg: 14.26418) QuantErr: 14.26418 batch_time=0.72607 
Train Epoch: 35 codebook_update_time=1.78471
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_MSRVTT_1kA_roberta-large/checkpoint-epoch35.pth ...
Done in 25.980s
removing stale ckpt [epoch 34] [took 0.00s]
 epoch          : 35
 loss           : 0.8507822887897492
 quant_reg      : 14.173859107971191
 quant_err      : 14.173859107971191
 learning_rate  : 8.74123073618985e-06
 n_samples      : 1120000
 n_steps        : 8750
 MSRVTT_jsfusion_test/t2v_metrics/R1: 25.2
 MSRVTT_jsfusion_test/t2v_metrics/R5: 55.5
 MSRVTT_jsfusion_test/t2v_metrics/R10: 68.5
 MSRVTT_jsfusion_test/t2v_metrics/R50: 88.5
 MSRVTT_jsfusion_test/t2v_metrics/MedR: 4.0
 MSRVTT_jsfusion_test/t2v_metrics/MeanR: 29.736
 MSRVTT_jsfusion_test/t2v_metrics/geometric_mean_R1-R5-R10: 45.75740272578999
 MSRVTT_jsfusion_test/v2t_metrics/R1: 27.9
 MSRVTT_jsfusion_test/v2t_metrics/R5: 57.8
 MSRVTT_jsfusion_test/v2t_metrics/R10: 69.3
 MSRVTT_jsfusion_test/v2t_metrics/R50: 89.2
 MSRVTT_jsfusion_test/v2t_metrics/MedR: 4.0
 MSRVTT_jsfusion_test/v2t_metrics/MeanR: 25.9615
 MSRVTT_jsfusion_test/v2t_metrics/geometric_mean_R1-R5-R10: 48.167609362557165
 mnt_best       : 46.251609274415934
 not_improved_count: 4
Train Epoch: 36 [1/250 128/32000 (0%)] Loss: 0.81410 (QuantReg: 14.13725) QuantErr: 14.13725 batch_time=31.61943 
Train Epoch: 36 [12/250 1536/32000 (5%)] Loss: 1.16398 (QuantReg: 14.27629) QuantErr: 14.27629 batch_time=0.67113 
Train Epoch: 36 [23/250 2944/32000 (9%)] Loss: 0.86504 (QuantReg: 14.35014) QuantErr: 14.35014 batch_time=0.70165 
Train Epoch: 36 [34/250 4352/32000 (14%)] Loss: 0.78662 (QuantReg: 14.40653) QuantErr: 14.40653 batch_time=0.65973 
Train Epoch: 36 [45/250 5760/32000 (18%)] Loss: 0.91063 (QuantReg: 13.71491) QuantErr: 13.71491 batch_time=0.66470 
Train Epoch: 36 [56/250 7168/32000 (22%)] Loss: 0.68809 (QuantReg: 14.15957) QuantErr: 14.15957 batch_time=0.65131 
Train Epoch: 36 [67/250 8576/32000 (27%)] Loss: 0.68182 (QuantReg: 14.50219) QuantErr: 14.50219 batch_time=0.75295 
Train Epoch: 36 [78/250 9984/32000 (31%)] Loss: 0.85326 (QuantReg: 13.99889) QuantErr: 13.99889 batch_time=0.76168 
Train Epoch: 36 [89/250 11392/32000 (36%)] Loss: 0.62673 (QuantReg: 14.40537) QuantErr: 14.40537 batch_time=1.37742 
Train Epoch: 36 [100/250 12800/32000 (40%)] Loss: 1.07096 (QuantReg: 14.00528) QuantErr: 14.00528 batch_time=0.66905 
Train Epoch: 36 [111/250 14208/32000 (44%)] Loss: 0.64283 (QuantReg: 14.24708) QuantErr: 14.24708 batch_time=0.71505 
Train Epoch: 36 [122/250 15616/32000 (49%)] Loss: 0.83818 (QuantReg: 14.02069) QuantErr: 14.02069 batch_time=0.77374 
Train Epoch: 36 [133/250 17024/32000 (53%)] Loss: 0.64938 (QuantReg: 14.11441) QuantErr: 14.11441 batch_time=0.68194 
Train Epoch: 36 [144/250 18432/32000 (58%)] Loss: 0.62646 (QuantReg: 14.38896) QuantErr: 14.38896 batch_time=0.71098 
Train Epoch: 36 [155/250 19840/32000 (62%)] Loss: 0.85420 (QuantReg: 13.92100) QuantErr: 13.92100 batch_time=0.66501 
Train Epoch: 36 [166/250 21248/32000 (66%)] Loss: 0.93458 (QuantReg: 13.75861) QuantErr: 13.75861 batch_time=0.67851 
Train Epoch: 36 [177/250 22656/32000 (71%)] Loss: 0.84881 (QuantReg: 14.33572) QuantErr: 14.33572 batch_time=0.66046 
Train Epoch: 36 [188/250 24064/32000 (75%)] Loss: 0.70734 (QuantReg: 14.29683) QuantErr: 14.29683 batch_time=0.65900 
Train Epoch: 36 [199/250 25472/32000 (80%)] Loss: 1.00143 (QuantReg: 14.38978) QuantErr: 14.38978 batch_time=0.81076 
Train Epoch: 36 [210/250 26880/32000 (84%)] Loss: 0.96751 (QuantReg: 14.23207) QuantErr: 14.23207 batch_time=0.64882 
Train Epoch: 36 [221/250 28288/32000 (88%)] Loss: 0.63159 (QuantReg: 14.47666) QuantErr: 14.47666 batch_time=0.64850 
Train Epoch: 36 [232/250 29696/32000 (93%)] Loss: 0.82985 (QuantReg: 14.44671) QuantErr: 14.44671 batch_time=0.65032 
Train Epoch: 36 [243/250 31104/32000 (97%)] Loss: 0.77470 (QuantReg: 14.31387) QuantErr: 14.31387 batch_time=0.66206 
Train Epoch: 36 codebook_update_time=1.71643
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_MSRVTT_1kA_roberta-large/checkpoint-epoch36.pth ...
Done in 11.028s
removing stale ckpt [epoch 35] [took 0.00s]
 epoch          : 36
 loss           : 0.8305607373714448
 quant_reg      : 14.217325099945068
 quant_err      : 14.217325099945068
 learning_rate  : 8.304169199380357e-06
 n_samples      : 1152000
 n_steps        : 9000
 MSRVTT_jsfusion_test/t2v_metrics/R1: 25.1
 MSRVTT_jsfusion_test/t2v_metrics/R5: 54.3
 MSRVTT_jsfusion_test/t2v_metrics/R10: 67.4
 MSRVTT_jsfusion_test/t2v_metrics/R50: 88.0
 MSRVTT_jsfusion_test/t2v_metrics/MedR: 4.0
 MSRVTT_jsfusion_test/t2v_metrics/MeanR: 29.545
 MSRVTT_jsfusion_test/t2v_metrics/geometric_mean_R1-R5-R10: 45.12090646127954
 MSRVTT_jsfusion_test/v2t_metrics/R1: 26.6
 MSRVTT_jsfusion_test/v2t_metrics/R5: 57.9
 MSRVTT_jsfusion_test/v2t_metrics/R10: 68.6
 MSRVTT_jsfusion_test/v2t_metrics/R50: 89.5
 MSRVTT_jsfusion_test/v2t_metrics/MedR: 4.0
 MSRVTT_jsfusion_test/v2t_metrics/MeanR: 26.047
 MSRVTT_jsfusion_test/v2t_metrics/geometric_mean_R1-R5-R10: 47.27462639447703
 mnt_best       : 46.251609274415934
 not_improved_count: 5
Train Epoch: 37 [1/250 128/32000 (0%)] Loss: 0.61940 (QuantReg: 13.78268) QuantErr: 13.78268 batch_time=35.53136 
Train Epoch: 37 [12/250 1536/32000 (5%)] Loss: 0.73807 (QuantReg: 14.23359) QuantErr: 14.23359 batch_time=0.65884 
Train Epoch: 37 [23/250 2944/32000 (9%)] Loss: 0.84462 (QuantReg: 14.02197) QuantErr: 14.02197 batch_time=0.72223 
Train Epoch: 37 [34/250 4352/32000 (14%)] Loss: 1.00303 (QuantReg: 14.26089) QuantErr: 14.26089 batch_time=0.74394 
Train Epoch: 37 [45/250 5760/32000 (18%)] Loss: 1.11821 (QuantReg: 13.89134) QuantErr: 13.89134 batch_time=0.66730 
Train Epoch: 37 [56/250 7168/32000 (22%)] Loss: 0.96068 (QuantReg: 14.09884) QuantErr: 14.09884 batch_time=0.95691 
Train Epoch: 37 [67/250 8576/32000 (27%)] Loss: 0.74906 (QuantReg: 14.24339) QuantErr: 14.24339 batch_time=0.66236 
Train Epoch: 37 [78/250 9984/32000 (31%)] Loss: 0.69745 (QuantReg: 14.02979) QuantErr: 14.02979 batch_time=0.68086 
Train Epoch: 37 [89/250 11392/32000 (36%)] Loss: 0.65445 (QuantReg: 14.18046) QuantErr: 14.18046 batch_time=0.67239 
Train Epoch: 37 [100/250 12800/32000 (40%)] Loss: 0.80891 (QuantReg: 14.09520) QuantErr: 14.09520 batch_time=0.73187 
Train Epoch: 37 [111/250 14208/32000 (44%)] Loss: 0.59128 (QuantReg: 14.49959) QuantErr: 14.49959 batch_time=0.65743 
Train Epoch: 37 [122/250 15616/32000 (49%)] Loss: 0.91871 (QuantReg: 14.17343) QuantErr: 14.17343 batch_time=0.65919 
Train Epoch: 37 [133/250 17024/32000 (53%)] Loss: 0.78158 (QuantReg: 14.42602) QuantErr: 14.42602 batch_time=0.72458 
Train Epoch: 37 [144/250 18432/32000 (58%)] Loss: 0.91392 (QuantReg: 14.20753) QuantErr: 14.20753 batch_time=0.70639 
Train Epoch: 37 [155/250 19840/32000 (62%)] Loss: 1.02438 (QuantReg: 14.05068) QuantErr: 14.05068 batch_time=0.72452 
Train Epoch: 37 [166/250 21248/32000 (66%)] Loss: 0.80053 (QuantReg: 14.01331) QuantErr: 14.01331 batch_time=0.65999 
Train Epoch: 37 [177/250 22656/32000 (71%)] Loss: 0.78122 (QuantReg: 13.99364) QuantErr: 13.99364 batch_time=0.89353 
Train Epoch: 37 [188/250 24064/32000 (75%)] Loss: 1.09791 (QuantReg: 13.95312) QuantErr: 13.95312 batch_time=0.70975 
Train Epoch: 37 [199/250 25472/32000 (80%)] Loss: 0.68998 (QuantReg: 14.28312) QuantErr: 14.28312 batch_time=0.65079 
Train Epoch: 37 [210/250 26880/32000 (84%)] Loss: 1.08374 (QuantReg: 14.13277) QuantErr: 14.13277 batch_time=0.69280 
Train Epoch: 37 [221/250 28288/32000 (88%)] Loss: 0.80198 (QuantReg: 13.82008) QuantErr: 13.82008 batch_time=0.69020 
Train Epoch: 37 [232/250 29696/32000 (93%)] Loss: 0.75688 (QuantReg: 14.15705) QuantErr: 14.15705 batch_time=0.66534 
Train Epoch: 37 [243/250 31104/32000 (97%)] Loss: 0.81342 (QuantReg: 14.20557) QuantErr: 14.20557 batch_time=0.67364 
Train Epoch: 37 codebook_update_time=1.83529
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_MSRVTT_1kA_roberta-large/checkpoint-epoch37.pth ...
Done in 10.895s
removing stale ckpt [epoch 36] [took 0.00s]
 epoch          : 37
 loss           : 0.8092655888795852
 quant_reg      : 14.194272747039795
 quant_err      : 14.194272747039795
 learning_rate  : 7.888960739411339e-06
 n_samples      : 1184000
 n_steps        : 9250
 MSRVTT_jsfusion_test/t2v_metrics/R1: 25.4
 MSRVTT_jsfusion_test/t2v_metrics/R5: 54.5
 MSRVTT_jsfusion_test/t2v_metrics/R10: 67.8
 MSRVTT_jsfusion_test/t2v_metrics/R50: 88.6
 MSRVTT_jsfusion_test/t2v_metrics/MedR: 4.0
 MSRVTT_jsfusion_test/t2v_metrics/MeanR: 29.757
 MSRVTT_jsfusion_test/t2v_metrics/geometric_mean_R1-R5-R10: 45.445055441840694
 MSRVTT_jsfusion_test/v2t_metrics/R1: 27.1
 MSRVTT_jsfusion_test/v2t_metrics/R5: 57.7
 MSRVTT_jsfusion_test/v2t_metrics/R10: 69.6
 MSRVTT_jsfusion_test/v2t_metrics/R50: 89.2
 MSRVTT_jsfusion_test/v2t_metrics/MedR: 4.0
 MSRVTT_jsfusion_test/v2t_metrics/MeanR: 26.099
 MSRVTT_jsfusion_test/v2t_metrics/geometric_mean_R1-R5-R10: 47.743924484905854
 mnt_best       : 46.251609274415934
 not_improved_count: 6
Train Epoch: 38 [1/250 128/32000 (0%)] Loss: 0.57795 (QuantReg: 14.28559) QuantErr: 14.28559 batch_time=33.37719 
Train Epoch: 38 [12/250 1536/32000 (5%)] Loss: 0.90344 (QuantReg: 14.22545) QuantErr: 14.22545 batch_time=0.72292 
Train Epoch: 38 [23/250 2944/32000 (9%)] Loss: 0.84492 (QuantReg: 14.36438) QuantErr: 14.36438 batch_time=1.06045 
Train Epoch: 38 [34/250 4352/32000 (14%)] Loss: 0.88970 (QuantReg: 14.15294) QuantErr: 14.15294 batch_time=0.71126 
Train Epoch: 38 [45/250 5760/32000 (18%)] Loss: 0.82984 (QuantReg: 14.23991) QuantErr: 14.23991 batch_time=0.66718 
Train Epoch: 38 [56/250 7168/32000 (22%)] Loss: 0.81050 (QuantReg: 14.17793) QuantErr: 14.17793 batch_time=0.66387 
Train Epoch: 38 [67/250 8576/32000 (27%)] Loss: 0.77986 (QuantReg: 14.13016) QuantErr: 14.13016 batch_time=0.72638 
Train Epoch: 38 [78/250 9984/32000 (31%)] Loss: 0.82492 (QuantReg: 14.23443) QuantErr: 14.23443 batch_time=0.66810 
Train Epoch: 38 [89/250 11392/32000 (36%)] Loss: 0.75754 (QuantReg: 13.99112) QuantErr: 13.99112 batch_time=0.66148 
Train Epoch: 38 [100/250 12800/32000 (40%)] Loss: 0.87073 (QuantReg: 14.30775) QuantErr: 14.30775 batch_time=0.70976 
Train Epoch: 38 [111/250 14208/32000 (44%)] Loss: 0.73514 (QuantReg: 14.25275) QuantErr: 14.25275 batch_time=0.72903 
Train Epoch: 38 [122/250 15616/32000 (49%)] Loss: 0.86795 (QuantReg: 14.20931) QuantErr: 14.20931 batch_time=0.65919 
Train Epoch: 38 [133/250 17024/32000 (53%)] Loss: 0.76406 (QuantReg: 14.39890) QuantErr: 14.39890 batch_time=0.67322 
Train Epoch: 38 [144/250 18432/32000 (58%)] Loss: 1.08155 (QuantReg: 14.07602) QuantErr: 14.07602 batch_time=1.02346 
Train Epoch: 38 [155/250 19840/32000 (62%)] Loss: 0.68674 (QuantReg: 14.28170) QuantErr: 14.28170 batch_time=3.68954 
Train Epoch: 38 [166/250 21248/32000 (66%)] Loss: 1.07173 (QuantReg: 14.07001) QuantErr: 14.07001 batch_time=0.72104 
Train Epoch: 38 [177/250 22656/32000 (71%)] Loss: 0.58883 (QuantReg: 14.41387) QuantErr: 14.41387 batch_time=0.66034 
Train Epoch: 38 [188/250 24064/32000 (75%)] Loss: 0.72250 (QuantReg: 14.14475) QuantErr: 14.14475 batch_time=0.66690 
Train Epoch: 38 [199/250 25472/32000 (80%)] Loss: 0.80758 (QuantReg: 14.11009) QuantErr: 14.11009 batch_time=0.65513 
Train Epoch: 38 [210/250 26880/32000 (84%)] Loss: 0.82050 (QuantReg: 14.29452) QuantErr: 14.29452 batch_time=0.65547 
Train Epoch: 38 [221/250 28288/32000 (88%)] Loss: 0.69500 (QuantReg: 14.39085) QuantErr: 14.39085 batch_time=0.67381 
Train Epoch: 38 [232/250 29696/32000 (93%)] Loss: 0.71720 (QuantReg: 14.00750) QuantErr: 14.00750 batch_time=0.68112 
Train Epoch: 38 [243/250 31104/32000 (97%)] Loss: 0.90309 (QuantReg: 14.31624) QuantErr: 14.31624 batch_time=0.70226 
Train Epoch: 38 codebook_update_time=1.93163
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_MSRVTT_1kA_roberta-large/checkpoint-epoch38.pth ...
Done in 10.528s
Updating 'best' checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_MSRVTT_1kA_roberta-large/checkpoint-epoch38.pth ...
Done in 21.175s
removing stale ckpt [epoch 37] [took 0.00s]
 epoch          : 38
 loss           : 0.8003488202095032
 quant_reg      : 14.214524909973145
 quant_err      : 14.214524909973145
 learning_rate  : 7.494512702440772e-06
 n_samples      : 1216000
 n_steps        : 9500
 MSRVTT_jsfusion_test/t2v_metrics/R1: 25.6
 MSRVTT_jsfusion_test/t2v_metrics/R5: 56.3
 MSRVTT_jsfusion_test/t2v_metrics/R10: 69.0
 MSRVTT_jsfusion_test/t2v_metrics/R50: 88.9
 MSRVTT_jsfusion_test/t2v_metrics/MedR: 4.0
 MSRVTT_jsfusion_test/t2v_metrics/MeanR: 30.514
 MSRVTT_jsfusion_test/t2v_metrics/geometric_mean_R1-R5-R10: 46.33037516553154
 MSRVTT_jsfusion_test/v2t_metrics/R1: 27.5
 MSRVTT_jsfusion_test/v2t_metrics/R5: 58.6
 MSRVTT_jsfusion_test/v2t_metrics/R10: 69.5
 MSRVTT_jsfusion_test/v2t_metrics/R50: 89.5
 MSRVTT_jsfusion_test/v2t_metrics/MedR: 4.0
 MSRVTT_jsfusion_test/v2t_metrics/MeanR: 26.3
 MSRVTT_jsfusion_test/v2t_metrics/geometric_mean_R1-R5-R10: 48.20273768762762
 mnt_best       : 46.33037516553154
 not_improved_count: 0
Train Epoch: 39 [1/250 128/32000 (0%)] Loss: 0.85788 (QuantReg: 13.92868) QuantErr: 13.92868 batch_time=33.39303 
Train Epoch: 39 [12/250 1536/32000 (5%)] Loss: 0.88214 (QuantReg: 14.11527) QuantErr: 14.11527 batch_time=0.65669 
Train Epoch: 39 [23/250 2944/32000 (9%)] Loss: 0.73119 (QuantReg: 14.20158) QuantErr: 14.20158 batch_time=0.66163 
Train Epoch: 39 [34/250 4352/32000 (14%)] Loss: 0.78894 (QuantReg: 14.20721) QuantErr: 14.20721 batch_time=0.70215 
Train Epoch: 39 [45/250 5760/32000 (18%)] Loss: 0.85149 (QuantReg: 14.12785) QuantErr: 14.12785 batch_time=0.67708 
Train Epoch: 39 [56/250 7168/32000 (22%)] Loss: 0.52175 (QuantReg: 13.95485) QuantErr: 13.95485 batch_time=0.75939 
Train Epoch: 39 [67/250 8576/32000 (27%)] Loss: 0.65750 (QuantReg: 14.25921) QuantErr: 14.25921 batch_time=1.72608 
Train Epoch: 39 [78/250 9984/32000 (31%)] Loss: 0.90605 (QuantReg: 14.27952) QuantErr: 14.27952 batch_time=0.65302 
Train Epoch: 39 [89/250 11392/32000 (36%)] Loss: 0.83548 (QuantReg: 14.04349) QuantErr: 14.04349 batch_time=0.66713 
Train Epoch: 39 [100/250 12800/32000 (40%)] Loss: 0.80614 (QuantReg: 14.17871) QuantErr: 14.17871 batch_time=0.69686 
Train Epoch: 39 [111/250 14208/32000 (44%)] Loss: 0.91279 (QuantReg: 14.18138) QuantErr: 14.18138 batch_time=0.69749 
Train Epoch: 39 [122/250 15616/32000 (49%)] Loss: 0.71169 (QuantReg: 14.19884) QuantErr: 14.19884 batch_time=0.70964 
Train Epoch: 39 [133/250 17024/32000 (53%)] Loss: 0.65221 (QuantReg: 14.41683) QuantErr: 14.41683 batch_time=1.02363 
Train Epoch: 39 [144/250 18432/32000 (58%)] Loss: 0.95756 (QuantReg: 14.09083) QuantErr: 14.09083 batch_time=4.99557 
Train Epoch: 39 [155/250 19840/32000 (62%)] Loss: 0.78019 (QuantReg: 14.43987) QuantErr: 14.43987 batch_time=0.70098 
Train Epoch: 39 [166/250 21248/32000 (66%)] Loss: 0.57324 (QuantReg: 14.33092) QuantErr: 14.33092 batch_time=0.67276 
Train Epoch: 39 [177/250 22656/32000 (71%)] Loss: 0.98174 (QuantReg: 13.95952) QuantErr: 13.95952 batch_time=0.69287 
Train Epoch: 39 [188/250 24064/32000 (75%)] Loss: 0.70009 (QuantReg: 14.33251) QuantErr: 14.33251 batch_time=0.66656 
Train Epoch: 39 [199/250 25472/32000 (80%)] Loss: 0.78580 (QuantReg: 14.39708) QuantErr: 14.39708 batch_time=0.67527 
Train Epoch: 39 [210/250 26880/32000 (84%)] Loss: 0.65516 (QuantReg: 14.55977) QuantErr: 14.55977 batch_time=0.71113 
Train Epoch: 39 [221/250 28288/32000 (88%)] Loss: 0.50046 (QuantReg: 14.15592) QuantErr: 14.15592 batch_time=0.66407 
Train Epoch: 39 [232/250 29696/32000 (93%)] Loss: 0.66842 (QuantReg: 14.11586) QuantErr: 14.11586 batch_time=0.77893 
Train Epoch: 39 [243/250 31104/32000 (97%)] Loss: 1.02651 (QuantReg: 14.25146) QuantErr: 14.25146 batch_time=0.66456 
Train Epoch: 39 codebook_update_time=1.88287
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_MSRVTT_1kA_roberta-large/checkpoint-epoch39.pth ...
Done in 11.221s
Updating 'best' checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_MSRVTT_1kA_roberta-large/checkpoint-epoch39.pth ...
Done in 22.544s
removing stale ckpt [epoch 38] [took 0.10s]
 epoch          : 39
 loss           : 0.8168932334184646
 quant_reg      : 14.232210327148438
 quant_err      : 14.232210327148438
 learning_rate  : 7.119787067318733e-06
 n_samples      : 1248000
 n_steps        : 9750
 MSRVTT_jsfusion_test/t2v_metrics/R1: 27.1
 MSRVTT_jsfusion_test/t2v_metrics/R5: 56.2
 MSRVTT_jsfusion_test/t2v_metrics/R10: 67.9
 MSRVTT_jsfusion_test/t2v_metrics/R50: 88.6
 MSRVTT_jsfusion_test/t2v_metrics/MedR: 4.0
 MSRVTT_jsfusion_test/t2v_metrics/MeanR: 30.176
 MSRVTT_jsfusion_test/t2v_metrics/geometric_mean_R1-R5-R10: 46.93805904110926
 MSRVTT_jsfusion_test/v2t_metrics/R1: 27.9
 MSRVTT_jsfusion_test/v2t_metrics/R5: 58.4
 MSRVTT_jsfusion_test/v2t_metrics/R10: 70.1
 MSRVTT_jsfusion_test/v2t_metrics/R50: 89.8
 MSRVTT_jsfusion_test/v2t_metrics/MedR: 4.0
 MSRVTT_jsfusion_test/v2t_metrics/MeanR: 26.015
 MSRVTT_jsfusion_test/v2t_metrics/geometric_mean_R1-R5-R10: 48.51898303913189
 mnt_best       : 46.93805904110926
 not_improved_count: 0
Train Epoch: 40 [1/250 128/32000 (0%)] Loss: 0.66465 (QuantReg: 14.16432) QuantErr: 14.16432 batch_time=28.64787 
Train Epoch: 40 [12/250 1536/32000 (5%)] Loss: 0.70053 (QuantReg: 14.23801) QuantErr: 14.23801 batch_time=0.65757 
Train Epoch: 40 [23/250 2944/32000 (9%)] Loss: 0.76557 (QuantReg: 14.41960) QuantErr: 14.41960 batch_time=0.95365 
Train Epoch: 40 [34/250 4352/32000 (14%)] Loss: 0.67060 (QuantReg: 14.23473) QuantErr: 14.23473 batch_time=0.65936 
Train Epoch: 40 [45/250 5760/32000 (18%)] Loss: 0.79409 (QuantReg: 14.11772) QuantErr: 14.11772 batch_time=0.66033 
Train Epoch: 40 [56/250 7168/32000 (22%)] Loss: 0.89799 (QuantReg: 13.94468) QuantErr: 13.94468 batch_time=0.66198 
Train Epoch: 40 [67/250 8576/32000 (27%)] Loss: 0.54741 (QuantReg: 14.42036) QuantErr: 14.42036 batch_time=0.94780 
Train Epoch: 40 [78/250 9984/32000 (31%)] Loss: 0.87039 (QuantReg: 14.31472) QuantErr: 14.31472 batch_time=1.09391 
Train Epoch: 40 [89/250 11392/32000 (36%)] Loss: 0.78257 (QuantReg: 14.06810) QuantErr: 14.06810 batch_time=0.68539 
Train Epoch: 40 [100/250 12800/32000 (40%)] Loss: 0.61893 (QuantReg: 14.38958) QuantErr: 14.38958 batch_time=0.65971 
Train Epoch: 40 [111/250 14208/32000 (44%)] Loss: 0.74095 (QuantReg: 14.45575) QuantErr: 14.45575 batch_time=0.67313 
Train Epoch: 40 [122/250 15616/32000 (49%)] Loss: 0.63116 (QuantReg: 14.44872) QuantErr: 14.44872 batch_time=0.66659 
Train Epoch: 40 [133/250 17024/32000 (53%)] Loss: 0.84607 (QuantReg: 14.24459) QuantErr: 14.24459 batch_time=0.67802 
Train Epoch: 40 [144/250 18432/32000 (58%)] Loss: 1.30900 (QuantReg: 14.11394) QuantErr: 14.11394 batch_time=0.69733 
Train Epoch: 40 [155/250 19840/32000 (62%)] Loss: 0.51041 (QuantReg: 14.23289) QuantErr: 14.23289 batch_time=0.66613 
Train Epoch: 40 [166/250 21248/32000 (66%)] Loss: 0.77331 (QuantReg: 14.06360) QuantErr: 14.06360 batch_time=0.68981 
Train Epoch: 40 [177/250 22656/32000 (71%)] Loss: 0.87627 (QuantReg: 14.23198) QuantErr: 14.23198 batch_time=0.65784 
Train Epoch: 40 [188/250 24064/32000 (75%)] Loss: 0.80563 (QuantReg: 14.32383) QuantErr: 14.32383 batch_time=0.69948 
Train Epoch: 40 [199/250 25472/32000 (80%)] Loss: 0.75333 (QuantReg: 14.23234) QuantErr: 14.23234 batch_time=0.66752 
Train Epoch: 40 [210/250 26880/32000 (84%)] Loss: 0.77879 (QuantReg: 14.46613) QuantErr: 14.46613 batch_time=4.88927 
Train Epoch: 40 [221/250 28288/32000 (88%)] Loss: 0.89464 (QuantReg: 14.28472) QuantErr: 14.28472 batch_time=0.66150 
Train Epoch: 40 [232/250 29696/32000 (93%)] Loss: 0.84440 (QuantReg: 14.12047) QuantErr: 14.12047 batch_time=0.68219 
Train Epoch: 40 [243/250 31104/32000 (97%)] Loss: 0.90853 (QuantReg: 14.56603) QuantErr: 14.56603 batch_time=0.66816 
Train Epoch: 40 codebook_update_time=1.91842
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_MSRVTT_1kA_roberta-large/checkpoint-epoch40.pth ...
Done in 16.594s
Updating 'best' checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_MSRVTT_1kA_roberta-large/checkpoint-epoch40.pth ...
Done in 37.607s
removing stale ckpt [epoch 39] [took 0.00s]
 epoch          : 40
 loss           : 0.7937686879634858
 quant_reg      : 14.26182548904419
 quant_err      : 14.26182548904419
 learning_rate  : 6.763797713952796e-06
 n_samples      : 1280000
 n_steps        : 10000
 MSRVTT_jsfusion_test/t2v_metrics/R1: 28.0
 MSRVTT_jsfusion_test/t2v_metrics/R5: 55.4
 MSRVTT_jsfusion_test/t2v_metrics/R10: 68.5
 MSRVTT_jsfusion_test/t2v_metrics/R50: 88.1
 MSRVTT_jsfusion_test/t2v_metrics/MedR: 4.0
 MSRVTT_jsfusion_test/t2v_metrics/MeanR: 30.666
 MSRVTT_jsfusion_test/t2v_metrics/geometric_mean_R1-R5-R10: 47.36448169102165
 MSRVTT_jsfusion_test/v2t_metrics/R1: 27.0
 MSRVTT_jsfusion_test/v2t_metrics/R5: 59.0
 MSRVTT_jsfusion_test/v2t_metrics/R10: 68.4
 MSRVTT_jsfusion_test/v2t_metrics/R50: 88.5
 MSRVTT_jsfusion_test/v2t_metrics/MedR: 4.0
 MSRVTT_jsfusion_test/v2t_metrics/MeanR: 27.412
 MSRVTT_jsfusion_test/v2t_metrics/geometric_mean_R1-R5-R10: 47.76289318601298
 mnt_best       : 47.36448169102165
 not_improved_count: 0
Train Epoch: 41 [1/250 128/32000 (0%)] Loss: 0.86557 (QuantReg: 14.31828) QuantErr: 14.31828 batch_time=31.83536 
Train Epoch: 41 [12/250 1536/32000 (5%)] Loss: 0.86932 (QuantReg: 14.13899) QuantErr: 14.13899 batch_time=0.65258 
Train Epoch: 41 [23/250 2944/32000 (9%)] Loss: 0.84347 (QuantReg: 14.15306) QuantErr: 14.15306 batch_time=0.83482 
Train Epoch: 41 [34/250 4352/32000 (14%)] Loss: 0.69462 (QuantReg: 14.06556) QuantErr: 14.06556 batch_time=0.65105 
Train Epoch: 41 [45/250 5760/32000 (18%)] Loss: 0.81281 (QuantReg: 14.15232) QuantErr: 14.15232 batch_time=0.65287 
Train Epoch: 41 [56/250 7168/32000 (22%)] Loss: 0.74433 (QuantReg: 14.10651) QuantErr: 14.10651 batch_time=0.65002 
Train Epoch: 41 [67/250 8576/32000 (27%)] Loss: 0.85225 (QuantReg: 14.17526) QuantErr: 14.17526 batch_time=0.65742 
Train Epoch: 41 [78/250 9984/32000 (31%)] Loss: 0.69307 (QuantReg: 14.25407) QuantErr: 14.25407 batch_time=0.66102 
Train Epoch: 41 [89/250 11392/32000 (36%)] Loss: 0.94409 (QuantReg: 14.26467) QuantErr: 14.26467 batch_time=0.67327 
Train Epoch: 41 [100/250 12800/32000 (40%)] Loss: 0.75611 (QuantReg: 14.31135) QuantErr: 14.31135 batch_time=1.23128 
Train Epoch: 41 [111/250 14208/32000 (44%)] Loss: 0.73015 (QuantReg: 14.40838) QuantErr: 14.40838 batch_time=0.69821 
Train Epoch: 41 [122/250 15616/32000 (49%)] Loss: 0.99072 (QuantReg: 14.04666) QuantErr: 14.04666 batch_time=0.66246 
Train Epoch: 41 [133/250 17024/32000 (53%)] Loss: 0.51055 (QuantReg: 14.32332) QuantErr: 14.32332 batch_time=0.65711 
Train Epoch: 41 [144/250 18432/32000 (58%)] Loss: 0.71223 (QuantReg: 14.25936) QuantErr: 14.25936 batch_time=3.49669 
Train Epoch: 41 [155/250 19840/32000 (62%)] Loss: 0.68523 (QuantReg: 14.31434) QuantErr: 14.31434 batch_time=0.66168 
Train Epoch: 41 [166/250 21248/32000 (66%)] Loss: 0.69221 (QuantReg: 14.21962) QuantErr: 14.21962 batch_time=0.64909 
Train Epoch: 41 [177/250 22656/32000 (71%)] Loss: 0.77668 (QuantReg: 14.42209) QuantErr: 14.42209 batch_time=0.65892 
Train Epoch: 41 [188/250 24064/32000 (75%)] Loss: 0.71321 (QuantReg: 14.42222) QuantErr: 14.42222 batch_time=0.66594 
Train Epoch: 41 [199/250 25472/32000 (80%)] Loss: 1.01188 (QuantReg: 14.28931) QuantErr: 14.28931 batch_time=0.65142 
Train Epoch: 41 [210/250 26880/32000 (84%)] Loss: 1.07216 (QuantReg: 14.10308) QuantErr: 14.10308 batch_time=0.65447 
Train Epoch: 41 [221/250 28288/32000 (88%)] Loss: 0.59874 (QuantReg: 14.47265) QuantErr: 14.47265 batch_time=0.68019 
Train Epoch: 41 [232/250 29696/32000 (93%)] Loss: 0.86590 (QuantReg: 14.22737) QuantErr: 14.22737 batch_time=0.67649 
Train Epoch: 41 [243/250 31104/32000 (97%)] Loss: 0.79681 (QuantReg: 14.27790) QuantErr: 14.27790 batch_time=0.68236 
Train Epoch: 41 codebook_update_time=1.90479
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_MSRVTT_1kA_roberta-large/checkpoint-epoch41.pth ...
Done in 11.209s
removing stale ckpt [epoch 40] [took 0.00s]
 epoch          : 41
 loss           : 0.8046016601324082
 quant_reg      : 14.262006706237793
 quant_err      : 14.262006706237793
 learning_rate  : 6.425607828255156e-06
 n_samples      : 1312000
 n_steps        : 10250
 MSRVTT_jsfusion_test/t2v_metrics/R1: 27.2
 MSRVTT_jsfusion_test/t2v_metrics/R5: 55.3
 MSRVTT_jsfusion_test/t2v_metrics/R10: 68.7
 MSRVTT_jsfusion_test/t2v_metrics/R50: 87.8
 MSRVTT_jsfusion_test/t2v_metrics/MedR: 4.0
 MSRVTT_jsfusion_test/t2v_metrics/MeanR: 30.121
 MSRVTT_jsfusion_test/t2v_metrics/geometric_mean_R1-R5-R10: 46.92636606358241
 MSRVTT_jsfusion_test/v2t_metrics/R1: 27.8
 MSRVTT_jsfusion_test/v2t_metrics/R5: 58.1
 MSRVTT_jsfusion_test/v2t_metrics/R10: 68.4
 MSRVTT_jsfusion_test/v2t_metrics/R50: 89.0
 MSRVTT_jsfusion_test/v2t_metrics/MedR: 4.0
 MSRVTT_jsfusion_test/v2t_metrics/MeanR: 26.91
 MSRVTT_jsfusion_test/v2t_metrics/geometric_mean_R1-R5-R10: 47.98354644398808
 mnt_best       : 47.36448169102165
 not_improved_count: 1
Train Epoch: 42 [1/250 128/32000 (0%)] Loss: 0.85711 (QuantReg: 14.04276) QuantErr: 14.04276 batch_time=34.40776 
Train Epoch: 42 [12/250 1536/32000 (5%)] Loss: 0.78644 (QuantReg: 14.21842) QuantErr: 14.21842 batch_time=0.65304 
Train Epoch: 42 [23/250 2944/32000 (9%)] Loss: 0.79220 (QuantReg: 14.15826) QuantErr: 14.15826 batch_time=0.72010 
Train Epoch: 42 [34/250 4352/32000 (14%)] Loss: 0.88729 (QuantReg: 14.30638) QuantErr: 14.30638 batch_time=0.65398 
Train Epoch: 42 [45/250 5760/32000 (18%)] Loss: 0.97381 (QuantReg: 14.17224) QuantErr: 14.17224 batch_time=0.72027 
Train Epoch: 42 [56/250 7168/32000 (22%)] Loss: 0.86584 (QuantReg: 14.27297) QuantErr: 14.27297 batch_time=0.69243 
Train Epoch: 42 [67/250 8576/32000 (27%)] Loss: 0.71491 (QuantReg: 14.38718) QuantErr: 14.38718 batch_time=1.53252 
Train Epoch: 42 [78/250 9984/32000 (31%)] Loss: 0.86296 (QuantReg: 14.50011) QuantErr: 14.50011 batch_time=0.66408 
Train Epoch: 42 [89/250 11392/32000 (36%)] Loss: 0.90645 (QuantReg: 14.24986) QuantErr: 14.24986 batch_time=0.65331 
Train Epoch: 42 [100/250 12800/32000 (40%)] Loss: 0.95778 (QuantReg: 14.12492) QuantErr: 14.12492 batch_time=0.65989 
Train Epoch: 42 [111/250 14208/32000 (44%)] Loss: 0.97723 (QuantReg: 14.42689) QuantErr: 14.42689 batch_time=0.64950 
Train Epoch: 42 [122/250 15616/32000 (49%)] Loss: 1.01027 (QuantReg: 14.12090) QuantErr: 14.12090 batch_time=0.65110 
Train Epoch: 42 [133/250 17024/32000 (53%)] Loss: 0.61803 (QuantReg: 14.32988) QuantErr: 14.32988 batch_time=0.67498 
Train Epoch: 42 [144/250 18432/32000 (58%)] Loss: 0.76268 (QuantReg: 14.08313) QuantErr: 14.08313 batch_time=0.87643 
Train Epoch: 42 [155/250 19840/32000 (62%)] Loss: 0.82594 (QuantReg: 14.40342) QuantErr: 14.40342 batch_time=0.65456 
Train Epoch: 42 [166/250 21248/32000 (66%)] Loss: 1.17261 (QuantReg: 14.13753) QuantErr: 14.13753 batch_time=0.70241 
Train Epoch: 42 [177/250 22656/32000 (71%)] Loss: 0.71357 (QuantReg: 14.59227) QuantErr: 14.59227 batch_time=0.66507 
Train Epoch: 42 [188/250 24064/32000 (75%)] Loss: 0.75231 (QuantReg: 14.19552) QuantErr: 14.19552 batch_time=0.75465 
Train Epoch: 42 [199/250 25472/32000 (80%)] Loss: 0.69880 (QuantReg: 14.27678) QuantErr: 14.27678 batch_time=0.70825 
Train Epoch: 42 [210/250 26880/32000 (84%)] Loss: 0.83272 (QuantReg: 14.28907) QuantErr: 14.28907 batch_time=0.94741 
Train Epoch: 42 [221/250 28288/32000 (88%)] Loss: 0.63261 (QuantReg: 14.45129) QuantErr: 14.45129 batch_time=0.68858 
Train Epoch: 42 [232/250 29696/32000 (93%)] Loss: 0.83963 (QuantReg: 14.33500) QuantErr: 14.33500 batch_time=0.66010 
Train Epoch: 42 [243/250 31104/32000 (97%)] Loss: 0.80432 (QuantReg: 14.51587) QuantErr: 14.51587 batch_time=0.69070 
Train Epoch: 42 codebook_update_time=2.12739
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_MSRVTT_1kA_roberta-large/checkpoint-epoch42.pth ...
Done in 26.111s
removing stale ckpt [epoch 41] [took 0.10s]
 epoch          : 42
 loss           : 0.7938462266921997
 quant_reg      : 14.29976682662964
 quant_err      : 14.29976682662964
 learning_rate  : 6.104327436842398e-06
 n_samples      : 1344000
 n_steps        : 10500
 MSRVTT_jsfusion_test/t2v_metrics/R1: 26.2
 MSRVTT_jsfusion_test/t2v_metrics/R5: 55.2
 MSRVTT_jsfusion_test/t2v_metrics/R10: 67.4
 MSRVTT_jsfusion_test/t2v_metrics/R50: 87.9
 MSRVTT_jsfusion_test/t2v_metrics/MedR: 4.0
 MSRVTT_jsfusion_test/t2v_metrics/MeanR: 30.709
 MSRVTT_jsfusion_test/t2v_metrics/geometric_mean_R1-R5-R10: 46.02213427525967
 MSRVTT_jsfusion_test/v2t_metrics/R1: 26.9
 MSRVTT_jsfusion_test/v2t_metrics/R5: 57.9
 MSRVTT_jsfusion_test/v2t_metrics/R10: 69.0
 MSRVTT_jsfusion_test/v2t_metrics/R50: 88.9
 MSRVTT_jsfusion_test/v2t_metrics/MedR: 4.0
 MSRVTT_jsfusion_test/v2t_metrics/MeanR: 26.83
 MSRVTT_jsfusion_test/v2t_metrics/geometric_mean_R1-R5-R10: 47.543736632182416
 mnt_best       : 47.36448169102165
 not_improved_count: 2
Train Epoch: 43 [1/250 128/32000 (0%)] Loss: 0.68232 (QuantReg: 14.40075) QuantErr: 14.40075 batch_time=33.92633 
Train Epoch: 43 [12/250 1536/32000 (5%)] Loss: 0.69722 (QuantReg: 13.92611) QuantErr: 13.92611 batch_time=0.66636 
Train Epoch: 43 [23/250 2944/32000 (9%)] Loss: 0.82043 (QuantReg: 14.09652) QuantErr: 14.09652 batch_time=0.66489 
Train Epoch: 43 [34/250 4352/32000 (14%)] Loss: 0.70674 (QuantReg: 14.33555) QuantErr: 14.33555 batch_time=0.65476 
Train Epoch: 43 [45/250 5760/32000 (18%)] Loss: 1.11641 (QuantReg: 14.21749) QuantErr: 14.21749 batch_time=0.79471 
Train Epoch: 43 [56/250 7168/32000 (22%)] Loss: 0.96022 (QuantReg: 14.43808) QuantErr: 14.43808 batch_time=0.67490 
Train Epoch: 43 [67/250 8576/32000 (27%)] Loss: 0.98104 (QuantReg: 14.18846) QuantErr: 14.18846 batch_time=0.64246 
Train Epoch: 43 [78/250 9984/32000 (31%)] Loss: 0.71917 (QuantReg: 14.08307) QuantErr: 14.08307 batch_time=0.66444 
Train Epoch: 43 [89/250 11392/32000 (36%)] Loss: 0.84371 (QuantReg: 14.13256) QuantErr: 14.13256 batch_time=0.66016 
Train Epoch: 43 [100/250 12800/32000 (40%)] Loss: 0.89404 (QuantReg: 13.95590) QuantErr: 13.95590 batch_time=0.68490 
Train Epoch: 43 [111/250 14208/32000 (44%)] Loss: 0.74910 (QuantReg: 14.25356) QuantErr: 14.25356 batch_time=0.66851 
Train Epoch: 43 [122/250 15616/32000 (49%)] Loss: 0.79224 (QuantReg: 14.39649) QuantErr: 14.39649 batch_time=0.66239 
Train Epoch: 43 [133/250 17024/32000 (53%)] Loss: 1.07080 (QuantReg: 14.22640) QuantErr: 14.22640 batch_time=0.66146 
Train Epoch: 43 [144/250 18432/32000 (58%)] Loss: 0.57913 (QuantReg: 14.42753) QuantErr: 14.42753 batch_time=0.64752 
Train Epoch: 43 [155/250 19840/32000 (62%)] Loss: 0.55219 (QuantReg: 14.26876) QuantErr: 14.26876 batch_time=0.64335 
Train Epoch: 43 [166/250 21248/32000 (66%)] Loss: 0.82338 (QuantReg: 14.18909) QuantErr: 14.18909 batch_time=0.65826 
Train Epoch: 43 [177/250 22656/32000 (71%)] Loss: 0.72794 (QuantReg: 14.34366) QuantErr: 14.34366 batch_time=0.65416 
Train Epoch: 43 [188/250 24064/32000 (75%)] Loss: 1.07186 (QuantReg: 14.19159) QuantErr: 14.19159 batch_time=0.70055 
Train Epoch: 43 [199/250 25472/32000 (80%)] Loss: 0.75739 (QuantReg: 14.43965) QuantErr: 14.43965 batch_time=0.66052 
Train Epoch: 43 [210/250 26880/32000 (84%)] Loss: 0.86064 (QuantReg: 14.41767) QuantErr: 14.41767 batch_time=0.68537 
Train Epoch: 43 [221/250 28288/32000 (88%)] Loss: 0.74865 (QuantReg: 14.29882) QuantErr: 14.29882 batch_time=0.69587 
Train Epoch: 43 [232/250 29696/32000 (93%)] Loss: 0.91603 (QuantReg: 14.11903) QuantErr: 14.11903 batch_time=0.66606 
Train Epoch: 43 [243/250 31104/32000 (97%)] Loss: 0.71217 (QuantReg: 14.46251) QuantErr: 14.46251 batch_time=0.97874 
Train Epoch: 43 codebook_update_time=1.92130
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_MSRVTT_1kA_roberta-large/checkpoint-epoch43.pth ...
Done in 10.929s
removing stale ckpt [epoch 42] [took 0.00s]
 epoch          : 43
 loss           : 0.7957511351108552
 quant_reg      : 14.281282531738281
 quant_err      : 14.281282531738281
 learning_rate  : 5.799111065000278e-06
 n_samples      : 1376000
 n_steps        : 10750
 MSRVTT_jsfusion_test/t2v_metrics/R1: 27.9
 MSRVTT_jsfusion_test/t2v_metrics/R5: 54.5
 MSRVTT_jsfusion_test/t2v_metrics/R10: 68.2
 MSRVTT_jsfusion_test/t2v_metrics/R50: 87.9
 MSRVTT_jsfusion_test/t2v_metrics/MedR: 5.0
 MSRVTT_jsfusion_test/t2v_metrics/MeanR: 31.052
 MSRVTT_jsfusion_test/t2v_metrics/geometric_mean_R1-R5-R10: 46.981660265792
 MSRVTT_jsfusion_test/v2t_metrics/R1: 26.8
 MSRVTT_jsfusion_test/v2t_metrics/R5: 58.9
 MSRVTT_jsfusion_test/v2t_metrics/R10: 68.3
 MSRVTT_jsfusion_test/v2t_metrics/R50: 88.5
 MSRVTT_jsfusion_test/v2t_metrics/MedR: 4.0
 MSRVTT_jsfusion_test/v2t_metrics/MeanR: 27.383
 MSRVTT_jsfusion_test/v2t_metrics/geometric_mean_R1-R5-R10: 47.5945177642121
 mnt_best       : 47.36448169102165
 not_improved_count: 3
Train Epoch: 44 [1/250 128/32000 (0%)] Loss: 0.69092 (QuantReg: 14.28881) QuantErr: 14.28881 batch_time=28.03258 
Train Epoch: 44 [12/250 1536/32000 (5%)] Loss: 1.03107 (QuantReg: 14.39985) QuantErr: 14.39985 batch_time=0.65695 
Train Epoch: 44 [23/250 2944/32000 (9%)] Loss: 0.69255 (QuantReg: 14.36559) QuantErr: 14.36559 batch_time=0.64846 
Train Epoch: 44 [34/250 4352/32000 (14%)] Loss: 0.63959 (QuantReg: 14.28613) QuantErr: 14.28613 batch_time=0.65382 
Train Epoch: 44 [45/250 5760/32000 (18%)] Loss: 0.59309 (QuantReg: 14.72116) QuantErr: 14.72116 batch_time=0.65762 
Train Epoch: 44 [56/250 7168/32000 (22%)] Loss: 0.59775 (QuantReg: 14.47087) QuantErr: 14.47087 batch_time=0.65525 
Train Epoch: 44 [67/250 8576/32000 (27%)] Loss: 0.70799 (QuantReg: 14.29466) QuantErr: 14.29466 batch_time=0.66455 
Train Epoch: 44 [78/250 9984/32000 (31%)] Loss: 0.87246 (QuantReg: 14.54829) QuantErr: 14.54829 batch_time=0.66089 
Train Epoch: 44 [89/250 11392/32000 (36%)] Loss: 0.78252 (QuantReg: 14.33026) QuantErr: 14.33026 batch_time=0.68806 
Train Epoch: 44 [100/250 12800/32000 (40%)] Loss: 0.97805 (QuantReg: 14.09634) QuantErr: 14.09634 batch_time=0.65749 
Train Epoch: 44 [111/250 14208/32000 (44%)] Loss: 0.97777 (QuantReg: 14.15740) QuantErr: 14.15740 batch_time=0.65688 
Train Epoch: 44 [122/250 15616/32000 (49%)] Loss: 0.65007 (QuantReg: 14.18681) QuantErr: 14.18681 batch_time=0.66762 
Train Epoch: 44 [133/250 17024/32000 (53%)] Loss: 0.84341 (QuantReg: 14.10481) QuantErr: 14.10481 batch_time=1.37019 
Train Epoch: 44 [144/250 18432/32000 (58%)] Loss: 0.70289 (QuantReg: 14.51841) QuantErr: 14.51841 batch_time=0.89480 
Train Epoch: 44 [155/250 19840/32000 (62%)] Loss: 0.76583 (QuantReg: 14.37224) QuantErr: 14.37224 batch_time=1.52099 
Train Epoch: 44 [166/250 21248/32000 (66%)] Loss: 0.71118 (QuantReg: 14.34003) QuantErr: 14.34003 batch_time=1.13298 
Train Epoch: 44 [177/250 22656/32000 (71%)] Loss: 0.84853 (QuantReg: 14.31733) QuantErr: 14.31733 batch_time=0.67796 
Train Epoch: 44 [188/250 24064/32000 (75%)] Loss: 0.68945 (QuantReg: 14.24228) QuantErr: 14.24228 batch_time=0.69667 
Train Epoch: 44 [199/250 25472/32000 (80%)] Loss: 0.88669 (QuantReg: 14.20933) QuantErr: 14.20933 batch_time=2.23493 
Train Epoch: 44 [210/250 26880/32000 (84%)] Loss: 0.83943 (QuantReg: 14.36947) QuantErr: 14.36947 batch_time=2.52732 
Train Epoch: 44 [221/250 28288/32000 (88%)] Loss: 1.00044 (QuantReg: 14.34160) QuantErr: 14.34160 batch_time=0.65845 
Train Epoch: 44 [232/250 29696/32000 (93%)] Loss: 0.63135 (QuantReg: 14.66158) QuantErr: 14.66158 batch_time=0.82706 
Train Epoch: 44 [243/250 31104/32000 (97%)] Loss: 0.81258 (QuantReg: 14.46529) QuantErr: 14.46529 batch_time=0.65682 
Train Epoch: 44 codebook_update_time=1.61558
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_MSRVTT_1kA_roberta-large/checkpoint-epoch44.pth ...
Done in 11.334s
removing stale ckpt [epoch 43] [took 0.02s]
 epoch          : 44
 loss           : 0.7839040136337281
 quant_reg      : 14.330237632751464
 quant_err      : 14.330237632751464
 learning_rate  : 5.5091555117502635e-06
 n_samples      : 1408000
 n_steps        : 11000
 MSRVTT_jsfusion_test/t2v_metrics/R1: 26.8
 MSRVTT_jsfusion_test/t2v_metrics/R5: 54.8
 MSRVTT_jsfusion_test/t2v_metrics/R10: 68.5
 MSRVTT_jsfusion_test/t2v_metrics/R50: 87.4
 MSRVTT_jsfusion_test/t2v_metrics/MedR: 4.0
 MSRVTT_jsfusion_test/t2v_metrics/MeanR: 31.587
 MSRVTT_jsfusion_test/t2v_metrics/geometric_mean_R1-R5-R10: 46.508818614973976
 MSRVTT_jsfusion_test/v2t_metrics/R1: 26.1
 MSRVTT_jsfusion_test/v2t_metrics/R5: 59.2
 MSRVTT_jsfusion_test/v2t_metrics/R10: 69.1
 MSRVTT_jsfusion_test/v2t_metrics/R50: 88.9
 MSRVTT_jsfusion_test/v2t_metrics/MedR: 4.0
 MSRVTT_jsfusion_test/v2t_metrics/MeanR: 27.002
 MSRVTT_jsfusion_test/v2t_metrics/geometric_mean_R1-R5-R10: 47.44022649370938
 mnt_best       : 47.36448169102165
 not_improved_count: 4
Train Epoch: 45 [1/250 128/32000 (0%)] Loss: 0.79857 (QuantReg: 14.41808) QuantErr: 14.41808 batch_time=28.39722 
Train Epoch: 45 [12/250 1536/32000 (5%)] Loss: 0.92307 (QuantReg: 14.29418) QuantErr: 14.29418 batch_time=0.65963 
Train Epoch: 45 [23/250 2944/32000 (9%)] Loss: 0.96494 (QuantReg: 14.10924) QuantErr: 14.10924 batch_time=0.66029 
Train Epoch: 45 [34/250 4352/32000 (14%)] Loss: 0.95621 (QuantReg: 14.04388) QuantErr: 14.04388 batch_time=0.67293 
Train Epoch: 45 [45/250 5760/32000 (18%)] Loss: 0.74783 (QuantReg: 14.42955) QuantErr: 14.42955 batch_time=0.65464 
Train Epoch: 45 [56/250 7168/32000 (22%)] Loss: 0.91936 (QuantReg: 14.29530) QuantErr: 14.29530 batch_time=0.64232 
Train Epoch: 45 [67/250 8576/32000 (27%)] Loss: 0.70441 (QuantReg: 14.31901) QuantErr: 14.31901 batch_time=0.70456 
Train Epoch: 45 [78/250 9984/32000 (31%)] Loss: 0.49245 (QuantReg: 14.45009) QuantErr: 14.45009 batch_time=0.65844 
Train Epoch: 45 [89/250 11392/32000 (36%)] Loss: 0.71737 (QuantReg: 14.32515) QuantErr: 14.32515 batch_time=1.75106 
Train Epoch: 45 [100/250 12800/32000 (40%)] Loss: 0.77236 (QuantReg: 14.22892) QuantErr: 14.22892 batch_time=0.66809 
Train Epoch: 45 [111/250 14208/32000 (44%)] Loss: 0.81733 (QuantReg: 14.36634) QuantErr: 14.36634 batch_time=0.65056 
Train Epoch: 45 [122/250 15616/32000 (49%)] Loss: 0.82109 (QuantReg: 14.17937) QuantErr: 14.17937 batch_time=0.65678 
Train Epoch: 45 [133/250 17024/32000 (53%)] Loss: 1.09211 (QuantReg: 14.32631) QuantErr: 14.32631 batch_time=0.64884 
Train Epoch: 45 [144/250 18432/32000 (58%)] Loss: 0.83193 (QuantReg: 14.34051) QuantErr: 14.34051 batch_time=0.67624 
Train Epoch: 45 [155/250 19840/32000 (62%)] Loss: 0.85236 (QuantReg: 14.24480) QuantErr: 14.24480 batch_time=0.67130 
Train Epoch: 45 [166/250 21248/32000 (66%)] Loss: 0.82113 (QuantReg: 14.39961) QuantErr: 14.39961 batch_time=0.69298 
Train Epoch: 45 [177/250 22656/32000 (71%)] Loss: 0.97155 (QuantReg: 14.34187) QuantErr: 14.34187 batch_time=0.64573 
Train Epoch: 45 [188/250 24064/32000 (75%)] Loss: 0.59881 (QuantReg: 14.25074) QuantErr: 14.25074 batch_time=0.66830 
Train Epoch: 45 [199/250 25472/32000 (80%)] Loss: 0.86172 (QuantReg: 14.32001) QuantErr: 14.32001 batch_time=0.65905 
Train Epoch: 45 [210/250 26880/32000 (84%)] Loss: 0.91912 (QuantReg: 14.35515) QuantErr: 14.35515 batch_time=0.68714 
Train Epoch: 45 [221/250 28288/32000 (88%)] Loss: 0.85878 (QuantReg: 14.35438) QuantErr: 14.35438 batch_time=0.67033 
Train Epoch: 45 [232/250 29696/32000 (93%)] Loss: 0.62720 (QuantReg: 14.47748) QuantErr: 14.47748 batch_time=0.65536 
Train Epoch: 45 [243/250 31104/32000 (97%)] Loss: 0.95153 (QuantReg: 14.24735) QuantErr: 14.24735 batch_time=0.69517 
Train Epoch: 45 codebook_update_time=1.74640
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_MSRVTT_1kA_roberta-large/checkpoint-epoch45.pth ...
Done in 10.756s
removing stale ckpt [epoch 44] [took 0.00s]
 epoch          : 45
 loss           : 0.7830445102453232
 quant_reg      : 14.306685222625733
 quant_err      : 14.306685222625733
 learning_rate  : 5.23369773616275e-06
 n_samples      : 1440000
 n_steps        : 11250
 MSRVTT_jsfusion_test/t2v_metrics/R1: 26.7
 MSRVTT_jsfusion_test/t2v_metrics/R5: 55.6
 MSRVTT_jsfusion_test/t2v_metrics/R10: 68.0
 MSRVTT_jsfusion_test/t2v_metrics/R50: 87.9
 MSRVTT_jsfusion_test/t2v_metrics/MedR: 4.0
 MSRVTT_jsfusion_test/t2v_metrics/MeanR: 31.498
 MSRVTT_jsfusion_test/t2v_metrics/geometric_mean_R1-R5-R10: 46.56200307864198
 MSRVTT_jsfusion_test/v2t_metrics/R1: 26.2
 MSRVTT_jsfusion_test/v2t_metrics/R5: 58.5
 MSRVTT_jsfusion_test/v2t_metrics/R10: 68.9
 MSRVTT_jsfusion_test/v2t_metrics/R50: 88.5
 MSRVTT_jsfusion_test/v2t_metrics/MedR: 4.0
 MSRVTT_jsfusion_test/v2t_metrics/MeanR: 27.219
 MSRVTT_jsfusion_test/v2t_metrics/geometric_mean_R1-R5-R10: 47.267082091045964
 mnt_best       : 47.36448169102165
 not_improved_count: 5
Train Epoch: 46 [1/250 128/32000 (0%)] Loss: 0.76492 (QuantReg: 14.03876) QuantErr: 14.03876 batch_time=29.64499 
Train Epoch: 46 [12/250 1536/32000 (5%)] Loss: 0.75549 (QuantReg: 14.66448) QuantErr: 14.66448 batch_time=0.67052 
Train Epoch: 46 [23/250 2944/32000 (9%)] Loss: 0.79258 (QuantReg: 14.30026) QuantErr: 14.30026 batch_time=0.66298 
Train Epoch: 46 [34/250 4352/32000 (14%)] Loss: 0.74019 (QuantReg: 14.43722) QuantErr: 14.43722 batch_time=0.65935 
Train Epoch: 46 [45/250 5760/32000 (18%)] Loss: 0.92100 (QuantReg: 14.20271) QuantErr: 14.20271 batch_time=0.68891 
Train Epoch: 46 [56/250 7168/32000 (22%)] Loss: 0.86346 (QuantReg: 14.54765) QuantErr: 14.54765 batch_time=0.96714 
Train Epoch: 46 [67/250 8576/32000 (27%)] Loss: 0.71414 (QuantReg: 14.16497) QuantErr: 14.16497 batch_time=0.69960 
Train Epoch: 46 [78/250 9984/32000 (31%)] Loss: 1.03965 (QuantReg: 14.27340) QuantErr: 14.27340 batch_time=0.69879 
Train Epoch: 46 [89/250 11392/32000 (36%)] Loss: 1.08184 (QuantReg: 14.20987) QuantErr: 14.20987 batch_time=0.69092 
Train Epoch: 46 [100/250 12800/32000 (40%)] Loss: 0.77194 (QuantReg: 14.23127) QuantErr: 14.23127 batch_time=0.69748 
Train Epoch: 46 [111/250 14208/32000 (44%)] Loss: 0.60677 (QuantReg: 14.15800) QuantErr: 14.15800 batch_time=0.67130 
Train Epoch: 46 [122/250 15616/32000 (49%)] Loss: 0.82530 (QuantReg: 14.45827) QuantErr: 14.45827 batch_time=0.67855 
Train Epoch: 46 [133/250 17024/32000 (53%)] Loss: 0.87212 (QuantReg: 14.29252) QuantErr: 14.29252 batch_time=0.68476 
Train Epoch: 46 [144/250 18432/32000 (58%)] Loss: 0.97840 (QuantReg: 14.30431) QuantErr: 14.30431 batch_time=0.70886 
Train Epoch: 46 [155/250 19840/32000 (62%)] Loss: 0.91087 (QuantReg: 14.38070) QuantErr: 14.38070 batch_time=0.65816 
Train Epoch: 46 [166/250 21248/32000 (66%)] Loss: 0.65056 (QuantReg: 14.13550) QuantErr: 14.13550 batch_time=0.69444 
Train Epoch: 46 [177/250 22656/32000 (71%)] Loss: 1.06506 (QuantReg: 14.25939) QuantErr: 14.25939 batch_time=0.66548 
Train Epoch: 46 [188/250 24064/32000 (75%)] Loss: 0.74673 (QuantReg: 14.57138) QuantErr: 14.57138 batch_time=0.67939 
Train Epoch: 46 [199/250 25472/32000 (80%)] Loss: 0.88938 (QuantReg: 14.24363) QuantErr: 14.24363 batch_time=0.67446 
Train Epoch: 46 [210/250 26880/32000 (84%)] Loss: 0.92393 (QuantReg: 14.28707) QuantErr: 14.28707 batch_time=0.65515 
Train Epoch: 46 [221/250 28288/32000 (88%)] Loss: 0.91586 (QuantReg: 14.16071) QuantErr: 14.16071 batch_time=0.66208 
Train Epoch: 46 [232/250 29696/32000 (93%)] Loss: 0.73917 (QuantReg: 14.55989) QuantErr: 14.55989 batch_time=0.65954 
Train Epoch: 46 [243/250 31104/32000 (97%)] Loss: 0.44888 (QuantReg: 14.57130) QuantErr: 14.57130 batch_time=0.65135 
Train Epoch: 46 codebook_update_time=1.72757
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_MSRVTT_1kA_roberta-large/checkpoint-epoch46.pth ...
Done in 11.032s
removing stale ckpt [epoch 45] [took 0.40s]
 epoch          : 46
 loss           : 0.7768348753452301
 quant_reg      : 14.326677017211914
 quant_err      : 14.326677017211914
 learning_rate  : 4.972012849354612e-06
 n_samples      : 1472000
 n_steps        : 11500
 MSRVTT_jsfusion_test/t2v_metrics/R1: 26.9
 MSRVTT_jsfusion_test/t2v_metrics/R5: 55.0
 MSRVTT_jsfusion_test/t2v_metrics/R10: 66.4
 MSRVTT_jsfusion_test/t2v_metrics/R50: 87.8
 MSRVTT_jsfusion_test/t2v_metrics/MedR: 4.0
 MSRVTT_jsfusion_test/t2v_metrics/MeanR: 32.147
 MSRVTT_jsfusion_test/t2v_metrics/geometric_mean_R1-R5-R10: 46.14178057827612
 MSRVTT_jsfusion_test/v2t_metrics/R1: 26.0
 MSRVTT_jsfusion_test/v2t_metrics/R5: 58.7
 MSRVTT_jsfusion_test/v2t_metrics/R10: 69.3
 MSRVTT_jsfusion_test/v2t_metrics/R50: 88.5
 MSRVTT_jsfusion_test/v2t_metrics/MedR: 4.0
 MSRVTT_jsfusion_test/v2t_metrics/MeanR: 28.121
 MSRVTT_jsfusion_test/v2t_metrics/geometric_mean_R1-R5-R10: 47.291333613892164
 mnt_best       : 47.36448169102165
 not_improved_count: 6
Train Epoch: 47 [1/250 128/32000 (0%)] Loss: 0.80294 (QuantReg: 14.17174) QuantErr: 14.17174 batch_time=28.17230 
Train Epoch: 47 [12/250 1536/32000 (5%)] Loss: 0.67979 (QuantReg: 14.19096) QuantErr: 14.19096 batch_time=0.64667 
Train Epoch: 47 [23/250 2944/32000 (9%)] Loss: 0.63743 (QuantReg: 14.32472) QuantErr: 14.32472 batch_time=0.65445 
Train Epoch: 47 [34/250 4352/32000 (14%)] Loss: 0.59947 (QuantReg: 14.57508) QuantErr: 14.57508 batch_time=0.64744 
Train Epoch: 47 [45/250 5760/32000 (18%)] Loss: 0.74894 (QuantReg: 14.19862) QuantErr: 14.19862 batch_time=0.64760 
Train Epoch: 47 [56/250 7168/32000 (22%)] Loss: 0.91288 (QuantReg: 14.53259) QuantErr: 14.53259 batch_time=0.65470 
Train Epoch: 47 [67/250 8576/32000 (27%)] Loss: 0.74317 (QuantReg: 14.32359) QuantErr: 14.32359 batch_time=3.10670 
Train Epoch: 47 [78/250 9984/32000 (31%)] Loss: 0.74291 (QuantReg: 14.35855) QuantErr: 14.35855 batch_time=0.65805 
Train Epoch: 47 [89/250 11392/32000 (36%)] Loss: 0.66467 (QuantReg: 14.41402) QuantErr: 14.41402 batch_time=0.66231 
Train Epoch: 47 [100/250 12800/32000 (40%)] Loss: 1.20092 (QuantReg: 14.27404) QuantErr: 14.27404 batch_time=1.39864 
Train Epoch: 47 [111/250 14208/32000 (44%)] Loss: 0.73395 (QuantReg: 14.25035) QuantErr: 14.25035 batch_time=0.65895 
Train Epoch: 47 [122/250 15616/32000 (49%)] Loss: 0.65639 (QuantReg: 14.24816) QuantErr: 14.24816 batch_time=0.67018 
Train Epoch: 47 [133/250 17024/32000 (53%)] Loss: 0.59791 (QuantReg: 14.33349) QuantErr: 14.33349 batch_time=0.67169 
Train Epoch: 47 [144/250 18432/32000 (58%)] Loss: 0.74112 (QuantReg: 14.24432) QuantErr: 14.24432 batch_time=0.65716 
Train Epoch: 47 [155/250 19840/32000 (62%)] Loss: 0.75240 (QuantReg: 14.30811) QuantErr: 14.30811 batch_time=0.66389 
Train Epoch: 47 [166/250 21248/32000 (66%)] Loss: 0.66358 (QuantReg: 14.46153) QuantErr: 14.46153 batch_time=0.65752 
Train Epoch: 47 [177/250 22656/32000 (71%)] Loss: 0.73702 (QuantReg: 14.17635) QuantErr: 14.17635 batch_time=0.69119 
Train Epoch: 47 [188/250 24064/32000 (75%)] Loss: 0.77588 (QuantReg: 14.37762) QuantErr: 14.37762 batch_time=0.65308 
Train Epoch: 47 [199/250 25472/32000 (80%)] Loss: 0.99784 (QuantReg: 14.37210) QuantErr: 14.37210 batch_time=0.67908 
Train Epoch: 47 [210/250 26880/32000 (84%)] Loss: 0.68201 (QuantReg: 14.43755) QuantErr: 14.43755 batch_time=0.66039 
Train Epoch: 47 [221/250 28288/32000 (88%)] Loss: 0.77911 (QuantReg: 14.39387) QuantErr: 14.39387 batch_time=0.69067 
Train Epoch: 47 [232/250 29696/32000 (93%)] Loss: 0.84976 (QuantReg: 14.37537) QuantErr: 14.37537 batch_time=0.65663 
Train Epoch: 47 [243/250 31104/32000 (97%)] Loss: 0.90417 (QuantReg: 14.51533) QuantErr: 14.51533 batch_time=0.66579 
Train Epoch: 47 codebook_update_time=1.70454
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_MSRVTT_1kA_roberta-large/checkpoint-epoch47.pth ...
Done in 11.576s
removing stale ckpt [epoch 46] [took 0.00s]
 epoch          : 47
 loss           : 0.7585509369373321
 quant_reg      : 14.349168067932128
 quant_err      : 14.349168067932128
 learning_rate  : 4.723412206886882e-06
 n_samples      : 1504000
 n_steps        : 11750
 MSRVTT_jsfusion_test/t2v_metrics/R1: 26.7
 MSRVTT_jsfusion_test/t2v_metrics/R5: 55.1
 MSRVTT_jsfusion_test/t2v_metrics/R10: 67.1
 MSRVTT_jsfusion_test/t2v_metrics/R50: 87.4
 MSRVTT_jsfusion_test/t2v_metrics/MedR: 4.0
 MSRVTT_jsfusion_test/t2v_metrics/MeanR: 32.131
 MSRVTT_jsfusion_test/t2v_metrics/geometric_mean_R1-R5-R10: 46.21629501470503
 MSRVTT_jsfusion_test/v2t_metrics/R1: 25.7
 MSRVTT_jsfusion_test/v2t_metrics/R5: 58.8
 MSRVTT_jsfusion_test/v2t_metrics/R10: 69.4
 MSRVTT_jsfusion_test/v2t_metrics/R50: 88.8
 MSRVTT_jsfusion_test/v2t_metrics/MedR: 4.0
 MSRVTT_jsfusion_test/v2t_metrics/MeanR: 28.3145
 MSRVTT_jsfusion_test/v2t_metrics/geometric_mean_R1-R5-R10: 47.15813701732706
 mnt_best       : 47.36448169102165
 not_improved_count: 7
Train Epoch: 48 [1/250 128/32000 (0%)] Loss: 0.73246 (QuantReg: 14.41942) QuantErr: 14.41942 batch_time=30.93531 
Train Epoch: 48 [12/250 1536/32000 (5%)] Loss: 0.88458 (QuantReg: 14.45930) QuantErr: 14.45930 batch_time=0.65295 
Train Epoch: 48 [23/250 2944/32000 (9%)] Loss: 0.99806 (QuantReg: 14.17524) QuantErr: 14.17524 batch_time=0.65273 
Train Epoch: 48 [34/250 4352/32000 (14%)] Loss: 0.76113 (QuantReg: 14.08934) QuantErr: 14.08934 batch_time=0.79506 
Train Epoch: 48 [45/250 5760/32000 (18%)] Loss: 0.75824 (QuantReg: 14.33192) QuantErr: 14.33192 batch_time=0.67191 
Train Epoch: 48 [56/250 7168/32000 (22%)] Loss: 0.77975 (QuantReg: 14.51713) QuantErr: 14.51713 batch_time=0.65089 
Train Epoch: 48 [67/250 8576/32000 (27%)] Loss: 0.55730 (QuantReg: 14.47880) QuantErr: 14.47880 batch_time=0.64954 
Train Epoch: 48 [78/250 9984/32000 (31%)] Loss: 0.77446 (QuantReg: 14.27363) QuantErr: 14.27363 batch_time=0.64745 
Train Epoch: 48 [89/250 11392/32000 (36%)] Loss: 0.86037 (QuantReg: 14.04649) QuantErr: 14.04649 batch_time=0.66815 
Train Epoch: 48 [100/250 12800/32000 (40%)] Loss: 0.79370 (QuantReg: 14.21633) QuantErr: 14.21633 batch_time=0.66678 
Train Epoch: 48 [111/250 14208/32000 (44%)] Loss: 0.51365 (QuantReg: 14.17568) QuantErr: 14.17568 batch_time=0.65451 
Train Epoch: 48 [122/250 15616/32000 (49%)] Loss: 0.58032 (QuantReg: 14.24763) QuantErr: 14.24763 batch_time=0.65392 
Train Epoch: 48 [133/250 17024/32000 (53%)] Loss: 0.77872 (QuantReg: 14.32133) QuantErr: 14.32133 batch_time=0.65522 
Train Epoch: 48 [144/250 18432/32000 (58%)] Loss: 0.54591 (QuantReg: 14.57930) QuantErr: 14.57930 batch_time=6.20194 
Train Epoch: 48 [155/250 19840/32000 (62%)] Loss: 0.60160 (QuantReg: 14.30412) QuantErr: 14.30412 batch_time=0.66065 
Train Epoch: 48 [166/250 21248/32000 (66%)] Loss: 0.89720 (QuantReg: 14.03436) QuantErr: 14.03436 batch_time=0.68830 
Train Epoch: 48 [177/250 22656/32000 (71%)] Loss: 0.77864 (QuantReg: 14.38247) QuantErr: 14.38247 batch_time=0.70501 
Train Epoch: 48 [188/250 24064/32000 (75%)] Loss: 0.92825 (QuantReg: 14.32298) QuantErr: 14.32298 batch_time=0.69353 
Train Epoch: 48 [199/250 25472/32000 (80%)] Loss: 0.60980 (QuantReg: 14.34884) QuantErr: 14.34884 batch_time=2.76602 
Train Epoch: 48 [210/250 26880/32000 (84%)] Loss: 0.93384 (QuantReg: 14.35859) QuantErr: 14.35859 batch_time=0.68014 
Train Epoch: 48 [221/250 28288/32000 (88%)] Loss: 0.80559 (QuantReg: 14.55107) QuantErr: 14.55107 batch_time=0.69514 
Train Epoch: 48 [232/250 29696/32000 (93%)] Loss: 0.93000 (QuantReg: 14.29957) QuantErr: 14.29957 batch_time=0.69465 
Train Epoch: 48 [243/250 31104/32000 (97%)] Loss: 0.83503 (QuantReg: 14.33800) QuantErr: 14.33800 batch_time=0.70692 
Train Epoch: 48 codebook_update_time=1.76387
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_MSRVTT_1kA_roberta-large/checkpoint-epoch48.pth ...
Done in 25.519s
removing stale ckpt [epoch 47] [took 0.00s]
 epoch          : 48
 loss           : 0.7601106967926026
 quant_reg      : 14.352169269561768
 quant_err      : 14.352169269561768
 learning_rate  : 4.487241596542537e-06
 n_samples      : 1536000
 n_steps        : 12000
 MSRVTT_jsfusion_test/t2v_metrics/R1: 26.7
 MSRVTT_jsfusion_test/t2v_metrics/R5: 55.0
 MSRVTT_jsfusion_test/t2v_metrics/R10: 68.8
 MSRVTT_jsfusion_test/t2v_metrics/R50: 87.0
 MSRVTT_jsfusion_test/t2v_metrics/MedR: 4.0
 MSRVTT_jsfusion_test/t2v_metrics/MeanR: 31.722
 MSRVTT_jsfusion_test/t2v_metrics/geometric_mean_R1-R5-R10: 46.575135783633556
 MSRVTT_jsfusion_test/v2t_metrics/R1: 26.9
 MSRVTT_jsfusion_test/v2t_metrics/R5: 59.2
 MSRVTT_jsfusion_test/v2t_metrics/R10: 69.6
 MSRVTT_jsfusion_test/v2t_metrics/R50: 88.2
 MSRVTT_jsfusion_test/v2t_metrics/MedR: 3.25
 MSRVTT_jsfusion_test/v2t_metrics/MeanR: 28.671
 MSRVTT_jsfusion_test/v2t_metrics/geometric_mean_R1-R5-R10: 48.035362829788255
 mnt_best       : 47.36448169102165
 not_improved_count: 8
Train Epoch: 49 [1/250 128/32000 (0%)] Loss: 0.61564 (QuantReg: 14.32157) QuantErr: 14.32157 batch_time=32.55798 
Train Epoch: 49 [12/250 1536/32000 (5%)] Loss: 0.65742 (QuantReg: 14.33372) QuantErr: 14.33372 batch_time=0.68093 
Train Epoch: 49 [23/250 2944/32000 (9%)] Loss: 0.86189 (QuantReg: 14.35549) QuantErr: 14.35549 batch_time=0.66525 
Train Epoch: 49 [34/250 4352/32000 (14%)] Loss: 0.80639 (QuantReg: 14.51660) QuantErr: 14.51660 batch_time=0.67918 
Train Epoch: 49 [45/250 5760/32000 (18%)] Loss: 0.86003 (QuantReg: 14.42612) QuantErr: 14.42612 batch_time=1.01480 
Train Epoch: 49 [56/250 7168/32000 (22%)] Loss: 0.71629 (QuantReg: 14.39355) QuantErr: 14.39355 batch_time=0.68514 
Train Epoch: 49 [67/250 8576/32000 (27%)] Loss: 0.67487 (QuantReg: 14.51339) QuantErr: 14.51339 batch_time=0.65567 
Train Epoch: 49 [78/250 9984/32000 (31%)] Loss: 0.75960 (QuantReg: 14.55674) QuantErr: 14.55674 batch_time=0.70305 
Train Epoch: 49 [89/250 11392/32000 (36%)] Loss: 0.78959 (QuantReg: 14.12967) QuantErr: 14.12967 batch_time=0.67058 
Train Epoch: 49 [100/250 12800/32000 (40%)] Loss: 0.72105 (QuantReg: 14.12109) QuantErr: 14.12109 batch_time=0.69414 
Train Epoch: 49 [111/250 14208/32000 (44%)] Loss: 0.89682 (QuantReg: 14.28876) QuantErr: 14.28876 batch_time=0.65459 
Train Epoch: 49 [122/250 15616/32000 (49%)] Loss: 0.70273 (QuantReg: 14.60569) QuantErr: 14.60569 batch_time=0.65636 
Train Epoch: 49 [133/250 17024/32000 (53%)] Loss: 0.74726 (QuantReg: 14.64529) QuantErr: 14.64529 batch_time=0.63898 
Train Epoch: 49 [144/250 18432/32000 (58%)] Loss: 0.47826 (QuantReg: 14.79047) QuantErr: 14.79047 batch_time=0.64437 
Train Epoch: 49 [155/250 19840/32000 (62%)] Loss: 0.79039 (QuantReg: 14.44307) QuantErr: 14.44307 batch_time=0.64847 
Train Epoch: 49 [166/250 21248/32000 (66%)] Loss: 0.81718 (QuantReg: 14.49638) QuantErr: 14.49638 batch_time=0.65247 
Train Epoch: 49 [177/250 22656/32000 (71%)] Loss: 0.73381 (QuantReg: 14.21742) QuantErr: 14.21742 batch_time=0.70970 
Train Epoch: 49 [188/250 24064/32000 (75%)] Loss: 0.94124 (QuantReg: 14.64753) QuantErr: 14.64753 batch_time=0.65961 
Train Epoch: 49 [199/250 25472/32000 (80%)] Loss: 1.04160 (QuantReg: 14.43779) QuantErr: 14.43779 batch_time=0.67764 
Train Epoch: 49 [210/250 26880/32000 (84%)] Loss: 0.93771 (QuantReg: 14.32748) QuantErr: 14.32748 batch_time=2.02746 
Train Epoch: 49 [221/250 28288/32000 (88%)] Loss: 0.75521 (QuantReg: 14.21133) QuantErr: 14.21133 batch_time=0.68329 
Train Epoch: 49 [232/250 29696/32000 (93%)] Loss: 0.82855 (QuantReg: 14.63021) QuantErr: 14.63021 batch_time=1.25091 
Train Epoch: 49 [243/250 31104/32000 (97%)] Loss: 0.71596 (QuantReg: 14.51032) QuantErr: 14.51032 batch_time=0.66191 
Train Epoch: 49 codebook_update_time=1.86601
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_MSRVTT_1kA_roberta-large/checkpoint-epoch49.pth ...
Done in 28.661s
removing stale ckpt [epoch 48] [took 0.00s]
 epoch          : 49
 loss           : 0.7746212173700333
 quant_reg      : 14.397442031860352
 quant_err      : 14.397442031860352
 learning_rate  : 4.26287951671541e-06
 n_samples      : 1568000
 n_steps        : 12250
 MSRVTT_jsfusion_test/t2v_metrics/R1: 27.7
 MSRVTT_jsfusion_test/t2v_metrics/R5: 55.0
 MSRVTT_jsfusion_test/t2v_metrics/R10: 68.5
 MSRVTT_jsfusion_test/t2v_metrics/R50: 87.4
 MSRVTT_jsfusion_test/t2v_metrics/MedR: 4.0
 MSRVTT_jsfusion_test/t2v_metrics/MeanR: 31.442
 MSRVTT_jsfusion_test/t2v_metrics/geometric_mean_R1-R5-R10: 47.080855239785926
 MSRVTT_jsfusion_test/v2t_metrics/R1: 26.5
 MSRVTT_jsfusion_test/v2t_metrics/R5: 58.6
 MSRVTT_jsfusion_test/v2t_metrics/R10: 69.2
 MSRVTT_jsfusion_test/v2t_metrics/R50: 87.8
 MSRVTT_jsfusion_test/v2t_metrics/MedR: 4.0
 MSRVTT_jsfusion_test/v2t_metrics/MeanR: 27.8275
 MSRVTT_jsfusion_test/v2t_metrics/geometric_mean_R1-R5-R10: 47.54262913615802
 mnt_best       : 47.36448169102165
 not_improved_count: 9
Train Epoch: 50 [1/250 128/32000 (0%)] Loss: 0.78117 (QuantReg: 14.39748) QuantErr: 14.39748 batch_time=29.25015 
Train Epoch: 50 [12/250 1536/32000 (5%)] Loss: 0.83521 (QuantReg: 14.31833) QuantErr: 14.31833 batch_time=2.98092 
Train Epoch: 50 [23/250 2944/32000 (9%)] Loss: 0.92642 (QuantReg: 14.34776) QuantErr: 14.34776 batch_time=0.67445 
Train Epoch: 50 [34/250 4352/32000 (14%)] Loss: 0.85161 (QuantReg: 14.28116) QuantErr: 14.28116 batch_time=0.68687 
Train Epoch: 50 [45/250 5760/32000 (18%)] Loss: 0.86804 (QuantReg: 14.13392) QuantErr: 14.13392 batch_time=0.66224 
Train Epoch: 50 [56/250 7168/32000 (22%)] Loss: 0.57906 (QuantReg: 14.38865) QuantErr: 14.38865 batch_time=0.65829 
Train Epoch: 50 [67/250 8576/32000 (27%)] Loss: 0.48668 (QuantReg: 14.38030) QuantErr: 14.38030 batch_time=0.79510 
Train Epoch: 50 [78/250 9984/32000 (31%)] Loss: 1.17203 (QuantReg: 14.37853) QuantErr: 14.37853 batch_time=0.66516 
Train Epoch: 50 [89/250 11392/32000 (36%)] Loss: 0.61524 (QuantReg: 14.46059) QuantErr: 14.46059 batch_time=0.65949 
Train Epoch: 50 [100/250 12800/32000 (40%)] Loss: 0.90989 (QuantReg: 14.26177) QuantErr: 14.26177 batch_time=2.06801 
Train Epoch: 50 [111/250 14208/32000 (44%)] Loss: 0.85292 (QuantReg: 14.56266) QuantErr: 14.56266 batch_time=0.66056 
Train Epoch: 50 [122/250 15616/32000 (49%)] Loss: 0.95131 (QuantReg: 14.33108) QuantErr: 14.33108 batch_time=0.65301 
Train Epoch: 50 [133/250 17024/32000 (53%)] Loss: 0.67980 (QuantReg: 14.62644) QuantErr: 14.62644 batch_time=0.66351 
Train Epoch: 50 [144/250 18432/32000 (58%)] Loss: 0.77555 (QuantReg: 14.53582) QuantErr: 14.53582 batch_time=2.57131 
Train Epoch: 50 [155/250 19840/32000 (62%)] Loss: 0.63378 (QuantReg: 14.43328) QuantErr: 14.43328 batch_time=0.67439 
Train Epoch: 50 [166/250 21248/32000 (66%)] Loss: 0.58984 (QuantReg: 14.54934) QuantErr: 14.54934 batch_time=0.67603 
Train Epoch: 50 [177/250 22656/32000 (71%)] Loss: 0.99336 (QuantReg: 14.36621) QuantErr: 14.36621 batch_time=0.66013 
Train Epoch: 50 [188/250 24064/32000 (75%)] Loss: 0.82555 (QuantReg: 14.38068) QuantErr: 14.38068 batch_time=0.64727 
Train Epoch: 50 [199/250 25472/32000 (80%)] Loss: 0.90074 (QuantReg: 14.28609) QuantErr: 14.28609 batch_time=2.15915 
Train Epoch: 50 [210/250 26880/32000 (84%)] Loss: 0.83561 (QuantReg: 14.28153) QuantErr: 14.28153 batch_time=0.64701 
Train Epoch: 50 [221/250 28288/32000 (88%)] Loss: 0.67299 (QuantReg: 14.29346) QuantErr: 14.29346 batch_time=0.69988 
Train Epoch: 50 [232/250 29696/32000 (93%)] Loss: 1.01842 (QuantReg: 14.51277) QuantErr: 14.51277 batch_time=0.69977 
Train Epoch: 50 [243/250 31104/32000 (97%)] Loss: 0.69464 (QuantReg: 14.51780) QuantErr: 14.51780 batch_time=0.65967 
Train Epoch: 50 codebook_update_time=1.88666
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_MSRVTT_1kA_roberta-large/checkpoint-epoch50.pth ...
Done in 11.447s
removing stale ckpt [epoch 49] [took 0.00s]
 epoch          : 50
 loss           : 0.7779118282794952
 quant_reg      : 14.394174011230469
 quant_err      : 14.394174011230469
 learning_rate  : 4.04973554087964e-06
 n_samples      : 1600000
 n_steps        : 12500
 MSRVTT_jsfusion_test/t2v_metrics/R1: 27.8
 MSRVTT_jsfusion_test/t2v_metrics/R5: 55.5
 MSRVTT_jsfusion_test/t2v_metrics/R10: 67.7
 MSRVTT_jsfusion_test/t2v_metrics/R50: 86.7
 MSRVTT_jsfusion_test/t2v_metrics/MedR: 4.0
 MSRVTT_jsfusion_test/t2v_metrics/MeanR: 31.986
 MSRVTT_jsfusion_test/t2v_metrics/geometric_mean_R1-R5-R10: 47.09507388493673
 MSRVTT_jsfusion_test/v2t_metrics/R1: 27.7
 MSRVTT_jsfusion_test/v2t_metrics/R5: 58.1
 MSRVTT_jsfusion_test/v2t_metrics/R10: 69.6
 MSRVTT_jsfusion_test/v2t_metrics/R50: 88.6
 MSRVTT_jsfusion_test/v2t_metrics/MedR: 4.0
 MSRVTT_jsfusion_test/v2t_metrics/MeanR: 28.0785
 MSRVTT_jsfusion_test/v2t_metrics/geometric_mean_R1-R5-R10: 48.20458855669549
 mnt_best       : 47.36448169102165
 not_improved_count: 10
Final evaluation ...
Loading checkpoint from: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_MSRVTT_1kA_roberta-large/trained_model.pth ...
Ckpt loaded at epoch 40.
Saved similarity matrix (quantize videos) to /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_MSRVTT_1kA_roberta-large/MSRVTT-test-qv-sims.npy
Saved v2t similarity matrix (quantize texts) to /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_MSRVTT_1kA_roberta-large/MSRVTT-test-qt-sims.npy
MSRVTT_jsfusion_test:
 t2v_metrics/R1/final_eval: 28.0
 t2v_metrics/R5/final_eval: 55.4
 t2v_metrics/R10/final_eval: 68.5
 t2v_metrics/R50/final_eval: 88.1
 t2v_metrics/MedR/final_eval: 4.0
 t2v_metrics/MeanR/final_eval: 30.666
 t2v_metrics/geometric_mean_R1-R5-R10/final_eval: 47.36448169102165
 v2t_metrics/R1/final_eval: 27.0
 v2t_metrics/R5/final_eval: 59.0
 v2t_metrics/R10/final_eval: 68.4
 v2t_metrics/R50/final_eval: 88.5
 v2t_metrics/MedR/final_eval: 4.0
 v2t_metrics/MeanR/final_eval: 27.411
 v2t_metrics/geometric_mean_R1-R5-R10/final_eval: 47.76289318601298
Best epoch for the monitored metric: 40
Script took 04h17m24s
The best performing ckpt can be found at /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_MSRVTT_1kA_roberta-large/trained_model.pth
