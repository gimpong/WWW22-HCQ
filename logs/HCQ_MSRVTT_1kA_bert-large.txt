Experiment directory: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_MSRVTT_1kA_bert-large
Preparing the dataloaders ...
Training ...
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_MSRVTT_1kA_bert-large/checkpoint-epoch0.pth ...
Done in 3.689s
Updating 'best' checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_MSRVTT_1kA_bert-large/checkpoint-epoch0.pth ...
Done in 7.560s
 epoch          : 0
 loss           : 0
 learning_rate  : 5e-05
 n_samples      : 0
 n_steps        : 0
 MSRVTT_jsfusion_test/t2v_metrics/R1: 0.1
 MSRVTT_jsfusion_test/t2v_metrics/R5: 0.5
 MSRVTT_jsfusion_test/t2v_metrics/R10: 0.9
 MSRVTT_jsfusion_test/t2v_metrics/R50: 6.1
 MSRVTT_jsfusion_test/t2v_metrics/MedR: 486.5
 MSRVTT_jsfusion_test/t2v_metrics/MeanR: 490.001
 MSRVTT_jsfusion_test/t2v_metrics/geometric_mean_R1-R5-R10: 0.3556893304490063
 MSRVTT_jsfusion_test/v2t_metrics/R1: 0.1
 MSRVTT_jsfusion_test/v2t_metrics/R5: 0.2
 MSRVTT_jsfusion_test/v2t_metrics/R10: 0.8
 MSRVTT_jsfusion_test/v2t_metrics/R50: 5.8
 MSRVTT_jsfusion_test/v2t_metrics/MedR: 467.5
 MSRVTT_jsfusion_test/v2t_metrics/MeanR: 487.826
 MSRVTT_jsfusion_test/v2t_metrics/geometric_mean_R1-R5-R10: 0.2519842099789747
 mnt_best       : 0.3556893304490063
 not_improved_count: 0
Train Epoch: 1 [1/250 128/32000 (0%)] Loss: 9.90157 (QuantReg: 22.62626) QuantErr: 22.62626 batch_time=51.59324 
Train Epoch: 1 [12/250 1536/32000 (5%)] Loss: 9.12747 (QuantReg: 22.73657) QuantErr: 22.73657 batch_time=0.88629 
Train Epoch: 1 [23/250 2944/32000 (9%)] Loss: 7.23432 (QuantReg: 22.54213) QuantErr: 22.54213 batch_time=0.65360 
Train Epoch: 1 [34/250 4352/32000 (14%)] Loss: 7.17346 (QuantReg: 22.48737) QuantErr: 22.48737 batch_time=1.95617 
Train Epoch: 1 [45/250 5760/32000 (18%)] Loss: 5.92079 (QuantReg: 22.58582) QuantErr: 22.58582 batch_time=0.68256 
Train Epoch: 1 [56/250 7168/32000 (22%)] Loss: 5.53785 (QuantReg: 22.59554) QuantErr: 22.59554 batch_time=0.63550 
Train Epoch: 1 [67/250 8576/32000 (27%)] Loss: 6.25629 (QuantReg: 22.63478) QuantErr: 22.63478 batch_time=0.77184 
Train Epoch: 1 [78/250 9984/32000 (31%)] Loss: 5.69528 (QuantReg: 22.61038) QuantErr: 22.61038 batch_time=1.76445 
Train Epoch: 1 [89/250 11392/32000 (36%)] Loss: 5.40410 (QuantReg: 22.61926) QuantErr: 22.61926 batch_time=0.65325 
Train Epoch: 1 [100/250 12800/32000 (40%)] Loss: 4.85936 (QuantReg: 22.63071) QuantErr: 22.63071 batch_time=0.69039 
Train Epoch: 1 [111/250 14208/32000 (44%)] Loss: 5.24883 (QuantReg: 22.61330) QuantErr: 22.61330 batch_time=0.66165 
Train Epoch: 1 [122/250 15616/32000 (49%)] Loss: 4.99816 (QuantReg: 22.62665) QuantErr: 22.62665 batch_time=0.67587 
Train Epoch: 1 [133/250 17024/32000 (53%)] Loss: 4.93215 (QuantReg: 22.59356) QuantErr: 22.59356 batch_time=0.83818 
Train Epoch: 1 [144/250 18432/32000 (58%)] Loss: 4.54260 (QuantReg: 22.64045) QuantErr: 22.64045 batch_time=0.68211 
Train Epoch: 1 [155/250 19840/32000 (62%)] Loss: 4.50378 (QuantReg: 22.61876) QuantErr: 22.61876 batch_time=0.70109 
Train Epoch: 1 [166/250 21248/32000 (66%)] Loss: 4.07526 (QuantReg: 22.62406) QuantErr: 22.62406 batch_time=0.65333 
Train Epoch: 1 [177/250 22656/32000 (71%)] Loss: 4.28675 (QuantReg: 22.62665) QuantErr: 22.62665 batch_time=0.65683 
Train Epoch: 1 [188/250 24064/32000 (75%)] Loss: 4.11598 (QuantReg: 22.60871) QuantErr: 22.60871 batch_time=0.68304 
Train Epoch: 1 [199/250 25472/32000 (80%)] Loss: 4.38517 (QuantReg: 22.67294) QuantErr: 22.67294 batch_time=0.71154 
Train Epoch: 1 [210/250 26880/32000 (84%)] Loss: 3.86324 (QuantReg: 22.63184) QuantErr: 22.63184 batch_time=0.67266 
Train Epoch: 1 [221/250 28288/32000 (88%)] Loss: 4.72173 (QuantReg: 22.63331) QuantErr: 22.63331 batch_time=0.72180 
Train Epoch: 1 [232/250 29696/32000 (93%)] Loss: 4.08901 (QuantReg: 22.65752) QuantErr: 22.65752 batch_time=0.68607 
Train Epoch: 1 [243/250 31104/32000 (97%)] Loss: 3.87725 (QuantReg: 22.63122) QuantErr: 22.63122 batch_time=0.67786 
Train Epoch: 1 codebook_update_time=1.72050
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_MSRVTT_1kA_bert-large/checkpoint-epoch1.pth ...
Done in 11.135s
Updating 'best' checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_MSRVTT_1kA_bert-large/checkpoint-epoch1.pth ...
Done in 22.381s
 epoch          : 1
 loss           : 5.341585871696473
 quant_reg      : 22.61388256072998
 quant_err      : 22.61388256072998
 learning_rate  : 5e-05
 n_samples      : 32000
 n_steps        : 250
 MSRVTT_jsfusion_test/t2v_metrics/R1: 11.7
 MSRVTT_jsfusion_test/t2v_metrics/R5: 33.3
 MSRVTT_jsfusion_test/t2v_metrics/R10: 47.7
 MSRVTT_jsfusion_test/t2v_metrics/R50: 81.2
 MSRVTT_jsfusion_test/t2v_metrics/MedR: 12.0
 MSRVTT_jsfusion_test/t2v_metrics/MeanR: 37.294
 MSRVTT_jsfusion_test/t2v_metrics/geometric_mean_R1-R5-R10: 26.48801974195142
 MSRVTT_jsfusion_test/v2t_metrics/R1: 11.3
 MSRVTT_jsfusion_test/v2t_metrics/R5: 34.4
 MSRVTT_jsfusion_test/v2t_metrics/R10: 49.6
 MSRVTT_jsfusion_test/v2t_metrics/R50: 80.5
 MSRVTT_jsfusion_test/v2t_metrics/MedR: 11.0
 MSRVTT_jsfusion_test/v2t_metrics/MeanR: 39.782
 MSRVTT_jsfusion_test/v2t_metrics/geometric_mean_R1-R5-R10: 26.814694547818867
 mnt_best       : 26.48801974195142
 not_improved_count: 0
Train Epoch: 2 [1/250 128/32000 (0%)] Loss: 4.00097 (QuantReg: 12.25031) QuantErr: 12.25031 batch_time=45.60027 
Train Epoch: 2 [12/250 1536/32000 (5%)] Loss: 3.96727 (QuantReg: 12.46347) QuantErr: 12.46347 batch_time=0.70176 
Train Epoch: 2 [23/250 2944/32000 (9%)] Loss: 3.84861 (QuantReg: 13.13649) QuantErr: 13.13649 batch_time=0.68861 
Train Epoch: 2 [34/250 4352/32000 (14%)] Loss: 3.61442 (QuantReg: 13.00640) QuantErr: 13.00640 batch_time=0.72764 
Train Epoch: 2 [45/250 5760/32000 (18%)] Loss: 5.05301 (QuantReg: 13.13036) QuantErr: 13.13036 batch_time=0.67746 
Train Epoch: 2 [56/250 7168/32000 (22%)] Loss: 3.87369 (QuantReg: 13.46346) QuantErr: 13.46346 batch_time=0.70868 
Train Epoch: 2 [67/250 8576/32000 (27%)] Loss: 3.79331 (QuantReg: 13.77826) QuantErr: 13.77826 batch_time=0.67038 
Train Epoch: 2 [78/250 9984/32000 (31%)] Loss: 3.46775 (QuantReg: 12.96553) QuantErr: 12.96553 batch_time=0.68681 
Train Epoch: 2 [89/250 11392/32000 (36%)] Loss: 3.91949 (QuantReg: 13.77348) QuantErr: 13.77348 batch_time=0.65942 
Train Epoch: 2 [100/250 12800/32000 (40%)] Loss: 3.45405 (QuantReg: 14.21213) QuantErr: 14.21213 batch_time=0.75893 
Train Epoch: 2 [111/250 14208/32000 (44%)] Loss: 3.73740 (QuantReg: 14.17816) QuantErr: 14.17816 batch_time=0.67763 
Train Epoch: 2 [122/250 15616/32000 (49%)] Loss: 4.10927 (QuantReg: 13.52417) QuantErr: 13.52417 batch_time=0.66275 
Train Epoch: 2 [133/250 17024/32000 (53%)] Loss: 4.22875 (QuantReg: 13.97401) QuantErr: 13.97401 batch_time=0.71021 
Train Epoch: 2 [144/250 18432/32000 (58%)] Loss: 3.89763 (QuantReg: 13.82999) QuantErr: 13.82999 batch_time=0.70909 
Train Epoch: 2 [155/250 19840/32000 (62%)] Loss: 3.38282 (QuantReg: 13.77207) QuantErr: 13.77207 batch_time=0.65929 
Train Epoch: 2 [166/250 21248/32000 (66%)] Loss: 3.56216 (QuantReg: 14.05404) QuantErr: 14.05404 batch_time=0.73461 
Train Epoch: 2 [177/250 22656/32000 (71%)] Loss: 3.58614 (QuantReg: 14.39092) QuantErr: 14.39092 batch_time=0.74633 
Train Epoch: 2 [188/250 24064/32000 (75%)] Loss: 3.18889 (QuantReg: 14.27547) QuantErr: 14.27547 batch_time=0.66954 
Train Epoch: 2 [199/250 25472/32000 (80%)] Loss: 3.52012 (QuantReg: 14.32135) QuantErr: 14.32135 batch_time=0.66389 
Train Epoch: 2 [210/250 26880/32000 (84%)] Loss: 3.45564 (QuantReg: 14.12117) QuantErr: 14.12117 batch_time=0.70689 
Train Epoch: 2 [221/250 28288/32000 (88%)] Loss: 3.25563 (QuantReg: 14.75181) QuantErr: 14.75181 batch_time=0.64890 
Train Epoch: 2 [232/250 29696/32000 (93%)] Loss: 2.77260 (QuantReg: 14.89141) QuantErr: 14.89141 batch_time=0.72592 
Train Epoch: 2 [243/250 31104/32000 (97%)] Loss: 3.83829 (QuantReg: 14.88797) QuantErr: 14.88797 batch_time=0.72097 
Train Epoch: 2 codebook_update_time=1.80841
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_MSRVTT_1kA_bert-large/checkpoint-epoch2.pth ...
Done in 11.007s
Updating 'best' checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_MSRVTT_1kA_bert-large/checkpoint-epoch2.pth ...
Done in 22.599s
removing stale ckpt [epoch 1] [took 0.04s]
removing stale ckpt [epoch 0] [took 0.03s]
 epoch          : 2
 loss           : 3.7270275983810426
 quant_reg      : 13.83795336151123
 quant_err      : 13.83795336151123
 learning_rate  : 4.75e-05
 n_samples      : 64000
 n_steps        : 500
 MSRVTT_jsfusion_test/t2v_metrics/R1: 13.6
 MSRVTT_jsfusion_test/t2v_metrics/R5: 38.8
 MSRVTT_jsfusion_test/t2v_metrics/R10: 54.6
 MSRVTT_jsfusion_test/t2v_metrics/R50: 84.5
 MSRVTT_jsfusion_test/t2v_metrics/MedR: 9.0
 MSRVTT_jsfusion_test/t2v_metrics/MeanR: 32.498999999999995
 MSRVTT_jsfusion_test/t2v_metrics/geometric_mean_R1-R5-R10: 30.656395636184513
 MSRVTT_jsfusion_test/v2t_metrics/R1: 14.5
 MSRVTT_jsfusion_test/v2t_metrics/R5: 41.1
 MSRVTT_jsfusion_test/v2t_metrics/R10: 56.7
 MSRVTT_jsfusion_test/v2t_metrics/R50: 83.7
 MSRVTT_jsfusion_test/v2t_metrics/MedR: 8.0
 MSRVTT_jsfusion_test/v2t_metrics/MeanR: 31.937
 MSRVTT_jsfusion_test/v2t_metrics/geometric_mean_R1-R5-R10: 32.32939873710492
 mnt_best       : 30.656395636184513
 not_improved_count: 0
Train Epoch: 3 [1/250 128/32000 (0%)] Loss: 3.71703 (QuantReg: 11.73929) QuantErr: 11.73929 batch_time=37.32081 
Train Epoch: 3 [12/250 1536/32000 (5%)] Loss: 3.30070 (QuantReg: 12.36005) QuantErr: 12.36005 batch_time=0.68351 
Train Epoch: 3 [23/250 2944/32000 (9%)] Loss: 3.76181 (QuantReg: 12.55981) QuantErr: 12.55981 batch_time=0.75750 
Train Epoch: 3 [34/250 4352/32000 (14%)] Loss: 3.08240 (QuantReg: 12.28752) QuantErr: 12.28752 batch_time=0.68159 
Train Epoch: 3 [45/250 5760/32000 (18%)] Loss: 2.72419 (QuantReg: 12.04693) QuantErr: 12.04693 batch_time=0.64852 
Train Epoch: 3 [56/250 7168/32000 (22%)] Loss: 2.86588 (QuantReg: 12.16188) QuantErr: 12.16188 batch_time=0.64134 
Train Epoch: 3 [67/250 8576/32000 (27%)] Loss: 3.30413 (QuantReg: 12.67384) QuantErr: 12.67384 batch_time=1.15097 
Train Epoch: 3 [78/250 9984/32000 (31%)] Loss: 3.51742 (QuantReg: 12.96263) QuantErr: 12.96263 batch_time=0.79169 
Train Epoch: 3 [89/250 11392/32000 (36%)] Loss: 3.20097 (QuantReg: 12.52099) QuantErr: 12.52099 batch_time=0.66961 
Train Epoch: 3 [100/250 12800/32000 (40%)] Loss: 3.23283 (QuantReg: 12.37053) QuantErr: 12.37053 batch_time=0.66887 
Train Epoch: 3 [111/250 14208/32000 (44%)] Loss: 2.75188 (QuantReg: 12.90039) QuantErr: 12.90039 batch_time=0.72388 
Train Epoch: 3 [122/250 15616/32000 (49%)] Loss: 3.44280 (QuantReg: 12.79505) QuantErr: 12.79505 batch_time=0.67242 
Train Epoch: 3 [133/250 17024/32000 (53%)] Loss: 3.12644 (QuantReg: 13.07330) QuantErr: 13.07330 batch_time=0.90755 
Train Epoch: 3 [144/250 18432/32000 (58%)] Loss: 2.94075 (QuantReg: 13.07922) QuantErr: 13.07922 batch_time=4.27536 
Train Epoch: 3 [155/250 19840/32000 (62%)] Loss: 2.95158 (QuantReg: 12.98240) QuantErr: 12.98240 batch_time=6.81130 
Train Epoch: 3 [166/250 21248/32000 (66%)] Loss: 3.05093 (QuantReg: 13.30937) QuantErr: 13.30937 batch_time=0.71829 
Train Epoch: 3 [177/250 22656/32000 (71%)] Loss: 2.65244 (QuantReg: 13.49017) QuantErr: 13.49017 batch_time=0.66089 
Train Epoch: 3 [188/250 24064/32000 (75%)] Loss: 2.84400 (QuantReg: 13.23790) QuantErr: 13.23790 batch_time=0.67486 
Train Epoch: 3 [199/250 25472/32000 (80%)] Loss: 3.24134 (QuantReg: 13.12080) QuantErr: 13.12080 batch_time=1.05770 
Train Epoch: 3 [210/250 26880/32000 (84%)] Loss: 3.15456 (QuantReg: 13.14541) QuantErr: 13.14541 batch_time=0.71729 
Train Epoch: 3 [221/250 28288/32000 (88%)] Loss: 3.69442 (QuantReg: 13.34395) QuantErr: 13.34395 batch_time=0.65955 
Train Epoch: 3 [232/250 29696/32000 (93%)] Loss: 2.83735 (QuantReg: 13.68658) QuantErr: 13.68658 batch_time=0.81369 
Train Epoch: 3 [243/250 31104/32000 (97%)] Loss: 2.92863 (QuantReg: 13.36873) QuantErr: 13.36873 batch_time=0.70518 
Train Epoch: 3 codebook_update_time=1.68283
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_MSRVTT_1kA_bert-large/checkpoint-epoch3.pth ...
Done in 11.100s
Updating 'best' checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_MSRVTT_1kA_bert-large/checkpoint-epoch3.pth ...
Done in 21.554s
removing stale ckpt [epoch 2] [took 0.00s]
 epoch          : 3
 loss           : 3.0887889194488527
 quant_reg      : 12.848927570343017
 quant_err      : 12.848927570343017
 learning_rate  : 4.5125e-05
 n_samples      : 96000
 n_steps        : 750
 MSRVTT_jsfusion_test/t2v_metrics/R1: 15.7
 MSRVTT_jsfusion_test/t2v_metrics/R5: 43.5
 MSRVTT_jsfusion_test/t2v_metrics/R10: 57.1
 MSRVTT_jsfusion_test/t2v_metrics/R50: 87.1
 MSRVTT_jsfusion_test/t2v_metrics/MedR: 7.0
 MSRVTT_jsfusion_test/t2v_metrics/MeanR: 30.217
 MSRVTT_jsfusion_test/t2v_metrics/geometric_mean_R1-R5-R10: 33.91108399227773
 MSRVTT_jsfusion_test/v2t_metrics/R1: 17.4
 MSRVTT_jsfusion_test/v2t_metrics/R5: 45.6
 MSRVTT_jsfusion_test/v2t_metrics/R10: 60.1
 MSRVTT_jsfusion_test/v2t_metrics/R50: 86.6
 MSRVTT_jsfusion_test/v2t_metrics/MedR: 7.0
 MSRVTT_jsfusion_test/v2t_metrics/MeanR: 29.721
 MSRVTT_jsfusion_test/v2t_metrics/geometric_mean_R1-R5-R10: 36.262926883930355
 mnt_best       : 33.91108399227773
 not_improved_count: 0
Train Epoch: 4 [1/250 128/32000 (0%)] Loss: 2.56724 (QuantReg: 11.80882) QuantErr: 11.80882 batch_time=38.39035 
Train Epoch: 4 [12/250 1536/32000 (5%)] Loss: 3.10112 (QuantReg: 12.21495) QuantErr: 12.21495 batch_time=0.73620 
Train Epoch: 4 [23/250 2944/32000 (9%)] Loss: 3.34405 (QuantReg: 12.35487) QuantErr: 12.35487 batch_time=0.65456 
Train Epoch: 4 [34/250 4352/32000 (14%)] Loss: 2.75701 (QuantReg: 12.17541) QuantErr: 12.17541 batch_time=0.69800 
Train Epoch: 4 [45/250 5760/32000 (18%)] Loss: 3.33252 (QuantReg: 12.77043) QuantErr: 12.77043 batch_time=0.71428 
Train Epoch: 4 [56/250 7168/32000 (22%)] Loss: 2.89109 (QuantReg: 12.15602) QuantErr: 12.15602 batch_time=0.67807 
Train Epoch: 4 [67/250 8576/32000 (27%)] Loss: 2.86110 (QuantReg: 12.33327) QuantErr: 12.33327 batch_time=0.63497 
Train Epoch: 4 [78/250 9984/32000 (31%)] Loss: 3.00007 (QuantReg: 12.41467) QuantErr: 12.41467 batch_time=0.68937 
Train Epoch: 4 [89/250 11392/32000 (36%)] Loss: 2.89684 (QuantReg: 12.56579) QuantErr: 12.56579 batch_time=0.68036 
Train Epoch: 4 [100/250 12800/32000 (40%)] Loss: 2.68911 (QuantReg: 12.41777) QuantErr: 12.41777 batch_time=0.68746 
Train Epoch: 4 [111/250 14208/32000 (44%)] Loss: 2.27930 (QuantReg: 13.14397) QuantErr: 13.14397 batch_time=0.73391 
Train Epoch: 4 [122/250 15616/32000 (49%)] Loss: 2.79919 (QuantReg: 12.60423) QuantErr: 12.60423 batch_time=0.65747 
Train Epoch: 4 [133/250 17024/32000 (53%)] Loss: 3.25580 (QuantReg: 12.78897) QuantErr: 12.78897 batch_time=0.66927 
Train Epoch: 4 [144/250 18432/32000 (58%)] Loss: 2.89205 (QuantReg: 12.55833) QuantErr: 12.55833 batch_time=0.67863 
Train Epoch: 4 [155/250 19840/32000 (62%)] Loss: 2.83380 (QuantReg: 12.62314) QuantErr: 12.62314 batch_time=0.66605 
Train Epoch: 4 [166/250 21248/32000 (66%)] Loss: 2.79427 (QuantReg: 12.82724) QuantErr: 12.82724 batch_time=0.71975 
Train Epoch: 4 [177/250 22656/32000 (71%)] Loss: 2.49351 (QuantReg: 13.03346) QuantErr: 13.03346 batch_time=0.70490 
Train Epoch: 4 [188/250 24064/32000 (75%)] Loss: 2.89925 (QuantReg: 12.57224) QuantErr: 12.57224 batch_time=0.67730 
Train Epoch: 4 [199/250 25472/32000 (80%)] Loss: 2.61024 (QuantReg: 13.16607) QuantErr: 13.16607 batch_time=0.68918 
Train Epoch: 4 [210/250 26880/32000 (84%)] Loss: 2.66471 (QuantReg: 13.18845) QuantErr: 13.18845 batch_time=0.78527 
Train Epoch: 4 [221/250 28288/32000 (88%)] Loss: 2.34186 (QuantReg: 12.90890) QuantErr: 12.90890 batch_time=0.66713 
Train Epoch: 4 [232/250 29696/32000 (93%)] Loss: 3.17614 (QuantReg: 13.12488) QuantErr: 13.12488 batch_time=0.66051 
Train Epoch: 4 [243/250 31104/32000 (97%)] Loss: 2.22345 (QuantReg: 13.08592) QuantErr: 13.08592 batch_time=0.80265 
Train Epoch: 4 codebook_update_time=1.80254
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_MSRVTT_1kA_bert-large/checkpoint-epoch4.pth ...
Done in 11.281s
Updating 'best' checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_MSRVTT_1kA_bert-large/checkpoint-epoch4.pth ...
Done in 22.451s
removing stale ckpt [epoch 3] [took 0.03s]
 epoch          : 4
 loss           : 2.724169358253479
 quant_reg      : 12.724106616973877
 quant_err      : 12.724106616973877
 learning_rate  : 4.2868749999999995e-05
 n_samples      : 128000
 n_steps        : 1000
 MSRVTT_jsfusion_test/t2v_metrics/R1: 18.4
 MSRVTT_jsfusion_test/t2v_metrics/R5: 44.7
 MSRVTT_jsfusion_test/t2v_metrics/R10: 58.3
 MSRVTT_jsfusion_test/t2v_metrics/R50: 86.2
 MSRVTT_jsfusion_test/t2v_metrics/MedR: 7.0
 MSRVTT_jsfusion_test/t2v_metrics/MeanR: 30.986
 MSRVTT_jsfusion_test/t2v_metrics/geometric_mean_R1-R5-R10: 36.32993607005325
 MSRVTT_jsfusion_test/v2t_metrics/R1: 17.7
 MSRVTT_jsfusion_test/v2t_metrics/R5: 46.3
 MSRVTT_jsfusion_test/v2t_metrics/R10: 59.8
 MSRVTT_jsfusion_test/v2t_metrics/R50: 86.5
 MSRVTT_jsfusion_test/v2t_metrics/MedR: 7.0
 MSRVTT_jsfusion_test/v2t_metrics/MeanR: 29.3235
 MSRVTT_jsfusion_test/v2t_metrics/geometric_mean_R1-R5-R10: 36.59472437321885
 mnt_best       : 36.32993607005325
 not_improved_count: 0
Train Epoch: 5 [1/250 128/32000 (0%)] Loss: 3.16937 (QuantReg: 11.96146) QuantErr: 11.96146 batch_time=44.61426 
Train Epoch: 5 [12/250 1536/32000 (5%)] Loss: 2.34986 (QuantReg: 12.13319) QuantErr: 12.13319 batch_time=0.66822 
Train Epoch: 5 [23/250 2944/32000 (9%)] Loss: 2.88271 (QuantReg: 12.44464) QuantErr: 12.44464 batch_time=0.71733 
Train Epoch: 5 [34/250 4352/32000 (14%)] Loss: 2.72054 (QuantReg: 12.51808) QuantErr: 12.51808 batch_time=0.71155 
Train Epoch: 5 [45/250 5760/32000 (18%)] Loss: 2.19941 (QuantReg: 12.14177) QuantErr: 12.14177 batch_time=0.68075 
Train Epoch: 5 [56/250 7168/32000 (22%)] Loss: 2.33108 (QuantReg: 12.30169) QuantErr: 12.30169 batch_time=0.77229 
Train Epoch: 5 [67/250 8576/32000 (27%)] Loss: 2.25907 (QuantReg: 12.70345) QuantErr: 12.70345 batch_time=0.65261 
Train Epoch: 5 [78/250 9984/32000 (31%)] Loss: 2.36410 (QuantReg: 12.78486) QuantErr: 12.78486 batch_time=0.68515 
Train Epoch: 5 [89/250 11392/32000 (36%)] Loss: 2.21037 (QuantReg: 12.43190) QuantErr: 12.43190 batch_time=0.71672 
Train Epoch: 5 [100/250 12800/32000 (40%)] Loss: 2.26417 (QuantReg: 12.48984) QuantErr: 12.48984 batch_time=0.67814 
Train Epoch: 5 [111/250 14208/32000 (44%)] Loss: 2.88886 (QuantReg: 12.94301) QuantErr: 12.94301 batch_time=0.67905 
Train Epoch: 5 [122/250 15616/32000 (49%)] Loss: 2.66016 (QuantReg: 12.36267) QuantErr: 12.36267 batch_time=0.68574 
Train Epoch: 5 [133/250 17024/32000 (53%)] Loss: 2.59169 (QuantReg: 12.58358) QuantErr: 12.58358 batch_time=0.67475 
Train Epoch: 5 [144/250 18432/32000 (58%)] Loss: 2.70235 (QuantReg: 12.26557) QuantErr: 12.26557 batch_time=9.79028 
Train Epoch: 5 [155/250 19840/32000 (62%)] Loss: 2.31859 (QuantReg: 12.79196) QuantErr: 12.79196 batch_time=0.70157 
Train Epoch: 5 [166/250 21248/32000 (66%)] Loss: 2.75836 (QuantReg: 13.01817) QuantErr: 13.01817 batch_time=0.84855 
Train Epoch: 5 [177/250 22656/32000 (71%)] Loss: 2.45380 (QuantReg: 12.92288) QuantErr: 12.92288 batch_time=0.74181 
Train Epoch: 5 [188/250 24064/32000 (75%)] Loss: 2.49698 (QuantReg: 12.92245) QuantErr: 12.92245 batch_time=0.67646 
Train Epoch: 5 [199/250 25472/32000 (80%)] Loss: 2.35395 (QuantReg: 13.26928) QuantErr: 13.26928 batch_time=0.67244 
Train Epoch: 5 [210/250 26880/32000 (84%)] Loss: 2.71963 (QuantReg: 12.77077) QuantErr: 12.77077 batch_time=1.21969 
Train Epoch: 5 [221/250 28288/32000 (88%)] Loss: 2.55992 (QuantReg: 12.92205) QuantErr: 12.92205 batch_time=0.68688 
Train Epoch: 5 [232/250 29696/32000 (93%)] Loss: 2.17863 (QuantReg: 12.90838) QuantErr: 12.90838 batch_time=0.66144 
Train Epoch: 5 [243/250 31104/32000 (97%)] Loss: 2.26882 (QuantReg: 12.81308) QuantErr: 12.81308 batch_time=0.64627 
Train Epoch: 5 codebook_update_time=1.70918
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_MSRVTT_1kA_bert-large/checkpoint-epoch5.pth ...
Done in 11.242s
Updating 'best' checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_MSRVTT_1kA_bert-large/checkpoint-epoch5.pth ...
Done in 22.054s
removing stale ckpt [epoch 4] [took 0.00s]
 epoch          : 5
 loss           : 2.4688736805915834
 quant_reg      : 12.673792861938477
 quant_err      : 12.673792861938477
 learning_rate  : 4.072531249999999e-05
 n_samples      : 160000
 n_steps        : 1250
 MSRVTT_jsfusion_test/t2v_metrics/R1: 20.6
 MSRVTT_jsfusion_test/t2v_metrics/R5: 47.7
 MSRVTT_jsfusion_test/t2v_metrics/R10: 60.5
 MSRVTT_jsfusion_test/t2v_metrics/R50: 87.5
 MSRVTT_jsfusion_test/t2v_metrics/MedR: 6.0
 MSRVTT_jsfusion_test/t2v_metrics/MeanR: 29.764
 MSRVTT_jsfusion_test/t2v_metrics/geometric_mean_R1-R5-R10: 39.02836201226121
 MSRVTT_jsfusion_test/v2t_metrics/R1: 19.1
 MSRVTT_jsfusion_test/v2t_metrics/R5: 50.1
 MSRVTT_jsfusion_test/v2t_metrics/R10: 62.8
 MSRVTT_jsfusion_test/v2t_metrics/R50: 87.8
 MSRVTT_jsfusion_test/v2t_metrics/MedR: 5.5
 MSRVTT_jsfusion_test/v2t_metrics/MeanR: 27.5175
 MSRVTT_jsfusion_test/v2t_metrics/geometric_mean_R1-R5-R10: 39.16909875546781
 mnt_best       : 39.02836201226121
 not_improved_count: 0
Train Epoch: 6 [1/250 128/32000 (0%)] Loss: 2.34602 (QuantReg: 12.31955) QuantErr: 12.31955 batch_time=39.79192 
Train Epoch: 6 [12/250 1536/32000 (5%)] Loss: 2.53791 (QuantReg: 12.47859) QuantErr: 12.47859 batch_time=0.74407 
Train Epoch: 6 [23/250 2944/32000 (9%)] Loss: 2.68014 (QuantReg: 12.73191) QuantErr: 12.73191 batch_time=0.69066 
Train Epoch: 6 [34/250 4352/32000 (14%)] Loss: 2.06548 (QuantReg: 12.33042) QuantErr: 12.33042 batch_time=0.80072 
Train Epoch: 6 [45/250 5760/32000 (18%)] Loss: 2.42596 (QuantReg: 12.55793) QuantErr: 12.55793 batch_time=0.69690 
Train Epoch: 6 [56/250 7168/32000 (22%)] Loss: 2.05675 (QuantReg: 12.66886) QuantErr: 12.66886 batch_time=0.67710 
Train Epoch: 6 [67/250 8576/32000 (27%)] Loss: 2.06190 (QuantReg: 12.67822) QuantErr: 12.67822 batch_time=1.18051 
Train Epoch: 6 [78/250 9984/32000 (31%)] Loss: 2.06354 (QuantReg: 12.66109) QuantErr: 12.66109 batch_time=0.65661 
Train Epoch: 6 [89/250 11392/32000 (36%)] Loss: 2.46403 (QuantReg: 12.39224) QuantErr: 12.39224 batch_time=0.67279 
Train Epoch: 6 [100/250 12800/32000 (40%)] Loss: 2.35806 (QuantReg: 13.28012) QuantErr: 13.28012 batch_time=0.67755 
Train Epoch: 6 [111/250 14208/32000 (44%)] Loss: 2.75112 (QuantReg: 13.07910) QuantErr: 13.07910 batch_time=0.66556 
Train Epoch: 6 [122/250 15616/32000 (49%)] Loss: 2.30767 (QuantReg: 12.72870) QuantErr: 12.72870 batch_time=0.68626 
Train Epoch: 6 [133/250 17024/32000 (53%)] Loss: 2.09832 (QuantReg: 12.80555) QuantErr: 12.80555 batch_time=0.68844 
Train Epoch: 6 [144/250 18432/32000 (58%)] Loss: 2.56312 (QuantReg: 13.01658) QuantErr: 13.01658 batch_time=1.58946 
Train Epoch: 6 [155/250 19840/32000 (62%)] Loss: 1.97964 (QuantReg: 12.87312) QuantErr: 12.87312 batch_time=0.65816 
Train Epoch: 6 [166/250 21248/32000 (66%)] Loss: 2.36515 (QuantReg: 13.02428) QuantErr: 13.02428 batch_time=0.83648 
Train Epoch: 6 [177/250 22656/32000 (71%)] Loss: 2.10061 (QuantReg: 12.71294) QuantErr: 12.71294 batch_time=0.65672 
Train Epoch: 6 [188/250 24064/32000 (75%)] Loss: 2.04125 (QuantReg: 12.74667) QuantErr: 12.74667 batch_time=0.70146 
Train Epoch: 6 [199/250 25472/32000 (80%)] Loss: 2.26533 (QuantReg: 13.28871) QuantErr: 13.28871 batch_time=0.78303 
Train Epoch: 6 [210/250 26880/32000 (84%)] Loss: 2.02739 (QuantReg: 12.96090) QuantErr: 12.96090 batch_time=0.68731 
Train Epoch: 6 [221/250 28288/32000 (88%)] Loss: 2.03240 (QuantReg: 13.14815) QuantErr: 13.14815 batch_time=0.67567 
Train Epoch: 6 [232/250 29696/32000 (93%)] Loss: 2.63262 (QuantReg: 12.81305) QuantErr: 12.81305 batch_time=0.66241 
Train Epoch: 6 [243/250 31104/32000 (97%)] Loss: 2.48605 (QuantReg: 13.16372) QuantErr: 13.16372 batch_time=0.72362 
Train Epoch: 6 codebook_update_time=1.69888
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_MSRVTT_1kA_bert-large/checkpoint-epoch6.pth ...
Done in 10.572s
removing stale ckpt [epoch 5] [took 0.00s]
 epoch          : 6
 loss           : 2.325248544692993
 quant_reg      : 12.806637077331542
 quant_err      : 12.806637077331542
 learning_rate  : 3.868904687499999e-05
 n_samples      : 192000
 n_steps        : 1500
 MSRVTT_jsfusion_test/t2v_metrics/R1: 19.4
 MSRVTT_jsfusion_test/t2v_metrics/R5: 47.6
 MSRVTT_jsfusion_test/t2v_metrics/R10: 60.9
 MSRVTT_jsfusion_test/t2v_metrics/R50: 86.4
 MSRVTT_jsfusion_test/t2v_metrics/MedR: 6.0
 MSRVTT_jsfusion_test/t2v_metrics/MeanR: 29.202
 MSRVTT_jsfusion_test/t2v_metrics/geometric_mean_R1-R5-R10: 38.31263231797979
 MSRVTT_jsfusion_test/v2t_metrics/R1: 19.3
 MSRVTT_jsfusion_test/v2t_metrics/R5: 49.9
 MSRVTT_jsfusion_test/v2t_metrics/R10: 63.4
 MSRVTT_jsfusion_test/v2t_metrics/R50: 87.4
 MSRVTT_jsfusion_test/v2t_metrics/MedR: 6.0
 MSRVTT_jsfusion_test/v2t_metrics/MeanR: 28.076
 MSRVTT_jsfusion_test/v2t_metrics/geometric_mean_R1-R5-R10: 39.37758136095879
 mnt_best       : 39.02836201226121
 not_improved_count: 1
Train Epoch: 7 [1/250 128/32000 (0%)] Loss: 1.89974 (QuantReg: 13.04079) QuantErr: 13.04079 batch_time=50.37739 
Train Epoch: 7 [12/250 1536/32000 (5%)] Loss: 2.38080 (QuantReg: 12.47096) QuantErr: 12.47096 batch_time=0.66822 
Train Epoch: 7 [23/250 2944/32000 (9%)] Loss: 2.13624 (QuantReg: 12.40967) QuantErr: 12.40967 batch_time=0.66347 
Train Epoch: 7 [34/250 4352/32000 (14%)] Loss: 2.16767 (QuantReg: 12.72051) QuantErr: 12.72051 batch_time=0.70058 
Train Epoch: 7 [45/250 5760/32000 (18%)] Loss: 2.43570 (QuantReg: 12.61013) QuantErr: 12.61013 batch_time=0.69793 
Train Epoch: 7 [56/250 7168/32000 (22%)] Loss: 2.48013 (QuantReg: 12.68746) QuantErr: 12.68746 batch_time=0.66952 
Train Epoch: 7 [67/250 8576/32000 (27%)] Loss: 2.23507 (QuantReg: 12.47050) QuantErr: 12.47050 batch_time=0.64963 
Train Epoch: 7 [78/250 9984/32000 (31%)] Loss: 2.01794 (QuantReg: 12.74138) QuantErr: 12.74138 batch_time=0.70599 
Train Epoch: 7 [89/250 11392/32000 (36%)] Loss: 1.85782 (QuantReg: 12.69280) QuantErr: 12.69280 batch_time=0.69849 
Train Epoch: 7 [100/250 12800/32000 (40%)] Loss: 2.10601 (QuantReg: 12.47057) QuantErr: 12.47057 batch_time=0.67436 
Train Epoch: 7 [111/250 14208/32000 (44%)] Loss: 2.15547 (QuantReg: 12.88379) QuantErr: 12.88379 batch_time=0.68206 
Train Epoch: 7 [122/250 15616/32000 (49%)] Loss: 1.72685 (QuantReg: 13.19197) QuantErr: 13.19197 batch_time=0.78218 
Train Epoch: 7 [133/250 17024/32000 (53%)] Loss: 2.43163 (QuantReg: 12.60202) QuantErr: 12.60202 batch_time=0.72378 
Train Epoch: 7 [144/250 18432/32000 (58%)] Loss: 1.99695 (QuantReg: 12.98296) QuantErr: 12.98296 batch_time=0.73088 
Train Epoch: 7 [155/250 19840/32000 (62%)] Loss: 2.76225 (QuantReg: 12.65994) QuantErr: 12.65994 batch_time=0.67991 
Train Epoch: 7 [166/250 21248/32000 (66%)] Loss: 2.39965 (QuantReg: 13.07555) QuantErr: 13.07555 batch_time=0.70018 
Train Epoch: 7 [177/250 22656/32000 (71%)] Loss: 1.91651 (QuantReg: 13.14035) QuantErr: 13.14035 batch_time=0.68016 
Train Epoch: 7 [188/250 24064/32000 (75%)] Loss: 2.12203 (QuantReg: 12.83861) QuantErr: 12.83861 batch_time=0.66642 
Train Epoch: 7 [199/250 25472/32000 (80%)] Loss: 2.15899 (QuantReg: 12.98417) QuantErr: 12.98417 batch_time=0.85514 
Train Epoch: 7 [210/250 26880/32000 (84%)] Loss: 1.78550 (QuantReg: 12.72717) QuantErr: 12.72717 batch_time=0.67995 
Train Epoch: 7 [221/250 28288/32000 (88%)] Loss: 2.24455 (QuantReg: 13.19365) QuantErr: 13.19365 batch_time=0.66882 
Train Epoch: 7 [232/250 29696/32000 (93%)] Loss: 2.20508 (QuantReg: 12.77380) QuantErr: 12.77380 batch_time=0.65351 
Train Epoch: 7 [243/250 31104/32000 (97%)] Loss: 2.56891 (QuantReg: 12.60416) QuantErr: 12.60416 batch_time=0.83092 
Train Epoch: 7 codebook_update_time=1.67586
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_MSRVTT_1kA_bert-large/checkpoint-epoch7.pth ...
Done in 10.676s
removing stale ckpt [epoch 6] [took 0.00s]
 epoch          : 7
 loss           : 2.2067505569458006
 quant_reg      : 12.78955094909668
 quant_err      : 12.78955094909668
 learning_rate  : 3.675459453124999e-05
 n_samples      : 224000
 n_steps        : 1750
 MSRVTT_jsfusion_test/t2v_metrics/R1: 19.1
 MSRVTT_jsfusion_test/t2v_metrics/R5: 49.0
 MSRVTT_jsfusion_test/t2v_metrics/R10: 63.3
 MSRVTT_jsfusion_test/t2v_metrics/R50: 87.9
 MSRVTT_jsfusion_test/t2v_metrics/MedR: 6.0
 MSRVTT_jsfusion_test/t2v_metrics/MeanR: 29.158
 MSRVTT_jsfusion_test/t2v_metrics/geometric_mean_R1-R5-R10: 38.98322092150765
 MSRVTT_jsfusion_test/v2t_metrics/R1: 18.6
 MSRVTT_jsfusion_test/v2t_metrics/R5: 50.9
 MSRVTT_jsfusion_test/v2t_metrics/R10: 64.1
 MSRVTT_jsfusion_test/v2t_metrics/R50: 87.2
 MSRVTT_jsfusion_test/v2t_metrics/MedR: 5.0
 MSRVTT_jsfusion_test/v2t_metrics/MeanR: 27.1165
 MSRVTT_jsfusion_test/v2t_metrics/geometric_mean_R1-R5-R10: 39.297318673127386
 mnt_best       : 39.02836201226121
 not_improved_count: 2
Train Epoch: 8 [1/250 128/32000 (0%)] Loss: 1.92135 (QuantReg: 12.33555) QuantErr: 12.33555 batch_time=38.06044 
Train Epoch: 8 [12/250 1536/32000 (5%)] Loss: 1.84798 (QuantReg: 12.53349) QuantErr: 12.53349 batch_time=0.70142 
Train Epoch: 8 [23/250 2944/32000 (9%)] Loss: 1.91674 (QuantReg: 12.15306) QuantErr: 12.15306 batch_time=0.74813 
Train Epoch: 8 [34/250 4352/32000 (14%)] Loss: 1.87012 (QuantReg: 12.76036) QuantErr: 12.76036 batch_time=0.66969 
Train Epoch: 8 [45/250 5760/32000 (18%)] Loss: 2.37068 (QuantReg: 12.19043) QuantErr: 12.19043 batch_time=0.72347 
Train Epoch: 8 [56/250 7168/32000 (22%)] Loss: 1.99200 (QuantReg: 12.73616) QuantErr: 12.73616 batch_time=0.66047 
Train Epoch: 8 [67/250 8576/32000 (27%)] Loss: 1.96305 (QuantReg: 13.13259) QuantErr: 13.13259 batch_time=0.68921 
Train Epoch: 8 [78/250 9984/32000 (31%)] Loss: 2.15674 (QuantReg: 12.62141) QuantErr: 12.62141 batch_time=0.93969 
Train Epoch: 8 [89/250 11392/32000 (36%)] Loss: 2.08352 (QuantReg: 12.79387) QuantErr: 12.79387 batch_time=0.67224 
Train Epoch: 8 [100/250 12800/32000 (40%)] Loss: 2.29817 (QuantReg: 12.89079) QuantErr: 12.89079 batch_time=0.70384 
Train Epoch: 8 [111/250 14208/32000 (44%)] Loss: 2.10334 (QuantReg: 12.80278) QuantErr: 12.80278 batch_time=0.68633 
Train Epoch: 8 [122/250 15616/32000 (49%)] Loss: 1.81608 (QuantReg: 13.40682) QuantErr: 13.40682 batch_time=0.67644 
Train Epoch: 8 [133/250 17024/32000 (53%)] Loss: 1.94083 (QuantReg: 12.91917) QuantErr: 12.91917 batch_time=0.68183 
Train Epoch: 8 [144/250 18432/32000 (58%)] Loss: 2.79277 (QuantReg: 12.83317) QuantErr: 12.83317 batch_time=0.95962 
Train Epoch: 8 [155/250 19840/32000 (62%)] Loss: 2.03768 (QuantReg: 12.71921) QuantErr: 12.71921 batch_time=0.70701 
Train Epoch: 8 [166/250 21248/32000 (66%)] Loss: 1.73747 (QuantReg: 13.36383) QuantErr: 13.36383 batch_time=0.67838 
Train Epoch: 8 [177/250 22656/32000 (71%)] Loss: 1.91070 (QuantReg: 13.11424) QuantErr: 13.11424 batch_time=0.69050 
Train Epoch: 8 [188/250 24064/32000 (75%)] Loss: 2.03665 (QuantReg: 12.85205) QuantErr: 12.85205 batch_time=0.67977 
Train Epoch: 8 [199/250 25472/32000 (80%)] Loss: 1.79848 (QuantReg: 13.20968) QuantErr: 13.20968 batch_time=0.66895 
Train Epoch: 8 [210/250 26880/32000 (84%)] Loss: 1.89337 (QuantReg: 13.01411) QuantErr: 13.01411 batch_time=0.91433 
Train Epoch: 8 [221/250 28288/32000 (88%)] Loss: 2.15412 (QuantReg: 13.04590) QuantErr: 13.04590 batch_time=0.69362 
Train Epoch: 8 [232/250 29696/32000 (93%)] Loss: 1.85256 (QuantReg: 13.02162) QuantErr: 13.02162 batch_time=0.67423 
Train Epoch: 8 [243/250 31104/32000 (97%)] Loss: 1.78732 (QuantReg: 13.33591) QuantErr: 13.33591 batch_time=0.66942 
Train Epoch: 8 codebook_update_time=1.64853
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_MSRVTT_1kA_bert-large/checkpoint-epoch8.pth ...
Done in 10.808s
Updating 'best' checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_MSRVTT_1kA_bert-large/checkpoint-epoch8.pth ...
Done in 21.003s
removing stale ckpt [epoch 7] [took 0.00s]
 epoch          : 8
 loss           : 2.064859663963318
 quant_reg      : 12.879175846099853
 quant_err      : 12.879175846099853
 learning_rate  : 3.4916864804687486e-05
 n_samples      : 256000
 n_steps        : 2000
 MSRVTT_jsfusion_test/t2v_metrics/R1: 21.3
 MSRVTT_jsfusion_test/t2v_metrics/R5: 49.9
 MSRVTT_jsfusion_test/t2v_metrics/R10: 64.4
 MSRVTT_jsfusion_test/t2v_metrics/R50: 87.6
 MSRVTT_jsfusion_test/t2v_metrics/MedR: 6.0
 MSRVTT_jsfusion_test/t2v_metrics/MeanR: 28.976
 MSRVTT_jsfusion_test/t2v_metrics/geometric_mean_R1-R5-R10: 40.90615617825036
 MSRVTT_jsfusion_test/v2t_metrics/R1: 21.1
 MSRVTT_jsfusion_test/v2t_metrics/R5: 51.8
 MSRVTT_jsfusion_test/v2t_metrics/R10: 64.8
 MSRVTT_jsfusion_test/v2t_metrics/R50: 88.2
 MSRVTT_jsfusion_test/v2t_metrics/MedR: 5.0
 MSRVTT_jsfusion_test/v2t_metrics/MeanR: 27.3635
 MSRVTT_jsfusion_test/v2t_metrics/geometric_mean_R1-R5-R10: 41.37414895277925
 mnt_best       : 40.90615617825036
 not_improved_count: 0
Train Epoch: 9 [1/250 128/32000 (0%)] Loss: 1.63067 (QuantReg: 12.75302) QuantErr: 12.75302 batch_time=46.89231 
Train Epoch: 9 [12/250 1536/32000 (5%)] Loss: 2.18140 (QuantReg: 12.56495) QuantErr: 12.56495 batch_time=0.97986 
Train Epoch: 9 [23/250 2944/32000 (9%)] Loss: 2.16610 (QuantReg: 12.85226) QuantErr: 12.85226 batch_time=0.67957 
Train Epoch: 9 [34/250 4352/32000 (14%)] Loss: 1.75529 (QuantReg: 12.86785) QuantErr: 12.86785 batch_time=0.65744 
Train Epoch: 9 [45/250 5760/32000 (18%)] Loss: 1.98973 (QuantReg: 12.73166) QuantErr: 12.73166 batch_time=0.92948 
Train Epoch: 9 [56/250 7168/32000 (22%)] Loss: 2.18916 (QuantReg: 12.81564) QuantErr: 12.81564 batch_time=0.65714 
Train Epoch: 9 [67/250 8576/32000 (27%)] Loss: 2.15209 (QuantReg: 13.21482) QuantErr: 13.21482 batch_time=1.38110 
Train Epoch: 9 [78/250 9984/32000 (31%)] Loss: 1.65117 (QuantReg: 12.89679) QuantErr: 12.89679 batch_time=0.77713 
Train Epoch: 9 [89/250 11392/32000 (36%)] Loss: 1.85827 (QuantReg: 12.97694) QuantErr: 12.97694 batch_time=0.67025 
Train Epoch: 9 [100/250 12800/32000 (40%)] Loss: 2.15676 (QuantReg: 12.59340) QuantErr: 12.59340 batch_time=0.65925 
Train Epoch: 9 [111/250 14208/32000 (44%)] Loss: 2.29775 (QuantReg: 12.76477) QuantErr: 12.76477 batch_time=0.71823 
Train Epoch: 9 [122/250 15616/32000 (49%)] Loss: 1.89757 (QuantReg: 12.73691) QuantErr: 12.73691 batch_time=0.70201 
Train Epoch: 9 [133/250 17024/32000 (53%)] Loss: 2.06680 (QuantReg: 13.04430) QuantErr: 13.04430 batch_time=0.66787 
Train Epoch: 9 [144/250 18432/32000 (58%)] Loss: 2.99460 (QuantReg: 12.96343) QuantErr: 12.96343 batch_time=0.66676 
Train Epoch: 9 [155/250 19840/32000 (62%)] Loss: 2.11427 (QuantReg: 12.96784) QuantErr: 12.96784 batch_time=0.68481 
Train Epoch: 9 [166/250 21248/32000 (66%)] Loss: 1.72216 (QuantReg: 13.30892) QuantErr: 13.30892 batch_time=0.71019 
Train Epoch: 9 [177/250 22656/32000 (71%)] Loss: 1.95586 (QuantReg: 12.93145) QuantErr: 12.93145 batch_time=0.67853 
Train Epoch: 9 [188/250 24064/32000 (75%)] Loss: 2.50777 (QuantReg: 12.56325) QuantErr: 12.56325 batch_time=0.70834 
Train Epoch: 9 [199/250 25472/32000 (80%)] Loss: 1.49784 (QuantReg: 12.66166) QuantErr: 12.66166 batch_time=0.68125 
Train Epoch: 9 [210/250 26880/32000 (84%)] Loss: 1.63119 (QuantReg: 13.05695) QuantErr: 13.05695 batch_time=0.73773 
Train Epoch: 9 [221/250 28288/32000 (88%)] Loss: 2.24626 (QuantReg: 13.20031) QuantErr: 13.20031 batch_time=0.68210 
Train Epoch: 9 [232/250 29696/32000 (93%)] Loss: 1.98714 (QuantReg: 12.95722) QuantErr: 12.95722 batch_time=0.69827 
Train Epoch: 9 [243/250 31104/32000 (97%)] Loss: 1.73188 (QuantReg: 13.63284) QuantErr: 13.63284 batch_time=0.68266 
Train Epoch: 9 codebook_update_time=2.01511
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_MSRVTT_1kA_bert-large/checkpoint-epoch9.pth ...
Done in 10.601s
Updating 'best' checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_MSRVTT_1kA_bert-large/checkpoint-epoch9.pth ...
Done in 20.446s
removing stale ckpt [epoch 8] [took 0.00s]
 epoch          : 9
 loss           : 1.9555841941833496
 quant_reg      : 12.95854084777832
 quant_err      : 12.95854084777832
 learning_rate  : 3.317102156445311e-05
 n_samples      : 288000
 n_steps        : 2250
 MSRVTT_jsfusion_test/t2v_metrics/R1: 21.2
 MSRVTT_jsfusion_test/t2v_metrics/R5: 50.3
 MSRVTT_jsfusion_test/t2v_metrics/R10: 65.8
 MSRVTT_jsfusion_test/t2v_metrics/R50: 88.6
 MSRVTT_jsfusion_test/t2v_metrics/MedR: 5.0
 MSRVTT_jsfusion_test/t2v_metrics/MeanR: 28.068
 MSRVTT_jsfusion_test/t2v_metrics/geometric_mean_R1-R5-R10: 41.24550067852522
 MSRVTT_jsfusion_test/v2t_metrics/R1: 19.6
 MSRVTT_jsfusion_test/v2t_metrics/R5: 52.1
 MSRVTT_jsfusion_test/v2t_metrics/R10: 65.5
 MSRVTT_jsfusion_test/v2t_metrics/R50: 88.9
 MSRVTT_jsfusion_test/v2t_metrics/MedR: 5.0
 MSRVTT_jsfusion_test/v2t_metrics/MeanR: 26.3765
 MSRVTT_jsfusion_test/v2t_metrics/geometric_mean_R1-R5-R10: 40.59242823522422
 mnt_best       : 41.24550067852522
 not_improved_count: 0
Train Epoch: 10 [1/250 128/32000 (0%)] Loss: 1.56730 (QuantReg: 13.05787) QuantErr: 13.05787 batch_time=41.41368 
Train Epoch: 10 [12/250 1536/32000 (5%)] Loss: 1.75459 (QuantReg: 12.79918) QuantErr: 12.79918 batch_time=0.68467 
Train Epoch: 10 [23/250 2944/32000 (9%)] Loss: 1.85192 (QuantReg: 13.07512) QuantErr: 13.07512 batch_time=6.98280 
Train Epoch: 10 [34/250 4352/32000 (14%)] Loss: 1.84410 (QuantReg: 12.98655) QuantErr: 12.98655 batch_time=0.68863 
Train Epoch: 10 [45/250 5760/32000 (18%)] Loss: 1.85532 (QuantReg: 13.16661) QuantErr: 13.16661 batch_time=0.66255 
Train Epoch: 10 [56/250 7168/32000 (22%)] Loss: 2.03436 (QuantReg: 13.01301) QuantErr: 13.01301 batch_time=0.66131 
Train Epoch: 10 [67/250 8576/32000 (27%)] Loss: 1.45372 (QuantReg: 13.16368) QuantErr: 13.16368 batch_time=1.05695 
Train Epoch: 10 [78/250 9984/32000 (31%)] Loss: 1.47569 (QuantReg: 12.89957) QuantErr: 12.89957 batch_time=0.70787 
Train Epoch: 10 [89/250 11392/32000 (36%)] Loss: 1.79065 (QuantReg: 12.91309) QuantErr: 12.91309 batch_time=0.88069 
Train Epoch: 10 [100/250 12800/32000 (40%)] Loss: 1.30891 (QuantReg: 13.13867) QuantErr: 13.13867 batch_time=0.66449 
Train Epoch: 10 [111/250 14208/32000 (44%)] Loss: 1.30504 (QuantReg: 13.15297) QuantErr: 13.15297 batch_time=0.65718 
Train Epoch: 10 [122/250 15616/32000 (49%)] Loss: 2.26490 (QuantReg: 13.27831) QuantErr: 13.27831 batch_time=0.69616 
Train Epoch: 10 [133/250 17024/32000 (53%)] Loss: 2.07814 (QuantReg: 13.06802) QuantErr: 13.06802 batch_time=0.67249 
Train Epoch: 10 [144/250 18432/32000 (58%)] Loss: 1.90023 (QuantReg: 12.68777) QuantErr: 12.68777 batch_time=3.53264 
Train Epoch: 10 [155/250 19840/32000 (62%)] Loss: 1.90486 (QuantReg: 13.11092) QuantErr: 13.11092 batch_time=0.67626 
Train Epoch: 10 [166/250 21248/32000 (66%)] Loss: 2.03468 (QuantReg: 13.06591) QuantErr: 13.06591 batch_time=0.71850 
Train Epoch: 10 [177/250 22656/32000 (71%)] Loss: 2.11661 (QuantReg: 12.97004) QuantErr: 12.97004 batch_time=0.68472 
Train Epoch: 10 [188/250 24064/32000 (75%)] Loss: 2.16705 (QuantReg: 12.97047) QuantErr: 12.97047 batch_time=0.79297 
Train Epoch: 10 [199/250 25472/32000 (80%)] Loss: 1.85437 (QuantReg: 13.11772) QuantErr: 13.11772 batch_time=0.70285 
Train Epoch: 10 [210/250 26880/32000 (84%)] Loss: 1.41050 (QuantReg: 12.94862) QuantErr: 12.94862 batch_time=1.47114 
Train Epoch: 10 [221/250 28288/32000 (88%)] Loss: 1.73957 (QuantReg: 13.38424) QuantErr: 13.38424 batch_time=0.67250 
Train Epoch: 10 [232/250 29696/32000 (93%)] Loss: 2.17801 (QuantReg: 13.04232) QuantErr: 13.04232 batch_time=0.66859 
Train Epoch: 10 [243/250 31104/32000 (97%)] Loss: 1.85158 (QuantReg: 13.13027) QuantErr: 13.13027 batch_time=0.65021 
Train Epoch: 10 codebook_update_time=1.75188
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_MSRVTT_1kA_bert-large/checkpoint-epoch10.pth ...
Done in 12.247s
removing stale ckpt [epoch 9] [took 0.00s]
 epoch          : 10
 loss           : 1.8418220162391663
 quant_reg      : 13.030643161773682
 quant_err      : 13.030643161773682
 learning_rate  : 3.151247048623045e-05
 n_samples      : 320000
 n_steps        : 2500
 MSRVTT_jsfusion_test/t2v_metrics/R1: 20.8
 MSRVTT_jsfusion_test/t2v_metrics/R5: 51.0
 MSRVTT_jsfusion_test/t2v_metrics/R10: 63.7
 MSRVTT_jsfusion_test/t2v_metrics/R50: 87.9
 MSRVTT_jsfusion_test/t2v_metrics/MedR: 5.0
 MSRVTT_jsfusion_test/t2v_metrics/MeanR: 29.031
 MSRVTT_jsfusion_test/t2v_metrics/geometric_mean_R1-R5-R10: 40.73092888578557
 MSRVTT_jsfusion_test/v2t_metrics/R1: 21.6
 MSRVTT_jsfusion_test/v2t_metrics/R5: 50.2
 MSRVTT_jsfusion_test/v2t_metrics/R10: 63.4
 MSRVTT_jsfusion_test/v2t_metrics/R50: 88.4
 MSRVTT_jsfusion_test/v2t_metrics/MedR: 5.0
 MSRVTT_jsfusion_test/v2t_metrics/MeanR: 27.41
 MSRVTT_jsfusion_test/v2t_metrics/geometric_mean_R1-R5-R10: 40.965246774581246
 mnt_best       : 41.24550067852522
 not_improved_count: 1
Train Epoch: 11 [1/250 128/32000 (0%)] Loss: 1.63531 (QuantReg: 12.98085) QuantErr: 12.98085 batch_time=32.70881 
Train Epoch: 11 [12/250 1536/32000 (5%)] Loss: 2.02283 (QuantReg: 13.17005) QuantErr: 13.17005 batch_time=0.69694 
Train Epoch: 11 [23/250 2944/32000 (9%)] Loss: 1.67630 (QuantReg: 13.27692) QuantErr: 13.27692 batch_time=0.67408 
Train Epoch: 11 [34/250 4352/32000 (14%)] Loss: 1.38226 (QuantReg: 13.42606) QuantErr: 13.42606 batch_time=0.66047 
Train Epoch: 11 [45/250 5760/32000 (18%)] Loss: 1.88246 (QuantReg: 12.93668) QuantErr: 12.93668 batch_time=0.66610 
Train Epoch: 11 [56/250 7168/32000 (22%)] Loss: 1.66848 (QuantReg: 13.01418) QuantErr: 13.01418 batch_time=0.68351 
Train Epoch: 11 [67/250 8576/32000 (27%)] Loss: 1.43695 (QuantReg: 13.07819) QuantErr: 13.07819 batch_time=1.06355 
Train Epoch: 11 [78/250 9984/32000 (31%)] Loss: 1.64399 (QuantReg: 12.67999) QuantErr: 12.67999 batch_time=2.29633 
Train Epoch: 11 [89/250 11392/32000 (36%)] Loss: 1.71769 (QuantReg: 13.13142) QuantErr: 13.13142 batch_time=0.65302 
Train Epoch: 11 [100/250 12800/32000 (40%)] Loss: 2.08170 (QuantReg: 13.00027) QuantErr: 13.00027 batch_time=0.66931 
Train Epoch: 11 [111/250 14208/32000 (44%)] Loss: 1.54992 (QuantReg: 13.30259) QuantErr: 13.30259 batch_time=0.73757 
Train Epoch: 11 [122/250 15616/32000 (49%)] Loss: 1.79663 (QuantReg: 12.97376) QuantErr: 12.97376 batch_time=0.67582 
Train Epoch: 11 [133/250 17024/32000 (53%)] Loss: 1.60772 (QuantReg: 12.90645) QuantErr: 12.90645 batch_time=0.69969 
Train Epoch: 11 [144/250 18432/32000 (58%)] Loss: 1.78623 (QuantReg: 13.37091) QuantErr: 13.37091 batch_time=1.09362 
Train Epoch: 11 [155/250 19840/32000 (62%)] Loss: 1.58040 (QuantReg: 13.31945) QuantErr: 13.31945 batch_time=0.68837 
Train Epoch: 11 [166/250 21248/32000 (66%)] Loss: 1.83462 (QuantReg: 13.56709) QuantErr: 13.56709 batch_time=0.69988 
Train Epoch: 11 [177/250 22656/32000 (71%)] Loss: 1.48447 (QuantReg: 13.38585) QuantErr: 13.38585 batch_time=0.83196 
Train Epoch: 11 [188/250 24064/32000 (75%)] Loss: 1.89874 (QuantReg: 13.47739) QuantErr: 13.47739 batch_time=0.68050 
Train Epoch: 11 [199/250 25472/32000 (80%)] Loss: 1.79637 (QuantReg: 13.30304) QuantErr: 13.30304 batch_time=0.69441 
Train Epoch: 11 [210/250 26880/32000 (84%)] Loss: 1.52495 (QuantReg: 13.08452) QuantErr: 13.08452 batch_time=1.93805 
Train Epoch: 11 [221/250 28288/32000 (88%)] Loss: 1.54371 (QuantReg: 13.24548) QuantErr: 13.24548 batch_time=0.88646 
Train Epoch: 11 [232/250 29696/32000 (93%)] Loss: 1.45085 (QuantReg: 13.27028) QuantErr: 13.27028 batch_time=0.70198 
Train Epoch: 11 [243/250 31104/32000 (97%)] Loss: 1.64957 (QuantReg: 13.26912) QuantErr: 13.26912 batch_time=0.64993 
Train Epoch: 11 codebook_update_time=2.57269
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_MSRVTT_1kA_bert-large/checkpoint-epoch11.pth ...
Done in 10.838s
removing stale ckpt [epoch 10] [took 0.00s]
 epoch          : 11
 loss           : 1.732420111656189
 quant_reg      : 13.092788791656494
 quant_err      : 13.092788791656494
 learning_rate  : 2.993684696191893e-05
 n_samples      : 352000
 n_steps        : 2750
 MSRVTT_jsfusion_test/t2v_metrics/R1: 20.4
 MSRVTT_jsfusion_test/t2v_metrics/R5: 51.4
 MSRVTT_jsfusion_test/t2v_metrics/R10: 65.1
 MSRVTT_jsfusion_test/t2v_metrics/R50: 88.0
 MSRVTT_jsfusion_test/t2v_metrics/MedR: 5.0
 MSRVTT_jsfusion_test/t2v_metrics/MeanR: 28.774
 MSRVTT_jsfusion_test/t2v_metrics/geometric_mean_R1-R5-R10: 40.86875661451874
 MSRVTT_jsfusion_test/v2t_metrics/R1: 21.0
 MSRVTT_jsfusion_test/v2t_metrics/R5: 52.6
 MSRVTT_jsfusion_test/v2t_metrics/R10: 64.6
 MSRVTT_jsfusion_test/v2t_metrics/R50: 88.2
 MSRVTT_jsfusion_test/v2t_metrics/MedR: 5.0
 MSRVTT_jsfusion_test/v2t_metrics/MeanR: 27.077
 MSRVTT_jsfusion_test/v2t_metrics/geometric_mean_R1-R5-R10: 41.477494934899674
 mnt_best       : 41.24550067852522
 not_improved_count: 2
Train Epoch: 12 [1/250 128/32000 (0%)] Loss: 1.93456 (QuantReg: 12.94293) QuantErr: 12.94293 batch_time=28.90318 
Train Epoch: 12 [12/250 1536/32000 (5%)] Loss: 1.98956 (QuantReg: 13.01849) QuantErr: 13.01849 batch_time=0.79900 
Train Epoch: 12 [23/250 2944/32000 (9%)] Loss: 1.60024 (QuantReg: 13.02558) QuantErr: 13.02558 batch_time=0.73684 
Train Epoch: 12 [34/250 4352/32000 (14%)] Loss: 1.76839 (QuantReg: 12.75871) QuantErr: 12.75871 batch_time=0.67510 
Train Epoch: 12 [45/250 5760/32000 (18%)] Loss: 1.78005 (QuantReg: 12.95717) QuantErr: 12.95717 batch_time=0.95086 
Train Epoch: 12 [56/250 7168/32000 (22%)] Loss: 1.66656 (QuantReg: 12.87292) QuantErr: 12.87292 batch_time=0.71744 
Train Epoch: 12 [67/250 8576/32000 (27%)] Loss: 1.66866 (QuantReg: 13.15747) QuantErr: 13.15747 batch_time=0.70423 
Train Epoch: 12 [78/250 9984/32000 (31%)] Loss: 2.22817 (QuantReg: 12.65633) QuantErr: 12.65633 batch_time=0.66234 
Train Epoch: 12 [89/250 11392/32000 (36%)] Loss: 1.69043 (QuantReg: 12.84387) QuantErr: 12.84387 batch_time=0.67176 
Train Epoch: 12 [100/250 12800/32000 (40%)] Loss: 1.97508 (QuantReg: 12.71885) QuantErr: 12.71885 batch_time=0.69728 
Train Epoch: 12 [111/250 14208/32000 (44%)] Loss: 1.70008 (QuantReg: 12.97799) QuantErr: 12.97799 batch_time=0.67104 
Train Epoch: 12 [122/250 15616/32000 (49%)] Loss: 1.75434 (QuantReg: 13.01962) QuantErr: 13.01962 batch_time=0.66832 
Train Epoch: 12 [133/250 17024/32000 (53%)] Loss: 1.71787 (QuantReg: 13.40906) QuantErr: 13.40906 batch_time=1.16000 
Train Epoch: 12 [144/250 18432/32000 (58%)] Loss: 1.57455 (QuantReg: 13.35262) QuantErr: 13.35262 batch_time=0.96128 
Train Epoch: 12 [155/250 19840/32000 (62%)] Loss: 1.43631 (QuantReg: 13.19624) QuantErr: 13.19624 batch_time=0.69954 
Train Epoch: 12 [166/250 21248/32000 (66%)] Loss: 1.53452 (QuantReg: 12.89735) QuantErr: 12.89735 batch_time=0.67885 
Train Epoch: 12 [177/250 22656/32000 (71%)] Loss: 1.58105 (QuantReg: 13.39559) QuantErr: 13.39559 batch_time=0.68124 
Train Epoch: 12 [188/250 24064/32000 (75%)] Loss: 1.39386 (QuantReg: 13.22013) QuantErr: 13.22013 batch_time=0.69030 
Train Epoch: 12 [199/250 25472/32000 (80%)] Loss: 1.76834 (QuantReg: 13.11258) QuantErr: 13.11258 batch_time=0.64830 
Train Epoch: 12 [210/250 26880/32000 (84%)] Loss: 1.94220 (QuantReg: 13.17049) QuantErr: 13.17049 batch_time=0.84185 
Train Epoch: 12 [221/250 28288/32000 (88%)] Loss: 1.37268 (QuantReg: 13.15080) QuantErr: 13.15080 batch_time=0.68251 
Train Epoch: 12 [232/250 29696/32000 (93%)] Loss: 1.96040 (QuantReg: 13.07991) QuantErr: 13.07991 batch_time=0.67382 
Train Epoch: 12 [243/250 31104/32000 (97%)] Loss: 2.32240 (QuantReg: 13.21557) QuantErr: 13.21557 batch_time=0.73687 
Train Epoch: 12 codebook_update_time=1.71677
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_MSRVTT_1kA_bert-large/checkpoint-epoch12.pth ...
Done in 11.474s
Updating 'best' checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_MSRVTT_1kA_bert-large/checkpoint-epoch12.pth ...
Done in 22.617s
removing stale ckpt [epoch 11] [took 0.00s]
 epoch          : 12
 loss           : 1.662465238571167
 quant_reg      : 13.08859691619873
 quant_err      : 13.08859691619873
 learning_rate  : 2.844000461382298e-05
 n_samples      : 384000
 n_steps        : 3000
 MSRVTT_jsfusion_test/t2v_metrics/R1: 21.7
 MSRVTT_jsfusion_test/t2v_metrics/R5: 51.5
 MSRVTT_jsfusion_test/t2v_metrics/R10: 66.2
 MSRVTT_jsfusion_test/t2v_metrics/R50: 89.4
 MSRVTT_jsfusion_test/t2v_metrics/MedR: 5.0
 MSRVTT_jsfusion_test/t2v_metrics/MeanR: 27.387
 MSRVTT_jsfusion_test/t2v_metrics/geometric_mean_R1-R5-R10: 41.979924267890894
 MSRVTT_jsfusion_test/v2t_metrics/R1: 22.0
 MSRVTT_jsfusion_test/v2t_metrics/R5: 53.5
 MSRVTT_jsfusion_test/v2t_metrics/R10: 65.6
 MSRVTT_jsfusion_test/v2t_metrics/R50: 89.0
 MSRVTT_jsfusion_test/v2t_metrics/MedR: 5.0
 MSRVTT_jsfusion_test/v2t_metrics/MeanR: 26.265
 MSRVTT_jsfusion_test/v2t_metrics/geometric_mean_R1-R5-R10: 42.58206979050199
 mnt_best       : 41.979924267890894
 not_improved_count: 0
Train Epoch: 13 [1/250 128/32000 (0%)] Loss: 1.53495 (QuantReg: 13.17280) QuantErr: 13.17280 batch_time=55.87834 
Train Epoch: 13 [12/250 1536/32000 (5%)] Loss: 1.36079 (QuantReg: 12.74875) QuantErr: 12.74875 batch_time=0.65085 
Train Epoch: 13 [23/250 2944/32000 (9%)] Loss: 1.34280 (QuantReg: 13.38146) QuantErr: 13.38146 batch_time=0.77318 
Train Epoch: 13 [34/250 4352/32000 (14%)] Loss: 1.38978 (QuantReg: 13.18074) QuantErr: 13.18074 batch_time=0.77579 
Train Epoch: 13 [45/250 5760/32000 (18%)] Loss: 1.47547 (QuantReg: 13.03444) QuantErr: 13.03444 batch_time=0.68630 
Train Epoch: 13 [56/250 7168/32000 (22%)] Loss: 1.81621 (QuantReg: 13.09687) QuantErr: 13.09687 batch_time=0.69333 
Train Epoch: 13 [67/250 8576/32000 (27%)] Loss: 1.85001 (QuantReg: 13.01064) QuantErr: 13.01064 batch_time=0.71349 
Train Epoch: 13 [78/250 9984/32000 (31%)] Loss: 1.50828 (QuantReg: 13.07046) QuantErr: 13.07046 batch_time=0.65563 
Train Epoch: 13 [89/250 11392/32000 (36%)] Loss: 1.34386 (QuantReg: 13.22663) QuantErr: 13.22663 batch_time=0.67244 
Train Epoch: 13 [100/250 12800/32000 (40%)] Loss: 1.69107 (QuantReg: 13.28848) QuantErr: 13.28848 batch_time=0.66212 
Train Epoch: 13 [111/250 14208/32000 (44%)] Loss: 1.80889 (QuantReg: 13.06190) QuantErr: 13.06190 batch_time=0.69712 
Train Epoch: 13 [122/250 15616/32000 (49%)] Loss: 1.41982 (QuantReg: 13.24881) QuantErr: 13.24881 batch_time=0.65216 
Train Epoch: 13 [133/250 17024/32000 (53%)] Loss: 1.50093 (QuantReg: 13.56364) QuantErr: 13.56364 batch_time=1.50287 
Train Epoch: 13 [144/250 18432/32000 (58%)] Loss: 2.01440 (QuantReg: 13.39202) QuantErr: 13.39202 batch_time=0.68047 
Train Epoch: 13 [155/250 19840/32000 (62%)] Loss: 1.75475 (QuantReg: 12.96403) QuantErr: 12.96403 batch_time=0.71456 
Train Epoch: 13 [166/250 21248/32000 (66%)] Loss: 1.59944 (QuantReg: 12.93272) QuantErr: 12.93272 batch_time=0.65646 
Train Epoch: 13 [177/250 22656/32000 (71%)] Loss: 1.42257 (QuantReg: 13.57654) QuantErr: 13.57654 batch_time=0.82207 
Train Epoch: 13 [188/250 24064/32000 (75%)] Loss: 1.26970 (QuantReg: 13.65975) QuantErr: 13.65975 batch_time=0.69177 
Train Epoch: 13 [199/250 25472/32000 (80%)] Loss: 2.06218 (QuantReg: 13.30068) QuantErr: 13.30068 batch_time=0.70138 
Train Epoch: 13 [210/250 26880/32000 (84%)] Loss: 1.73086 (QuantReg: 13.24579) QuantErr: 13.24579 batch_time=0.66589 
Train Epoch: 13 [221/250 28288/32000 (88%)] Loss: 1.77847 (QuantReg: 13.38855) QuantErr: 13.38855 batch_time=0.68624 
Train Epoch: 13 [232/250 29696/32000 (93%)] Loss: 1.21703 (QuantReg: 13.27078) QuantErr: 13.27078 batch_time=0.65536 
Train Epoch: 13 [243/250 31104/32000 (97%)] Loss: 1.21918 (QuantReg: 13.44851) QuantErr: 13.44851 batch_time=0.69751 
Train Epoch: 13 codebook_update_time=1.74880
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_MSRVTT_1kA_bert-large/checkpoint-epoch13.pth ...
Done in 11.922s
Updating 'best' checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_MSRVTT_1kA_bert-large/checkpoint-epoch13.pth ...
Done in 22.706s
removing stale ckpt [epoch 12] [took 0.04s]
 epoch          : 13
 loss           : 1.5876945526599884
 quant_reg      : 13.18521439743042
 quant_err      : 13.18521439743042
 learning_rate  : 2.7018004383131832e-05
 n_samples      : 416000
 n_steps        : 3250
 MSRVTT_jsfusion_test/t2v_metrics/R1: 22.6
 MSRVTT_jsfusion_test/t2v_metrics/R5: 52.9
 MSRVTT_jsfusion_test/t2v_metrics/R10: 65.3
 MSRVTT_jsfusion_test/t2v_metrics/R50: 88.7
 MSRVTT_jsfusion_test/t2v_metrics/MedR: 5.0
 MSRVTT_jsfusion_test/t2v_metrics/MeanR: 27.864
 MSRVTT_jsfusion_test/t2v_metrics/geometric_mean_R1-R5-R10: 42.73913853770691
 MSRVTT_jsfusion_test/v2t_metrics/R1: 21.6
 MSRVTT_jsfusion_test/v2t_metrics/R5: 52.9
 MSRVTT_jsfusion_test/v2t_metrics/R10: 67.0
 MSRVTT_jsfusion_test/v2t_metrics/R50: 88.9
 MSRVTT_jsfusion_test/v2t_metrics/MedR: 5.0
 MSRVTT_jsfusion_test/v2t_metrics/MeanR: 26.0745
 MSRVTT_jsfusion_test/v2t_metrics/geometric_mean_R1-R5-R10: 42.46144230747454
 mnt_best       : 42.73913853770691
 not_improved_count: 0
Train Epoch: 14 [1/250 128/32000 (0%)] Loss: 1.82980 (QuantReg: 12.86997) QuantErr: 12.86997 batch_time=46.32866 
Train Epoch: 14 [12/250 1536/32000 (5%)] Loss: 1.64474 (QuantReg: 13.45485) QuantErr: 13.45485 batch_time=0.77969 
Train Epoch: 14 [23/250 2944/32000 (9%)] Loss: 1.75441 (QuantReg: 13.13675) QuantErr: 13.13675 batch_time=5.06946 
Train Epoch: 14 [34/250 4352/32000 (14%)] Loss: 1.63841 (QuantReg: 12.88261) QuantErr: 12.88261 batch_time=0.69152 
Train Epoch: 14 [45/250 5760/32000 (18%)] Loss: 1.80605 (QuantReg: 13.26412) QuantErr: 13.26412 batch_time=0.78104 
Train Epoch: 14 [56/250 7168/32000 (22%)] Loss: 1.32961 (QuantReg: 13.45867) QuantErr: 13.45867 batch_time=0.66956 
Train Epoch: 14 [67/250 8576/32000 (27%)] Loss: 1.62956 (QuantReg: 12.71856) QuantErr: 12.71856 batch_time=0.66933 
Train Epoch: 14 [78/250 9984/32000 (31%)] Loss: 1.70472 (QuantReg: 12.98042) QuantErr: 12.98042 batch_time=9.11781 
Train Epoch: 14 [89/250 11392/32000 (36%)] Loss: 1.59269 (QuantReg: 13.31730) QuantErr: 13.31730 batch_time=0.72864 
Train Epoch: 14 [100/250 12800/32000 (40%)] Loss: 1.26199 (QuantReg: 13.01326) QuantErr: 13.01326 batch_time=0.66934 
Train Epoch: 14 [111/250 14208/32000 (44%)] Loss: 1.53338 (QuantReg: 13.20979) QuantErr: 13.20979 batch_time=0.66973 
Train Epoch: 14 [122/250 15616/32000 (49%)] Loss: 1.54985 (QuantReg: 13.22293) QuantErr: 13.22293 batch_time=0.69860 
Train Epoch: 14 [133/250 17024/32000 (53%)] Loss: 1.39698 (QuantReg: 13.18803) QuantErr: 13.18803 batch_time=0.68819 
Train Epoch: 14 [144/250 18432/32000 (58%)] Loss: 1.64346 (QuantReg: 13.16248) QuantErr: 13.16248 batch_time=0.81374 
Train Epoch: 14 [155/250 19840/32000 (62%)] Loss: 1.32577 (QuantReg: 13.30675) QuantErr: 13.30675 batch_time=0.71191 
Train Epoch: 14 [166/250 21248/32000 (66%)] Loss: 1.23464 (QuantReg: 13.32730) QuantErr: 13.32730 batch_time=0.67417 
Train Epoch: 14 [177/250 22656/32000 (71%)] Loss: 1.48810 (QuantReg: 13.32815) QuantErr: 13.32815 batch_time=0.72107 
Train Epoch: 14 [188/250 24064/32000 (75%)] Loss: 1.09813 (QuantReg: 13.13550) QuantErr: 13.13550 batch_time=0.82679 
Train Epoch: 14 [199/250 25472/32000 (80%)] Loss: 1.39766 (QuantReg: 13.42980) QuantErr: 13.42980 batch_time=0.72531 
Train Epoch: 14 [210/250 26880/32000 (84%)] Loss: 1.39406 (QuantReg: 12.77509) QuantErr: 12.77509 batch_time=0.66238 
Train Epoch: 14 [221/250 28288/32000 (88%)] Loss: 1.20672 (QuantReg: 13.32870) QuantErr: 13.32870 batch_time=1.45840 
Train Epoch: 14 [232/250 29696/32000 (93%)] Loss: 1.56298 (QuantReg: 13.31357) QuantErr: 13.31357 batch_time=0.65582 
Train Epoch: 14 [243/250 31104/32000 (97%)] Loss: 1.55628 (QuantReg: 13.39360) QuantErr: 13.39360 batch_time=0.71237 
Train Epoch: 14 codebook_update_time=1.72540
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_MSRVTT_1kA_bert-large/checkpoint-epoch14.pth ...
Done in 11.169s
Updating 'best' checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_MSRVTT_1kA_bert-large/checkpoint-epoch14.pth ...
Done in 22.405s
removing stale ckpt [epoch 13] [took 0.03s]
 epoch          : 14
 loss           : 1.5497506308555602
 quant_reg      : 13.227337394714356
 quant_err      : 13.227337394714356
 learning_rate  : 2.566710416397524e-05
 n_samples      : 448000
 n_steps        : 3500
 MSRVTT_jsfusion_test/t2v_metrics/R1: 22.7
 MSRVTT_jsfusion_test/t2v_metrics/R5: 53.2
 MSRVTT_jsfusion_test/t2v_metrics/R10: 66.2
 MSRVTT_jsfusion_test/t2v_metrics/R50: 88.4
 MSRVTT_jsfusion_test/t2v_metrics/MedR: 5.0
 MSRVTT_jsfusion_test/t2v_metrics/MeanR: 27.657
 MSRVTT_jsfusion_test/t2v_metrics/geometric_mean_R1-R5-R10: 43.078954991150574
 MSRVTT_jsfusion_test/v2t_metrics/R1: 23.0
 MSRVTT_jsfusion_test/v2t_metrics/R5: 53.7
 MSRVTT_jsfusion_test/v2t_metrics/R10: 66.6
 MSRVTT_jsfusion_test/v2t_metrics/R50: 88.7
 MSRVTT_jsfusion_test/v2t_metrics/MedR: 5.0
 MSRVTT_jsfusion_test/v2t_metrics/MeanR: 26.348
 MSRVTT_jsfusion_test/v2t_metrics/geometric_mean_R1-R5-R10: 43.49027130830663
 mnt_best       : 43.078954991150574
 not_improved_count: 0
Train Epoch: 15 [1/250 128/32000 (0%)] Loss: 1.60673 (QuantReg: 13.08305) QuantErr: 13.08305 batch_time=43.20338 
Train Epoch: 15 [12/250 1536/32000 (5%)] Loss: 1.46315 (QuantReg: 13.14190) QuantErr: 13.14190 batch_time=0.72696 
Train Epoch: 15 [23/250 2944/32000 (9%)] Loss: 1.26776 (QuantReg: 13.29253) QuantErr: 13.29253 batch_time=0.67278 
Train Epoch: 15 [34/250 4352/32000 (14%)] Loss: 1.60742 (QuantReg: 13.64537) QuantErr: 13.64537 batch_time=0.75791 
Train Epoch: 15 [45/250 5760/32000 (18%)] Loss: 1.48636 (QuantReg: 13.10649) QuantErr: 13.10649 batch_time=0.73699 
Train Epoch: 15 [56/250 7168/32000 (22%)] Loss: 1.58639 (QuantReg: 13.27367) QuantErr: 13.27367 batch_time=0.72034 
Train Epoch: 15 [67/250 8576/32000 (27%)] Loss: 1.15520 (QuantReg: 13.20648) QuantErr: 13.20648 batch_time=5.91605 
Train Epoch: 15 [78/250 9984/32000 (31%)] Loss: 1.33757 (QuantReg: 13.32266) QuantErr: 13.32266 batch_time=0.67937 
Train Epoch: 15 [89/250 11392/32000 (36%)] Loss: 1.41709 (QuantReg: 13.63945) QuantErr: 13.63945 batch_time=0.71030 
Train Epoch: 15 [100/250 12800/32000 (40%)] Loss: 1.40691 (QuantReg: 13.14390) QuantErr: 13.14390 batch_time=0.68305 
Train Epoch: 15 [111/250 14208/32000 (44%)] Loss: 1.48253 (QuantReg: 12.80666) QuantErr: 12.80666 batch_time=0.75873 
Train Epoch: 15 [122/250 15616/32000 (49%)] Loss: 1.37509 (QuantReg: 13.02249) QuantErr: 13.02249 batch_time=0.75957 
Train Epoch: 15 [133/250 17024/32000 (53%)] Loss: 1.32180 (QuantReg: 13.53933) QuantErr: 13.53933 batch_time=0.78472 
Train Epoch: 15 [144/250 18432/32000 (58%)] Loss: 1.40724 (QuantReg: 13.38583) QuantErr: 13.38583 batch_time=0.75232 
Train Epoch: 15 [155/250 19840/32000 (62%)] Loss: 1.60707 (QuantReg: 13.24297) QuantErr: 13.24297 batch_time=0.63085 
Train Epoch: 15 [166/250 21248/32000 (66%)] Loss: 1.17240 (QuantReg: 13.48298) QuantErr: 13.48298 batch_time=0.70572 
Train Epoch: 15 [177/250 22656/32000 (71%)] Loss: 1.14157 (QuantReg: 13.59701) QuantErr: 13.59701 batch_time=0.68175 
Train Epoch: 15 [188/250 24064/32000 (75%)] Loss: 1.61488 (QuantReg: 13.44520) QuantErr: 13.44520 batch_time=0.70589 
Train Epoch: 15 [199/250 25472/32000 (80%)] Loss: 1.47734 (QuantReg: 13.57072) QuantErr: 13.57072 batch_time=0.70274 
Train Epoch: 15 [210/250 26880/32000 (84%)] Loss: 1.37351 (QuantReg: 13.34203) QuantErr: 13.34203 batch_time=1.13384 
Train Epoch: 15 [221/250 28288/32000 (88%)] Loss: 1.67944 (QuantReg: 13.38450) QuantErr: 13.38450 batch_time=0.64962 
Train Epoch: 15 [232/250 29696/32000 (93%)] Loss: 1.71614 (QuantReg: 12.86998) QuantErr: 12.86998 batch_time=0.69376 
Train Epoch: 15 [243/250 31104/32000 (97%)] Loss: 1.17582 (QuantReg: 13.11736) QuantErr: 13.11736 batch_time=0.73705 
Train Epoch: 15 codebook_update_time=1.75183
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_MSRVTT_1kA_bert-large/checkpoint-epoch15.pth ...
Done in 28.719s
Updating 'best' checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_MSRVTT_1kA_bert-large/checkpoint-epoch15.pth ...
Done in 40.261s
removing stale ckpt [epoch 14] [took 0.04s]
 epoch          : 15
 loss           : 1.486278640985489
 quant_reg      : 13.262633167266845
 quant_err      : 13.262633167266845
 learning_rate  : 2.4383748955776477e-05
 n_samples      : 480000
 n_steps        : 3750
 MSRVTT_jsfusion_test/t2v_metrics/R1: 23.6
 MSRVTT_jsfusion_test/t2v_metrics/R5: 52.8
 MSRVTT_jsfusion_test/t2v_metrics/R10: 67.5
 MSRVTT_jsfusion_test/t2v_metrics/R50: 88.0
 MSRVTT_jsfusion_test/t2v_metrics/MedR: 5.0
 MSRVTT_jsfusion_test/t2v_metrics/MeanR: 27.741
 MSRVTT_jsfusion_test/t2v_metrics/geometric_mean_R1-R5-R10: 43.81436946431534
 MSRVTT_jsfusion_test/v2t_metrics/R1: 23.0
 MSRVTT_jsfusion_test/v2t_metrics/R5: 54.1
 MSRVTT_jsfusion_test/v2t_metrics/R10: 67.2
 MSRVTT_jsfusion_test/v2t_metrics/R50: 89.0
 MSRVTT_jsfusion_test/v2t_metrics/MedR: 5.0
 MSRVTT_jsfusion_test/v2t_metrics/MeanR: 26.2225
 MSRVTT_jsfusion_test/v2t_metrics/geometric_mean_R1-R5-R10: 43.72852126642668
 mnt_best       : 43.81436946431534
 not_improved_count: 0
Train Epoch: 16 [1/250 128/32000 (0%)] Loss: 1.52697 (QuantReg: 12.72495) QuantErr: 12.72495 batch_time=55.05464 
Train Epoch: 16 [12/250 1536/32000 (5%)] Loss: 1.22866 (QuantReg: 13.53498) QuantErr: 13.53498 batch_time=6.41629 
Train Epoch: 16 [23/250 2944/32000 (9%)] Loss: 1.50029 (QuantReg: 13.35563) QuantErr: 13.35563 batch_time=0.64986 
Train Epoch: 16 [34/250 4352/32000 (14%)] Loss: 1.37912 (QuantReg: 13.16278) QuantErr: 13.16278 batch_time=0.68731 
Train Epoch: 16 [45/250 5760/32000 (18%)] Loss: 1.12874 (QuantReg: 13.51981) QuantErr: 13.51981 batch_time=0.85084 
Train Epoch: 16 [56/250 7168/32000 (22%)] Loss: 1.42865 (QuantReg: 13.32908) QuantErr: 13.32908 batch_time=0.72809 
Train Epoch: 16 [67/250 8576/32000 (27%)] Loss: 1.32560 (QuantReg: 13.15163) QuantErr: 13.15163 batch_time=0.63893 
Train Epoch: 16 [78/250 9984/32000 (31%)] Loss: 1.58961 (QuantReg: 13.02431) QuantErr: 13.02431 batch_time=0.65009 
Train Epoch: 16 [89/250 11392/32000 (36%)] Loss: 1.65973 (QuantReg: 12.73236) QuantErr: 12.73236 batch_time=0.70835 
Train Epoch: 16 [100/250 12800/32000 (40%)] Loss: 1.36518 (QuantReg: 13.22608) QuantErr: 13.22608 batch_time=0.68780 
Train Epoch: 16 [111/250 14208/32000 (44%)] Loss: 1.74784 (QuantReg: 13.36645) QuantErr: 13.36645 batch_time=0.65711 
Train Epoch: 16 [122/250 15616/32000 (49%)] Loss: 1.34857 (QuantReg: 13.16656) QuantErr: 13.16656 batch_time=0.68249 
Train Epoch: 16 [133/250 17024/32000 (53%)] Loss: 1.53109 (QuantReg: 13.31872) QuantErr: 13.31872 batch_time=0.68505 
Train Epoch: 16 [144/250 18432/32000 (58%)] Loss: 1.60845 (QuantReg: 13.33637) QuantErr: 13.33637 batch_time=6.59515 
Train Epoch: 16 [155/250 19840/32000 (62%)] Loss: 1.48669 (QuantReg: 13.07620) QuantErr: 13.07620 batch_time=0.65278 
Train Epoch: 16 [166/250 21248/32000 (66%)] Loss: 1.51539 (QuantReg: 13.50965) QuantErr: 13.50965 batch_time=0.65307 
Train Epoch: 16 [177/250 22656/32000 (71%)] Loss: 1.24529 (QuantReg: 13.18629) QuantErr: 13.18629 batch_time=0.72704 
Train Epoch: 16 [188/250 24064/32000 (75%)] Loss: 1.08499 (QuantReg: 13.45058) QuantErr: 13.45058 batch_time=0.73998 
Train Epoch: 16 [199/250 25472/32000 (80%)] Loss: 1.30010 (QuantReg: 13.44621) QuantErr: 13.44621 batch_time=0.70662 
Train Epoch: 16 [210/250 26880/32000 (84%)] Loss: 1.54961 (QuantReg: 13.44378) QuantErr: 13.44378 batch_time=0.65196 
Train Epoch: 16 [221/250 28288/32000 (88%)] Loss: 1.65271 (QuantReg: 13.40457) QuantErr: 13.40457 batch_time=0.68197 
Train Epoch: 16 [232/250 29696/32000 (93%)] Loss: 1.44769 (QuantReg: 12.95922) QuantErr: 12.95922 batch_time=0.87748 
Train Epoch: 16 [243/250 31104/32000 (97%)] Loss: 1.22554 (QuantReg: 13.39072) QuantErr: 13.39072 batch_time=0.65533 
Train Epoch: 16 codebook_update_time=2.00094
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_MSRVTT_1kA_bert-large/checkpoint-epoch16.pth ...
Done in 11.370s
Updating 'best' checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_MSRVTT_1kA_bert-large/checkpoint-epoch16.pth ...
Done in 22.734s
removing stale ckpt [epoch 15] [took 0.11s]
 epoch          : 16
 loss           : 1.440460570335388
 quant_reg      : 13.311044330596923
 quant_err      : 13.311044330596923
 learning_rate  : 2.3164561507987653e-05
 n_samples      : 512000
 n_steps        : 4000
 MSRVTT_jsfusion_test/t2v_metrics/R1: 23.2
 MSRVTT_jsfusion_test/t2v_metrics/R5: 54.7
 MSRVTT_jsfusion_test/t2v_metrics/R10: 68.3
 MSRVTT_jsfusion_test/t2v_metrics/R50: 89.2
 MSRVTT_jsfusion_test/t2v_metrics/MedR: 5.0
 MSRVTT_jsfusion_test/t2v_metrics/MeanR: 27.776
 MSRVTT_jsfusion_test/t2v_metrics/geometric_mean_R1-R5-R10: 44.255305012624525
 MSRVTT_jsfusion_test/v2t_metrics/R1: 24.8
 MSRVTT_jsfusion_test/v2t_metrics/R5: 54.8
 MSRVTT_jsfusion_test/v2t_metrics/R10: 69.2
 MSRVTT_jsfusion_test/v2t_metrics/R50: 90.1
 MSRVTT_jsfusion_test/v2t_metrics/MedR: 4.0
 MSRVTT_jsfusion_test/v2t_metrics/MeanR: 24.908
 MSRVTT_jsfusion_test/v2t_metrics/geometric_mean_R1-R5-R10: 45.475705421795766
 mnt_best       : 44.255305012624525
 not_improved_count: 0
Train Epoch: 17 [1/250 128/32000 (0%)] Loss: 1.25187 (QuantReg: 13.06203) QuantErr: 13.06203 batch_time=56.16811 
Train Epoch: 17 [12/250 1536/32000 (5%)] Loss: 1.40524 (QuantReg: 12.89142) QuantErr: 12.89142 batch_time=8.46956 
Train Epoch: 17 [23/250 2944/32000 (9%)] Loss: 1.23669 (QuantReg: 13.40396) QuantErr: 13.40396 batch_time=0.66225 
Train Epoch: 17 [34/250 4352/32000 (14%)] Loss: 1.41041 (QuantReg: 12.79893) QuantErr: 12.79893 batch_time=1.71978 
Train Epoch: 17 [45/250 5760/32000 (18%)] Loss: 1.54115 (QuantReg: 13.24148) QuantErr: 13.24148 batch_time=0.67689 
Train Epoch: 17 [56/250 7168/32000 (22%)] Loss: 1.66780 (QuantReg: 13.27089) QuantErr: 13.27089 batch_time=0.63995 
Train Epoch: 17 [67/250 8576/32000 (27%)] Loss: 1.31190 (QuantReg: 13.47788) QuantErr: 13.47788 batch_time=0.65452 
Train Epoch: 17 [78/250 9984/32000 (31%)] Loss: 1.53979 (QuantReg: 13.20385) QuantErr: 13.20385 batch_time=0.66296 
Train Epoch: 17 [89/250 11392/32000 (36%)] Loss: 1.11138 (QuantReg: 13.33981) QuantErr: 13.33981 batch_time=0.65423 
Train Epoch: 17 [100/250 12800/32000 (40%)] Loss: 1.18701 (QuantReg: 13.28192) QuantErr: 13.28192 batch_time=0.67544 
Train Epoch: 17 [111/250 14208/32000 (44%)] Loss: 1.23455 (QuantReg: 13.13732) QuantErr: 13.13732 batch_time=0.68767 
Train Epoch: 17 [122/250 15616/32000 (49%)] Loss: 1.19945 (QuantReg: 13.28523) QuantErr: 13.28523 batch_time=0.73363 
Train Epoch: 17 [133/250 17024/32000 (53%)] Loss: 1.44107 (QuantReg: 13.31021) QuantErr: 13.31021 batch_time=0.69551 
Train Epoch: 17 [144/250 18432/32000 (58%)] Loss: 1.45560 (QuantReg: 13.20295) QuantErr: 13.20295 batch_time=0.65191 
Train Epoch: 17 [155/250 19840/32000 (62%)] Loss: 1.37702 (QuantReg: 13.33696) QuantErr: 13.33696 batch_time=0.70397 
Train Epoch: 17 [166/250 21248/32000 (66%)] Loss: 1.44853 (QuantReg: 13.57499) QuantErr: 13.57499 batch_time=0.65965 
Train Epoch: 17 [177/250 22656/32000 (71%)] Loss: 1.05190 (QuantReg: 13.80608) QuantErr: 13.80608 batch_time=1.48415 
Train Epoch: 17 [188/250 24064/32000 (75%)] Loss: 1.72511 (QuantReg: 13.55553) QuantErr: 13.55553 batch_time=0.73085 
Train Epoch: 17 [199/250 25472/32000 (80%)] Loss: 1.32251 (QuantReg: 13.36535) QuantErr: 13.36535 batch_time=0.92466 
Train Epoch: 17 [210/250 26880/32000 (84%)] Loss: 1.08047 (QuantReg: 13.91802) QuantErr: 13.91802 batch_time=0.77819 
Train Epoch: 17 [221/250 28288/32000 (88%)] Loss: 1.24535 (QuantReg: 13.63052) QuantErr: 13.63052 batch_time=0.68178 
Train Epoch: 17 [232/250 29696/32000 (93%)] Loss: 1.15385 (QuantReg: 13.53104) QuantErr: 13.53104 batch_time=0.67330 
Train Epoch: 17 [243/250 31104/32000 (97%)] Loss: 1.16621 (QuantReg: 13.25293) QuantErr: 13.25293 batch_time=0.71303 
Train Epoch: 17 codebook_update_time=1.68509
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_MSRVTT_1kA_bert-large/checkpoint-epoch17.pth ...
Done in 11.578s
removing stale ckpt [epoch 16] [took 0.04s]
 epoch          : 17
 loss           : 1.3972294182777405
 quant_reg      : 13.34130435180664
 quant_err      : 13.34130435180664
 learning_rate  : 2.2006333432588268e-05
 n_samples      : 544000
 n_steps        : 4250
 MSRVTT_jsfusion_test/t2v_metrics/R1: 22.8
 MSRVTT_jsfusion_test/t2v_metrics/R5: 54.2
 MSRVTT_jsfusion_test/t2v_metrics/R10: 67.2
 MSRVTT_jsfusion_test/t2v_metrics/R50: 89.8
 MSRVTT_jsfusion_test/t2v_metrics/MedR: 5.0
 MSRVTT_jsfusion_test/t2v_metrics/MeanR: 27.148
 MSRVTT_jsfusion_test/t2v_metrics/geometric_mean_R1-R5-R10: 43.62825091604727
 MSRVTT_jsfusion_test/v2t_metrics/R1: 22.5
 MSRVTT_jsfusion_test/v2t_metrics/R5: 54.6
 MSRVTT_jsfusion_test/v2t_metrics/R10: 67.8
 MSRVTT_jsfusion_test/v2t_metrics/R50: 90.1
 MSRVTT_jsfusion_test/v2t_metrics/MedR: 5.0
 MSRVTT_jsfusion_test/v2t_metrics/MeanR: 25.462
 MSRVTT_jsfusion_test/v2t_metrics/geometric_mean_R1-R5-R10: 43.6718528761103
 mnt_best       : 44.255305012624525
 not_improved_count: 1
Train Epoch: 18 [1/250 128/32000 (0%)] Loss: 1.50778 (QuantReg: 13.46699) QuantErr: 13.46699 batch_time=55.77780 
Train Epoch: 18 [12/250 1536/32000 (5%)] Loss: 1.15248 (QuantReg: 13.37426) QuantErr: 13.37426 batch_time=12.21836 
Train Epoch: 18 [23/250 2944/32000 (9%)] Loss: 1.18552 (QuantReg: 13.30410) QuantErr: 13.30410 batch_time=0.68847 
Train Epoch: 18 [34/250 4352/32000 (14%)] Loss: 1.38097 (QuantReg: 13.35557) QuantErr: 13.35557 batch_time=0.76838 
Train Epoch: 18 [45/250 5760/32000 (18%)] Loss: 1.34960 (QuantReg: 13.42922) QuantErr: 13.42922 batch_time=0.69789 
Train Epoch: 18 [56/250 7168/32000 (22%)] Loss: 1.18938 (QuantReg: 13.29171) QuantErr: 13.29171 batch_time=0.76995 
Train Epoch: 18 [67/250 8576/32000 (27%)] Loss: 1.21929 (QuantReg: 13.19421) QuantErr: 13.19421 batch_time=0.65289 
Train Epoch: 18 [78/250 9984/32000 (31%)] Loss: 1.21639 (QuantReg: 13.24880) QuantErr: 13.24880 batch_time=0.65281 
Train Epoch: 18 [89/250 11392/32000 (36%)] Loss: 1.18658 (QuantReg: 13.61812) QuantErr: 13.61812 batch_time=0.72827 
Train Epoch: 18 [100/250 12800/32000 (40%)] Loss: 1.30622 (QuantReg: 13.54189) QuantErr: 13.54189 batch_time=0.66120 
Train Epoch: 18 [111/250 14208/32000 (44%)] Loss: 1.25109 (QuantReg: 13.28003) QuantErr: 13.28003 batch_time=0.68970 
Train Epoch: 18 [122/250 15616/32000 (49%)] Loss: 1.29088 (QuantReg: 13.60385) QuantErr: 13.60385 batch_time=0.67859 
Train Epoch: 18 [133/250 17024/32000 (53%)] Loss: 1.16894 (QuantReg: 13.44320) QuantErr: 13.44320 batch_time=0.68981 
Train Epoch: 18 [144/250 18432/32000 (58%)] Loss: 1.57236 (QuantReg: 13.48923) QuantErr: 13.48923 batch_time=1.04926 
Train Epoch: 18 [155/250 19840/32000 (62%)] Loss: 1.29400 (QuantReg: 13.37517) QuantErr: 13.37517 batch_time=0.69620 
Train Epoch: 18 [166/250 21248/32000 (66%)] Loss: 1.63080 (QuantReg: 13.39686) QuantErr: 13.39686 batch_time=0.73111 
Train Epoch: 18 [177/250 22656/32000 (71%)] Loss: 1.59609 (QuantReg: 13.58225) QuantErr: 13.58225 batch_time=0.69933 
Train Epoch: 18 [188/250 24064/32000 (75%)] Loss: 1.28146 (QuantReg: 13.46258) QuantErr: 13.46258 batch_time=0.71081 
Train Epoch: 18 [199/250 25472/32000 (80%)] Loss: 1.66853 (QuantReg: 13.30685) QuantErr: 13.30685 batch_time=0.68053 
Train Epoch: 18 [210/250 26880/32000 (84%)] Loss: 1.53679 (QuantReg: 13.48382) QuantErr: 13.48382 batch_time=0.85705 
Train Epoch: 18 [221/250 28288/32000 (88%)] Loss: 1.35644 (QuantReg: 13.34972) QuantErr: 13.34972 batch_time=0.65636 
Train Epoch: 18 [232/250 29696/32000 (93%)] Loss: 1.49606 (QuantReg: 13.16798) QuantErr: 13.16798 batch_time=0.67414 
Train Epoch: 18 [243/250 31104/32000 (97%)] Loss: 1.47100 (QuantReg: 13.50450) QuantErr: 13.50450 batch_time=0.71575 
Train Epoch: 18 codebook_update_time=1.72827
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_MSRVTT_1kA_bert-large/checkpoint-epoch18.pth ...
Done in 11.065s
Updating 'best' checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_MSRVTT_1kA_bert-large/checkpoint-epoch18.pth ...
Done in 22.115s
removing stale ckpt [epoch 17] [took 0.00s]
 epoch          : 18
 loss           : 1.3647120082378388
 quant_reg      : 13.393117729187011
 quant_err      : 13.393117729187011
 learning_rate  : 2.0906016760958855e-05
 n_samples      : 576000
 n_steps        : 4500
 MSRVTT_jsfusion_test/t2v_metrics/R1: 25.0
 MSRVTT_jsfusion_test/t2v_metrics/R5: 55.1
 MSRVTT_jsfusion_test/t2v_metrics/R10: 67.1
 MSRVTT_jsfusion_test/t2v_metrics/R50: 90.0
 MSRVTT_jsfusion_test/t2v_metrics/MedR: 4.0
 MSRVTT_jsfusion_test/t2v_metrics/MeanR: 26.541
 MSRVTT_jsfusion_test/t2v_metrics/geometric_mean_R1-R5-R10: 45.2138382068709
 MSRVTT_jsfusion_test/v2t_metrics/R1: 23.9
 MSRVTT_jsfusion_test/v2t_metrics/R5: 54.1
 MSRVTT_jsfusion_test/v2t_metrics/R10: 69.2
 MSRVTT_jsfusion_test/v2t_metrics/R50: 89.8
 MSRVTT_jsfusion_test/v2t_metrics/MedR: 5.0
 MSRVTT_jsfusion_test/v2t_metrics/MeanR: 24.1085
 MSRVTT_jsfusion_test/v2t_metrics/geometric_mean_R1-R5-R10: 44.72672372322402
 mnt_best       : 45.2138382068709
 not_improved_count: 0
Train Epoch: 19 [1/250 128/32000 (0%)] Loss: 1.15624 (QuantReg: 13.22382) QuantErr: 13.22382 batch_time=105.13889 
Train Epoch: 19 [12/250 1536/32000 (5%)] Loss: 1.17746 (QuantReg: 13.48020) QuantErr: 13.48020 batch_time=0.69004 
Train Epoch: 19 [23/250 2944/32000 (9%)] Loss: 1.27976 (QuantReg: 13.42569) QuantErr: 13.42569 batch_time=0.74874 
Train Epoch: 19 [34/250 4352/32000 (14%)] Loss: 1.37659 (QuantReg: 13.57086) QuantErr: 13.57086 batch_time=0.75934 
Train Epoch: 19 [45/250 5760/32000 (18%)] Loss: 1.20128 (QuantReg: 13.38230) QuantErr: 13.38230 batch_time=0.66786 
Train Epoch: 19 [56/250 7168/32000 (22%)] Loss: 1.50558 (QuantReg: 13.56650) QuantErr: 13.56650 batch_time=0.73356 
Train Epoch: 19 [67/250 8576/32000 (27%)] Loss: 1.41702 (QuantReg: 13.53015) QuantErr: 13.53015 batch_time=3.26972 
Train Epoch: 19 [78/250 9984/32000 (31%)] Loss: 1.16101 (QuantReg: 13.62296) QuantErr: 13.62296 batch_time=0.66348 
Train Epoch: 19 [89/250 11392/32000 (36%)] Loss: 1.13243 (QuantReg: 13.52678) QuantErr: 13.52678 batch_time=0.69437 
Train Epoch: 19 [100/250 12800/32000 (40%)] Loss: 1.38599 (QuantReg: 13.16551) QuantErr: 13.16551 batch_time=0.66393 
Train Epoch: 19 [111/250 14208/32000 (44%)] Loss: 1.57142 (QuantReg: 13.51797) QuantErr: 13.51797 batch_time=0.67475 
Train Epoch: 19 [122/250 15616/32000 (49%)] Loss: 1.72902 (QuantReg: 13.36709) QuantErr: 13.36709 batch_time=0.68876 
Train Epoch: 19 [133/250 17024/32000 (53%)] Loss: 1.32830 (QuantReg: 13.64314) QuantErr: 13.64314 batch_time=0.67822 
Train Epoch: 19 [144/250 18432/32000 (58%)] Loss: 1.20137 (QuantReg: 13.78611) QuantErr: 13.78611 batch_time=0.70015 
Train Epoch: 19 [155/250 19840/32000 (62%)] Loss: 1.40604 (QuantReg: 13.45343) QuantErr: 13.45343 batch_time=0.65731 
Train Epoch: 19 [166/250 21248/32000 (66%)] Loss: 1.38357 (QuantReg: 13.08326) QuantErr: 13.08326 batch_time=0.69744 
Train Epoch: 19 [177/250 22656/32000 (71%)] Loss: 1.19126 (QuantReg: 13.75674) QuantErr: 13.75674 batch_time=0.66564 
Train Epoch: 19 [188/250 24064/32000 (75%)] Loss: 1.19638 (QuantReg: 13.81817) QuantErr: 13.81817 batch_time=0.66953 
Train Epoch: 19 [199/250 25472/32000 (80%)] Loss: 1.40055 (QuantReg: 13.34833) QuantErr: 13.34833 batch_time=0.70706 
Train Epoch: 19 [210/250 26880/32000 (84%)] Loss: 1.60709 (QuantReg: 13.41084) QuantErr: 13.41084 batch_time=0.67116 
Train Epoch: 19 [221/250 28288/32000 (88%)] Loss: 1.49625 (QuantReg: 13.67574) QuantErr: 13.67574 batch_time=0.66858 
Train Epoch: 19 [232/250 29696/32000 (93%)] Loss: 1.14326 (QuantReg: 13.37918) QuantErr: 13.37918 batch_time=0.71746 
Train Epoch: 19 [243/250 31104/32000 (97%)] Loss: 1.25367 (QuantReg: 13.13838) QuantErr: 13.13838 batch_time=0.67644 
Train Epoch: 19 codebook_update_time=1.95948
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_MSRVTT_1kA_bert-large/checkpoint-epoch19.pth ...
Done in 11.245s
removing stale ckpt [epoch 18] [took 0.00s]
 epoch          : 19
 loss           : 1.3168656113147736
 quant_reg      : 13.469576217651367
 quant_err      : 13.469576217651367
 learning_rate  : 1.986071592291091e-05
 n_samples      : 608000
 n_steps        : 4750
 MSRVTT_jsfusion_test/t2v_metrics/R1: 24.8
 MSRVTT_jsfusion_test/t2v_metrics/R5: 54.6
 MSRVTT_jsfusion_test/t2v_metrics/R10: 68.2
 MSRVTT_jsfusion_test/t2v_metrics/R50: 89.1
 MSRVTT_jsfusion_test/t2v_metrics/MedR: 4.0
 MSRVTT_jsfusion_test/t2v_metrics/MeanR: 26.87
 MSRVTT_jsfusion_test/t2v_metrics/geometric_mean_R1-R5-R10: 45.20046466225533
 MSRVTT_jsfusion_test/v2t_metrics/R1: 22.7
 MSRVTT_jsfusion_test/v2t_metrics/R5: 55.0
 MSRVTT_jsfusion_test/v2t_metrics/R10: 67.9
 MSRVTT_jsfusion_test/v2t_metrics/R50: 90.0
 MSRVTT_jsfusion_test/v2t_metrics/MedR: 5.0
 MSRVTT_jsfusion_test/v2t_metrics/MeanR: 24.4555
 MSRVTT_jsfusion_test/v2t_metrics/geometric_mean_R1-R5-R10: 43.929147331681705
 mnt_best       : 45.2138382068709
 not_improved_count: 1
Train Epoch: 20 [1/250 128/32000 (0%)] Loss: 1.33009 (QuantReg: 13.02251) QuantErr: 13.02251 batch_time=137.47587 
Train Epoch: 20 [12/250 1536/32000 (5%)] Loss: 1.18199 (QuantReg: 13.53619) QuantErr: 13.53619 batch_time=0.64677 
Train Epoch: 20 [23/250 2944/32000 (9%)] Loss: 1.11427 (QuantReg: 13.28522) QuantErr: 13.28522 batch_time=0.69920 
Train Epoch: 20 [34/250 4352/32000 (14%)] Loss: 1.21925 (QuantReg: 13.49080) QuantErr: 13.49080 batch_time=0.67996 
Train Epoch: 20 [45/250 5760/32000 (18%)] Loss: 1.34603 (QuantReg: 13.18650) QuantErr: 13.18650 batch_time=0.67913 
Train Epoch: 20 [56/250 7168/32000 (22%)] Loss: 1.33510 (QuantReg: 13.48005) QuantErr: 13.48005 batch_time=0.67115 
Train Epoch: 20 [67/250 8576/32000 (27%)] Loss: 1.12149 (QuantReg: 13.67770) QuantErr: 13.67770 batch_time=0.68126 
Train Epoch: 20 [78/250 9984/32000 (31%)] Loss: 1.46152 (QuantReg: 13.34326) QuantErr: 13.34326 batch_time=0.66638 
Train Epoch: 20 [89/250 11392/32000 (36%)] Loss: 1.06797 (QuantReg: 13.38465) QuantErr: 13.38465 batch_time=0.66577 
Train Epoch: 20 [100/250 12800/32000 (40%)] Loss: 1.63151 (QuantReg: 13.42945) QuantErr: 13.42945 batch_time=0.68420 
Train Epoch: 20 [111/250 14208/32000 (44%)] Loss: 1.54977 (QuantReg: 13.41262) QuantErr: 13.41262 batch_time=0.71528 
Train Epoch: 20 [122/250 15616/32000 (49%)] Loss: 1.51768 (QuantReg: 13.28333) QuantErr: 13.28333 batch_time=0.65573 
Train Epoch: 20 [133/250 17024/32000 (53%)] Loss: 0.99051 (QuantReg: 13.48886) QuantErr: 13.48886 batch_time=0.66969 
Train Epoch: 20 [144/250 18432/32000 (58%)] Loss: 1.18998 (QuantReg: 13.38803) QuantErr: 13.38803 batch_time=0.69714 
Train Epoch: 20 [155/250 19840/32000 (62%)] Loss: 1.29207 (QuantReg: 13.24548) QuantErr: 13.24548 batch_time=0.66764 
Train Epoch: 20 [166/250 21248/32000 (66%)] Loss: 1.16340 (QuantReg: 13.41785) QuantErr: 13.41785 batch_time=0.73024 
Train Epoch: 20 [177/250 22656/32000 (71%)] Loss: 1.19285 (QuantReg: 13.14148) QuantErr: 13.14148 batch_time=0.69956 
Train Epoch: 20 [188/250 24064/32000 (75%)] Loss: 1.32851 (QuantReg: 13.63475) QuantErr: 13.63475 batch_time=0.81686 
Train Epoch: 20 [199/250 25472/32000 (80%)] Loss: 1.03180 (QuantReg: 13.60408) QuantErr: 13.60408 batch_time=0.69008 
Train Epoch: 20 [210/250 26880/32000 (84%)] Loss: 1.45196 (QuantReg: 13.80556) QuantErr: 13.80556 batch_time=0.70649 
Train Epoch: 20 [221/250 28288/32000 (88%)] Loss: 1.13942 (QuantReg: 13.50026) QuantErr: 13.50026 batch_time=0.73525 
Train Epoch: 20 [232/250 29696/32000 (93%)] Loss: 1.32170 (QuantReg: 13.24873) QuantErr: 13.24873 batch_time=0.70326 
Train Epoch: 20 [243/250 31104/32000 (97%)] Loss: 1.49254 (QuantReg: 13.46891) QuantErr: 13.46891 batch_time=0.80131 
Train Epoch: 20 codebook_update_time=1.74357
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_MSRVTT_1kA_bert-large/checkpoint-epoch20.pth ...
Done in 27.589s
removing stale ckpt [epoch 19] [took 0.00s]
 epoch          : 20
 loss           : 1.275536081790924
 quant_reg      : 13.428188156127929
 quant_err      : 13.428188156127929
 learning_rate  : 1.8867680126765363e-05
 n_samples      : 640000
 n_steps        : 5000
 MSRVTT_jsfusion_test/t2v_metrics/R1: 24.2
 MSRVTT_jsfusion_test/t2v_metrics/R5: 54.0
 MSRVTT_jsfusion_test/t2v_metrics/R10: 66.4
 MSRVTT_jsfusion_test/t2v_metrics/R50: 89.6
 MSRVTT_jsfusion_test/t2v_metrics/MedR: 4.5
 MSRVTT_jsfusion_test/t2v_metrics/MeanR: 27.556
 MSRVTT_jsfusion_test/t2v_metrics/geometric_mean_R1-R5-R10: 44.27165271815232
 MSRVTT_jsfusion_test/v2t_metrics/R1: 24.2
 MSRVTT_jsfusion_test/v2t_metrics/R5: 55.2
 MSRVTT_jsfusion_test/v2t_metrics/R10: 67.8
 MSRVTT_jsfusion_test/v2t_metrics/R50: 89.3
 MSRVTT_jsfusion_test/v2t_metrics/MedR: 4.0
 MSRVTT_jsfusion_test/v2t_metrics/MeanR: 24.908
 MSRVTT_jsfusion_test/v2t_metrics/geometric_mean_R1-R5-R10: 44.908447938613456
 mnt_best       : 45.2138382068709
 not_improved_count: 2
Train Epoch: 21 [1/250 128/32000 (0%)] Loss: 1.11763 (QuantReg: 13.27293) QuantErr: 13.27293 batch_time=61.04200 
Train Epoch: 21 [12/250 1536/32000 (5%)] Loss: 1.04808 (QuantReg: 13.52063) QuantErr: 13.52063 batch_time=0.70077 
Train Epoch: 21 [23/250 2944/32000 (9%)] Loss: 1.22707 (QuantReg: 13.85626) QuantErr: 13.85626 batch_time=8.94919 
Train Epoch: 21 [34/250 4352/32000 (14%)] Loss: 1.63327 (QuantReg: 13.44406) QuantErr: 13.44406 batch_time=0.66278 
Train Epoch: 21 [45/250 5760/32000 (18%)] Loss: 1.40369 (QuantReg: 12.95643) QuantErr: 12.95643 batch_time=0.66132 
Train Epoch: 21 [56/250 7168/32000 (22%)] Loss: 1.26237 (QuantReg: 13.54325) QuantErr: 13.54325 batch_time=0.79693 
Train Epoch: 21 [67/250 8576/32000 (27%)] Loss: 1.52725 (QuantReg: 13.15742) QuantErr: 13.15742 batch_time=0.65500 
Train Epoch: 21 [78/250 9984/32000 (31%)] Loss: 1.08254 (QuantReg: 13.21334) QuantErr: 13.21334 batch_time=0.64953 
Train Epoch: 21 [89/250 11392/32000 (36%)] Loss: 1.19086 (QuantReg: 13.51369) QuantErr: 13.51369 batch_time=1.03234 
Train Epoch: 21 [100/250 12800/32000 (40%)] Loss: 1.42359 (QuantReg: 13.23781) QuantErr: 13.23781 batch_time=0.69860 
Train Epoch: 21 [111/250 14208/32000 (44%)] Loss: 1.56981 (QuantReg: 13.52421) QuantErr: 13.52421 batch_time=0.70346 
Train Epoch: 21 [122/250 15616/32000 (49%)] Loss: 1.31801 (QuantReg: 13.47530) QuantErr: 13.47530 batch_time=0.68784 
Train Epoch: 21 [133/250 17024/32000 (53%)] Loss: 0.88210 (QuantReg: 13.47704) QuantErr: 13.47704 batch_time=0.65386 
Train Epoch: 21 [144/250 18432/32000 (58%)] Loss: 1.37437 (QuantReg: 13.23760) QuantErr: 13.23760 batch_time=2.67982 
Train Epoch: 21 [155/250 19840/32000 (62%)] Loss: 1.16270 (QuantReg: 13.54180) QuantErr: 13.54180 batch_time=0.72280 
Train Epoch: 21 [166/250 21248/32000 (66%)] Loss: 1.45942 (QuantReg: 13.68432) QuantErr: 13.68432 batch_time=0.68175 
Train Epoch: 21 [177/250 22656/32000 (71%)] Loss: 0.91929 (QuantReg: 13.60755) QuantErr: 13.60755 batch_time=0.68184 
Train Epoch: 21 [188/250 24064/32000 (75%)] Loss: 1.21396 (QuantReg: 13.38177) QuantErr: 13.38177 batch_time=0.69242 
Train Epoch: 21 [199/250 25472/32000 (80%)] Loss: 1.38377 (QuantReg: 13.65832) QuantErr: 13.65832 batch_time=0.68880 
Train Epoch: 21 [210/250 26880/32000 (84%)] Loss: 1.41531 (QuantReg: 13.44550) QuantErr: 13.44550 batch_time=0.80614 
Train Epoch: 21 [221/250 28288/32000 (88%)] Loss: 1.11935 (QuantReg: 13.48447) QuantErr: 13.48447 batch_time=0.67833 
Train Epoch: 21 [232/250 29696/32000 (93%)] Loss: 1.17199 (QuantReg: 13.73440) QuantErr: 13.73440 batch_time=1.53329 
Train Epoch: 21 [243/250 31104/32000 (97%)] Loss: 1.31122 (QuantReg: 13.84208) QuantErr: 13.84208 batch_time=0.66184 
Train Epoch: 21 codebook_update_time=1.74278
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_MSRVTT_1kA_bert-large/checkpoint-epoch21.pth ...
Done in 11.626s
removing stale ckpt [epoch 20] [took 0.08s]
 epoch          : 21
 loss           : 1.2595629703998565
 quant_reg      : 13.465624141693116
 quant_err      : 13.465624141693116
 learning_rate  : 1.7924296120427095e-05
 n_samples      : 672000
 n_steps        : 5250
 MSRVTT_jsfusion_test/t2v_metrics/R1: 24.6
 MSRVTT_jsfusion_test/t2v_metrics/R5: 54.2
 MSRVTT_jsfusion_test/t2v_metrics/R10: 69.0
 MSRVTT_jsfusion_test/t2v_metrics/R50: 89.5
 MSRVTT_jsfusion_test/t2v_metrics/MedR: 5.0
 MSRVTT_jsfusion_test/t2v_metrics/MeanR: 27.703
 MSRVTT_jsfusion_test/t2v_metrics/geometric_mean_R1-R5-R10: 45.14342387565723
 MSRVTT_jsfusion_test/v2t_metrics/R1: 24.3
 MSRVTT_jsfusion_test/v2t_metrics/R5: 55.4
 MSRVTT_jsfusion_test/v2t_metrics/R10: 70.2
 MSRVTT_jsfusion_test/v2t_metrics/R50: 89.3
 MSRVTT_jsfusion_test/v2t_metrics/MedR: 4.0
 MSRVTT_jsfusion_test/v2t_metrics/MeanR: 25.0775
 MSRVTT_jsfusion_test/v2t_metrics/geometric_mean_R1-R5-R10: 45.54958069920312
 mnt_best       : 45.2138382068709
 not_improved_count: 3
Train Epoch: 22 [1/250 128/32000 (0%)] Loss: 1.26840 (QuantReg: 13.22924) QuantErr: 13.22924 batch_time=64.93686 
Train Epoch: 22 [12/250 1536/32000 (5%)] Loss: 1.12480 (QuantReg: 13.30197) QuantErr: 13.30197 batch_time=2.17066 
Train Epoch: 22 [23/250 2944/32000 (9%)] Loss: 1.11821 (QuantReg: 13.52037) QuantErr: 13.52037 batch_time=0.74456 
Train Epoch: 22 [34/250 4352/32000 (14%)] Loss: 1.12061 (QuantReg: 13.93287) QuantErr: 13.93287 batch_time=0.74448 
Train Epoch: 22 [45/250 5760/32000 (18%)] Loss: 1.01606 (QuantReg: 13.92013) QuantErr: 13.92013 batch_time=0.73734 
Train Epoch: 22 [56/250 7168/32000 (22%)] Loss: 1.35375 (QuantReg: 13.55327) QuantErr: 13.55327 batch_time=0.67715 
Train Epoch: 22 [67/250 8576/32000 (27%)] Loss: 1.20498 (QuantReg: 13.56813) QuantErr: 13.56813 batch_time=0.69245 
Train Epoch: 22 [78/250 9984/32000 (31%)] Loss: 1.28324 (QuantReg: 13.30462) QuantErr: 13.30462 batch_time=0.68701 
Train Epoch: 22 [89/250 11392/32000 (36%)] Loss: 1.25180 (QuantReg: 13.20028) QuantErr: 13.20028 batch_time=0.67778 
Train Epoch: 22 [100/250 12800/32000 (40%)] Loss: 1.21671 (QuantReg: 13.36221) QuantErr: 13.36221 batch_time=0.76193 
Train Epoch: 22 [111/250 14208/32000 (44%)] Loss: 1.12131 (QuantReg: 13.41903) QuantErr: 13.41903 batch_time=0.65809 
Train Epoch: 22 [122/250 15616/32000 (49%)] Loss: 1.26595 (QuantReg: 13.41758) QuantErr: 13.41758 batch_time=0.67490 
Train Epoch: 22 [133/250 17024/32000 (53%)] Loss: 1.18579 (QuantReg: 13.52986) QuantErr: 13.52986 batch_time=0.67757 
Train Epoch: 22 [144/250 18432/32000 (58%)] Loss: 1.68606 (QuantReg: 13.43286) QuantErr: 13.43286 batch_time=0.67899 
Train Epoch: 22 [155/250 19840/32000 (62%)] Loss: 1.16737 (QuantReg: 13.55071) QuantErr: 13.55071 batch_time=0.66530 
Train Epoch: 22 [166/250 21248/32000 (66%)] Loss: 1.32948 (QuantReg: 13.51173) QuantErr: 13.51173 batch_time=0.70461 
Train Epoch: 22 [177/250 22656/32000 (71%)] Loss: 1.44609 (QuantReg: 13.37655) QuantErr: 13.37655 batch_time=0.67454 
Train Epoch: 22 [188/250 24064/32000 (75%)] Loss: 1.24498 (QuantReg: 13.87332) QuantErr: 13.87332 batch_time=0.67351 
Train Epoch: 22 [199/250 25472/32000 (80%)] Loss: 1.24222 (QuantReg: 13.80889) QuantErr: 13.80889 batch_time=0.93978 
Train Epoch: 22 [210/250 26880/32000 (84%)] Loss: 1.13005 (QuantReg: 13.74497) QuantErr: 13.74497 batch_time=0.66539 
Train Epoch: 22 [221/250 28288/32000 (88%)] Loss: 1.12340 (QuantReg: 13.47689) QuantErr: 13.47689 batch_time=2.14502 
Train Epoch: 22 [232/250 29696/32000 (93%)] Loss: 0.97012 (QuantReg: 13.36575) QuantErr: 13.36575 batch_time=0.67001 
Train Epoch: 22 [243/250 31104/32000 (97%)] Loss: 1.47973 (QuantReg: 13.57669) QuantErr: 13.57669 batch_time=0.66158 
Train Epoch: 22 codebook_update_time=2.85618
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_MSRVTT_1kA_bert-large/checkpoint-epoch22.pth ...
Done in 12.028s
Updating 'best' checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_MSRVTT_1kA_bert-large/checkpoint-epoch22.pth ...
Done in 23.404s
removing stale ckpt [epoch 21] [took 0.04s]
 epoch          : 22
 loss           : 1.2555454666614532
 quant_reg      : 13.491285335540772
 quant_err      : 13.491285335540772
 learning_rate  : 1.702808131440574e-05
 n_samples      : 704000
 n_steps        : 5500
 MSRVTT_jsfusion_test/t2v_metrics/R1: 24.5
 MSRVTT_jsfusion_test/t2v_metrics/R5: 55.3
 MSRVTT_jsfusion_test/t2v_metrics/R10: 68.8
 MSRVTT_jsfusion_test/t2v_metrics/R50: 89.2
 MSRVTT_jsfusion_test/t2v_metrics/MedR: 4.0
 MSRVTT_jsfusion_test/t2v_metrics/MeanR: 26.85
 MSRVTT_jsfusion_test/t2v_metrics/geometric_mean_R1-R5-R10: 45.34122171454982
 MSRVTT_jsfusion_test/v2t_metrics/R1: 24.3
 MSRVTT_jsfusion_test/v2t_metrics/R5: 58.3
 MSRVTT_jsfusion_test/v2t_metrics/R10: 71.3
 MSRVTT_jsfusion_test/v2t_metrics/R50: 89.6
 MSRVTT_jsfusion_test/v2t_metrics/MedR: 4.0
 MSRVTT_jsfusion_test/v2t_metrics/MeanR: 24.573
 MSRVTT_jsfusion_test/v2t_metrics/geometric_mean_R1-R5-R10: 46.57163153309078
 mnt_best       : 45.34122171454982
 not_improved_count: 0
Train Epoch: 23 [1/250 128/32000 (0%)] Loss: 1.03068 (QuantReg: 13.81856) QuantErr: 13.81856 batch_time=54.71849 
Train Epoch: 23 [12/250 1536/32000 (5%)] Loss: 1.47032 (QuantReg: 13.34216) QuantErr: 13.34216 batch_time=0.74106 
Train Epoch: 23 [23/250 2944/32000 (9%)] Loss: 1.09930 (QuantReg: 13.68726) QuantErr: 13.68726 batch_time=0.66641 
Train Epoch: 23 [34/250 4352/32000 (14%)] Loss: 1.04967 (QuantReg: 13.45570) QuantErr: 13.45570 batch_time=0.71667 
Train Epoch: 23 [45/250 5760/32000 (18%)] Loss: 1.12640 (QuantReg: 13.78016) QuantErr: 13.78016 batch_time=0.69387 
Train Epoch: 23 [56/250 7168/32000 (22%)] Loss: 1.39676 (QuantReg: 13.42616) QuantErr: 13.42616 batch_time=0.71228 
Train Epoch: 23 [67/250 8576/32000 (27%)] Loss: 1.44897 (QuantReg: 13.30424) QuantErr: 13.30424 batch_time=1.59022 
Train Epoch: 23 [78/250 9984/32000 (31%)] Loss: 1.16289 (QuantReg: 13.49763) QuantErr: 13.49763 batch_time=6.81041 
Train Epoch: 23 [89/250 11392/32000 (36%)] Loss: 1.16421 (QuantReg: 13.30360) QuantErr: 13.30360 batch_time=0.70683 
Train Epoch: 23 [100/250 12800/32000 (40%)] Loss: 1.25716 (QuantReg: 13.56182) QuantErr: 13.56182 batch_time=0.67818 
Train Epoch: 23 [111/250 14208/32000 (44%)] Loss: 1.45591 (QuantReg: 13.31343) QuantErr: 13.31343 batch_time=0.64704 
Train Epoch: 23 [122/250 15616/32000 (49%)] Loss: 1.71284 (QuantReg: 13.45274) QuantErr: 13.45274 batch_time=0.67021 
Train Epoch: 23 [133/250 17024/32000 (53%)] Loss: 1.61931 (QuantReg: 13.16822) QuantErr: 13.16822 batch_time=0.68142 
Train Epoch: 23 [144/250 18432/32000 (58%)] Loss: 1.27507 (QuantReg: 12.97626) QuantErr: 12.97626 batch_time=0.72200 
Train Epoch: 23 [155/250 19840/32000 (62%)] Loss: 1.13799 (QuantReg: 13.71429) QuantErr: 13.71429 batch_time=0.67233 
Train Epoch: 23 [166/250 21248/32000 (66%)] Loss: 1.26358 (QuantReg: 13.61469) QuantErr: 13.61469 batch_time=0.68759 
Train Epoch: 23 [177/250 22656/32000 (71%)] Loss: 1.30403 (QuantReg: 13.47474) QuantErr: 13.47474 batch_time=0.70944 
Train Epoch: 23 [188/250 24064/32000 (75%)] Loss: 1.45377 (QuantReg: 13.73848) QuantErr: 13.73848 batch_time=0.76268 
Train Epoch: 23 [199/250 25472/32000 (80%)] Loss: 1.16321 (QuantReg: 13.71205) QuantErr: 13.71205 batch_time=0.72934 
Train Epoch: 23 [210/250 26880/32000 (84%)] Loss: 1.18061 (QuantReg: 13.44078) QuantErr: 13.44078 batch_time=0.66467 
Train Epoch: 23 [221/250 28288/32000 (88%)] Loss: 1.23764 (QuantReg: 13.60279) QuantErr: 13.60279 batch_time=0.69102 
Train Epoch: 23 [232/250 29696/32000 (93%)] Loss: 1.30310 (QuantReg: 13.69649) QuantErr: 13.69649 batch_time=0.71787 
Train Epoch: 23 [243/250 31104/32000 (97%)] Loss: 1.35831 (QuantReg: 13.63632) QuantErr: 13.63632 batch_time=0.73536 
Train Epoch: 23 codebook_update_time=1.73382
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_MSRVTT_1kA_bert-large/checkpoint-epoch23.pth ...
Done in 11.289s
removing stale ckpt [epoch 22] [took 7.94s]
 epoch          : 23
 loss           : 1.2154434311389923
 quant_reg      : 13.566852268218994
 quant_err      : 13.566852268218994
 learning_rate  : 1.6176677248685452e-05
 n_samples      : 736000
 n_steps        : 5750
 MSRVTT_jsfusion_test/t2v_metrics/R1: 23.9
 MSRVTT_jsfusion_test/t2v_metrics/R5: 55.5
 MSRVTT_jsfusion_test/t2v_metrics/R10: 68.6
 MSRVTT_jsfusion_test/t2v_metrics/R50: 89.4
 MSRVTT_jsfusion_test/t2v_metrics/MedR: 4.0
 MSRVTT_jsfusion_test/t2v_metrics/MeanR: 26.06
 MSRVTT_jsfusion_test/t2v_metrics/geometric_mean_R1-R5-R10: 44.97850331282525
 MSRVTT_jsfusion_test/v2t_metrics/R1: 24.7
 MSRVTT_jsfusion_test/v2t_metrics/R5: 57.6
 MSRVTT_jsfusion_test/v2t_metrics/R10: 69.8
 MSRVTT_jsfusion_test/v2t_metrics/R50: 89.3
 MSRVTT_jsfusion_test/v2t_metrics/MedR: 4.0
 MSRVTT_jsfusion_test/v2t_metrics/MeanR: 24.634
 MSRVTT_jsfusion_test/v2t_metrics/geometric_mean_R1-R5-R10: 46.30824117382898
 mnt_best       : 45.34122171454982
 not_improved_count: 1
Train Epoch: 24 [1/250 128/32000 (0%)] Loss: 1.27660 (QuantReg: 13.55954) QuantErr: 13.55954 batch_time=77.89653 
Train Epoch: 24 [12/250 1536/32000 (5%)] Loss: 1.42517 (QuantReg: 13.20279) QuantErr: 13.20279 batch_time=0.66864 
Train Epoch: 24 [23/250 2944/32000 (9%)] Loss: 1.13392 (QuantReg: 13.45994) QuantErr: 13.45994 batch_time=15.27571 
Train Epoch: 24 [34/250 4352/32000 (14%)] Loss: 0.84726 (QuantReg: 13.58908) QuantErr: 13.58908 batch_time=0.71166 
Train Epoch: 24 [45/250 5760/32000 (18%)] Loss: 1.00072 (QuantReg: 13.67029) QuantErr: 13.67029 batch_time=0.68278 
Train Epoch: 24 [56/250 7168/32000 (22%)] Loss: 1.59603 (QuantReg: 13.36706) QuantErr: 13.36706 batch_time=0.71626 
Train Epoch: 24 [67/250 8576/32000 (27%)] Loss: 1.28050 (QuantReg: 13.29693) QuantErr: 13.29693 batch_time=0.73082 
Train Epoch: 24 [78/250 9984/32000 (31%)] Loss: 1.10155 (QuantReg: 13.54621) QuantErr: 13.54621 batch_time=0.67652 
Train Epoch: 24 [89/250 11392/32000 (36%)] Loss: 1.54292 (QuantReg: 13.60349) QuantErr: 13.60349 batch_time=0.66140 
Train Epoch: 24 [100/250 12800/32000 (40%)] Loss: 1.15109 (QuantReg: 13.82951) QuantErr: 13.82951 batch_time=0.68122 
Train Epoch: 24 [111/250 14208/32000 (44%)] Loss: 1.43809 (QuantReg: 13.63604) QuantErr: 13.63604 batch_time=0.69614 
Train Epoch: 24 [122/250 15616/32000 (49%)] Loss: 1.10741 (QuantReg: 13.78602) QuantErr: 13.78602 batch_time=0.66611 
Train Epoch: 24 [133/250 17024/32000 (53%)] Loss: 1.09564 (QuantReg: 13.85344) QuantErr: 13.85344 batch_time=1.48223 
Train Epoch: 24 [144/250 18432/32000 (58%)] Loss: 1.33191 (QuantReg: 13.67635) QuantErr: 13.67635 batch_time=2.51895 
Train Epoch: 24 [155/250 19840/32000 (62%)] Loss: 0.97095 (QuantReg: 13.82877) QuantErr: 13.82877 batch_time=0.67964 
Train Epoch: 24 [166/250 21248/32000 (66%)] Loss: 1.00621 (QuantReg: 13.76413) QuantErr: 13.76413 batch_time=0.71444 
Train Epoch: 24 [177/250 22656/32000 (71%)] Loss: 1.31812 (QuantReg: 13.61247) QuantErr: 13.61247 batch_time=1.07523 
Train Epoch: 24 [188/250 24064/32000 (75%)] Loss: 0.95463 (QuantReg: 13.44474) QuantErr: 13.44474 batch_time=0.77262 
Train Epoch: 24 [199/250 25472/32000 (80%)] Loss: 1.24134 (QuantReg: 13.75994) QuantErr: 13.75994 batch_time=0.66881 
Train Epoch: 24 [210/250 26880/32000 (84%)] Loss: 1.27311 (QuantReg: 13.76526) QuantErr: 13.76526 batch_time=0.67888 
Train Epoch: 24 [221/250 28288/32000 (88%)] Loss: 1.11330 (QuantReg: 13.78785) QuantErr: 13.78785 batch_time=0.68884 
Train Epoch: 24 [232/250 29696/32000 (93%)] Loss: 0.87586 (QuantReg: 13.70413) QuantErr: 13.70413 batch_time=0.71181 
Train Epoch: 24 [243/250 31104/32000 (97%)] Loss: 1.04975 (QuantReg: 13.82862) QuantErr: 13.82862 batch_time=0.69975 
Train Epoch: 24 codebook_update_time=1.81128
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_MSRVTT_1kA_bert-large/checkpoint-epoch24.pth ...
Done in 12.193s
Updating 'best' checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_MSRVTT_1kA_bert-large/checkpoint-epoch24.pth ...
Done in 23.893s
removing stale ckpt [epoch 23] [took 0.05s]
 epoch          : 24
 loss           : 1.182821016550064
 quant_reg      : 13.62058857345581
 quant_err      : 13.62058857345581
 learning_rate  : 1.5367843386251178e-05
 n_samples      : 768000
 n_steps        : 6000
 MSRVTT_jsfusion_test/t2v_metrics/R1: 25.7
 MSRVTT_jsfusion_test/t2v_metrics/R5: 56.3
 MSRVTT_jsfusion_test/t2v_metrics/R10: 68.0
 MSRVTT_jsfusion_test/t2v_metrics/R50: 89.4
 MSRVTT_jsfusion_test/t2v_metrics/MedR: 4.0
 MSRVTT_jsfusion_test/t2v_metrics/MeanR: 27.489
 MSRVTT_jsfusion_test/t2v_metrics/geometric_mean_R1-R5-R10: 46.16542205080976
 MSRVTT_jsfusion_test/v2t_metrics/R1: 23.9
 MSRVTT_jsfusion_test/v2t_metrics/R5: 56.3
 MSRVTT_jsfusion_test/v2t_metrics/R10: 69.7
 MSRVTT_jsfusion_test/v2t_metrics/R50: 88.9
 MSRVTT_jsfusion_test/v2t_metrics/MedR: 4.0
 MSRVTT_jsfusion_test/v2t_metrics/MeanR: 25.2085
 MSRVTT_jsfusion_test/v2t_metrics/geometric_mean_R1-R5-R10: 45.43386584156976
 mnt_best       : 46.16542205080976
 not_improved_count: 0
Train Epoch: 25 [1/250 128/32000 (0%)] Loss: 1.06760 (QuantReg: 13.89698) QuantErr: 13.89698 batch_time=52.65360 
Train Epoch: 25 [12/250 1536/32000 (5%)] Loss: 0.97981 (QuantReg: 13.55538) QuantErr: 13.55538 batch_time=0.69463 
Train Epoch: 25 [23/250 2944/32000 (9%)] Loss: 1.24033 (QuantReg: 13.57722) QuantErr: 13.57722 batch_time=0.65978 
Train Epoch: 25 [34/250 4352/32000 (14%)] Loss: 1.26494 (QuantReg: 13.50588) QuantErr: 13.50588 batch_time=0.67408 
Train Epoch: 25 [45/250 5760/32000 (18%)] Loss: 0.89869 (QuantReg: 13.81609) QuantErr: 13.81609 batch_time=0.68659 
Train Epoch: 25 [56/250 7168/32000 (22%)] Loss: 1.27982 (QuantReg: 13.45340) QuantErr: 13.45340 batch_time=0.73741 
Train Epoch: 25 [67/250 8576/32000 (27%)] Loss: 0.96065 (QuantReg: 13.54976) QuantErr: 13.54976 batch_time=0.67151 
Train Epoch: 25 [78/250 9984/32000 (31%)] Loss: 1.24670 (QuantReg: 13.46711) QuantErr: 13.46711 batch_time=1.59718 
Train Epoch: 25 [89/250 11392/32000 (36%)] Loss: 1.14807 (QuantReg: 13.36104) QuantErr: 13.36104 batch_time=0.66661 
Train Epoch: 25 [100/250 12800/32000 (40%)] Loss: 1.25799 (QuantReg: 13.12569) QuantErr: 13.12569 batch_time=0.69040 
Train Epoch: 25 [111/250 14208/32000 (44%)] Loss: 1.16723 (QuantReg: 13.69553) QuantErr: 13.69553 batch_time=0.68565 
Train Epoch: 25 [122/250 15616/32000 (49%)] Loss: 1.31604 (QuantReg: 13.60716) QuantErr: 13.60716 batch_time=0.72047 
Train Epoch: 25 [133/250 17024/32000 (53%)] Loss: 1.32328 (QuantReg: 13.32493) QuantErr: 13.32493 batch_time=0.70584 
Train Epoch: 25 [144/250 18432/32000 (58%)] Loss: 1.31202 (QuantReg: 13.97249) QuantErr: 13.97249 batch_time=3.13752 
Train Epoch: 25 [155/250 19840/32000 (62%)] Loss: 1.12912 (QuantReg: 13.64621) QuantErr: 13.64621 batch_time=0.69992 
Train Epoch: 25 [166/250 21248/32000 (66%)] Loss: 1.49036 (QuantReg: 13.61193) QuantErr: 13.61193 batch_time=0.65688 
Train Epoch: 25 [177/250 22656/32000 (71%)] Loss: 1.16953 (QuantReg: 13.49377) QuantErr: 13.49377 batch_time=1.01696 
Train Epoch: 25 [188/250 24064/32000 (75%)] Loss: 1.40152 (QuantReg: 13.81907) QuantErr: 13.81907 batch_time=0.94311 
Train Epoch: 25 [199/250 25472/32000 (80%)] Loss: 0.91213 (QuantReg: 13.65449) QuantErr: 13.65449 batch_time=0.88236 
Train Epoch: 25 [210/250 26880/32000 (84%)] Loss: 0.95372 (QuantReg: 13.56925) QuantErr: 13.56925 batch_time=0.68128 
Train Epoch: 25 [221/250 28288/32000 (88%)] Loss: 1.00226 (QuantReg: 13.42613) QuantErr: 13.42613 batch_time=0.68644 
Train Epoch: 25 [232/250 29696/32000 (93%)] Loss: 1.05671 (QuantReg: 13.59708) QuantErr: 13.59708 batch_time=0.73156 
Train Epoch: 25 [243/250 31104/32000 (97%)] Loss: 1.37397 (QuantReg: 13.52407) QuantErr: 13.52407 batch_time=0.70641 
Train Epoch: 25 codebook_update_time=1.73741
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_MSRVTT_1kA_bert-large/checkpoint-epoch25.pth ...
Done in 12.028s
removing stale ckpt [epoch 24] [took 0.05s]
 epoch          : 25
 loss           : 1.1589856853485108
 quant_reg      : 13.612030361175536
 quant_err      : 13.612030361175536
 learning_rate  : 1.4599451216938618e-05
 n_samples      : 800000
 n_steps        : 6250
 MSRVTT_jsfusion_test/t2v_metrics/R1: 26.0
 MSRVTT_jsfusion_test/t2v_metrics/R5: 54.5
 MSRVTT_jsfusion_test/t2v_metrics/R10: 68.0
 MSRVTT_jsfusion_test/t2v_metrics/R50: 89.4
 MSRVTT_jsfusion_test/t2v_metrics/MedR: 4.0
 MSRVTT_jsfusion_test/t2v_metrics/MeanR: 27.236
 MSRVTT_jsfusion_test/t2v_metrics/geometric_mean_R1-R5-R10: 45.84509964209461
 MSRVTT_jsfusion_test/v2t_metrics/R1: 25.1
 MSRVTT_jsfusion_test/v2t_metrics/R5: 57.6
 MSRVTT_jsfusion_test/v2t_metrics/R10: 70.3
 MSRVTT_jsfusion_test/v2t_metrics/R50: 89.7
 MSRVTT_jsfusion_test/v2t_metrics/MedR: 4.0
 MSRVTT_jsfusion_test/v2t_metrics/MeanR: 25.1085
 MSRVTT_jsfusion_test/v2t_metrics/geometric_mean_R1-R5-R10: 46.66778373743254
 mnt_best       : 46.16542205080976
 not_improved_count: 1
Train Epoch: 26 [1/250 128/32000 (0%)] Loss: 0.93087 (QuantReg: 13.49866) QuantErr: 13.49866 batch_time=66.97912 
Train Epoch: 26 [12/250 1536/32000 (5%)] Loss: 1.18927 (QuantReg: 13.57635) QuantErr: 13.57635 batch_time=0.75744 
Train Epoch: 26 [23/250 2944/32000 (9%)] Loss: 1.51871 (QuantReg: 13.53457) QuantErr: 13.53457 batch_time=0.78527 
Train Epoch: 26 [34/250 4352/32000 (14%)] Loss: 1.08451 (QuantReg: 13.64161) QuantErr: 13.64161 batch_time=0.67075 
Train Epoch: 26 [45/250 5760/32000 (18%)] Loss: 1.05898 (QuantReg: 13.60506) QuantErr: 13.60506 batch_time=0.70305 
Train Epoch: 26 [56/250 7168/32000 (22%)] Loss: 1.19239 (QuantReg: 13.16974) QuantErr: 13.16974 batch_time=0.76480 
Train Epoch: 26 [67/250 8576/32000 (27%)] Loss: 1.27318 (QuantReg: 13.67402) QuantErr: 13.67402 batch_time=0.68372 
Train Epoch: 26 [78/250 9984/32000 (31%)] Loss: 0.94546 (QuantReg: 13.75404) QuantErr: 13.75404 batch_time=0.71474 
Train Epoch: 26 [89/250 11392/32000 (36%)] Loss: 1.18562 (QuantReg: 13.56328) QuantErr: 13.56328 batch_time=1.08132 
Train Epoch: 26 [100/250 12800/32000 (40%)] Loss: 1.22104 (QuantReg: 13.81354) QuantErr: 13.81354 batch_time=0.67744 
Train Epoch: 26 [111/250 14208/32000 (44%)] Loss: 0.83538 (QuantReg: 13.61479) QuantErr: 13.61479 batch_time=0.68839 
Train Epoch: 26 [122/250 15616/32000 (49%)] Loss: 1.42310 (QuantReg: 13.26743) QuantErr: 13.26743 batch_time=0.86425 
Train Epoch: 26 [133/250 17024/32000 (53%)] Loss: 1.03582 (QuantReg: 13.38787) QuantErr: 13.38787 batch_time=0.73262 
Train Epoch: 26 [144/250 18432/32000 (58%)] Loss: 0.97879 (QuantReg: 13.56487) QuantErr: 13.56487 batch_time=0.67266 
Train Epoch: 26 [155/250 19840/32000 (62%)] Loss: 0.90299 (QuantReg: 13.70735) QuantErr: 13.70735 batch_time=1.13465 
Train Epoch: 26 [166/250 21248/32000 (66%)] Loss: 1.06018 (QuantReg: 13.65961) QuantErr: 13.65961 batch_time=2.92075 
Train Epoch: 26 [177/250 22656/32000 (71%)] Loss: 0.87414 (QuantReg: 13.86382) QuantErr: 13.86382 batch_time=0.67072 
Train Epoch: 26 [188/250 24064/32000 (75%)] Loss: 0.99289 (QuantReg: 13.93775) QuantErr: 13.93775 batch_time=0.69862 
Train Epoch: 26 [199/250 25472/32000 (80%)] Loss: 1.11889 (QuantReg: 13.90748) QuantErr: 13.90748 batch_time=0.77184 
Train Epoch: 26 [210/250 26880/32000 (84%)] Loss: 1.10081 (QuantReg: 13.33210) QuantErr: 13.33210 batch_time=0.67827 
Train Epoch: 26 [221/250 28288/32000 (88%)] Loss: 0.86302 (QuantReg: 13.42334) QuantErr: 13.42334 batch_time=0.68956 
Train Epoch: 26 [232/250 29696/32000 (93%)] Loss: 1.21949 (QuantReg: 13.68169) QuantErr: 13.68169 batch_time=0.65073 
Train Epoch: 26 [243/250 31104/32000 (97%)] Loss: 1.13476 (QuantReg: 13.50069) QuantErr: 13.50069 batch_time=0.73476 
Train Epoch: 26 codebook_update_time=1.77342
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_MSRVTT_1kA_bert-large/checkpoint-epoch26.pth ...
Done in 18.455s
removing stale ckpt [epoch 25] [took 0.11s]
 epoch          : 26
 loss           : 1.1306091930866242
 quant_reg      : 13.62413512802124
 quant_err      : 13.62413512802124
 learning_rate  : 1.3869478656091687e-05
 n_samples      : 832000
 n_steps        : 6500
 MSRVTT_jsfusion_test/t2v_metrics/R1: 25.2
 MSRVTT_jsfusion_test/t2v_metrics/R5: 55.5
 MSRVTT_jsfusion_test/t2v_metrics/R10: 68.6
 MSRVTT_jsfusion_test/t2v_metrics/R50: 89.0
 MSRVTT_jsfusion_test/t2v_metrics/MedR: 4.0
 MSRVTT_jsfusion_test/t2v_metrics/MeanR: 27.719
 MSRVTT_jsfusion_test/t2v_metrics/geometric_mean_R1-R5-R10: 45.779658275371936
 MSRVTT_jsfusion_test/v2t_metrics/R1: 25.8
 MSRVTT_jsfusion_test/v2t_metrics/R5: 57.2
 MSRVTT_jsfusion_test/v2t_metrics/R10: 71.3
 MSRVTT_jsfusion_test/v2t_metrics/R50: 89.9
 MSRVTT_jsfusion_test/v2t_metrics/MedR: 4.0
 MSRVTT_jsfusion_test/v2t_metrics/MeanR: 25.1895
 MSRVTT_jsfusion_test/v2t_metrics/geometric_mean_R1-R5-R10: 47.210118246389705
 mnt_best       : 46.16542205080976
 not_improved_count: 2
Train Epoch: 27 [1/250 128/32000 (0%)] Loss: 0.96885 (QuantReg: 13.88746) QuantErr: 13.88746 batch_time=64.02840 
Train Epoch: 27 [12/250 1536/32000 (5%)] Loss: 1.21551 (QuantReg: 13.59114) QuantErr: 13.59114 batch_time=0.70718 
Train Epoch: 27 [23/250 2944/32000 (9%)] Loss: 1.09986 (QuantReg: 13.74924) QuantErr: 13.74924 batch_time=0.68658 
Train Epoch: 27 [34/250 4352/32000 (14%)] Loss: 1.47232 (QuantReg: 13.33490) QuantErr: 13.33490 batch_time=0.67655 
Train Epoch: 27 [45/250 5760/32000 (18%)] Loss: 0.76377 (QuantReg: 13.97355) QuantErr: 13.97355 batch_time=0.69058 
Train Epoch: 27 [56/250 7168/32000 (22%)] Loss: 1.12782 (QuantReg: 13.67566) QuantErr: 13.67566 batch_time=0.66250 
Train Epoch: 27 [67/250 8576/32000 (27%)] Loss: 1.08475 (QuantReg: 13.78397) QuantErr: 13.78397 batch_time=1.16199 
Train Epoch: 27 [78/250 9984/32000 (31%)] Loss: 1.25578 (QuantReg: 13.73800) QuantErr: 13.73800 batch_time=0.72212 
Train Epoch: 27 [89/250 11392/32000 (36%)] Loss: 1.16998 (QuantReg: 13.63817) QuantErr: 13.63817 batch_time=0.68539 
Train Epoch: 27 [100/250 12800/32000 (40%)] Loss: 1.26279 (QuantReg: 13.68320) QuantErr: 13.68320 batch_time=0.68529 
Train Epoch: 27 [111/250 14208/32000 (44%)] Loss: 1.39727 (QuantReg: 13.49057) QuantErr: 13.49057 batch_time=0.68531 
Train Epoch: 27 [122/250 15616/32000 (49%)] Loss: 1.12801 (QuantReg: 13.55211) QuantErr: 13.55211 batch_time=0.69025 
Train Epoch: 27 [133/250 17024/32000 (53%)] Loss: 1.07323 (QuantReg: 13.57244) QuantErr: 13.57244 batch_time=1.06981 
Train Epoch: 27 [144/250 18432/32000 (58%)] Loss: 1.00902 (QuantReg: 13.64338) QuantErr: 13.64338 batch_time=0.70739 
Train Epoch: 27 [155/250 19840/32000 (62%)] Loss: 1.06087 (QuantReg: 13.60441) QuantErr: 13.60441 batch_time=0.77215 
Train Epoch: 27 [166/250 21248/32000 (66%)] Loss: 1.11197 (QuantReg: 13.57898) QuantErr: 13.57898 batch_time=0.72201 
Train Epoch: 27 [177/250 22656/32000 (71%)] Loss: 1.35981 (QuantReg: 13.20960) QuantErr: 13.20960 batch_time=0.71636 
Train Epoch: 27 [188/250 24064/32000 (75%)] Loss: 1.12915 (QuantReg: 13.68179) QuantErr: 13.68179 batch_time=0.68626 
Train Epoch: 27 [199/250 25472/32000 (80%)] Loss: 1.25939 (QuantReg: 13.76697) QuantErr: 13.76697 batch_time=0.97313 
Train Epoch: 27 [210/250 26880/32000 (84%)] Loss: 0.85670 (QuantReg: 13.84917) QuantErr: 13.84917 batch_time=5.69990 
Train Epoch: 27 [221/250 28288/32000 (88%)] Loss: 1.14325 (QuantReg: 13.45183) QuantErr: 13.45183 batch_time=0.68197 
Train Epoch: 27 [232/250 29696/32000 (93%)] Loss: 0.96145 (QuantReg: 13.92015) QuantErr: 13.92015 batch_time=1.29687 
Train Epoch: 27 [243/250 31104/32000 (97%)] Loss: 0.94271 (QuantReg: 13.83588) QuantErr: 13.83588 batch_time=1.07405 
Train Epoch: 27 codebook_update_time=1.75372
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_MSRVTT_1kA_bert-large/checkpoint-epoch27.pth ...
Done in 16.026s
removing stale ckpt [epoch 26] [took 0.06s]
 epoch          : 27
 loss           : 1.1128728828430177
 quant_reg      : 13.628651222229005
 quant_err      : 13.628651222229005
 learning_rate  : 1.3176004723287102e-05
 n_samples      : 864000
 n_steps        : 6750
 MSRVTT_jsfusion_test/t2v_metrics/R1: 25.3
 MSRVTT_jsfusion_test/t2v_metrics/R5: 55.6
 MSRVTT_jsfusion_test/t2v_metrics/R10: 68.8
 MSRVTT_jsfusion_test/t2v_metrics/R50: 89.4
 MSRVTT_jsfusion_test/t2v_metrics/MedR: 4.0
 MSRVTT_jsfusion_test/t2v_metrics/MeanR: 27.597
 MSRVTT_jsfusion_test/t2v_metrics/geometric_mean_R1-R5-R10: 45.91218027399217
 MSRVTT_jsfusion_test/v2t_metrics/R1: 25.7
 MSRVTT_jsfusion_test/v2t_metrics/R5: 56.2
 MSRVTT_jsfusion_test/v2t_metrics/R10: 70.1
 MSRVTT_jsfusion_test/v2t_metrics/R50: 89.3
 MSRVTT_jsfusion_test/v2t_metrics/MedR: 4.0
 MSRVTT_jsfusion_test/v2t_metrics/MeanR: 24.4185
 MSRVTT_jsfusion_test/v2t_metrics/geometric_mean_R1-R5-R10: 46.60821660636915
 mnt_best       : 46.16542205080976
 not_improved_count: 3
Train Epoch: 28 [1/250 128/32000 (0%)] Loss: 1.25095 (QuantReg: 13.52510) QuantErr: 13.52510 batch_time=51.28492 
Train Epoch: 28 [12/250 1536/32000 (5%)] Loss: 1.06477 (QuantReg: 13.39187) QuantErr: 13.39187 batch_time=0.71285 
Train Epoch: 28 [23/250 2944/32000 (9%)] Loss: 0.92544 (QuantReg: 13.57908) QuantErr: 13.57908 batch_time=0.80992 
Train Epoch: 28 [34/250 4352/32000 (14%)] Loss: 1.36775 (QuantReg: 13.42858) QuantErr: 13.42858 batch_time=0.71367 
Train Epoch: 28 [45/250 5760/32000 (18%)] Loss: 1.45622 (QuantReg: 13.46599) QuantErr: 13.46599 batch_time=0.72369 
Train Epoch: 28 [56/250 7168/32000 (22%)] Loss: 0.97026 (QuantReg: 13.76993) QuantErr: 13.76993 batch_time=0.74226 
Train Epoch: 28 [67/250 8576/32000 (27%)] Loss: 1.06586 (QuantReg: 13.20640) QuantErr: 13.20640 batch_time=0.67659 
Train Epoch: 28 [78/250 9984/32000 (31%)] Loss: 1.07133 (QuantReg: 13.56044) QuantErr: 13.56044 batch_time=0.68751 
Train Epoch: 28 [89/250 11392/32000 (36%)] Loss: 0.98982 (QuantReg: 13.59172) QuantErr: 13.59172 batch_time=0.70032 
Train Epoch: 28 [100/250 12800/32000 (40%)] Loss: 1.03511 (QuantReg: 13.44460) QuantErr: 13.44460 batch_time=0.68208 
Train Epoch: 28 [111/250 14208/32000 (44%)] Loss: 1.39427 (QuantReg: 13.82258) QuantErr: 13.82258 batch_time=0.67093 
Train Epoch: 28 [122/250 15616/32000 (49%)] Loss: 1.11110 (QuantReg: 13.55616) QuantErr: 13.55616 batch_time=0.74274 
Train Epoch: 28 [133/250 17024/32000 (53%)] Loss: 0.87962 (QuantReg: 13.42956) QuantErr: 13.42956 batch_time=0.66390 
Train Epoch: 28 [144/250 18432/32000 (58%)] Loss: 1.14525 (QuantReg: 13.76742) QuantErr: 13.76742 batch_time=0.69297 
Train Epoch: 28 [155/250 19840/32000 (62%)] Loss: 1.21946 (QuantReg: 13.48453) QuantErr: 13.48453 batch_time=0.73394 
Train Epoch: 28 [166/250 21248/32000 (66%)] Loss: 1.10218 (QuantReg: 13.70220) QuantErr: 13.70220 batch_time=0.70286 
Train Epoch: 28 [177/250 22656/32000 (71%)] Loss: 0.97013 (QuantReg: 13.40587) QuantErr: 13.40587 batch_time=0.68499 
Train Epoch: 28 [188/250 24064/32000 (75%)] Loss: 1.08944 (QuantReg: 13.48740) QuantErr: 13.48740 batch_time=1.03151 
Train Epoch: 28 [199/250 25472/32000 (80%)] Loss: 1.19972 (QuantReg: 13.62999) QuantErr: 13.62999 batch_time=0.67470 
Train Epoch: 28 [210/250 26880/32000 (84%)] Loss: 1.02937 (QuantReg: 13.98403) QuantErr: 13.98403 batch_time=0.70164 
Train Epoch: 28 [221/250 28288/32000 (88%)] Loss: 1.31561 (QuantReg: 13.47251) QuantErr: 13.47251 batch_time=0.77062 
Train Epoch: 28 [232/250 29696/32000 (93%)] Loss: 1.09160 (QuantReg: 13.61337) QuantErr: 13.61337 batch_time=0.72783 
Train Epoch: 28 [243/250 31104/32000 (97%)] Loss: 1.10978 (QuantReg: 13.64017) QuantErr: 13.64017 batch_time=0.95083 
Train Epoch: 28 codebook_update_time=1.74566
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_MSRVTT_1kA_bert-large/checkpoint-epoch28.pth ...
Done in 11.859s
removing stale ckpt [epoch 27] [took 0.04s]
 epoch          : 28
 loss           : 1.1164747507572175
 quant_reg      : 13.614948947906495
 quant_err      : 13.614948947906495
 learning_rate  : 1.2517204487122746e-05
 n_samples      : 896000
 n_steps        : 7000
 MSRVTT_jsfusion_test/t2v_metrics/R1: 24.5
 MSRVTT_jsfusion_test/t2v_metrics/R5: 55.7
 MSRVTT_jsfusion_test/t2v_metrics/R10: 69.0
 MSRVTT_jsfusion_test/t2v_metrics/R50: 89.1
 MSRVTT_jsfusion_test/t2v_metrics/MedR: 4.0
 MSRVTT_jsfusion_test/t2v_metrics/MeanR: 28.296
 MSRVTT_jsfusion_test/t2v_metrics/geometric_mean_R1-R5-R10: 45.494279359678906
 MSRVTT_jsfusion_test/v2t_metrics/R1: 24.8
 MSRVTT_jsfusion_test/v2t_metrics/R5: 55.3
 MSRVTT_jsfusion_test/v2t_metrics/R10: 69.2
 MSRVTT_jsfusion_test/v2t_metrics/R50: 89.2
 MSRVTT_jsfusion_test/v2t_metrics/MedR: 4.0
 MSRVTT_jsfusion_test/v2t_metrics/MeanR: 25.574
 MSRVTT_jsfusion_test/v2t_metrics/geometric_mean_R1-R5-R10: 45.61359500255706
 mnt_best       : 46.16542205080976
 not_improved_count: 4
Train Epoch: 29 [1/250 128/32000 (0%)] Loss: 1.23208 (QuantReg: 13.58799) QuantErr: 13.58799 batch_time=80.73752 
Train Epoch: 29 [12/250 1536/32000 (5%)] Loss: 1.01792 (QuantReg: 13.76893) QuantErr: 13.76893 batch_time=0.65172 
Train Epoch: 29 [23/250 2944/32000 (9%)] Loss: 0.89917 (QuantReg: 13.80812) QuantErr: 13.80812 batch_time=0.68765 
Train Epoch: 29 [34/250 4352/32000 (14%)] Loss: 0.87475 (QuantReg: 13.91448) QuantErr: 13.91448 batch_time=0.66729 
Train Epoch: 29 [45/250 5760/32000 (18%)] Loss: 1.07294 (QuantReg: 13.63943) QuantErr: 13.63943 batch_time=0.67641 
Train Epoch: 29 [56/250 7168/32000 (22%)] Loss: 1.07298 (QuantReg: 13.54875) QuantErr: 13.54875 batch_time=0.74871 
Train Epoch: 29 [67/250 8576/32000 (27%)] Loss: 1.33956 (QuantReg: 13.69889) QuantErr: 13.69889 batch_time=0.68326 
Train Epoch: 29 [78/250 9984/32000 (31%)] Loss: 1.22419 (QuantReg: 13.67448) QuantErr: 13.67448 batch_time=0.68624 
Train Epoch: 29 [89/250 11392/32000 (36%)] Loss: 1.53123 (QuantReg: 13.59965) QuantErr: 13.59965 batch_time=0.69339 
Train Epoch: 29 [100/250 12800/32000 (40%)] Loss: 1.27027 (QuantReg: 13.37130) QuantErr: 13.37130 batch_time=0.73614 
Train Epoch: 29 [111/250 14208/32000 (44%)] Loss: 1.24433 (QuantReg: 13.41857) QuantErr: 13.41857 batch_time=0.69267 
Train Epoch: 29 [122/250 15616/32000 (49%)] Loss: 1.12947 (QuantReg: 13.25157) QuantErr: 13.25157 batch_time=0.76009 
Train Epoch: 29 [133/250 17024/32000 (53%)] Loss: 1.13105 (QuantReg: 13.66961) QuantErr: 13.66961 batch_time=0.72825 
Train Epoch: 29 [144/250 18432/32000 (58%)] Loss: 1.41284 (QuantReg: 13.22131) QuantErr: 13.22131 batch_time=0.69478 
Train Epoch: 29 [155/250 19840/32000 (62%)] Loss: 1.00362 (QuantReg: 13.88839) QuantErr: 13.88839 batch_time=0.69749 
Train Epoch: 29 [166/250 21248/32000 (66%)] Loss: 1.57694 (QuantReg: 13.41381) QuantErr: 13.41381 batch_time=0.72432 
Train Epoch: 29 [177/250 22656/32000 (71%)] Loss: 1.27151 (QuantReg: 13.79861) QuantErr: 13.79861 batch_time=0.72734 
Train Epoch: 29 [188/250 24064/32000 (75%)] Loss: 1.14227 (QuantReg: 13.91516) QuantErr: 13.91516 batch_time=0.69105 
Train Epoch: 29 [199/250 25472/32000 (80%)] Loss: 0.85886 (QuantReg: 14.06081) QuantErr: 14.06081 batch_time=0.68580 
Train Epoch: 29 [210/250 26880/32000 (84%)] Loss: 0.81065 (QuantReg: 13.96524) QuantErr: 13.96524 batch_time=0.72311 
Train Epoch: 29 [221/250 28288/32000 (88%)] Loss: 1.00088 (QuantReg: 13.82696) QuantErr: 13.82696 batch_time=0.69607 
Train Epoch: 29 [232/250 29696/32000 (93%)] Loss: 1.10128 (QuantReg: 14.04280) QuantErr: 14.04280 batch_time=0.71765 
Train Epoch: 29 [243/250 31104/32000 (97%)] Loss: 0.92607 (QuantReg: 13.86707) QuantErr: 13.86707 batch_time=0.68000 
Train Epoch: 29 codebook_update_time=1.75371
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_MSRVTT_1kA_bert-large/checkpoint-epoch29.pth ...
Done in 11.825s
Updating 'best' checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_MSRVTT_1kA_bert-large/checkpoint-epoch29.pth ...
Done in 23.847s
removing stale ckpt [epoch 28] [took 0.04s]
 epoch          : 29
 loss           : 1.0728151819705962
 quant_reg      : 13.677860210418702
 quant_err      : 13.677860210418702
 learning_rate  : 1.1891344262766608e-05
 n_samples      : 928000
 n_steps        : 7250
 MSRVTT_jsfusion_test/t2v_metrics/R1: 25.2
 MSRVTT_jsfusion_test/t2v_metrics/R5: 56.1
 MSRVTT_jsfusion_test/t2v_metrics/R10: 69.9
 MSRVTT_jsfusion_test/t2v_metrics/R50: 90.1
 MSRVTT_jsfusion_test/t2v_metrics/MedR: 4.0
 MSRVTT_jsfusion_test/t2v_metrics/MeanR: 27.023
 MSRVTT_jsfusion_test/t2v_metrics/geometric_mean_R1-R5-R10: 46.23244474225722
 MSRVTT_jsfusion_test/v2t_metrics/R1: 25.6
 MSRVTT_jsfusion_test/v2t_metrics/R5: 55.8
 MSRVTT_jsfusion_test/v2t_metrics/R10: 70.1
 MSRVTT_jsfusion_test/v2t_metrics/R50: 89.4
 MSRVTT_jsfusion_test/v2t_metrics/MedR: 4.0
 MSRVTT_jsfusion_test/v2t_metrics/MeanR: 24.969
 MSRVTT_jsfusion_test/v2t_metrics/geometric_mean_R1-R5-R10: 46.43698992524283
 mnt_best       : 46.23244474225722
 not_improved_count: 0
Train Epoch: 30 [1/250 128/32000 (0%)] Loss: 1.07604 (QuantReg: 13.76183) QuantErr: 13.76183 batch_time=85.55198 
Train Epoch: 30 [12/250 1536/32000 (5%)] Loss: 1.17471 (QuantReg: 13.67429) QuantErr: 13.67429 batch_time=0.68531 
Train Epoch: 30 [23/250 2944/32000 (9%)] Loss: 1.00570 (QuantReg: 13.50856) QuantErr: 13.50856 batch_time=0.66528 
Train Epoch: 30 [34/250 4352/32000 (14%)] Loss: 1.31290 (QuantReg: 13.51722) QuantErr: 13.51722 batch_time=0.65220 
Train Epoch: 30 [45/250 5760/32000 (18%)] Loss: 0.98000 (QuantReg: 13.93469) QuantErr: 13.93469 batch_time=0.68425 
Train Epoch: 30 [56/250 7168/32000 (22%)] Loss: 1.27311 (QuantReg: 13.76016) QuantErr: 13.76016 batch_time=0.69224 
Train Epoch: 30 [67/250 8576/32000 (27%)] Loss: 1.03970 (QuantReg: 13.79323) QuantErr: 13.79323 batch_time=0.66297 
Train Epoch: 30 [78/250 9984/32000 (31%)] Loss: 0.96553 (QuantReg: 13.69991) QuantErr: 13.69991 batch_time=0.66855 
Train Epoch: 30 [89/250 11392/32000 (36%)] Loss: 1.00487 (QuantReg: 13.90751) QuantErr: 13.90751 batch_time=0.73065 
Train Epoch: 30 [100/250 12800/32000 (40%)] Loss: 1.31390 (QuantReg: 13.86003) QuantErr: 13.86003 batch_time=0.72890 
Train Epoch: 30 [111/250 14208/32000 (44%)] Loss: 1.13647 (QuantReg: 13.61714) QuantErr: 13.61714 batch_time=0.76795 
Train Epoch: 30 [122/250 15616/32000 (49%)] Loss: 1.01677 (QuantReg: 13.81682) QuantErr: 13.81682 batch_time=0.79630 
Train Epoch: 30 [133/250 17024/32000 (53%)] Loss: 1.17373 (QuantReg: 13.65511) QuantErr: 13.65511 batch_time=12.65908 
Train Epoch: 30 [144/250 18432/32000 (58%)] Loss: 1.08639 (QuantReg: 13.64273) QuantErr: 13.64273 batch_time=0.69444 
Train Epoch: 30 [155/250 19840/32000 (62%)] Loss: 1.23558 (QuantReg: 14.14879) QuantErr: 14.14879 batch_time=0.74032 
Train Epoch: 30 [166/250 21248/32000 (66%)] Loss: 0.97901 (QuantReg: 13.93484) QuantErr: 13.93484 batch_time=0.66707 
Train Epoch: 30 [177/250 22656/32000 (71%)] Loss: 0.85620 (QuantReg: 13.86791) QuantErr: 13.86791 batch_time=1.77570 
Train Epoch: 30 [188/250 24064/32000 (75%)] Loss: 1.07270 (QuantReg: 14.01166) QuantErr: 14.01166 batch_time=0.70249 
Train Epoch: 30 [199/250 25472/32000 (80%)] Loss: 1.03018 (QuantReg: 13.69798) QuantErr: 13.69798 batch_time=0.66003 
Train Epoch: 30 [210/250 26880/32000 (84%)] Loss: 1.07988 (QuantReg: 13.63107) QuantErr: 13.63107 batch_time=0.69425 
Train Epoch: 30 [221/250 28288/32000 (88%)] Loss: 0.96204 (QuantReg: 13.95382) QuantErr: 13.95382 batch_time=0.68239 
Train Epoch: 30 [232/250 29696/32000 (93%)] Loss: 1.22542 (QuantReg: 13.37173) QuantErr: 13.37173 batch_time=0.65194 
Train Epoch: 30 [243/250 31104/32000 (97%)] Loss: 0.95169 (QuantReg: 13.66010) QuantErr: 13.66010 batch_time=0.64220 
Train Epoch: 30 codebook_update_time=1.64568
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_MSRVTT_1kA_bert-large/checkpoint-epoch30.pth ...
Done in 10.896s
Updating 'best' checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_MSRVTT_1kA_bert-large/checkpoint-epoch30.pth ...
Done in 22.542s
removing stale ckpt [epoch 29] [took 0.14s]
 epoch          : 30
 loss           : 1.074692953824997
 quant_reg      : 13.74436513519287
 quant_err      : 13.74436513519287
 learning_rate  : 1.1296777049628277e-05
 n_samples      : 960000
 n_steps        : 7500
 MSRVTT_jsfusion_test/t2v_metrics/R1: 26.2
 MSRVTT_jsfusion_test/t2v_metrics/R5: 56.3
 MSRVTT_jsfusion_test/t2v_metrics/R10: 69.8
 MSRVTT_jsfusion_test/t2v_metrics/R50: 90.2
 MSRVTT_jsfusion_test/t2v_metrics/MedR: 4.0
 MSRVTT_jsfusion_test/t2v_metrics/MeanR: 26.9815
 MSRVTT_jsfusion_test/t2v_metrics/geometric_mean_R1-R5-R10: 46.869289454267076
 MSRVTT_jsfusion_test/v2t_metrics/R1: 25.8
 MSRVTT_jsfusion_test/v2t_metrics/R5: 56.6
 MSRVTT_jsfusion_test/v2t_metrics/R10: 69.5
 MSRVTT_jsfusion_test/v2t_metrics/R50: 90.1
 MSRVTT_jsfusion_test/v2t_metrics/MedR: 4.0
 MSRVTT_jsfusion_test/v2t_metrics/MeanR: 24.955
 MSRVTT_jsfusion_test/v2t_metrics/geometric_mean_R1-R5-R10: 46.64520226044574
 mnt_best       : 46.869289454267076
 not_improved_count: 0
Train Epoch: 31 [1/250 128/32000 (0%)] Loss: 1.15007 (QuantReg: 13.73022) QuantErr: 13.73022 batch_time=93.03682 
Train Epoch: 31 [12/250 1536/32000 (5%)] Loss: 1.05179 (QuantReg: 13.73374) QuantErr: 13.73374 batch_time=1.71916 
Train Epoch: 31 [23/250 2944/32000 (9%)] Loss: 1.10739 (QuantReg: 13.85292) QuantErr: 13.85292 batch_time=0.69677 
Train Epoch: 31 [34/250 4352/32000 (14%)] Loss: 1.04150 (QuantReg: 13.50478) QuantErr: 13.50478 batch_time=0.70480 
Train Epoch: 31 [45/250 5760/32000 (18%)] Loss: 0.97336 (QuantReg: 14.11741) QuantErr: 14.11741 batch_time=0.70540 
Train Epoch: 31 [56/250 7168/32000 (22%)] Loss: 0.96664 (QuantReg: 13.50436) QuantErr: 13.50436 batch_time=0.71960 
Train Epoch: 31 [67/250 8576/32000 (27%)] Loss: 0.83656 (QuantReg: 13.66957) QuantErr: 13.66957 batch_time=7.86813 
Train Epoch: 31 [78/250 9984/32000 (31%)] Loss: 0.75011 (QuantReg: 13.87749) QuantErr: 13.87749 batch_time=0.74005 
Train Epoch: 31 [89/250 11392/32000 (36%)] Loss: 0.99357 (QuantReg: 13.55398) QuantErr: 13.55398 batch_time=0.69322 
Train Epoch: 31 [100/250 12800/32000 (40%)] Loss: 1.27923 (QuantReg: 13.36055) QuantErr: 13.36055 batch_time=0.67839 
Train Epoch: 31 [111/250 14208/32000 (44%)] Loss: 1.13629 (QuantReg: 13.57976) QuantErr: 13.57976 batch_time=0.68036 
Train Epoch: 31 [122/250 15616/32000 (49%)] Loss: 0.91385 (QuantReg: 13.80879) QuantErr: 13.80879 batch_time=0.67443 
Train Epoch: 31 [133/250 17024/32000 (53%)] Loss: 1.14613 (QuantReg: 13.80726) QuantErr: 13.80726 batch_time=1.73990 
Train Epoch: 31 [144/250 18432/32000 (58%)] Loss: 1.10024 (QuantReg: 13.63184) QuantErr: 13.63184 batch_time=0.70731 
Train Epoch: 31 [155/250 19840/32000 (62%)] Loss: 1.25576 (QuantReg: 13.30788) QuantErr: 13.30788 batch_time=0.69958 
Train Epoch: 31 [166/250 21248/32000 (66%)] Loss: 1.07886 (QuantReg: 13.55936) QuantErr: 13.55936 batch_time=0.65984 
Train Epoch: 31 [177/250 22656/32000 (71%)] Loss: 1.10164 (QuantReg: 13.61280) QuantErr: 13.61280 batch_time=0.68538 
Train Epoch: 31 [188/250 24064/32000 (75%)] Loss: 0.92476 (QuantReg: 13.78068) QuantErr: 13.78068 batch_time=0.82770 
Train Epoch: 31 [199/250 25472/32000 (80%)] Loss: 1.37797 (QuantReg: 13.78358) QuantErr: 13.78358 batch_time=3.77631 
Train Epoch: 31 [210/250 26880/32000 (84%)] Loss: 0.84821 (QuantReg: 13.38279) QuantErr: 13.38279 batch_time=7.30942 
Train Epoch: 31 [221/250 28288/32000 (88%)] Loss: 0.80785 (QuantReg: 13.66374) QuantErr: 13.66374 batch_time=0.67310 
Train Epoch: 31 [232/250 29696/32000 (93%)] Loss: 1.07098 (QuantReg: 13.88799) QuantErr: 13.88799 batch_time=0.66409 
Train Epoch: 31 [243/250 31104/32000 (97%)] Loss: 1.05170 (QuantReg: 13.94129) QuantErr: 13.94129 batch_time=0.67281 
Train Epoch: 31 codebook_update_time=1.75207
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_MSRVTT_1kA_bert-large/checkpoint-epoch31.pth ...
Done in 15.302s
removing stale ckpt [epoch 30] [took 0.07s]
 epoch          : 31
 loss           : 1.0634530169963836
 quant_reg      : 13.702219829559326
 quant_err      : 13.702219829559326
 learning_rate  : 1.0731938197146863e-05
 n_samples      : 992000
 n_steps        : 7750
 MSRVTT_jsfusion_test/t2v_metrics/R1: 25.9
 MSRVTT_jsfusion_test/t2v_metrics/R5: 56.8
 MSRVTT_jsfusion_test/t2v_metrics/R10: 69.6
 MSRVTT_jsfusion_test/t2v_metrics/R50: 88.9
 MSRVTT_jsfusion_test/t2v_metrics/MedR: 4.0
 MSRVTT_jsfusion_test/t2v_metrics/MeanR: 27.433
 MSRVTT_jsfusion_test/t2v_metrics/geometric_mean_R1-R5-R10: 46.78275352540202
 MSRVTT_jsfusion_test/v2t_metrics/R1: 24.5
 MSRVTT_jsfusion_test/v2t_metrics/R5: 57.1
 MSRVTT_jsfusion_test/v2t_metrics/R10: 71.7
 MSRVTT_jsfusion_test/v2t_metrics/R50: 89.3
 MSRVTT_jsfusion_test/v2t_metrics/MedR: 4.0
 MSRVTT_jsfusion_test/v2t_metrics/MeanR: 24.7445
 MSRVTT_jsfusion_test/v2t_metrics/geometric_mean_R1-R5-R10: 46.4629859220498
 mnt_best       : 46.869289454267076
 not_improved_count: 1
Train Epoch: 32 [1/250 128/32000 (0%)] Loss: 1.11244 (QuantReg: 13.49816) QuantErr: 13.49816 batch_time=86.38901 
Train Epoch: 32 [12/250 1536/32000 (5%)] Loss: 1.18018 (QuantReg: 13.72997) QuantErr: 13.72997 batch_time=0.70013 
Train Epoch: 32 [23/250 2944/32000 (9%)] Loss: 0.91868 (QuantReg: 13.95411) QuantErr: 13.95411 batch_time=0.66215 
Train Epoch: 32 [34/250 4352/32000 (14%)] Loss: 1.23331 (QuantReg: 13.61988) QuantErr: 13.61988 batch_time=0.66226 
Train Epoch: 32 [45/250 5760/32000 (18%)] Loss: 1.00442 (QuantReg: 13.52148) QuantErr: 13.52148 batch_time=0.66741 
Train Epoch: 32 [56/250 7168/32000 (22%)] Loss: 0.89306 (QuantReg: 13.39299) QuantErr: 13.39299 batch_time=0.95748 
Train Epoch: 32 [67/250 8576/32000 (27%)] Loss: 0.80602 (QuantReg: 13.74267) QuantErr: 13.74267 batch_time=1.06011 
Train Epoch: 32 [78/250 9984/32000 (31%)] Loss: 1.13235 (QuantReg: 13.59214) QuantErr: 13.59214 batch_time=0.76007 
Train Epoch: 32 [89/250 11392/32000 (36%)] Loss: 0.97438 (QuantReg: 13.51755) QuantErr: 13.51755 batch_time=0.69651 
Train Epoch: 32 [100/250 12800/32000 (40%)] Loss: 0.92673 (QuantReg: 13.76231) QuantErr: 13.76231 batch_time=0.68198 
Train Epoch: 32 [111/250 14208/32000 (44%)] Loss: 1.13455 (QuantReg: 13.55418) QuantErr: 13.55418 batch_time=0.68370 
Train Epoch: 32 [122/250 15616/32000 (49%)] Loss: 0.91277 (QuantReg: 13.57791) QuantErr: 13.57791 batch_time=0.69826 
Train Epoch: 32 [133/250 17024/32000 (53%)] Loss: 1.38490 (QuantReg: 13.56545) QuantErr: 13.56545 batch_time=3.18946 
Train Epoch: 32 [144/250 18432/32000 (58%)] Loss: 0.92018 (QuantReg: 13.58233) QuantErr: 13.58233 batch_time=0.70304 
Train Epoch: 32 [155/250 19840/32000 (62%)] Loss: 0.92604 (QuantReg: 13.65955) QuantErr: 13.65955 batch_time=0.71896 
Train Epoch: 32 [166/250 21248/32000 (66%)] Loss: 0.90158 (QuantReg: 13.72340) QuantErr: 13.72340 batch_time=0.69553 
Train Epoch: 32 [177/250 22656/32000 (71%)] Loss: 1.01041 (QuantReg: 13.89334) QuantErr: 13.89334 batch_time=0.68975 
Train Epoch: 32 [188/250 24064/32000 (75%)] Loss: 0.99136 (QuantReg: 13.64673) QuantErr: 13.64673 batch_time=0.65066 
Train Epoch: 32 [199/250 25472/32000 (80%)] Loss: 1.00174 (QuantReg: 13.73760) QuantErr: 13.73760 batch_time=0.70418 
Train Epoch: 32 [210/250 26880/32000 (84%)] Loss: 0.84449 (QuantReg: 13.78797) QuantErr: 13.78797 batch_time=0.65512 
Train Epoch: 32 [221/250 28288/32000 (88%)] Loss: 1.00446 (QuantReg: 13.87140) QuantErr: 13.87140 batch_time=0.69516 
Train Epoch: 32 [232/250 29696/32000 (93%)] Loss: 1.30928 (QuantReg: 13.75015) QuantErr: 13.75015 batch_time=3.78699 
Train Epoch: 32 [243/250 31104/32000 (97%)] Loss: 0.94980 (QuantReg: 13.89862) QuantErr: 13.89862 batch_time=0.70401 
Train Epoch: 32 codebook_update_time=2.02766
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_MSRVTT_1kA_bert-large/checkpoint-epoch32.pth ...
Done in 11.921s
removing stale ckpt [epoch 31] [took 0.12s]
 epoch          : 32
 loss           : 1.0296240680217743
 quant_reg      : 13.720482307434082
 quant_err      : 13.720482307434082
 learning_rate  : 1.019534128728952e-05
 n_samples      : 1024000
 n_steps        : 8000
 MSRVTT_jsfusion_test/t2v_metrics/R1: 26.7
 MSRVTT_jsfusion_test/t2v_metrics/R5: 55.3
 MSRVTT_jsfusion_test/t2v_metrics/R10: 68.5
 MSRVTT_jsfusion_test/t2v_metrics/R50: 88.7
 MSRVTT_jsfusion_test/t2v_metrics/MedR: 4.0
 MSRVTT_jsfusion_test/t2v_metrics/MeanR: 27.355
 MSRVTT_jsfusion_test/t2v_metrics/geometric_mean_R1-R5-R10: 46.59174625258319
 MSRVTT_jsfusion_test/v2t_metrics/R1: 24.4
 MSRVTT_jsfusion_test/v2t_metrics/R5: 56.8
 MSRVTT_jsfusion_test/v2t_metrics/R10: 68.8
 MSRVTT_jsfusion_test/v2t_metrics/R50: 89.7
 MSRVTT_jsfusion_test/v2t_metrics/MedR: 4.0
 MSRVTT_jsfusion_test/v2t_metrics/MeanR: 25.429
 MSRVTT_jsfusion_test/v2t_metrics/geometric_mean_R1-R5-R10: 45.685200308054746
 mnt_best       : 46.869289454267076
 not_improved_count: 2
Train Epoch: 33 [1/250 128/32000 (0%)] Loss: 0.84731 (QuantReg: 13.66562) QuantErr: 13.66562 batch_time=89.02092 
Train Epoch: 33 [12/250 1536/32000 (5%)] Loss: 1.02442 (QuantReg: 13.84553) QuantErr: 13.84553 batch_time=0.66901 
Train Epoch: 33 [23/250 2944/32000 (9%)] Loss: 1.07671 (QuantReg: 13.64477) QuantErr: 13.64477 batch_time=0.70766 
Train Epoch: 33 [34/250 4352/32000 (14%)] Loss: 0.93238 (QuantReg: 13.97718) QuantErr: 13.97718 batch_time=0.67994 
Train Epoch: 33 [45/250 5760/32000 (18%)] Loss: 1.19492 (QuantReg: 13.69955) QuantErr: 13.69955 batch_time=0.69216 
Train Epoch: 33 [56/250 7168/32000 (22%)] Loss: 1.07233 (QuantReg: 13.77285) QuantErr: 13.77285 batch_time=0.69334 
Train Epoch: 33 [67/250 8576/32000 (27%)] Loss: 1.09137 (QuantReg: 13.56111) QuantErr: 13.56111 batch_time=0.67042 
Train Epoch: 33 [78/250 9984/32000 (31%)] Loss: 1.24217 (QuantReg: 13.44640) QuantErr: 13.44640 batch_time=0.72606 
Train Epoch: 33 [89/250 11392/32000 (36%)] Loss: 1.08604 (QuantReg: 13.89444) QuantErr: 13.89444 batch_time=0.66020 
Train Epoch: 33 [100/250 12800/32000 (40%)] Loss: 1.16094 (QuantReg: 13.39116) QuantErr: 13.39116 batch_time=0.67018 
Train Epoch: 33 [111/250 14208/32000 (44%)] Loss: 1.05581 (QuantReg: 13.64093) QuantErr: 13.64093 batch_time=0.72877 
Train Epoch: 33 [122/250 15616/32000 (49%)] Loss: 0.94704 (QuantReg: 13.61409) QuantErr: 13.61409 batch_time=0.69402 
Train Epoch: 33 [133/250 17024/32000 (53%)] Loss: 1.27328 (QuantReg: 13.56272) QuantErr: 13.56272 batch_time=2.21392 
Train Epoch: 33 [144/250 18432/32000 (58%)] Loss: 0.98604 (QuantReg: 13.88132) QuantErr: 13.88132 batch_time=0.69883 
Train Epoch: 33 [155/250 19840/32000 (62%)] Loss: 1.22722 (QuantReg: 13.67604) QuantErr: 13.67604 batch_time=0.80606 
Train Epoch: 33 [166/250 21248/32000 (66%)] Loss: 1.09071 (QuantReg: 13.72115) QuantErr: 13.72115 batch_time=0.74295 
Train Epoch: 33 [177/250 22656/32000 (71%)] Loss: 0.86241 (QuantReg: 13.79956) QuantErr: 13.79956 batch_time=0.68526 
Train Epoch: 33 [188/250 24064/32000 (75%)] Loss: 1.13943 (QuantReg: 13.75654) QuantErr: 13.75654 batch_time=0.83492 
Train Epoch: 33 [199/250 25472/32000 (80%)] Loss: 1.11322 (QuantReg: 13.73280) QuantErr: 13.73280 batch_time=0.64383 
Train Epoch: 33 [210/250 26880/32000 (84%)] Loss: 1.02335 (QuantReg: 13.72198) QuantErr: 13.72198 batch_time=0.69703 
Train Epoch: 33 [221/250 28288/32000 (88%)] Loss: 1.02337 (QuantReg: 13.63034) QuantErr: 13.63034 batch_time=0.67042 
Train Epoch: 33 [232/250 29696/32000 (93%)] Loss: 0.87109 (QuantReg: 14.03455) QuantErr: 14.03455 batch_time=0.69598 
Train Epoch: 33 [243/250 31104/32000 (97%)] Loss: 0.93762 (QuantReg: 13.90609) QuantErr: 13.90609 batch_time=0.86108 
Train Epoch: 33 codebook_update_time=1.69240
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_MSRVTT_1kA_bert-large/checkpoint-epoch33.pth ...
Done in 12.237s
Updating 'best' checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_MSRVTT_1kA_bert-large/checkpoint-epoch33.pth ...
Done in 24.746s
removing stale ckpt [epoch 32] [took 0.07s]
 epoch          : 33
 loss           : 1.0369792737960815
 quant_reg      : 13.786599124908447
 quant_err      : 13.786599124908447
 learning_rate  : 9.685574222925043e-06
 n_samples      : 1056000
 n_steps        : 8250
 MSRVTT_jsfusion_test/t2v_metrics/R1: 27.6
 MSRVTT_jsfusion_test/t2v_metrics/R5: 55.9
 MSRVTT_jsfusion_test/t2v_metrics/R10: 69.6
 MSRVTT_jsfusion_test/t2v_metrics/R50: 89.8
 MSRVTT_jsfusion_test/t2v_metrics/MedR: 4.0
 MSRVTT_jsfusion_test/t2v_metrics/MeanR: 27.661
 MSRVTT_jsfusion_test/t2v_metrics/geometric_mean_R1-R5-R10: 47.530973556611336
 MSRVTT_jsfusion_test/v2t_metrics/R1: 24.6
 MSRVTT_jsfusion_test/v2t_metrics/R5: 56.4
 MSRVTT_jsfusion_test/v2t_metrics/R10: 70.2
 MSRVTT_jsfusion_test/v2t_metrics/R50: 89.9
 MSRVTT_jsfusion_test/v2t_metrics/MedR: 4.0
 MSRVTT_jsfusion_test/v2t_metrics/MeanR: 25.3355
 MSRVTT_jsfusion_test/v2t_metrics/geometric_mean_R1-R5-R10: 46.00981013202847
 mnt_best       : 47.530973556611336
 not_improved_count: 0
Train Epoch: 34 [1/250 128/32000 (0%)] Loss: 1.05702 (QuantReg: 13.46640) QuantErr: 13.46640 batch_time=97.41766 
Train Epoch: 34 [12/250 1536/32000 (5%)] Loss: 0.86499 (QuantReg: 13.87507) QuantErr: 13.87507 batch_time=0.66025 
Train Epoch: 34 [23/250 2944/32000 (9%)] Loss: 1.17706 (QuantReg: 13.66211) QuantErr: 13.66211 batch_time=0.71946 
Train Epoch: 34 [34/250 4352/32000 (14%)] Loss: 0.90693 (QuantReg: 13.65470) QuantErr: 13.65470 batch_time=0.69011 
Train Epoch: 34 [45/250 5760/32000 (18%)] Loss: 0.89406 (QuantReg: 13.71886) QuantErr: 13.71886 batch_time=0.67817 
Train Epoch: 34 [56/250 7168/32000 (22%)] Loss: 1.27068 (QuantReg: 13.51622) QuantErr: 13.51622 batch_time=0.71589 
Train Epoch: 34 [67/250 8576/32000 (27%)] Loss: 0.92023 (QuantReg: 13.90958) QuantErr: 13.90958 batch_time=0.66872 
Train Epoch: 34 [78/250 9984/32000 (31%)] Loss: 0.95429 (QuantReg: 13.78452) QuantErr: 13.78452 batch_time=0.66516 
Train Epoch: 34 [89/250 11392/32000 (36%)] Loss: 1.30951 (QuantReg: 13.97398) QuantErr: 13.97398 batch_time=0.67088 
Train Epoch: 34 [100/250 12800/32000 (40%)] Loss: 1.22794 (QuantReg: 14.08230) QuantErr: 14.08230 batch_time=0.69713 
Train Epoch: 34 [111/250 14208/32000 (44%)] Loss: 1.35692 (QuantReg: 13.11887) QuantErr: 13.11887 batch_time=1.21159 
Train Epoch: 34 [122/250 15616/32000 (49%)] Loss: 0.99296 (QuantReg: 13.90573) QuantErr: 13.90573 batch_time=0.68438 
Train Epoch: 34 [133/250 17024/32000 (53%)] Loss: 0.96068 (QuantReg: 13.92927) QuantErr: 13.92927 batch_time=1.43824 
Train Epoch: 34 [144/250 18432/32000 (58%)] Loss: 1.30598 (QuantReg: 13.79651) QuantErr: 13.79651 batch_time=0.68487 
Train Epoch: 34 [155/250 19840/32000 (62%)] Loss: 0.81864 (QuantReg: 13.95196) QuantErr: 13.95196 batch_time=4.05190 
Train Epoch: 34 [166/250 21248/32000 (66%)] Loss: 1.07325 (QuantReg: 13.36276) QuantErr: 13.36276 batch_time=0.69111 
Train Epoch: 34 [177/250 22656/32000 (71%)] Loss: 0.87243 (QuantReg: 14.17328) QuantErr: 14.17328 batch_time=0.67429 
Train Epoch: 34 [188/250 24064/32000 (75%)] Loss: 1.15935 (QuantReg: 14.04801) QuantErr: 14.04801 batch_time=0.86398 
Train Epoch: 34 [199/250 25472/32000 (80%)] Loss: 1.09503 (QuantReg: 13.84156) QuantErr: 13.84156 batch_time=0.66813 
Train Epoch: 34 [210/250 26880/32000 (84%)] Loss: 1.03490 (QuantReg: 13.81071) QuantErr: 13.81071 batch_time=1.25175 
Train Epoch: 34 [221/250 28288/32000 (88%)] Loss: 0.76438 (QuantReg: 13.85308) QuantErr: 13.85308 batch_time=0.68442 
Train Epoch: 34 [232/250 29696/32000 (93%)] Loss: 1.08801 (QuantReg: 13.61474) QuantErr: 13.61474 batch_time=0.70440 
Train Epoch: 34 [243/250 31104/32000 (97%)] Loss: 1.10440 (QuantReg: 14.27694) QuantErr: 14.27694 batch_time=0.86279 
Train Epoch: 34 codebook_update_time=1.73099
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_MSRVTT_1kA_bert-large/checkpoint-epoch34.pth ...
Done in 12.473s
removing stale ckpt [epoch 33] [took 0.06s]
 epoch          : 34
 loss           : 1.0313227376937866
 quant_reg      : 13.78849695968628
 quant_err      : 13.78849695968628
 learning_rate  : 9.20129551177879e-06
 n_samples      : 1088000
 n_steps        : 8500
 MSRVTT_jsfusion_test/t2v_metrics/R1: 26.0
 MSRVTT_jsfusion_test/t2v_metrics/R5: 56.3
 MSRVTT_jsfusion_test/t2v_metrics/R10: 68.7
 MSRVTT_jsfusion_test/t2v_metrics/R50: 89.4
 MSRVTT_jsfusion_test/t2v_metrics/MedR: 4.0
 MSRVTT_jsfusion_test/t2v_metrics/MeanR: 27.907
 MSRVTT_jsfusion_test/t2v_metrics/geometric_mean_R1-R5-R10: 46.50284177337192
 MSRVTT_jsfusion_test/v2t_metrics/R1: 24.4
 MSRVTT_jsfusion_test/v2t_metrics/R5: 58.2
 MSRVTT_jsfusion_test/v2t_metrics/R10: 70.5
 MSRVTT_jsfusion_test/v2t_metrics/R50: 89.4
 MSRVTT_jsfusion_test/v2t_metrics/MedR: 4.0
 MSRVTT_jsfusion_test/v2t_metrics/MeanR: 25.5145
 MSRVTT_jsfusion_test/v2t_metrics/geometric_mean_R1-R5-R10: 46.43377322162849
 mnt_best       : 47.530973556611336
 not_improved_count: 1
Train Epoch: 35 [1/250 128/32000 (0%)] Loss: 1.01188 (QuantReg: 13.56410) QuantErr: 13.56410 batch_time=86.20700 
Train Epoch: 35 [12/250 1536/32000 (5%)] Loss: 1.08991 (QuantReg: 13.57398) QuantErr: 13.57398 batch_time=25.71247 
Train Epoch: 35 [23/250 2944/32000 (9%)] Loss: 1.12026 (QuantReg: 13.86659) QuantErr: 13.86659 batch_time=0.67686 
Train Epoch: 35 [34/250 4352/32000 (14%)] Loss: 0.94813 (QuantReg: 13.45834) QuantErr: 13.45834 batch_time=0.71379 
Train Epoch: 35 [45/250 5760/32000 (18%)] Loss: 0.86751 (QuantReg: 13.83760) QuantErr: 13.83760 batch_time=0.70575 
Train Epoch: 35 [56/250 7168/32000 (22%)] Loss: 1.27129 (QuantReg: 13.68012) QuantErr: 13.68012 batch_time=0.74360 
Train Epoch: 35 [67/250 8576/32000 (27%)] Loss: 1.01848 (QuantReg: 13.58385) QuantErr: 13.58385 batch_time=5.10169 
Train Epoch: 35 [78/250 9984/32000 (31%)] Loss: 1.10429 (QuantReg: 13.83599) QuantErr: 13.83599 batch_time=0.72608 
Train Epoch: 35 [89/250 11392/32000 (36%)] Loss: 1.17947 (QuantReg: 13.88367) QuantErr: 13.88367 batch_time=0.69367 
Train Epoch: 35 [100/250 12800/32000 (40%)] Loss: 1.22509 (QuantReg: 13.96716) QuantErr: 13.96716 batch_time=0.68415 
Train Epoch: 35 [111/250 14208/32000 (44%)] Loss: 0.67225 (QuantReg: 13.67851) QuantErr: 13.67851 batch_time=0.66466 
Train Epoch: 35 [122/250 15616/32000 (49%)] Loss: 1.00566 (QuantReg: 14.13124) QuantErr: 14.13124 batch_time=0.64985 
Train Epoch: 35 [133/250 17024/32000 (53%)] Loss: 1.15305 (QuantReg: 13.66898) QuantErr: 13.66898 batch_time=0.68251 
Train Epoch: 35 [144/250 18432/32000 (58%)] Loss: 0.90148 (QuantReg: 14.06005) QuantErr: 14.06005 batch_time=0.76259 
Train Epoch: 35 [155/250 19840/32000 (62%)] Loss: 1.06226 (QuantReg: 13.75562) QuantErr: 13.75562 batch_time=0.70681 
Train Epoch: 35 [166/250 21248/32000 (66%)] Loss: 1.04264 (QuantReg: 13.74660) QuantErr: 13.74660 batch_time=0.69963 
Train Epoch: 35 [177/250 22656/32000 (71%)] Loss: 0.88934 (QuantReg: 14.02485) QuantErr: 14.02485 batch_time=0.96062 
Train Epoch: 35 [188/250 24064/32000 (75%)] Loss: 1.08608 (QuantReg: 13.68962) QuantErr: 13.68962 batch_time=0.69263 
Train Epoch: 35 [199/250 25472/32000 (80%)] Loss: 1.12826 (QuantReg: 13.64366) QuantErr: 13.64366 batch_time=0.68255 
Train Epoch: 35 [210/250 26880/32000 (84%)] Loss: 1.07652 (QuantReg: 13.64505) QuantErr: 13.64505 batch_time=0.69320 
Train Epoch: 35 [221/250 28288/32000 (88%)] Loss: 0.87555 (QuantReg: 13.99919) QuantErr: 13.99919 batch_time=0.73925 
Train Epoch: 35 [232/250 29696/32000 (93%)] Loss: 1.24577 (QuantReg: 13.64719) QuantErr: 13.64719 batch_time=0.73393 
Train Epoch: 35 [243/250 31104/32000 (97%)] Loss: 0.87033 (QuantReg: 13.75095) QuantErr: 13.75095 batch_time=0.67542 
Train Epoch: 35 codebook_update_time=1.76023
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_MSRVTT_1kA_bert-large/checkpoint-epoch35.pth ...
Done in 12.630s
removing stale ckpt [epoch 34] [took 0.06s]
 epoch          : 35
 loss           : 1.025977562189102
 quant_reg      : 13.807140949249268
 quant_err      : 13.807140949249268
 learning_rate  : 8.74123073618985e-06
 n_samples      : 1120000
 n_steps        : 8750
 MSRVTT_jsfusion_test/t2v_metrics/R1: 26.4
 MSRVTT_jsfusion_test/t2v_metrics/R5: 57.4
 MSRVTT_jsfusion_test/t2v_metrics/R10: 70.1
 MSRVTT_jsfusion_test/t2v_metrics/R50: 89.1
 MSRVTT_jsfusion_test/t2v_metrics/MedR: 4.0
 MSRVTT_jsfusion_test/t2v_metrics/MeanR: 27.293
 MSRVTT_jsfusion_test/t2v_metrics/geometric_mean_R1-R5-R10: 47.35995478371018
 MSRVTT_jsfusion_test/v2t_metrics/R1: 25.4
 MSRVTT_jsfusion_test/v2t_metrics/R5: 57.0
 MSRVTT_jsfusion_test/v2t_metrics/R10: 71.6
 MSRVTT_jsfusion_test/v2t_metrics/R50: 89.8
 MSRVTT_jsfusion_test/v2t_metrics/MedR: 4.0
 MSRVTT_jsfusion_test/v2t_metrics/MeanR: 25.03
 MSRVTT_jsfusion_test/v2t_metrics/geometric_mean_R1-R5-R10: 46.97576538442643
 mnt_best       : 47.530973556611336
 not_improved_count: 2
Train Epoch: 36 [1/250 128/32000 (0%)] Loss: 0.97793 (QuantReg: 13.59194) QuantErr: 13.59194 batch_time=82.49218 
Train Epoch: 36 [12/250 1536/32000 (5%)] Loss: 0.91069 (QuantReg: 13.92250) QuantErr: 13.92250 batch_time=0.64778 
Train Epoch: 36 [23/250 2944/32000 (9%)] Loss: 1.04033 (QuantReg: 14.07758) QuantErr: 14.07758 batch_time=0.70885 
Train Epoch: 36 [34/250 4352/32000 (14%)] Loss: 0.97649 (QuantReg: 14.08325) QuantErr: 14.08325 batch_time=0.70332 
Train Epoch: 36 [45/250 5760/32000 (18%)] Loss: 1.11149 (QuantReg: 14.06787) QuantErr: 14.06787 batch_time=0.75432 
Train Epoch: 36 [56/250 7168/32000 (22%)] Loss: 1.00375 (QuantReg: 13.85228) QuantErr: 13.85228 batch_time=0.71091 
Train Epoch: 36 [67/250 8576/32000 (27%)] Loss: 0.85977 (QuantReg: 13.44840) QuantErr: 13.44840 batch_time=0.69599 
Train Epoch: 36 [78/250 9984/32000 (31%)] Loss: 0.80154 (QuantReg: 14.03052) QuantErr: 14.03052 batch_time=0.70400 
Train Epoch: 36 [89/250 11392/32000 (36%)] Loss: 0.98117 (QuantReg: 13.87462) QuantErr: 13.87462 batch_time=1.79777 
Train Epoch: 36 [100/250 12800/32000 (40%)] Loss: 1.33229 (QuantReg: 13.64902) QuantErr: 13.64902 batch_time=0.65992 
Train Epoch: 36 [111/250 14208/32000 (44%)] Loss: 0.85251 (QuantReg: 13.83348) QuantErr: 13.83348 batch_time=0.67277 
Train Epoch: 36 [122/250 15616/32000 (49%)] Loss: 1.01209 (QuantReg: 14.06205) QuantErr: 14.06205 batch_time=0.67073 
Train Epoch: 36 [133/250 17024/32000 (53%)] Loss: 0.86648 (QuantReg: 13.86953) QuantErr: 13.86953 batch_time=0.66013 
Train Epoch: 36 [144/250 18432/32000 (58%)] Loss: 0.88900 (QuantReg: 13.96702) QuantErr: 13.96702 batch_time=0.72401 
Train Epoch: 36 [155/250 19840/32000 (62%)] Loss: 1.26768 (QuantReg: 13.84016) QuantErr: 13.84016 batch_time=0.67112 
Train Epoch: 36 [166/250 21248/32000 (66%)] Loss: 0.83208 (QuantReg: 13.65965) QuantErr: 13.65965 batch_time=0.82701 
Train Epoch: 36 [177/250 22656/32000 (71%)] Loss: 1.03302 (QuantReg: 14.03757) QuantErr: 14.03757 batch_time=0.67260 
Train Epoch: 36 [188/250 24064/32000 (75%)] Loss: 0.70872 (QuantReg: 13.92034) QuantErr: 13.92034 batch_time=0.68149 
Train Epoch: 36 [199/250 25472/32000 (80%)] Loss: 1.13656 (QuantReg: 13.71675) QuantErr: 13.71675 batch_time=0.93778 
Train Epoch: 36 [210/250 26880/32000 (84%)] Loss: 0.75294 (QuantReg: 13.73850) QuantErr: 13.73850 batch_time=0.73708 
Train Epoch: 36 [221/250 28288/32000 (88%)] Loss: 1.07817 (QuantReg: 13.92169) QuantErr: 13.92169 batch_time=0.70367 
Train Epoch: 36 [232/250 29696/32000 (93%)] Loss: 0.81715 (QuantReg: 14.11594) QuantErr: 14.11594 batch_time=0.67567 
Train Epoch: 36 [243/250 31104/32000 (97%)] Loss: 0.92680 (QuantReg: 14.28319) QuantErr: 14.28319 batch_time=0.81812 
Train Epoch: 36 codebook_update_time=1.76786
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_MSRVTT_1kA_bert-large/checkpoint-epoch36.pth ...
Done in 13.086s
removing stale ckpt [epoch 35] [took 0.06s]
 epoch          : 36
 loss           : 1.0139063732624054
 quant_reg      : 13.804634483337402
 quant_err      : 13.804634483337402
 learning_rate  : 8.304169199380357e-06
 n_samples      : 1152000
 n_steps        : 9000
 MSRVTT_jsfusion_test/t2v_metrics/R1: 25.3
 MSRVTT_jsfusion_test/t2v_metrics/R5: 57.4
 MSRVTT_jsfusion_test/t2v_metrics/R10: 69.1
 MSRVTT_jsfusion_test/t2v_metrics/R50: 89.1
 MSRVTT_jsfusion_test/t2v_metrics/MedR: 4.0
 MSRVTT_jsfusion_test/t2v_metrics/MeanR: 26.815
 MSRVTT_jsfusion_test/t2v_metrics/geometric_mean_R1-R5-R10: 46.46973048317651
 MSRVTT_jsfusion_test/v2t_metrics/R1: 25.0
 MSRVTT_jsfusion_test/v2t_metrics/R5: 57.8
 MSRVTT_jsfusion_test/v2t_metrics/R10: 71.2
 MSRVTT_jsfusion_test/v2t_metrics/R50: 89.6
 MSRVTT_jsfusion_test/v2t_metrics/MedR: 4.0
 MSRVTT_jsfusion_test/v2t_metrics/MeanR: 24.894
 MSRVTT_jsfusion_test/v2t_metrics/geometric_mean_R1-R5-R10: 46.857877598178305
 mnt_best       : 47.530973556611336
 not_improved_count: 3
Train Epoch: 37 [1/250 128/32000 (0%)] Loss: 1.08389 (QuantReg: 13.73057) QuantErr: 13.73057 batch_time=74.83673 
Train Epoch: 37 [12/250 1536/32000 (5%)] Loss: 1.15860 (QuantReg: 13.74430) QuantErr: 13.74430 batch_time=3.01131 
Train Epoch: 37 [23/250 2944/32000 (9%)] Loss: 0.89480 (QuantReg: 13.85251) QuantErr: 13.85251 batch_time=0.70568 
Train Epoch: 37 [34/250 4352/32000 (14%)] Loss: 1.06470 (QuantReg: 13.87051) QuantErr: 13.87051 batch_time=0.66680 
Train Epoch: 37 [45/250 5760/32000 (18%)] Loss: 0.96857 (QuantReg: 13.70452) QuantErr: 13.70452 batch_time=0.67354 
Train Epoch: 37 [56/250 7168/32000 (22%)] Loss: 1.10102 (QuantReg: 13.60139) QuantErr: 13.60139 batch_time=0.70780 
Train Epoch: 37 [67/250 8576/32000 (27%)] Loss: 0.86897 (QuantReg: 13.70026) QuantErr: 13.70026 batch_time=0.69702 
Train Epoch: 37 [78/250 9984/32000 (31%)] Loss: 0.86584 (QuantReg: 14.15118) QuantErr: 14.15118 batch_time=0.72710 
Train Epoch: 37 [89/250 11392/32000 (36%)] Loss: 1.01146 (QuantReg: 13.89905) QuantErr: 13.89905 batch_time=0.69168 
Train Epoch: 37 [100/250 12800/32000 (40%)] Loss: 0.83063 (QuantReg: 13.82714) QuantErr: 13.82714 batch_time=0.72062 
Train Epoch: 37 [111/250 14208/32000 (44%)] Loss: 0.97089 (QuantReg: 13.76232) QuantErr: 13.76232 batch_time=0.67395 
Train Epoch: 37 [122/250 15616/32000 (49%)] Loss: 1.05478 (QuantReg: 13.77722) QuantErr: 13.77722 batch_time=0.71686 
Train Epoch: 37 [133/250 17024/32000 (53%)] Loss: 0.84939 (QuantReg: 13.66137) QuantErr: 13.66137 batch_time=0.82934 
Train Epoch: 37 [144/250 18432/32000 (58%)] Loss: 0.87829 (QuantReg: 13.76772) QuantErr: 13.76772 batch_time=2.91523 
Train Epoch: 37 [155/250 19840/32000 (62%)] Loss: 1.13512 (QuantReg: 13.90857) QuantErr: 13.90857 batch_time=0.72561 
Train Epoch: 37 [166/250 21248/32000 (66%)] Loss: 0.90698 (QuantReg: 13.97892) QuantErr: 13.97892 batch_time=0.70300 
Train Epoch: 37 [177/250 22656/32000 (71%)] Loss: 1.04908 (QuantReg: 13.79443) QuantErr: 13.79443 batch_time=0.70651 
Train Epoch: 37 [188/250 24064/32000 (75%)] Loss: 1.20885 (QuantReg: 13.85202) QuantErr: 13.85202 batch_time=0.69583 
Train Epoch: 37 [199/250 25472/32000 (80%)] Loss: 0.68493 (QuantReg: 13.92845) QuantErr: 13.92845 batch_time=0.78583 
Train Epoch: 37 [210/250 26880/32000 (84%)] Loss: 1.06928 (QuantReg: 13.84462) QuantErr: 13.84462 batch_time=0.70934 
Train Epoch: 37 [221/250 28288/32000 (88%)] Loss: 0.92472 (QuantReg: 13.92667) QuantErr: 13.92667 batch_time=0.69045 
Train Epoch: 37 [232/250 29696/32000 (93%)] Loss: 0.99874 (QuantReg: 14.05882) QuantErr: 14.05882 batch_time=0.68827 
Train Epoch: 37 [243/250 31104/32000 (97%)] Loss: 1.40366 (QuantReg: 14.03724) QuantErr: 14.03724 batch_time=0.84134 
Train Epoch: 37 codebook_update_time=1.76395
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_MSRVTT_1kA_bert-large/checkpoint-epoch37.pth ...
Done in 11.999s
Updating 'best' checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_MSRVTT_1kA_bert-large/checkpoint-epoch37.pth ...
Done in 24.568s
removing stale ckpt [epoch 36] [took 0.05s]
 epoch          : 37
 loss           : 1.0143856637477875
 quant_reg      : 13.8349019241333
 quant_err      : 13.8349019241333
 learning_rate  : 7.888960739411339e-06
 n_samples      : 1184000
 n_steps        : 9250
 MSRVTT_jsfusion_test/t2v_metrics/R1: 27.0
 MSRVTT_jsfusion_test/t2v_metrics/R5: 57.2
 MSRVTT_jsfusion_test/t2v_metrics/R10: 69.9
 MSRVTT_jsfusion_test/t2v_metrics/R50: 88.6
 MSRVTT_jsfusion_test/t2v_metrics/MedR: 4.0
 MSRVTT_jsfusion_test/t2v_metrics/MeanR: 27.467
 MSRVTT_jsfusion_test/t2v_metrics/geometric_mean_R1-R5-R10: 47.61520475592054
 MSRVTT_jsfusion_test/v2t_metrics/R1: 25.2
 MSRVTT_jsfusion_test/v2t_metrics/R5: 58.1
 MSRVTT_jsfusion_test/v2t_metrics/R10: 71.1
 MSRVTT_jsfusion_test/v2t_metrics/R50: 90.1
 MSRVTT_jsfusion_test/v2t_metrics/MedR: 4.0
 MSRVTT_jsfusion_test/v2t_metrics/MeanR: 24.651
 MSRVTT_jsfusion_test/v2t_metrics/geometric_mean_R1-R5-R10: 47.041600710835354
 mnt_best       : 47.61520475592054
 not_improved_count: 0
Train Epoch: 38 [1/250 128/32000 (0%)] Loss: 0.83998 (QuantReg: 14.09529) QuantErr: 14.09529 batch_time=82.91868 
Train Epoch: 38 [12/250 1536/32000 (5%)] Loss: 0.86778 (QuantReg: 13.80771) QuantErr: 13.80771 batch_time=0.70100 
Train Epoch: 38 [23/250 2944/32000 (9%)] Loss: 1.21985 (QuantReg: 13.73800) QuantErr: 13.73800 batch_time=0.67682 
Train Epoch: 38 [34/250 4352/32000 (14%)] Loss: 1.11585 (QuantReg: 13.68873) QuantErr: 13.68873 batch_time=6.90930 
Train Epoch: 38 [45/250 5760/32000 (18%)] Loss: 0.77031 (QuantReg: 13.96540) QuantErr: 13.96540 batch_time=0.75275 
Train Epoch: 38 [56/250 7168/32000 (22%)] Loss: 1.08811 (QuantReg: 13.66191) QuantErr: 13.66191 batch_time=0.68035 
Train Epoch: 38 [67/250 8576/32000 (27%)] Loss: 0.84142 (QuantReg: 13.92731) QuantErr: 13.92731 batch_time=0.66020 
Train Epoch: 38 [78/250 9984/32000 (31%)] Loss: 0.91497 (QuantReg: 13.79453) QuantErr: 13.79453 batch_time=0.63610 
Train Epoch: 38 [89/250 11392/32000 (36%)] Loss: 1.11320 (QuantReg: 13.57928) QuantErr: 13.57928 batch_time=0.67719 
Train Epoch: 38 [100/250 12800/32000 (40%)] Loss: 0.93616 (QuantReg: 13.71504) QuantErr: 13.71504 batch_time=0.71493 
Train Epoch: 38 [111/250 14208/32000 (44%)] Loss: 1.35260 (QuantReg: 13.61519) QuantErr: 13.61519 batch_time=0.66706 
Train Epoch: 38 [122/250 15616/32000 (49%)] Loss: 1.23302 (QuantReg: 13.81382) QuantErr: 13.81382 batch_time=0.66082 
Train Epoch: 38 [133/250 17024/32000 (53%)] Loss: 0.97527 (QuantReg: 13.63606) QuantErr: 13.63606 batch_time=6.79463 
Train Epoch: 38 [144/250 18432/32000 (58%)] Loss: 0.81581 (QuantReg: 13.98930) QuantErr: 13.98930 batch_time=0.72228 
Train Epoch: 38 [155/250 19840/32000 (62%)] Loss: 0.82974 (QuantReg: 14.16469) QuantErr: 14.16469 batch_time=0.71819 
Train Epoch: 38 [166/250 21248/32000 (66%)] Loss: 0.95358 (QuantReg: 13.94756) QuantErr: 13.94756 batch_time=0.65739 
Train Epoch: 38 [177/250 22656/32000 (71%)] Loss: 0.85463 (QuantReg: 13.80945) QuantErr: 13.80945 batch_time=0.70330 
Train Epoch: 38 [188/250 24064/32000 (75%)] Loss: 1.06866 (QuantReg: 13.79864) QuantErr: 13.79864 batch_time=0.66543 
Train Epoch: 38 [199/250 25472/32000 (80%)] Loss: 1.02895 (QuantReg: 14.02156) QuantErr: 14.02156 batch_time=0.69395 
Train Epoch: 38 [210/250 26880/32000 (84%)] Loss: 0.98172 (QuantReg: 14.00162) QuantErr: 14.00162 batch_time=0.68070 
Train Epoch: 38 [221/250 28288/32000 (88%)] Loss: 0.90860 (QuantReg: 13.93861) QuantErr: 13.93861 batch_time=2.70390 
Train Epoch: 38 [232/250 29696/32000 (93%)] Loss: 0.81182 (QuantReg: 14.06218) QuantErr: 14.06218 batch_time=0.71165 
Train Epoch: 38 [243/250 31104/32000 (97%)] Loss: 0.88359 (QuantReg: 14.16529) QuantErr: 14.16529 batch_time=0.70651 
Train Epoch: 38 codebook_update_time=1.78696
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_MSRVTT_1kA_bert-large/checkpoint-epoch38.pth ...
Done in 13.141s
removing stale ckpt [epoch 37] [took 0.06s]
 epoch          : 38
 loss           : 1.0133696501255036
 quant_reg      : 13.84694190979004
 quant_err      : 13.84694190979004
 learning_rate  : 7.494512702440772e-06
 n_samples      : 1216000
 n_steps        : 9500
 MSRVTT_jsfusion_test/t2v_metrics/R1: 26.0
 MSRVTT_jsfusion_test/t2v_metrics/R5: 57.4
 MSRVTT_jsfusion_test/t2v_metrics/R10: 70.5
 MSRVTT_jsfusion_test/t2v_metrics/R50: 89.6
 MSRVTT_jsfusion_test/t2v_metrics/MedR: 4.0
 MSRVTT_jsfusion_test/t2v_metrics/MeanR: 27.111
 MSRVTT_jsfusion_test/t2v_metrics/geometric_mean_R1-R5-R10: 47.208998332304176
 MSRVTT_jsfusion_test/v2t_metrics/R1: 25.3
 MSRVTT_jsfusion_test/v2t_metrics/R5: 58.0
 MSRVTT_jsfusion_test/v2t_metrics/R10: 70.7
 MSRVTT_jsfusion_test/v2t_metrics/R50: 89.9
 MSRVTT_jsfusion_test/v2t_metrics/MedR: 4.0
 MSRVTT_jsfusion_test/v2t_metrics/MeanR: 24.932
 MSRVTT_jsfusion_test/v2t_metrics/geometric_mean_R1-R5-R10: 46.98825419476457
 mnt_best       : 47.61520475592054
 not_improved_count: 1
Train Epoch: 39 [1/250 128/32000 (0%)] Loss: 0.87484 (QuantReg: 13.61476) QuantErr: 13.61476 batch_time=101.85858 
Train Epoch: 39 [12/250 1536/32000 (5%)] Loss: 0.93813 (QuantReg: 13.61370) QuantErr: 13.61370 batch_time=0.65736 
Train Epoch: 39 [23/250 2944/32000 (9%)] Loss: 1.06095 (QuantReg: 13.86965) QuantErr: 13.86965 batch_time=0.64977 
Train Epoch: 39 [34/250 4352/32000 (14%)] Loss: 0.83628 (QuantReg: 14.00095) QuantErr: 14.00095 batch_time=0.67299 
Train Epoch: 39 [45/250 5760/32000 (18%)] Loss: 0.98965 (QuantReg: 14.07035) QuantErr: 14.07035 batch_time=0.75344 
Train Epoch: 39 [56/250 7168/32000 (22%)] Loss: 0.75068 (QuantReg: 13.76722) QuantErr: 13.76722 batch_time=0.82024 
Train Epoch: 39 [67/250 8576/32000 (27%)] Loss: 1.02118 (QuantReg: 13.67672) QuantErr: 13.67672 batch_time=0.89533 
Train Epoch: 39 [78/250 9984/32000 (31%)] Loss: 0.91088 (QuantReg: 14.12122) QuantErr: 14.12122 batch_time=0.68233 
Train Epoch: 39 [89/250 11392/32000 (36%)] Loss: 0.97261 (QuantReg: 13.94542) QuantErr: 13.94542 batch_time=0.67691 
Train Epoch: 39 [100/250 12800/32000 (40%)] Loss: 0.96339 (QuantReg: 13.96395) QuantErr: 13.96395 batch_time=0.71843 
Train Epoch: 39 [111/250 14208/32000 (44%)] Loss: 0.90236 (QuantReg: 14.04451) QuantErr: 14.04451 batch_time=0.79503 
Train Epoch: 39 [122/250 15616/32000 (49%)] Loss: 1.01624 (QuantReg: 13.61820) QuantErr: 13.61820 batch_time=0.69035 
Train Epoch: 39 [133/250 17024/32000 (53%)] Loss: 0.85847 (QuantReg: 14.04836) QuantErr: 14.04836 batch_time=12.46812 
Train Epoch: 39 [144/250 18432/32000 (58%)] Loss: 0.91827 (QuantReg: 13.77709) QuantErr: 13.77709 batch_time=0.67263 
Train Epoch: 39 [155/250 19840/32000 (62%)] Loss: 0.89527 (QuantReg: 14.04896) QuantErr: 14.04896 batch_time=0.68069 
Train Epoch: 39 [166/250 21248/32000 (66%)] Loss: 1.12204 (QuantReg: 13.67411) QuantErr: 13.67411 batch_time=0.70849 
Train Epoch: 39 [177/250 22656/32000 (71%)] Loss: 0.82489 (QuantReg: 14.01771) QuantErr: 14.01771 batch_time=0.68466 
Train Epoch: 39 [188/250 24064/32000 (75%)] Loss: 1.26916 (QuantReg: 13.72856) QuantErr: 13.72856 batch_time=0.84814 
Train Epoch: 39 [199/250 25472/32000 (80%)] Loss: 1.22998 (QuantReg: 14.00521) QuantErr: 14.00521 batch_time=6.83809 
Train Epoch: 39 [210/250 26880/32000 (84%)] Loss: 1.13022 (QuantReg: 13.94026) QuantErr: 13.94026 batch_time=2.02156 
Train Epoch: 39 [221/250 28288/32000 (88%)] Loss: 0.87220 (QuantReg: 13.48406) QuantErr: 13.48406 batch_time=0.66693 
Train Epoch: 39 [232/250 29696/32000 (93%)] Loss: 1.21798 (QuantReg: 13.93802) QuantErr: 13.93802 batch_time=0.65431 
Train Epoch: 39 [243/250 31104/32000 (97%)] Loss: 0.91697 (QuantReg: 13.97795) QuantErr: 13.97795 batch_time=0.73542 
Train Epoch: 39 codebook_update_time=1.74774
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_MSRVTT_1kA_bert-large/checkpoint-epoch39.pth ...
Done in 13.049s
removing stale ckpt [epoch 38] [took 0.23s]
 epoch          : 39
 loss           : 0.990748693704605
 quant_reg      : 13.864111331939696
 quant_err      : 13.864111331939696
 learning_rate  : 7.119787067318733e-06
 n_samples      : 1248000
 n_steps        : 9750
 MSRVTT_jsfusion_test/t2v_metrics/R1: 27.2
 MSRVTT_jsfusion_test/t2v_metrics/R5: 56.7
 MSRVTT_jsfusion_test/t2v_metrics/R10: 69.5
 MSRVTT_jsfusion_test/t2v_metrics/R50: 89.5
 MSRVTT_jsfusion_test/t2v_metrics/MedR: 4.0
 MSRVTT_jsfusion_test/t2v_metrics/MeanR: 26.969
 MSRVTT_jsfusion_test/t2v_metrics/geometric_mean_R1-R5-R10: 47.50203943228713
 MSRVTT_jsfusion_test/v2t_metrics/R1: 25.3
 MSRVTT_jsfusion_test/v2t_metrics/R5: 58.1
 MSRVTT_jsfusion_test/v2t_metrics/R10: 70.1
 MSRVTT_jsfusion_test/v2t_metrics/R50: 90.0
 MSRVTT_jsfusion_test/v2t_metrics/MedR: 4.0
 MSRVTT_jsfusion_test/v2t_metrics/MeanR: 24.964
 MSRVTT_jsfusion_test/v2t_metrics/geometric_mean_R1-R5-R10: 46.88186613969637
 mnt_best       : 47.61520475592054
 not_improved_count: 2
Train Epoch: 40 [1/250 128/32000 (0%)] Loss: 1.02639 (QuantReg: 13.71013) QuantErr: 13.71013 batch_time=104.90984 
Train Epoch: 40 [12/250 1536/32000 (5%)] Loss: 0.96312 (QuantReg: 13.88743) QuantErr: 13.88743 batch_time=0.71391 
Train Epoch: 40 [23/250 2944/32000 (9%)] Loss: 0.81851 (QuantReg: 13.89331) QuantErr: 13.89331 batch_time=0.68020 
Train Epoch: 40 [34/250 4352/32000 (14%)] Loss: 1.24428 (QuantReg: 13.73269) QuantErr: 13.73269 batch_time=0.76614 
Train Epoch: 40 [45/250 5760/32000 (18%)] Loss: 1.14913 (QuantReg: 13.83289) QuantErr: 13.83289 batch_time=0.74983 
Train Epoch: 40 [56/250 7168/32000 (22%)] Loss: 0.96767 (QuantReg: 13.88582) QuantErr: 13.88582 batch_time=0.72364 
Train Epoch: 40 [67/250 8576/32000 (27%)] Loss: 1.18866 (QuantReg: 13.82274) QuantErr: 13.82274 batch_time=0.69402 
Train Epoch: 40 [78/250 9984/32000 (31%)] Loss: 0.94866 (QuantReg: 14.02802) QuantErr: 14.02802 batch_time=0.70058 
Train Epoch: 40 [89/250 11392/32000 (36%)] Loss: 1.08922 (QuantReg: 13.78104) QuantErr: 13.78104 batch_time=0.68133 
Train Epoch: 40 [100/250 12800/32000 (40%)] Loss: 1.08645 (QuantReg: 13.72522) QuantErr: 13.72522 batch_time=0.66644 
Train Epoch: 40 [111/250 14208/32000 (44%)] Loss: 0.91768 (QuantReg: 13.91451) QuantErr: 13.91451 batch_time=0.77443 
Train Epoch: 40 [122/250 15616/32000 (49%)] Loss: 0.88318 (QuantReg: 13.70093) QuantErr: 13.70093 batch_time=0.67959 
Train Epoch: 40 [133/250 17024/32000 (53%)] Loss: 0.72093 (QuantReg: 13.91310) QuantErr: 13.91310 batch_time=0.65949 
Train Epoch: 40 [144/250 18432/32000 (58%)] Loss: 0.85241 (QuantReg: 14.02731) QuantErr: 14.02731 batch_time=0.68657 
Train Epoch: 40 [155/250 19840/32000 (62%)] Loss: 0.77643 (QuantReg: 13.92630) QuantErr: 13.92630 batch_time=0.91999 
Train Epoch: 40 [166/250 21248/32000 (66%)] Loss: 0.96555 (QuantReg: 13.57126) QuantErr: 13.57126 batch_time=0.71029 
Train Epoch: 40 [177/250 22656/32000 (71%)] Loss: 1.04544 (QuantReg: 13.70087) QuantErr: 13.70087 batch_time=0.77443 
Train Epoch: 40 [188/250 24064/32000 (75%)] Loss: 0.77581 (QuantReg: 13.87830) QuantErr: 13.87830 batch_time=0.89797 
Train Epoch: 40 [199/250 25472/32000 (80%)] Loss: 0.89756 (QuantReg: 13.89968) QuantErr: 13.89968 batch_time=0.79919 
Train Epoch: 40 [210/250 26880/32000 (84%)] Loss: 0.81966 (QuantReg: 13.90033) QuantErr: 13.90033 batch_time=0.73463 
Train Epoch: 40 [221/250 28288/32000 (88%)] Loss: 0.78648 (QuantReg: 13.73075) QuantErr: 13.73075 batch_time=0.69046 
Train Epoch: 40 [232/250 29696/32000 (93%)] Loss: 0.89787 (QuantReg: 14.44256) QuantErr: 14.44256 batch_time=0.72554 
Train Epoch: 40 [243/250 31104/32000 (97%)] Loss: 0.93304 (QuantReg: 14.12963) QuantErr: 14.12963 batch_time=0.81434 
Train Epoch: 40 codebook_update_time=1.73487
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_MSRVTT_1kA_bert-large/checkpoint-epoch40.pth ...
Done in 12.345s
removing stale ckpt [epoch 39] [took 0.08s]
 epoch          : 40
 loss           : 0.9737506189346313
 quant_reg      : 13.878868675231933
 quant_err      : 13.878868675231933
 learning_rate  : 6.763797713952796e-06
 n_samples      : 1280000
 n_steps        : 10000
 MSRVTT_jsfusion_test/t2v_metrics/R1: 26.7
 MSRVTT_jsfusion_test/t2v_metrics/R5: 56.4
 MSRVTT_jsfusion_test/t2v_metrics/R10: 69.6
 MSRVTT_jsfusion_test/t2v_metrics/R50: 89.2
 MSRVTT_jsfusion_test/t2v_metrics/MedR: 4.0
 MSRVTT_jsfusion_test/t2v_metrics/MeanR: 28.012
 MSRVTT_jsfusion_test/t2v_metrics/geometric_mean_R1-R5-R10: 47.14835392812561
 MSRVTT_jsfusion_test/v2t_metrics/R1: 25.3
 MSRVTT_jsfusion_test/v2t_metrics/R5: 58.2
 MSRVTT_jsfusion_test/v2t_metrics/R10: 70.9
 MSRVTT_jsfusion_test/v2t_metrics/R50: 89.5
 MSRVTT_jsfusion_test/v2t_metrics/MedR: 4.0
 MSRVTT_jsfusion_test/v2t_metrics/MeanR: 26.0545
 MSRVTT_jsfusion_test/v2t_metrics/geometric_mean_R1-R5-R10: 47.08651847057791
 mnt_best       : 47.61520475592054
 not_improved_count: 3
Train Epoch: 41 [1/250 128/32000 (0%)] Loss: 0.90642 (QuantReg: 13.67533) QuantErr: 13.67533 batch_time=101.62872 
Train Epoch: 41 [12/250 1536/32000 (5%)] Loss: 0.97607 (QuantReg: 13.72454) QuantErr: 13.72454 batch_time=0.71058 
Train Epoch: 41 [23/250 2944/32000 (9%)] Loss: 1.24291 (QuantReg: 14.25231) QuantErr: 14.25231 batch_time=0.66437 
Train Epoch: 41 [34/250 4352/32000 (14%)] Loss: 1.02735 (QuantReg: 13.89829) QuantErr: 13.89829 batch_time=2.24725 
Train Epoch: 41 [45/250 5760/32000 (18%)] Loss: 0.95834 (QuantReg: 14.12179) QuantErr: 14.12179 batch_time=0.66643 
Train Epoch: 41 [56/250 7168/32000 (22%)] Loss: 1.10141 (QuantReg: 13.86703) QuantErr: 13.86703 batch_time=0.65915 
Train Epoch: 41 [67/250 8576/32000 (27%)] Loss: 1.07259 (QuantReg: 13.81266) QuantErr: 13.81266 batch_time=1.36673 
Train Epoch: 41 [78/250 9984/32000 (31%)] Loss: 0.91436 (QuantReg: 13.68186) QuantErr: 13.68186 batch_time=0.68614 
Train Epoch: 41 [89/250 11392/32000 (36%)] Loss: 0.92808 (QuantReg: 13.70894) QuantErr: 13.70894 batch_time=0.65949 
Train Epoch: 41 [100/250 12800/32000 (40%)] Loss: 0.95003 (QuantReg: 13.86004) QuantErr: 13.86004 batch_time=0.66630 
Train Epoch: 41 [111/250 14208/32000 (44%)] Loss: 1.01333 (QuantReg: 13.85642) QuantErr: 13.85642 batch_time=0.71796 
Train Epoch: 41 [122/250 15616/32000 (49%)] Loss: 1.04768 (QuantReg: 13.69380) QuantErr: 13.69380 batch_time=0.66589 
Train Epoch: 41 [133/250 17024/32000 (53%)] Loss: 0.87551 (QuantReg: 13.93033) QuantErr: 13.93033 batch_time=0.81236 
Train Epoch: 41 [144/250 18432/32000 (58%)] Loss: 0.99680 (QuantReg: 13.98962) QuantErr: 13.98962 batch_time=0.69940 
Train Epoch: 41 [155/250 19840/32000 (62%)] Loss: 1.15119 (QuantReg: 13.62465) QuantErr: 13.62465 batch_time=0.67271 
Train Epoch: 41 [166/250 21248/32000 (66%)] Loss: 0.87457 (QuantReg: 13.83430) QuantErr: 13.83430 batch_time=0.67815 
Train Epoch: 41 [177/250 22656/32000 (71%)] Loss: 0.85361 (QuantReg: 14.02769) QuantErr: 14.02769 batch_time=0.70132 
Train Epoch: 41 [188/250 24064/32000 (75%)] Loss: 1.12602 (QuantReg: 13.76750) QuantErr: 13.76750 batch_time=0.72203 
Train Epoch: 41 [199/250 25472/32000 (80%)] Loss: 1.19885 (QuantReg: 13.88731) QuantErr: 13.88731 batch_time=0.87633 
Train Epoch: 41 [210/250 26880/32000 (84%)] Loss: 1.02066 (QuantReg: 13.77352) QuantErr: 13.77352 batch_time=0.68295 
Train Epoch: 41 [221/250 28288/32000 (88%)] Loss: 0.81227 (QuantReg: 14.00154) QuantErr: 14.00154 batch_time=0.70337 
Train Epoch: 41 [232/250 29696/32000 (93%)] Loss: 1.20182 (QuantReg: 13.62113) QuantErr: 13.62113 batch_time=0.69313 
Train Epoch: 41 [243/250 31104/32000 (97%)] Loss: 1.23836 (QuantReg: 13.73781) QuantErr: 13.73781 batch_time=0.66318 
Train Epoch: 41 codebook_update_time=1.73409
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_MSRVTT_1kA_bert-large/checkpoint-epoch41.pth ...
Done in 12.216s
removing stale ckpt [epoch 40] [took 0.11s]
 epoch          : 41
 loss           : 0.9755050024986267
 quant_reg      : 13.887144424438477
 quant_err      : 13.887144424438477
 learning_rate  : 6.425607828255156e-06
 n_samples      : 1312000
 n_steps        : 10250
 MSRVTT_jsfusion_test/t2v_metrics/R1: 27.0
 MSRVTT_jsfusion_test/t2v_metrics/R5: 55.9
 MSRVTT_jsfusion_test/t2v_metrics/R10: 70.4
 MSRVTT_jsfusion_test/t2v_metrics/R50: 89.1
 MSRVTT_jsfusion_test/t2v_metrics/MedR: 4.0
 MSRVTT_jsfusion_test/t2v_metrics/MeanR: 27.78
 MSRVTT_jsfusion_test/t2v_metrics/geometric_mean_R1-R5-R10: 47.364113198883494
 MSRVTT_jsfusion_test/v2t_metrics/R1: 25.1
 MSRVTT_jsfusion_test/v2t_metrics/R5: 57.7
 MSRVTT_jsfusion_test/v2t_metrics/R10: 70.6
 MSRVTT_jsfusion_test/v2t_metrics/R50: 89.4
 MSRVTT_jsfusion_test/v2t_metrics/MedR: 4.0
 MSRVTT_jsfusion_test/v2t_metrics/MeanR: 25.347
 MSRVTT_jsfusion_test/v2t_metrics/geometric_mean_R1-R5-R10: 46.76110283730828
 mnt_best       : 47.61520475592054
 not_improved_count: 4
Train Epoch: 42 [1/250 128/32000 (0%)] Loss: 1.08047 (QuantReg: 13.88825) QuantErr: 13.88825 batch_time=111.78992 
Train Epoch: 42 [12/250 1536/32000 (5%)] Loss: 0.90090 (QuantReg: 13.68157) QuantErr: 13.68157 batch_time=0.66936 
Train Epoch: 42 [23/250 2944/32000 (9%)] Loss: 1.23152 (QuantReg: 13.63667) QuantErr: 13.63667 batch_time=0.72794 
Train Epoch: 42 [34/250 4352/32000 (14%)] Loss: 1.06528 (QuantReg: 13.83213) QuantErr: 13.83213 batch_time=1.94941 
Train Epoch: 42 [45/250 5760/32000 (18%)] Loss: 1.11585 (QuantReg: 13.57073) QuantErr: 13.57073 batch_time=0.68401 
Train Epoch: 42 [56/250 7168/32000 (22%)] Loss: 1.06529 (QuantReg: 14.04691) QuantErr: 14.04691 batch_time=0.84651 
Train Epoch: 42 [67/250 8576/32000 (27%)] Loss: 1.11342 (QuantReg: 13.89347) QuantErr: 13.89347 batch_time=0.67159 
Train Epoch: 42 [78/250 9984/32000 (31%)] Loss: 1.07365 (QuantReg: 14.08363) QuantErr: 14.08363 batch_time=5.28959 
Train Epoch: 42 [89/250 11392/32000 (36%)] Loss: 0.97810 (QuantReg: 13.46697) QuantErr: 13.46697 batch_time=2.88409 
Train Epoch: 42 [100/250 12800/32000 (40%)] Loss: 0.97175 (QuantReg: 13.84253) QuantErr: 13.84253 batch_time=0.75585 
Train Epoch: 42 [111/250 14208/32000 (44%)] Loss: 1.23201 (QuantReg: 13.64895) QuantErr: 13.64895 batch_time=0.68648 
Train Epoch: 42 [122/250 15616/32000 (49%)] Loss: 0.91216 (QuantReg: 13.93705) QuantErr: 13.93705 batch_time=0.77216 
Train Epoch: 42 [133/250 17024/32000 (53%)] Loss: 0.80869 (QuantReg: 13.92180) QuantErr: 13.92180 batch_time=0.69217 
Train Epoch: 42 [144/250 18432/32000 (58%)] Loss: 0.96267 (QuantReg: 13.77527) QuantErr: 13.77527 batch_time=2.16251 
Train Epoch: 42 [155/250 19840/32000 (62%)] Loss: 0.89037 (QuantReg: 13.89101) QuantErr: 13.89101 batch_time=6.53860 
Train Epoch: 42 [166/250 21248/32000 (66%)] Loss: 0.69847 (QuantReg: 14.09194) QuantErr: 14.09194 batch_time=0.81769 
Train Epoch: 42 [177/250 22656/32000 (71%)] Loss: 0.98484 (QuantReg: 13.81619) QuantErr: 13.81619 batch_time=0.75039 
Train Epoch: 42 [188/250 24064/32000 (75%)] Loss: 0.96633 (QuantReg: 14.10825) QuantErr: 14.10825 batch_time=0.76140 
Train Epoch: 42 [199/250 25472/32000 (80%)] Loss: 0.92904 (QuantReg: 14.03498) QuantErr: 14.03498 batch_time=0.67074 
Train Epoch: 42 [210/250 26880/32000 (84%)] Loss: 0.91192 (QuantReg: 14.22995) QuantErr: 14.22995 batch_time=0.67282 
Train Epoch: 42 [221/250 28288/32000 (88%)] Loss: 0.90988 (QuantReg: 14.14211) QuantErr: 14.14211 batch_time=0.71780 
Train Epoch: 42 [232/250 29696/32000 (93%)] Loss: 1.00547 (QuantReg: 14.03917) QuantErr: 14.03917 batch_time=0.69062 
Train Epoch: 42 [243/250 31104/32000 (97%)] Loss: 1.00202 (QuantReg: 14.12699) QuantErr: 14.12699 batch_time=0.68287 
Train Epoch: 42 codebook_update_time=1.73067
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_MSRVTT_1kA_bert-large/checkpoint-epoch42.pth ...
Done in 13.182s
removing stale ckpt [epoch 41] [took 0.07s]
 epoch          : 42
 loss           : 0.9907238643169403
 quant_reg      : 13.932762237548829
 quant_err      : 13.932762237548829
 learning_rate  : 6.104327436842398e-06
 n_samples      : 1344000
 n_steps        : 10500
 MSRVTT_jsfusion_test/t2v_metrics/R1: 26.4
 MSRVTT_jsfusion_test/t2v_metrics/R5: 57.0
 MSRVTT_jsfusion_test/t2v_metrics/R10: 70.6
 MSRVTT_jsfusion_test/t2v_metrics/R50: 90.0
 MSRVTT_jsfusion_test/t2v_metrics/MedR: 4.0
 MSRVTT_jsfusion_test/t2v_metrics/MeanR: 27.24
 MSRVTT_jsfusion_test/t2v_metrics/geometric_mean_R1-R5-R10: 47.36175946866054
 MSRVTT_jsfusion_test/v2t_metrics/R1: 25.8
 MSRVTT_jsfusion_test/v2t_metrics/R5: 58.6
 MSRVTT_jsfusion_test/v2t_metrics/R10: 71.6
 MSRVTT_jsfusion_test/v2t_metrics/R50: 89.5
 MSRVTT_jsfusion_test/v2t_metrics/MedR: 4.0
 MSRVTT_jsfusion_test/v2t_metrics/MeanR: 25.486
 MSRVTT_jsfusion_test/v2t_metrics/geometric_mean_R1-R5-R10: 47.658837864235124
 mnt_best       : 47.61520475592054
 not_improved_count: 5
Train Epoch: 43 [1/250 128/32000 (0%)] Loss: 1.10322 (QuantReg: 13.84994) QuantErr: 13.84994 batch_time=110.98600 
Train Epoch: 43 [12/250 1536/32000 (5%)] Loss: 0.96957 (QuantReg: 14.09283) QuantErr: 14.09283 batch_time=0.67684 
Train Epoch: 43 [23/250 2944/32000 (9%)] Loss: 0.98136 (QuantReg: 14.15581) QuantErr: 14.15581 batch_time=0.69791 
Train Epoch: 43 [34/250 4352/32000 (14%)] Loss: 1.10128 (QuantReg: 13.79251) QuantErr: 13.79251 batch_time=0.72160 
Train Epoch: 43 [45/250 5760/32000 (18%)] Loss: 1.02526 (QuantReg: 14.19345) QuantErr: 14.19345 batch_time=0.72037 
Train Epoch: 43 [56/250 7168/32000 (22%)] Loss: 1.14929 (QuantReg: 13.79159) QuantErr: 13.79159 batch_time=0.68332 
Train Epoch: 43 [67/250 8576/32000 (27%)] Loss: 1.02833 (QuantReg: 13.86488) QuantErr: 13.86488 batch_time=0.64214 
Train Epoch: 43 [78/250 9984/32000 (31%)] Loss: 1.10416 (QuantReg: 14.16165) QuantErr: 14.16165 batch_time=0.69497 
Train Epoch: 43 [89/250 11392/32000 (36%)] Loss: 0.83896 (QuantReg: 14.07506) QuantErr: 14.07506 batch_time=0.67214 
Train Epoch: 43 [100/250 12800/32000 (40%)] Loss: 0.87757 (QuantReg: 14.22832) QuantErr: 14.22832 batch_time=6.79947 
Train Epoch: 43 [111/250 14208/32000 (44%)] Loss: 1.19978 (QuantReg: 13.76055) QuantErr: 13.76055 batch_time=0.70231 
Train Epoch: 43 [122/250 15616/32000 (49%)] Loss: 1.06124 (QuantReg: 13.78875) QuantErr: 13.78875 batch_time=0.69162 
Train Epoch: 43 [133/250 17024/32000 (53%)] Loss: 0.87881 (QuantReg: 14.22461) QuantErr: 14.22461 batch_time=0.66783 
Train Epoch: 43 [144/250 18432/32000 (58%)] Loss: 0.88663 (QuantReg: 14.03429) QuantErr: 14.03429 batch_time=2.27395 
Train Epoch: 43 [155/250 19840/32000 (62%)] Loss: 0.81947 (QuantReg: 14.24439) QuantErr: 14.24439 batch_time=0.75849 
Train Epoch: 43 [166/250 21248/32000 (66%)] Loss: 0.72486 (QuantReg: 13.76158) QuantErr: 13.76158 batch_time=0.69846 
Train Epoch: 43 [177/250 22656/32000 (71%)] Loss: 1.03714 (QuantReg: 14.12954) QuantErr: 14.12954 batch_time=0.68015 
Train Epoch: 43 [188/250 24064/32000 (75%)] Loss: 0.79364 (QuantReg: 13.95734) QuantErr: 13.95734 batch_time=0.68419 
Train Epoch: 43 [199/250 25472/32000 (80%)] Loss: 0.87148 (QuantReg: 13.83263) QuantErr: 13.83263 batch_time=0.67220 
Train Epoch: 43 [210/250 26880/32000 (84%)] Loss: 0.96189 (QuantReg: 13.92414) QuantErr: 13.92414 batch_time=0.76795 
Train Epoch: 43 [221/250 28288/32000 (88%)] Loss: 1.06521 (QuantReg: 13.99849) QuantErr: 13.99849 batch_time=7.33690 
Train Epoch: 43 [232/250 29696/32000 (93%)] Loss: 0.63368 (QuantReg: 14.05766) QuantErr: 14.05766 batch_time=0.70350 
Train Epoch: 43 [243/250 31104/32000 (97%)] Loss: 1.00348 (QuantReg: 13.92501) QuantErr: 13.92501 batch_time=0.69686 
Train Epoch: 43 codebook_update_time=1.80474
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_MSRVTT_1kA_bert-large/checkpoint-epoch43.pth ...
Done in 31.526s
removing stale ckpt [epoch 42] [took 0.18s]
 epoch          : 43
 loss           : 0.9667847218513489
 quant_reg      : 13.949421077728271
 quant_err      : 13.949421077728271
 learning_rate  : 5.799111065000278e-06
 n_samples      : 1376000
 n_steps        : 10750
 MSRVTT_jsfusion_test/t2v_metrics/R1: 26.3
 MSRVTT_jsfusion_test/t2v_metrics/R5: 56.9
 MSRVTT_jsfusion_test/t2v_metrics/R10: 69.9
 MSRVTT_jsfusion_test/t2v_metrics/R50: 89.2
 MSRVTT_jsfusion_test/t2v_metrics/MedR: 4.0
 MSRVTT_jsfusion_test/t2v_metrics/MeanR: 27.882
 MSRVTT_jsfusion_test/t2v_metrics/geometric_mean_R1-R5-R10: 47.117444775649716
 MSRVTT_jsfusion_test/v2t_metrics/R1: 25.8
 MSRVTT_jsfusion_test/v2t_metrics/R5: 58.9
 MSRVTT_jsfusion_test/v2t_metrics/R10: 70.9
 MSRVTT_jsfusion_test/v2t_metrics/R50: 89.6
 MSRVTT_jsfusion_test/v2t_metrics/MedR: 4.0
 MSRVTT_jsfusion_test/v2t_metrics/MeanR: 25.0725
 MSRVTT_jsfusion_test/v2t_metrics/geometric_mean_R1-R5-R10: 47.58394139700857
 mnt_best       : 47.61520475592054
 not_improved_count: 6
Train Epoch: 44 [1/250 128/32000 (0%)] Loss: 1.34408 (QuantReg: 13.86152) QuantErr: 13.86152 batch_time=95.21849 
Train Epoch: 44 [12/250 1536/32000 (5%)] Loss: 0.88283 (QuantReg: 14.08486) QuantErr: 14.08486 batch_time=0.73158 
Train Epoch: 44 [23/250 2944/32000 (9%)] Loss: 0.91011 (QuantReg: 13.95687) QuantErr: 13.95687 batch_time=0.69116 
Train Epoch: 44 [34/250 4352/32000 (14%)] Loss: 1.38256 (QuantReg: 13.81238) QuantErr: 13.81238 batch_time=0.71114 
Train Epoch: 44 [45/250 5760/32000 (18%)] Loss: 1.28707 (QuantReg: 13.84793) QuantErr: 13.84793 batch_time=0.75058 
Train Epoch: 44 [56/250 7168/32000 (22%)] Loss: 1.10743 (QuantReg: 13.65567) QuantErr: 13.65567 batch_time=0.66248 
Train Epoch: 44 [67/250 8576/32000 (27%)] Loss: 0.87976 (QuantReg: 14.09558) QuantErr: 14.09558 batch_time=0.71745 
Train Epoch: 44 [78/250 9984/32000 (31%)] Loss: 1.05659 (QuantReg: 14.07809) QuantErr: 14.07809 batch_time=0.74391 
Train Epoch: 44 [89/250 11392/32000 (36%)] Loss: 0.78289 (QuantReg: 13.88394) QuantErr: 13.88394 batch_time=0.73743 
Train Epoch: 44 [100/250 12800/32000 (40%)] Loss: 0.86013 (QuantReg: 13.91792) QuantErr: 13.91792 batch_time=0.69945 
Train Epoch: 44 [111/250 14208/32000 (44%)] Loss: 1.29508 (QuantReg: 13.54734) QuantErr: 13.54734 batch_time=0.76443 
Train Epoch: 44 [122/250 15616/32000 (49%)] Loss: 0.76427 (QuantReg: 14.15076) QuantErr: 14.15076 batch_time=0.67570 
Train Epoch: 44 [133/250 17024/32000 (53%)] Loss: 0.68313 (QuantReg: 14.09212) QuantErr: 14.09212 batch_time=0.65875 
Train Epoch: 44 [144/250 18432/32000 (58%)] Loss: 0.89343 (QuantReg: 14.08178) QuantErr: 14.08178 batch_time=0.78372 
Train Epoch: 44 [155/250 19840/32000 (62%)] Loss: 1.08764 (QuantReg: 13.85272) QuantErr: 13.85272 batch_time=0.68847 
Train Epoch: 44 [166/250 21248/32000 (66%)] Loss: 1.33958 (QuantReg: 13.90996) QuantErr: 13.90996 batch_time=0.72173 
Train Epoch: 44 [177/250 22656/32000 (71%)] Loss: 0.66917 (QuantReg: 14.12007) QuantErr: 14.12007 batch_time=0.68835 
Train Epoch: 44 [188/250 24064/32000 (75%)] Loss: 1.05278 (QuantReg: 13.71974) QuantErr: 13.71974 batch_time=0.74720 
Train Epoch: 44 [199/250 25472/32000 (80%)] Loss: 0.84248 (QuantReg: 14.14591) QuantErr: 14.14591 batch_time=0.87209 
Train Epoch: 44 [210/250 26880/32000 (84%)] Loss: 0.74638 (QuantReg: 14.21807) QuantErr: 14.21807 batch_time=0.66216 
Train Epoch: 44 [221/250 28288/32000 (88%)] Loss: 0.83529 (QuantReg: 14.06933) QuantErr: 14.06933 batch_time=0.70776 
Train Epoch: 44 [232/250 29696/32000 (93%)] Loss: 0.92980 (QuantReg: 14.13589) QuantErr: 14.13589 batch_time=0.76200 
Train Epoch: 44 [243/250 31104/32000 (97%)] Loss: 1.09395 (QuantReg: 13.88142) QuantErr: 13.88142 batch_time=0.71744 
Train Epoch: 44 codebook_update_time=1.92360
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_MSRVTT_1kA_bert-large/checkpoint-epoch44.pth ...
Done in 13.781s
Updating 'best' checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_MSRVTT_1kA_bert-large/checkpoint-epoch44.pth ...
Done in 27.016s
removing stale ckpt [epoch 43] [took 0.09s]
 epoch          : 44
 loss           : 0.9711536018848419
 quant_reg      : 13.96806685256958
 quant_err      : 13.96806685256958
 learning_rate  : 5.5091555117502635e-06
 n_samples      : 1408000
 n_steps        : 11000
 MSRVTT_jsfusion_test/t2v_metrics/R1: 27.4
 MSRVTT_jsfusion_test/t2v_metrics/R5: 57.7
 MSRVTT_jsfusion_test/t2v_metrics/R10: 70.7
 MSRVTT_jsfusion_test/t2v_metrics/R50: 89.6
 MSRVTT_jsfusion_test/t2v_metrics/MedR: 4.0
 MSRVTT_jsfusion_test/t2v_metrics/MeanR: 27.091
 MSRVTT_jsfusion_test/t2v_metrics/geometric_mean_R1-R5-R10: 48.17058603792577
 MSRVTT_jsfusion_test/v2t_metrics/R1: 26.2
 MSRVTT_jsfusion_test/v2t_metrics/R5: 59.0
 MSRVTT_jsfusion_test/v2t_metrics/R10: 71.8
 MSRVTT_jsfusion_test/v2t_metrics/R50: 89.5
 MSRVTT_jsfusion_test/v2t_metrics/MedR: 4.0
 MSRVTT_jsfusion_test/v2t_metrics/MeanR: 25.4725
 MSRVTT_jsfusion_test/v2t_metrics/geometric_mean_R1-R5-R10: 48.05728692620955
 mnt_best       : 48.17058603792577
 not_improved_count: 0
Train Epoch: 45 [1/250 128/32000 (0%)] Loss: 0.90358 (QuantReg: 13.88485) QuantErr: 13.88485 batch_time=108.01372 
Train Epoch: 45 [12/250 1536/32000 (5%)] Loss: 0.98486 (QuantReg: 13.83738) QuantErr: 13.83738 batch_time=0.70081 
Train Epoch: 45 [23/250 2944/32000 (9%)] Loss: 1.00428 (QuantReg: 13.71619) QuantErr: 13.71619 batch_time=7.98074 
Train Epoch: 45 [34/250 4352/32000 (14%)] Loss: 0.95971 (QuantReg: 14.14786) QuantErr: 14.14786 batch_time=0.67404 
Train Epoch: 45 [45/250 5760/32000 (18%)] Loss: 0.93336 (QuantReg: 13.89814) QuantErr: 13.89814 batch_time=0.69185 
Train Epoch: 45 [56/250 7168/32000 (22%)] Loss: 0.90103 (QuantReg: 14.03793) QuantErr: 14.03793 batch_time=0.76147 
Train Epoch: 45 [67/250 8576/32000 (27%)] Loss: 0.99255 (QuantReg: 14.10246) QuantErr: 14.10246 batch_time=0.67491 
Train Epoch: 45 [78/250 9984/32000 (31%)] Loss: 1.16318 (QuantReg: 13.96307) QuantErr: 13.96307 batch_time=0.76366 
Train Epoch: 45 [89/250 11392/32000 (36%)] Loss: 0.95160 (QuantReg: 13.74000) QuantErr: 13.74000 batch_time=0.69148 
Train Epoch: 45 [100/250 12800/32000 (40%)] Loss: 1.07495 (QuantReg: 14.03502) QuantErr: 14.03502 batch_time=0.73319 
Train Epoch: 45 [111/250 14208/32000 (44%)] Loss: 1.07835 (QuantReg: 13.98188) QuantErr: 13.98188 batch_time=0.72310 
Train Epoch: 45 [122/250 15616/32000 (49%)] Loss: 0.92313 (QuantReg: 13.72753) QuantErr: 13.72753 batch_time=0.70517 
Train Epoch: 45 [133/250 17024/32000 (53%)] Loss: 0.67917 (QuantReg: 13.85272) QuantErr: 13.85272 batch_time=0.79648 
Train Epoch: 45 [144/250 18432/32000 (58%)] Loss: 1.07920 (QuantReg: 14.04021) QuantErr: 14.04021 batch_time=0.70703 
Train Epoch: 45 [155/250 19840/32000 (62%)] Loss: 1.13150 (QuantReg: 14.05319) QuantErr: 14.05319 batch_time=0.68528 
Train Epoch: 45 [166/250 21248/32000 (66%)] Loss: 0.98220 (QuantReg: 13.94194) QuantErr: 13.94194 batch_time=0.91229 
Train Epoch: 45 [177/250 22656/32000 (71%)] Loss: 1.26992 (QuantReg: 14.03893) QuantErr: 14.03893 batch_time=0.77030 
Train Epoch: 45 [188/250 24064/32000 (75%)] Loss: 0.92503 (QuantReg: 13.68501) QuantErr: 13.68501 batch_time=0.70350 
Train Epoch: 45 [199/250 25472/32000 (80%)] Loss: 0.97646 (QuantReg: 14.24815) QuantErr: 14.24815 batch_time=0.70530 
Train Epoch: 45 [210/250 26880/32000 (84%)] Loss: 0.86205 (QuantReg: 14.19761) QuantErr: 14.19761 batch_time=0.74519 
Train Epoch: 45 [221/250 28288/32000 (88%)] Loss: 1.06444 (QuantReg: 14.14614) QuantErr: 14.14614 batch_time=0.76186 
Train Epoch: 45 [232/250 29696/32000 (93%)] Loss: 1.19866 (QuantReg: 14.02179) QuantErr: 14.02179 batch_time=0.70895 
Train Epoch: 45 [243/250 31104/32000 (97%)] Loss: 0.76835 (QuantReg: 13.90361) QuantErr: 13.90361 batch_time=0.70522 
Train Epoch: 45 codebook_update_time=1.79512
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_MSRVTT_1kA_bert-large/checkpoint-epoch45.pth ...
Done in 13.566s
removing stale ckpt [epoch 44] [took 0.08s]
 epoch          : 45
 loss           : 0.9718270838260651
 quant_reg      : 13.971915065765382
 quant_err      : 13.971915065765382
 learning_rate  : 5.23369773616275e-06
 n_samples      : 1440000
 n_steps        : 11250
 MSRVTT_jsfusion_test/t2v_metrics/R1: 26.6
 MSRVTT_jsfusion_test/t2v_metrics/R5: 57.3
 MSRVTT_jsfusion_test/t2v_metrics/R10: 70.2
 MSRVTT_jsfusion_test/t2v_metrics/R50: 88.9
 MSRVTT_jsfusion_test/t2v_metrics/MedR: 4.0
 MSRVTT_jsfusion_test/t2v_metrics/MeanR: 28.003
 MSRVTT_jsfusion_test/t2v_metrics/geometric_mean_R1-R5-R10: 47.47421477703692
 MSRVTT_jsfusion_test/v2t_metrics/R1: 25.3
 MSRVTT_jsfusion_test/v2t_metrics/R5: 58.3
 MSRVTT_jsfusion_test/v2t_metrics/R10: 71.2
 MSRVTT_jsfusion_test/v2t_metrics/R50: 89.1
 MSRVTT_jsfusion_test/v2t_metrics/MedR: 4.0
 MSRVTT_jsfusion_test/v2t_metrics/MeanR: 25.207
 MSRVTT_jsfusion_test/v2t_metrics/geometric_mean_R1-R5-R10: 47.179828352698195
 mnt_best       : 48.17058603792577
 not_improved_count: 1
Train Epoch: 46 [1/250 128/32000 (0%)] Loss: 0.90185 (QuantReg: 13.89165) QuantErr: 13.89165 batch_time=106.61270 
Train Epoch: 46 [12/250 1536/32000 (5%)] Loss: 1.10753 (QuantReg: 13.88484) QuantErr: 13.88484 batch_time=7.53753 
Train Epoch: 46 [23/250 2944/32000 (9%)] Loss: 0.80849 (QuantReg: 13.97014) QuantErr: 13.97014 batch_time=2.03172 
Train Epoch: 46 [34/250 4352/32000 (14%)] Loss: 0.98681 (QuantReg: 14.08907) QuantErr: 14.08907 batch_time=0.70793 
Train Epoch: 46 [45/250 5760/32000 (18%)] Loss: 0.80207 (QuantReg: 13.96711) QuantErr: 13.96711 batch_time=0.68670 
Train Epoch: 46 [56/250 7168/32000 (22%)] Loss: 0.89081 (QuantReg: 13.78883) QuantErr: 13.78883 batch_time=0.69993 
Train Epoch: 46 [67/250 8576/32000 (27%)] Loss: 0.69205 (QuantReg: 14.14224) QuantErr: 14.14224 batch_time=0.75701 
Train Epoch: 46 [78/250 9984/32000 (31%)] Loss: 0.85508 (QuantReg: 14.12743) QuantErr: 14.12743 batch_time=0.68886 
Train Epoch: 46 [89/250 11392/32000 (36%)] Loss: 1.21898 (QuantReg: 13.89846) QuantErr: 13.89846 batch_time=0.68015 
Train Epoch: 46 [100/250 12800/32000 (40%)] Loss: 1.08009 (QuantReg: 13.88916) QuantErr: 13.88916 batch_time=0.67710 
Train Epoch: 46 [111/250 14208/32000 (44%)] Loss: 0.89085 (QuantReg: 13.71026) QuantErr: 13.71026 batch_time=0.69548 
Train Epoch: 46 [122/250 15616/32000 (49%)] Loss: 0.78229 (QuantReg: 14.05826) QuantErr: 14.05826 batch_time=0.72730 
Train Epoch: 46 [133/250 17024/32000 (53%)] Loss: 0.88696 (QuantReg: 14.16670) QuantErr: 14.16670 batch_time=6.00881 
Train Epoch: 46 [144/250 18432/32000 (58%)] Loss: 1.11428 (QuantReg: 14.29751) QuantErr: 14.29751 batch_time=0.77543 
Train Epoch: 46 [155/250 19840/32000 (62%)] Loss: 0.81078 (QuantReg: 14.07314) QuantErr: 14.07314 batch_time=22.56669 
Train Epoch: 46 [166/250 21248/32000 (66%)] Loss: 0.98724 (QuantReg: 13.83019) QuantErr: 13.83019 batch_time=0.68264 
Train Epoch: 46 [177/250 22656/32000 (71%)] Loss: 0.88943 (QuantReg: 14.00807) QuantErr: 14.00807 batch_time=0.66673 
Train Epoch: 46 [188/250 24064/32000 (75%)] Loss: 0.99069 (QuantReg: 14.09088) QuantErr: 14.09088 batch_time=0.71885 
Train Epoch: 46 [199/250 25472/32000 (80%)] Loss: 1.01407 (QuantReg: 13.91304) QuantErr: 13.91304 batch_time=0.76024 
Train Epoch: 46 [210/250 26880/32000 (84%)] Loss: 1.12000 (QuantReg: 14.15604) QuantErr: 14.15604 batch_time=0.70979 
Train Epoch: 46 [221/250 28288/32000 (88%)] Loss: 0.80376 (QuantReg: 14.14485) QuantErr: 14.14485 batch_time=0.69984 
Train Epoch: 46 [232/250 29696/32000 (93%)] Loss: 0.94845 (QuantReg: 14.14416) QuantErr: 14.14416 batch_time=0.81297 
Train Epoch: 46 [243/250 31104/32000 (97%)] Loss: 0.71843 (QuantReg: 14.46276) QuantErr: 14.46276 batch_time=0.75441 
Train Epoch: 46 codebook_update_time=1.80000
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_MSRVTT_1kA_bert-large/checkpoint-epoch46.pth ...
Done in 12.596s
removing stale ckpt [epoch 45] [took 0.16s]
 epoch          : 46
 loss           : 0.9590402460098266
 quant_reg      : 14.005498851776123
 quant_err      : 14.005498851776123
 learning_rate  : 4.972012849354612e-06
 n_samples      : 1472000
 n_steps        : 11500
 MSRVTT_jsfusion_test/t2v_metrics/R1: 26.8
 MSRVTT_jsfusion_test/t2v_metrics/R5: 56.2
 MSRVTT_jsfusion_test/t2v_metrics/R10: 69.1
 MSRVTT_jsfusion_test/t2v_metrics/R50: 88.8
 MSRVTT_jsfusion_test/t2v_metrics/MedR: 4.0
 MSRVTT_jsfusion_test/t2v_metrics/MeanR: 28.493
 MSRVTT_jsfusion_test/t2v_metrics/geometric_mean_R1-R5-R10: 47.03809436069015
 MSRVTT_jsfusion_test/v2t_metrics/R1: 26.0
 MSRVTT_jsfusion_test/v2t_metrics/R5: 57.4
 MSRVTT_jsfusion_test/v2t_metrics/R10: 71.1
 MSRVTT_jsfusion_test/v2t_metrics/R50: 89.6
 MSRVTT_jsfusion_test/v2t_metrics/MedR: 4.0
 MSRVTT_jsfusion_test/v2t_metrics/MeanR: 25.515
 MSRVTT_jsfusion_test/v2t_metrics/geometric_mean_R1-R5-R10: 47.34254642236492
 mnt_best       : 48.17058603792577
 not_improved_count: 2
Train Epoch: 47 [1/250 128/32000 (0%)] Loss: 0.86029 (QuantReg: 14.24762) QuantErr: 14.24762 batch_time=102.64331 
Train Epoch: 47 [12/250 1536/32000 (5%)] Loss: 1.45065 (QuantReg: 14.03856) QuantErr: 14.03856 batch_time=11.71666 
Train Epoch: 47 [23/250 2944/32000 (9%)] Loss: 0.91295 (QuantReg: 14.26167) QuantErr: 14.26167 batch_time=0.75720 
Train Epoch: 47 [34/250 4352/32000 (14%)] Loss: 1.05087 (QuantReg: 13.71083) QuantErr: 13.71083 batch_time=0.71468 
Train Epoch: 47 [45/250 5760/32000 (18%)] Loss: 0.88636 (QuantReg: 13.88175) QuantErr: 13.88175 batch_time=0.67202 
Train Epoch: 47 [56/250 7168/32000 (22%)] Loss: 0.82407 (QuantReg: 14.07756) QuantErr: 14.07756 batch_time=0.70097 
Train Epoch: 47 [67/250 8576/32000 (27%)] Loss: 1.01429 (QuantReg: 14.14569) QuantErr: 14.14569 batch_time=0.75516 
Train Epoch: 47 [78/250 9984/32000 (31%)] Loss: 0.76211 (QuantReg: 14.14382) QuantErr: 14.14382 batch_time=0.70720 
Train Epoch: 47 [89/250 11392/32000 (36%)] Loss: 0.90255 (QuantReg: 14.26046) QuantErr: 14.26046 batch_time=0.73529 
Train Epoch: 47 [100/250 12800/32000 (40%)] Loss: 0.79766 (QuantReg: 14.20385) QuantErr: 14.20385 batch_time=0.70629 
Train Epoch: 47 [111/250 14208/32000 (44%)] Loss: 1.02498 (QuantReg: 13.87064) QuantErr: 13.87064 batch_time=0.71947 
Train Epoch: 47 [122/250 15616/32000 (49%)] Loss: 0.88552 (QuantReg: 14.20209) QuantErr: 14.20209 batch_time=0.70729 
Train Epoch: 47 [133/250 17024/32000 (53%)] Loss: 0.91964 (QuantReg: 13.92244) QuantErr: 13.92244 batch_time=0.67988 
Train Epoch: 47 [144/250 18432/32000 (58%)] Loss: 0.77975 (QuantReg: 14.04681) QuantErr: 14.04681 batch_time=0.68817 
Train Epoch: 47 [155/250 19840/32000 (62%)] Loss: 1.15507 (QuantReg: 14.02180) QuantErr: 14.02180 batch_time=21.84348 
Train Epoch: 47 [166/250 21248/32000 (66%)] Loss: 1.16635 (QuantReg: 13.99487) QuantErr: 13.99487 batch_time=0.72378 
Train Epoch: 47 [177/250 22656/32000 (71%)] Loss: 1.01198 (QuantReg: 13.92339) QuantErr: 13.92339 batch_time=0.68060 
Train Epoch: 47 [188/250 24064/32000 (75%)] Loss: 0.87862 (QuantReg: 14.10984) QuantErr: 14.10984 batch_time=0.67986 
Train Epoch: 47 [199/250 25472/32000 (80%)] Loss: 0.78526 (QuantReg: 14.05781) QuantErr: 14.05781 batch_time=6.85882 
Train Epoch: 47 [210/250 26880/32000 (84%)] Loss: 1.06584 (QuantReg: 14.27131) QuantErr: 14.27131 batch_time=0.75631 
Train Epoch: 47 [221/250 28288/32000 (88%)] Loss: 0.88704 (QuantReg: 13.87023) QuantErr: 13.87023 batch_time=0.74519 
Train Epoch: 47 [232/250 29696/32000 (93%)] Loss: 1.12389 (QuantReg: 13.83586) QuantErr: 13.83586 batch_time=0.67740 
Train Epoch: 47 [243/250 31104/32000 (97%)] Loss: 0.88858 (QuantReg: 13.95788) QuantErr: 13.95788 batch_time=0.70616 
Train Epoch: 47 codebook_update_time=2.18639
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_MSRVTT_1kA_bert-large/checkpoint-epoch47.pth ...
Done in 31.106s
removing stale ckpt [epoch 46] [took 0.17s]
 epoch          : 47
 loss           : 0.9500358226299286
 quant_reg      : 14.028483985900879
 quant_err      : 14.028483985900879
 learning_rate  : 4.723412206886882e-06
 n_samples      : 1504000
 n_steps        : 11750
 MSRVTT_jsfusion_test/t2v_metrics/R1: 27.3
 MSRVTT_jsfusion_test/t2v_metrics/R5: 56.0
 MSRVTT_jsfusion_test/t2v_metrics/R10: 69.7
 MSRVTT_jsfusion_test/t2v_metrics/R50: 89.0
 MSRVTT_jsfusion_test/t2v_metrics/MedR: 4.0
 MSRVTT_jsfusion_test/t2v_metrics/MeanR: 27.558
 MSRVTT_jsfusion_test/t2v_metrics/geometric_mean_R1-R5-R10: 47.409038850226686
 MSRVTT_jsfusion_test/v2t_metrics/R1: 25.7
 MSRVTT_jsfusion_test/v2t_metrics/R5: 57.8
 MSRVTT_jsfusion_test/v2t_metrics/R10: 72.1
 MSRVTT_jsfusion_test/v2t_metrics/R50: 89.8
 MSRVTT_jsfusion_test/v2t_metrics/MedR: 4.0
 MSRVTT_jsfusion_test/v2t_metrics/MeanR: 25.9305
 MSRVTT_jsfusion_test/v2t_metrics/geometric_mean_R1-R5-R10: 47.489625213364135
 mnt_best       : 48.17058603792577
 not_improved_count: 3
Train Epoch: 48 [1/250 128/32000 (0%)] Loss: 1.11924 (QuantReg: 13.95990) QuantErr: 13.95990 batch_time=125.29471 
Train Epoch: 48 [12/250 1536/32000 (5%)] Loss: 0.94028 (QuantReg: 14.07362) QuantErr: 14.07362 batch_time=0.80485 
Train Epoch: 48 [23/250 2944/32000 (9%)] Loss: 0.95873 (QuantReg: 14.04826) QuantErr: 14.04826 batch_time=0.73022 
Train Epoch: 48 [34/250 4352/32000 (14%)] Loss: 1.09639 (QuantReg: 13.74574) QuantErr: 13.74574 batch_time=0.68482 
Train Epoch: 48 [45/250 5760/32000 (18%)] Loss: 1.25277 (QuantReg: 13.99598) QuantErr: 13.99598 batch_time=0.76067 
Train Epoch: 48 [56/250 7168/32000 (22%)] Loss: 0.77019 (QuantReg: 14.27126) QuantErr: 14.27126 batch_time=0.73333 
Train Epoch: 48 [67/250 8576/32000 (27%)] Loss: 0.85390 (QuantReg: 13.90570) QuantErr: 13.90570 batch_time=0.69006 
Train Epoch: 48 [78/250 9984/32000 (31%)] Loss: 0.89201 (QuantReg: 13.99865) QuantErr: 13.99865 batch_time=0.68683 
Train Epoch: 48 [89/250 11392/32000 (36%)] Loss: 1.21675 (QuantReg: 14.05338) QuantErr: 14.05338 batch_time=0.69215 
Train Epoch: 48 [100/250 12800/32000 (40%)] Loss: 1.03462 (QuantReg: 13.93014) QuantErr: 13.93014 batch_time=0.73446 
Train Epoch: 48 [111/250 14208/32000 (44%)] Loss: 1.13939 (QuantReg: 13.82643) QuantErr: 13.82643 batch_time=0.70286 
Train Epoch: 48 [122/250 15616/32000 (49%)] Loss: 0.97761 (QuantReg: 13.93661) QuantErr: 13.93661 batch_time=0.70434 
Train Epoch: 48 [133/250 17024/32000 (53%)] Loss: 0.86799 (QuantReg: 14.23151) QuantErr: 14.23151 batch_time=0.71538 
Train Epoch: 48 [144/250 18432/32000 (58%)] Loss: 0.93999 (QuantReg: 14.25101) QuantErr: 14.25101 batch_time=0.72865 
Train Epoch: 48 [155/250 19840/32000 (62%)] Loss: 0.91512 (QuantReg: 14.06340) QuantErr: 14.06340 batch_time=0.66011 
Train Epoch: 48 [166/250 21248/32000 (66%)] Loss: 0.97314 (QuantReg: 14.05924) QuantErr: 14.05924 batch_time=0.70032 
Train Epoch: 48 [177/250 22656/32000 (71%)] Loss: 1.06319 (QuantReg: 14.03963) QuantErr: 14.03963 batch_time=0.77024 
Train Epoch: 48 [188/250 24064/32000 (75%)] Loss: 0.83730 (QuantReg: 14.09767) QuantErr: 14.09767 batch_time=0.66278 
Train Epoch: 48 [199/250 25472/32000 (80%)] Loss: 0.77885 (QuantReg: 14.44821) QuantErr: 14.44821 batch_time=0.72301 
Train Epoch: 48 [210/250 26880/32000 (84%)] Loss: 0.94932 (QuantReg: 14.03871) QuantErr: 14.03871 batch_time=0.71715 
Train Epoch: 48 [221/250 28288/32000 (88%)] Loss: 1.05943 (QuantReg: 14.12620) QuantErr: 14.12620 batch_time=0.84996 
Train Epoch: 48 [232/250 29696/32000 (93%)] Loss: 0.84243 (QuantReg: 14.09812) QuantErr: 14.09812 batch_time=0.71308 
Train Epoch: 48 [243/250 31104/32000 (97%)] Loss: 0.82285 (QuantReg: 14.28542) QuantErr: 14.28542 batch_time=0.68724 
Train Epoch: 48 codebook_update_time=2.37403
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_MSRVTT_1kA_bert-large/checkpoint-epoch48.pth ...
Done in 13.049s
removing stale ckpt [epoch 47] [took 0.38s]
 epoch          : 48
 loss           : 0.96636505818367
 quant_reg      : 14.029514415740966
 quant_err      : 14.029514415740966
 learning_rate  : 4.487241596542537e-06
 n_samples      : 1536000
 n_steps        : 12000
 MSRVTT_jsfusion_test/t2v_metrics/R1: 26.4
 MSRVTT_jsfusion_test/t2v_metrics/R5: 57.0
 MSRVTT_jsfusion_test/t2v_metrics/R10: 69.4
 MSRVTT_jsfusion_test/t2v_metrics/R50: 88.9
 MSRVTT_jsfusion_test/t2v_metrics/MedR: 4.0
 MSRVTT_jsfusion_test/t2v_metrics/MeanR: 27.826
 MSRVTT_jsfusion_test/t2v_metrics/geometric_mean_R1-R5-R10: 47.09188603517043
 MSRVTT_jsfusion_test/v2t_metrics/R1: 26.5
 MSRVTT_jsfusion_test/v2t_metrics/R5: 57.8
 MSRVTT_jsfusion_test/v2t_metrics/R10: 71.6
 MSRVTT_jsfusion_test/v2t_metrics/R50: 90.4
 MSRVTT_jsfusion_test/v2t_metrics/MedR: 4.0
 MSRVTT_jsfusion_test/v2t_metrics/MeanR: 25.7025
 MSRVTT_jsfusion_test/v2t_metrics/geometric_mean_R1-R5-R10: 47.86619564182262
 mnt_best       : 48.17058603792577
 not_improved_count: 4
Train Epoch: 49 [1/250 128/32000 (0%)] Loss: 0.79605 (QuantReg: 13.94644) QuantErr: 13.94644 batch_time=97.15682 
Train Epoch: 49 [12/250 1536/32000 (5%)] Loss: 1.11863 (QuantReg: 13.62215) QuantErr: 13.62215 batch_time=5.69291 
Train Epoch: 49 [23/250 2944/32000 (9%)] Loss: 0.83679 (QuantReg: 13.68484) QuantErr: 13.68484 batch_time=0.72515 
Train Epoch: 49 [34/250 4352/32000 (14%)] Loss: 1.13097 (QuantReg: 14.15494) QuantErr: 14.15494 batch_time=0.73840 
Train Epoch: 49 [45/250 5760/32000 (18%)] Loss: 0.94753 (QuantReg: 13.95661) QuantErr: 13.95661 batch_time=0.74468 
Train Epoch: 49 [56/250 7168/32000 (22%)] Loss: 1.09391 (QuantReg: 14.02469) QuantErr: 14.02469 batch_time=0.69876 
Train Epoch: 49 [67/250 8576/32000 (27%)] Loss: 0.86720 (QuantReg: 14.09330) QuantErr: 14.09330 batch_time=3.12532 
Train Epoch: 49 [78/250 9984/32000 (31%)] Loss: 1.20145 (QuantReg: 13.90664) QuantErr: 13.90664 batch_time=0.70190 
Train Epoch: 49 [89/250 11392/32000 (36%)] Loss: 1.02042 (QuantReg: 14.20771) QuantErr: 14.20771 batch_time=0.69385 
Train Epoch: 49 [100/250 12800/32000 (40%)] Loss: 0.94559 (QuantReg: 13.96836) QuantErr: 13.96836 batch_time=1.47768 
Train Epoch: 49 [111/250 14208/32000 (44%)] Loss: 0.85969 (QuantReg: 13.93754) QuantErr: 13.93754 batch_time=0.72583 
Train Epoch: 49 [122/250 15616/32000 (49%)] Loss: 0.96214 (QuantReg: 14.20389) QuantErr: 14.20389 batch_time=0.66334 
Train Epoch: 49 [133/250 17024/32000 (53%)] Loss: 0.90030 (QuantReg: 14.28379) QuantErr: 14.28379 batch_time=0.68164 
Train Epoch: 49 [144/250 18432/32000 (58%)] Loss: 0.91367 (QuantReg: 14.36470) QuantErr: 14.36470 batch_time=0.72462 
Train Epoch: 49 [155/250 19840/32000 (62%)] Loss: 1.39475 (QuantReg: 14.06708) QuantErr: 14.06708 batch_time=0.72320 
Train Epoch: 49 [166/250 21248/32000 (66%)] Loss: 0.98490 (QuantReg: 13.82999) QuantErr: 13.82999 batch_time=0.70643 
Train Epoch: 49 [177/250 22656/32000 (71%)] Loss: 0.99639 (QuantReg: 13.89810) QuantErr: 13.89810 batch_time=0.66724 
Train Epoch: 49 [188/250 24064/32000 (75%)] Loss: 0.89926 (QuantReg: 14.31041) QuantErr: 14.31041 batch_time=0.87782 
Train Epoch: 49 [199/250 25472/32000 (80%)] Loss: 1.04208 (QuantReg: 14.14790) QuantErr: 14.14790 batch_time=0.67064 
Train Epoch: 49 [210/250 26880/32000 (84%)] Loss: 1.15860 (QuantReg: 13.96289) QuantErr: 13.96289 batch_time=0.71462 
Train Epoch: 49 [221/250 28288/32000 (88%)] Loss: 1.03629 (QuantReg: 14.18438) QuantErr: 14.18438 batch_time=0.71680 
Train Epoch: 49 [232/250 29696/32000 (93%)] Loss: 1.03191 (QuantReg: 14.19559) QuantErr: 14.19559 batch_time=0.67482 
Train Epoch: 49 [243/250 31104/32000 (97%)] Loss: 1.00869 (QuantReg: 13.89867) QuantErr: 13.89867 batch_time=0.82506 
Train Epoch: 49 codebook_update_time=1.87146
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_MSRVTT_1kA_bert-large/checkpoint-epoch49.pth ...
Done in 16.440s
removing stale ckpt [epoch 48] [took 0.25s]
 epoch          : 49
 loss           : 0.9863263640403748
 quant_reg      : 14.049096138000488
 quant_err      : 14.049096138000488
 learning_rate  : 4.26287951671541e-06
 n_samples      : 1568000
 n_steps        : 12250
 MSRVTT_jsfusion_test/t2v_metrics/R1: 26.5
 MSRVTT_jsfusion_test/t2v_metrics/R5: 57.4
 MSRVTT_jsfusion_test/t2v_metrics/R10: 70.1
 MSRVTT_jsfusion_test/t2v_metrics/R50: 88.6
 MSRVTT_jsfusion_test/t2v_metrics/MedR: 4.0
 MSRVTT_jsfusion_test/t2v_metrics/MeanR: 28.06
 MSRVTT_jsfusion_test/t2v_metrics/geometric_mean_R1-R5-R10: 47.41967736247469
 MSRVTT_jsfusion_test/v2t_metrics/R1: 26.1
 MSRVTT_jsfusion_test/v2t_metrics/R5: 57.4
 MSRVTT_jsfusion_test/v2t_metrics/R10: 71.4
 MSRVTT_jsfusion_test/v2t_metrics/R50: 90.1
 MSRVTT_jsfusion_test/v2t_metrics/MedR: 4.0
 MSRVTT_jsfusion_test/v2t_metrics/MeanR: 25.752
 MSRVTT_jsfusion_test/v2t_metrics/geometric_mean_R1-R5-R10: 47.469741911217284
 mnt_best       : 48.17058603792577
 not_improved_count: 5
Train Epoch: 50 [1/250 128/32000 (0%)] Loss: 0.82991 (QuantReg: 13.97725) QuantErr: 13.97725 batch_time=98.62902 
Train Epoch: 50 [12/250 1536/32000 (5%)] Loss: 0.83231 (QuantReg: 13.95874) QuantErr: 13.95874 batch_time=0.73015 
Train Epoch: 50 [23/250 2944/32000 (9%)] Loss: 1.02977 (QuantReg: 14.18879) QuantErr: 14.18879 batch_time=0.71217 
Train Epoch: 50 [34/250 4352/32000 (14%)] Loss: 0.95339 (QuantReg: 14.11237) QuantErr: 14.11237 batch_time=0.74834 
Train Epoch: 50 [45/250 5760/32000 (18%)] Loss: 0.77592 (QuantReg: 14.31414) QuantErr: 14.31414 batch_time=0.66217 
Train Epoch: 50 [56/250 7168/32000 (22%)] Loss: 1.10482 (QuantReg: 13.88667) QuantErr: 13.88667 batch_time=0.69192 
Train Epoch: 50 [67/250 8576/32000 (27%)] Loss: 0.97236 (QuantReg: 14.33586) QuantErr: 14.33586 batch_time=0.73587 
Train Epoch: 50 [78/250 9984/32000 (31%)] Loss: 0.91618 (QuantReg: 14.09467) QuantErr: 14.09467 batch_time=1.01241 
Train Epoch: 50 [89/250 11392/32000 (36%)] Loss: 1.23613 (QuantReg: 13.89550) QuantErr: 13.89550 batch_time=5.04492 
Train Epoch: 50 [100/250 12800/32000 (40%)] Loss: 0.79010 (QuantReg: 14.11718) QuantErr: 14.11718 batch_time=0.75530 
Train Epoch: 50 [111/250 14208/32000 (44%)] Loss: 0.96826 (QuantReg: 13.93453) QuantErr: 13.93453 batch_time=0.77508 
Train Epoch: 50 [122/250 15616/32000 (49%)] Loss: 1.03696 (QuantReg: 13.95231) QuantErr: 13.95231 batch_time=0.70120 
Train Epoch: 50 [133/250 17024/32000 (53%)] Loss: 1.01568 (QuantReg: 14.12597) QuantErr: 14.12597 batch_time=0.81083 
Train Epoch: 50 [144/250 18432/32000 (58%)] Loss: 0.85288 (QuantReg: 14.14799) QuantErr: 14.14799 batch_time=0.70389 
Train Epoch: 50 [155/250 19840/32000 (62%)] Loss: 0.95462 (QuantReg: 14.18629) QuantErr: 14.18629 batch_time=0.90214 
Train Epoch: 50 [166/250 21248/32000 (66%)] Loss: 0.83509 (QuantReg: 13.99805) QuantErr: 13.99805 batch_time=0.67693 
Train Epoch: 50 [177/250 22656/32000 (71%)] Loss: 0.83996 (QuantReg: 14.27477) QuantErr: 14.27477 batch_time=0.70729 
Train Epoch: 50 [188/250 24064/32000 (75%)] Loss: 1.14117 (QuantReg: 14.03050) QuantErr: 14.03050 batch_time=0.68632 
Train Epoch: 50 [199/250 25472/32000 (80%)] Loss: 1.01563 (QuantReg: 14.06010) QuantErr: 14.06010 batch_time=0.69593 
Train Epoch: 50 [210/250 26880/32000 (84%)] Loss: 1.05169 (QuantReg: 13.79681) QuantErr: 13.79681 batch_time=0.73546 
Train Epoch: 50 [221/250 28288/32000 (88%)] Loss: 0.98302 (QuantReg: 14.14573) QuantErr: 14.14573 batch_time=0.75113 
Train Epoch: 50 [232/250 29696/32000 (93%)] Loss: 1.01007 (QuantReg: 13.92819) QuantErr: 13.92819 batch_time=0.85930 
Train Epoch: 50 [243/250 31104/32000 (97%)] Loss: 0.86054 (QuantReg: 14.10235) QuantErr: 14.10235 batch_time=0.68341 
Train Epoch: 50 codebook_update_time=1.81254
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_MSRVTT_1kA_bert-large/checkpoint-epoch50.pth ...
Done in 12.898s
removing stale ckpt [epoch 49] [took 0.07s]
 epoch          : 50
 loss           : 0.9754212989807128
 quant_reg      : 14.061944313049317
 quant_err      : 14.061944313049317
 learning_rate  : 4.04973554087964e-06
 n_samples      : 1600000
 n_steps        : 12500
 MSRVTT_jsfusion_test/t2v_metrics/R1: 25.9
 MSRVTT_jsfusion_test/t2v_metrics/R5: 57.6
 MSRVTT_jsfusion_test/t2v_metrics/R10: 70.3
 MSRVTT_jsfusion_test/t2v_metrics/R50: 88.5
 MSRVTT_jsfusion_test/t2v_metrics/MedR: 4.0
 MSRVTT_jsfusion_test/t2v_metrics/MeanR: 28.308
 MSRVTT_jsfusion_test/t2v_metrics/geometric_mean_R1-R5-R10: 47.158414007831624
 MSRVTT_jsfusion_test/v2t_metrics/R1: 26.9
 MSRVTT_jsfusion_test/v2t_metrics/R5: 58.4
 MSRVTT_jsfusion_test/v2t_metrics/R10: 70.2
 MSRVTT_jsfusion_test/v2t_metrics/R50: 89.3
 MSRVTT_jsfusion_test/v2t_metrics/MedR: 4.0
 MSRVTT_jsfusion_test/v2t_metrics/MeanR: 26.205
 MSRVTT_jsfusion_test/v2t_metrics/geometric_mean_R1-R5-R10: 47.95502036383924
 mnt_best       : 48.17058603792577
 not_improved_count: 6
Final evaluation ...
Loading checkpoint from: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_MSRVTT_1kA_bert-large/trained_model.pth ...
Ckpt loaded at epoch 44.
Saved similarity matrix (quantize videos) to /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_MSRVTT_1kA_bert-large/MSRVTT-test-qv-sims.npy
Saved v2t similarity matrix (quantize texts) to /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_MSRVTT_1kA_bert-large/MSRVTT-test-qt-sims.npy
MSRVTT_jsfusion_test:
 t2v_metrics/R1/final_eval: 27.4
 t2v_metrics/R5/final_eval: 57.7
 t2v_metrics/R10/final_eval: 70.7
 t2v_metrics/R50/final_eval: 89.6
 t2v_metrics/MedR/final_eval: 4.0
 t2v_metrics/MeanR/final_eval: 27.091
 t2v_metrics/geometric_mean_R1-R5-R10/final_eval: 48.17058603792577
 v2t_metrics/R1/final_eval: 26.2
 v2t_metrics/R5/final_eval: 59.0
 v2t_metrics/R10/final_eval: 71.8
 v2t_metrics/R50/final_eval: 89.5
 v2t_metrics/MedR/final_eval: 4.0
 v2t_metrics/MeanR/final_eval: 25.472
 v2t_metrics/geometric_mean_R1-R5-R10/final_eval: 48.05728692620955
Best epoch for the monitored metric: 44
Script took 08h03m48s
The best performing ckpt can be found at /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_MSRVTT_1kA_bert-large/trained_model.pth
