Experiment directory: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_ActivityNet_bs64
Preparing the dataloaders ...
Loading dataset ActivityNet_val1_trainval in ram ...
Finish loading dataset ActivityNet_val1_trainval in ram, taking 895.3150341510773 s.
Loading dataset ActivityNet_val1_test in ram ...
Finish loading dataset ActivityNet_val1_test in ram, taking 222.9132363796234 s.
Loading dataset ActivityNet_val1_test in ram ...
Finish loading dataset ActivityNet_val1_test in ram, taking 167.39756417274475 s.
Training ...
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_ActivityNet_bs64/checkpoint-epoch0.pth ...
Done in 1.241s
Updating 'best' checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_ActivityNet_bs64/checkpoint-epoch0.pth ...
Done in 2.485s
 epoch          : 0
 loss           : 0
 learning_rate  : 5e-05
 n_samples      : 0
 n_steps        : 0
 ActivityNet_val1_test/t2v_metrics/R1: 0.04067520846044336
 ActivityNet_val1_test/t2v_metrics/R5: 0.18303843807199513
 ActivityNet_val1_test/t2v_metrics/R10: 0.24405125076266015
 ActivityNet_val1_test/t2v_metrics/R50: 0.9558673988204189
 ActivityNet_val1_test/t2v_metrics/MedR: 2484.0
 ActivityNet_val1_test/t2v_metrics/MeanR: 2488.61043319097
 ActivityNet_val1_test/t2v_metrics/geometric_mean_R1-R5-R10: 0.12202562538133006
 ActivityNet_val1_test/v2t_metrics/R1: 0.04067520846044336
 ActivityNet_val1_test/v2t_metrics/R5: 0.1016880211511084
 ActivityNet_val1_test/v2t_metrics/R10: 0.22371364653243847
 ActivityNet_val1_test/v2t_metrics/R50: 0.9151921903599756
 ActivityNet_val1_test/v2t_metrics/MedR: 2511.0
 ActivityNet_val1_test/v2t_metrics/MeanR: 2492.5206426682935
 ActivityNet_val1_test/v2t_metrics/geometric_mean_R1-R5-R10: 0.09744600075376822
 mnt_best       : 0.12202562538133006
 not_improved_count: 0
Train Epoch: 1 [1/500 64/32000 (0%)] Loss: 8.45386 (QuantReg: 22.41818) QuantErr: 22.41818 batch_time=24.20000 
Train Epoch: 1 [9/500 576/32000 (2%)] Loss: 7.71489 (QuantReg: 22.50525) QuantErr: 22.50525 batch_time=1.22628 
Train Epoch: 1 [17/500 1088/32000 (3%)] Loss: 6.36542 (QuantReg: 22.57572) QuantErr: 22.57572 batch_time=0.46792 
Train Epoch: 1 [25/500 1600/32000 (5%)] Loss: 5.15219 (QuantReg: 22.64177) QuantErr: 22.64177 batch_time=0.46463 
Train Epoch: 1 [33/500 2112/32000 (7%)] Loss: 4.36890 (QuantReg: 22.63716) QuantErr: 22.63716 batch_time=0.43537 
Train Epoch: 1 [41/500 2624/32000 (8%)] Loss: 3.75129 (QuantReg: 22.65233) QuantErr: 22.65233 batch_time=0.43662 
Train Epoch: 1 [49/500 3136/32000 (10%)] Loss: 3.27377 (QuantReg: 22.71187) QuantErr: 22.71187 batch_time=0.47337 
Train Epoch: 1 [57/500 3648/32000 (11%)] Loss: 2.73272 (QuantReg: 22.64702) QuantErr: 22.64702 batch_time=0.53851 
Train Epoch: 1 [65/500 4160/32000 (13%)] Loss: 2.71565 (QuantReg: 22.67479) QuantErr: 22.67479 batch_time=0.44526 
Train Epoch: 1 [73/500 4672/32000 (15%)] Loss: 2.92645 (QuantReg: 22.68732) QuantErr: 22.68732 batch_time=0.92036 
Train Epoch: 1 [81/500 5184/32000 (16%)] Loss: 2.53191 (QuantReg: 22.67205) QuantErr: 22.67205 batch_time=0.45233 
Train Epoch: 1 [89/500 5696/32000 (18%)] Loss: 2.14129 (QuantReg: 22.66655) QuantErr: 22.66655 batch_time=0.47819 
Train Epoch: 1 [97/500 6208/32000 (19%)] Loss: 2.09651 (QuantReg: 22.66313) QuantErr: 22.66313 batch_time=0.45175 
Train Epoch: 1 [105/500 6720/32000 (21%)] Loss: 1.80867 (QuantReg: 22.66559) QuantErr: 22.66559 batch_time=0.44984 
Train Epoch: 1 [113/500 7232/32000 (23%)] Loss: 1.61312 (QuantReg: 22.69565) QuantErr: 22.69565 batch_time=0.50402 
Train Epoch: 1 [121/500 7744/32000 (24%)] Loss: 1.39946 (QuantReg: 22.67565) QuantErr: 22.67565 batch_time=0.44197 
Train Epoch: 1 [129/500 8256/32000 (26%)] Loss: 1.42428 (QuantReg: 22.72449) QuantErr: 22.72449 batch_time=0.44423 
Train Epoch: 1 [137/500 8768/32000 (27%)] Loss: 1.44395 (QuantReg: 22.66346) QuantErr: 22.66346 batch_time=0.94788 
Train Epoch: 1 [145/500 9280/32000 (29%)] Loss: 1.39153 (QuantReg: 22.69287) QuantErr: 22.69287 batch_time=0.46923 
Train Epoch: 1 [153/500 9792/32000 (31%)] Loss: 1.29976 (QuantReg: 22.68519) QuantErr: 22.68519 batch_time=0.44727 
Train Epoch: 1 [161/500 10304/32000 (32%)] Loss: 1.54687 (QuantReg: 22.71046) QuantErr: 22.71046 batch_time=0.44467 
Train Epoch: 1 [169/500 10816/32000 (34%)] Loss: 1.57149 (QuantReg: 22.65053) QuantErr: 22.65053 batch_time=0.44196 
Train Epoch: 1 [177/500 11328/32000 (35%)] Loss: 1.28318 (QuantReg: 22.65221) QuantErr: 22.65221 batch_time=0.49163 
Train Epoch: 1 [185/500 11840/32000 (37%)] Loss: 1.19069 (QuantReg: 22.67959) QuantErr: 22.67959 batch_time=0.47984 
Train Epoch: 1 [193/500 12352/32000 (39%)] Loss: 1.14025 (QuantReg: 22.65106) QuantErr: 22.65106 batch_time=0.47997 
Train Epoch: 1 [201/500 12864/32000 (40%)] Loss: 1.38853 (QuantReg: 22.64795) QuantErr: 22.64795 batch_time=0.95619 
Train Epoch: 1 [209/500 13376/32000 (42%)] Loss: 1.03770 (QuantReg: 22.66087) QuantErr: 22.66087 batch_time=0.44832 
Train Epoch: 1 [217/500 13888/32000 (43%)] Loss: 0.95553 (QuantReg: 22.65033) QuantErr: 22.65033 batch_time=0.44597 
Train Epoch: 1 [225/500 14400/32000 (45%)] Loss: 0.91056 (QuantReg: 22.69502) QuantErr: 22.69502 batch_time=0.44294 
Train Epoch: 1 [233/500 14912/32000 (47%)] Loss: 1.27543 (QuantReg: 22.67630) QuantErr: 22.67630 batch_time=0.44910 
Train Epoch: 1 [241/500 15424/32000 (48%)] Loss: 0.90810 (QuantReg: 22.62929) QuantErr: 22.62929 batch_time=0.51267 
Train Epoch: 1 [249/500 15936/32000 (50%)] Loss: 1.01608 (QuantReg: 22.67409) QuantErr: 22.67409 batch_time=0.47714 
Train Epoch: 1 [257/500 16448/32000 (51%)] Loss: 1.08295 (QuantReg: 22.68485) QuantErr: 22.68485 batch_time=0.47619 
Train Epoch: 1 [265/500 16960/32000 (53%)] Loss: 1.16952 (QuantReg: 22.65524) QuantErr: 22.65524 batch_time=0.94579 
Train Epoch: 1 [273/500 17472/32000 (55%)] Loss: 1.09255 (QuantReg: 22.66187) QuantErr: 22.66187 batch_time=0.44680 
Train Epoch: 1 [281/500 17984/32000 (56%)] Loss: 0.87580 (QuantReg: 22.66628) QuantErr: 22.66628 batch_time=0.44653 
Train Epoch: 1 [289/500 18496/32000 (58%)] Loss: 1.10960 (QuantReg: 22.61569) QuantErr: 22.61569 batch_time=0.44757 
Train Epoch: 1 [297/500 19008/32000 (59%)] Loss: 0.82078 (QuantReg: 22.66670) QuantErr: 22.66670 batch_time=0.44624 
Train Epoch: 1 [305/500 19520/32000 (61%)] Loss: 1.00503 (QuantReg: 22.67703) QuantErr: 22.67703 batch_time=0.47807 
Train Epoch: 1 [313/500 20032/32000 (63%)] Loss: 0.78355 (QuantReg: 22.67794) QuantErr: 22.67794 batch_time=0.44761 
Train Epoch: 1 [321/500 20544/32000 (64%)] Loss: 0.90615 (QuantReg: 22.64537) QuantErr: 22.64537 batch_time=0.44447 
Train Epoch: 1 [329/500 21056/32000 (66%)] Loss: 0.75516 (QuantReg: 22.65967) QuantErr: 22.65967 batch_time=0.97427 
Train Epoch: 1 [337/500 21568/32000 (67%)] Loss: 0.70075 (QuantReg: 22.64360) QuantErr: 22.64360 batch_time=0.44862 
Train Epoch: 1 [345/500 22080/32000 (69%)] Loss: 0.71222 (QuantReg: 22.65818) QuantErr: 22.65818 batch_time=0.46556 
Train Epoch: 1 [353/500 22592/32000 (71%)] Loss: 0.70609 (QuantReg: 22.63818) QuantErr: 22.63818 batch_time=0.44487 
Train Epoch: 1 [361/500 23104/32000 (72%)] Loss: 0.71493 (QuantReg: 22.71354) QuantErr: 22.71354 batch_time=0.44719 
Train Epoch: 1 [369/500 23616/32000 (74%)] Loss: 0.61644 (QuantReg: 22.67355) QuantErr: 22.67355 batch_time=0.47293 
Train Epoch: 1 [377/500 24128/32000 (75%)] Loss: 0.58879 (QuantReg: 22.69790) QuantErr: 22.69790 batch_time=0.46632 
Train Epoch: 1 [385/500 24640/32000 (77%)] Loss: 0.91056 (QuantReg: 22.70962) QuantErr: 22.70962 batch_time=0.45226 
Train Epoch: 1 [393/500 25152/32000 (79%)] Loss: 0.77722 (QuantReg: 22.65633) QuantErr: 22.65633 batch_time=0.96340 
Train Epoch: 1 [401/500 25664/32000 (80%)] Loss: 0.70446 (QuantReg: 22.67061) QuantErr: 22.67061 batch_time=0.47204 
Train Epoch: 1 [409/500 26176/32000 (82%)] Loss: 0.82212 (QuantReg: 22.64172) QuantErr: 22.64172 batch_time=0.47576 
Train Epoch: 1 [417/500 26688/32000 (83%)] Loss: 0.59018 (QuantReg: 22.66025) QuantErr: 22.66025 batch_time=0.47621 
Train Epoch: 1 [425/500 27200/32000 (85%)] Loss: 0.68781 (QuantReg: 22.69551) QuantErr: 22.69551 batch_time=0.45029 
Train Epoch: 1 [433/500 27712/32000 (87%)] Loss: 0.93166 (QuantReg: 22.64676) QuantErr: 22.64676 batch_time=0.48386 
Train Epoch: 1 [441/500 28224/32000 (88%)] Loss: 0.44907 (QuantReg: 22.67698) QuantErr: 22.67698 batch_time=0.44816 
Train Epoch: 1 [449/500 28736/32000 (90%)] Loss: 0.82014 (QuantReg: 22.67235) QuantErr: 22.67235 batch_time=0.44734 
Train Epoch: 1 [457/500 29248/32000 (91%)] Loss: 0.86227 (QuantReg: 22.69470) QuantErr: 22.69470 batch_time=0.92520 
Train Epoch: 1 [465/500 29760/32000 (93%)] Loss: 0.49908 (QuantReg: 22.64480) QuantErr: 22.64480 batch_time=0.44643 
Train Epoch: 1 [473/500 30272/32000 (95%)] Loss: 0.54844 (QuantReg: 22.69093) QuantErr: 22.69093 batch_time=0.44407 
Train Epoch: 1 [481/500 30784/32000 (96%)] Loss: 0.67728 (QuantReg: 22.64714) QuantErr: 22.64714 batch_time=0.44510 
Train Epoch: 1 [489/500 31296/32000 (98%)] Loss: 0.59014 (QuantReg: 22.68123) QuantErr: 22.68123 batch_time=0.44901 
Train Epoch: 1 [497/500 31808/32000 (99%)] Loss: 0.64536 (QuantReg: 22.67393) QuantErr: 22.67393 batch_time=0.48407 
Train Epoch: 1 codebook_update_time=1.93552
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_ActivityNet_bs64/checkpoint-epoch1.pth ...
Done in 3.704s
Updating 'best' checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_ActivityNet_bs64/checkpoint-epoch1.pth ...
Done in 7.288s
 epoch          : 1
 loss           : 1.6141951302886008
 quant_reg      : 22.665719146728517
 quant_err      : 22.665719146728517
 learning_rate  : 5e-05
 n_samples      : 32000
 n_steps        : 500
 ActivityNet_val1_test/t2v_metrics/R1: 10.941631075859263
 ActivityNet_val1_test/t2v_metrics/R5: 32.255440309131586
 ActivityNet_val1_test/t2v_metrics/R10: 48.44417327638804
 ActivityNet_val1_test/t2v_metrics/R50: 84.9908480780964
 ActivityNet_val1_test/t2v_metrics/MedR: 11.0
 ActivityNet_val1_test/t2v_metrics/MeanR: 35.75330486068741
 ActivityNet_val1_test/t2v_metrics/geometric_mean_R1-R5-R10: 25.761760020175295
 ActivityNet_val1_test/v2t_metrics/R1: 11.511083994305471
 ActivityNet_val1_test/v2t_metrics/R5: 34.28920073215375
 ActivityNet_val1_test/v2t_metrics/R10: 49.928818385194226
 ActivityNet_val1_test/v2t_metrics/R50: 86.98393329265812
 ActivityNet_val1_test/v2t_metrics/MedR: 11.0
 ActivityNet_val1_test/v2t_metrics/MeanR: 32.74283099450885
 ActivityNet_val1_test/v2t_metrics/geometric_mean_R1-R5-R10: 27.011059796931953
 mnt_best       : 25.761760020175295
 not_improved_count: 0
Train Epoch: 2 [1/500 64/32000 (0%)] Loss: 0.72561 (QuantReg: 11.94269) QuantErr: 11.94269 batch_time=24.48405 
Train Epoch: 2 [9/500 576/32000 (2%)] Loss: 0.57737 (QuantReg: 11.84015) QuantErr: 11.84015 batch_time=0.43810 
Train Epoch: 2 [17/500 1088/32000 (3%)] Loss: 0.71258 (QuantReg: 11.41277) QuantErr: 11.41277 batch_time=0.43407 
Train Epoch: 2 [25/500 1600/32000 (5%)] Loss: 0.85016 (QuantReg: 11.71424) QuantErr: 11.71424 batch_time=0.43614 
Train Epoch: 2 [33/500 2112/32000 (7%)] Loss: 0.59503 (QuantReg: 11.42082) QuantErr: 11.42082 batch_time=0.43477 
Train Epoch: 2 [41/500 2624/32000 (8%)] Loss: 0.41292 (QuantReg: 11.65594) QuantErr: 11.65594 batch_time=0.43399 
Train Epoch: 2 [49/500 3136/32000 (10%)] Loss: 0.41943 (QuantReg: 11.49574) QuantErr: 11.49574 batch_time=0.43708 
Train Epoch: 2 [57/500 3648/32000 (11%)] Loss: 0.42754 (QuantReg: 11.30480) QuantErr: 11.30480 batch_time=0.43817 
Train Epoch: 2 [65/500 4160/32000 (13%)] Loss: 0.52866 (QuantReg: 11.49654) QuantErr: 11.49654 batch_time=0.94863 
Train Epoch: 2 [73/500 4672/32000 (15%)] Loss: 0.42514 (QuantReg: 11.79908) QuantErr: 11.79908 batch_time=0.46029 
Train Epoch: 2 [81/500 5184/32000 (16%)] Loss: 0.62165 (QuantReg: 11.44191) QuantErr: 11.44191 batch_time=0.43721 
Train Epoch: 2 [89/500 5696/32000 (18%)] Loss: 0.47641 (QuantReg: 11.70312) QuantErr: 11.70312 batch_time=0.43991 
Train Epoch: 2 [97/500 6208/32000 (19%)] Loss: 0.54800 (QuantReg: 11.81351) QuantErr: 11.81351 batch_time=0.43473 
Train Epoch: 2 [105/500 6720/32000 (21%)] Loss: 0.35568 (QuantReg: 12.53562) QuantErr: 12.53562 batch_time=0.44060 
Train Epoch: 2 [113/500 7232/32000 (23%)] Loss: 0.52862 (QuantReg: 12.49627) QuantErr: 12.49627 batch_time=0.44722 
Train Epoch: 2 [121/500 7744/32000 (24%)] Loss: 0.49737 (QuantReg: 12.26356) QuantErr: 12.26356 batch_time=0.43631 
Train Epoch: 2 [129/500 8256/32000 (26%)] Loss: 0.48285 (QuantReg: 12.19302) QuantErr: 12.19302 batch_time=0.97620 
Train Epoch: 2 [137/500 8768/32000 (27%)] Loss: 0.36473 (QuantReg: 11.95347) QuantErr: 11.95347 batch_time=0.44891 
Train Epoch: 2 [145/500 9280/32000 (29%)] Loss: 0.70330 (QuantReg: 11.76206) QuantErr: 11.76206 batch_time=0.44793 
Train Epoch: 2 [153/500 9792/32000 (31%)] Loss: 0.56199 (QuantReg: 12.14221) QuantErr: 12.14221 batch_time=0.44647 
Train Epoch: 2 [161/500 10304/32000 (32%)] Loss: 0.62803 (QuantReg: 11.92181) QuantErr: 11.92181 batch_time=0.44875 
Train Epoch: 2 [169/500 10816/32000 (34%)] Loss: 0.49296 (QuantReg: 12.34320) QuantErr: 12.34320 batch_time=0.45128 
Train Epoch: 2 [177/500 11328/32000 (35%)] Loss: 0.44256 (QuantReg: 11.74029) QuantErr: 11.74029 batch_time=0.44882 
Train Epoch: 2 [185/500 11840/32000 (37%)] Loss: 0.47053 (QuantReg: 12.04703) QuantErr: 12.04703 batch_time=0.47542 
Train Epoch: 2 [193/500 12352/32000 (39%)] Loss: 0.48854 (QuantReg: 12.01397) QuantErr: 12.01397 batch_time=1.05818 
Train Epoch: 2 [201/500 12864/32000 (40%)] Loss: 0.29749 (QuantReg: 12.51154) QuantErr: 12.51154 batch_time=0.44164 
Train Epoch: 2 [209/500 13376/32000 (42%)] Loss: 0.58331 (QuantReg: 12.26067) QuantErr: 12.26067 batch_time=0.44198 
Train Epoch: 2 [217/500 13888/32000 (43%)] Loss: 0.55483 (QuantReg: 12.12471) QuantErr: 12.12471 batch_time=0.43961 
Train Epoch: 2 [225/500 14400/32000 (45%)] Loss: 0.47792 (QuantReg: 12.30828) QuantErr: 12.30828 batch_time=0.43174 
Train Epoch: 2 [233/500 14912/32000 (47%)] Loss: 0.50005 (QuantReg: 12.59545) QuantErr: 12.59545 batch_time=0.43438 
Train Epoch: 2 [241/500 15424/32000 (48%)] Loss: 0.47472 (QuantReg: 12.36238) QuantErr: 12.36238 batch_time=0.43965 
Train Epoch: 2 [249/500 15936/32000 (50%)] Loss: 0.37577 (QuantReg: 12.11763) QuantErr: 12.11763 batch_time=0.45526 
Train Epoch: 2 [257/500 16448/32000 (51%)] Loss: 0.36974 (QuantReg: 12.57280) QuantErr: 12.57280 batch_time=1.03322 
Train Epoch: 2 [265/500 16960/32000 (53%)] Loss: 0.45639 (QuantReg: 12.26483) QuantErr: 12.26483 batch_time=0.43940 
Train Epoch: 2 [273/500 17472/32000 (55%)] Loss: 0.39022 (QuantReg: 12.03066) QuantErr: 12.03066 batch_time=0.44100 
Train Epoch: 2 [281/500 17984/32000 (56%)] Loss: 0.26798 (QuantReg: 12.19280) QuantErr: 12.19280 batch_time=0.44999 
Train Epoch: 2 [289/500 18496/32000 (58%)] Loss: 0.34657 (QuantReg: 12.70201) QuantErr: 12.70201 batch_time=0.46315 
Train Epoch: 2 [297/500 19008/32000 (59%)] Loss: 0.34445 (QuantReg: 12.37846) QuantErr: 12.37846 batch_time=0.44864 
Train Epoch: 2 [305/500 19520/32000 (61%)] Loss: 0.59839 (QuantReg: 11.91625) QuantErr: 11.91625 batch_time=0.44528 
Train Epoch: 2 [313/500 20032/32000 (63%)] Loss: 0.44745 (QuantReg: 12.49513) QuantErr: 12.49513 batch_time=0.44478 
Train Epoch: 2 [321/500 20544/32000 (64%)] Loss: 0.29735 (QuantReg: 12.42545) QuantErr: 12.42545 batch_time=0.94504 
Train Epoch: 2 [329/500 21056/32000 (66%)] Loss: 0.45677 (QuantReg: 12.28759) QuantErr: 12.28759 batch_time=0.44418 
Train Epoch: 2 [337/500 21568/32000 (67%)] Loss: 0.35988 (QuantReg: 12.62699) QuantErr: 12.62699 batch_time=0.45762 
Train Epoch: 2 [345/500 22080/32000 (69%)] Loss: 0.48417 (QuantReg: 12.39612) QuantErr: 12.39612 batch_time=0.43627 
Train Epoch: 2 [353/500 22592/32000 (71%)] Loss: 0.45944 (QuantReg: 12.29129) QuantErr: 12.29129 batch_time=0.43591 
Train Epoch: 2 [361/500 23104/32000 (72%)] Loss: 0.31969 (QuantReg: 13.05449) QuantErr: 13.05449 batch_time=0.43822 
Train Epoch: 2 [369/500 23616/32000 (74%)] Loss: 0.28519 (QuantReg: 12.39510) QuantErr: 12.39510 batch_time=0.44620 
Train Epoch: 2 [377/500 24128/32000 (75%)] Loss: 0.41241 (QuantReg: 12.46684) QuantErr: 12.46684 batch_time=0.45663 
Train Epoch: 2 [385/500 24640/32000 (77%)] Loss: 0.39577 (QuantReg: 12.56548) QuantErr: 12.56548 batch_time=0.96423 
Train Epoch: 2 [393/500 25152/32000 (79%)] Loss: 0.46063 (QuantReg: 12.61829) QuantErr: 12.61829 batch_time=0.44632 
Train Epoch: 2 [401/500 25664/32000 (80%)] Loss: 0.35709 (QuantReg: 12.25833) QuantErr: 12.25833 batch_time=0.44624 
Train Epoch: 2 [409/500 26176/32000 (82%)] Loss: 0.37262 (QuantReg: 12.66273) QuantErr: 12.66273 batch_time=0.44548 
Train Epoch: 2 [417/500 26688/32000 (83%)] Loss: 0.36536 (QuantReg: 12.84407) QuantErr: 12.84407 batch_time=0.45127 
Train Epoch: 2 [425/500 27200/32000 (85%)] Loss: 0.47645 (QuantReg: 12.23712) QuantErr: 12.23712 batch_time=0.44872 
Train Epoch: 2 [433/500 27712/32000 (87%)] Loss: 0.29463 (QuantReg: 12.92317) QuantErr: 12.92317 batch_time=0.44978 
Train Epoch: 2 [441/500 28224/32000 (88%)] Loss: 0.31129 (QuantReg: 12.53390) QuantErr: 12.53390 batch_time=0.44776 
Train Epoch: 2 [449/500 28736/32000 (90%)] Loss: 0.39711 (QuantReg: 12.74175) QuantErr: 12.74175 batch_time=0.99466 
Train Epoch: 2 [457/500 29248/32000 (91%)] Loss: 0.34072 (QuantReg: 12.82094) QuantErr: 12.82094 batch_time=0.44497 
Train Epoch: 2 [465/500 29760/32000 (93%)] Loss: 0.30355 (QuantReg: 12.82866) QuantErr: 12.82866 batch_time=0.45882 
Train Epoch: 2 [473/500 30272/32000 (95%)] Loss: 0.35684 (QuantReg: 13.26902) QuantErr: 13.26902 batch_time=0.47630 
Train Epoch: 2 [481/500 30784/32000 (96%)] Loss: 0.28016 (QuantReg: 13.10432) QuantErr: 13.10432 batch_time=0.43879 
Train Epoch: 2 [489/500 31296/32000 (98%)] Loss: 0.50992 (QuantReg: 12.88146) QuantErr: 12.88146 batch_time=0.44342 
Train Epoch: 2 [497/500 31808/32000 (99%)] Loss: 0.37634 (QuantReg: 12.96099) QuantErr: 12.96099 batch_time=0.46293 
Train Epoch: 2 codebook_update_time=1.66010
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_ActivityNet_bs64/checkpoint-epoch2.pth ...
Done in 3.845s
Updating 'best' checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_ActivityNet_bs64/checkpoint-epoch2.pth ...
Done in 7.552s
removing stale ckpt [epoch 1] [took 0.00s]
removing stale ckpt [epoch 0] [took 0.01s]
 epoch          : 2
 loss           : 0.4646230584383011
 quant_reg      : 12.237847219467163
 quant_err      : 12.237847219467163
 learning_rate  : 5e-05
 n_samples      : 64000
 n_steps        : 1000
 ActivityNet_val1_test/t2v_metrics/R1: 12.385600976205003
 ActivityNet_val1_test/t2v_metrics/R5: 37.21781574130567
 ActivityNet_val1_test/t2v_metrics/R10: 53.101484645108805
 ActivityNet_val1_test/t2v_metrics/R50: 89.26174496644295
 ActivityNet_val1_test/t2v_metrics/MedR: 9.0
 ActivityNet_val1_test/t2v_metrics/MeanR: 29.53670937563555
 ActivityNet_val1_test/t2v_metrics/geometric_mean_R1-R5-R10: 29.03520364737379
 ActivityNet_val1_test/v2t_metrics/R1: 13.666870042708968
 ActivityNet_val1_test/v2t_metrics/R5: 40.085417937766934
 ActivityNet_val1_test/v2t_metrics/R10: 56.88427903193004
 ActivityNet_val1_test/v2t_metrics/R50: 90.5226764287167
 ActivityNet_val1_test/v2t_metrics/MedR: 8.0
 ActivityNet_val1_test/v2t_metrics/MeanR: 28.2479153955664
 ActivityNet_val1_test/v2t_metrics/geometric_mean_R1-R5-R10: 31.468973710563155
 mnt_best       : 29.03520364737379
 not_improved_count: 0
Train Epoch: 3 [1/500 64/32000 (0%)] Loss: 0.40993 (QuantReg: 10.71375) QuantErr: 10.71375 batch_time=22.99474 
Train Epoch: 3 [9/500 576/32000 (2%)] Loss: 0.46474 (QuantReg: 10.75748) QuantErr: 10.75748 batch_time=0.48450 
Train Epoch: 3 [17/500 1088/32000 (3%)] Loss: 0.38643 (QuantReg: 10.99748) QuantErr: 10.99748 batch_time=0.44436 
Train Epoch: 3 [25/500 1600/32000 (5%)] Loss: 0.35345 (QuantReg: 10.25052) QuantErr: 10.25052 batch_time=0.44962 
Train Epoch: 3 [33/500 2112/32000 (7%)] Loss: 0.40726 (QuantReg: 10.72150) QuantErr: 10.72150 batch_time=0.51551 
Train Epoch: 3 [41/500 2624/32000 (8%)] Loss: 0.40029 (QuantReg: 10.84274) QuantErr: 10.84274 batch_time=0.45129 
Train Epoch: 3 [49/500 3136/32000 (10%)] Loss: 0.25687 (QuantReg: 11.01723) QuantErr: 11.01723 batch_time=0.44791 
Train Epoch: 3 [57/500 3648/32000 (11%)] Loss: 0.19419 (QuantReg: 10.72959) QuantErr: 10.72959 batch_time=0.43958 
Train Epoch: 3 [65/500 4160/32000 (13%)] Loss: 0.31108 (QuantReg: 10.44353) QuantErr: 10.44353 batch_time=0.44033 
Train Epoch: 3 [73/500 4672/32000 (15%)] Loss: 0.26679 (QuantReg: 10.48056) QuantErr: 10.48056 batch_time=0.44636 
Train Epoch: 3 [81/500 5184/32000 (16%)] Loss: 0.24867 (QuantReg: 10.88305) QuantErr: 10.88305 batch_time=0.44768 
Train Epoch: 3 [89/500 5696/32000 (18%)] Loss: 0.36001 (QuantReg: 10.76767) QuantErr: 10.76767 batch_time=0.44208 
Train Epoch: 3 [97/500 6208/32000 (19%)] Loss: 0.31835 (QuantReg: 10.75226) QuantErr: 10.75226 batch_time=0.43788 
Train Epoch: 3 [105/500 6720/32000 (21%)] Loss: 0.32759 (QuantReg: 10.27977) QuantErr: 10.27977 batch_time=0.44229 
Train Epoch: 3 [113/500 7232/32000 (23%)] Loss: 0.35476 (QuantReg: 11.09404) QuantErr: 11.09404 batch_time=0.44306 
Train Epoch: 3 [121/500 7744/32000 (24%)] Loss: 0.46567 (QuantReg: 10.30645) QuantErr: 10.30645 batch_time=0.44015 
Train Epoch: 3 [129/500 8256/32000 (26%)] Loss: 0.28122 (QuantReg: 10.75619) QuantErr: 10.75619 batch_time=0.44164 
Train Epoch: 3 [137/500 8768/32000 (27%)] Loss: 0.27271 (QuantReg: 10.63039) QuantErr: 10.63039 batch_time=0.44508 
Train Epoch: 3 [145/500 9280/32000 (29%)] Loss: 0.25132 (QuantReg: 10.98249) QuantErr: 10.98249 batch_time=0.47105 
Train Epoch: 3 [153/500 9792/32000 (31%)] Loss: 0.36782 (QuantReg: 10.78363) QuantErr: 10.78363 batch_time=0.44402 
Train Epoch: 3 [161/500 10304/32000 (32%)] Loss: 0.43878 (QuantReg: 10.92621) QuantErr: 10.92621 batch_time=0.47842 
Train Epoch: 3 [169/500 10816/32000 (34%)] Loss: 0.39755 (QuantReg: 10.78389) QuantErr: 10.78389 batch_time=0.47038 
Train Epoch: 3 [177/500 11328/32000 (35%)] Loss: 0.36341 (QuantReg: 10.60740) QuantErr: 10.60740 batch_time=0.44630 
Train Epoch: 3 [185/500 11840/32000 (37%)] Loss: 0.21364 (QuantReg: 11.00736) QuantErr: 11.00736 batch_time=0.44562 
Train Epoch: 3 [193/500 12352/32000 (39%)] Loss: 0.28754 (QuantReg: 10.95399) QuantErr: 10.95399 batch_time=0.44158 
Train Epoch: 3 [201/500 12864/32000 (40%)] Loss: 0.35121 (QuantReg: 10.92761) QuantErr: 10.92761 batch_time=0.44814 
Train Epoch: 3 [209/500 13376/32000 (42%)] Loss: 0.29015 (QuantReg: 10.73912) QuantErr: 10.73912 batch_time=0.44942 
Train Epoch: 3 [217/500 13888/32000 (43%)] Loss: 0.21805 (QuantReg: 10.95119) QuantErr: 10.95119 batch_time=0.44326 
Train Epoch: 3 [225/500 14400/32000 (45%)] Loss: 0.39336 (QuantReg: 10.82223) QuantErr: 10.82223 batch_time=0.44383 
Train Epoch: 3 [233/500 14912/32000 (47%)] Loss: 0.36095 (QuantReg: 10.79705) QuantErr: 10.79705 batch_time=0.44080 
Train Epoch: 3 [241/500 15424/32000 (48%)] Loss: 0.29764 (QuantReg: 11.44570) QuantErr: 11.44570 batch_time=0.51349 
Train Epoch: 3 [249/500 15936/32000 (50%)] Loss: 0.29001 (QuantReg: 10.77888) QuantErr: 10.77888 batch_time=0.44635 
Train Epoch: 3 [257/500 16448/32000 (51%)] Loss: 0.27291 (QuantReg: 11.07236) QuantErr: 11.07236 batch_time=0.47518 
Train Epoch: 3 [265/500 16960/32000 (53%)] Loss: 0.50357 (QuantReg: 11.26909) QuantErr: 11.26909 batch_time=0.47454 
Train Epoch: 3 [273/500 17472/32000 (55%)] Loss: 0.31944 (QuantReg: 10.91059) QuantErr: 10.91059 batch_time=0.47373 
Train Epoch: 3 [281/500 17984/32000 (56%)] Loss: 0.29584 (QuantReg: 10.88494) QuantErr: 10.88494 batch_time=0.48053 
Train Epoch: 3 [289/500 18496/32000 (58%)] Loss: 0.24773 (QuantReg: 11.28522) QuantErr: 11.28522 batch_time=0.44815 
Train Epoch: 3 [297/500 19008/32000 (59%)] Loss: 0.39481 (QuantReg: 11.03147) QuantErr: 11.03147 batch_time=0.43711 
Train Epoch: 3 [305/500 19520/32000 (61%)] Loss: 0.21448 (QuantReg: 10.98965) QuantErr: 10.98965 batch_time=0.43810 
Train Epoch: 3 [313/500 20032/32000 (63%)] Loss: 0.37343 (QuantReg: 11.14926) QuantErr: 11.14926 batch_time=0.43623 
Train Epoch: 3 [321/500 20544/32000 (64%)] Loss: 0.42089 (QuantReg: 10.84798) QuantErr: 10.84798 batch_time=0.44012 
Train Epoch: 3 [329/500 21056/32000 (66%)] Loss: 0.31365 (QuantReg: 10.82343) QuantErr: 10.82343 batch_time=0.46678 
Train Epoch: 3 [337/500 21568/32000 (67%)] Loss: 0.26799 (QuantReg: 10.60613) QuantErr: 10.60613 batch_time=0.45443 
Train Epoch: 3 [345/500 22080/32000 (69%)] Loss: 0.24319 (QuantReg: 10.97656) QuantErr: 10.97656 batch_time=0.45093 
Train Epoch: 3 [353/500 22592/32000 (71%)] Loss: 0.32546 (QuantReg: 10.97236) QuantErr: 10.97236 batch_time=0.44696 
Train Epoch: 3 [361/500 23104/32000 (72%)] Loss: 0.25567 (QuantReg: 11.36458) QuantErr: 11.36458 batch_time=0.44506 
Train Epoch: 3 [369/500 23616/32000 (74%)] Loss: 0.26189 (QuantReg: 11.25579) QuantErr: 11.25579 batch_time=0.44577 
Train Epoch: 3 [377/500 24128/32000 (75%)] Loss: 0.29855 (QuantReg: 10.67048) QuantErr: 10.67048 batch_time=0.44247 
Train Epoch: 3 [385/500 24640/32000 (77%)] Loss: 0.21579 (QuantReg: 11.24943) QuantErr: 11.24943 batch_time=0.44293 
Train Epoch: 3 [393/500 25152/32000 (79%)] Loss: 0.38956 (QuantReg: 10.93985) QuantErr: 10.93985 batch_time=0.43846 
Train Epoch: 3 [401/500 25664/32000 (80%)] Loss: 0.36131 (QuantReg: 11.46022) QuantErr: 11.46022 batch_time=0.44596 
Train Epoch: 3 [409/500 26176/32000 (82%)] Loss: 0.29492 (QuantReg: 10.94477) QuantErr: 10.94477 batch_time=0.45094 
Train Epoch: 3 [417/500 26688/32000 (83%)] Loss: 0.27739 (QuantReg: 11.41177) QuantErr: 11.41177 batch_time=0.47105 
Train Epoch: 3 [425/500 27200/32000 (85%)] Loss: 0.29994 (QuantReg: 10.99319) QuantErr: 10.99319 batch_time=0.44569 
Train Epoch: 3 [433/500 27712/32000 (87%)] Loss: 0.22637 (QuantReg: 10.94746) QuantErr: 10.94746 batch_time=0.44288 
Train Epoch: 3 [441/500 28224/32000 (88%)] Loss: 0.29155 (QuantReg: 11.36957) QuantErr: 11.36957 batch_time=0.44865 
Train Epoch: 3 [449/500 28736/32000 (90%)] Loss: 0.30023 (QuantReg: 11.21756) QuantErr: 11.21756 batch_time=0.44343 
Train Epoch: 3 [457/500 29248/32000 (91%)] Loss: 0.19223 (QuantReg: 11.06503) QuantErr: 11.06503 batch_time=0.43983 
Train Epoch: 3 [465/500 29760/32000 (93%)] Loss: 0.29842 (QuantReg: 11.30961) QuantErr: 11.30961 batch_time=0.44554 
Train Epoch: 3 [473/500 30272/32000 (95%)] Loss: 0.34664 (QuantReg: 11.19434) QuantErr: 11.19434 batch_time=0.44184 
Train Epoch: 3 [481/500 30784/32000 (96%)] Loss: 0.32124 (QuantReg: 11.66651) QuantErr: 11.66651 batch_time=0.45018 
Train Epoch: 3 [489/500 31296/32000 (98%)] Loss: 0.28483 (QuantReg: 10.99618) QuantErr: 10.99618 batch_time=0.44850 
Train Epoch: 3 [497/500 31808/32000 (99%)] Loss: 0.32154 (QuantReg: 11.24058) QuantErr: 11.24058 batch_time=0.44788 
Train Epoch: 3 codebook_update_time=1.67331
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_ActivityNet_bs64/checkpoint-epoch3.pth ...
Done in 3.488s
Updating 'best' checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_ActivityNet_bs64/checkpoint-epoch3.pth ...
Done in 7.073s
removing stale ckpt [epoch 2] [took 0.00s]
 epoch          : 3
 loss           : 0.3017108673900366
 quant_reg      : 10.954798482894898
 quant_err      : 10.954798482894898
 learning_rate  : 4.25e-05
 n_samples      : 96000
 n_steps        : 1500
 ActivityNet_val1_test/t2v_metrics/R1: 14.012609314622738
 ActivityNet_val1_test/t2v_metrics/R5: 39.251576164327844
 ActivityNet_val1_test/t2v_metrics/R10: 56.457189343095386
 ActivityNet_val1_test/t2v_metrics/R50: 90.92942851332113
 ActivityNet_val1_test/t2v_metrics/MedR: 8.0
 ActivityNet_val1_test/t2v_metrics/MeanR: 28.050030506406344
 ActivityNet_val1_test/t2v_metrics/geometric_mean_R1-R5-R10: 31.43150111000888
 ActivityNet_val1_test/v2t_metrics/R1: 14.968476713443156
 ActivityNet_val1_test/v2t_metrics/R5: 41.67175106772422
 ActivityNet_val1_test/v2t_metrics/R10: 58.287573723815335
 ActivityNet_val1_test/v2t_metrics/R50: 91.25483018100468
 ActivityNet_val1_test/v2t_metrics/MedR: 8.0
 ActivityNet_val1_test/v2t_metrics/MeanR: 26.869025828757373
 ActivityNet_val1_test/v2t_metrics/geometric_mean_R1-R5-R10: 33.12824616795514
 mnt_best       : 31.43150111000888
 not_improved_count: 0
Train Epoch: 4 [1/500 64/32000 (0%)] Loss: 0.31668 (QuantReg: 10.49403) QuantErr: 10.49403 batch_time=24.97642 
Train Epoch: 4 [9/500 576/32000 (2%)] Loss: 0.28908 (QuantReg: 10.25020) QuantErr: 10.25020 batch_time=0.44047 
Train Epoch: 4 [17/500 1088/32000 (3%)] Loss: 0.25065 (QuantReg: 10.22250) QuantErr: 10.22250 batch_time=0.43714 
Train Epoch: 4 [25/500 1600/32000 (5%)] Loss: 0.32267 (QuantReg: 10.36715) QuantErr: 10.36715 batch_time=0.44198 
Train Epoch: 4 [33/500 2112/32000 (7%)] Loss: 0.30382 (QuantReg: 10.41416) QuantErr: 10.41416 batch_time=0.44714 
Train Epoch: 4 [41/500 2624/32000 (8%)] Loss: 0.20200 (QuantReg: 10.91406) QuantErr: 10.91406 batch_time=0.44428 
Train Epoch: 4 [49/500 3136/32000 (10%)] Loss: 0.27584 (QuantReg: 10.41804) QuantErr: 10.41804 batch_time=0.47418 
Train Epoch: 4 [57/500 3648/32000 (11%)] Loss: 0.20106 (QuantReg: 10.67783) QuantErr: 10.67783 batch_time=0.44292 
Train Epoch: 4 [65/500 4160/32000 (13%)] Loss: 0.25178 (QuantReg: 10.58445) QuantErr: 10.58445 batch_time=0.87217 
Train Epoch: 4 [73/500 4672/32000 (15%)] Loss: 0.32869 (QuantReg: 10.36861) QuantErr: 10.36861 batch_time=0.45181 
Train Epoch: 4 [81/500 5184/32000 (16%)] Loss: 0.41843 (QuantReg: 10.21831) QuantErr: 10.21831 batch_time=0.44495 
Train Epoch: 4 [89/500 5696/32000 (18%)] Loss: 0.29685 (QuantReg: 10.31413) QuantErr: 10.31413 batch_time=0.43781 
Train Epoch: 4 [97/500 6208/32000 (19%)] Loss: 0.12007 (QuantReg: 10.71739) QuantErr: 10.71739 batch_time=0.44608 
Train Epoch: 4 [105/500 6720/32000 (21%)] Loss: 0.22683 (QuantReg: 10.26605) QuantErr: 10.26605 batch_time=0.44479 
Train Epoch: 4 [113/500 7232/32000 (23%)] Loss: 0.16645 (QuantReg: 10.35295) QuantErr: 10.35295 batch_time=0.44591 
Train Epoch: 4 [121/500 7744/32000 (24%)] Loss: 0.34859 (QuantReg: 10.55089) QuantErr: 10.55089 batch_time=0.44542 
Train Epoch: 4 [129/500 8256/32000 (26%)] Loss: 0.23694 (QuantReg: 10.33128) QuantErr: 10.33128 batch_time=0.83888 
Train Epoch: 4 [137/500 8768/32000 (27%)] Loss: 0.24139 (QuantReg: 10.35362) QuantErr: 10.35362 batch_time=0.43796 
Train Epoch: 4 [145/500 9280/32000 (29%)] Loss: 0.18898 (QuantReg: 10.69968) QuantErr: 10.69968 batch_time=0.43641 
Train Epoch: 4 [153/500 9792/32000 (31%)] Loss: 0.23084 (QuantReg: 10.84095) QuantErr: 10.84095 batch_time=0.44288 
Train Epoch: 4 [161/500 10304/32000 (32%)] Loss: 0.29987 (QuantReg: 10.64164) QuantErr: 10.64164 batch_time=0.44455 
Train Epoch: 4 [169/500 10816/32000 (34%)] Loss: 0.25026 (QuantReg: 11.11030) QuantErr: 11.11030 batch_time=0.44266 
Train Epoch: 4 [177/500 11328/32000 (35%)] Loss: 0.18914 (QuantReg: 10.97939) QuantErr: 10.97939 batch_time=0.44795 
Train Epoch: 4 [185/500 11840/32000 (37%)] Loss: 0.31622 (QuantReg: 10.22728) QuantErr: 10.22728 batch_time=0.44537 
Train Epoch: 4 [193/500 12352/32000 (39%)] Loss: 0.20161 (QuantReg: 10.67864) QuantErr: 10.67864 batch_time=0.87546 
Train Epoch: 4 [201/500 12864/32000 (40%)] Loss: 0.29261 (QuantReg: 10.51759) QuantErr: 10.51759 batch_time=0.44844 
Train Epoch: 4 [209/500 13376/32000 (42%)] Loss: 0.29786 (QuantReg: 10.79147) QuantErr: 10.79147 batch_time=0.44668 
Train Epoch: 4 [217/500 13888/32000 (43%)] Loss: 0.16765 (QuantReg: 10.82858) QuantErr: 10.82858 batch_time=0.44343 
Train Epoch: 4 [225/500 14400/32000 (45%)] Loss: 0.18758 (QuantReg: 11.22581) QuantErr: 11.22581 batch_time=0.44164 
Train Epoch: 4 [233/500 14912/32000 (47%)] Loss: 0.22730 (QuantReg: 10.58330) QuantErr: 10.58330 batch_time=0.44875 
Train Epoch: 4 [241/500 15424/32000 (48%)] Loss: 0.17710 (QuantReg: 11.03730) QuantErr: 11.03730 batch_time=0.43982 
Train Epoch: 4 [249/500 15936/32000 (50%)] Loss: 0.13548 (QuantReg: 10.73270) QuantErr: 10.73270 batch_time=0.44444 
Train Epoch: 4 [257/500 16448/32000 (51%)] Loss: 0.13474 (QuantReg: 10.80898) QuantErr: 10.80898 batch_time=0.83512 
Train Epoch: 4 [265/500 16960/32000 (53%)] Loss: 0.20839 (QuantReg: 11.06962) QuantErr: 11.06962 batch_time=0.44474 
Train Epoch: 4 [273/500 17472/32000 (55%)] Loss: 0.13639 (QuantReg: 11.29702) QuantErr: 11.29702 batch_time=0.44378 
Train Epoch: 4 [281/500 17984/32000 (56%)] Loss: 0.31699 (QuantReg: 10.60871) QuantErr: 10.60871 batch_time=0.45181 
Train Epoch: 4 [289/500 18496/32000 (58%)] Loss: 0.32189 (QuantReg: 10.53854) QuantErr: 10.53854 batch_time=0.44476 
Train Epoch: 4 [297/500 19008/32000 (59%)] Loss: 0.17006 (QuantReg: 11.08009) QuantErr: 11.08009 batch_time=0.44035 
Train Epoch: 4 [305/500 19520/32000 (61%)] Loss: 0.17244 (QuantReg: 10.55333) QuantErr: 10.55333 batch_time=0.44844 
Train Epoch: 4 [313/500 20032/32000 (63%)] Loss: 0.21301 (QuantReg: 10.81970) QuantErr: 10.81970 batch_time=0.43873 
Train Epoch: 4 [321/500 20544/32000 (64%)] Loss: 0.25626 (QuantReg: 10.65682) QuantErr: 10.65682 batch_time=0.87750 
Train Epoch: 4 [329/500 21056/32000 (66%)] Loss: 0.17315 (QuantReg: 11.03007) QuantErr: 11.03007 batch_time=0.44030 
Train Epoch: 4 [337/500 21568/32000 (67%)] Loss: 0.16300 (QuantReg: 10.74859) QuantErr: 10.74859 batch_time=0.46207 
Train Epoch: 4 [345/500 22080/32000 (69%)] Loss: 0.23563 (QuantReg: 10.97024) QuantErr: 10.97024 batch_time=0.44685 
Train Epoch: 4 [353/500 22592/32000 (71%)] Loss: 0.27254 (QuantReg: 10.98203) QuantErr: 10.98203 batch_time=0.47412 
Train Epoch: 4 [361/500 23104/32000 (72%)] Loss: 0.40224 (QuantReg: 10.48666) QuantErr: 10.48666 batch_time=0.44721 
Train Epoch: 4 [369/500 23616/32000 (74%)] Loss: 0.22941 (QuantReg: 10.84777) QuantErr: 10.84777 batch_time=0.45859 
Train Epoch: 4 [377/500 24128/32000 (75%)] Loss: 0.23385 (QuantReg: 11.15265) QuantErr: 11.15265 batch_time=0.45302 
Train Epoch: 4 [385/500 24640/32000 (77%)] Loss: 0.30820 (QuantReg: 10.94125) QuantErr: 10.94125 batch_time=0.44794 
Train Epoch: 4 [393/500 25152/32000 (79%)] Loss: 0.29493 (QuantReg: 10.75366) QuantErr: 10.75366 batch_time=0.45352 
Train Epoch: 4 [401/500 25664/32000 (80%)] Loss: 0.18232 (QuantReg: 10.47132) QuantErr: 10.47132 batch_time=0.45770 
Train Epoch: 4 [409/500 26176/32000 (82%)] Loss: 0.19428 (QuantReg: 10.82954) QuantErr: 10.82954 batch_time=0.44465 
Train Epoch: 4 [417/500 26688/32000 (83%)] Loss: 0.18538 (QuantReg: 10.43752) QuantErr: 10.43752 batch_time=0.44576 
Train Epoch: 4 [425/500 27200/32000 (85%)] Loss: 0.18616 (QuantReg: 11.12352) QuantErr: 11.12352 batch_time=0.44392 
Train Epoch: 4 [433/500 27712/32000 (87%)] Loss: 0.19220 (QuantReg: 11.25396) QuantErr: 11.25396 batch_time=0.44708 
Train Epoch: 4 [441/500 28224/32000 (88%)] Loss: 0.31112 (QuantReg: 10.77728) QuantErr: 10.77728 batch_time=0.44637 
Train Epoch: 4 [449/500 28736/32000 (90%)] Loss: 0.15565 (QuantReg: 10.83008) QuantErr: 10.83008 batch_time=0.44358 
Train Epoch: 4 [457/500 29248/32000 (91%)] Loss: 0.21716 (QuantReg: 11.09379) QuantErr: 11.09379 batch_time=0.44529 
Train Epoch: 4 [465/500 29760/32000 (93%)] Loss: 0.23212 (QuantReg: 11.09332) QuantErr: 11.09332 batch_time=0.44735 
Train Epoch: 4 [473/500 30272/32000 (95%)] Loss: 0.21230 (QuantReg: 10.96637) QuantErr: 10.96637 batch_time=0.44227 
Train Epoch: 4 [481/500 30784/32000 (96%)] Loss: 0.16492 (QuantReg: 11.23637) QuantErr: 11.23637 batch_time=0.44321 
Train Epoch: 4 [489/500 31296/32000 (98%)] Loss: 0.33311 (QuantReg: 11.25983) QuantErr: 11.25983 batch_time=0.44640 
Train Epoch: 4 [497/500 31808/32000 (99%)] Loss: 0.18437 (QuantReg: 11.06644) QuantErr: 11.06644 batch_time=0.44771 
Train Epoch: 4 codebook_update_time=1.63558
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_ActivityNet_bs64/checkpoint-epoch4.pth ...
Done in 3.787s
Updating 'best' checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_ActivityNet_bs64/checkpoint-epoch4.pth ...
Done in 7.242s
removing stale ckpt [epoch 3] [took 0.00s]
 epoch          : 4
 loss           : 0.22879829144477845
 quant_reg      : 10.78496283531189
 quant_err      : 10.78496283531189
 learning_rate  : 4.25e-05
 n_samples      : 128000
 n_steps        : 2000
 ActivityNet_val1_test/t2v_metrics/R1: 14.05328452308318
 ActivityNet_val1_test/t2v_metrics/R5: 39.84136668700427
 ActivityNet_val1_test/t2v_metrics/R10: 57.63677038844824
 ActivityNet_val1_test/t2v_metrics/R50: 91.49888143176734
 ActivityNet_val1_test/t2v_metrics/MedR: 8.0
 ActivityNet_val1_test/t2v_metrics/MeanR: 25.777404921700224
 ActivityNet_val1_test/t2v_metrics/geometric_mean_R1-R5-R10: 31.837373677270676
 ActivityNet_val1_test/v2t_metrics/R1: 15.761643278421802
 ActivityNet_val1_test/v2t_metrics/R5: 43.054708155379295
 ActivityNet_val1_test/v2t_metrics/R10: 59.7518812283913
 ActivityNet_val1_test/v2t_metrics/R50: 91.96664632906244
 ActivityNet_val1_test/v2t_metrics/MedR: 7.0
 ActivityNet_val1_test/v2t_metrics/MeanR: 24.908074028879398
 ActivityNet_val1_test/v2t_metrics/geometric_mean_R1-R5-R10: 34.35510200588799
 mnt_best       : 31.837373677270676
 not_improved_count: 0
Train Epoch: 5 [1/500 64/32000 (0%)] Loss: 0.17851 (QuantReg: 10.73540) QuantErr: 10.73540 batch_time=23.24251 
Train Epoch: 5 [9/500 576/32000 (2%)] Loss: 0.12941 (QuantReg: 10.92670) QuantErr: 10.92670 batch_time=0.43812 
Train Epoch: 5 [17/500 1088/32000 (3%)] Loss: 0.12576 (QuantReg: 10.31118) QuantErr: 10.31118 batch_time=0.50535 
Train Epoch: 5 [25/500 1600/32000 (5%)] Loss: 0.19024 (QuantReg: 10.58322) QuantErr: 10.58322 batch_time=0.43682 
Train Epoch: 5 [33/500 2112/32000 (7%)] Loss: 0.17136 (QuantReg: 10.55180) QuantErr: 10.55180 batch_time=0.44439 
Train Epoch: 5 [41/500 2624/32000 (8%)] Loss: 0.18249 (QuantReg: 10.98717) QuantErr: 10.98717 batch_time=0.43842 
Train Epoch: 5 [49/500 3136/32000 (10%)] Loss: 0.17490 (QuantReg: 10.97654) QuantErr: 10.97654 batch_time=0.44244 
Train Epoch: 5 [57/500 3648/32000 (11%)] Loss: 0.21813 (QuantReg: 10.44407) QuantErr: 10.44407 batch_time=0.43920 
Train Epoch: 5 [65/500 4160/32000 (13%)] Loss: 0.16118 (QuantReg: 10.59707) QuantErr: 10.59707 batch_time=0.45851 
Train Epoch: 5 [73/500 4672/32000 (15%)] Loss: 0.17793 (QuantReg: 10.66656) QuantErr: 10.66656 batch_time=0.49298 
Train Epoch: 5 [81/500 5184/32000 (16%)] Loss: 0.17820 (QuantReg: 10.78656) QuantErr: 10.78656 batch_time=0.44072 
Train Epoch: 5 [89/500 5696/32000 (18%)] Loss: 0.17827 (QuantReg: 10.38005) QuantErr: 10.38005 batch_time=0.43655 
Train Epoch: 5 [97/500 6208/32000 (19%)] Loss: 0.17859 (QuantReg: 10.61297) QuantErr: 10.61297 batch_time=0.43662 
Train Epoch: 5 [105/500 6720/32000 (21%)] Loss: 0.16239 (QuantReg: 10.91727) QuantErr: 10.91727 batch_time=0.47699 
Train Epoch: 5 [113/500 7232/32000 (23%)] Loss: 0.10224 (QuantReg: 10.97290) QuantErr: 10.97290 batch_time=0.43816 
Train Epoch: 5 [121/500 7744/32000 (24%)] Loss: 0.12901 (QuantReg: 10.89669) QuantErr: 10.89669 batch_time=0.43704 
Train Epoch: 5 [129/500 8256/32000 (26%)] Loss: 0.17970 (QuantReg: 10.67652) QuantErr: 10.67652 batch_time=0.47864 
Train Epoch: 5 [137/500 8768/32000 (27%)] Loss: 0.22734 (QuantReg: 10.95682) QuantErr: 10.95682 batch_time=0.47040 
Train Epoch: 5 [145/500 9280/32000 (29%)] Loss: 0.16587 (QuantReg: 11.14880) QuantErr: 11.14880 batch_time=0.46415 
Train Epoch: 5 [153/500 9792/32000 (31%)] Loss: 0.22604 (QuantReg: 10.68453) QuantErr: 10.68453 batch_time=0.45043 
Train Epoch: 5 [161/500 10304/32000 (32%)] Loss: 0.27198 (QuantReg: 10.38835) QuantErr: 10.38835 batch_time=0.43884 
Train Epoch: 5 [169/500 10816/32000 (34%)] Loss: 0.16967 (QuantReg: 10.89299) QuantErr: 10.89299 batch_time=0.43511 
Train Epoch: 5 [177/500 11328/32000 (35%)] Loss: 0.18981 (QuantReg: 10.52777) QuantErr: 10.52777 batch_time=0.44123 
Train Epoch: 5 [185/500 11840/32000 (37%)] Loss: 0.15988 (QuantReg: 11.07530) QuantErr: 11.07530 batch_time=0.44027 
Train Epoch: 5 [193/500 12352/32000 (39%)] Loss: 0.18778 (QuantReg: 11.06758) QuantErr: 11.06758 batch_time=0.43596 
Train Epoch: 5 [201/500 12864/32000 (40%)] Loss: 0.19788 (QuantReg: 10.71915) QuantErr: 10.71915 batch_time=0.43515 
Train Epoch: 5 [209/500 13376/32000 (42%)] Loss: 0.16586 (QuantReg: 10.94318) QuantErr: 10.94318 batch_time=0.43475 
Train Epoch: 5 [217/500 13888/32000 (43%)] Loss: 0.15113 (QuantReg: 10.99276) QuantErr: 10.99276 batch_time=0.43444 
Train Epoch: 5 [225/500 14400/32000 (45%)] Loss: 0.19650 (QuantReg: 11.03507) QuantErr: 11.03507 batch_time=0.43814 
Train Epoch: 5 [233/500 14912/32000 (47%)] Loss: 0.13557 (QuantReg: 11.07434) QuantErr: 11.07434 batch_time=0.47939 
Train Epoch: 5 [241/500 15424/32000 (48%)] Loss: 0.29574 (QuantReg: 10.89392) QuantErr: 10.89392 batch_time=0.44689 
Train Epoch: 5 [249/500 15936/32000 (50%)] Loss: 0.18821 (QuantReg: 10.76620) QuantErr: 10.76620 batch_time=0.44700 
Train Epoch: 5 [257/500 16448/32000 (51%)] Loss: 0.22391 (QuantReg: 11.00930) QuantErr: 11.00930 batch_time=0.45152 
Train Epoch: 5 [265/500 16960/32000 (53%)] Loss: 0.12234 (QuantReg: 10.75050) QuantErr: 10.75050 batch_time=0.45152 
Train Epoch: 5 [273/500 17472/32000 (55%)] Loss: 0.11610 (QuantReg: 10.56121) QuantErr: 10.56121 batch_time=0.44883 
Train Epoch: 5 [281/500 17984/32000 (56%)] Loss: 0.22500 (QuantReg: 10.27580) QuantErr: 10.27580 batch_time=0.44363 
Train Epoch: 5 [289/500 18496/32000 (58%)] Loss: 0.23407 (QuantReg: 10.15714) QuantErr: 10.15714 batch_time=0.45403 
Train Epoch: 5 [297/500 19008/32000 (59%)] Loss: 0.18007 (QuantReg: 11.05294) QuantErr: 11.05294 batch_time=0.48725 
Train Epoch: 5 [305/500 19520/32000 (61%)] Loss: 0.16549 (QuantReg: 11.18235) QuantErr: 11.18235 batch_time=0.49296 
Train Epoch: 5 [313/500 20032/32000 (63%)] Loss: 0.19557 (QuantReg: 10.69771) QuantErr: 10.69771 batch_time=0.44493 
Train Epoch: 5 [321/500 20544/32000 (64%)] Loss: 0.21296 (QuantReg: 10.54412) QuantErr: 10.54412 batch_time=0.44090 
Train Epoch: 5 [329/500 21056/32000 (66%)] Loss: 0.19766 (QuantReg: 10.84439) QuantErr: 10.84439 batch_time=0.44442 
Train Epoch: 5 [337/500 21568/32000 (67%)] Loss: 0.28217 (QuantReg: 10.65438) QuantErr: 10.65438 batch_time=0.43831 
Train Epoch: 5 [345/500 22080/32000 (69%)] Loss: 0.13551 (QuantReg: 10.76471) QuantErr: 10.76471 batch_time=0.43604 
Train Epoch: 5 [353/500 22592/32000 (71%)] Loss: 0.14686 (QuantReg: 11.19111) QuantErr: 11.19111 batch_time=0.45991 
Train Epoch: 5 [361/500 23104/32000 (72%)] Loss: 0.16182 (QuantReg: 10.93837) QuantErr: 10.93837 batch_time=0.45052 
Train Epoch: 5 [369/500 23616/32000 (74%)] Loss: 0.20485 (QuantReg: 10.66376) QuantErr: 10.66376 batch_time=0.44698 
Train Epoch: 5 [377/500 24128/32000 (75%)] Loss: 0.22762 (QuantReg: 10.66908) QuantErr: 10.66908 batch_time=0.45072 
Train Epoch: 5 [385/500 24640/32000 (77%)] Loss: 0.13504 (QuantReg: 10.73984) QuantErr: 10.73984 batch_time=0.48775 
Train Epoch: 5 [393/500 25152/32000 (79%)] Loss: 0.10810 (QuantReg: 10.96009) QuantErr: 10.96009 batch_time=0.46806 
Train Epoch: 5 [401/500 25664/32000 (80%)] Loss: 0.08526 (QuantReg: 10.92311) QuantErr: 10.92311 batch_time=0.43955 
Train Epoch: 5 [409/500 26176/32000 (82%)] Loss: 0.15679 (QuantReg: 10.60987) QuantErr: 10.60987 batch_time=0.46727 
Train Epoch: 5 [417/500 26688/32000 (83%)] Loss: 0.30909 (QuantReg: 10.89381) QuantErr: 10.89381 batch_time=0.43644 
Train Epoch: 5 [425/500 27200/32000 (85%)] Loss: 0.17074 (QuantReg: 11.11278) QuantErr: 11.11278 batch_time=0.43733 
Train Epoch: 5 [433/500 27712/32000 (87%)] Loss: 0.20773 (QuantReg: 10.68769) QuantErr: 10.68769 batch_time=0.43221 
Train Epoch: 5 [441/500 28224/32000 (88%)] Loss: 0.12402 (QuantReg: 11.11136) QuantErr: 11.11136 batch_time=0.44055 
Train Epoch: 5 [449/500 28736/32000 (90%)] Loss: 0.17298 (QuantReg: 10.68180) QuantErr: 10.68180 batch_time=0.43415 
Train Epoch: 5 [457/500 29248/32000 (91%)] Loss: 0.16275 (QuantReg: 11.02382) QuantErr: 11.02382 batch_time=0.43334 
Train Epoch: 5 [465/500 29760/32000 (93%)] Loss: 0.23387 (QuantReg: 10.86831) QuantErr: 10.86831 batch_time=0.43400 
Train Epoch: 5 [473/500 30272/32000 (95%)] Loss: 0.18054 (QuantReg: 11.39383) QuantErr: 11.39383 batch_time=0.43523 
Train Epoch: 5 [481/500 30784/32000 (96%)] Loss: 0.13112 (QuantReg: 11.02951) QuantErr: 11.02951 batch_time=0.46992 
Train Epoch: 5 [489/500 31296/32000 (98%)] Loss: 0.11395 (QuantReg: 11.52053) QuantErr: 11.52053 batch_time=0.42833 
Train Epoch: 5 [497/500 31808/32000 (99%)] Loss: 0.12778 (QuantReg: 11.05574) QuantErr: 11.05574 batch_time=0.44763 
Train Epoch: 5 codebook_update_time=1.66809
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_ActivityNet_bs64/checkpoint-epoch5.pth ...
Done in 4.763s
Updating 'best' checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_ActivityNet_bs64/checkpoint-epoch5.pth ...
Done in 8.427s
removing stale ckpt [epoch 4] [took 0.00s]
 epoch          : 5
 loss           : 0.17780708983540536
 quant_reg      : 10.778248008728028
 quant_err      : 10.778248008728028
 learning_rate  : 3.6125000000000004e-05
 n_samples      : 160000
 n_steps        : 2500
 ActivityNet_val1_test/t2v_metrics/R1: 15.659955257270694
 ActivityNet_val1_test/t2v_metrics/R5: 42.42424242424242
 ActivityNet_val1_test/t2v_metrics/R10: 59.99593247915396
 ActivityNet_val1_test/t2v_metrics/R50: 91.376855806386
 ActivityNet_val1_test/t2v_metrics/MedR: 7.0
 ActivityNet_val1_test/t2v_metrics/MeanR: 25.778726865975187
 ActivityNet_val1_test/t2v_metrics/geometric_mean_R1-R5-R10: 34.15928775673267
 ActivityNet_val1_test/v2t_metrics/R1: 15.965019320724018
 ActivityNet_val1_test/v2t_metrics/R5: 43.74618669920683
 ActivityNet_val1_test/v2t_metrics/R10: 61.7246288387228
 ActivityNet_val1_test/v2t_metrics/R50: 91.82428309945088
 ActivityNet_val1_test/v2t_metrics/MedR: 7.0
 ActivityNet_val1_test/v2t_metrics/MeanR: 25.051860890787065
 ActivityNet_val1_test/v2t_metrics/geometric_mean_R1-R5-R10: 35.06356306931447
 mnt_best       : 34.15928775673267
 not_improved_count: 0
Train Epoch: 6 [1/500 64/32000 (0%)] Loss: 0.19443 (QuantReg: 10.73992) QuantErr: 10.73992 batch_time=23.54455 
Train Epoch: 6 [9/500 576/32000 (2%)] Loss: 0.15517 (QuantReg: 10.26380) QuantErr: 10.26380 batch_time=0.43502 
Train Epoch: 6 [17/500 1088/32000 (3%)] Loss: 0.15631 (QuantReg: 10.70610) QuantErr: 10.70610 batch_time=0.43506 
Train Epoch: 6 [25/500 1600/32000 (5%)] Loss: 0.11941 (QuantReg: 10.68809) QuantErr: 10.68809 batch_time=0.43604 
Train Epoch: 6 [33/500 2112/32000 (7%)] Loss: 0.12116 (QuantReg: 10.46775) QuantErr: 10.46775 batch_time=0.61732 
Train Epoch: 6 [41/500 2624/32000 (8%)] Loss: 0.18813 (QuantReg: 10.29799) QuantErr: 10.29799 batch_time=0.66069 
Train Epoch: 6 [49/500 3136/32000 (10%)] Loss: 0.25467 (QuantReg: 10.45523) QuantErr: 10.45523 batch_time=0.43092 
Train Epoch: 6 [57/500 3648/32000 (11%)] Loss: 0.34152 (QuantReg: 10.58192) QuantErr: 10.58192 batch_time=0.43480 
Train Epoch: 6 [65/500 4160/32000 (13%)] Loss: 0.16110 (QuantReg: 10.65464) QuantErr: 10.65464 batch_time=0.44189 
Train Epoch: 6 [73/500 4672/32000 (15%)] Loss: 0.22827 (QuantReg: 10.41096) QuantErr: 10.41096 batch_time=0.43523 
Train Epoch: 6 [81/500 5184/32000 (16%)] Loss: 0.14081 (QuantReg: 10.56411) QuantErr: 10.56411 batch_time=0.44272 
Train Epoch: 6 [89/500 5696/32000 (18%)] Loss: 0.22655 (QuantReg: 10.85612) QuantErr: 10.85612 batch_time=0.43739 
Train Epoch: 6 [97/500 6208/32000 (19%)] Loss: 0.18192 (QuantReg: 10.39497) QuantErr: 10.39497 batch_time=0.59598 
Train Epoch: 6 [105/500 6720/32000 (21%)] Loss: 0.20877 (QuantReg: 10.72946) QuantErr: 10.72946 batch_time=0.59381 
Train Epoch: 6 [113/500 7232/32000 (23%)] Loss: 0.14428 (QuantReg: 10.76588) QuantErr: 10.76588 batch_time=0.43873 
Train Epoch: 6 [121/500 7744/32000 (24%)] Loss: 0.08727 (QuantReg: 10.69525) QuantErr: 10.69525 batch_time=0.44349 
Train Epoch: 6 [129/500 8256/32000 (26%)] Loss: 0.10754 (QuantReg: 10.64569) QuantErr: 10.64569 batch_time=0.44433 
Train Epoch: 6 [137/500 8768/32000 (27%)] Loss: 0.12493 (QuantReg: 11.17598) QuantErr: 11.17598 batch_time=0.43958 
Train Epoch: 6 [145/500 9280/32000 (29%)] Loss: 0.10857 (QuantReg: 11.05760) QuantErr: 11.05760 batch_time=0.44001 
Train Epoch: 6 [153/500 9792/32000 (31%)] Loss: 0.13062 (QuantReg: 10.62638) QuantErr: 10.62638 batch_time=0.43618 
Train Epoch: 6 [161/500 10304/32000 (32%)] Loss: 0.17111 (QuantReg: 10.60595) QuantErr: 10.60595 batch_time=0.59718 
Train Epoch: 6 [169/500 10816/32000 (34%)] Loss: 0.20783 (QuantReg: 11.12497) QuantErr: 11.12497 batch_time=0.60353 
Train Epoch: 6 [177/500 11328/32000 (35%)] Loss: 0.17495 (QuantReg: 10.66512) QuantErr: 10.66512 batch_time=0.43272 
Train Epoch: 6 [185/500 11840/32000 (37%)] Loss: 0.23910 (QuantReg: 10.53741) QuantErr: 10.53741 batch_time=0.43558 
Train Epoch: 6 [193/500 12352/32000 (39%)] Loss: 0.18836 (QuantReg: 10.70690) QuantErr: 10.70690 batch_time=0.43696 
Train Epoch: 6 [201/500 12864/32000 (40%)] Loss: 0.18609 (QuantReg: 10.99919) QuantErr: 10.99919 batch_time=0.45367 
Train Epoch: 6 [209/500 13376/32000 (42%)] Loss: 0.19375 (QuantReg: 10.72075) QuantErr: 10.72075 batch_time=0.48123 
Train Epoch: 6 [217/500 13888/32000 (43%)] Loss: 0.11751 (QuantReg: 10.92525) QuantErr: 10.92525 batch_time=0.44562 
Train Epoch: 6 [225/500 14400/32000 (45%)] Loss: 0.24624 (QuantReg: 11.00934) QuantErr: 11.00934 batch_time=0.61568 
Train Epoch: 6 [233/500 14912/32000 (47%)] Loss: 0.15801 (QuantReg: 10.57636) QuantErr: 10.57636 batch_time=0.64081 
Train Epoch: 6 [241/500 15424/32000 (48%)] Loss: 0.19955 (QuantReg: 10.80214) QuantErr: 10.80214 batch_time=0.46334 
Train Epoch: 6 [249/500 15936/32000 (50%)] Loss: 0.17799 (QuantReg: 10.75019) QuantErr: 10.75019 batch_time=0.44791 
Train Epoch: 6 [257/500 16448/32000 (51%)] Loss: 0.17378 (QuantReg: 10.61813) QuantErr: 10.61813 batch_time=0.43980 
Train Epoch: 6 [265/500 16960/32000 (53%)] Loss: 0.18941 (QuantReg: 10.64413) QuantErr: 10.64413 batch_time=0.44444 
Train Epoch: 6 [273/500 17472/32000 (55%)] Loss: 0.22122 (QuantReg: 10.77298) QuantErr: 10.77298 batch_time=0.43763 
Train Epoch: 6 [281/500 17984/32000 (56%)] Loss: 0.17229 (QuantReg: 10.72384) QuantErr: 10.72384 batch_time=0.44168 
Train Epoch: 6 [289/500 18496/32000 (58%)] Loss: 0.18959 (QuantReg: 10.73426) QuantErr: 10.73426 batch_time=0.60899 
Train Epoch: 6 [297/500 19008/32000 (59%)] Loss: 0.16687 (QuantReg: 10.90883) QuantErr: 10.90883 batch_time=0.65076 
Train Epoch: 6 [305/500 19520/32000 (61%)] Loss: 0.08038 (QuantReg: 10.94905) QuantErr: 10.94905 batch_time=0.47756 
Train Epoch: 6 [313/500 20032/32000 (63%)] Loss: 0.24151 (QuantReg: 10.72030) QuantErr: 10.72030 batch_time=0.45327 
Train Epoch: 6 [321/500 20544/32000 (64%)] Loss: 0.16828 (QuantReg: 10.95769) QuantErr: 10.95769 batch_time=0.44750 
Train Epoch: 6 [329/500 21056/32000 (66%)] Loss: 0.13413 (QuantReg: 10.82130) QuantErr: 10.82130 batch_time=0.44325 
Train Epoch: 6 [337/500 21568/32000 (67%)] Loss: 0.11289 (QuantReg: 10.78587) QuantErr: 10.78587 batch_time=0.44960 
Train Epoch: 6 [345/500 22080/32000 (69%)] Loss: 0.12450 (QuantReg: 11.16088) QuantErr: 11.16088 batch_time=0.45245 
Train Epoch: 6 [353/500 22592/32000 (71%)] Loss: 0.10545 (QuantReg: 10.76685) QuantErr: 10.76685 batch_time=0.61673 
Train Epoch: 6 [361/500 23104/32000 (72%)] Loss: 0.22361 (QuantReg: 10.59281) QuantErr: 10.59281 batch_time=0.61894 
Train Epoch: 6 [369/500 23616/32000 (74%)] Loss: 0.22367 (QuantReg: 11.38853) QuantErr: 11.38853 batch_time=0.44602 
Train Epoch: 6 [377/500 24128/32000 (75%)] Loss: 0.14112 (QuantReg: 10.69026) QuantErr: 10.69026 batch_time=0.44957 
Train Epoch: 6 [385/500 24640/32000 (77%)] Loss: 0.13163 (QuantReg: 10.85526) QuantErr: 10.85526 batch_time=0.44744 
Train Epoch: 6 [393/500 25152/32000 (79%)] Loss: 0.13534 (QuantReg: 10.92420) QuantErr: 10.92420 batch_time=0.44674 
Train Epoch: 6 [401/500 25664/32000 (80%)] Loss: 0.23201 (QuantReg: 10.34180) QuantErr: 10.34180 batch_time=0.44852 
Train Epoch: 6 [409/500 26176/32000 (82%)] Loss: 0.11316 (QuantReg: 10.70067) QuantErr: 10.70067 batch_time=0.44643 
Train Epoch: 6 [417/500 26688/32000 (83%)] Loss: 0.13033 (QuantReg: 10.63125) QuantErr: 10.63125 batch_time=0.59666 
Train Epoch: 6 [425/500 27200/32000 (85%)] Loss: 0.16141 (QuantReg: 10.60937) QuantErr: 10.60937 batch_time=0.62940 
Train Epoch: 6 [433/500 27712/32000 (87%)] Loss: 0.16288 (QuantReg: 10.90672) QuantErr: 10.90672 batch_time=0.45031 
Train Epoch: 6 [441/500 28224/32000 (88%)] Loss: 0.19501 (QuantReg: 10.94549) QuantErr: 10.94549 batch_time=0.45183 
Train Epoch: 6 [449/500 28736/32000 (90%)] Loss: 0.17285 (QuantReg: 10.55149) QuantErr: 10.55149 batch_time=0.45527 
Train Epoch: 6 [457/500 29248/32000 (91%)] Loss: 0.12986 (QuantReg: 11.25691) QuantErr: 11.25691 batch_time=0.44852 
Train Epoch: 6 [465/500 29760/32000 (93%)] Loss: 0.11187 (QuantReg: 11.05970) QuantErr: 11.05970 batch_time=0.44572 
Train Epoch: 6 [473/500 30272/32000 (95%)] Loss: 0.11966 (QuantReg: 10.97981) QuantErr: 10.97981 batch_time=0.44821 
Train Epoch: 6 [481/500 30784/32000 (96%)] Loss: 0.12350 (QuantReg: 11.30135) QuantErr: 11.30135 batch_time=0.61899 
Train Epoch: 6 [489/500 31296/32000 (98%)] Loss: 0.18008 (QuantReg: 10.68379) QuantErr: 10.68379 batch_time=0.61792 
Train Epoch: 6 [497/500 31808/32000 (99%)] Loss: 0.21449 (QuantReg: 10.93660) QuantErr: 10.93660 batch_time=0.45324 
Train Epoch: 6 codebook_update_time=1.72323
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_ActivityNet_bs64/checkpoint-epoch6.pth ...
Done in 4.232s
Updating 'best' checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_ActivityNet_bs64/checkpoint-epoch6.pth ...
Done in 8.849s
removing stale ckpt [epoch 5] [took 0.01s]
 epoch          : 6
 loss           : 0.1595266472324729
 quant_reg      : 10.792181676864624
 quant_err      : 10.792181676864624
 learning_rate  : 3.6125000000000004e-05
 n_samples      : 192000
 n_steps        : 3000
 ActivityNet_val1_test/t2v_metrics/R1: 15.74130567419158
 ActivityNet_val1_test/t2v_metrics/R5: 43.380109823062845
 ActivityNet_val1_test/t2v_metrics/R10: 61.15517592027659
 ActivityNet_val1_test/t2v_metrics/R50: 91.29550538946512
 ActivityNet_val1_test/t2v_metrics/MedR: 7.0
 ActivityNet_val1_test/t2v_metrics/MeanR: 25.984950172869635
 ActivityNet_val1_test/t2v_metrics/geometric_mean_R1-R5-R10: 34.69403986065813
 ActivityNet_val1_test/v2t_metrics/R1: 16.758185885702666
 ActivityNet_val1_test/v2t_metrics/R5: 44.90543014032947
 ActivityNet_val1_test/v2t_metrics/R10: 62.151718527557456
 ActivityNet_val1_test/v2t_metrics/R50: 92.17002237136465
 ActivityNet_val1_test/v2t_metrics/MedR: 7.0
 ActivityNet_val1_test/v2t_metrics/MeanR: 24.959833231645312
 ActivityNet_val1_test/v2t_metrics/geometric_mean_R1-R5-R10: 36.029618913201624
 mnt_best       : 34.69403986065813
 not_improved_count: 0
Train Epoch: 7 [1/500 64/32000 (0%)] Loss: 0.09704 (QuantReg: 10.49316) QuantErr: 10.49316 batch_time=24.43721 
Train Epoch: 7 [9/500 576/32000 (2%)] Loss: 0.12900 (QuantReg: 10.85610) QuantErr: 10.85610 batch_time=0.47123 
Train Epoch: 7 [17/500 1088/32000 (3%)] Loss: 0.10922 (QuantReg: 11.00590) QuantErr: 11.00590 batch_time=0.49107 
Train Epoch: 7 [25/500 1600/32000 (5%)] Loss: 0.17490 (QuantReg: 10.18777) QuantErr: 10.18777 batch_time=0.44900 
Train Epoch: 7 [33/500 2112/32000 (7%)] Loss: 0.10345 (QuantReg: 10.37253) QuantErr: 10.37253 batch_time=0.44786 
Train Epoch: 7 [41/500 2624/32000 (8%)] Loss: 0.10339 (QuantReg: 10.49200) QuantErr: 10.49200 batch_time=0.44787 
Train Epoch: 7 [49/500 3136/32000 (10%)] Loss: 0.15855 (QuantReg: 10.54745) QuantErr: 10.54745 batch_time=0.44993 
Train Epoch: 7 [57/500 3648/32000 (11%)] Loss: 0.10423 (QuantReg: 10.99332) QuantErr: 10.99332 batch_time=0.43997 
Train Epoch: 7 [65/500 4160/32000 (13%)] Loss: 0.10730 (QuantReg: 10.91005) QuantErr: 10.91005 batch_time=0.64946 
Train Epoch: 7 [73/500 4672/32000 (15%)] Loss: 0.12108 (QuantReg: 10.92254) QuantErr: 10.92254 batch_time=0.46931 
Train Epoch: 7 [81/500 5184/32000 (16%)] Loss: 0.16159 (QuantReg: 10.59173) QuantErr: 10.59173 batch_time=0.47555 
Train Epoch: 7 [89/500 5696/32000 (18%)] Loss: 0.11138 (QuantReg: 10.62034) QuantErr: 10.62034 batch_time=0.44768 
Train Epoch: 7 [97/500 6208/32000 (19%)] Loss: 0.15643 (QuantReg: 10.94290) QuantErr: 10.94290 batch_time=0.44085 
Train Epoch: 7 [105/500 6720/32000 (21%)] Loss: 0.21477 (QuantReg: 10.38681) QuantErr: 10.38681 batch_time=0.43479 
Train Epoch: 7 [113/500 7232/32000 (23%)] Loss: 0.06851 (QuantReg: 10.46452) QuantErr: 10.46452 batch_time=0.44106 
Train Epoch: 7 [121/500 7744/32000 (24%)] Loss: 0.17253 (QuantReg: 11.06437) QuantErr: 11.06437 batch_time=0.43105 
Train Epoch: 7 [129/500 8256/32000 (26%)] Loss: 0.13254 (QuantReg: 10.96112) QuantErr: 10.96112 batch_time=0.62601 
Train Epoch: 7 [137/500 8768/32000 (27%)] Loss: 0.06908 (QuantReg: 10.75589) QuantErr: 10.75589 batch_time=0.52493 
Train Epoch: 7 [145/500 9280/32000 (29%)] Loss: 0.19648 (QuantReg: 10.50917) QuantErr: 10.50917 batch_time=0.47633 
Train Epoch: 7 [153/500 9792/32000 (31%)] Loss: 0.11552 (QuantReg: 10.51240) QuantErr: 10.51240 batch_time=0.44160 
Train Epoch: 7 [161/500 10304/32000 (32%)] Loss: 0.11583 (QuantReg: 10.46801) QuantErr: 10.46801 batch_time=0.44849 
Train Epoch: 7 [169/500 10816/32000 (34%)] Loss: 0.16549 (QuantReg: 10.44192) QuantErr: 10.44192 batch_time=0.44262 
Train Epoch: 7 [177/500 11328/32000 (35%)] Loss: 0.14546 (QuantReg: 10.68585) QuantErr: 10.68585 batch_time=0.44518 
Train Epoch: 7 [185/500 11840/32000 (37%)] Loss: 0.15287 (QuantReg: 10.58775) QuantErr: 10.58775 batch_time=0.43368 
Train Epoch: 7 [193/500 12352/32000 (39%)] Loss: 0.12410 (QuantReg: 10.43377) QuantErr: 10.43377 batch_time=0.64405 
Train Epoch: 7 [201/500 12864/32000 (40%)] Loss: 0.12400 (QuantReg: 10.82856) QuantErr: 10.82856 batch_time=0.47551 
Train Epoch: 7 [209/500 13376/32000 (42%)] Loss: 0.10025 (QuantReg: 10.74147) QuantErr: 10.74147 batch_time=0.48246 
Train Epoch: 7 [217/500 13888/32000 (43%)] Loss: 0.15438 (QuantReg: 10.99773) QuantErr: 10.99773 batch_time=0.44630 
Train Epoch: 7 [225/500 14400/32000 (45%)] Loss: 0.17559 (QuantReg: 10.81037) QuantErr: 10.81037 batch_time=0.44680 
Train Epoch: 7 [233/500 14912/32000 (47%)] Loss: 0.09291 (QuantReg: 10.30277) QuantErr: 10.30277 batch_time=0.44181 
Train Epoch: 7 [241/500 15424/32000 (48%)] Loss: 0.14372 (QuantReg: 10.58403) QuantErr: 10.58403 batch_time=0.48488 
Train Epoch: 7 [249/500 15936/32000 (50%)] Loss: 0.14310 (QuantReg: 10.83456) QuantErr: 10.83456 batch_time=0.44013 
Train Epoch: 7 [257/500 16448/32000 (51%)] Loss: 0.08741 (QuantReg: 10.49801) QuantErr: 10.49801 batch_time=0.64434 
Train Epoch: 7 [265/500 16960/32000 (53%)] Loss: 0.11062 (QuantReg: 10.61164) QuantErr: 10.61164 batch_time=0.47633 
Train Epoch: 7 [273/500 17472/32000 (55%)] Loss: 0.22483 (QuantReg: 10.70112) QuantErr: 10.70112 batch_time=0.47922 
Train Epoch: 7 [281/500 17984/32000 (56%)] Loss: 0.11811 (QuantReg: 10.88297) QuantErr: 10.88297 batch_time=0.44193 
Train Epoch: 7 [289/500 18496/32000 (58%)] Loss: 0.13587 (QuantReg: 10.63014) QuantErr: 10.63014 batch_time=0.44572 
Train Epoch: 7 [297/500 19008/32000 (59%)] Loss: 0.10072 (QuantReg: 11.32237) QuantErr: 11.32237 batch_time=0.43769 
Train Epoch: 7 [305/500 19520/32000 (61%)] Loss: 0.16318 (QuantReg: 10.34722) QuantErr: 10.34722 batch_time=0.48989 
Train Epoch: 7 [313/500 20032/32000 (63%)] Loss: 0.13148 (QuantReg: 10.90995) QuantErr: 10.90995 batch_time=0.43819 
Train Epoch: 7 [321/500 20544/32000 (64%)] Loss: 0.19340 (QuantReg: 10.81755) QuantErr: 10.81755 batch_time=0.62891 
Train Epoch: 7 [329/500 21056/32000 (66%)] Loss: 0.07983 (QuantReg: 10.79370) QuantErr: 10.79370 batch_time=0.47560 
Train Epoch: 7 [337/500 21568/32000 (67%)] Loss: 0.06353 (QuantReg: 11.11154) QuantErr: 11.11154 batch_time=0.47347 
Train Epoch: 7 [345/500 22080/32000 (69%)] Loss: 0.06114 (QuantReg: 11.28543) QuantErr: 11.28543 batch_time=0.44780 
Train Epoch: 7 [353/500 22592/32000 (71%)] Loss: 0.13821 (QuantReg: 10.88274) QuantErr: 10.88274 batch_time=0.44244 
Train Epoch: 7 [361/500 23104/32000 (72%)] Loss: 0.13396 (QuantReg: 10.31671) QuantErr: 10.31671 batch_time=0.46069 
Train Epoch: 7 [369/500 23616/32000 (74%)] Loss: 0.07312 (QuantReg: 10.65281) QuantErr: 10.65281 batch_time=0.44689 
Train Epoch: 7 [377/500 24128/32000 (75%)] Loss: 0.11083 (QuantReg: 10.86351) QuantErr: 10.86351 batch_time=0.44713 
Train Epoch: 7 [385/500 24640/32000 (77%)] Loss: 0.18558 (QuantReg: 10.67930) QuantErr: 10.67930 batch_time=0.67042 
Train Epoch: 7 [393/500 25152/32000 (79%)] Loss: 0.05921 (QuantReg: 10.80960) QuantErr: 10.80960 batch_time=0.48169 
Train Epoch: 7 [401/500 25664/32000 (80%)] Loss: 0.13633 (QuantReg: 10.86471) QuantErr: 10.86471 batch_time=0.47853 
Train Epoch: 7 [409/500 26176/32000 (82%)] Loss: 0.05893 (QuantReg: 10.84523) QuantErr: 10.84523 batch_time=0.45585 
Train Epoch: 7 [417/500 26688/32000 (83%)] Loss: 0.10689 (QuantReg: 10.84120) QuantErr: 10.84120 batch_time=0.44281 
Train Epoch: 7 [425/500 27200/32000 (85%)] Loss: 0.10912 (QuantReg: 10.58088) QuantErr: 10.58088 batch_time=0.45289 
Train Epoch: 7 [433/500 27712/32000 (87%)] Loss: 0.11033 (QuantReg: 11.20600) QuantErr: 11.20600 batch_time=0.45147 
Train Epoch: 7 [441/500 28224/32000 (88%)] Loss: 0.17868 (QuantReg: 11.03239) QuantErr: 11.03239 batch_time=0.46210 
Train Epoch: 7 [449/500 28736/32000 (90%)] Loss: 0.09399 (QuantReg: 11.13415) QuantErr: 11.13415 batch_time=0.68104 
Train Epoch: 7 [457/500 29248/32000 (91%)] Loss: 0.11696 (QuantReg: 10.73288) QuantErr: 10.73288 batch_time=0.48094 
Train Epoch: 7 [465/500 29760/32000 (93%)] Loss: 0.12474 (QuantReg: 10.71038) QuantErr: 10.71038 batch_time=0.49415 
Train Epoch: 7 [473/500 30272/32000 (95%)] Loss: 0.12535 (QuantReg: 10.83793) QuantErr: 10.83793 batch_time=0.45413 
Train Epoch: 7 [481/500 30784/32000 (96%)] Loss: 0.14174 (QuantReg: 10.72293) QuantErr: 10.72293 batch_time=0.43990 
Train Epoch: 7 [489/500 31296/32000 (98%)] Loss: 0.07962 (QuantReg: 10.76503) QuantErr: 10.76503 batch_time=0.43733 
Train Epoch: 7 [497/500 31808/32000 (99%)] Loss: 0.10783 (QuantReg: 10.66794) QuantErr: 10.66794 batch_time=0.45295 
Train Epoch: 7 codebook_update_time=1.83324
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_ActivityNet_bs64/checkpoint-epoch7.pth ...
Done in 3.955s
removing stale ckpt [epoch 6] [took 0.47s]
 epoch          : 7
 loss           : 0.12992934752255678
 quant_reg      : 10.763591983795166
 quant_err      : 10.763591983795166
 learning_rate  : 3.0706250000000004e-05
 n_samples      : 224000
 n_steps        : 3500
 ActivityNet_val1_test/t2v_metrics/R1: 15.110839943054708
 ActivityNet_val1_test/t2v_metrics/R5: 43.542810656904614
 ActivityNet_val1_test/t2v_metrics/R10: 61.826316859873906
 ActivityNet_val1_test/t2v_metrics/R50: 91.39719341061623
 ActivityNet_val1_test/t2v_metrics/MedR: 7.0
 ActivityNet_val1_test/t2v_metrics/MeanR: 26.011185682326623
 ActivityNet_val1_test/t2v_metrics/geometric_mean_R1-R5-R10: 34.392162168455144
 ActivityNet_val1_test/v2t_metrics/R1: 16.94122432377466
 ActivityNet_val1_test/v2t_metrics/R5: 45.800284726459225
 ActivityNet_val1_test/v2t_metrics/R10: 63.57535082367297
 ActivityNet_val1_test/v2t_metrics/R50: 91.88529591214154
 ActivityNet_val1_test/v2t_metrics/MedR: 6.0
 ActivityNet_val1_test/v2t_metrics/MeanR: 24.925360992475085
 ActivityNet_val1_test/v2t_metrics/geometric_mean_R1-R5-R10: 36.6747570417558
 mnt_best       : 34.69403986065813
 not_improved_count: 1
Train Epoch: 8 [1/500 64/32000 (0%)] Loss: 0.09685 (QuantReg: 10.45446) QuantErr: 10.45446 batch_time=23.52926 
Train Epoch: 8 [9/500 576/32000 (2%)] Loss: 0.17109 (QuantReg: 10.47085) QuantErr: 10.47085 batch_time=0.43912 
Train Epoch: 8 [17/500 1088/32000 (3%)] Loss: 0.13079 (QuantReg: 11.10093) QuantErr: 11.10093 batch_time=1.81008 
Train Epoch: 8 [25/500 1600/32000 (5%)] Loss: 0.14400 (QuantReg: 10.73205) QuantErr: 10.73205 batch_time=0.43963 
Train Epoch: 8 [33/500 2112/32000 (7%)] Loss: 0.12962 (QuantReg: 10.63404) QuantErr: 10.63404 batch_time=0.43894 
Train Epoch: 8 [41/500 2624/32000 (8%)] Loss: 0.17311 (QuantReg: 10.72897) QuantErr: 10.72897 batch_time=0.44882 
Train Epoch: 8 [49/500 3136/32000 (10%)] Loss: 0.24176 (QuantReg: 10.92377) QuantErr: 10.92377 batch_time=0.44269 
Train Epoch: 8 [57/500 3648/32000 (11%)] Loss: 0.11962 (QuantReg: 10.91237) QuantErr: 10.91237 batch_time=0.44291 
Train Epoch: 8 [65/500 4160/32000 (13%)] Loss: 0.10775 (QuantReg: 10.93327) QuantErr: 10.93327 batch_time=0.63718 
Train Epoch: 8 [73/500 4672/32000 (15%)] Loss: 0.15581 (QuantReg: 11.15445) QuantErr: 11.15445 batch_time=0.43741 
Train Epoch: 8 [81/500 5184/32000 (16%)] Loss: 0.17137 (QuantReg: 10.35590) QuantErr: 10.35590 batch_time=1.38468 
Train Epoch: 8 [89/500 5696/32000 (18%)] Loss: 0.10975 (QuantReg: 10.60612) QuantErr: 10.60612 batch_time=0.43771 
Train Epoch: 8 [97/500 6208/32000 (19%)] Loss: 0.11793 (QuantReg: 10.65908) QuantErr: 10.65908 batch_time=0.45120 
Train Epoch: 8 [105/500 6720/32000 (21%)] Loss: 0.10585 (QuantReg: 10.63674) QuantErr: 10.63674 batch_time=0.44202 
Train Epoch: 8 [113/500 7232/32000 (23%)] Loss: 0.18324 (QuantReg: 10.85975) QuantErr: 10.85975 batch_time=0.43994 
Train Epoch: 8 [121/500 7744/32000 (24%)] Loss: 0.16566 (QuantReg: 10.83301) QuantErr: 10.83301 batch_time=0.44208 
Train Epoch: 8 [129/500 8256/32000 (26%)] Loss: 0.17084 (QuantReg: 10.38396) QuantErr: 10.38396 batch_time=0.67615 
Train Epoch: 8 [137/500 8768/32000 (27%)] Loss: 0.08042 (QuantReg: 10.67128) QuantErr: 10.67128 batch_time=0.45092 
Train Epoch: 8 [145/500 9280/32000 (29%)] Loss: 0.17392 (QuantReg: 10.99837) QuantErr: 10.99837 batch_time=1.63270 
Train Epoch: 8 [153/500 9792/32000 (31%)] Loss: 0.14059 (QuantReg: 10.71436) QuantErr: 10.71436 batch_time=0.49904 
Train Epoch: 8 [161/500 10304/32000 (32%)] Loss: 0.10058 (QuantReg: 10.56208) QuantErr: 10.56208 batch_time=0.44755 
Train Epoch: 8 [169/500 10816/32000 (34%)] Loss: 0.06977 (QuantReg: 11.20388) QuantErr: 11.20388 batch_time=0.46438 
Train Epoch: 8 [177/500 11328/32000 (35%)] Loss: 0.17418 (QuantReg: 10.43228) QuantErr: 10.43228 batch_time=0.44718 
Train Epoch: 8 [185/500 11840/32000 (37%)] Loss: 0.09744 (QuantReg: 10.58468) QuantErr: 10.58468 batch_time=0.44529 
Train Epoch: 8 [193/500 12352/32000 (39%)] Loss: 0.09072 (QuantReg: 10.68986) QuantErr: 10.68986 batch_time=0.65175 
Train Epoch: 8 [201/500 12864/32000 (40%)] Loss: 0.08356 (QuantReg: 10.86297) QuantErr: 10.86297 batch_time=0.43817 
Train Epoch: 8 [209/500 13376/32000 (42%)] Loss: 0.08190 (QuantReg: 10.87605) QuantErr: 10.87605 batch_time=1.45641 
Train Epoch: 8 [217/500 13888/32000 (43%)] Loss: 0.09265 (QuantReg: 10.83875) QuantErr: 10.83875 batch_time=0.44421 
Train Epoch: 8 [225/500 14400/32000 (45%)] Loss: 0.12076 (QuantReg: 10.25227) QuantErr: 10.25227 batch_time=0.45150 
Train Epoch: 8 [233/500 14912/32000 (47%)] Loss: 0.23078 (QuantReg: 10.56816) QuantErr: 10.56816 batch_time=0.45170 
Train Epoch: 8 [241/500 15424/32000 (48%)] Loss: 0.09514 (QuantReg: 10.58318) QuantErr: 10.58318 batch_time=0.44182 
Train Epoch: 8 [249/500 15936/32000 (50%)] Loss: 0.07333 (QuantReg: 10.70683) QuantErr: 10.70683 batch_time=0.45027 
Train Epoch: 8 [257/500 16448/32000 (51%)] Loss: 0.09858 (QuantReg: 10.54245) QuantErr: 10.54245 batch_time=0.69713 
Train Epoch: 8 [265/500 16960/32000 (53%)] Loss: 0.11249 (QuantReg: 10.86164) QuantErr: 10.86164 batch_time=0.45203 
Train Epoch: 8 [273/500 17472/32000 (55%)] Loss: 0.07778 (QuantReg: 10.75832) QuantErr: 10.75832 batch_time=1.39641 
Train Epoch: 8 [281/500 17984/32000 (56%)] Loss: 0.13890 (QuantReg: 10.84099) QuantErr: 10.84099 batch_time=0.44490 
Train Epoch: 8 [289/500 18496/32000 (58%)] Loss: 0.07823 (QuantReg: 10.67339) QuantErr: 10.67339 batch_time=0.44398 
Train Epoch: 8 [297/500 19008/32000 (59%)] Loss: 0.11431 (QuantReg: 10.78340) QuantErr: 10.78340 batch_time=0.44630 
Train Epoch: 8 [305/500 19520/32000 (61%)] Loss: 0.17722 (QuantReg: 10.98640) QuantErr: 10.98640 batch_time=0.47933 
Train Epoch: 8 [313/500 20032/32000 (63%)] Loss: 0.07494 (QuantReg: 11.16432) QuantErr: 11.16432 batch_time=0.46380 
Train Epoch: 8 [321/500 20544/32000 (64%)] Loss: 0.14744 (QuantReg: 10.77626) QuantErr: 10.77626 batch_time=0.64787 
Train Epoch: 8 [329/500 21056/32000 (66%)] Loss: 0.08522 (QuantReg: 11.05707) QuantErr: 11.05707 batch_time=0.43949 
Train Epoch: 8 [337/500 21568/32000 (67%)] Loss: 0.10111 (QuantReg: 10.90172) QuantErr: 10.90172 batch_time=1.41330 
Train Epoch: 8 [345/500 22080/32000 (69%)] Loss: 0.08620 (QuantReg: 10.76810) QuantErr: 10.76810 batch_time=0.45203 
Train Epoch: 8 [353/500 22592/32000 (71%)] Loss: 0.06339 (QuantReg: 10.84906) QuantErr: 10.84906 batch_time=0.45055 
Train Epoch: 8 [361/500 23104/32000 (72%)] Loss: 0.11304 (QuantReg: 10.78549) QuantErr: 10.78549 batch_time=0.48066 
Train Epoch: 8 [369/500 23616/32000 (74%)] Loss: 0.22352 (QuantReg: 10.67672) QuantErr: 10.67672 batch_time=0.47850 
Train Epoch: 8 [377/500 24128/32000 (75%)] Loss: 0.15618 (QuantReg: 10.79058) QuantErr: 10.79058 batch_time=0.44309 
Train Epoch: 8 [385/500 24640/32000 (77%)] Loss: 0.13974 (QuantReg: 10.15665) QuantErr: 10.15665 batch_time=0.66366 
Train Epoch: 8 [393/500 25152/32000 (79%)] Loss: 0.13473 (QuantReg: 10.90666) QuantErr: 10.90666 batch_time=0.48045 
Train Epoch: 8 [401/500 25664/32000 (80%)] Loss: 0.10541 (QuantReg: 10.58012) QuantErr: 10.58012 batch_time=1.50064 
Train Epoch: 8 [409/500 26176/32000 (82%)] Loss: 0.12289 (QuantReg: 10.99899) QuantErr: 10.99899 batch_time=0.45424 
Train Epoch: 8 [417/500 26688/32000 (83%)] Loss: 0.08157 (QuantReg: 11.03294) QuantErr: 11.03294 batch_time=0.44373 
Train Epoch: 8 [425/500 27200/32000 (85%)] Loss: 0.22861 (QuantReg: 10.83061) QuantErr: 10.83061 batch_time=0.44591 
Train Epoch: 8 [433/500 27712/32000 (87%)] Loss: 0.11655 (QuantReg: 11.18982) QuantErr: 11.18982 batch_time=0.44867 
Train Epoch: 8 [441/500 28224/32000 (88%)] Loss: 0.10689 (QuantReg: 10.72007) QuantErr: 10.72007 batch_time=0.47740 
Train Epoch: 8 [449/500 28736/32000 (90%)] Loss: 0.20061 (QuantReg: 10.38824) QuantErr: 10.38824 batch_time=0.64666 
Train Epoch: 8 [457/500 29248/32000 (91%)] Loss: 0.10211 (QuantReg: 11.28168) QuantErr: 11.28168 batch_time=0.44074 
Train Epoch: 8 [465/500 29760/32000 (93%)] Loss: 0.07625 (QuantReg: 10.96194) QuantErr: 10.96194 batch_time=1.47083 
Train Epoch: 8 [473/500 30272/32000 (95%)] Loss: 0.10806 (QuantReg: 10.73047) QuantErr: 10.73047 batch_time=0.44911 
Train Epoch: 8 [481/500 30784/32000 (96%)] Loss: 0.15183 (QuantReg: 10.97155) QuantErr: 10.97155 batch_time=0.45051 
Train Epoch: 8 [489/500 31296/32000 (98%)] Loss: 0.12262 (QuantReg: 10.71086) QuantErr: 10.71086 batch_time=0.44408 
Train Epoch: 8 [497/500 31808/32000 (99%)] Loss: 0.08480 (QuantReg: 10.63647) QuantErr: 10.63647 batch_time=0.44520 
Train Epoch: 8 codebook_update_time=1.71395
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_ActivityNet_bs64/checkpoint-epoch8.pth ...
Done in 5.079s
Updating 'best' checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_ActivityNet_bs64/checkpoint-epoch8.pth ...
Done in 10.010s
removing stale ckpt [epoch 7] [took 0.01s]
 epoch          : 8
 loss           : 0.12136694414168596
 quant_reg      : 10.834959915161132
 quant_err      : 10.834959915161132
 learning_rate  : 3.0706250000000004e-05
 n_samples      : 256000
 n_steps        : 4000
 ActivityNet_val1_test/t2v_metrics/R1: 15.61928004881025
 ActivityNet_val1_test/t2v_metrics/R5: 45.12914378686191
 ActivityNet_val1_test/t2v_metrics/R10: 62.55847061216189
 ActivityNet_val1_test/t2v_metrics/R50: 91.41753101484645
 ActivityNet_val1_test/t2v_metrics/MedR: 7.0
 ActivityNet_val1_test/t2v_metrics/MeanR: 23.870042708968885
 ActivityNet_val1_test/t2v_metrics/geometric_mean_R1-R5-R10: 35.32927642923768
 ActivityNet_val1_test/v2t_metrics/R1: 17.9174293268253
 ActivityNet_val1_test/v2t_metrics/R5: 45.67825910107789
 ActivityNet_val1_test/v2t_metrics/R10: 63.61602603213341
 ActivityNet_val1_test/v2t_metrics/R50: 91.90563351637176
 ActivityNet_val1_test/v2t_metrics/MedR: 6.0
 ActivityNet_val1_test/v2t_metrics/MeanR: 23.475696562944886
 ActivityNet_val1_test/v2t_metrics/geometric_mean_R1-R5-R10: 37.34082652117908
 mnt_best       : 35.32927642923768
 not_improved_count: 0
Train Epoch: 9 [1/500 64/32000 (0%)] Loss: 0.09106 (QuantReg: 10.68149) QuantErr: 10.68149 batch_time=24.39184 
Train Epoch: 9 [9/500 576/32000 (2%)] Loss: 0.09507 (QuantReg: 10.90082) QuantErr: 10.90082 batch_time=0.43881 
Train Epoch: 9 [17/500 1088/32000 (3%)] Loss: 0.08765 (QuantReg: 10.69934) QuantErr: 10.69934 batch_time=0.42937 
Train Epoch: 9 [25/500 1600/32000 (5%)] Loss: 0.15104 (QuantReg: 10.89473) QuantErr: 10.89473 batch_time=0.43995 
Train Epoch: 9 [33/500 2112/32000 (7%)] Loss: 0.14866 (QuantReg: 10.82577) QuantErr: 10.82577 batch_time=0.43718 
Train Epoch: 9 [41/500 2624/32000 (8%)] Loss: 0.08190 (QuantReg: 10.75660) QuantErr: 10.75660 batch_time=0.52203 
Train Epoch: 9 [49/500 3136/32000 (10%)] Loss: 0.11704 (QuantReg: 10.26471) QuantErr: 10.26471 batch_time=0.44582 
Train Epoch: 9 [57/500 3648/32000 (11%)] Loss: 0.09522 (QuantReg: 10.58959) QuantErr: 10.58959 batch_time=0.44194 
Train Epoch: 9 [65/500 4160/32000 (13%)] Loss: 0.10173 (QuantReg: 10.87994) QuantErr: 10.87994 batch_time=0.57922 
Train Epoch: 9 [73/500 4672/32000 (15%)] Loss: 0.12604 (QuantReg: 11.16294) QuantErr: 11.16294 batch_time=0.44991 
Train Epoch: 9 [81/500 5184/32000 (16%)] Loss: 0.07974 (QuantReg: 10.70484) QuantErr: 10.70484 batch_time=0.44481 
Train Epoch: 9 [89/500 5696/32000 (18%)] Loss: 0.14877 (QuantReg: 10.65412) QuantErr: 10.65412 batch_time=0.44604 
Train Epoch: 9 [97/500 6208/32000 (19%)] Loss: 0.17857 (QuantReg: 10.76158) QuantErr: 10.76158 batch_time=0.43861 
Train Epoch: 9 [105/500 6720/32000 (21%)] Loss: 0.07012 (QuantReg: 11.04038) QuantErr: 11.04038 batch_time=0.50908 
Train Epoch: 9 [113/500 7232/32000 (23%)] Loss: 0.16982 (QuantReg: 10.73767) QuantErr: 10.73767 batch_time=0.44646 
Train Epoch: 9 [121/500 7744/32000 (24%)] Loss: 0.07712 (QuantReg: 11.38011) QuantErr: 11.38011 batch_time=0.44530 
Train Epoch: 9 [129/500 8256/32000 (26%)] Loss: 0.06107 (QuantReg: 10.72460) QuantErr: 10.72460 batch_time=0.57260 
Train Epoch: 9 [137/500 8768/32000 (27%)] Loss: 0.10466 (QuantReg: 10.45342) QuantErr: 10.45342 batch_time=0.44243 
Train Epoch: 9 [145/500 9280/32000 (29%)] Loss: 0.08393 (QuantReg: 11.29388) QuantErr: 11.29388 batch_time=0.43672 
Train Epoch: 9 [153/500 9792/32000 (31%)] Loss: 0.07062 (QuantReg: 10.98149) QuantErr: 10.98149 batch_time=0.45424 
Train Epoch: 9 [161/500 10304/32000 (32%)] Loss: 0.09795 (QuantReg: 10.74881) QuantErr: 10.74881 batch_time=0.44430 
Train Epoch: 9 [169/500 10816/32000 (34%)] Loss: 0.09244 (QuantReg: 10.84223) QuantErr: 10.84223 batch_time=0.52759 
Train Epoch: 9 [177/500 11328/32000 (35%)] Loss: 0.13637 (QuantReg: 10.85983) QuantErr: 10.85983 batch_time=0.44029 
Train Epoch: 9 [185/500 11840/32000 (37%)] Loss: 0.10584 (QuantReg: 11.07413) QuantErr: 11.07413 batch_time=0.44986 
Train Epoch: 9 [193/500 12352/32000 (39%)] Loss: 0.16527 (QuantReg: 10.74557) QuantErr: 10.74557 batch_time=0.60231 
Train Epoch: 9 [201/500 12864/32000 (40%)] Loss: 0.09735 (QuantReg: 11.10402) QuantErr: 11.10402 batch_time=0.44500 
Train Epoch: 9 [209/500 13376/32000 (42%)] Loss: 0.09920 (QuantReg: 10.86981) QuantErr: 10.86981 batch_time=0.49823 
Train Epoch: 9 [217/500 13888/32000 (43%)] Loss: 0.11819 (QuantReg: 10.92758) QuantErr: 10.92758 batch_time=0.44484 
Train Epoch: 9 [225/500 14400/32000 (45%)] Loss: 0.13248 (QuantReg: 10.42890) QuantErr: 10.42890 batch_time=0.44099 
Train Epoch: 9 [233/500 14912/32000 (47%)] Loss: 0.09031 (QuantReg: 10.97729) QuantErr: 10.97729 batch_time=0.50778 
Train Epoch: 9 [241/500 15424/32000 (48%)] Loss: 0.09248 (QuantReg: 10.73767) QuantErr: 10.73767 batch_time=0.44354 
Train Epoch: 9 [249/500 15936/32000 (50%)] Loss: 0.08170 (QuantReg: 11.07884) QuantErr: 11.07884 batch_time=0.44049 
Train Epoch: 9 [257/500 16448/32000 (51%)] Loss: 0.08925 (QuantReg: 10.58916) QuantErr: 10.58916 batch_time=0.57657 
Train Epoch: 9 [265/500 16960/32000 (53%)] Loss: 0.10294 (QuantReg: 10.78032) QuantErr: 10.78032 batch_time=0.44060 
Train Epoch: 9 [273/500 17472/32000 (55%)] Loss: 0.10066 (QuantReg: 10.93202) QuantErr: 10.93202 batch_time=0.46753 
Train Epoch: 9 [281/500 17984/32000 (56%)] Loss: 0.06932 (QuantReg: 11.05924) QuantErr: 11.05924 batch_time=0.45195 
Train Epoch: 9 [289/500 18496/32000 (58%)] Loss: 0.07033 (QuantReg: 10.97915) QuantErr: 10.97915 batch_time=0.45253 
Train Epoch: 9 [297/500 19008/32000 (59%)] Loss: 0.12030 (QuantReg: 10.68080) QuantErr: 10.68080 batch_time=0.52034 
Train Epoch: 9 [305/500 19520/32000 (61%)] Loss: 0.13641 (QuantReg: 10.37909) QuantErr: 10.37909 batch_time=0.45262 
Train Epoch: 9 [313/500 20032/32000 (63%)] Loss: 0.15327 (QuantReg: 10.37763) QuantErr: 10.37763 batch_time=0.45334 
Train Epoch: 9 [321/500 20544/32000 (64%)] Loss: 0.13051 (QuantReg: 10.77019) QuantErr: 10.77019 batch_time=0.59575 
Train Epoch: 9 [329/500 21056/32000 (66%)] Loss: 0.07535 (QuantReg: 11.02718) QuantErr: 11.02718 batch_time=0.45861 
Train Epoch: 9 [337/500 21568/32000 (67%)] Loss: 0.11603 (QuantReg: 11.00078) QuantErr: 11.00078 batch_time=0.44826 
Train Epoch: 9 [345/500 22080/32000 (69%)] Loss: 0.05171 (QuantReg: 10.85315) QuantErr: 10.85315 batch_time=0.45194 
Train Epoch: 9 [353/500 22592/32000 (71%)] Loss: 0.06350 (QuantReg: 10.79515) QuantErr: 10.79515 batch_time=0.48115 
Train Epoch: 9 [361/500 23104/32000 (72%)] Loss: 0.08870 (QuantReg: 10.84481) QuantErr: 10.84481 batch_time=0.50583 
Train Epoch: 9 [369/500 23616/32000 (74%)] Loss: 0.06684 (QuantReg: 10.95028) QuantErr: 10.95028 batch_time=0.43633 
Train Epoch: 9 [377/500 24128/32000 (75%)] Loss: 0.11543 (QuantReg: 10.74112) QuantErr: 10.74112 batch_time=0.43733 
Train Epoch: 9 [385/500 24640/32000 (77%)] Loss: 0.10778 (QuantReg: 10.55594) QuantErr: 10.55594 batch_time=0.57837 
Train Epoch: 9 [393/500 25152/32000 (79%)] Loss: 0.06935 (QuantReg: 11.12210) QuantErr: 11.12210 batch_time=0.44168 
Train Epoch: 9 [401/500 25664/32000 (80%)] Loss: 0.10444 (QuantReg: 10.84229) QuantErr: 10.84229 batch_time=0.43803 
Train Epoch: 9 [409/500 26176/32000 (82%)] Loss: 0.07294 (QuantReg: 11.01834) QuantErr: 11.01834 batch_time=0.44216 
Train Epoch: 9 [417/500 26688/32000 (83%)] Loss: 0.10828 (QuantReg: 10.70757) QuantErr: 10.70757 batch_time=0.44837 
Train Epoch: 9 [425/500 27200/32000 (85%)] Loss: 0.06006 (QuantReg: 10.87035) QuantErr: 10.87035 batch_time=0.50916 
Train Epoch: 9 [433/500 27712/32000 (87%)] Loss: 0.07294 (QuantReg: 11.28106) QuantErr: 11.28106 batch_time=0.44097 
Train Epoch: 9 [441/500 28224/32000 (88%)] Loss: 0.11700 (QuantReg: 10.79826) QuantErr: 10.79826 batch_time=0.44128 
Train Epoch: 9 [449/500 28736/32000 (90%)] Loss: 0.04866 (QuantReg: 10.80731) QuantErr: 10.80731 batch_time=0.58082 
Train Epoch: 9 [457/500 29248/32000 (91%)] Loss: 0.06534 (QuantReg: 11.07844) QuantErr: 11.07844 batch_time=0.44077 
Train Epoch: 9 [465/500 29760/32000 (93%)] Loss: 0.04289 (QuantReg: 10.78385) QuantErr: 10.78385 batch_time=0.44238 
Train Epoch: 9 [473/500 30272/32000 (95%)] Loss: 0.04286 (QuantReg: 10.98940) QuantErr: 10.98940 batch_time=0.44970 
Train Epoch: 9 [481/500 30784/32000 (96%)] Loss: 0.07396 (QuantReg: 10.71796) QuantErr: 10.71796 batch_time=0.44988 
Train Epoch: 9 [489/500 31296/32000 (98%)] Loss: 0.09072 (QuantReg: 10.70041) QuantErr: 10.70041 batch_time=0.51363 
Train Epoch: 9 [497/500 31808/32000 (99%)] Loss: 0.12791 (QuantReg: 10.97866) QuantErr: 10.97866 batch_time=0.43793 
Train Epoch: 9 codebook_update_time=1.64927
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_ActivityNet_bs64/checkpoint-epoch9.pth ...
Done in 4.871s
Updating 'best' checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_ActivityNet_bs64/checkpoint-epoch9.pth ...
Done in 9.850s
removing stale ckpt [epoch 8] [took 0.01s]
 epoch          : 9
 loss           : 0.10399316986650228
 quant_reg      : 10.813135730743408
 quant_err      : 10.813135730743408
 learning_rate  : 2.6100312500000002e-05
 n_samples      : 288000
 n_steps        : 4500
 ActivityNet_val1_test/t2v_metrics/R1: 17.144600366076876
 ActivityNet_val1_test/t2v_metrics/R5: 46.329062436444985
 ActivityNet_val1_test/t2v_metrics/R10: 64.22615415904006
 ActivityNet_val1_test/t2v_metrics/R50: 91.60056945291845
 ActivityNet_val1_test/t2v_metrics/MedR: 6.0
 ActivityNet_val1_test/t2v_metrics/MeanR: 25.2019524100061
 ActivityNet_val1_test/t2v_metrics/geometric_mean_R1-R5-R10: 37.0877879942367
 ActivityNet_val1_test/v2t_metrics/R1: 17.77506609721375
 ActivityNet_val1_test/v2t_metrics/R5: 47.691681919869836
 ActivityNet_val1_test/v2t_metrics/R10: 65.34472239170226
 ActivityNet_val1_test/v2t_metrics/R50: 92.27171039251576
 ActivityNet_val1_test/v2t_metrics/MedR: 6.0
 ActivityNet_val1_test/v2t_metrics/MeanR: 24.140736221273134
 ActivityNet_val1_test/v2t_metrics/geometric_mean_R1-R5-R10: 38.12016690271447
 mnt_best       : 37.0877879942367
 not_improved_count: 0
Train Epoch: 10 [1/500 64/32000 (0%)] Loss: 0.05149 (QuantReg: 10.73204) QuantErr: 10.73204 batch_time=23.40699 
Train Epoch: 10 [9/500 576/32000 (2%)] Loss: 0.09443 (QuantReg: 10.41991) QuantErr: 10.41991 batch_time=0.48021 
Train Epoch: 10 [17/500 1088/32000 (3%)] Loss: 0.06597 (QuantReg: 10.75257) QuantErr: 10.75257 batch_time=0.45897 
Train Epoch: 10 [25/500 1600/32000 (5%)] Loss: 0.06519 (QuantReg: 10.87070) QuantErr: 10.87070 batch_time=0.71872 
Train Epoch: 10 [33/500 2112/32000 (7%)] Loss: 0.06119 (QuantReg: 11.10855) QuantErr: 11.10855 batch_time=0.69109 
Train Epoch: 10 [41/500 2624/32000 (8%)] Loss: 0.12472 (QuantReg: 10.69189) QuantErr: 10.69189 batch_time=0.44351 
Train Epoch: 10 [49/500 3136/32000 (10%)] Loss: 0.17063 (QuantReg: 10.70940) QuantErr: 10.70940 batch_time=0.43709 
Train Epoch: 10 [57/500 3648/32000 (11%)] Loss: 0.09168 (QuantReg: 10.73877) QuantErr: 10.73877 batch_time=0.44645 
Train Epoch: 10 [65/500 4160/32000 (13%)] Loss: 0.08872 (QuantReg: 10.97080) QuantErr: 10.97080 batch_time=0.79621 
Train Epoch: 10 [73/500 4672/32000 (15%)] Loss: 0.14161 (QuantReg: 10.62375) QuantErr: 10.62375 batch_time=0.44404 
Train Epoch: 10 [81/500 5184/32000 (16%)] Loss: 0.05421 (QuantReg: 10.71059) QuantErr: 10.71059 batch_time=0.44428 
Train Epoch: 10 [89/500 5696/32000 (18%)] Loss: 0.06604 (QuantReg: 10.55017) QuantErr: 10.55017 batch_time=0.72223 
Train Epoch: 10 [97/500 6208/32000 (19%)] Loss: 0.07207 (QuantReg: 10.65330) QuantErr: 10.65330 batch_time=0.68594 
Train Epoch: 10 [105/500 6720/32000 (21%)] Loss: 0.04702 (QuantReg: 11.13562) QuantErr: 11.13562 batch_time=0.44006 
Train Epoch: 10 [113/500 7232/32000 (23%)] Loss: 0.12587 (QuantReg: 10.82412) QuantErr: 10.82412 batch_time=0.44919 
Train Epoch: 10 [121/500 7744/32000 (24%)] Loss: 0.08161 (QuantReg: 10.64907) QuantErr: 10.64907 batch_time=0.43988 
Train Epoch: 10 [129/500 8256/32000 (26%)] Loss: 0.07734 (QuantReg: 10.65249) QuantErr: 10.65249 batch_time=0.78503 
Train Epoch: 10 [137/500 8768/32000 (27%)] Loss: 0.07925 (QuantReg: 10.59092) QuantErr: 10.59092 batch_time=0.44032 
Train Epoch: 10 [145/500 9280/32000 (29%)] Loss: 0.07130 (QuantReg: 10.57823) QuantErr: 10.57823 batch_time=0.43675 
Train Epoch: 10 [153/500 9792/32000 (31%)] Loss: 0.11757 (QuantReg: 11.03039) QuantErr: 11.03039 batch_time=0.76198 
Train Epoch: 10 [161/500 10304/32000 (32%)] Loss: 0.09744 (QuantReg: 10.73986) QuantErr: 10.73986 batch_time=0.69039 
Train Epoch: 10 [169/500 10816/32000 (34%)] Loss: 0.12236 (QuantReg: 10.59127) QuantErr: 10.59127 batch_time=0.43958 
Train Epoch: 10 [177/500 11328/32000 (35%)] Loss: 0.08881 (QuantReg: 10.64599) QuantErr: 10.64599 batch_time=0.43921 
Train Epoch: 10 [185/500 11840/32000 (37%)] Loss: 0.15111 (QuantReg: 10.73991) QuantErr: 10.73991 batch_time=0.45068 
Train Epoch: 10 [193/500 12352/32000 (39%)] Loss: 0.16472 (QuantReg: 11.05294) QuantErr: 11.05294 batch_time=0.78517 
Train Epoch: 10 [201/500 12864/32000 (40%)] Loss: 0.05892 (QuantReg: 10.98078) QuantErr: 10.98078 batch_time=0.44231 
Train Epoch: 10 [209/500 13376/32000 (42%)] Loss: 0.09886 (QuantReg: 10.77879) QuantErr: 10.77879 batch_time=0.44022 
Train Epoch: 10 [217/500 13888/32000 (43%)] Loss: 0.03829 (QuantReg: 10.87745) QuantErr: 10.87745 batch_time=0.73083 
Train Epoch: 10 [225/500 14400/32000 (45%)] Loss: 0.08682 (QuantReg: 10.86128) QuantErr: 10.86128 batch_time=0.70132 
Train Epoch: 10 [233/500 14912/32000 (47%)] Loss: 0.11240 (QuantReg: 10.78337) QuantErr: 10.78337 batch_time=0.44120 
Train Epoch: 10 [241/500 15424/32000 (48%)] Loss: 0.12175 (QuantReg: 10.95870) QuantErr: 10.95870 batch_time=0.44931 
Train Epoch: 10 [249/500 15936/32000 (50%)] Loss: 0.11883 (QuantReg: 10.96865) QuantErr: 10.96865 batch_time=0.44894 
Train Epoch: 10 [257/500 16448/32000 (51%)] Loss: 0.14479 (QuantReg: 10.94016) QuantErr: 10.94016 batch_time=0.82439 
Train Epoch: 10 [265/500 16960/32000 (53%)] Loss: 0.07361 (QuantReg: 10.75476) QuantErr: 10.75476 batch_time=0.44478 
Train Epoch: 10 [273/500 17472/32000 (55%)] Loss: 0.05422 (QuantReg: 10.74598) QuantErr: 10.74598 batch_time=0.45927 
Train Epoch: 10 [281/500 17984/32000 (56%)] Loss: 0.09373 (QuantReg: 10.72189) QuantErr: 10.72189 batch_time=0.76823 
Train Epoch: 10 [289/500 18496/32000 (58%)] Loss: 0.09910 (QuantReg: 10.65749) QuantErr: 10.65749 batch_time=0.72000 
Train Epoch: 10 [297/500 19008/32000 (59%)] Loss: 0.10811 (QuantReg: 10.85019) QuantErr: 10.85019 batch_time=0.45080 
Train Epoch: 10 [305/500 19520/32000 (61%)] Loss: 0.08857 (QuantReg: 10.71196) QuantErr: 10.71196 batch_time=0.44272 
Train Epoch: 10 [313/500 20032/32000 (63%)] Loss: 0.11055 (QuantReg: 10.95957) QuantErr: 10.95957 batch_time=0.44300 
Train Epoch: 10 [321/500 20544/32000 (64%)] Loss: 0.06749 (QuantReg: 10.70523) QuantErr: 10.70523 batch_time=0.78498 
Train Epoch: 10 [329/500 21056/32000 (66%)] Loss: 0.05952 (QuantReg: 10.57877) QuantErr: 10.57877 batch_time=0.43975 
Train Epoch: 10 [337/500 21568/32000 (67%)] Loss: 0.06293 (QuantReg: 10.66597) QuantErr: 10.66597 batch_time=0.43573 
Train Epoch: 10 [345/500 22080/32000 (69%)] Loss: 0.09006 (QuantReg: 10.52944) QuantErr: 10.52944 batch_time=0.72189 
Train Epoch: 10 [353/500 22592/32000 (71%)] Loss: 0.09162 (QuantReg: 10.76768) QuantErr: 10.76768 batch_time=0.68209 
Train Epoch: 10 [361/500 23104/32000 (72%)] Loss: 0.08092 (QuantReg: 10.43036) QuantErr: 10.43036 batch_time=0.44027 
Train Epoch: 10 [369/500 23616/32000 (74%)] Loss: 0.07153 (QuantReg: 11.09867) QuantErr: 11.09867 batch_time=0.50372 
Train Epoch: 10 [377/500 24128/32000 (75%)] Loss: 0.12795 (QuantReg: 11.07561) QuantErr: 11.07561 batch_time=0.43969 
Train Epoch: 10 [385/500 24640/32000 (77%)] Loss: 0.12610 (QuantReg: 10.82122) QuantErr: 10.82122 batch_time=0.76593 
Train Epoch: 10 [393/500 25152/32000 (79%)] Loss: 0.12302 (QuantReg: 10.39358) QuantErr: 10.39358 batch_time=0.43389 
Train Epoch: 10 [401/500 25664/32000 (80%)] Loss: 0.05929 (QuantReg: 10.67045) QuantErr: 10.67045 batch_time=0.44232 
Train Epoch: 10 [409/500 26176/32000 (82%)] Loss: 0.08939 (QuantReg: 10.53979) QuantErr: 10.53979 batch_time=0.70414 
Train Epoch: 10 [417/500 26688/32000 (83%)] Loss: 0.08417 (QuantReg: 10.86459) QuantErr: 10.86459 batch_time=0.68700 
Train Epoch: 10 [425/500 27200/32000 (85%)] Loss: 0.11103 (QuantReg: 10.39026) QuantErr: 10.39026 batch_time=0.44929 
Train Epoch: 10 [433/500 27712/32000 (87%)] Loss: 0.05365 (QuantReg: 10.75894) QuantErr: 10.75894 batch_time=0.44835 
Train Epoch: 10 [441/500 28224/32000 (88%)] Loss: 0.06650 (QuantReg: 10.97997) QuantErr: 10.97997 batch_time=0.44664 
Train Epoch: 10 [449/500 28736/32000 (90%)] Loss: 0.07434 (QuantReg: 10.51767) QuantErr: 10.51767 batch_time=0.81698 
Train Epoch: 10 [457/500 29248/32000 (91%)] Loss: 0.17696 (QuantReg: 10.55169) QuantErr: 10.55169 batch_time=0.43746 
Train Epoch: 10 [465/500 29760/32000 (93%)] Loss: 0.04616 (QuantReg: 10.54434) QuantErr: 10.54434 batch_time=0.45251 
Train Epoch: 10 [473/500 30272/32000 (95%)] Loss: 0.11838 (QuantReg: 10.94390) QuantErr: 10.94390 batch_time=0.71323 
Train Epoch: 10 [481/500 30784/32000 (96%)] Loss: 0.10361 (QuantReg: 11.03999) QuantErr: 11.03999 batch_time=0.68261 
Train Epoch: 10 [489/500 31296/32000 (98%)] Loss: 0.05924 (QuantReg: 10.52190) QuantErr: 10.52190 batch_time=0.44318 
Train Epoch: 10 [497/500 31808/32000 (99%)] Loss: 0.07322 (QuantReg: 10.72706) QuantErr: 10.72706 batch_time=0.44131 
Train Epoch: 10 codebook_update_time=1.81380
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_ActivityNet_bs64/checkpoint-epoch10.pth ...
Done in 4.761s
Updating 'best' checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_ActivityNet_bs64/checkpoint-epoch10.pth ...
Done in 9.999s
removing stale ckpt [epoch 9] [took 0.01s]
 epoch          : 10
 loss           : 0.09655615510046482
 quant_reg      : 10.782334804534912
 quant_err      : 10.782334804534912
 learning_rate  : 2.6100312500000002e-05
 n_samples      : 320000
 n_steps        : 5000
 ActivityNet_val1_test/t2v_metrics/R1: 17.754728492983528
 ActivityNet_val1_test/t2v_metrics/R5: 46.12568639414277
 ActivityNet_val1_test/t2v_metrics/R10: 64.51088061826317
 ActivityNet_val1_test/t2v_metrics/R50: 91.35651820215578
 ActivityNet_val1_test/t2v_metrics/MedR: 6.0
 ActivityNet_val1_test/t2v_metrics/MeanR: 26.294285133211307
 ActivityNet_val1_test/t2v_metrics/geometric_mean_R1-R5-R10: 37.52291900390766
 ActivityNet_val1_test/v2t_metrics/R1: 17.876754118364858
 ActivityNet_val1_test/v2t_metrics/R5: 48.32214765100671
 ActivityNet_val1_test/v2t_metrics/R10: 66.07687614399023
 ActivityNet_val1_test/v2t_metrics/R50: 91.72259507829978
 ActivityNet_val1_test/v2t_metrics/MedR: 6.0
 ActivityNet_val1_test/v2t_metrics/MeanR: 24.954443766524303
 ActivityNet_val1_test/v2t_metrics/geometric_mean_R1-R5-R10: 38.503020388083
 mnt_best       : 37.52291900390766
 not_improved_count: 0
Train Epoch: 11 [1/500 64/32000 (0%)] Loss: 0.06201 (QuantReg: 11.07409) QuantErr: 11.07409 batch_time=23.97259 
Train Epoch: 11 [9/500 576/32000 (2%)] Loss: 0.08768 (QuantReg: 11.10478) QuantErr: 11.10478 batch_time=0.45020 
Train Epoch: 11 [17/500 1088/32000 (3%)] Loss: 0.10756 (QuantReg: 10.54798) QuantErr: 10.54798 batch_time=0.44659 
Train Epoch: 11 [25/500 1600/32000 (5%)] Loss: 0.14185 (QuantReg: 10.68512) QuantErr: 10.68512 batch_time=0.44891 
Train Epoch: 11 [33/500 2112/32000 (7%)] Loss: 0.04992 (QuantReg: 10.70291) QuantErr: 10.70291 batch_time=0.49086 
Train Epoch: 11 [41/500 2624/32000 (8%)] Loss: 0.11141 (QuantReg: 10.48239) QuantErr: 10.48239 batch_time=0.44590 
Train Epoch: 11 [49/500 3136/32000 (10%)] Loss: 0.12479 (QuantReg: 10.46276) QuantErr: 10.46276 batch_time=0.44237 
Train Epoch: 11 [57/500 3648/32000 (11%)] Loss: 0.10682 (QuantReg: 10.51935) QuantErr: 10.51935 batch_time=0.43908 
Train Epoch: 11 [65/500 4160/32000 (13%)] Loss: 0.12314 (QuantReg: 10.80655) QuantErr: 10.80655 batch_time=0.52508 
Train Epoch: 11 [73/500 4672/32000 (15%)] Loss: 0.07095 (QuantReg: 10.47108) QuantErr: 10.47108 batch_time=0.44690 
Train Epoch: 11 [81/500 5184/32000 (16%)] Loss: 0.05180 (QuantReg: 10.85573) QuantErr: 10.85573 batch_time=0.44484 
Train Epoch: 11 [89/500 5696/32000 (18%)] Loss: 0.06939 (QuantReg: 10.72767) QuantErr: 10.72767 batch_time=0.45172 
Train Epoch: 11 [97/500 6208/32000 (19%)] Loss: 0.07486 (QuantReg: 10.50472) QuantErr: 10.50472 batch_time=0.50706 
Train Epoch: 11 [105/500 6720/32000 (21%)] Loss: 0.04550 (QuantReg: 10.76776) QuantErr: 10.76776 batch_time=0.47172 
Train Epoch: 11 [113/500 7232/32000 (23%)] Loss: 0.10694 (QuantReg: 10.65403) QuantErr: 10.65403 batch_time=0.44052 
Train Epoch: 11 [121/500 7744/32000 (24%)] Loss: 0.14790 (QuantReg: 10.55584) QuantErr: 10.55584 batch_time=0.45025 
Train Epoch: 11 [129/500 8256/32000 (26%)] Loss: 0.15121 (QuantReg: 10.57924) QuantErr: 10.57924 batch_time=0.50819 
Train Epoch: 11 [137/500 8768/32000 (27%)] Loss: 0.11860 (QuantReg: 10.60624) QuantErr: 10.60624 batch_time=0.44378 
Train Epoch: 11 [145/500 9280/32000 (29%)] Loss: 0.09421 (QuantReg: 10.92990) QuantErr: 10.92990 batch_time=0.48876 
Train Epoch: 11 [153/500 9792/32000 (31%)] Loss: 0.12405 (QuantReg: 10.51924) QuantErr: 10.51924 batch_time=0.44270 
Train Epoch: 11 [161/500 10304/32000 (32%)] Loss: 0.10365 (QuantReg: 10.84255) QuantErr: 10.84255 batch_time=0.47160 
Train Epoch: 11 [169/500 10816/32000 (34%)] Loss: 0.04925 (QuantReg: 10.86308) QuantErr: 10.86308 batch_time=0.46726 
Train Epoch: 11 [177/500 11328/32000 (35%)] Loss: 0.11291 (QuantReg: 10.72070) QuantErr: 10.72070 batch_time=0.44105 
Train Epoch: 11 [185/500 11840/32000 (37%)] Loss: 0.04614 (QuantReg: 10.58689) QuantErr: 10.58689 batch_time=0.45003 
Train Epoch: 11 [193/500 12352/32000 (39%)] Loss: 0.09663 (QuantReg: 10.87005) QuantErr: 10.87005 batch_time=0.51916 
Train Epoch: 11 [201/500 12864/32000 (40%)] Loss: 0.07930 (QuantReg: 10.63771) QuantErr: 10.63771 batch_time=0.45142 
Train Epoch: 11 [209/500 13376/32000 (42%)] Loss: 0.06329 (QuantReg: 11.07346) QuantErr: 11.07346 batch_time=0.45824 
Train Epoch: 11 [217/500 13888/32000 (43%)] Loss: 0.05822 (QuantReg: 10.94934) QuantErr: 10.94934 batch_time=0.44197 
Train Epoch: 11 [225/500 14400/32000 (45%)] Loss: 0.04746 (QuantReg: 10.65034) QuantErr: 10.65034 batch_time=0.47571 
Train Epoch: 11 [233/500 14912/32000 (47%)] Loss: 0.07678 (QuantReg: 10.95339) QuantErr: 10.95339 batch_time=0.44242 
Train Epoch: 11 [241/500 15424/32000 (48%)] Loss: 0.12976 (QuantReg: 10.56915) QuantErr: 10.56915 batch_time=0.49051 
Train Epoch: 11 [249/500 15936/32000 (50%)] Loss: 0.07648 (QuantReg: 10.84206) QuantErr: 10.84206 batch_time=0.44055 
Train Epoch: 11 [257/500 16448/32000 (51%)] Loss: 0.05494 (QuantReg: 10.81332) QuantErr: 10.81332 batch_time=0.51428 
Train Epoch: 11 [265/500 16960/32000 (53%)] Loss: 0.05442 (QuantReg: 10.40579) QuantErr: 10.40579 batch_time=0.44274 
Train Epoch: 11 [273/500 17472/32000 (55%)] Loss: 0.09093 (QuantReg: 10.59411) QuantErr: 10.59411 batch_time=0.44095 
Train Epoch: 11 [281/500 17984/32000 (56%)] Loss: 0.08954 (QuantReg: 10.75133) QuantErr: 10.75133 batch_time=0.44872 
Train Epoch: 11 [289/500 18496/32000 (58%)] Loss: 0.11268 (QuantReg: 10.61660) QuantErr: 10.61660 batch_time=0.47971 
Train Epoch: 11 [297/500 19008/32000 (59%)] Loss: 0.15072 (QuantReg: 11.03575) QuantErr: 11.03575 batch_time=0.44464 
Train Epoch: 11 [305/500 19520/32000 (61%)] Loss: 0.08495 (QuantReg: 10.83414) QuantErr: 10.83414 batch_time=0.47037 
Train Epoch: 11 [313/500 20032/32000 (63%)] Loss: 0.04559 (QuantReg: 10.79020) QuantErr: 10.79020 batch_time=0.45332 
Train Epoch: 11 [321/500 20544/32000 (64%)] Loss: 0.15620 (QuantReg: 10.51727) QuantErr: 10.51727 batch_time=0.53032 
Train Epoch: 11 [329/500 21056/32000 (66%)] Loss: 0.07820 (QuantReg: 10.75639) QuantErr: 10.75639 batch_time=0.44451 
Train Epoch: 11 [337/500 21568/32000 (67%)] Loss: 0.06514 (QuantReg: 11.04034) QuantErr: 11.04034 batch_time=0.44513 
Train Epoch: 11 [345/500 22080/32000 (69%)] Loss: 0.08509 (QuantReg: 10.75801) QuantErr: 10.75801 batch_time=0.44376 
Train Epoch: 11 [353/500 22592/32000 (71%)] Loss: 0.05984 (QuantReg: 10.93200) QuantErr: 10.93200 batch_time=0.47689 
Train Epoch: 11 [361/500 23104/32000 (72%)] Loss: 0.07882 (QuantReg: 11.08491) QuantErr: 11.08491 batch_time=0.45108 
Train Epoch: 11 [369/500 23616/32000 (74%)] Loss: 0.07266 (QuantReg: 10.65925) QuantErr: 10.65925 batch_time=0.46258 
Train Epoch: 11 [377/500 24128/32000 (75%)] Loss: 0.15229 (QuantReg: 10.63134) QuantErr: 10.63134 batch_time=0.46952 
Train Epoch: 11 [385/500 24640/32000 (77%)] Loss: 0.09224 (QuantReg: 10.84440) QuantErr: 10.84440 batch_time=0.50568 
Train Epoch: 11 [393/500 25152/32000 (79%)] Loss: 0.08306 (QuantReg: 10.70483) QuantErr: 10.70483 batch_time=0.44310 
Train Epoch: 11 [401/500 25664/32000 (80%)] Loss: 0.05298 (QuantReg: 11.00790) QuantErr: 11.00790 batch_time=0.44548 
Train Epoch: 11 [409/500 26176/32000 (82%)] Loss: 0.10367 (QuantReg: 11.06690) QuantErr: 11.06690 batch_time=0.43991 
Train Epoch: 11 [417/500 26688/32000 (83%)] Loss: 0.07909 (QuantReg: 10.87044) QuantErr: 10.87044 batch_time=0.46984 
Train Epoch: 11 [425/500 27200/32000 (85%)] Loss: 0.07575 (QuantReg: 11.01992) QuantErr: 11.01992 batch_time=0.44034 
Train Epoch: 11 [433/500 27712/32000 (87%)] Loss: 0.10637 (QuantReg: 10.99980) QuantErr: 10.99980 batch_time=0.44711 
Train Epoch: 11 [441/500 28224/32000 (88%)] Loss: 0.09563 (QuantReg: 11.01264) QuantErr: 11.01264 batch_time=0.44906 
Train Epoch: 11 [449/500 28736/32000 (90%)] Loss: 0.07905 (QuantReg: 10.65143) QuantErr: 10.65143 batch_time=0.51717 
Train Epoch: 11 [457/500 29248/32000 (91%)] Loss: 0.07729 (QuantReg: 10.91698) QuantErr: 10.91698 batch_time=0.44658 
Train Epoch: 11 [465/500 29760/32000 (93%)] Loss: 0.09124 (QuantReg: 10.76200) QuantErr: 10.76200 batch_time=0.44720 
Train Epoch: 11 [473/500 30272/32000 (95%)] Loss: 0.07485 (QuantReg: 10.60796) QuantErr: 10.60796 batch_time=0.44580 
Train Epoch: 11 [481/500 30784/32000 (96%)] Loss: 0.06719 (QuantReg: 10.67056) QuantErr: 10.67056 batch_time=0.51733 
Train Epoch: 11 [489/500 31296/32000 (98%)] Loss: 0.10717 (QuantReg: 10.44415) QuantErr: 10.44415 batch_time=0.44579 
Train Epoch: 11 [497/500 31808/32000 (99%)] Loss: 0.03954 (QuantReg: 10.85323) QuantErr: 10.85323 batch_time=0.46118 
Train Epoch: 11 codebook_update_time=1.67797
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_ActivityNet_bs64/checkpoint-epoch11.pth ...
Done in 5.249s
removing stale ckpt [epoch 10] [took 0.01s]
 epoch          : 11
 loss           : 0.0880343412682414
 quant_reg      : 10.74478493309021
 quant_err      : 10.74478493309021
 learning_rate  : 2.2185265625e-05
 n_samples      : 352000
 n_steps        : 5500
 ActivityNet_val1_test/t2v_metrics/R1: 17.592027659141753
 ActivityNet_val1_test/t2v_metrics/R5: 46.18669920683344
 ActivityNet_val1_test/t2v_metrics/R10: 64.2668293675005
 ActivityNet_val1_test/t2v_metrics/R50: 90.78706528370958
 ActivityNet_val1_test/t2v_metrics/MedR: 6.0
 ActivityNet_val1_test/t2v_metrics/MeanR: 28.48911938173683
 ActivityNet_val1_test/t2v_metrics/geometric_mean_R1-R5-R10: 37.377182965751025
 ActivityNet_val1_test/v2t_metrics/R1: 17.81574130567419
 ActivityNet_val1_test/v2t_metrics/R5: 48.03742119178361
 ActivityNet_val1_test/v2t_metrics/R10: 65.30404718324182
 ActivityNet_val1_test/v2t_metrics/R50: 91.74293268253
 ActivityNet_val1_test/v2t_metrics/MedR: 6.0
 ActivityNet_val1_test/v2t_metrics/MeanR: 26.291437868619077
 ActivityNet_val1_test/v2t_metrics/geometric_mean_R1-R5-R10: 38.233250891013284
 mnt_best       : 37.52291900390766
 not_improved_count: 1
Train Epoch: 12 [1/500 64/32000 (0%)] Loss: 0.06236 (QuantReg: 10.46321) QuantErr: 10.46321 batch_time=22.90388 
Train Epoch: 12 [9/500 576/32000 (2%)] Loss: 0.06838 (QuantReg: 10.65774) QuantErr: 10.65774 batch_time=0.44488 
Train Epoch: 12 [17/500 1088/32000 (3%)] Loss: 0.07239 (QuantReg: 10.81870) QuantErr: 10.81870 batch_time=1.02140 
Train Epoch: 12 [25/500 1600/32000 (5%)] Loss: 0.04906 (QuantReg: 10.95814) QuantErr: 10.95814 batch_time=0.45331 
Train Epoch: 12 [33/500 2112/32000 (7%)] Loss: 0.06316 (QuantReg: 10.78748) QuantErr: 10.78748 batch_time=0.44463 
Train Epoch: 12 [41/500 2624/32000 (8%)] Loss: 0.14896 (QuantReg: 10.55979) QuantErr: 10.55979 batch_time=0.48294 
Train Epoch: 12 [49/500 3136/32000 (10%)] Loss: 0.05856 (QuantReg: 10.92132) QuantErr: 10.92132 batch_time=0.57945 
Train Epoch: 12 [57/500 3648/32000 (11%)] Loss: 0.05130 (QuantReg: 10.77092) QuantErr: 10.77092 batch_time=0.44179 
Train Epoch: 12 [65/500 4160/32000 (13%)] Loss: 0.05963 (QuantReg: 10.56671) QuantErr: 10.56671 batch_time=0.73317 
Train Epoch: 12 [73/500 4672/32000 (15%)] Loss: 0.09019 (QuantReg: 10.72753) QuantErr: 10.72753 batch_time=0.44067 
Train Epoch: 12 [81/500 5184/32000 (16%)] Loss: 0.09470 (QuantReg: 10.82722) QuantErr: 10.82722 batch_time=0.88583 
Train Epoch: 12 [89/500 5696/32000 (18%)] Loss: 0.09188 (QuantReg: 11.09923) QuantErr: 11.09923 batch_time=0.44731 
Train Epoch: 12 [97/500 6208/32000 (19%)] Loss: 0.06670 (QuantReg: 11.21901) QuantErr: 11.21901 batch_time=0.44729 
Train Epoch: 12 [105/500 6720/32000 (21%)] Loss: 0.05000 (QuantReg: 10.65605) QuantErr: 10.65605 batch_time=0.47996 
Train Epoch: 12 [113/500 7232/32000 (23%)] Loss: 0.04164 (QuantReg: 10.56545) QuantErr: 10.56545 batch_time=0.57514 
Train Epoch: 12 [121/500 7744/32000 (24%)] Loss: 0.11341 (QuantReg: 10.57193) QuantErr: 10.57193 batch_time=0.44037 
Train Epoch: 12 [129/500 8256/32000 (26%)] Loss: 0.08059 (QuantReg: 10.79752) QuantErr: 10.79752 batch_time=0.67958 
Train Epoch: 12 [137/500 8768/32000 (27%)] Loss: 0.08138 (QuantReg: 10.56447) QuantErr: 10.56447 batch_time=0.43967 
Train Epoch: 12 [145/500 9280/32000 (29%)] Loss: 0.12598 (QuantReg: 10.78530) QuantErr: 10.78530 batch_time=0.86967 
Train Epoch: 12 [153/500 9792/32000 (31%)] Loss: 0.04952 (QuantReg: 10.75141) QuantErr: 10.75141 batch_time=0.45973 
Train Epoch: 12 [161/500 10304/32000 (32%)] Loss: 0.17058 (QuantReg: 10.43169) QuantErr: 10.43169 batch_time=0.43778 
Train Epoch: 12 [169/500 10816/32000 (34%)] Loss: 0.05921 (QuantReg: 10.83184) QuantErr: 10.83184 batch_time=0.44457 
Train Epoch: 12 [177/500 11328/32000 (35%)] Loss: 0.10100 (QuantReg: 10.47301) QuantErr: 10.47301 batch_time=0.57843 
Train Epoch: 12 [185/500 11840/32000 (37%)] Loss: 0.06915 (QuantReg: 10.57863) QuantErr: 10.57863 batch_time=0.43616 
Train Epoch: 12 [193/500 12352/32000 (39%)] Loss: 0.13630 (QuantReg: 10.66089) QuantErr: 10.66089 batch_time=0.71658 
Train Epoch: 12 [201/500 12864/32000 (40%)] Loss: 0.06085 (QuantReg: 10.95101) QuantErr: 10.95101 batch_time=0.43530 
Train Epoch: 12 [209/500 13376/32000 (42%)] Loss: 0.09376 (QuantReg: 10.57930) QuantErr: 10.57930 batch_time=0.88541 
Train Epoch: 12 [217/500 13888/32000 (43%)] Loss: 0.10245 (QuantReg: 10.43891) QuantErr: 10.43891 batch_time=0.45258 
Train Epoch: 12 [225/500 14400/32000 (45%)] Loss: 0.04466 (QuantReg: 10.78866) QuantErr: 10.78866 batch_time=0.44055 
Train Epoch: 12 [233/500 14912/32000 (47%)] Loss: 0.03085 (QuantReg: 10.73871) QuantErr: 10.73871 batch_time=0.48176 
Train Epoch: 12 [241/500 15424/32000 (48%)] Loss: 0.15201 (QuantReg: 10.64017) QuantErr: 10.64017 batch_time=0.56467 
Train Epoch: 12 [249/500 15936/32000 (50%)] Loss: 0.08733 (QuantReg: 10.66602) QuantErr: 10.66602 batch_time=0.44103 
Train Epoch: 12 [257/500 16448/32000 (51%)] Loss: 0.09186 (QuantReg: 10.37980) QuantErr: 10.37980 batch_time=0.68428 
Train Epoch: 12 [265/500 16960/32000 (53%)] Loss: 0.10761 (QuantReg: 10.74506) QuantErr: 10.74506 batch_time=0.44144 
Train Epoch: 12 [273/500 17472/32000 (55%)] Loss: 0.07112 (QuantReg: 10.80115) QuantErr: 10.80115 batch_time=0.87540 
Train Epoch: 12 [281/500 17984/32000 (56%)] Loss: 0.05745 (QuantReg: 10.54867) QuantErr: 10.54867 batch_time=0.44748 
Train Epoch: 12 [289/500 18496/32000 (58%)] Loss: 0.06344 (QuantReg: 10.80615) QuantErr: 10.80615 batch_time=0.43975 
Train Epoch: 12 [297/500 19008/32000 (59%)] Loss: 0.04396 (QuantReg: 10.46383) QuantErr: 10.46383 batch_time=0.43526 
Train Epoch: 12 [305/500 19520/32000 (61%)] Loss: 0.04926 (QuantReg: 10.81140) QuantErr: 10.81140 batch_time=0.58034 
Train Epoch: 12 [313/500 20032/32000 (63%)] Loss: 0.04706 (QuantReg: 10.55031) QuantErr: 10.55031 batch_time=0.43910 
Train Epoch: 12 [321/500 20544/32000 (64%)] Loss: 0.05361 (QuantReg: 11.04798) QuantErr: 11.04798 batch_time=0.67770 
Train Epoch: 12 [329/500 21056/32000 (66%)] Loss: 0.05905 (QuantReg: 10.47890) QuantErr: 10.47890 batch_time=0.48095 
Train Epoch: 12 [337/500 21568/32000 (67%)] Loss: 0.09809 (QuantReg: 10.34577) QuantErr: 10.34577 batch_time=0.83060 
Train Epoch: 12 [345/500 22080/32000 (69%)] Loss: 0.07951 (QuantReg: 10.97747) QuantErr: 10.97747 batch_time=0.44516 
Train Epoch: 12 [353/500 22592/32000 (71%)] Loss: 0.17310 (QuantReg: 10.58324) QuantErr: 10.58324 batch_time=0.44718 
Train Epoch: 12 [361/500 23104/32000 (72%)] Loss: 0.04181 (QuantReg: 11.05098) QuantErr: 11.05098 batch_time=0.44995 
Train Epoch: 12 [369/500 23616/32000 (74%)] Loss: 0.06044 (QuantReg: 10.72541) QuantErr: 10.72541 batch_time=0.56308 
Train Epoch: 12 [377/500 24128/32000 (75%)] Loss: 0.07521 (QuantReg: 10.86230) QuantErr: 10.86230 batch_time=0.44083 
Train Epoch: 12 [385/500 24640/32000 (77%)] Loss: 0.05290 (QuantReg: 10.83599) QuantErr: 10.83599 batch_time=0.69990 
Train Epoch: 12 [393/500 25152/32000 (79%)] Loss: 0.07677 (QuantReg: 10.90636) QuantErr: 10.90636 batch_time=0.47042 
Train Epoch: 12 [401/500 25664/32000 (80%)] Loss: 0.13992 (QuantReg: 10.89753) QuantErr: 10.89753 batch_time=0.88508 
Train Epoch: 12 [409/500 26176/32000 (82%)] Loss: 0.05188 (QuantReg: 10.69588) QuantErr: 10.69588 batch_time=0.44965 
Train Epoch: 12 [417/500 26688/32000 (83%)] Loss: 0.05086 (QuantReg: 10.93501) QuantErr: 10.93501 batch_time=0.47455 
Train Epoch: 12 [425/500 27200/32000 (85%)] Loss: 0.04989 (QuantReg: 10.84272) QuantErr: 10.84272 batch_time=0.46967 
Train Epoch: 12 [433/500 27712/32000 (87%)] Loss: 0.10562 (QuantReg: 10.62551) QuantErr: 10.62551 batch_time=0.59191 
Train Epoch: 12 [441/500 28224/32000 (88%)] Loss: 0.05682 (QuantReg: 10.70795) QuantErr: 10.70795 batch_time=0.44814 
Train Epoch: 12 [449/500 28736/32000 (90%)] Loss: 0.06311 (QuantReg: 10.66992) QuantErr: 10.66992 batch_time=0.68547 
Train Epoch: 12 [457/500 29248/32000 (91%)] Loss: 0.09091 (QuantReg: 11.00866) QuantErr: 11.00866 batch_time=0.46386 
Train Epoch: 12 [465/500 29760/32000 (93%)] Loss: 0.10341 (QuantReg: 10.85301) QuantErr: 10.85301 batch_time=0.93362 
Train Epoch: 12 [473/500 30272/32000 (95%)] Loss: 0.05074 (QuantReg: 10.52312) QuantErr: 10.52312 batch_time=0.44053 
Train Epoch: 12 [481/500 30784/32000 (96%)] Loss: 0.07061 (QuantReg: 10.78436) QuantErr: 10.78436 batch_time=0.45136 
Train Epoch: 12 [489/500 31296/32000 (98%)] Loss: 0.08102 (QuantReg: 10.78958) QuantErr: 10.78958 batch_time=0.46105 
Train Epoch: 12 [497/500 31808/32000 (99%)] Loss: 0.08572 (QuantReg: 10.87899) QuantErr: 10.87899 batch_time=0.55500 
Train Epoch: 12 codebook_update_time=1.68849
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_ActivityNet_bs64/checkpoint-epoch12.pth ...
Done in 6.264s
Updating 'best' checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_ActivityNet_bs64/checkpoint-epoch12.pth ...
Done in 10.988s
removing stale ckpt [epoch 11] [took 0.01s]
 epoch          : 12
 loss           : 0.08207355313003063
 quant_reg      : 10.689673517227172
 quant_err      : 10.689673517227172
 learning_rate  : 2.2185265625e-05
 n_samples      : 384000
 n_steps        : 6000
 ActivityNet_val1_test/t2v_metrics/R1: 18.120805369127517
 ActivityNet_val1_test/t2v_metrics/R5: 47.915395566402275
 ActivityNet_val1_test/t2v_metrics/R10: 64.81594468171649
 ActivityNet_val1_test/t2v_metrics/R50: 90.9090909090909
 ActivityNet_val1_test/t2v_metrics/MedR: 6.0
 ActivityNet_val1_test/t2v_metrics/MeanR: 25.809945088468577
 ActivityNet_val1_test/t2v_metrics/geometric_mean_R1-R5-R10: 38.32170378441886
 ActivityNet_val1_test/v2t_metrics/R1: 17.632702867602198
 ActivityNet_val1_test/v2t_metrics/R5: 48.8712629652227
 ActivityNet_val1_test/v2t_metrics/R10: 65.95485051860891
 ActivityNet_val1_test/v2t_metrics/R50: 91.31584299369534
 ActivityNet_val1_test/v2t_metrics/MedR: 6.0
 ActivityNet_val1_test/v2t_metrics/MeanR: 25.093146227374415
 ActivityNet_val1_test/v2t_metrics/geometric_mean_R1-R5-R10: 38.44793896475127
 mnt_best       : 38.32170378441886
 not_improved_count: 0
Train Epoch: 13 [1/500 64/32000 (0%)] Loss: 0.06886 (QuantReg: 10.53354) QuantErr: 10.53354 batch_time=24.30263 
Train Epoch: 13 [9/500 576/32000 (2%)] Loss: 0.15580 (QuantReg: 10.52077) QuantErr: 10.52077 batch_time=0.45213 
Train Epoch: 13 [17/500 1088/32000 (3%)] Loss: 0.12458 (QuantReg: 10.53692) QuantErr: 10.53692 batch_time=0.45284 
Train Epoch: 13 [25/500 1600/32000 (5%)] Loss: 0.11913 (QuantReg: 10.32801) QuantErr: 10.32801 batch_time=0.43925 
Train Epoch: 13 [33/500 2112/32000 (7%)] Loss: 0.06280 (QuantReg: 10.76701) QuantErr: 10.76701 batch_time=0.57142 
Train Epoch: 13 [41/500 2624/32000 (8%)] Loss: 0.06519 (QuantReg: 10.31132) QuantErr: 10.31132 batch_time=0.44157 
Train Epoch: 13 [49/500 3136/32000 (10%)] Loss: 0.04924 (QuantReg: 10.69856) QuantErr: 10.69856 batch_time=0.44286 
Train Epoch: 13 [57/500 3648/32000 (11%)] Loss: 0.09155 (QuantReg: 10.62750) QuantErr: 10.62750 batch_time=0.44143 
Train Epoch: 13 [65/500 4160/32000 (13%)] Loss: 0.06608 (QuantReg: 10.75251) QuantErr: 10.75251 batch_time=1.20585 
Train Epoch: 13 [73/500 4672/32000 (15%)] Loss: 0.11940 (QuantReg: 10.23119) QuantErr: 10.23119 batch_time=0.44214 
Train Epoch: 13 [81/500 5184/32000 (16%)] Loss: 0.04971 (QuantReg: 10.67460) QuantErr: 10.67460 batch_time=0.43975 
Train Epoch: 13 [89/500 5696/32000 (18%)] Loss: 0.05517 (QuantReg: 10.79987) QuantErr: 10.79987 batch_time=0.44068 
Train Epoch: 13 [97/500 6208/32000 (19%)] Loss: 0.05659 (QuantReg: 10.22303) QuantErr: 10.22303 batch_time=0.59978 
Train Epoch: 13 [105/500 6720/32000 (21%)] Loss: 0.13707 (QuantReg: 10.65340) QuantErr: 10.65340 batch_time=0.44804 
Train Epoch: 13 [113/500 7232/32000 (23%)] Loss: 0.05736 (QuantReg: 10.39398) QuantErr: 10.39398 batch_time=0.44781 
Train Epoch: 13 [121/500 7744/32000 (24%)] Loss: 0.06156 (QuantReg: 10.67391) QuantErr: 10.67391 batch_time=0.48916 
Train Epoch: 13 [129/500 8256/32000 (26%)] Loss: 0.06440 (QuantReg: 10.59388) QuantErr: 10.59388 batch_time=1.20950 
Train Epoch: 13 [137/500 8768/32000 (27%)] Loss: 0.08051 (QuantReg: 10.88229) QuantErr: 10.88229 batch_time=0.44760 
Train Epoch: 13 [145/500 9280/32000 (29%)] Loss: 0.05260 (QuantReg: 10.42137) QuantErr: 10.42137 batch_time=0.44073 
Train Epoch: 13 [153/500 9792/32000 (31%)] Loss: 0.09920 (QuantReg: 10.71887) QuantErr: 10.71887 batch_time=0.44619 
Train Epoch: 13 [161/500 10304/32000 (32%)] Loss: 0.07048 (QuantReg: 10.34079) QuantErr: 10.34079 batch_time=0.57387 
Train Epoch: 13 [169/500 10816/32000 (34%)] Loss: 0.08637 (QuantReg: 10.66204) QuantErr: 10.66204 batch_time=0.44724 
Train Epoch: 13 [177/500 11328/32000 (35%)] Loss: 0.06210 (QuantReg: 10.91577) QuantErr: 10.91577 batch_time=0.44547 
Train Epoch: 13 [185/500 11840/32000 (37%)] Loss: 0.10424 (QuantReg: 10.38608) QuantErr: 10.38608 batch_time=0.44125 
Train Epoch: 13 [193/500 12352/32000 (39%)] Loss: 0.14172 (QuantReg: 10.56859) QuantErr: 10.56859 batch_time=1.20354 
Train Epoch: 13 [201/500 12864/32000 (40%)] Loss: 0.06062 (QuantReg: 10.74915) QuantErr: 10.74915 batch_time=0.44003 
Train Epoch: 13 [209/500 13376/32000 (42%)] Loss: 0.07485 (QuantReg: 10.74097) QuantErr: 10.74097 batch_time=0.44244 
Train Epoch: 13 [217/500 13888/32000 (43%)] Loss: 0.05212 (QuantReg: 10.62541) QuantErr: 10.62541 batch_time=0.44080 
Train Epoch: 13 [225/500 14400/32000 (45%)] Loss: 0.13418 (QuantReg: 10.56175) QuantErr: 10.56175 batch_time=0.59047 
Train Epoch: 13 [233/500 14912/32000 (47%)] Loss: 0.06347 (QuantReg: 10.88340) QuantErr: 10.88340 batch_time=0.44777 
Train Epoch: 13 [241/500 15424/32000 (48%)] Loss: 0.05092 (QuantReg: 10.78189) QuantErr: 10.78189 batch_time=0.44913 
Train Epoch: 13 [249/500 15936/32000 (50%)] Loss: 0.02942 (QuantReg: 10.79580) QuantErr: 10.79580 batch_time=0.44498 
Train Epoch: 13 [257/500 16448/32000 (51%)] Loss: 0.04941 (QuantReg: 10.83936) QuantErr: 10.83936 batch_time=1.23468 
Train Epoch: 13 [265/500 16960/32000 (53%)] Loss: 0.03352 (QuantReg: 10.51815) QuantErr: 10.51815 batch_time=0.44763 
Train Epoch: 13 [273/500 17472/32000 (55%)] Loss: 0.05690 (QuantReg: 10.72370) QuantErr: 10.72370 batch_time=0.44219 
Train Epoch: 13 [281/500 17984/32000 (56%)] Loss: 0.11973 (QuantReg: 10.16045) QuantErr: 10.16045 batch_time=0.45258 
Train Epoch: 13 [289/500 18496/32000 (58%)] Loss: 0.05592 (QuantReg: 10.66269) QuantErr: 10.66269 batch_time=0.58586 
Train Epoch: 13 [297/500 19008/32000 (59%)] Loss: 0.08311 (QuantReg: 10.46012) QuantErr: 10.46012 batch_time=0.44275 
Train Epoch: 13 [305/500 19520/32000 (61%)] Loss: 0.05390 (QuantReg: 10.88059) QuantErr: 10.88059 batch_time=0.44129 
Train Epoch: 13 [313/500 20032/32000 (63%)] Loss: 0.11557 (QuantReg: 10.77940) QuantErr: 10.77940 batch_time=0.44398 
Train Epoch: 13 [321/500 20544/32000 (64%)] Loss: 0.04241 (QuantReg: 10.49410) QuantErr: 10.49410 batch_time=1.18186 
Train Epoch: 13 [329/500 21056/32000 (66%)] Loss: 0.04785 (QuantReg: 10.72840) QuantErr: 10.72840 batch_time=0.43683 
Train Epoch: 13 [337/500 21568/32000 (67%)] Loss: 0.05675 (QuantReg: 10.61668) QuantErr: 10.61668 batch_time=0.45901 
Train Epoch: 13 [345/500 22080/32000 (69%)] Loss: 0.12021 (QuantReg: 10.79721) QuantErr: 10.79721 batch_time=0.43913 
Train Epoch: 13 [353/500 22592/32000 (71%)] Loss: 0.03303 (QuantReg: 10.98120) QuantErr: 10.98120 batch_time=0.58369 
Train Epoch: 13 [361/500 23104/32000 (72%)] Loss: 0.06550 (QuantReg: 10.69061) QuantErr: 10.69061 batch_time=0.44053 
Train Epoch: 13 [369/500 23616/32000 (74%)] Loss: 0.08067 (QuantReg: 10.62423) QuantErr: 10.62423 batch_time=0.45900 
Train Epoch: 13 [377/500 24128/32000 (75%)] Loss: 0.05808 (QuantReg: 10.60993) QuantErr: 10.60993 batch_time=0.45491 
Train Epoch: 13 [385/500 24640/32000 (77%)] Loss: 0.06169 (QuantReg: 10.67479) QuantErr: 10.67479 batch_time=1.20748 
Train Epoch: 13 [393/500 25152/32000 (79%)] Loss: 0.06589 (QuantReg: 10.73699) QuantErr: 10.73699 batch_time=0.44134 
Train Epoch: 13 [401/500 25664/32000 (80%)] Loss: 0.03896 (QuantReg: 10.40320) QuantErr: 10.40320 batch_time=0.44024 
Train Epoch: 13 [409/500 26176/32000 (82%)] Loss: 0.08451 (QuantReg: 10.46192) QuantErr: 10.46192 batch_time=0.44466 
Train Epoch: 13 [417/500 26688/32000 (83%)] Loss: 0.08951 (QuantReg: 10.68691) QuantErr: 10.68691 batch_time=0.57766 
Train Epoch: 13 [425/500 27200/32000 (85%)] Loss: 0.08637 (QuantReg: 10.78663) QuantErr: 10.78663 batch_time=0.44525 
Train Epoch: 13 [433/500 27712/32000 (87%)] Loss: 0.10064 (QuantReg: 10.64985) QuantErr: 10.64985 batch_time=0.44884 
Train Epoch: 13 [441/500 28224/32000 (88%)] Loss: 0.11968 (QuantReg: 10.75837) QuantErr: 10.75837 batch_time=0.45329 
Train Epoch: 13 [449/500 28736/32000 (90%)] Loss: 0.13487 (QuantReg: 10.65281) QuantErr: 10.65281 batch_time=1.16859 
Train Epoch: 13 [457/500 29248/32000 (91%)] Loss: 0.04344 (QuantReg: 10.70209) QuantErr: 10.70209 batch_time=0.43910 
Train Epoch: 13 [465/500 29760/32000 (93%)] Loss: 0.05860 (QuantReg: 10.54851) QuantErr: 10.54851 batch_time=0.44130 
Train Epoch: 13 [473/500 30272/32000 (95%)] Loss: 0.09148 (QuantReg: 10.88800) QuantErr: 10.88800 batch_time=0.49204 
Train Epoch: 13 [481/500 30784/32000 (96%)] Loss: 0.09148 (QuantReg: 10.62350) QuantErr: 10.62350 batch_time=0.59082 
Train Epoch: 13 [489/500 31296/32000 (98%)] Loss: 0.03544 (QuantReg: 10.28443) QuantErr: 10.28443 batch_time=0.44687 
Train Epoch: 13 [497/500 31808/32000 (99%)] Loss: 0.04663 (QuantReg: 10.61007) QuantErr: 10.61007 batch_time=0.45746 
Train Epoch: 13 codebook_update_time=2.06205
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_ActivityNet_bs64/checkpoint-epoch13.pth ...
Done in 6.366s
Updating 'best' checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_ActivityNet_bs64/checkpoint-epoch13.pth ...
Done in 11.295s
removing stale ckpt [epoch 12] [took 0.01s]
 epoch          : 13
 loss           : 0.07372945679724216
 quant_reg      : 10.618706459045411
 quant_err      : 10.618706459045411
 learning_rate  : 1.885747578125e-05
 n_samples      : 416000
 n_steps        : 6500
 ActivityNet_val1_test/t2v_metrics/R1: 19.11734797640838
 ActivityNet_val1_test/t2v_metrics/R5: 48.89160056945292
 ActivityNet_val1_test/t2v_metrics/R10: 66.52430343705511
 ActivityNet_val1_test/t2v_metrics/R50: 91.78360789099044
 ActivityNet_val1_test/t2v_metrics/MedR: 6.0
 ActivityNet_val1_test/t2v_metrics/MeanR: 26.03396379906447
 ActivityNet_val1_test/t2v_metrics/geometric_mean_R1-R5-R10: 39.616923367278034
 ActivityNet_val1_test/v2t_metrics/R1: 19.503762456782592
 ActivityNet_val1_test/v2t_metrics/R5: 50.152532031726665
 ActivityNet_val1_test/v2t_metrics/R10: 67.80557250355908
 ActivityNet_val1_test/v2t_metrics/R50: 91.96664632906244
 ActivityNet_val1_test/v2t_metrics/MedR: 5.0
 ActivityNet_val1_test/v2t_metrics/MeanR: 24.318080130160666
 ActivityNet_val1_test/v2t_metrics/geometric_mean_R1-R5-R10: 40.47860619922018
 mnt_best       : 39.616923367278034
 not_improved_count: 0
Train Epoch: 14 [1/500 64/32000 (0%)] Loss: 0.05153 (QuantReg: 10.47621) QuantErr: 10.47621 batch_time=24.76964 
Train Epoch: 14 [9/500 576/32000 (2%)] Loss: 0.05533 (QuantReg: 10.70947) QuantErr: 10.70947 batch_time=0.44064 
Train Epoch: 14 [17/500 1088/32000 (3%)] Loss: 0.05817 (QuantReg: 10.30405) QuantErr: 10.30405 batch_time=0.43227 
Train Epoch: 14 [25/500 1600/32000 (5%)] Loss: 0.04806 (QuantReg: 10.55696) QuantErr: 10.55696 batch_time=0.43682 
Train Epoch: 14 [33/500 2112/32000 (7%)] Loss: 0.07096 (QuantReg: 10.39018) QuantErr: 10.39018 batch_time=0.43416 
Train Epoch: 14 [41/500 2624/32000 (8%)] Loss: 0.04922 (QuantReg: 10.86429) QuantErr: 10.86429 batch_time=0.44488 
Train Epoch: 14 [49/500 3136/32000 (10%)] Loss: 0.05502 (QuantReg: 10.62571) QuantErr: 10.62571 batch_time=0.45020 
Train Epoch: 14 [57/500 3648/32000 (11%)] Loss: 0.05715 (QuantReg: 10.50990) QuantErr: 10.50990 batch_time=0.44751 
Train Epoch: 14 [65/500 4160/32000 (13%)] Loss: 0.04041 (QuantReg: 10.77978) QuantErr: 10.77978 batch_time=1.14749 
Train Epoch: 14 [73/500 4672/32000 (15%)] Loss: 0.07111 (QuantReg: 10.54138) QuantErr: 10.54138 batch_time=0.43578 
Train Epoch: 14 [81/500 5184/32000 (16%)] Loss: 0.06366 (QuantReg: 10.47645) QuantErr: 10.47645 batch_time=0.46853 
Train Epoch: 14 [89/500 5696/32000 (18%)] Loss: 0.06863 (QuantReg: 10.37416) QuantErr: 10.37416 batch_time=0.43442 
Train Epoch: 14 [97/500 6208/32000 (19%)] Loss: 0.06467 (QuantReg: 10.14384) QuantErr: 10.14384 batch_time=0.43475 
Train Epoch: 14 [105/500 6720/32000 (21%)] Loss: 0.06549 (QuantReg: 10.27387) QuantErr: 10.27387 batch_time=0.43682 
Train Epoch: 14 [113/500 7232/32000 (23%)] Loss: 0.06305 (QuantReg: 10.41282) QuantErr: 10.41282 batch_time=0.43577 
Train Epoch: 14 [121/500 7744/32000 (24%)] Loss: 0.10197 (QuantReg: 10.53879) QuantErr: 10.53879 batch_time=0.43580 
Train Epoch: 14 [129/500 8256/32000 (26%)] Loss: 0.04272 (QuantReg: 10.39444) QuantErr: 10.39444 batch_time=1.14229 
Train Epoch: 14 [137/500 8768/32000 (27%)] Loss: 0.06585 (QuantReg: 10.69934) QuantErr: 10.69934 batch_time=0.44178 
Train Epoch: 14 [145/500 9280/32000 (29%)] Loss: 0.04365 (QuantReg: 10.83848) QuantErr: 10.83848 batch_time=0.43610 
Train Epoch: 14 [153/500 9792/32000 (31%)] Loss: 0.05802 (QuantReg: 10.25937) QuantErr: 10.25937 batch_time=0.44327 
Train Epoch: 14 [161/500 10304/32000 (32%)] Loss: 0.07137 (QuantReg: 10.52756) QuantErr: 10.52756 batch_time=0.44336 
Train Epoch: 14 [169/500 10816/32000 (34%)] Loss: 0.09891 (QuantReg: 10.38025) QuantErr: 10.38025 batch_time=0.45554 
Train Epoch: 14 [177/500 11328/32000 (35%)] Loss: 0.15103 (QuantReg: 10.65273) QuantErr: 10.65273 batch_time=0.45630 
Train Epoch: 14 [185/500 11840/32000 (37%)] Loss: 0.07087 (QuantReg: 10.72101) QuantErr: 10.72101 batch_time=0.44330 
Train Epoch: 14 [193/500 12352/32000 (39%)] Loss: 0.13772 (QuantReg: 10.59171) QuantErr: 10.59171 batch_time=1.15677 
Train Epoch: 14 [201/500 12864/32000 (40%)] Loss: 0.05353 (QuantReg: 10.66425) QuantErr: 10.66425 batch_time=0.44809 
Train Epoch: 14 [209/500 13376/32000 (42%)] Loss: 0.05668 (QuantReg: 10.76557) QuantErr: 10.76557 batch_time=0.45580 
Train Epoch: 14 [217/500 13888/32000 (43%)] Loss: 0.05989 (QuantReg: 10.43546) QuantErr: 10.43546 batch_time=0.45134 
Train Epoch: 14 [225/500 14400/32000 (45%)] Loss: 0.07331 (QuantReg: 10.77045) QuantErr: 10.77045 batch_time=0.47328 
Train Epoch: 14 [233/500 14912/32000 (47%)] Loss: 0.04072 (QuantReg: 10.62132) QuantErr: 10.62132 batch_time=0.44570 
Train Epoch: 14 [241/500 15424/32000 (48%)] Loss: 0.10427 (QuantReg: 10.64168) QuantErr: 10.64168 batch_time=0.44666 
Train Epoch: 14 [249/500 15936/32000 (50%)] Loss: 0.02534 (QuantReg: 10.62281) QuantErr: 10.62281 batch_time=0.44915 
Train Epoch: 14 [257/500 16448/32000 (51%)] Loss: 0.09162 (QuantReg: 10.35651) QuantErr: 10.35651 batch_time=1.16849 
Train Epoch: 14 [265/500 16960/32000 (53%)] Loss: 0.05466 (QuantReg: 10.69396) QuantErr: 10.69396 batch_time=0.43628 
Train Epoch: 14 [273/500 17472/32000 (55%)] Loss: 0.06121 (QuantReg: 10.32562) QuantErr: 10.32562 batch_time=0.43280 
Train Epoch: 14 [281/500 17984/32000 (56%)] Loss: 0.07141 (QuantReg: 10.56963) QuantErr: 10.56963 batch_time=0.42634 
Train Epoch: 14 [289/500 18496/32000 (58%)] Loss: 0.05247 (QuantReg: 10.49956) QuantErr: 10.49956 batch_time=0.44416 
Train Epoch: 14 [297/500 19008/32000 (59%)] Loss: 0.06098 (QuantReg: 10.53318) QuantErr: 10.53318 batch_time=0.46007 
Train Epoch: 14 [305/500 19520/32000 (61%)] Loss: 0.13047 (QuantReg: 10.81407) QuantErr: 10.81407 batch_time=0.46321 
Train Epoch: 14 [313/500 20032/32000 (63%)] Loss: 0.05028 (QuantReg: 10.55590) QuantErr: 10.55590 batch_time=0.45044 
Train Epoch: 14 [321/500 20544/32000 (64%)] Loss: 0.08822 (QuantReg: 10.61785) QuantErr: 10.61785 batch_time=1.23007 
Train Epoch: 14 [329/500 21056/32000 (66%)] Loss: 0.10224 (QuantReg: 10.41606) QuantErr: 10.41606 batch_time=0.45346 
Train Epoch: 14 [337/500 21568/32000 (67%)] Loss: 0.10859 (QuantReg: 10.60519) QuantErr: 10.60519 batch_time=0.46717 
Train Epoch: 14 [345/500 22080/32000 (69%)] Loss: 0.05229 (QuantReg: 10.40687) QuantErr: 10.40687 batch_time=0.44904 
Train Epoch: 14 [353/500 22592/32000 (71%)] Loss: 0.06106 (QuantReg: 10.62314) QuantErr: 10.62314 batch_time=0.46430 
Train Epoch: 14 [361/500 23104/32000 (72%)] Loss: 0.07460 (QuantReg: 10.88827) QuantErr: 10.88827 batch_time=0.45874 
Train Epoch: 14 [369/500 23616/32000 (74%)] Loss: 0.07442 (QuantReg: 10.58517) QuantErr: 10.58517 batch_time=0.45040 
Train Epoch: 14 [377/500 24128/32000 (75%)] Loss: 0.07484 (QuantReg: 10.66237) QuantErr: 10.66237 batch_time=0.44763 
Train Epoch: 14 [385/500 24640/32000 (77%)] Loss: 0.12181 (QuantReg: 10.45154) QuantErr: 10.45154 batch_time=1.18554 
Train Epoch: 14 [393/500 25152/32000 (79%)] Loss: 0.06446 (QuantReg: 10.46528) QuantErr: 10.46528 batch_time=0.44232 
Train Epoch: 14 [401/500 25664/32000 (80%)] Loss: 0.06909 (QuantReg: 10.41040) QuantErr: 10.41040 batch_time=0.47379 
Train Epoch: 14 [409/500 26176/32000 (82%)] Loss: 0.11476 (QuantReg: 10.50686) QuantErr: 10.50686 batch_time=0.47328 
Train Epoch: 14 [417/500 26688/32000 (83%)] Loss: 0.06462 (QuantReg: 10.60811) QuantErr: 10.60811 batch_time=0.51132 
Train Epoch: 14 [425/500 27200/32000 (85%)] Loss: 0.08536 (QuantReg: 10.78883) QuantErr: 10.78883 batch_time=0.48523 
Train Epoch: 14 [433/500 27712/32000 (87%)] Loss: 0.05030 (QuantReg: 10.61360) QuantErr: 10.61360 batch_time=0.48335 
Train Epoch: 14 [441/500 28224/32000 (88%)] Loss: 0.04134 (QuantReg: 10.69052) QuantErr: 10.69052 batch_time=0.44808 
Train Epoch: 14 [449/500 28736/32000 (90%)] Loss: 0.07483 (QuantReg: 10.57022) QuantErr: 10.57022 batch_time=1.40418 
Train Epoch: 14 [457/500 29248/32000 (91%)] Loss: 0.03893 (QuantReg: 10.66520) QuantErr: 10.66520 batch_time=0.43587 
Train Epoch: 14 [465/500 29760/32000 (93%)] Loss: 0.05953 (QuantReg: 10.57741) QuantErr: 10.57741 batch_time=0.43710 
Train Epoch: 14 [473/500 30272/32000 (95%)] Loss: 0.04206 (QuantReg: 10.88917) QuantErr: 10.88917 batch_time=0.44303 
Train Epoch: 14 [481/500 30784/32000 (96%)] Loss: 0.04792 (QuantReg: 10.78934) QuantErr: 10.78934 batch_time=0.44996 
Train Epoch: 14 [489/500 31296/32000 (98%)] Loss: 0.04736 (QuantReg: 10.67389) QuantErr: 10.67389 batch_time=0.45064 
Train Epoch: 14 [497/500 31808/32000 (99%)] Loss: 0.12007 (QuantReg: 10.55945) QuantErr: 10.55945 batch_time=0.44470 
Train Epoch: 14 codebook_update_time=1.66221
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_ActivityNet_bs64/checkpoint-epoch14.pth ...
Done in 4.725s
removing stale ckpt [epoch 13] [took 0.01s]
 epoch          : 14
 loss           : 0.06781851695105433
 quant_reg      : 10.562030179977416
 quant_err      : 10.562030179977416
 learning_rate  : 1.885747578125e-05
 n_samples      : 448000
 n_steps        : 7000
 ActivityNet_val1_test/t2v_metrics/R1: 18.466544641041285
 ActivityNet_val1_test/t2v_metrics/R5: 49.03396379906447
 ActivityNet_val1_test/t2v_metrics/R10: 66.34126499898312
 ActivityNet_val1_test/t2v_metrics/R50: 90.68537726255848
 ActivityNet_val1_test/t2v_metrics/MedR: 6.0
 ActivityNet_val1_test/t2v_metrics/MeanR: 26.664836282285947
 ActivityNet_val1_test/t2v_metrics/geometric_mean_R1-R5-R10: 39.16415826486886
 ActivityNet_val1_test/v2t_metrics/R1: 19.23937360178971
 ActivityNet_val1_test/v2t_metrics/R5: 50.23388244864755
 ActivityNet_val1_test/v2t_metrics/R10: 66.82936750050844
 ActivityNet_val1_test/v2t_metrics/R50: 91.35651820215578
 ActivityNet_val1_test/v2t_metrics/MedR: 5.0
 ActivityNet_val1_test/v2t_metrics/MeanR: 25.612161887329673
 ActivityNet_val1_test/v2t_metrics/geometric_mean_R1-R5-R10: 40.12222489915012
 mnt_best       : 39.616923367278034
 not_improved_count: 1
Train Epoch: 15 [1/500 64/32000 (0%)] Loss: 0.07048 (QuantReg: 10.43659) QuantErr: 10.43659 batch_time=23.87992 
Train Epoch: 15 [9/500 576/32000 (2%)] Loss: 0.03509 (QuantReg: 10.42471) QuantErr: 10.42471 batch_time=0.45166 
Train Epoch: 15 [17/500 1088/32000 (3%)] Loss: 0.02879 (QuantReg: 10.47843) QuantErr: 10.47843 batch_time=0.44900 
Train Epoch: 15 [25/500 1600/32000 (5%)] Loss: 0.10291 (QuantReg: 10.32848) QuantErr: 10.32848 batch_time=0.54780 
Train Epoch: 15 [33/500 2112/32000 (7%)] Loss: 0.06084 (QuantReg: 10.73057) QuantErr: 10.73057 batch_time=0.44711 
Train Epoch: 15 [41/500 2624/32000 (8%)] Loss: 0.03424 (QuantReg: 10.57654) QuantErr: 10.57654 batch_time=0.47351 
Train Epoch: 15 [49/500 3136/32000 (10%)] Loss: 0.12948 (QuantReg: 10.57214) QuantErr: 10.57214 batch_time=0.44814 
Train Epoch: 15 [57/500 3648/32000 (11%)] Loss: 0.02821 (QuantReg: 10.45718) QuantErr: 10.45718 batch_time=0.44918 
Train Epoch: 15 [65/500 4160/32000 (13%)] Loss: 0.08130 (QuantReg: 10.32742) QuantErr: 10.32742 batch_time=0.70113 
Train Epoch: 15 [73/500 4672/32000 (15%)] Loss: 0.04179 (QuantReg: 10.38690) QuantErr: 10.38690 batch_time=0.45424 
Train Epoch: 15 [81/500 5184/32000 (16%)] Loss: 0.08566 (QuantReg: 10.43253) QuantErr: 10.43253 batch_time=0.44389 
Train Epoch: 15 [89/500 5696/32000 (18%)] Loss: 0.05404 (QuantReg: 10.27381) QuantErr: 10.27381 batch_time=0.55948 
Train Epoch: 15 [97/500 6208/32000 (19%)] Loss: 0.03540 (QuantReg: 10.39282) QuantErr: 10.39282 batch_time=0.43347 
Train Epoch: 15 [105/500 6720/32000 (21%)] Loss: 0.04758 (QuantReg: 10.47665) QuantErr: 10.47665 batch_time=0.47310 
Train Epoch: 15 [113/500 7232/32000 (23%)] Loss: 0.07438 (QuantReg: 10.68626) QuantErr: 10.68626 batch_time=0.44667 
Train Epoch: 15 [121/500 7744/32000 (24%)] Loss: 0.05879 (QuantReg: 10.61436) QuantErr: 10.61436 batch_time=0.43770 
Train Epoch: 15 [129/500 8256/32000 (26%)] Loss: 0.08550 (QuantReg: 10.43573) QuantErr: 10.43573 batch_time=0.70866 
Train Epoch: 15 [137/500 8768/32000 (27%)] Loss: 0.08099 (QuantReg: 10.50319) QuantErr: 10.50319 batch_time=0.43645 
Train Epoch: 15 [145/500 9280/32000 (29%)] Loss: 0.04696 (QuantReg: 10.39098) QuantErr: 10.39098 batch_time=0.43606 
Train Epoch: 15 [153/500 9792/32000 (31%)] Loss: 0.04864 (QuantReg: 10.63561) QuantErr: 10.63561 batch_time=0.52955 
Train Epoch: 15 [161/500 10304/32000 (32%)] Loss: 0.04202 (QuantReg: 10.88870) QuantErr: 10.88870 batch_time=0.43958 
Train Epoch: 15 [169/500 10816/32000 (34%)] Loss: 0.08442 (QuantReg: 10.22976) QuantErr: 10.22976 batch_time=0.47040 
Train Epoch: 15 [177/500 11328/32000 (35%)] Loss: 0.04236 (QuantReg: 10.48120) QuantErr: 10.48120 batch_time=0.43690 
Train Epoch: 15 [185/500 11840/32000 (37%)] Loss: 0.05011 (QuantReg: 10.37527) QuantErr: 10.37527 batch_time=0.43577 
Train Epoch: 15 [193/500 12352/32000 (39%)] Loss: 0.04054 (QuantReg: 10.35364) QuantErr: 10.35364 batch_time=0.70003 
Train Epoch: 15 [201/500 12864/32000 (40%)] Loss: 0.03794 (QuantReg: 10.53497) QuantErr: 10.53497 batch_time=0.44010 
Train Epoch: 15 [209/500 13376/32000 (42%)] Loss: 0.07214 (QuantReg: 10.19510) QuantErr: 10.19510 batch_time=0.43633 
Train Epoch: 15 [217/500 13888/32000 (43%)] Loss: 0.10988 (QuantReg: 10.51399) QuantErr: 10.51399 batch_time=0.54025 
Train Epoch: 15 [225/500 14400/32000 (45%)] Loss: 0.07261 (QuantReg: 10.50713) QuantErr: 10.50713 batch_time=0.43395 
Train Epoch: 15 [233/500 14912/32000 (47%)] Loss: 0.04515 (QuantReg: 10.54557) QuantErr: 10.54557 batch_time=0.50072 
Train Epoch: 15 [241/500 15424/32000 (48%)] Loss: 0.04772 (QuantReg: 10.54708) QuantErr: 10.54708 batch_time=0.43289 
Train Epoch: 15 [249/500 15936/32000 (50%)] Loss: 0.02981 (QuantReg: 10.79491) QuantErr: 10.79491 batch_time=0.43549 
Train Epoch: 15 [257/500 16448/32000 (51%)] Loss: 0.05417 (QuantReg: 10.37514) QuantErr: 10.37514 batch_time=0.73619 
Train Epoch: 15 [265/500 16960/32000 (53%)] Loss: 0.03085 (QuantReg: 10.51942) QuantErr: 10.51942 batch_time=0.43738 
Train Epoch: 15 [273/500 17472/32000 (55%)] Loss: 0.03370 (QuantReg: 10.15055) QuantErr: 10.15055 batch_time=0.44060 
Train Epoch: 15 [281/500 17984/32000 (56%)] Loss: 0.03448 (QuantReg: 10.67043) QuantErr: 10.67043 batch_time=0.54287 
Train Epoch: 15 [289/500 18496/32000 (58%)] Loss: 0.07571 (QuantReg: 10.55107) QuantErr: 10.55107 batch_time=0.43793 
Train Epoch: 15 [297/500 19008/32000 (59%)] Loss: 0.03439 (QuantReg: 10.52312) QuantErr: 10.52312 batch_time=0.46698 
Train Epoch: 15 [305/500 19520/32000 (61%)] Loss: 0.06417 (QuantReg: 10.13315) QuantErr: 10.13315 batch_time=0.44137 
Train Epoch: 15 [313/500 20032/32000 (63%)] Loss: 0.07978 (QuantReg: 10.49199) QuantErr: 10.49199 batch_time=0.43994 
Train Epoch: 15 [321/500 20544/32000 (64%)] Loss: 0.04844 (QuantReg: 10.10816) QuantErr: 10.10816 batch_time=0.71806 
Train Epoch: 15 [329/500 21056/32000 (66%)] Loss: 0.07274 (QuantReg: 10.44595) QuantErr: 10.44595 batch_time=0.44626 
Train Epoch: 15 [337/500 21568/32000 (67%)] Loss: 0.05373 (QuantReg: 10.61259) QuantErr: 10.61259 batch_time=0.43415 
Train Epoch: 15 [345/500 22080/32000 (69%)] Loss: 0.04055 (QuantReg: 10.55547) QuantErr: 10.55547 batch_time=0.54802 
Train Epoch: 15 [353/500 22592/32000 (71%)] Loss: 0.06990 (QuantReg: 10.45064) QuantErr: 10.45064 batch_time=0.43433 
Train Epoch: 15 [361/500 23104/32000 (72%)] Loss: 0.07740 (QuantReg: 10.51233) QuantErr: 10.51233 batch_time=0.46401 
Train Epoch: 15 [369/500 23616/32000 (74%)] Loss: 0.04498 (QuantReg: 10.41543) QuantErr: 10.41543 batch_time=0.43460 
Train Epoch: 15 [377/500 24128/32000 (75%)] Loss: 0.05507 (QuantReg: 10.39020) QuantErr: 10.39020 batch_time=0.45165 
Train Epoch: 15 [385/500 24640/32000 (77%)] Loss: 0.03647 (QuantReg: 10.42753) QuantErr: 10.42753 batch_time=0.73611 
Train Epoch: 15 [393/500 25152/32000 (79%)] Loss: 0.04283 (QuantReg: 10.30027) QuantErr: 10.30027 batch_time=0.43641 
Train Epoch: 15 [401/500 25664/32000 (80%)] Loss: 0.11935 (QuantReg: 10.37118) QuantErr: 10.37118 batch_time=0.44132 
Train Epoch: 15 [409/500 26176/32000 (82%)] Loss: 0.11623 (QuantReg: 10.30652) QuantErr: 10.30652 batch_time=0.54074 
Train Epoch: 15 [417/500 26688/32000 (83%)] Loss: 0.03337 (QuantReg: 10.58553) QuantErr: 10.58553 batch_time=0.43722 
Train Epoch: 15 [425/500 27200/32000 (85%)] Loss: 0.05146 (QuantReg: 10.54912) QuantErr: 10.54912 batch_time=0.49096 
Train Epoch: 15 [433/500 27712/32000 (87%)] Loss: 0.04277 (QuantReg: 10.41061) QuantErr: 10.41061 batch_time=0.44521 
Train Epoch: 15 [441/500 28224/32000 (88%)] Loss: 0.08020 (QuantReg: 10.47392) QuantErr: 10.47392 batch_time=0.44506 
Train Epoch: 15 [449/500 28736/32000 (90%)] Loss: 0.05110 (QuantReg: 10.53700) QuantErr: 10.53700 batch_time=0.71255 
Train Epoch: 15 [457/500 29248/32000 (91%)] Loss: 0.02908 (QuantReg: 10.31263) QuantErr: 10.31263 batch_time=0.43897 
Train Epoch: 15 [465/500 29760/32000 (93%)] Loss: 0.04011 (QuantReg: 10.49089) QuantErr: 10.49089 batch_time=0.43921 
Train Epoch: 15 [473/500 30272/32000 (95%)] Loss: 0.03239 (QuantReg: 10.64103) QuantErr: 10.64103 batch_time=0.52453 
Train Epoch: 15 [481/500 30784/32000 (96%)] Loss: 0.10007 (QuantReg: 10.34645) QuantErr: 10.34645 batch_time=0.43627 
Train Epoch: 15 [489/500 31296/32000 (98%)] Loss: 0.04101 (QuantReg: 10.57511) QuantErr: 10.57511 batch_time=0.47444 
Train Epoch: 15 [497/500 31808/32000 (99%)] Loss: 0.03169 (QuantReg: 10.25303) QuantErr: 10.25303 batch_time=0.45345 
Train Epoch: 15 codebook_update_time=1.90242
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_ActivityNet_bs64/checkpoint-epoch15.pth ...
Done in 4.594s
Updating 'best' checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_ActivityNet_bs64/checkpoint-epoch15.pth ...
Done in 9.918s
removing stale ckpt [epoch 14] [took 0.01s]
 epoch          : 15
 loss           : 0.06247389308363199
 quant_reg      : 10.470622211456298
 quant_err      : 10.470622211456298
 learning_rate  : 1.6028854414062497e-05
 n_samples      : 480000
 n_steps        : 7500
 ActivityNet_val1_test/t2v_metrics/R1: 18.8529591214155
 ActivityNet_val1_test/t2v_metrics/R5: 49.603416717510676
 ActivityNet_val1_test/t2v_metrics/R10: 66.54464104128533
 ActivityNet_val1_test/t2v_metrics/R50: 90.92942851332113
 ActivityNet_val1_test/t2v_metrics/MedR: 6.0
 ActivityNet_val1_test/t2v_metrics/MeanR: 26.55867398820419
 ActivityNet_val1_test/t2v_metrics/geometric_mean_R1-R5-R10: 39.62793131021209
 ActivityNet_val1_test/v2t_metrics/R1: 19.72747610331503
 ActivityNet_val1_test/v2t_metrics/R5: 50.905023388244864
 ActivityNet_val1_test/v2t_metrics/R10: 67.52084604433598
 ActivityNet_val1_test/v2t_metrics/R50: 91.53955664022779
 ActivityNet_val1_test/v2t_metrics/MedR: 5.0
 ActivityNet_val1_test/v2t_metrics/MeanR: 24.522066300589792
 ActivityNet_val1_test/v2t_metrics/geometric_mean_R1-R5-R10: 40.77775831880548
 mnt_best       : 39.62793131021209
 not_improved_count: 0
Train Epoch: 16 [1/500 64/32000 (0%)] Loss: 0.05109 (QuantReg: 10.56323) QuantErr: 10.56323 batch_time=24.44682 
Train Epoch: 16 [9/500 576/32000 (2%)] Loss: 0.03128 (QuantReg: 10.36097) QuantErr: 10.36097 batch_time=0.47035 
Train Epoch: 16 [17/500 1088/32000 (3%)] Loss: 0.06480 (QuantReg: 10.32877) QuantErr: 10.32877 batch_time=0.68128 
Train Epoch: 16 [25/500 1600/32000 (5%)] Loss: 0.02841 (QuantReg: 10.66510) QuantErr: 10.66510 batch_time=0.45579 
Train Epoch: 16 [33/500 2112/32000 (7%)] Loss: 0.05763 (QuantReg: 10.25467) QuantErr: 10.25467 batch_time=0.45913 
Train Epoch: 16 [41/500 2624/32000 (8%)] Loss: 0.10498 (QuantReg: 10.45000) QuantErr: 10.45000 batch_time=0.45009 
Train Epoch: 16 [49/500 3136/32000 (10%)] Loss: 0.05523 (QuantReg: 10.31871) QuantErr: 10.31871 batch_time=0.44120 
Train Epoch: 16 [57/500 3648/32000 (11%)] Loss: 0.04536 (QuantReg: 10.40854) QuantErr: 10.40854 batch_time=0.47997 
Train Epoch: 16 [65/500 4160/32000 (13%)] Loss: 0.04261 (QuantReg: 10.31597) QuantErr: 10.31597 batch_time=0.60952 
Train Epoch: 16 [73/500 4672/32000 (15%)] Loss: 0.03370 (QuantReg: 10.22434) QuantErr: 10.22434 batch_time=0.44304 
Train Epoch: 16 [81/500 5184/32000 (16%)] Loss: 0.04245 (QuantReg: 10.23509) QuantErr: 10.23509 batch_time=0.62773 
Train Epoch: 16 [89/500 5696/32000 (18%)] Loss: 0.04403 (QuantReg: 10.42171) QuantErr: 10.42171 batch_time=0.45991 
Train Epoch: 16 [97/500 6208/32000 (19%)] Loss: 0.09278 (QuantReg: 10.16208) QuantErr: 10.16208 batch_time=0.45043 
Train Epoch: 16 [105/500 6720/32000 (21%)] Loss: 0.04853 (QuantReg: 10.32884) QuantErr: 10.32884 batch_time=0.44638 
Train Epoch: 16 [113/500 7232/32000 (23%)] Loss: 0.03891 (QuantReg: 10.72815) QuantErr: 10.72815 batch_time=0.44927 
Train Epoch: 16 [121/500 7744/32000 (24%)] Loss: 0.03556 (QuantReg: 10.60581) QuantErr: 10.60581 batch_time=0.43324 
Train Epoch: 16 [129/500 8256/32000 (26%)] Loss: 0.04940 (QuantReg: 10.52056) QuantErr: 10.52056 batch_time=0.63245 
Train Epoch: 16 [137/500 8768/32000 (27%)] Loss: 0.09314 (QuantReg: 10.24239) QuantErr: 10.24239 batch_time=0.44871 
Train Epoch: 16 [145/500 9280/32000 (29%)] Loss: 0.02899 (QuantReg: 10.49487) QuantErr: 10.49487 batch_time=0.62152 
Train Epoch: 16 [153/500 9792/32000 (31%)] Loss: 0.04678 (QuantReg: 10.51492) QuantErr: 10.51492 batch_time=0.44836 
Train Epoch: 16 [161/500 10304/32000 (32%)] Loss: 0.04667 (QuantReg: 10.54294) QuantErr: 10.54294 batch_time=0.44280 
Train Epoch: 16 [169/500 10816/32000 (34%)] Loss: 0.08104 (QuantReg: 10.06906) QuantErr: 10.06906 batch_time=0.44806 
Train Epoch: 16 [177/500 11328/32000 (35%)] Loss: 0.05291 (QuantReg: 10.24131) QuantErr: 10.24131 batch_time=0.43899 
Train Epoch: 16 [185/500 11840/32000 (37%)] Loss: 0.07416 (QuantReg: 10.45060) QuantErr: 10.45060 batch_time=0.43831 
Train Epoch: 16 [193/500 12352/32000 (39%)] Loss: 0.03298 (QuantReg: 10.31974) QuantErr: 10.31974 batch_time=0.59120 
Train Epoch: 16 [201/500 12864/32000 (40%)] Loss: 0.05133 (QuantReg: 10.68291) QuantErr: 10.68291 batch_time=0.43249 
Train Epoch: 16 [209/500 13376/32000 (42%)] Loss: 0.04141 (QuantReg: 10.23518) QuantErr: 10.23518 batch_time=0.60336 
Train Epoch: 16 [217/500 13888/32000 (43%)] Loss: 0.04375 (QuantReg: 10.73596) QuantErr: 10.73596 batch_time=0.44260 
Train Epoch: 16 [225/500 14400/32000 (45%)] Loss: 0.05208 (QuantReg: 10.39448) QuantErr: 10.39448 batch_time=0.45264 
Train Epoch: 16 [233/500 14912/32000 (47%)] Loss: 0.06083 (QuantReg: 10.34679) QuantErr: 10.34679 batch_time=0.44164 
Train Epoch: 16 [241/500 15424/32000 (48%)] Loss: 0.09323 (QuantReg: 10.66011) QuantErr: 10.66011 batch_time=0.45262 
Train Epoch: 16 [249/500 15936/32000 (50%)] Loss: 0.04787 (QuantReg: 10.62799) QuantErr: 10.62799 batch_time=0.44419 
Train Epoch: 16 [257/500 16448/32000 (51%)] Loss: 0.04253 (QuantReg: 10.56532) QuantErr: 10.56532 batch_time=0.60412 
Train Epoch: 16 [265/500 16960/32000 (53%)] Loss: 0.02505 (QuantReg: 9.93458) QuantErr: 9.93458 batch_time=0.44980 
Train Epoch: 16 [273/500 17472/32000 (55%)] Loss: 0.08345 (QuantReg: 10.49615) QuantErr: 10.49615 batch_time=0.59174 
Train Epoch: 16 [281/500 17984/32000 (56%)] Loss: 0.03227 (QuantReg: 10.27890) QuantErr: 10.27890 batch_time=0.44628 
Train Epoch: 16 [289/500 18496/32000 (58%)] Loss: 0.09133 (QuantReg: 10.32405) QuantErr: 10.32405 batch_time=0.44223 
Train Epoch: 16 [297/500 19008/32000 (59%)] Loss: 0.04635 (QuantReg: 10.40443) QuantErr: 10.40443 batch_time=0.44431 
Train Epoch: 16 [305/500 19520/32000 (61%)] Loss: 0.10140 (QuantReg: 10.20586) QuantErr: 10.20586 batch_time=0.43967 
Train Epoch: 16 [313/500 20032/32000 (63%)] Loss: 0.05788 (QuantReg: 10.20453) QuantErr: 10.20453 batch_time=0.44143 
Train Epoch: 16 [321/500 20544/32000 (64%)] Loss: 0.03457 (QuantReg: 10.43547) QuantErr: 10.43547 batch_time=0.60536 
Train Epoch: 16 [329/500 21056/32000 (66%)] Loss: 0.03090 (QuantReg: 10.21890) QuantErr: 10.21890 batch_time=0.45862 
Train Epoch: 16 [337/500 21568/32000 (67%)] Loss: 0.04096 (QuantReg: 10.31908) QuantErr: 10.31908 batch_time=0.62814 
Train Epoch: 16 [345/500 22080/32000 (69%)] Loss: 0.05502 (QuantReg: 10.41106) QuantErr: 10.41106 batch_time=0.44478 
Train Epoch: 16 [353/500 22592/32000 (71%)] Loss: 0.04062 (QuantReg: 10.27589) QuantErr: 10.27589 batch_time=0.44908 
Train Epoch: 16 [361/500 23104/32000 (72%)] Loss: 0.04108 (QuantReg: 10.43360) QuantErr: 10.43360 batch_time=0.44953 
Train Epoch: 16 [369/500 23616/32000 (74%)] Loss: 0.03585 (QuantReg: 10.43879) QuantErr: 10.43879 batch_time=0.45322 
Train Epoch: 16 [377/500 24128/32000 (75%)] Loss: 0.03976 (QuantReg: 10.52339) QuantErr: 10.52339 batch_time=0.44909 
Train Epoch: 16 [385/500 24640/32000 (77%)] Loss: 0.06259 (QuantReg: 10.36616) QuantErr: 10.36616 batch_time=0.59615 
Train Epoch: 16 [393/500 25152/32000 (79%)] Loss: 0.07013 (QuantReg: 10.51999) QuantErr: 10.51999 batch_time=0.45017 
Train Epoch: 16 [401/500 25664/32000 (80%)] Loss: 0.08967 (QuantReg: 10.57857) QuantErr: 10.57857 batch_time=0.62776 
Train Epoch: 16 [409/500 26176/32000 (82%)] Loss: 0.13608 (QuantReg: 10.24703) QuantErr: 10.24703 batch_time=0.45261 
Train Epoch: 16 [417/500 26688/32000 (83%)] Loss: 0.09077 (QuantReg: 10.15822) QuantErr: 10.15822 batch_time=0.44088 
Train Epoch: 16 [425/500 27200/32000 (85%)] Loss: 0.04207 (QuantReg: 10.20964) QuantErr: 10.20964 batch_time=0.47771 
Train Epoch: 16 [433/500 27712/32000 (87%)] Loss: 0.04079 (QuantReg: 10.27060) QuantErr: 10.27060 batch_time=0.44244 
Train Epoch: 16 [441/500 28224/32000 (88%)] Loss: 0.05842 (QuantReg: 10.31356) QuantErr: 10.31356 batch_time=0.45478 
Train Epoch: 16 [449/500 28736/32000 (90%)] Loss: 0.04969 (QuantReg: 10.56613) QuantErr: 10.56613 batch_time=0.61700 
Train Epoch: 16 [457/500 29248/32000 (91%)] Loss: 0.06645 (QuantReg: 10.49129) QuantErr: 10.49129 batch_time=0.44849 
Train Epoch: 16 [465/500 29760/32000 (93%)] Loss: 0.03165 (QuantReg: 10.56074) QuantErr: 10.56074 batch_time=0.59967 
Train Epoch: 16 [473/500 30272/32000 (95%)] Loss: 0.04948 (QuantReg: 10.46145) QuantErr: 10.46145 batch_time=0.45682 
Train Epoch: 16 [481/500 30784/32000 (96%)] Loss: 0.03068 (QuantReg: 10.40430) QuantErr: 10.40430 batch_time=0.46699 
Train Epoch: 16 [489/500 31296/32000 (98%)] Loss: 0.08221 (QuantReg: 10.36752) QuantErr: 10.36752 batch_time=0.44546 
Train Epoch: 16 [497/500 31808/32000 (99%)] Loss: 0.10514 (QuantReg: 10.77791) QuantErr: 10.77791 batch_time=0.44551 
Train Epoch: 16 codebook_update_time=1.67651
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_ActivityNet_bs64/checkpoint-epoch16.pth ...
Done in 4.239s
removing stale ckpt [epoch 15] [took 0.01s]
 epoch          : 16
 loss           : 0.06322762317955494
 quant_reg      : 10.390087066650391
 quant_err      : 10.390087066650391
 learning_rate  : 1.6028854414062497e-05
 n_samples      : 512000
 n_steps        : 8000
 ActivityNet_val1_test/t2v_metrics/R1: 18.73093349603417
 ActivityNet_val1_test/t2v_metrics/R5: 49.318690258287575
 ActivityNet_val1_test/t2v_metrics/R10: 66.788692292048
 ActivityNet_val1_test/t2v_metrics/R50: 90.99044132601179
 ActivityNet_val1_test/t2v_metrics/MedR: 6.0
 ActivityNet_val1_test/t2v_metrics/MeanR: 26.118771608704495
 ActivityNet_val1_test/t2v_metrics/geometric_mean_R1-R5-R10: 39.514634171255054
 ActivityNet_val1_test/v2t_metrics/R1: 19.910514541387023
 ActivityNet_val1_test/v2t_metrics/R5: 50.925360992475085
 ActivityNet_val1_test/v2t_metrics/R10: 67.84624771201952
 ActivityNet_val1_test/v2t_metrics/R50: 91.2751677852349
 ActivityNet_val1_test/v2t_metrics/MedR: 5.0
 ActivityNet_val1_test/v2t_metrics/MeanR: 25.65873500101688
 ActivityNet_val1_test/v2t_metrics/geometric_mean_R1-R5-R10: 40.974545454115464
 mnt_best       : 39.62793131021209
 not_improved_count: 1
Train Epoch: 17 [1/500 64/32000 (0%)] Loss: 0.07568 (QuantReg: 10.37139) QuantErr: 10.37139 batch_time=22.82601 
Train Epoch: 17 [9/500 576/32000 (2%)] Loss: 0.04988 (QuantReg: 10.24598) QuantErr: 10.24598 batch_time=0.44865 
Train Epoch: 17 [17/500 1088/32000 (3%)] Loss: 0.02774 (QuantReg: 10.17568) QuantErr: 10.17568 batch_time=0.67396 
Train Epoch: 17 [25/500 1600/32000 (5%)] Loss: 0.05620 (QuantReg: 10.34059) QuantErr: 10.34059 batch_time=0.44428 
Train Epoch: 17 [33/500 2112/32000 (7%)] Loss: 0.07731 (QuantReg: 10.45193) QuantErr: 10.45193 batch_time=0.71605 
Train Epoch: 17 [41/500 2624/32000 (8%)] Loss: 0.03438 (QuantReg: 10.19528) QuantErr: 10.19528 batch_time=0.44808 
Train Epoch: 17 [49/500 3136/32000 (10%)] Loss: 0.02551 (QuantReg: 10.43966) QuantErr: 10.43966 batch_time=0.67458 
Train Epoch: 17 [57/500 3648/32000 (11%)] Loss: 0.09869 (QuantReg: 10.19240) QuantErr: 10.19240 batch_time=0.44001 
Train Epoch: 17 [65/500 4160/32000 (13%)] Loss: 0.05262 (QuantReg: 10.05167) QuantErr: 10.05167 batch_time=0.43296 
Train Epoch: 17 [73/500 4672/32000 (15%)] Loss: 0.11564 (QuantReg: 10.31274) QuantErr: 10.31274 batch_time=0.44061 
Train Epoch: 17 [81/500 5184/32000 (16%)] Loss: 0.06169 (QuantReg: 10.27034) QuantErr: 10.27034 batch_time=0.65940 
Train Epoch: 17 [89/500 5696/32000 (18%)] Loss: 0.05996 (QuantReg: 10.04395) QuantErr: 10.04395 batch_time=0.44434 
Train Epoch: 17 [97/500 6208/32000 (19%)] Loss: 0.04345 (QuantReg: 10.34800) QuantErr: 10.34800 batch_time=0.44454 
Train Epoch: 17 [105/500 6720/32000 (21%)] Loss: 0.04519 (QuantReg: 10.33096) QuantErr: 10.33096 batch_time=0.44072 
Train Epoch: 17 [113/500 7232/32000 (23%)] Loss: 0.02300 (QuantReg: 10.41408) QuantErr: 10.41408 batch_time=0.67409 
Train Epoch: 17 [121/500 7744/32000 (24%)] Loss: 0.10397 (QuantReg: 10.31616) QuantErr: 10.31616 batch_time=0.45957 
Train Epoch: 17 [129/500 8256/32000 (26%)] Loss: 0.07354 (QuantReg: 10.53195) QuantErr: 10.53195 batch_time=0.44698 
Train Epoch: 17 [137/500 8768/32000 (27%)] Loss: 0.03042 (QuantReg: 10.64104) QuantErr: 10.64104 batch_time=0.44523 
Train Epoch: 17 [145/500 9280/32000 (29%)] Loss: 0.05474 (QuantReg: 10.42648) QuantErr: 10.42648 batch_time=0.66214 
Train Epoch: 17 [153/500 9792/32000 (31%)] Loss: 0.08073 (QuantReg: 10.36175) QuantErr: 10.36175 batch_time=0.43587 
Train Epoch: 17 [161/500 10304/32000 (32%)] Loss: 0.04684 (QuantReg: 10.16944) QuantErr: 10.16944 batch_time=0.43633 
Train Epoch: 17 [169/500 10816/32000 (34%)] Loss: 0.08709 (QuantReg: 10.15256) QuantErr: 10.15256 batch_time=0.47767 
Train Epoch: 17 [177/500 11328/32000 (35%)] Loss: 0.04038 (QuantReg: 10.19378) QuantErr: 10.19378 batch_time=0.64827 
Train Epoch: 17 [185/500 11840/32000 (37%)] Loss: 0.08285 (QuantReg: 9.91350) QuantErr: 9.91350 batch_time=0.44669 
Train Epoch: 17 [193/500 12352/32000 (39%)] Loss: 0.05194 (QuantReg: 10.54513) QuantErr: 10.54513 batch_time=0.44521 
Train Epoch: 17 [201/500 12864/32000 (40%)] Loss: 0.05709 (QuantReg: 10.39804) QuantErr: 10.39804 batch_time=0.45245 
Train Epoch: 17 [209/500 13376/32000 (42%)] Loss: 0.04594 (QuantReg: 10.45530) QuantErr: 10.45530 batch_time=0.67290 
Train Epoch: 17 [217/500 13888/32000 (43%)] Loss: 0.08768 (QuantReg: 10.28629) QuantErr: 10.28629 batch_time=0.46080 
Train Epoch: 17 [225/500 14400/32000 (45%)] Loss: 0.03685 (QuantReg: 10.34776) QuantErr: 10.34776 batch_time=0.44347 
Train Epoch: 17 [233/500 14912/32000 (47%)] Loss: 0.05754 (QuantReg: 10.38258) QuantErr: 10.38258 batch_time=0.44587 
Train Epoch: 17 [241/500 15424/32000 (48%)] Loss: 0.09987 (QuantReg: 10.28790) QuantErr: 10.28790 batch_time=0.65257 
Train Epoch: 17 [249/500 15936/32000 (50%)] Loss: 0.11169 (QuantReg: 10.23290) QuantErr: 10.23290 batch_time=0.44211 
Train Epoch: 17 [257/500 16448/32000 (51%)] Loss: 0.08311 (QuantReg: 10.27091) QuantErr: 10.27091 batch_time=0.45224 
Train Epoch: 17 [265/500 16960/32000 (53%)] Loss: 0.05004 (QuantReg: 10.23795) QuantErr: 10.23795 batch_time=0.43774 
Train Epoch: 17 [273/500 17472/32000 (55%)] Loss: 0.03525 (QuantReg: 10.32825) QuantErr: 10.32825 batch_time=0.67025 
Train Epoch: 17 [281/500 17984/32000 (56%)] Loss: 0.05410 (QuantReg: 10.11841) QuantErr: 10.11841 batch_time=0.43774 
Train Epoch: 17 [289/500 18496/32000 (58%)] Loss: 0.04417 (QuantReg: 10.19522) QuantErr: 10.19522 batch_time=0.44973 
Train Epoch: 17 [297/500 19008/32000 (59%)] Loss: 0.07808 (QuantReg: 10.15353) QuantErr: 10.15353 batch_time=0.45028 
Train Epoch: 17 [305/500 19520/32000 (61%)] Loss: 0.03137 (QuantReg: 10.15218) QuantErr: 10.15218 batch_time=0.69020 
Train Epoch: 17 [313/500 20032/32000 (63%)] Loss: 0.08895 (QuantReg: 10.13004) QuantErr: 10.13004 batch_time=0.44658 
Train Epoch: 17 [321/500 20544/32000 (64%)] Loss: 0.10128 (QuantReg: 10.23519) QuantErr: 10.23519 batch_time=0.45160 
Train Epoch: 17 [329/500 21056/32000 (66%)] Loss: 0.04063 (QuantReg: 10.08517) QuantErr: 10.08517 batch_time=0.44205 
Train Epoch: 17 [337/500 21568/32000 (67%)] Loss: 0.04930 (QuantReg: 10.24396) QuantErr: 10.24396 batch_time=0.68309 
Train Epoch: 17 [345/500 22080/32000 (69%)] Loss: 0.11028 (QuantReg: 10.53402) QuantErr: 10.53402 batch_time=0.45138 
Train Epoch: 17 [353/500 22592/32000 (71%)] Loss: 0.10341 (QuantReg: 10.27287) QuantErr: 10.27287 batch_time=0.44748 
Train Epoch: 17 [361/500 23104/32000 (72%)] Loss: 0.11381 (QuantReg: 9.94890) QuantErr: 9.94890 batch_time=0.44809 
Train Epoch: 17 [369/500 23616/32000 (74%)] Loss: 0.04302 (QuantReg: 10.34178) QuantErr: 10.34178 batch_time=0.67891 
Train Epoch: 17 [377/500 24128/32000 (75%)] Loss: 0.12227 (QuantReg: 10.25102) QuantErr: 10.25102 batch_time=0.45916 
Train Epoch: 17 [385/500 24640/32000 (77%)] Loss: 0.03121 (QuantReg: 10.47733) QuantErr: 10.47733 batch_time=0.44562 
Train Epoch: 17 [393/500 25152/32000 (79%)] Loss: 0.05611 (QuantReg: 10.49118) QuantErr: 10.49118 batch_time=0.44151 
Train Epoch: 17 [401/500 25664/32000 (80%)] Loss: 0.07205 (QuantReg: 9.84134) QuantErr: 9.84134 batch_time=0.65533 
Train Epoch: 17 [409/500 26176/32000 (82%)] Loss: 0.08157 (QuantReg: 10.12472) QuantErr: 10.12472 batch_time=0.44003 
Train Epoch: 17 [417/500 26688/32000 (83%)] Loss: 0.05050 (QuantReg: 10.16874) QuantErr: 10.16874 batch_time=0.44955 
Train Epoch: 17 [425/500 27200/32000 (85%)] Loss: 0.13362 (QuantReg: 10.22375) QuantErr: 10.22375 batch_time=0.44601 
Train Epoch: 17 [433/500 27712/32000 (87%)] Loss: 0.08751 (QuantReg: 10.03569) QuantErr: 10.03569 batch_time=0.68897 
Train Epoch: 17 [441/500 28224/32000 (88%)] Loss: 0.02998 (QuantReg: 10.40612) QuantErr: 10.40612 batch_time=0.44304 
Train Epoch: 17 [449/500 28736/32000 (90%)] Loss: 0.03224 (QuantReg: 10.28005) QuantErr: 10.28005 batch_time=0.43738 
Train Epoch: 17 [457/500 29248/32000 (91%)] Loss: 0.03994 (QuantReg: 10.34933) QuantErr: 10.34933 batch_time=0.45451 
Train Epoch: 17 [465/500 29760/32000 (93%)] Loss: 0.04441 (QuantReg: 10.17432) QuantErr: 10.17432 batch_time=0.66806 
Train Epoch: 17 [473/500 30272/32000 (95%)] Loss: 0.03987 (QuantReg: 10.30326) QuantErr: 10.30326 batch_time=0.43959 
Train Epoch: 17 [481/500 30784/32000 (96%)] Loss: 0.04974 (QuantReg: 10.27911) QuantErr: 10.27911 batch_time=0.45785 
Train Epoch: 17 [489/500 31296/32000 (98%)] Loss: 0.08376 (QuantReg: 10.74598) QuantErr: 10.74598 batch_time=0.44477 
Train Epoch: 17 [497/500 31808/32000 (99%)] Loss: 0.05990 (QuantReg: 9.91829) QuantErr: 9.91829 batch_time=0.68689 
Train Epoch: 17 codebook_update_time=1.68314
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_ActivityNet_bs64/checkpoint-epoch17.pth ...
Done in 4.692s
removing stale ckpt [epoch 16] [took 0.02s]
 epoch          : 17
 loss           : 0.05950580840185284
 quant_reg      : 10.278137628555298
 quant_err      : 10.278137628555298
 learning_rate  : 1.3624526251953122e-05
 n_samples      : 544000
 n_steps        : 8500
 ActivityNet_val1_test/t2v_metrics/R1: 18.28350620296929
 ActivityNet_val1_test/t2v_metrics/R5: 48.728899735611144
 ActivityNet_val1_test/t2v_metrics/R10: 65.42607280862315
 ActivityNet_val1_test/t2v_metrics/R50: 90.62436444986781
 ActivityNet_val1_test/t2v_metrics/MedR: 6.0
 ActivityNet_val1_test/t2v_metrics/MeanR: 29.13402481187716
 ActivityNet_val1_test/t2v_metrics/geometric_mean_R1-R5-R10: 38.773259681170856
 ActivityNet_val1_test/v2t_metrics/R1: 19.483424852552368
 ActivityNet_val1_test/v2t_metrics/R5: 50.96603620093553
 ActivityNet_val1_test/v2t_metrics/R10: 66.66666666666667
 ActivityNet_val1_test/v2t_metrics/R50: 90.94976611755135
 ActivityNet_val1_test/v2t_metrics/MedR: 5.0
 ActivityNet_val1_test/v2t_metrics/MeanR: 26.99003457392719
 ActivityNet_val1_test/v2t_metrics/geometric_mean_R1-R5-R10: 40.453083728172125
 mnt_best       : 39.62793131021209
 not_improved_count: 2
Train Epoch: 18 [1/500 64/32000 (0%)] Loss: 0.04569 (QuantReg: 10.08896) QuantErr: 10.08896 batch_time=22.95167 
Train Epoch: 18 [9/500 576/32000 (2%)] Loss: 0.03937 (QuantReg: 10.38411) QuantErr: 10.38411 batch_time=0.43783 
Train Epoch: 18 [17/500 1088/32000 (3%)] Loss: 0.03801 (QuantReg: 10.20780) QuantErr: 10.20780 batch_time=0.44574 
Train Epoch: 18 [25/500 1600/32000 (5%)] Loss: 0.03150 (QuantReg: 10.12752) QuantErr: 10.12752 batch_time=0.44319 
Train Epoch: 18 [33/500 2112/32000 (7%)] Loss: 0.08842 (QuantReg: 10.18055) QuantErr: 10.18055 batch_time=0.43915 
Train Epoch: 18 [41/500 2624/32000 (8%)] Loss: 0.04090 (QuantReg: 10.36178) QuantErr: 10.36178 batch_time=0.44506 
Train Epoch: 18 [49/500 3136/32000 (10%)] Loss: 0.02969 (QuantReg: 10.47816) QuantErr: 10.47816 batch_time=0.47935 
Train Epoch: 18 [57/500 3648/32000 (11%)] Loss: 0.02511 (QuantReg: 10.23553) QuantErr: 10.23553 batch_time=0.43841 
Train Epoch: 18 [65/500 4160/32000 (13%)] Loss: 0.05160 (QuantReg: 10.07924) QuantErr: 10.07924 batch_time=0.54309 
Train Epoch: 18 [73/500 4672/32000 (15%)] Loss: 0.03191 (QuantReg: 10.63348) QuantErr: 10.63348 batch_time=0.43989 
Train Epoch: 18 [81/500 5184/32000 (16%)] Loss: 0.03301 (QuantReg: 10.30085) QuantErr: 10.30085 batch_time=0.43870 
Train Epoch: 18 [89/500 5696/32000 (18%)] Loss: 0.08198 (QuantReg: 10.18625) QuantErr: 10.18625 batch_time=0.43885 
Train Epoch: 18 [97/500 6208/32000 (19%)] Loss: 0.03808 (QuantReg: 10.18746) QuantErr: 10.18746 batch_time=0.45078 
Train Epoch: 18 [105/500 6720/32000 (21%)] Loss: 0.07554 (QuantReg: 10.16430) QuantErr: 10.16430 batch_time=0.44430 
Train Epoch: 18 [113/500 7232/32000 (23%)] Loss: 0.08392 (QuantReg: 10.13834) QuantErr: 10.13834 batch_time=0.47741 
Train Epoch: 18 [121/500 7744/32000 (24%)] Loss: 0.02883 (QuantReg: 10.34009) QuantErr: 10.34009 batch_time=0.44512 
Train Epoch: 18 [129/500 8256/32000 (26%)] Loss: 0.07846 (QuantReg: 10.29889) QuantErr: 10.29889 batch_time=0.54353 
Train Epoch: 18 [137/500 8768/32000 (27%)] Loss: 0.07560 (QuantReg: 10.42632) QuantErr: 10.42632 batch_time=0.44378 
Train Epoch: 18 [145/500 9280/32000 (29%)] Loss: 0.04293 (QuantReg: 10.16640) QuantErr: 10.16640 batch_time=0.43563 
Train Epoch: 18 [153/500 9792/32000 (31%)] Loss: 0.03345 (QuantReg: 10.01947) QuantErr: 10.01947 batch_time=0.43446 
Train Epoch: 18 [161/500 10304/32000 (32%)] Loss: 0.04590 (QuantReg: 10.36405) QuantErr: 10.36405 batch_time=0.43933 
Train Epoch: 18 [169/500 10816/32000 (34%)] Loss: 0.03944 (QuantReg: 10.43079) QuantErr: 10.43079 batch_time=0.43951 
Train Epoch: 18 [177/500 11328/32000 (35%)] Loss: 0.04265 (QuantReg: 10.23650) QuantErr: 10.23650 batch_time=0.46813 
Train Epoch: 18 [185/500 11840/32000 (37%)] Loss: 0.08482 (QuantReg: 10.23246) QuantErr: 10.23246 batch_time=0.43931 
Train Epoch: 18 [193/500 12352/32000 (39%)] Loss: 0.02300 (QuantReg: 10.15482) QuantErr: 10.15482 batch_time=0.54470 
Train Epoch: 18 [201/500 12864/32000 (40%)] Loss: 0.03902 (QuantReg: 10.28560) QuantErr: 10.28560 batch_time=0.43790 
Train Epoch: 18 [209/500 13376/32000 (42%)] Loss: 0.03856 (QuantReg: 10.26198) QuantErr: 10.26198 batch_time=0.43876 
Train Epoch: 18 [217/500 13888/32000 (43%)] Loss: 0.02261 (QuantReg: 10.30037) QuantErr: 10.30037 batch_time=0.44732 
Train Epoch: 18 [225/500 14400/32000 (45%)] Loss: 0.06609 (QuantReg: 10.05981) QuantErr: 10.05981 batch_time=0.43647 
Train Epoch: 18 [233/500 14912/32000 (47%)] Loss: 0.03120 (QuantReg: 10.20809) QuantErr: 10.20809 batch_time=0.44872 
Train Epoch: 18 [241/500 15424/32000 (48%)] Loss: 0.05602 (QuantReg: 10.36547) QuantErr: 10.36547 batch_time=0.47140 
Train Epoch: 18 [249/500 15936/32000 (50%)] Loss: 0.03908 (QuantReg: 10.42390) QuantErr: 10.42390 batch_time=0.44077 
Train Epoch: 18 [257/500 16448/32000 (51%)] Loss: 0.04185 (QuantReg: 10.12610) QuantErr: 10.12610 batch_time=0.55401 
Train Epoch: 18 [265/500 16960/32000 (53%)] Loss: 0.10351 (QuantReg: 10.15794) QuantErr: 10.15794 batch_time=0.44104 
Train Epoch: 18 [273/500 17472/32000 (55%)] Loss: 0.03735 (QuantReg: 10.30180) QuantErr: 10.30180 batch_time=0.43998 
Train Epoch: 18 [281/500 17984/32000 (56%)] Loss: 0.05636 (QuantReg: 9.85332) QuantErr: 9.85332 batch_time=0.46920 
Train Epoch: 18 [289/500 18496/32000 (58%)] Loss: 0.03560 (QuantReg: 10.66492) QuantErr: 10.66492 batch_time=0.44061 
Train Epoch: 18 [297/500 19008/32000 (59%)] Loss: 0.02516 (QuantReg: 10.09833) QuantErr: 10.09833 batch_time=0.43732 
Train Epoch: 18 [305/500 19520/32000 (61%)] Loss: 0.05431 (QuantReg: 9.97643) QuantErr: 9.97643 batch_time=0.47372 
Train Epoch: 18 [313/500 20032/32000 (63%)] Loss: 0.11371 (QuantReg: 9.97416) QuantErr: 9.97416 batch_time=0.43893 
Train Epoch: 18 [321/500 20544/32000 (64%)] Loss: 0.02924 (QuantReg: 10.41768) QuantErr: 10.41768 batch_time=0.58280 
Train Epoch: 18 [329/500 21056/32000 (66%)] Loss: 0.03907 (QuantReg: 9.93568) QuantErr: 9.93568 batch_time=0.44114 
Train Epoch: 18 [337/500 21568/32000 (67%)] Loss: 0.04277 (QuantReg: 10.13828) QuantErr: 10.13828 batch_time=0.44115 
Train Epoch: 18 [345/500 22080/32000 (69%)] Loss: 0.04457 (QuantReg: 10.39643) QuantErr: 10.39643 batch_time=0.43838 
Train Epoch: 18 [353/500 22592/32000 (71%)] Loss: 0.04701 (QuantReg: 10.26615) QuantErr: 10.26615 batch_time=0.43848 
Train Epoch: 18 [361/500 23104/32000 (72%)] Loss: 0.08010 (QuantReg: 10.10530) QuantErr: 10.10530 batch_time=0.44497 
Train Epoch: 18 [369/500 23616/32000 (74%)] Loss: 0.03364 (QuantReg: 10.00517) QuantErr: 10.00517 batch_time=0.47385 
Train Epoch: 18 [377/500 24128/32000 (75%)] Loss: 0.04751 (QuantReg: 10.19905) QuantErr: 10.19905 batch_time=0.43908 
Train Epoch: 18 [385/500 24640/32000 (77%)] Loss: 0.03767 (QuantReg: 10.25772) QuantErr: 10.25772 batch_time=0.54697 
Train Epoch: 18 [393/500 25152/32000 (79%)] Loss: 0.03188 (QuantReg: 10.31629) QuantErr: 10.31629 batch_time=0.44512 
Train Epoch: 18 [401/500 25664/32000 (80%)] Loss: 0.05247 (QuantReg: 10.15503) QuantErr: 10.15503 batch_time=0.43838 
Train Epoch: 18 [409/500 26176/32000 (82%)] Loss: 0.02628 (QuantReg: 10.29668) QuantErr: 10.29668 batch_time=0.43769 
Train Epoch: 18 [417/500 26688/32000 (83%)] Loss: 0.02936 (QuantReg: 10.24694) QuantErr: 10.24694 batch_time=0.44133 
Train Epoch: 18 [425/500 27200/32000 (85%)] Loss: 0.07565 (QuantReg: 10.28788) QuantErr: 10.28788 batch_time=0.43805 
Train Epoch: 18 [433/500 27712/32000 (87%)] Loss: 0.08928 (QuantReg: 10.20339) QuantErr: 10.20339 batch_time=0.46864 
Train Epoch: 18 [441/500 28224/32000 (88%)] Loss: 0.05612 (QuantReg: 9.92331) QuantErr: 9.92331 batch_time=0.43867 
Train Epoch: 18 [449/500 28736/32000 (90%)] Loss: 0.03809 (QuantReg: 10.00078) QuantErr: 10.00078 batch_time=0.53872 
Train Epoch: 18 [457/500 29248/32000 (91%)] Loss: 0.05807 (QuantReg: 10.20247) QuantErr: 10.20247 batch_time=0.43922 
Train Epoch: 18 [465/500 29760/32000 (93%)] Loss: 0.02654 (QuantReg: 10.26957) QuantErr: 10.26957 batch_time=0.43973 
Train Epoch: 18 [473/500 30272/32000 (95%)] Loss: 0.10509 (QuantReg: 10.13091) QuantErr: 10.13091 batch_time=0.43902 
Train Epoch: 18 [481/500 30784/32000 (96%)] Loss: 0.15021 (QuantReg: 10.12655) QuantErr: 10.12655 batch_time=0.44120 
Train Epoch: 18 [489/500 31296/32000 (98%)] Loss: 0.03821 (QuantReg: 10.25033) QuantErr: 10.25033 batch_time=0.43712 
Train Epoch: 18 [497/500 31808/32000 (99%)] Loss: 0.03554 (QuantReg: 10.13056) QuantErr: 10.13056 batch_time=0.46908 
Train Epoch: 18 codebook_update_time=1.89966
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_ActivityNet_bs64/checkpoint-epoch18.pth ...
Done in 6.165s
Updating 'best' checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_ActivityNet_bs64/checkpoint-epoch18.pth ...
Done in 11.354s
removing stale ckpt [epoch 17] [took 0.16s]
 epoch          : 18
 loss           : 0.05640120645612478
 quant_reg      : 10.19108198928833
 quant_err      : 10.19108198928833
 learning_rate  : 1.3624526251953122e-05
 n_samples      : 576000
 n_steps        : 9000
 ActivityNet_val1_test/t2v_metrics/R1: 19.198698393329266
 ActivityNet_val1_test/t2v_metrics/R5: 49.76611755135245
 ActivityNet_val1_test/t2v_metrics/R10: 67.03274354281066
 ActivityNet_val1_test/t2v_metrics/R50: 91.01077893024201
 ActivityNet_val1_test/t2v_metrics/MedR: 6.0
 ActivityNet_val1_test/t2v_metrics/MeanR: 26.315232865568436
 ActivityNet_val1_test/t2v_metrics/geometric_mean_R1-R5-R10: 40.00959733789949
 ActivityNet_val1_test/v2t_metrics/R1: 20.13422818791946
 ActivityNet_val1_test/v2t_metrics/R5: 51.84055318283506
 ActivityNet_val1_test/v2t_metrics/R10: 68.17164937970307
 ActivityNet_val1_test/v2t_metrics/R50: 91.43786861907667
 ActivityNet_val1_test/v2t_metrics/MedR: 5.0
 ActivityNet_val1_test/v2t_metrics/MeanR: 24.63575350823673
 ActivityNet_val1_test/v2t_metrics/geometric_mean_R1-R5-R10: 41.438383470688095
 mnt_best       : 40.00959733789949
 not_improved_count: 0
Train Epoch: 19 [1/500 64/32000 (0%)] Loss: 0.02577 (QuantReg: 9.84782) QuantErr: 9.84782 batch_time=23.78575 
Train Epoch: 19 [9/500 576/32000 (2%)] Loss: 0.04211 (QuantReg: 10.12808) QuantErr: 10.12808 batch_time=0.43786 
Train Epoch: 19 [17/500 1088/32000 (3%)] Loss: 0.04032 (QuantReg: 10.07278) QuantErr: 10.07278 batch_time=1.80096 
Train Epoch: 19 [25/500 1600/32000 (5%)] Loss: 0.03331 (QuantReg: 10.31388) QuantErr: 10.31388 batch_time=0.45928 
Train Epoch: 19 [33/500 2112/32000 (7%)] Loss: 0.07906 (QuantReg: 10.16321) QuantErr: 10.16321 batch_time=0.48233 
Train Epoch: 19 [41/500 2624/32000 (8%)] Loss: 0.09348 (QuantReg: 10.19411) QuantErr: 10.19411 batch_time=0.48379 
Train Epoch: 19 [49/500 3136/32000 (10%)] Loss: 0.03998 (QuantReg: 10.14245) QuantErr: 10.14245 batch_time=0.44204 
Train Epoch: 19 [57/500 3648/32000 (11%)] Loss: 0.03114 (QuantReg: 10.16408) QuantErr: 10.16408 batch_time=0.43965 
Train Epoch: 19 [65/500 4160/32000 (13%)] Loss: 0.05300 (QuantReg: 10.21712) QuantErr: 10.21712 batch_time=0.70237 
Train Epoch: 19 [73/500 4672/32000 (15%)] Loss: 0.05265 (QuantReg: 10.04924) QuantErr: 10.04924 batch_time=0.43811 
Train Epoch: 19 [81/500 5184/32000 (16%)] Loss: 0.06266 (QuantReg: 10.06969) QuantErr: 10.06969 batch_time=1.49738 
Train Epoch: 19 [89/500 5696/32000 (18%)] Loss: 0.05637 (QuantReg: 10.07514) QuantErr: 10.07514 batch_time=0.45278 
Train Epoch: 19 [97/500 6208/32000 (19%)] Loss: 0.05908 (QuantReg: 9.96185) QuantErr: 9.96185 batch_time=0.44522 
Train Epoch: 19 [105/500 6720/32000 (21%)] Loss: 0.07480 (QuantReg: 10.06664) QuantErr: 10.06664 batch_time=0.43675 
Train Epoch: 19 [113/500 7232/32000 (23%)] Loss: 0.02655 (QuantReg: 9.94441) QuantErr: 9.94441 batch_time=0.44354 
Train Epoch: 19 [121/500 7744/32000 (24%)] Loss: 0.03666 (QuantReg: 10.23127) QuantErr: 10.23127 batch_time=0.44613 
Train Epoch: 19 [129/500 8256/32000 (26%)] Loss: 0.06781 (QuantReg: 10.01679) QuantErr: 10.01679 batch_time=0.75133 
Train Epoch: 19 [137/500 8768/32000 (27%)] Loss: 0.04409 (QuantReg: 10.03341) QuantErr: 10.03341 batch_time=0.47516 
Train Epoch: 19 [145/500 9280/32000 (29%)] Loss: 0.09237 (QuantReg: 10.07312) QuantErr: 10.07312 batch_time=1.42980 
Train Epoch: 19 [153/500 9792/32000 (31%)] Loss: 0.04631 (QuantReg: 10.17632) QuantErr: 10.17632 batch_time=0.44861 
Train Epoch: 19 [161/500 10304/32000 (32%)] Loss: 0.05318 (QuantReg: 9.98213) QuantErr: 9.98213 batch_time=0.44483 
Train Epoch: 19 [169/500 10816/32000 (34%)] Loss: 0.02985 (QuantReg: 10.05922) QuantErr: 10.05922 batch_time=0.44765 
Train Epoch: 19 [177/500 11328/32000 (35%)] Loss: 0.04578 (QuantReg: 10.16985) QuantErr: 10.16985 batch_time=0.44781 
Train Epoch: 19 [185/500 11840/32000 (37%)] Loss: 0.02475 (QuantReg: 10.15290) QuantErr: 10.15290 batch_time=0.44210 
Train Epoch: 19 [193/500 12352/32000 (39%)] Loss: 0.01745 (QuantReg: 10.22186) QuantErr: 10.22186 batch_time=0.69780 
Train Epoch: 19 [201/500 12864/32000 (40%)] Loss: 0.03264 (QuantReg: 10.21244) QuantErr: 10.21244 batch_time=0.44026 
Train Epoch: 19 [209/500 13376/32000 (42%)] Loss: 0.08478 (QuantReg: 9.90312) QuantErr: 9.90312 batch_time=1.55889 
Train Epoch: 19 [217/500 13888/32000 (43%)] Loss: 0.06234 (QuantReg: 10.09488) QuantErr: 10.09488 batch_time=0.43867 
Train Epoch: 19 [225/500 14400/32000 (45%)] Loss: 0.03505 (QuantReg: 10.10048) QuantErr: 10.10048 batch_time=0.44803 
Train Epoch: 19 [233/500 14912/32000 (47%)] Loss: 0.06350 (QuantReg: 9.96084) QuantErr: 9.96084 batch_time=0.44424 
Train Epoch: 19 [241/500 15424/32000 (48%)] Loss: 0.04548 (QuantReg: 10.02733) QuantErr: 10.02733 batch_time=0.44444 
Train Epoch: 19 [249/500 15936/32000 (50%)] Loss: 0.03205 (QuantReg: 10.17299) QuantErr: 10.17299 batch_time=0.44419 
Train Epoch: 19 [257/500 16448/32000 (51%)] Loss: 0.06544 (QuantReg: 10.09026) QuantErr: 10.09026 batch_time=0.71854 
Train Epoch: 19 [265/500 16960/32000 (53%)] Loss: 0.06149 (QuantReg: 10.11647) QuantErr: 10.11647 batch_time=0.44413 
Train Epoch: 19 [273/500 17472/32000 (55%)] Loss: 0.08021 (QuantReg: 10.11646) QuantErr: 10.11646 batch_time=1.48409 
Train Epoch: 19 [281/500 17984/32000 (56%)] Loss: 0.03656 (QuantReg: 10.06104) QuantErr: 10.06104 batch_time=0.44981 
Train Epoch: 19 [289/500 18496/32000 (58%)] Loss: 0.04128 (QuantReg: 9.94152) QuantErr: 9.94152 batch_time=0.44795 
Train Epoch: 19 [297/500 19008/32000 (59%)] Loss: 0.05441 (QuantReg: 10.13991) QuantErr: 10.13991 batch_time=0.44633 
Train Epoch: 19 [305/500 19520/32000 (61%)] Loss: 0.06266 (QuantReg: 9.91512) QuantErr: 9.91512 batch_time=0.44169 
Train Epoch: 19 [313/500 20032/32000 (63%)] Loss: 0.03354 (QuantReg: 9.85834) QuantErr: 9.85834 batch_time=0.44028 
Train Epoch: 19 [321/500 20544/32000 (64%)] Loss: 0.06110 (QuantReg: 10.04430) QuantErr: 10.04430 batch_time=0.71404 
Train Epoch: 19 [329/500 21056/32000 (66%)] Loss: 0.07359 (QuantReg: 10.18813) QuantErr: 10.18813 batch_time=0.44786 
Train Epoch: 19 [337/500 21568/32000 (67%)] Loss: 0.09478 (QuantReg: 10.12608) QuantErr: 10.12608 batch_time=1.58264 
Train Epoch: 19 [345/500 22080/32000 (69%)] Loss: 0.03597 (QuantReg: 9.97206) QuantErr: 9.97206 batch_time=0.45273 
Train Epoch: 19 [353/500 22592/32000 (71%)] Loss: 0.06422 (QuantReg: 10.10056) QuantErr: 10.10056 batch_time=0.44753 
Train Epoch: 19 [361/500 23104/32000 (72%)] Loss: 0.02690 (QuantReg: 10.14174) QuantErr: 10.14174 batch_time=0.45044 
Train Epoch: 19 [369/500 23616/32000 (74%)] Loss: 0.03970 (QuantReg: 9.86553) QuantErr: 9.86553 batch_time=0.47997 
Train Epoch: 19 [377/500 24128/32000 (75%)] Loss: 0.03143 (QuantReg: 10.41847) QuantErr: 10.41847 batch_time=0.48303 
Train Epoch: 19 [385/500 24640/32000 (77%)] Loss: 0.03571 (QuantReg: 10.06402) QuantErr: 10.06402 batch_time=0.72063 
Train Epoch: 19 [393/500 25152/32000 (79%)] Loss: 0.02267 (QuantReg: 9.88244) QuantErr: 9.88244 batch_time=0.45274 
Train Epoch: 19 [401/500 25664/32000 (80%)] Loss: 0.04046 (QuantReg: 10.27007) QuantErr: 10.27007 batch_time=1.44199 
Train Epoch: 19 [409/500 26176/32000 (82%)] Loss: 0.03138 (QuantReg: 10.54218) QuantErr: 10.54218 batch_time=0.44034 
Train Epoch: 19 [417/500 26688/32000 (83%)] Loss: 0.03382 (QuantReg: 10.08626) QuantErr: 10.08626 batch_time=0.44136 
Train Epoch: 19 [425/500 27200/32000 (85%)] Loss: 0.04812 (QuantReg: 10.09699) QuantErr: 10.09699 batch_time=0.44130 
Train Epoch: 19 [433/500 27712/32000 (87%)] Loss: 0.03814 (QuantReg: 10.08506) QuantErr: 10.08506 batch_time=0.43704 
Train Epoch: 19 [441/500 28224/32000 (88%)] Loss: 0.08661 (QuantReg: 10.11481) QuantErr: 10.11481 batch_time=0.44075 
Train Epoch: 19 [449/500 28736/32000 (90%)] Loss: 0.03269 (QuantReg: 10.06571) QuantErr: 10.06571 batch_time=0.72520 
Train Epoch: 19 [457/500 29248/32000 (91%)] Loss: 0.04144 (QuantReg: 10.29659) QuantErr: 10.29659 batch_time=0.44732 
Train Epoch: 19 [465/500 29760/32000 (93%)] Loss: 0.11179 (QuantReg: 10.02291) QuantErr: 10.02291 batch_time=1.54336 
Train Epoch: 19 [473/500 30272/32000 (95%)] Loss: 0.03263 (QuantReg: 9.96239) QuantErr: 9.96239 batch_time=0.44868 
Train Epoch: 19 [481/500 30784/32000 (96%)] Loss: 0.05458 (QuantReg: 9.81731) QuantErr: 9.81731 batch_time=0.44973 
Train Epoch: 19 [489/500 31296/32000 (98%)] Loss: 0.08951 (QuantReg: 10.09055) QuantErr: 10.09055 batch_time=0.44525 
Train Epoch: 19 [497/500 31808/32000 (99%)] Loss: 0.09271 (QuantReg: 10.10045) QuantErr: 10.10045 batch_time=0.44023 
Train Epoch: 19 codebook_update_time=1.75391
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_ActivityNet_bs64/checkpoint-epoch19.pth ...
Done in 4.714s
removing stale ckpt [epoch 18] [took 2.31s]
 epoch          : 19
 loss           : 0.0533743608109653
 quant_reg      : 10.088550186157226
 quant_err      : 10.088550186157226
 learning_rate  : 1.1580847314160154e-05
 n_samples      : 608000
 n_steps        : 9500
 ActivityNet_val1_test/t2v_metrics/R1: 18.832621517185277
 ActivityNet_val1_test/t2v_metrics/R5: 50.25422005287777
 ActivityNet_val1_test/t2v_metrics/R10: 67.21578198088265
 ActivityNet_val1_test/t2v_metrics/R50: 90.56335163717713
 ActivityNet_val1_test/t2v_metrics/MedR: 5.0
 ActivityNet_val1_test/t2v_metrics/MeanR: 28.68883465527761
 ActivityNet_val1_test/t2v_metrics/geometric_mean_R1-R5-R10: 39.91947830648361
 ActivityNet_val1_test/v2t_metrics/R1: 19.72747610331503
 ActivityNet_val1_test/v2t_metrics/R5: 51.4134634940004
 ActivityNet_val1_test/v2t_metrics/R10: 68.17164937970307
 ActivityNet_val1_test/v2t_metrics/R50: 90.3396379906447
 ActivityNet_val1_test/v2t_metrics/MedR: 5.0
 ActivityNet_val1_test/v2t_metrics/MeanR: 27.035184055318283
 ActivityNet_val1_test/v2t_metrics/geometric_mean_R1-R5-R10: 41.04409930053331
 mnt_best       : 40.00959733789949
 not_improved_count: 1
Train Epoch: 20 [1/500 64/32000 (0%)] Loss: 0.05840 (QuantReg: 9.73907) QuantErr: 9.73907 batch_time=23.58516 
Train Epoch: 20 [9/500 576/32000 (2%)] Loss: 0.04523 (QuantReg: 10.06568) QuantErr: 10.06568 batch_time=0.43898 
Train Epoch: 20 [17/500 1088/32000 (3%)] Loss: 0.12759 (QuantReg: 9.99797) QuantErr: 9.99797 batch_time=1.14240 
Train Epoch: 20 [25/500 1600/32000 (5%)] Loss: 0.03618 (QuantReg: 10.01740) QuantErr: 10.01740 batch_time=0.43942 
Train Epoch: 20 [33/500 2112/32000 (7%)] Loss: 0.09188 (QuantReg: 10.29206) QuantErr: 10.29206 batch_time=0.44609 
Train Epoch: 20 [41/500 2624/32000 (8%)] Loss: 0.09817 (QuantReg: 9.98642) QuantErr: 9.98642 batch_time=0.44673 
Train Epoch: 20 [49/500 3136/32000 (10%)] Loss: 0.07377 (QuantReg: 9.91110) QuantErr: 9.91110 batch_time=0.46136 
Train Epoch: 20 [57/500 3648/32000 (11%)] Loss: 0.05453 (QuantReg: 9.82755) QuantErr: 9.82755 batch_time=0.44531 
Train Epoch: 20 [65/500 4160/32000 (13%)] Loss: 0.03918 (QuantReg: 10.23690) QuantErr: 10.23690 batch_time=0.54941 
Train Epoch: 20 [73/500 4672/32000 (15%)] Loss: 0.04563 (QuantReg: 10.06512) QuantErr: 10.06512 batch_time=0.45415 
Train Epoch: 20 [81/500 5184/32000 (16%)] Loss: 0.04061 (QuantReg: 10.24937) QuantErr: 10.24937 batch_time=1.09785 
Train Epoch: 20 [89/500 5696/32000 (18%)] Loss: 0.06456 (QuantReg: 10.21558) QuantErr: 10.21558 batch_time=0.43716 
Train Epoch: 20 [97/500 6208/32000 (19%)] Loss: 0.05359 (QuantReg: 10.18415) QuantErr: 10.18415 batch_time=0.44470 
Train Epoch: 20 [105/500 6720/32000 (21%)] Loss: 0.03469 (QuantReg: 10.18816) QuantErr: 10.18816 batch_time=0.44204 
Train Epoch: 20 [113/500 7232/32000 (23%)] Loss: 0.02625 (QuantReg: 10.02164) QuantErr: 10.02164 batch_time=0.44254 
Train Epoch: 20 [121/500 7744/32000 (24%)] Loss: 0.04337 (QuantReg: 9.92665) QuantErr: 9.92665 batch_time=0.44339 
Train Epoch: 20 [129/500 8256/32000 (26%)] Loss: 0.02827 (QuantReg: 9.94322) QuantErr: 9.94322 batch_time=0.61234 
Train Epoch: 20 [137/500 8768/32000 (27%)] Loss: 0.02995 (QuantReg: 9.96509) QuantErr: 9.96509 batch_time=0.44224 
Train Epoch: 20 [145/500 9280/32000 (29%)] Loss: 0.04749 (QuantReg: 10.19062) QuantErr: 10.19062 batch_time=1.05907 
Train Epoch: 20 [153/500 9792/32000 (31%)] Loss: 0.03163 (QuantReg: 10.07826) QuantErr: 10.07826 batch_time=0.43990 
Train Epoch: 20 [161/500 10304/32000 (32%)] Loss: 0.04559 (QuantReg: 9.95083) QuantErr: 9.95083 batch_time=0.44736 
Train Epoch: 20 [169/500 10816/32000 (34%)] Loss: 0.02929 (QuantReg: 10.17492) QuantErr: 10.17492 batch_time=0.49764 
Train Epoch: 20 [177/500 11328/32000 (35%)] Loss: 0.05398 (QuantReg: 9.93029) QuantErr: 9.93029 batch_time=0.44095 
Train Epoch: 20 [185/500 11840/32000 (37%)] Loss: 0.04301 (QuantReg: 9.94100) QuantErr: 9.94100 batch_time=0.45684 
Train Epoch: 20 [193/500 12352/32000 (39%)] Loss: 0.06081 (QuantReg: 10.07857) QuantErr: 10.07857 batch_time=0.64933 
Train Epoch: 20 [201/500 12864/32000 (40%)] Loss: 0.03724 (QuantReg: 9.98828) QuantErr: 9.98828 batch_time=0.44067 
Train Epoch: 20 [209/500 13376/32000 (42%)] Loss: 0.09840 (QuantReg: 9.79069) QuantErr: 9.79069 batch_time=1.19638 
Train Epoch: 20 [217/500 13888/32000 (43%)] Loss: 0.05841 (QuantReg: 10.08490) QuantErr: 10.08490 batch_time=0.44687 
Train Epoch: 20 [225/500 14400/32000 (45%)] Loss: 0.04241 (QuantReg: 9.89905) QuantErr: 9.89905 batch_time=0.45099 
Train Epoch: 20 [233/500 14912/32000 (47%)] Loss: 0.09328 (QuantReg: 9.87249) QuantErr: 9.87249 batch_time=0.44524 
Train Epoch: 20 [241/500 15424/32000 (48%)] Loss: 0.04755 (QuantReg: 9.81043) QuantErr: 9.81043 batch_time=0.45352 
Train Epoch: 20 [249/500 15936/32000 (50%)] Loss: 0.03136 (QuantReg: 10.13291) QuantErr: 10.13291 batch_time=0.44534 
Train Epoch: 20 [257/500 16448/32000 (51%)] Loss: 0.05418 (QuantReg: 9.96896) QuantErr: 9.96896 batch_time=0.61326 
Train Epoch: 20 [265/500 16960/32000 (53%)] Loss: 0.04485 (QuantReg: 10.10492) QuantErr: 10.10492 batch_time=0.44455 
Train Epoch: 20 [273/500 17472/32000 (55%)] Loss: 0.08011 (QuantReg: 9.96433) QuantErr: 9.96433 batch_time=1.06513 
Train Epoch: 20 [281/500 17984/32000 (56%)] Loss: 0.03894 (QuantReg: 9.93219) QuantErr: 9.93219 batch_time=0.45119 
Train Epoch: 20 [289/500 18496/32000 (58%)] Loss: 0.03540 (QuantReg: 10.03864) QuantErr: 10.03864 batch_time=0.43736 
Train Epoch: 20 [297/500 19008/32000 (59%)] Loss: 0.08858 (QuantReg: 9.88480) QuantErr: 9.88480 batch_time=0.44495 
Train Epoch: 20 [305/500 19520/32000 (61%)] Loss: 0.04407 (QuantReg: 9.84439) QuantErr: 9.84439 batch_time=0.44289 
Train Epoch: 20 [313/500 20032/32000 (63%)] Loss: 0.04189 (QuantReg: 9.96299) QuantErr: 9.96299 batch_time=0.44182 
Train Epoch: 20 [321/500 20544/32000 (64%)] Loss: 0.03799 (QuantReg: 9.88421) QuantErr: 9.88421 batch_time=0.65319 
Train Epoch: 20 [329/500 21056/32000 (66%)] Loss: 0.04399 (QuantReg: 10.16388) QuantErr: 10.16388 batch_time=0.43728 
Train Epoch: 20 [337/500 21568/32000 (67%)] Loss: 0.06513 (QuantReg: 9.98666) QuantErr: 9.98666 batch_time=1.17329 
Train Epoch: 20 [345/500 22080/32000 (69%)] Loss: 0.02433 (QuantReg: 9.94230) QuantErr: 9.94230 batch_time=0.44187 
Train Epoch: 20 [353/500 22592/32000 (71%)] Loss: 0.02971 (QuantReg: 10.04002) QuantErr: 10.04002 batch_time=0.47801 
Train Epoch: 20 [361/500 23104/32000 (72%)] Loss: 0.03954 (QuantReg: 10.31188) QuantErr: 10.31188 batch_time=0.47798 
Train Epoch: 20 [369/500 23616/32000 (74%)] Loss: 0.02554 (QuantReg: 9.77334) QuantErr: 9.77334 batch_time=0.47786 
Train Epoch: 20 [377/500 24128/32000 (75%)] Loss: 0.03094 (QuantReg: 9.95858) QuantErr: 9.95858 batch_time=0.47726 
Train Epoch: 20 [385/500 24640/32000 (77%)] Loss: 0.03502 (QuantReg: 10.10902) QuantErr: 10.10902 batch_time=0.61441 
Train Epoch: 20 [393/500 25152/32000 (79%)] Loss: 0.02783 (QuantReg: 9.60603) QuantErr: 9.60603 batch_time=0.43987 
Train Epoch: 20 [401/500 25664/32000 (80%)] Loss: 0.03881 (QuantReg: 9.84547) QuantErr: 9.84547 batch_time=1.13322 
Train Epoch: 20 [409/500 26176/32000 (82%)] Loss: 0.04738 (QuantReg: 10.05334) QuantErr: 10.05334 batch_time=0.44334 
Train Epoch: 20 [417/500 26688/32000 (83%)] Loss: 0.03084 (QuantReg: 9.94585) QuantErr: 9.94585 batch_time=0.44112 
Train Epoch: 20 [425/500 27200/32000 (85%)] Loss: 0.02974 (QuantReg: 9.87313) QuantErr: 9.87313 batch_time=0.44307 
Train Epoch: 20 [433/500 27712/32000 (87%)] Loss: 0.04275 (QuantReg: 9.74542) QuantErr: 9.74542 batch_time=0.45193 
Train Epoch: 20 [441/500 28224/32000 (88%)] Loss: 0.04926 (QuantReg: 10.05456) QuantErr: 10.05456 batch_time=0.43727 
Train Epoch: 20 [449/500 28736/32000 (90%)] Loss: 0.04018 (QuantReg: 9.90412) QuantErr: 9.90412 batch_time=0.60722 
Train Epoch: 20 [457/500 29248/32000 (91%)] Loss: 0.05921 (QuantReg: 9.89043) QuantErr: 9.89043 batch_time=0.44243 
Train Epoch: 20 [465/500 29760/32000 (93%)] Loss: 0.04492 (QuantReg: 10.10897) QuantErr: 10.10897 batch_time=1.06181 
Train Epoch: 20 [473/500 30272/32000 (95%)] Loss: 0.12951 (QuantReg: 9.84838) QuantErr: 9.84838 batch_time=0.44545 
Train Epoch: 20 [481/500 30784/32000 (96%)] Loss: 0.04683 (QuantReg: 10.05227) QuantErr: 10.05227 batch_time=0.44096 
Train Epoch: 20 [489/500 31296/32000 (98%)] Loss: 0.02808 (QuantReg: 10.01298) QuantErr: 10.01298 batch_time=0.44598 
Train Epoch: 20 [497/500 31808/32000 (99%)] Loss: 0.02524 (QuantReg: 9.95569) QuantErr: 9.95569 batch_time=0.44519 
Train Epoch: 20 codebook_update_time=1.68900
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_ActivityNet_bs64/checkpoint-epoch20.pth ...
Done in 4.141s
removing stale ckpt [epoch 19] [took 0.29s]
 epoch          : 20
 loss           : 0.051739283200353384
 quant_reg      : 9.998477949142456
 quant_err      : 9.998477949142456
 learning_rate  : 1.1580847314160154e-05
 n_samples      : 640000
 n_steps        : 10000
 ActivityNet_val1_test/t2v_metrics/R1: 19.15802318486882
 ActivityNet_val1_test/t2v_metrics/R5: 50.25422005287777
 ActivityNet_val1_test/t2v_metrics/R10: 66.36160260321334
 ActivityNet_val1_test/t2v_metrics/R50: 90.66503965832825
 ActivityNet_val1_test/t2v_metrics/MedR: 5.0
 ActivityNet_val1_test/t2v_metrics/MeanR: 29.034980679275982
 ActivityNet_val1_test/t2v_metrics/geometric_mean_R1-R5-R10: 39.977291389052546
 ActivityNet_val1_test/v2t_metrics/R1: 20.23591620907057
 ActivityNet_val1_test/v2t_metrics/R5: 51.45413870246085
 ActivityNet_val1_test/v2t_metrics/R10: 68.41570063046574
 ActivityNet_val1_test/v2t_metrics/R50: 91.03111653447223
 ActivityNet_val1_test/v2t_metrics/MedR: 5.0
 ActivityNet_val1_test/v2t_metrics/MeanR: 26.485458612975393
 ActivityNet_val1_test/v2t_metrics/geometric_mean_R1-R5-R10: 41.45398838593554
 mnt_best       : 40.00959733789949
 not_improved_count: 2
Train Epoch: 21 [1/500 64/32000 (0%)] Loss: 0.05222 (QuantReg: 9.82104) QuantErr: 9.82104 batch_time=23.04140 
Train Epoch: 21 [9/500 576/32000 (2%)] Loss: 0.05252 (QuantReg: 9.95336) QuantErr: 9.95336 batch_time=0.44843 
Train Epoch: 21 [17/500 1088/32000 (3%)] Loss: 0.04464 (QuantReg: 9.89439) QuantErr: 9.89439 batch_time=0.45333 
Train Epoch: 21 [25/500 1600/32000 (5%)] Loss: 0.02666 (QuantReg: 10.12270) QuantErr: 10.12270 batch_time=0.45258 
Train Epoch: 21 [33/500 2112/32000 (7%)] Loss: 0.02460 (QuantReg: 9.81304) QuantErr: 9.81304 batch_time=0.45139 
Train Epoch: 21 [41/500 2624/32000 (8%)] Loss: 0.04471 (QuantReg: 9.71945) QuantErr: 9.71945 batch_time=0.45108 
Train Epoch: 21 [49/500 3136/32000 (10%)] Loss: 0.04338 (QuantReg: 9.87847) QuantErr: 9.87847 batch_time=0.44484 
Train Epoch: 21 [57/500 3648/32000 (11%)] Loss: 0.04477 (QuantReg: 9.91691) QuantErr: 9.91691 batch_time=0.44487 
Train Epoch: 21 [65/500 4160/32000 (13%)] Loss: 0.09554 (QuantReg: 9.94375) QuantErr: 9.94375 batch_time=0.47077 
Train Epoch: 21 [73/500 4672/32000 (15%)] Loss: 0.04816 (QuantReg: 10.09882) QuantErr: 10.09882 batch_time=0.44695 
Train Epoch: 21 [81/500 5184/32000 (16%)] Loss: 0.02206 (QuantReg: 10.01036) QuantErr: 10.01036 batch_time=0.43857 
Train Epoch: 21 [89/500 5696/32000 (18%)] Loss: 0.04611 (QuantReg: 9.89129) QuantErr: 9.89129 batch_time=0.44121 
Train Epoch: 21 [97/500 6208/32000 (19%)] Loss: 0.05654 (QuantReg: 10.21690) QuantErr: 10.21690 batch_time=0.44007 
Train Epoch: 21 [105/500 6720/32000 (21%)] Loss: 0.04293 (QuantReg: 9.78204) QuantErr: 9.78204 batch_time=0.43956 
Train Epoch: 21 [113/500 7232/32000 (23%)] Loss: 0.04801 (QuantReg: 9.79394) QuantErr: 9.79394 batch_time=0.43783 
Train Epoch: 21 [121/500 7744/32000 (24%)] Loss: 0.03094 (QuantReg: 9.78027) QuantErr: 9.78027 batch_time=0.44448 
Train Epoch: 21 [129/500 8256/32000 (26%)] Loss: 0.03390 (QuantReg: 9.71584) QuantErr: 9.71584 batch_time=0.44191 
Train Epoch: 21 [137/500 8768/32000 (27%)] Loss: 0.04270 (QuantReg: 9.92855) QuantErr: 9.92855 batch_time=0.44500 
Train Epoch: 21 [145/500 9280/32000 (29%)] Loss: 0.02902 (QuantReg: 9.70109) QuantErr: 9.70109 batch_time=0.46064 
Train Epoch: 21 [153/500 9792/32000 (31%)] Loss: 0.02656 (QuantReg: 9.87951) QuantErr: 9.87951 batch_time=0.45005 
Train Epoch: 21 [161/500 10304/32000 (32%)] Loss: 0.03939 (QuantReg: 9.88889) QuantErr: 9.88889 batch_time=0.45167 
Train Epoch: 21 [169/500 10816/32000 (34%)] Loss: 0.03345 (QuantReg: 10.00798) QuantErr: 10.00798 batch_time=0.44223 
Train Epoch: 21 [177/500 11328/32000 (35%)] Loss: 0.03742 (QuantReg: 9.95792) QuantErr: 9.95792 batch_time=0.44843 
Train Epoch: 21 [185/500 11840/32000 (37%)] Loss: 0.04142 (QuantReg: 9.85735) QuantErr: 9.85735 batch_time=0.44694 
Train Epoch: 21 [193/500 12352/32000 (39%)] Loss: 0.03209 (QuantReg: 10.06667) QuantErr: 10.06667 batch_time=0.45239 
Train Epoch: 21 [201/500 12864/32000 (40%)] Loss: 0.11001 (QuantReg: 10.03186) QuantErr: 10.03186 batch_time=0.44969 
Train Epoch: 21 [209/500 13376/32000 (42%)] Loss: 0.02345 (QuantReg: 9.86229) QuantErr: 9.86229 batch_time=0.45848 
Train Epoch: 21 [217/500 13888/32000 (43%)] Loss: 0.03524 (QuantReg: 9.65278) QuantErr: 9.65278 batch_time=0.45314 
Train Epoch: 21 [225/500 14400/32000 (45%)] Loss: 0.03359 (QuantReg: 9.96612) QuantErr: 9.96612 batch_time=0.44743 
Train Epoch: 21 [233/500 14912/32000 (47%)] Loss: 0.03036 (QuantReg: 10.08175) QuantErr: 10.08175 batch_time=0.44791 
Train Epoch: 21 [241/500 15424/32000 (48%)] Loss: 0.03182 (QuantReg: 10.02623) QuantErr: 10.02623 batch_time=0.44833 
Train Epoch: 21 [249/500 15936/32000 (50%)] Loss: 0.05540 (QuantReg: 9.76453) QuantErr: 9.76453 batch_time=0.44146 
Train Epoch: 21 [257/500 16448/32000 (51%)] Loss: 0.03066 (QuantReg: 10.03914) QuantErr: 10.03914 batch_time=0.45577 
Train Epoch: 21 [265/500 16960/32000 (53%)] Loss: 0.03159 (QuantReg: 9.64748) QuantErr: 9.64748 batch_time=0.44492 
Train Epoch: 21 [273/500 17472/32000 (55%)] Loss: 0.02705 (QuantReg: 9.88453) QuantErr: 9.88453 batch_time=0.44067 
Train Epoch: 21 [281/500 17984/32000 (56%)] Loss: 0.10531 (QuantReg: 9.72439) QuantErr: 9.72439 batch_time=0.43889 
Train Epoch: 21 [289/500 18496/32000 (58%)] Loss: 0.08170 (QuantReg: 9.90689) QuantErr: 9.90689 batch_time=0.44272 
Train Epoch: 21 [297/500 19008/32000 (59%)] Loss: 0.07808 (QuantReg: 9.81629) QuantErr: 9.81629 batch_time=0.44397 
Train Epoch: 21 [305/500 19520/32000 (61%)] Loss: 0.03270 (QuantReg: 9.72744) QuantErr: 9.72744 batch_time=0.44326 
Train Epoch: 21 [313/500 20032/32000 (63%)] Loss: 0.02555 (QuantReg: 9.61426) QuantErr: 9.61426 batch_time=0.44311 
Train Epoch: 21 [321/500 20544/32000 (64%)] Loss: 0.06424 (QuantReg: 9.78222) QuantErr: 9.78222 batch_time=0.43902 
Train Epoch: 21 [329/500 21056/32000 (66%)] Loss: 0.08383 (QuantReg: 10.03560) QuantErr: 10.03560 batch_time=0.44273 
Train Epoch: 21 [337/500 21568/32000 (67%)] Loss: 0.08711 (QuantReg: 9.80198) QuantErr: 9.80198 batch_time=0.44042 
Train Epoch: 21 [345/500 22080/32000 (69%)] Loss: 0.02542 (QuantReg: 9.97868) QuantErr: 9.97868 batch_time=0.44027 
Train Epoch: 21 [353/500 22592/32000 (71%)] Loss: 0.09288 (QuantReg: 9.91712) QuantErr: 9.91712 batch_time=0.43971 
Train Epoch: 21 [361/500 23104/32000 (72%)] Loss: 0.04194 (QuantReg: 10.04655) QuantErr: 10.04655 batch_time=0.43971 
Train Epoch: 21 [369/500 23616/32000 (74%)] Loss: 0.08309 (QuantReg: 9.86891) QuantErr: 9.86891 batch_time=0.44620 
Train Epoch: 21 [377/500 24128/32000 (75%)] Loss: 0.03014 (QuantReg: 9.60196) QuantErr: 9.60196 batch_time=0.44309 
Train Epoch: 21 [385/500 24640/32000 (77%)] Loss: 0.05984 (QuantReg: 9.91018) QuantErr: 9.91018 batch_time=0.44304 
Train Epoch: 21 [393/500 25152/32000 (79%)] Loss: 0.04400 (QuantReg: 9.80847) QuantErr: 9.80847 batch_time=0.44538 
Train Epoch: 21 [401/500 25664/32000 (80%)] Loss: 0.07632 (QuantReg: 9.96200) QuantErr: 9.96200 batch_time=0.44573 
Train Epoch: 21 [409/500 26176/32000 (82%)] Loss: 0.02133 (QuantReg: 10.14042) QuantErr: 10.14042 batch_time=0.44511 
Train Epoch: 21 [417/500 26688/32000 (83%)] Loss: 0.03100 (QuantReg: 10.02890) QuantErr: 10.02890 batch_time=0.44619 
Train Epoch: 21 [425/500 27200/32000 (85%)] Loss: 0.05623 (QuantReg: 9.90827) QuantErr: 9.90827 batch_time=0.44508 
Train Epoch: 21 [433/500 27712/32000 (87%)] Loss: 0.03904 (QuantReg: 9.96516) QuantErr: 9.96516 batch_time=0.44983 
Train Epoch: 21 [441/500 28224/32000 (88%)] Loss: 0.02695 (QuantReg: 9.92164) QuantErr: 9.92164 batch_time=0.44687 
Train Epoch: 21 [449/500 28736/32000 (90%)] Loss: 0.03173 (QuantReg: 9.93766) QuantErr: 9.93766 batch_time=0.44541 
Train Epoch: 21 [457/500 29248/32000 (91%)] Loss: 0.07010 (QuantReg: 9.93667) QuantErr: 9.93667 batch_time=0.45014 
Train Epoch: 21 [465/500 29760/32000 (93%)] Loss: 0.02312 (QuantReg: 9.96441) QuantErr: 9.96441 batch_time=0.43988 
Train Epoch: 21 [473/500 30272/32000 (95%)] Loss: 0.03719 (QuantReg: 9.79441) QuantErr: 9.79441 batch_time=0.43822 
Train Epoch: 21 [481/500 30784/32000 (96%)] Loss: 0.03718 (QuantReg: 10.01241) QuantErr: 10.01241 batch_time=0.43753 
Train Epoch: 21 [489/500 31296/32000 (98%)] Loss: 0.02721 (QuantReg: 9.84371) QuantErr: 9.84371 batch_time=0.43835 
Train Epoch: 21 [497/500 31808/32000 (99%)] Loss: 0.03182 (QuantReg: 9.77834) QuantErr: 9.77834 batch_time=0.45042 
Train Epoch: 21 codebook_update_time=1.63238
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_ActivityNet_bs64/checkpoint-epoch21.pth ...
Done in 4.018s
Updating 'best' checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_ActivityNet_bs64/checkpoint-epoch21.pth ...
Done in 7.945s
removing stale ckpt [epoch 20] [took 0.01s]
 epoch          : 21
 loss           : 0.046488788347691296
 quant_reg      : 9.892445999145508
 quant_err      : 9.892445999145508
 learning_rate  : 9.843720217036131e-06
 n_samples      : 672000
 n_steps        : 10500
 ActivityNet_val1_test/t2v_metrics/R1: 19.97152735407769
 ActivityNet_val1_test/t2v_metrics/R5: 50.47793369941021
 ActivityNet_val1_test/t2v_metrics/R10: 66.91071791742932
 ActivityNet_val1_test/t2v_metrics/R50: 90.7057148667887
 ActivityNet_val1_test/t2v_metrics/MedR: 5.0
 ActivityNet_val1_test/t2v_metrics/MeanR: 28.648769574944073
 ActivityNet_val1_test/t2v_metrics/geometric_mean_R1-R5-R10: 40.707038944556345
 ActivityNet_val1_test/v2t_metrics/R1: 20.11389058368924
 ActivityNet_val1_test/v2t_metrics/R5: 52.18629245474883
 ActivityNet_val1_test/v2t_metrics/R10: 67.72422208663819
 ActivityNet_val1_test/v2t_metrics/R50: 91.13280455562335
 ActivityNet_val1_test/v2t_metrics/MedR: 5.0
 ActivityNet_val1_test/v2t_metrics/MeanR: 26.799674598332317
 ActivityNet_val1_test/v2t_metrics/geometric_mean_R1-R5-R10: 41.425286186475965
 mnt_best       : 40.707038944556345
 not_improved_count: 0
Train Epoch: 22 [1/500 64/32000 (0%)] Loss: 0.04965 (QuantReg: 9.79754) QuantErr: 9.79754 batch_time=24.71903 
Train Epoch: 22 [9/500 576/32000 (2%)] Loss: 0.07203 (QuantReg: 9.90311) QuantErr: 9.90311 batch_time=0.43508 
Train Epoch: 22 [17/500 1088/32000 (3%)] Loss: 0.05894 (QuantReg: 9.90820) QuantErr: 9.90820 batch_time=0.43641 
Train Epoch: 22 [25/500 1600/32000 (5%)] Loss: 0.02387 (QuantReg: 9.84352) QuantErr: 9.84352 batch_time=0.43859 
Train Epoch: 22 [33/500 2112/32000 (7%)] Loss: 0.03063 (QuantReg: 9.64198) QuantErr: 9.64198 batch_time=0.43580 
Train Epoch: 22 [41/500 2624/32000 (8%)] Loss: 0.03763 (QuantReg: 9.90185) QuantErr: 9.90185 batch_time=0.43614 
Train Epoch: 22 [49/500 3136/32000 (10%)] Loss: 0.03340 (QuantReg: 9.85756) QuantErr: 9.85756 batch_time=0.43295 
Train Epoch: 22 [57/500 3648/32000 (11%)] Loss: 0.03180 (QuantReg: 9.79220) QuantErr: 9.79220 batch_time=0.43603 
Train Epoch: 22 [65/500 4160/32000 (13%)] Loss: 0.06945 (QuantReg: 9.47991) QuantErr: 9.47991 batch_time=1.06503 
Train Epoch: 22 [73/500 4672/32000 (15%)] Loss: 0.05223 (QuantReg: 9.70560) QuantErr: 9.70560 batch_time=0.47787 
Train Epoch: 22 [81/500 5184/32000 (16%)] Loss: 0.03840 (QuantReg: 9.84105) QuantErr: 9.84105 batch_time=0.44350 
Train Epoch: 22 [89/500 5696/32000 (18%)] Loss: 0.06858 (QuantReg: 9.86811) QuantErr: 9.86811 batch_time=0.43673 
Train Epoch: 22 [97/500 6208/32000 (19%)] Loss: 0.02757 (QuantReg: 9.91169) QuantErr: 9.91169 batch_time=0.43592 
Train Epoch: 22 [105/500 6720/32000 (21%)] Loss: 0.04545 (QuantReg: 9.69535) QuantErr: 9.69535 batch_time=0.43662 
Train Epoch: 22 [113/500 7232/32000 (23%)] Loss: 0.05077 (QuantReg: 9.83557) QuantErr: 9.83557 batch_time=0.44414 
Train Epoch: 22 [121/500 7744/32000 (24%)] Loss: 0.03656 (QuantReg: 10.05639) QuantErr: 10.05639 batch_time=0.45239 
Train Epoch: 22 [129/500 8256/32000 (26%)] Loss: 0.05949 (QuantReg: 9.85368) QuantErr: 9.85368 batch_time=1.08187 
Train Epoch: 22 [137/500 8768/32000 (27%)] Loss: 0.03766 (QuantReg: 9.61425) QuantErr: 9.61425 batch_time=0.45047 
Train Epoch: 22 [145/500 9280/32000 (29%)] Loss: 0.04545 (QuantReg: 9.80845) QuantErr: 9.80845 batch_time=0.44528 
Train Epoch: 22 [153/500 9792/32000 (31%)] Loss: 0.02450 (QuantReg: 9.84134) QuantErr: 9.84134 batch_time=0.43686 
Train Epoch: 22 [161/500 10304/32000 (32%)] Loss: 0.04102 (QuantReg: 9.92929) QuantErr: 9.92929 batch_time=0.45074 
Train Epoch: 22 [169/500 10816/32000 (34%)] Loss: 0.04446 (QuantReg: 9.83459) QuantErr: 9.83459 batch_time=0.44750 
Train Epoch: 22 [177/500 11328/32000 (35%)] Loss: 0.05471 (QuantReg: 9.83947) QuantErr: 9.83947 batch_time=0.52389 
Train Epoch: 22 [185/500 11840/32000 (37%)] Loss: 0.02952 (QuantReg: 9.76243) QuantErr: 9.76243 batch_time=0.44314 
Train Epoch: 22 [193/500 12352/32000 (39%)] Loss: 0.03804 (QuantReg: 9.71052) QuantErr: 9.71052 batch_time=1.12030 
Train Epoch: 22 [201/500 12864/32000 (40%)] Loss: 0.04989 (QuantReg: 9.81143) QuantErr: 9.81143 batch_time=0.44219 
Train Epoch: 22 [209/500 13376/32000 (42%)] Loss: 0.02763 (QuantReg: 9.97972) QuantErr: 9.97972 batch_time=0.44245 
Train Epoch: 22 [217/500 13888/32000 (43%)] Loss: 0.12497 (QuantReg: 9.68848) QuantErr: 9.68848 batch_time=0.44036 
Train Epoch: 22 [225/500 14400/32000 (45%)] Loss: 0.03214 (QuantReg: 10.03806) QuantErr: 10.03806 batch_time=0.44059 
Train Epoch: 22 [233/500 14912/32000 (47%)] Loss: 0.04022 (QuantReg: 9.81130) QuantErr: 9.81130 batch_time=0.43909 
Train Epoch: 22 [241/500 15424/32000 (48%)] Loss: 0.04006 (QuantReg: 9.74631) QuantErr: 9.74631 batch_time=0.43900 
Train Epoch: 22 [249/500 15936/32000 (50%)] Loss: 0.06240 (QuantReg: 9.70354) QuantErr: 9.70354 batch_time=0.44308 
Train Epoch: 22 [257/500 16448/32000 (51%)] Loss: 0.08687 (QuantReg: 10.05098) QuantErr: 10.05098 batch_time=1.09813 
Train Epoch: 22 [265/500 16960/32000 (53%)] Loss: 0.02896 (QuantReg: 9.94253) QuantErr: 9.94253 batch_time=0.44247 
Train Epoch: 22 [273/500 17472/32000 (55%)] Loss: 0.02988 (QuantReg: 9.93555) QuantErr: 9.93555 batch_time=0.45341 
Train Epoch: 22 [281/500 17984/32000 (56%)] Loss: 0.04512 (QuantReg: 9.68754) QuantErr: 9.68754 batch_time=0.43514 
Train Epoch: 22 [289/500 18496/32000 (58%)] Loss: 0.03992 (QuantReg: 9.65622) QuantErr: 9.65622 batch_time=0.44235 
Train Epoch: 22 [297/500 19008/32000 (59%)] Loss: 0.07334 (QuantReg: 9.71708) QuantErr: 9.71708 batch_time=0.43925 
Train Epoch: 22 [305/500 19520/32000 (61%)] Loss: 0.02097 (QuantReg: 9.75863) QuantErr: 9.75863 batch_time=0.43996 
Train Epoch: 22 [313/500 20032/32000 (63%)] Loss: 0.05144 (QuantReg: 10.08443) QuantErr: 10.08443 batch_time=0.44762 
Train Epoch: 22 [321/500 20544/32000 (64%)] Loss: 0.05540 (QuantReg: 9.85087) QuantErr: 9.85087 batch_time=1.07432 
Train Epoch: 22 [329/500 21056/32000 (66%)] Loss: 0.07601 (QuantReg: 9.89767) QuantErr: 9.89767 batch_time=0.44298 
Train Epoch: 22 [337/500 21568/32000 (67%)] Loss: 0.04169 (QuantReg: 9.84170) QuantErr: 9.84170 batch_time=0.45758 
Train Epoch: 22 [345/500 22080/32000 (69%)] Loss: 0.02871 (QuantReg: 9.89010) QuantErr: 9.89010 batch_time=0.44153 
Train Epoch: 22 [353/500 22592/32000 (71%)] Loss: 0.03901 (QuantReg: 9.86385) QuantErr: 9.86385 batch_time=0.45969 
Train Epoch: 22 [361/500 23104/32000 (72%)] Loss: 0.02906 (QuantReg: 9.82141) QuantErr: 9.82141 batch_time=0.44401 
Train Epoch: 22 [369/500 23616/32000 (74%)] Loss: 0.04375 (QuantReg: 9.92884) QuantErr: 9.92884 batch_time=0.44781 
Train Epoch: 22 [377/500 24128/32000 (75%)] Loss: 0.03999 (QuantReg: 9.74734) QuantErr: 9.74734 batch_time=0.44301 
Train Epoch: 22 [385/500 24640/32000 (77%)] Loss: 0.02051 (QuantReg: 9.84427) QuantErr: 9.84427 batch_time=1.11337 
Train Epoch: 22 [393/500 25152/32000 (79%)] Loss: 0.06977 (QuantReg: 9.82374) QuantErr: 9.82374 batch_time=0.44324 
Train Epoch: 22 [401/500 25664/32000 (80%)] Loss: 0.08211 (QuantReg: 9.68816) QuantErr: 9.68816 batch_time=0.44292 
Train Epoch: 22 [409/500 26176/32000 (82%)] Loss: 0.07329 (QuantReg: 9.70856) QuantErr: 9.70856 batch_time=0.48627 
Train Epoch: 22 [417/500 26688/32000 (83%)] Loss: 0.03567 (QuantReg: 9.73586) QuantErr: 9.73586 batch_time=0.43798 
Train Epoch: 22 [425/500 27200/32000 (85%)] Loss: 0.03374 (QuantReg: 9.77238) QuantErr: 9.77238 batch_time=0.43829 
Train Epoch: 22 [433/500 27712/32000 (87%)] Loss: 0.03255 (QuantReg: 9.80606) QuantErr: 9.80606 batch_time=0.43710 
Train Epoch: 22 [441/500 28224/32000 (88%)] Loss: 0.02455 (QuantReg: 9.82834) QuantErr: 9.82834 batch_time=0.43570 
Train Epoch: 22 [449/500 28736/32000 (90%)] Loss: 0.03716 (QuantReg: 9.75204) QuantErr: 9.75204 batch_time=1.06906 
Train Epoch: 22 [457/500 29248/32000 (91%)] Loss: 0.04096 (QuantReg: 9.64838) QuantErr: 9.64838 batch_time=0.43970 
Train Epoch: 22 [465/500 29760/32000 (93%)] Loss: 0.03312 (QuantReg: 9.83259) QuantErr: 9.83259 batch_time=0.44166 
Train Epoch: 22 [473/500 30272/32000 (95%)] Loss: 0.07231 (QuantReg: 9.89664) QuantErr: 9.89664 batch_time=0.44440 
Train Epoch: 22 [481/500 30784/32000 (96%)] Loss: 0.03186 (QuantReg: 9.80503) QuantErr: 9.80503 batch_time=0.44032 
Train Epoch: 22 [489/500 31296/32000 (98%)] Loss: 0.03813 (QuantReg: 9.58253) QuantErr: 9.58253 batch_time=0.45439 
Train Epoch: 22 [497/500 31808/32000 (99%)] Loss: 0.02688 (QuantReg: 10.05939) QuantErr: 10.05939 batch_time=0.44395 
Train Epoch: 22 codebook_update_time=1.73055
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_ActivityNet_bs64/checkpoint-epoch22.pth ...
Done in 3.677s
removing stale ckpt [epoch 21] [took 0.02s]
 epoch          : 22
 loss           : 0.04559872741624713
 quant_reg      : 9.805140293121339
 quant_err      : 9.805140293121339
 learning_rate  : 9.843720217036131e-06
 n_samples      : 704000
 n_steps        : 11000
 ActivityNet_val1_test/t2v_metrics/R1: 19.585112873703476
 ActivityNet_val1_test/t2v_metrics/R5: 51.06772422208664
 ActivityNet_val1_test/t2v_metrics/R10: 66.95139312588977
 ActivityNet_val1_test/t2v_metrics/R50: 90.7057148667887
 ActivityNet_val1_test/t2v_metrics/MedR: 5.0
 ActivityNet_val1_test/t2v_metrics/MeanR: 28.77160870449461
 ActivityNet_val1_test/t2v_metrics/geometric_mean_R1-R5-R10: 40.607918972030845
 ActivityNet_val1_test/v2t_metrics/R1: 20.45962985560301
 ActivityNet_val1_test/v2t_metrics/R5: 51.21008745169819
 ActivityNet_val1_test/v2t_metrics/R10: 67.78523489932886
 ActivityNet_val1_test/v2t_metrics/R50: 90.86841570063046
 ActivityNet_val1_test/v2t_metrics/MedR: 5.0
 ActivityNet_val1_test/v2t_metrics/MeanR: 27.86333129957291
 ActivityNet_val1_test/v2t_metrics/geometric_mean_R1-R5-R10: 41.41231083395918
 mnt_best       : 40.707038944556345
 not_improved_count: 1
Train Epoch: 23 [1/500 64/32000 (0%)] Loss: 0.07801 (QuantReg: 9.61133) QuantErr: 9.61133 batch_time=23.42957 
Train Epoch: 23 [9/500 576/32000 (2%)] Loss: 0.06882 (QuantReg: 9.78843) QuantErr: 9.78843 batch_time=0.43247 
Train Epoch: 23 [17/500 1088/32000 (3%)] Loss: 0.03022 (QuantReg: 9.90253) QuantErr: 9.90253 batch_time=0.54536 
Train Epoch: 23 [25/500 1600/32000 (5%)] Loss: 0.09183 (QuantReg: 9.60406) QuantErr: 9.60406 batch_time=0.44495 
Train Epoch: 23 [33/500 2112/32000 (7%)] Loss: 0.02943 (QuantReg: 9.86693) QuantErr: 9.86693 batch_time=0.44157 
Train Epoch: 23 [41/500 2624/32000 (8%)] Loss: 0.03198 (QuantReg: 9.54021) QuantErr: 9.54021 batch_time=0.44863 
Train Epoch: 23 [49/500 3136/32000 (10%)] Loss: 0.03894 (QuantReg: 9.70782) QuantErr: 9.70782 batch_time=0.44567 
Train Epoch: 23 [57/500 3648/32000 (11%)] Loss: 0.06122 (QuantReg: 9.53604) QuantErr: 9.53604 batch_time=0.50870 
Train Epoch: 23 [65/500 4160/32000 (13%)] Loss: 0.04293 (QuantReg: 9.56732) QuantErr: 9.56732 batch_time=0.48478 
Train Epoch: 23 [73/500 4672/32000 (15%)] Loss: 0.08010 (QuantReg: 9.49371) QuantErr: 9.49371 batch_time=0.45351 
Train Epoch: 23 [81/500 5184/32000 (16%)] Loss: 0.04219 (QuantReg: 9.79096) QuantErr: 9.79096 batch_time=0.51531 
Train Epoch: 23 [89/500 5696/32000 (18%)] Loss: 0.03153 (QuantReg: 9.61015) QuantErr: 9.61015 batch_time=0.48461 
Train Epoch: 23 [97/500 6208/32000 (19%)] Loss: 0.01690 (QuantReg: 9.71257) QuantErr: 9.71257 batch_time=0.45902 
Train Epoch: 23 [105/500 6720/32000 (21%)] Loss: 0.07553 (QuantReg: 9.86261) QuantErr: 9.86261 batch_time=0.48860 
Train Epoch: 23 [113/500 7232/32000 (23%)] Loss: 0.03176 (QuantReg: 9.78638) QuantErr: 9.78638 batch_time=0.44517 
Train Epoch: 23 [121/500 7744/32000 (24%)] Loss: 0.02244 (QuantReg: 9.76772) QuantErr: 9.76772 batch_time=0.52460 
Train Epoch: 23 [129/500 8256/32000 (26%)] Loss: 0.02809 (QuantReg: 9.71680) QuantErr: 9.71680 batch_time=0.47181 
Train Epoch: 23 [137/500 8768/32000 (27%)] Loss: 0.02438 (QuantReg: 9.89794) QuantErr: 9.89794 batch_time=0.43852 
Train Epoch: 23 [145/500 9280/32000 (29%)] Loss: 0.03534 (QuantReg: 9.69160) QuantErr: 9.69160 batch_time=0.51473 
Train Epoch: 23 [153/500 9792/32000 (31%)] Loss: 0.02624 (QuantReg: 9.72559) QuantErr: 9.72559 batch_time=0.44292 
Train Epoch: 23 [161/500 10304/32000 (32%)] Loss: 0.08904 (QuantReg: 9.62525) QuantErr: 9.62525 batch_time=0.44773 
Train Epoch: 23 [169/500 10816/32000 (34%)] Loss: 0.03686 (QuantReg: 9.43308) QuantErr: 9.43308 batch_time=0.48362 
Train Epoch: 23 [177/500 11328/32000 (35%)] Loss: 0.03168 (QuantReg: 9.83642) QuantErr: 9.83642 batch_time=0.44589 
Train Epoch: 23 [185/500 11840/32000 (37%)] Loss: 0.04462 (QuantReg: 9.91541) QuantErr: 9.91541 batch_time=0.51795 
Train Epoch: 23 [193/500 12352/32000 (39%)] Loss: 0.04209 (QuantReg: 9.86847) QuantErr: 9.86847 batch_time=0.48519 
Train Epoch: 23 [201/500 12864/32000 (40%)] Loss: 0.03029 (QuantReg: 9.86487) QuantErr: 9.86487 batch_time=0.49236 
Train Epoch: 23 [209/500 13376/32000 (42%)] Loss: 0.06502 (QuantReg: 9.57210) QuantErr: 9.57210 batch_time=0.51261 
Train Epoch: 23 [217/500 13888/32000 (43%)] Loss: 0.03350 (QuantReg: 9.60346) QuantErr: 9.60346 batch_time=0.44717 
Train Epoch: 23 [225/500 14400/32000 (45%)] Loss: 0.03442 (QuantReg: 9.76562) QuantErr: 9.76562 batch_time=0.44879 
Train Epoch: 23 [233/500 14912/32000 (47%)] Loss: 0.03909 (QuantReg: 9.64573) QuantErr: 9.64573 batch_time=0.44803 
Train Epoch: 23 [241/500 15424/32000 (48%)] Loss: 0.04771 (QuantReg: 9.77164) QuantErr: 9.77164 batch_time=0.44944 
Train Epoch: 23 [249/500 15936/32000 (50%)] Loss: 0.03128 (QuantReg: 9.71811) QuantErr: 9.71811 batch_time=0.52203 
Train Epoch: 23 [257/500 16448/32000 (51%)] Loss: 0.15897 (QuantReg: 9.42506) QuantErr: 9.42506 batch_time=0.48645 
Train Epoch: 23 [265/500 16960/32000 (53%)] Loss: 0.05282 (QuantReg: 9.60651) QuantErr: 9.60651 batch_time=0.44706 
Train Epoch: 23 [273/500 17472/32000 (55%)] Loss: 0.04728 (QuantReg: 9.68881) QuantErr: 9.68881 batch_time=0.50732 
Train Epoch: 23 [281/500 17984/32000 (56%)] Loss: 0.03061 (QuantReg: 9.54555) QuantErr: 9.54555 batch_time=0.43361 
Train Epoch: 23 [289/500 18496/32000 (58%)] Loss: 0.03093 (QuantReg: 9.67664) QuantErr: 9.67664 batch_time=0.45978 
Train Epoch: 23 [297/500 19008/32000 (59%)] Loss: 0.05586 (QuantReg: 9.82025) QuantErr: 9.82025 batch_time=0.44150 
Train Epoch: 23 [305/500 19520/32000 (61%)] Loss: 0.05226 (QuantReg: 9.67913) QuantErr: 9.67913 batch_time=0.43968 
Train Epoch: 23 [313/500 20032/32000 (63%)] Loss: 0.04907 (QuantReg: 9.96826) QuantErr: 9.96826 batch_time=0.51974 
Train Epoch: 23 [321/500 20544/32000 (64%)] Loss: 0.03774 (QuantReg: 9.71854) QuantErr: 9.71854 batch_time=0.47917 
Train Epoch: 23 [329/500 21056/32000 (66%)] Loss: 0.02667 (QuantReg: 9.58767) QuantErr: 9.58767 batch_time=0.44718 
Train Epoch: 23 [337/500 21568/32000 (67%)] Loss: 0.08485 (QuantReg: 9.78521) QuantErr: 9.78521 batch_time=0.52108 
Train Epoch: 23 [345/500 22080/32000 (69%)] Loss: 0.02236 (QuantReg: 9.57927) QuantErr: 9.57927 batch_time=0.44785 
Train Epoch: 23 [353/500 22592/32000 (71%)] Loss: 0.03462 (QuantReg: 9.87693) QuantErr: 9.87693 batch_time=0.43496 
Train Epoch: 23 [361/500 23104/32000 (72%)] Loss: 0.04801 (QuantReg: 9.75432) QuantErr: 9.75432 batch_time=0.43544 
Train Epoch: 23 [369/500 23616/32000 (74%)] Loss: 0.04303 (QuantReg: 9.60576) QuantErr: 9.60576 batch_time=0.43734 
Train Epoch: 23 [377/500 24128/32000 (75%)] Loss: 0.06002 (QuantReg: 9.75273) QuantErr: 9.75273 batch_time=0.51621 
Train Epoch: 23 [385/500 24640/32000 (77%)] Loss: 0.04896 (QuantReg: 9.83669) QuantErr: 9.83669 batch_time=0.47864 
Train Epoch: 23 [393/500 25152/32000 (79%)] Loss: 0.03901 (QuantReg: 9.77514) QuantErr: 9.77514 batch_time=0.44473 
Train Epoch: 23 [401/500 25664/32000 (80%)] Loss: 0.08383 (QuantReg: 9.73472) QuantErr: 9.73472 batch_time=0.50692 
Train Epoch: 23 [409/500 26176/32000 (82%)] Loss: 0.07323 (QuantReg: 9.76578) QuantErr: 9.76578 batch_time=0.44658 
Train Epoch: 23 [417/500 26688/32000 (83%)] Loss: 0.04380 (QuantReg: 9.62043) QuantErr: 9.62043 batch_time=0.46735 
Train Epoch: 23 [425/500 27200/32000 (85%)] Loss: 0.01486 (QuantReg: 9.77030) QuantErr: 9.77030 batch_time=0.45281 
Train Epoch: 23 [433/500 27712/32000 (87%)] Loss: 0.01946 (QuantReg: 9.80137) QuantErr: 9.80137 batch_time=0.45075 
Train Epoch: 23 [441/500 28224/32000 (88%)] Loss: 0.08369 (QuantReg: 9.90968) QuantErr: 9.90968 batch_time=0.51719 
Train Epoch: 23 [449/500 28736/32000 (90%)] Loss: 0.04783 (QuantReg: 9.62983) QuantErr: 9.62983 batch_time=0.48768 
Train Epoch: 23 [457/500 29248/32000 (91%)] Loss: 0.08136 (QuantReg: 9.74885) QuantErr: 9.74885 batch_time=0.45274 
Train Epoch: 23 [465/500 29760/32000 (93%)] Loss: 0.07831 (QuantReg: 9.80729) QuantErr: 9.80729 batch_time=0.51360 
Train Epoch: 23 [473/500 30272/32000 (95%)] Loss: 0.05065 (QuantReg: 9.64882) QuantErr: 9.64882 batch_time=0.45116 
Train Epoch: 23 [481/500 30784/32000 (96%)] Loss: 0.02058 (QuantReg: 9.89695) QuantErr: 9.89695 batch_time=0.44881 
Train Epoch: 23 [489/500 31296/32000 (98%)] Loss: 0.07540 (QuantReg: 9.82729) QuantErr: 9.82729 batch_time=0.43554 
Train Epoch: 23 [497/500 31808/32000 (99%)] Loss: 0.20095 (QuantReg: 9.50280) QuantErr: 9.50280 batch_time=0.44444 
Train Epoch: 23 codebook_update_time=1.65307
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_ActivityNet_bs64/checkpoint-epoch23.pth ...
Done in 17.986s
Updating 'best' checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_ActivityNet_bs64/checkpoint-epoch23.pth ...
Done in 22.512s
removing stale ckpt [epoch 22] [took 0.03s]
 epoch          : 23
 loss           : 0.048799696009606125
 quant_reg      : 9.719682598114014
 quant_err      : 9.719682598114014
 learning_rate  : 8.36716218448071e-06
 n_samples      : 736000
 n_steps        : 11500
 ActivityNet_val1_test/t2v_metrics/R1: 20.561317876754117
 ActivityNet_val1_test/t2v_metrics/R5: 50.88468578401464
 ActivityNet_val1_test/t2v_metrics/R10: 67.09375635550133
 ActivityNet_val1_test/t2v_metrics/R50: 90.38031319910515
 ActivityNet_val1_test/t2v_metrics/MedR: 5.0
 ActivityNet_val1_test/t2v_metrics/MeanR: 29.428513321130772
 ActivityNet_val1_test/t2v_metrics/geometric_mean_R1-R5-R10: 41.251529009943695
 ActivityNet_val1_test/v2t_metrics/R1: 20.317266625991458
 ActivityNet_val1_test/v2t_metrics/R5: 51.5965019320724
 ActivityNet_val1_test/v2t_metrics/R10: 67.68354687817775
 ActivityNet_val1_test/v2t_metrics/R50: 90.56335163717713
 ActivityNet_val1_test/v2t_metrics/MedR: 5.0
 ActivityNet_val1_test/v2t_metrics/MeanR: 27.587756762253406
 ActivityNet_val1_test/v2t_metrics/geometric_mean_R1-R5-R10: 41.3989712700269
 mnt_best       : 41.251529009943695
 not_improved_count: 0
Train Epoch: 24 [1/500 64/32000 (0%)] Loss: 0.02347 (QuantReg: 9.58438) QuantErr: 9.58438 batch_time=22.81387 
Train Epoch: 24 [9/500 576/32000 (2%)] Loss: 0.06031 (QuantReg: 9.76298) QuantErr: 9.76298 batch_time=0.45219 
Train Epoch: 24 [17/500 1088/32000 (3%)] Loss: 0.07809 (QuantReg: 9.79091) QuantErr: 9.79091 batch_time=1.67452 
Train Epoch: 24 [25/500 1600/32000 (5%)] Loss: 0.02363 (QuantReg: 9.66581) QuantErr: 9.66581 batch_time=0.46301 
Train Epoch: 24 [33/500 2112/32000 (7%)] Loss: 0.03232 (QuantReg: 9.70394) QuantErr: 9.70394 batch_time=0.44834 
Train Epoch: 24 [41/500 2624/32000 (8%)] Loss: 0.03064 (QuantReg: 9.51736) QuantErr: 9.51736 batch_time=0.44639 
Train Epoch: 24 [49/500 3136/32000 (10%)] Loss: 0.03466 (QuantReg: 9.80389) QuantErr: 9.80389 batch_time=0.50537 
Train Epoch: 24 [57/500 3648/32000 (11%)] Loss: 0.05322 (QuantReg: 9.75827) QuantErr: 9.75827 batch_time=0.44197 
Train Epoch: 24 [65/500 4160/32000 (13%)] Loss: 0.03379 (QuantReg: 9.78775) QuantErr: 9.78775 batch_time=0.81515 
Train Epoch: 24 [73/500 4672/32000 (15%)] Loss: 0.04893 (QuantReg: 9.56938) QuantErr: 9.56938 batch_time=0.45368 
Train Epoch: 24 [81/500 5184/32000 (16%)] Loss: 0.02440 (QuantReg: 9.82512) QuantErr: 9.82512 batch_time=1.30557 
Train Epoch: 24 [89/500 5696/32000 (18%)] Loss: 0.02917 (QuantReg: 9.55079) QuantErr: 9.55079 batch_time=0.50145 
Train Epoch: 24 [97/500 6208/32000 (19%)] Loss: 0.02632 (QuantReg: 9.69069) QuantErr: 9.69069 batch_time=0.44501 
Train Epoch: 24 [105/500 6720/32000 (21%)] Loss: 0.04065 (QuantReg: 9.64142) QuantErr: 9.64142 batch_time=0.44840 
Train Epoch: 24 [113/500 7232/32000 (23%)] Loss: 0.03313 (QuantReg: 9.68737) QuantErr: 9.68737 batch_time=0.50581 
Train Epoch: 24 [121/500 7744/32000 (24%)] Loss: 0.02172 (QuantReg: 9.64080) QuantErr: 9.64080 batch_time=0.45155 
Train Epoch: 24 [129/500 8256/32000 (26%)] Loss: 0.06395 (QuantReg: 9.53805) QuantErr: 9.53805 batch_time=0.54811 
Train Epoch: 24 [137/500 8768/32000 (27%)] Loss: 0.04562 (QuantReg: 9.47714) QuantErr: 9.47714 batch_time=0.44252 
Train Epoch: 24 [145/500 9280/32000 (29%)] Loss: 0.06910 (QuantReg: 9.66453) QuantErr: 9.66453 batch_time=1.29780 
Train Epoch: 24 [153/500 9792/32000 (31%)] Loss: 0.12041 (QuantReg: 9.74048) QuantErr: 9.74048 batch_time=0.44197 
Train Epoch: 24 [161/500 10304/32000 (32%)] Loss: 0.08794 (QuantReg: 9.66746) QuantErr: 9.66746 batch_time=0.44357 
Train Epoch: 24 [169/500 10816/32000 (34%)] Loss: 0.02853 (QuantReg: 9.58166) QuantErr: 9.58166 batch_time=0.44426 
Train Epoch: 24 [177/500 11328/32000 (35%)] Loss: 0.06943 (QuantReg: 9.61096) QuantErr: 9.61096 batch_time=0.52202 
Train Epoch: 24 [185/500 11840/32000 (37%)] Loss: 0.06599 (QuantReg: 9.62194) QuantErr: 9.62194 batch_time=0.43918 
Train Epoch: 24 [193/500 12352/32000 (39%)] Loss: 0.02884 (QuantReg: 9.54200) QuantErr: 9.54200 batch_time=0.52819 
Train Epoch: 24 [201/500 12864/32000 (40%)] Loss: 0.06243 (QuantReg: 9.69074) QuantErr: 9.69074 batch_time=0.44221 
Train Epoch: 24 [209/500 13376/32000 (42%)] Loss: 0.06247 (QuantReg: 9.66405) QuantErr: 9.66405 batch_time=1.22593 
Train Epoch: 24 [217/500 13888/32000 (43%)] Loss: 0.03080 (QuantReg: 9.84039) QuantErr: 9.84039 batch_time=0.46396 
Train Epoch: 24 [225/500 14400/32000 (45%)] Loss: 0.07264 (QuantReg: 9.65956) QuantErr: 9.65956 batch_time=0.48110 
Train Epoch: 24 [233/500 14912/32000 (47%)] Loss: 0.02211 (QuantReg: 9.74783) QuantErr: 9.74783 batch_time=0.47164 
Train Epoch: 24 [241/500 15424/32000 (48%)] Loss: 0.03568 (QuantReg: 9.70464) QuantErr: 9.70464 batch_time=0.53487 
Train Epoch: 24 [249/500 15936/32000 (50%)] Loss: 0.03389 (QuantReg: 9.70507) QuantErr: 9.70507 batch_time=0.47584 
Train Epoch: 24 [257/500 16448/32000 (51%)] Loss: 0.04994 (QuantReg: 9.63578) QuantErr: 9.63578 batch_time=0.58322 
Train Epoch: 24 [265/500 16960/32000 (53%)] Loss: 0.06731 (QuantReg: 9.72348) QuantErr: 9.72348 batch_time=0.44282 
Train Epoch: 24 [273/500 17472/32000 (55%)] Loss: 0.02701 (QuantReg: 9.60655) QuantErr: 9.60655 batch_time=1.30571 
Train Epoch: 24 [281/500 17984/32000 (56%)] Loss: 0.03115 (QuantReg: 9.73032) QuantErr: 9.73032 batch_time=0.44477 
Train Epoch: 24 [289/500 18496/32000 (58%)] Loss: 0.02387 (QuantReg: 9.63918) QuantErr: 9.63918 batch_time=0.44229 
Train Epoch: 24 [297/500 19008/32000 (59%)] Loss: 0.03804 (QuantReg: 9.56916) QuantErr: 9.56916 batch_time=0.49894 
Train Epoch: 24 [305/500 19520/32000 (61%)] Loss: 0.06622 (QuantReg: 9.79481) QuantErr: 9.79481 batch_time=0.51731 
Train Epoch: 24 [313/500 20032/32000 (63%)] Loss: 0.04657 (QuantReg: 9.66195) QuantErr: 9.66195 batch_time=0.43999 
Train Epoch: 24 [321/500 20544/32000 (64%)] Loss: 0.02592 (QuantReg: 9.69035) QuantErr: 9.69035 batch_time=0.54760 
Train Epoch: 24 [329/500 21056/32000 (66%)] Loss: 0.03042 (QuantReg: 9.59703) QuantErr: 9.59703 batch_time=0.44310 
Train Epoch: 24 [337/500 21568/32000 (67%)] Loss: 0.04348 (QuantReg: 9.54241) QuantErr: 9.54241 batch_time=1.33450 
Train Epoch: 24 [345/500 22080/32000 (69%)] Loss: 0.02052 (QuantReg: 9.69259) QuantErr: 9.69259 batch_time=0.45335 
Train Epoch: 24 [353/500 22592/32000 (71%)] Loss: 0.02659 (QuantReg: 9.63658) QuantErr: 9.63658 batch_time=0.44538 
Train Epoch: 24 [361/500 23104/32000 (72%)] Loss: 0.04279 (QuantReg: 9.46155) QuantErr: 9.46155 batch_time=0.45533 
Train Epoch: 24 [369/500 23616/32000 (74%)] Loss: 0.02958 (QuantReg: 9.62116) QuantErr: 9.62116 batch_time=0.50601 
Train Epoch: 24 [377/500 24128/32000 (75%)] Loss: 0.07946 (QuantReg: 9.61113) QuantErr: 9.61113 batch_time=0.44803 
Train Epoch: 24 [385/500 24640/32000 (77%)] Loss: 0.02471 (QuantReg: 9.55916) QuantErr: 9.55916 batch_time=0.53828 
Train Epoch: 24 [393/500 25152/32000 (79%)] Loss: 0.02550 (QuantReg: 9.67061) QuantErr: 9.67061 batch_time=0.45828 
Train Epoch: 24 [401/500 25664/32000 (80%)] Loss: 0.02748 (QuantReg: 9.51681) QuantErr: 9.51681 batch_time=1.26670 
Train Epoch: 24 [409/500 26176/32000 (82%)] Loss: 0.01892 (QuantReg: 9.40423) QuantErr: 9.40423 batch_time=0.44842 
Train Epoch: 24 [417/500 26688/32000 (83%)] Loss: 0.04148 (QuantReg: 9.72729) QuantErr: 9.72729 batch_time=0.47462 
Train Epoch: 24 [425/500 27200/32000 (85%)] Loss: 0.04021 (QuantReg: 9.75447) QuantErr: 9.75447 batch_time=0.45038 
Train Epoch: 24 [433/500 27712/32000 (87%)] Loss: 0.08127 (QuantReg: 9.67654) QuantErr: 9.67654 batch_time=0.52125 
Train Epoch: 24 [441/500 28224/32000 (88%)] Loss: 0.08187 (QuantReg: 9.64846) QuantErr: 9.64846 batch_time=0.43230 
Train Epoch: 24 [449/500 28736/32000 (90%)] Loss: 0.07151 (QuantReg: 9.33860) QuantErr: 9.33860 batch_time=0.52786 
Train Epoch: 24 [457/500 29248/32000 (91%)] Loss: 0.03472 (QuantReg: 9.63656) QuantErr: 9.63656 batch_time=0.44191 
Train Epoch: 24 [465/500 29760/32000 (93%)] Loss: 0.03568 (QuantReg: 9.70290) QuantErr: 9.70290 batch_time=1.32017 
Train Epoch: 24 [473/500 30272/32000 (95%)] Loss: 0.01962 (QuantReg: 9.69904) QuantErr: 9.69904 batch_time=0.47882 
Train Epoch: 24 [481/500 30784/32000 (96%)] Loss: 0.02771 (QuantReg: 9.57759) QuantErr: 9.57759 batch_time=0.45343 
Train Epoch: 24 [489/500 31296/32000 (98%)] Loss: 0.02801 (QuantReg: 9.53462) QuantErr: 9.53462 batch_time=0.44226 
Train Epoch: 24 [497/500 31808/32000 (99%)] Loss: 0.05535 (QuantReg: 9.74855) QuantErr: 9.74855 batch_time=0.54344 
Train Epoch: 24 codebook_update_time=1.63882
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_ActivityNet_bs64/checkpoint-epoch24.pth ...
Done in 4.564s
removing stale ckpt [epoch 23] [took 0.00s]
 epoch          : 24
 loss           : 0.04482180066406727
 quant_reg      : 9.626366230010987
 quant_err      : 9.626366230010987
 learning_rate  : 8.36716218448071e-06
 n_samples      : 768000
 n_steps        : 12000
 ActivityNet_val1_test/t2v_metrics/R1: 19.686800894854585
 ActivityNet_val1_test/t2v_metrics/R5: 50.925360992475085
 ActivityNet_val1_test/t2v_metrics/R10: 66.95139312588977
 ActivityNet_val1_test/t2v_metrics/R50: 89.8718730933496
 ActivityNet_val1_test/t2v_metrics/MedR: 5.0
 ActivityNet_val1_test/t2v_metrics/MeanR: 31.46593451291438
 ActivityNet_val1_test/t2v_metrics/geometric_mean_R1-R5-R10: 40.640242854681404
 ActivityNet_val1_test/v2t_metrics/R1: 20.45962985560301
 ActivityNet_val1_test/v2t_metrics/R5: 51.29143786861908
 ActivityNet_val1_test/v2t_metrics/R10: 67.15476916819199
 ActivityNet_val1_test/v2t_metrics/R50: 90.29896278218426
 ActivityNet_val1_test/v2t_metrics/MedR: 5.0
 ActivityNet_val1_test/v2t_metrics/MeanR: 29.700833841773438
 ActivityNet_val1_test/v2t_metrics/geometric_mean_R1-R5-R10: 41.30536862604763
 mnt_best       : 41.251529009943695
 not_improved_count: 1
Train Epoch: 25 [1/500 64/32000 (0%)] Loss: 0.06997 (QuantReg: 9.74199) QuantErr: 9.74199 batch_time=24.24829 
Train Epoch: 25 [9/500 576/32000 (2%)] Loss: 0.03552 (QuantReg: 9.69927) QuantErr: 9.69927 batch_time=0.44445 
Train Epoch: 25 [17/500 1088/32000 (3%)] Loss: 0.02698 (QuantReg: 9.65808) QuantErr: 9.65808 batch_time=1.57312 
Train Epoch: 25 [25/500 1600/32000 (5%)] Loss: 0.08344 (QuantReg: 9.53957) QuantErr: 9.53957 batch_time=0.44583 
Train Epoch: 25 [33/500 2112/32000 (7%)] Loss: 0.03693 (QuantReg: 9.58456) QuantErr: 9.58456 batch_time=0.43665 
Train Epoch: 25 [41/500 2624/32000 (8%)] Loss: 0.02221 (QuantReg: 9.61517) QuantErr: 9.61517 batch_time=0.43924 
Train Epoch: 25 [49/500 3136/32000 (10%)] Loss: 0.06919 (QuantReg: 9.56195) QuantErr: 9.56195 batch_time=0.48305 
Train Epoch: 25 [57/500 3648/32000 (11%)] Loss: 0.02345 (QuantReg: 9.65544) QuantErr: 9.65544 batch_time=0.43949 
Train Epoch: 25 [65/500 4160/32000 (13%)] Loss: 0.02273 (QuantReg: 9.49867) QuantErr: 9.49867 batch_time=0.44016 
Train Epoch: 25 [73/500 4672/32000 (15%)] Loss: 0.03395 (QuantReg: 9.63916) QuantErr: 9.63916 batch_time=0.44406 
Train Epoch: 25 [81/500 5184/32000 (16%)] Loss: 0.06149 (QuantReg: 9.60917) QuantErr: 9.60917 batch_time=1.26037 
Train Epoch: 25 [89/500 5696/32000 (18%)] Loss: 0.05222 (QuantReg: 9.64165) QuantErr: 9.64165 batch_time=0.44527 
Train Epoch: 25 [97/500 6208/32000 (19%)] Loss: 0.03822 (QuantReg: 9.44558) QuantErr: 9.44558 batch_time=0.45184 
Train Epoch: 25 [105/500 6720/32000 (21%)] Loss: 0.02812 (QuantReg: 9.70548) QuantErr: 9.70548 batch_time=0.44322 
Train Epoch: 25 [113/500 7232/32000 (23%)] Loss: 0.10357 (QuantReg: 9.41158) QuantErr: 9.41158 batch_time=0.44163 
Train Epoch: 25 [121/500 7744/32000 (24%)] Loss: 0.04158 (QuantReg: 9.48998) QuantErr: 9.48998 batch_time=0.44202 
Train Epoch: 25 [129/500 8256/32000 (26%)] Loss: 0.02171 (QuantReg: 9.50730) QuantErr: 9.50730 batch_time=0.44337 
Train Epoch: 25 [137/500 8768/32000 (27%)] Loss: 0.03731 (QuantReg: 9.49218) QuantErr: 9.49218 batch_time=0.43757 
Train Epoch: 25 [145/500 9280/32000 (29%)] Loss: 0.05023 (QuantReg: 9.41902) QuantErr: 9.41902 batch_time=1.28376 
Train Epoch: 25 [153/500 9792/32000 (31%)] Loss: 0.02435 (QuantReg: 9.56084) QuantErr: 9.56084 batch_time=0.43840 
Train Epoch: 25 [161/500 10304/32000 (32%)] Loss: 0.03827 (QuantReg: 9.49015) QuantErr: 9.49015 batch_time=0.45953 
Train Epoch: 25 [169/500 10816/32000 (34%)] Loss: 0.03091 (QuantReg: 9.40948) QuantErr: 9.40948 batch_time=0.44529 
Train Epoch: 25 [177/500 11328/32000 (35%)] Loss: 0.02439 (QuantReg: 9.40992) QuantErr: 9.40992 batch_time=0.44051 
Train Epoch: 25 [185/500 11840/32000 (37%)] Loss: 0.03357 (QuantReg: 9.74451) QuantErr: 9.74451 batch_time=0.44709 
Train Epoch: 25 [193/500 12352/32000 (39%)] Loss: 0.04780 (QuantReg: 9.56235) QuantErr: 9.56235 batch_time=0.44853 
Train Epoch: 25 [201/500 12864/32000 (40%)] Loss: 0.02517 (QuantReg: 9.44833) QuantErr: 9.44833 batch_time=0.43756 
Train Epoch: 25 [209/500 13376/32000 (42%)] Loss: 0.03480 (QuantReg: 9.58526) QuantErr: 9.58526 batch_time=1.29976 
Train Epoch: 25 [217/500 13888/32000 (43%)] Loss: 0.07413 (QuantReg: 9.53348) QuantErr: 9.53348 batch_time=0.43940 
Train Epoch: 25 [225/500 14400/32000 (45%)] Loss: 0.03245 (QuantReg: 9.57996) QuantErr: 9.57996 batch_time=0.43903 
Train Epoch: 25 [233/500 14912/32000 (47%)] Loss: 0.03851 (QuantReg: 9.55604) QuantErr: 9.55604 batch_time=0.44482 
Train Epoch: 25 [241/500 15424/32000 (48%)] Loss: 0.04221 (QuantReg: 9.49661) QuantErr: 9.49661 batch_time=0.45086 
Train Epoch: 25 [249/500 15936/32000 (50%)] Loss: 0.05847 (QuantReg: 9.40849) QuantErr: 9.40849 batch_time=0.43867 
Train Epoch: 25 [257/500 16448/32000 (51%)] Loss: 0.03637 (QuantReg: 9.58423) QuantErr: 9.58423 batch_time=0.44001 
Train Epoch: 25 [265/500 16960/32000 (53%)] Loss: 0.03343 (QuantReg: 9.59325) QuantErr: 9.59325 batch_time=0.45008 
Train Epoch: 25 [273/500 17472/32000 (55%)] Loss: 0.04140 (QuantReg: 9.61309) QuantErr: 9.61309 batch_time=1.25471 
Train Epoch: 25 [281/500 17984/32000 (56%)] Loss: 0.04357 (QuantReg: 9.39415) QuantErr: 9.39415 batch_time=0.46410 
Train Epoch: 25 [289/500 18496/32000 (58%)] Loss: 0.02561 (QuantReg: 9.59104) QuantErr: 9.59104 batch_time=0.43443 
Train Epoch: 25 [297/500 19008/32000 (59%)] Loss: 0.04844 (QuantReg: 9.33943) QuantErr: 9.33943 batch_time=0.44977 
Train Epoch: 25 [305/500 19520/32000 (61%)] Loss: 0.08017 (QuantReg: 9.55797) QuantErr: 9.55797 batch_time=0.48244 
Train Epoch: 25 [313/500 20032/32000 (63%)] Loss: 0.03716 (QuantReg: 9.43169) QuantErr: 9.43169 batch_time=0.44257 
Train Epoch: 25 [321/500 20544/32000 (64%)] Loss: 0.04557 (QuantReg: 9.43865) QuantErr: 9.43865 batch_time=0.44639 
Train Epoch: 25 [329/500 21056/32000 (66%)] Loss: 0.02914 (QuantReg: 9.73780) QuantErr: 9.73780 batch_time=0.44526 
Train Epoch: 25 [337/500 21568/32000 (67%)] Loss: 0.02162 (QuantReg: 9.70424) QuantErr: 9.70424 batch_time=1.29555 
Train Epoch: 25 [345/500 22080/32000 (69%)] Loss: 0.07168 (QuantReg: 9.82490) QuantErr: 9.82490 batch_time=0.47255 
Train Epoch: 25 [353/500 22592/32000 (71%)] Loss: 0.02236 (QuantReg: 9.59333) QuantErr: 9.59333 batch_time=0.45547 
Train Epoch: 25 [361/500 23104/32000 (72%)] Loss: 0.03377 (QuantReg: 9.56282) QuantErr: 9.56282 batch_time=0.44832 
Train Epoch: 25 [369/500 23616/32000 (74%)] Loss: 0.05691 (QuantReg: 9.44098) QuantErr: 9.44098 batch_time=0.48156 
Train Epoch: 25 [377/500 24128/32000 (75%)] Loss: 0.08738 (QuantReg: 9.42740) QuantErr: 9.42740 batch_time=0.44496 
Train Epoch: 25 [385/500 24640/32000 (77%)] Loss: 0.02497 (QuantReg: 9.58270) QuantErr: 9.58270 batch_time=0.44192 
Train Epoch: 25 [393/500 25152/32000 (79%)] Loss: 0.06439 (QuantReg: 9.45971) QuantErr: 9.45971 batch_time=0.44145 
Train Epoch: 25 [401/500 25664/32000 (80%)] Loss: 0.02457 (QuantReg: 9.74238) QuantErr: 9.74238 batch_time=1.26428 
Train Epoch: 25 [409/500 26176/32000 (82%)] Loss: 0.04528 (QuantReg: 9.49397) QuantErr: 9.49397 batch_time=0.44162 
Train Epoch: 25 [417/500 26688/32000 (83%)] Loss: 0.06120 (QuantReg: 9.53973) QuantErr: 9.53973 batch_time=0.43600 
Train Epoch: 25 [425/500 27200/32000 (85%)] Loss: 0.02911 (QuantReg: 9.49310) QuantErr: 9.49310 batch_time=0.46266 
Train Epoch: 25 [433/500 27712/32000 (87%)] Loss: 0.02725 (QuantReg: 9.75337) QuantErr: 9.75337 batch_time=0.45500 
Train Epoch: 25 [441/500 28224/32000 (88%)] Loss: 0.02290 (QuantReg: 9.51101) QuantErr: 9.51101 batch_time=0.44552 
Train Epoch: 25 [449/500 28736/32000 (90%)] Loss: 0.03036 (QuantReg: 9.41849) QuantErr: 9.41849 batch_time=0.45174 
Train Epoch: 25 [457/500 29248/32000 (91%)] Loss: 0.01561 (QuantReg: 9.52728) QuantErr: 9.52728 batch_time=0.45445 
Train Epoch: 25 [465/500 29760/32000 (93%)] Loss: 0.08902 (QuantReg: 9.52087) QuantErr: 9.52087 batch_time=1.28901 
Train Epoch: 25 [473/500 30272/32000 (95%)] Loss: 0.04947 (QuantReg: 9.58017) QuantErr: 9.58017 batch_time=0.44553 
Train Epoch: 25 [481/500 30784/32000 (96%)] Loss: 0.03576 (QuantReg: 9.65746) QuantErr: 9.65746 batch_time=0.43998 
Train Epoch: 25 [489/500 31296/32000 (98%)] Loss: 0.02662 (QuantReg: 9.52595) QuantErr: 9.52595 batch_time=0.44474 
Train Epoch: 25 [497/500 31808/32000 (99%)] Loss: 0.02876 (QuantReg: 9.54298) QuantErr: 9.54298 batch_time=0.44591 
Train Epoch: 25 codebook_update_time=1.64016
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_ActivityNet_bs64/checkpoint-epoch25.pth ...
Done in 4.608s
removing stale ckpt [epoch 24] [took 0.01s]
 epoch          : 25
 loss           : 0.043357710616663096
 quant_reg      : 9.537833129882813
 quant_err      : 9.537833129882813
 learning_rate  : 7.112087856808604e-06
 n_samples      : 800000
 n_steps        : 12500
 ActivityNet_val1_test/t2v_metrics/R1: 19.97152735407769
 ActivityNet_val1_test/t2v_metrics/R5: 51.14907463900752
 ActivityNet_val1_test/t2v_metrics/R10: 66.788692292048
 ActivityNet_val1_test/t2v_metrics/R50: 89.85153548911939
 ActivityNet_val1_test/t2v_metrics/MedR: 5.0
 ActivityNet_val1_test/t2v_metrics/MeanR: 30.785031523286555
 ActivityNet_val1_test/t2v_metrics/geometric_mean_R1-R5-R10: 40.86178492664647
 ActivityNet_val1_test/v2t_metrics/R1: 20.70368110636567
 ActivityNet_val1_test/v2t_metrics/R5: 52.45068130974171
 ActivityNet_val1_test/v2t_metrics/R10: 67.56152125279642
 ActivityNet_val1_test/v2t_metrics/R50: 90.11592434411226
 ActivityNet_val1_test/v2t_metrics/MedR: 5.0
 ActivityNet_val1_test/v2t_metrics/MeanR: 29.383973967866584
 ActivityNet_val1_test/v2t_metrics/geometric_mean_R1-R5-R10: 41.863227500277475
 mnt_best       : 41.251529009943695
 not_improved_count: 2
Train Epoch: 26 [1/500 64/32000 (0%)] Loss: 0.03310 (QuantReg: 9.58372) QuantErr: 9.58372 batch_time=23.63103 
Train Epoch: 26 [9/500 576/32000 (2%)] Loss: 0.03018 (QuantReg: 9.24766) QuantErr: 9.24766 batch_time=0.45574 
Train Epoch: 26 [17/500 1088/32000 (3%)] Loss: 0.04581 (QuantReg: 9.47953) QuantErr: 9.47953 batch_time=1.57427 
Train Epoch: 26 [25/500 1600/32000 (5%)] Loss: 0.03782 (QuantReg: 9.41490) QuantErr: 9.41490 batch_time=0.47451 
Train Epoch: 26 [33/500 2112/32000 (7%)] Loss: 0.09182 (QuantReg: 9.49301) QuantErr: 9.49301 batch_time=0.42716 
Train Epoch: 26 [41/500 2624/32000 (8%)] Loss: 0.02957 (QuantReg: 9.53875) QuantErr: 9.53875 batch_time=0.49953 
Train Epoch: 26 [49/500 3136/32000 (10%)] Loss: 0.02910 (QuantReg: 9.46411) QuantErr: 9.46411 batch_time=0.47682 
Train Epoch: 26 [57/500 3648/32000 (11%)] Loss: 0.04283 (QuantReg: 9.25883) QuantErr: 9.25883 batch_time=0.44585 
Train Epoch: 26 [65/500 4160/32000 (13%)] Loss: 0.01916 (QuantReg: 9.35243) QuantErr: 9.35243 batch_time=0.46017 
Train Epoch: 26 [73/500 4672/32000 (15%)] Loss: 0.07319 (QuantReg: 9.58846) QuantErr: 9.58846 batch_time=0.47803 
Train Epoch: 26 [81/500 5184/32000 (16%)] Loss: 0.06388 (QuantReg: 9.28987) QuantErr: 9.28987 batch_time=1.21197 
Train Epoch: 26 [89/500 5696/32000 (18%)] Loss: 0.03539 (QuantReg: 9.29625) QuantErr: 9.29625 batch_time=0.47762 
Train Epoch: 26 [97/500 6208/32000 (19%)] Loss: 0.02556 (QuantReg: 9.53890) QuantErr: 9.53890 batch_time=0.44632 
Train Epoch: 26 [105/500 6720/32000 (21%)] Loss: 0.06172 (QuantReg: 9.49212) QuantErr: 9.49212 batch_time=0.44756 
Train Epoch: 26 [113/500 7232/32000 (23%)] Loss: 0.05651 (QuantReg: 9.52397) QuantErr: 9.52397 batch_time=0.44189 
Train Epoch: 26 [121/500 7744/32000 (24%)] Loss: 0.04258 (QuantReg: 9.43661) QuantErr: 9.43661 batch_time=0.44659 
Train Epoch: 26 [129/500 8256/32000 (26%)] Loss: 0.03125 (QuantReg: 9.45760) QuantErr: 9.45760 batch_time=0.45691 
Train Epoch: 26 [137/500 8768/32000 (27%)] Loss: 0.02408 (QuantReg: 9.45294) QuantErr: 9.45294 batch_time=0.44516 
Train Epoch: 26 [145/500 9280/32000 (29%)] Loss: 0.02742 (QuantReg: 9.55486) QuantErr: 9.55486 batch_time=1.22809 
Train Epoch: 26 [153/500 9792/32000 (31%)] Loss: 0.04682 (QuantReg: 9.65113) QuantErr: 9.65113 batch_time=0.48788 
Train Epoch: 26 [161/500 10304/32000 (32%)] Loss: 0.09626 (QuantReg: 9.47408) QuantErr: 9.47408 batch_time=0.44621 
Train Epoch: 26 [169/500 10816/32000 (34%)] Loss: 0.02557 (QuantReg: 9.39275) QuantErr: 9.39275 batch_time=0.43885 
Train Epoch: 26 [177/500 11328/32000 (35%)] Loss: 0.05830 (QuantReg: 9.40326) QuantErr: 9.40326 batch_time=0.45421 
Train Epoch: 26 [185/500 11840/32000 (37%)] Loss: 0.02242 (QuantReg: 9.45926) QuantErr: 9.45926 batch_time=0.44297 
Train Epoch: 26 [193/500 12352/32000 (39%)] Loss: 0.02055 (QuantReg: 9.35782) QuantErr: 9.35782 batch_time=0.43887 
Train Epoch: 26 [201/500 12864/32000 (40%)] Loss: 0.04051 (QuantReg: 9.78585) QuantErr: 9.78585 batch_time=0.44104 
Train Epoch: 26 [209/500 13376/32000 (42%)] Loss: 0.02539 (QuantReg: 9.38870) QuantErr: 9.38870 batch_time=1.20279 
Train Epoch: 26 [217/500 13888/32000 (43%)] Loss: 0.04106 (QuantReg: 9.46646) QuantErr: 9.46646 batch_time=0.47090 
Train Epoch: 26 [225/500 14400/32000 (45%)] Loss: 0.06770 (QuantReg: 9.38788) QuantErr: 9.38788 batch_time=0.43644 
Train Epoch: 26 [233/500 14912/32000 (47%)] Loss: 0.04011 (QuantReg: 9.52026) QuantErr: 9.52026 batch_time=0.43660 
Train Epoch: 26 [241/500 15424/32000 (48%)] Loss: 0.03763 (QuantReg: 9.55211) QuantErr: 9.55211 batch_time=0.43661 
Train Epoch: 26 [249/500 15936/32000 (50%)] Loss: 0.06858 (QuantReg: 9.27195) QuantErr: 9.27195 batch_time=0.44196 
Train Epoch: 26 [257/500 16448/32000 (51%)] Loss: 0.02054 (QuantReg: 9.50297) QuantErr: 9.50297 batch_time=0.44587 
Train Epoch: 26 [265/500 16960/32000 (53%)] Loss: 0.02462 (QuantReg: 9.63218) QuantErr: 9.63218 batch_time=0.44171 
Train Epoch: 26 [273/500 17472/32000 (55%)] Loss: 0.02960 (QuantReg: 9.47421) QuantErr: 9.47421 batch_time=1.16737 
Train Epoch: 26 [281/500 17984/32000 (56%)] Loss: 0.02135 (QuantReg: 9.38558) QuantErr: 9.38558 batch_time=0.49137 
Train Epoch: 26 [289/500 18496/32000 (58%)] Loss: 0.05431 (QuantReg: 9.44308) QuantErr: 9.44308 batch_time=0.44564 
Train Epoch: 26 [297/500 19008/32000 (59%)] Loss: 0.04001 (QuantReg: 9.37192) QuantErr: 9.37192 batch_time=0.44459 
Train Epoch: 26 [305/500 19520/32000 (61%)] Loss: 0.03344 (QuantReg: 9.41499) QuantErr: 9.41499 batch_time=0.44228 
Train Epoch: 26 [313/500 20032/32000 (63%)] Loss: 0.01918 (QuantReg: 9.32732) QuantErr: 9.32732 batch_time=0.45830 
Train Epoch: 26 [321/500 20544/32000 (64%)] Loss: 0.03991 (QuantReg: 9.45138) QuantErr: 9.45138 batch_time=0.45602 
Train Epoch: 26 [329/500 21056/32000 (66%)] Loss: 0.03966 (QuantReg: 9.23658) QuantErr: 9.23658 batch_time=0.44390 
Train Epoch: 26 [337/500 21568/32000 (67%)] Loss: 0.01645 (QuantReg: 9.45578) QuantErr: 9.45578 batch_time=1.17360 
Train Epoch: 26 [345/500 22080/32000 (69%)] Loss: 0.02378 (QuantReg: 9.35990) QuantErr: 9.35990 batch_time=0.47383 
Train Epoch: 26 [353/500 22592/32000 (71%)] Loss: 0.07239 (QuantReg: 9.40384) QuantErr: 9.40384 batch_time=0.46558 
Train Epoch: 26 [361/500 23104/32000 (72%)] Loss: 0.04368 (QuantReg: 9.52941) QuantErr: 9.52941 batch_time=0.43922 
Train Epoch: 26 [369/500 23616/32000 (74%)] Loss: 0.01841 (QuantReg: 9.39850) QuantErr: 9.39850 batch_time=0.43886 
Train Epoch: 26 [377/500 24128/32000 (75%)] Loss: 0.04867 (QuantReg: 9.18867) QuantErr: 9.18867 batch_time=0.43740 
Train Epoch: 26 [385/500 24640/32000 (77%)] Loss: 0.07137 (QuantReg: 9.56756) QuantErr: 9.56756 batch_time=0.44486 
Train Epoch: 26 [393/500 25152/32000 (79%)] Loss: 0.03017 (QuantReg: 9.47731) QuantErr: 9.47731 batch_time=0.44035 
Train Epoch: 26 [401/500 25664/32000 (80%)] Loss: 0.03846 (QuantReg: 9.58482) QuantErr: 9.58482 batch_time=1.17342 
Train Epoch: 26 [409/500 26176/32000 (82%)] Loss: 0.07391 (QuantReg: 9.37618) QuantErr: 9.37618 batch_time=0.47604 
Train Epoch: 26 [417/500 26688/32000 (83%)] Loss: 0.03070 (QuantReg: 9.47302) QuantErr: 9.47302 batch_time=0.49296 
Train Epoch: 26 [425/500 27200/32000 (85%)] Loss: 0.06145 (QuantReg: 9.30927) QuantErr: 9.30927 batch_time=0.47233 
Train Epoch: 26 [433/500 27712/32000 (87%)] Loss: 0.02542 (QuantReg: 9.37205) QuantErr: 9.37205 batch_time=0.44828 
Train Epoch: 26 [441/500 28224/32000 (88%)] Loss: 0.04427 (QuantReg: 9.37003) QuantErr: 9.37003 batch_time=0.44408 
Train Epoch: 26 [449/500 28736/32000 (90%)] Loss: 0.05043 (QuantReg: 9.66579) QuantErr: 9.66579 batch_time=0.44403 
Train Epoch: 26 [457/500 29248/32000 (91%)] Loss: 0.03683 (QuantReg: 9.51132) QuantErr: 9.51132 batch_time=0.45467 
Train Epoch: 26 [465/500 29760/32000 (93%)] Loss: 0.01754 (QuantReg: 9.49501) QuantErr: 9.49501 batch_time=1.17577 
Train Epoch: 26 [473/500 30272/32000 (95%)] Loss: 0.03846 (QuantReg: 9.78856) QuantErr: 9.78856 batch_time=0.46901 
Train Epoch: 26 [481/500 30784/32000 (96%)] Loss: 0.02815 (QuantReg: 9.48200) QuantErr: 9.48200 batch_time=0.44930 
Train Epoch: 26 [489/500 31296/32000 (98%)] Loss: 0.03111 (QuantReg: 9.55224) QuantErr: 9.55224 batch_time=0.43671 
Train Epoch: 26 [497/500 31808/32000 (99%)] Loss: 0.07803 (QuantReg: 9.35085) QuantErr: 9.35085 batch_time=0.44357 
Train Epoch: 26 codebook_update_time=1.63718
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_ActivityNet_bs64/checkpoint-epoch26.pth ...
Done in 4.191s
removing stale ckpt [epoch 25] [took 0.00s]
 epoch          : 26
 loss           : 0.04354426832683384
 quant_reg      : 9.457506690979004
 quant_err      : 9.457506690979004
 learning_rate  : 7.112087856808604e-06
 n_samples      : 832000
 n_steps        : 13000
 ActivityNet_val1_test/t2v_metrics/R1: 19.788488916005694
 ActivityNet_val1_test/t2v_metrics/R5: 50.80333536709376
 ActivityNet_val1_test/t2v_metrics/R10: 66.788692292048
 ActivityNet_val1_test/t2v_metrics/R50: 89.79052267642872
 ActivityNet_val1_test/t2v_metrics/MedR: 5.0
 ActivityNet_val1_test/t2v_metrics/MeanR: 32.59487492373398
 ActivityNet_val1_test/t2v_metrics/geometric_mean_R1-R5-R10: 40.6445761775113
 ActivityNet_val1_test/v2t_metrics/R1: 21.09009558673988
 ActivityNet_val1_test/v2t_metrics/R5: 52.12527964205817
 ActivityNet_val1_test/v2t_metrics/R10: 67.68354687817775
 ActivityNet_val1_test/v2t_metrics/R50: 89.99389871873093
 ActivityNet_val1_test/v2t_metrics/MedR: 5.0
 ActivityNet_val1_test/v2t_metrics/MeanR: 29.234289200732153
 ActivityNet_val1_test/v2t_metrics/geometric_mean_R1-R5-R10: 42.06007264384443
 mnt_best       : 41.251529009943695
 not_improved_count: 3
Train Epoch: 27 [1/500 64/32000 (0%)] Loss: 0.04240 (QuantReg: 9.49909) QuantErr: 9.49909 batch_time=24.20250 
Train Epoch: 27 [9/500 576/32000 (2%)] Loss: 0.03468 (QuantReg: 9.16230) QuantErr: 9.16230 batch_time=0.43667 
Train Epoch: 27 [17/500 1088/32000 (3%)] Loss: 0.03315 (QuantReg: 9.50499) QuantErr: 9.50499 batch_time=1.68700 
Train Epoch: 27 [25/500 1600/32000 (5%)] Loss: 0.04447 (QuantReg: 9.47381) QuantErr: 9.47381 batch_time=0.45126 
Train Epoch: 27 [33/500 2112/32000 (7%)] Loss: 0.08726 (QuantReg: 9.34717) QuantErr: 9.34717 batch_time=0.44403 
Train Epoch: 27 [41/500 2624/32000 (8%)] Loss: 0.07241 (QuantReg: 9.53104) QuantErr: 9.53104 batch_time=0.44793 
Train Epoch: 27 [49/500 3136/32000 (10%)] Loss: 0.02087 (QuantReg: 9.30134) QuantErr: 9.30134 batch_time=0.44071 
Train Epoch: 27 [57/500 3648/32000 (11%)] Loss: 0.04846 (QuantReg: 9.52468) QuantErr: 9.52468 batch_time=0.44051 
Train Epoch: 27 [65/500 4160/32000 (13%)] Loss: 0.04403 (QuantReg: 9.48055) QuantErr: 9.48055 batch_time=0.75416 
Train Epoch: 27 [73/500 4672/32000 (15%)] Loss: 0.08970 (QuantReg: 9.24074) QuantErr: 9.24074 batch_time=0.44923 
Train Epoch: 27 [81/500 5184/32000 (16%)] Loss: 0.01623 (QuantReg: 9.24799) QuantErr: 9.24799 batch_time=1.40498 
Train Epoch: 27 [89/500 5696/32000 (18%)] Loss: 0.03012 (QuantReg: 9.38983) QuantErr: 9.38983 batch_time=0.43607 
Train Epoch: 27 [97/500 6208/32000 (19%)] Loss: 0.02406 (QuantReg: 9.41939) QuantErr: 9.41939 batch_time=0.44218 
Train Epoch: 27 [105/500 6720/32000 (21%)] Loss: 0.07107 (QuantReg: 9.41000) QuantErr: 9.41000 batch_time=0.46493 
Train Epoch: 27 [113/500 7232/32000 (23%)] Loss: 0.03567 (QuantReg: 9.42487) QuantErr: 9.42487 batch_time=0.44526 
Train Epoch: 27 [121/500 7744/32000 (24%)] Loss: 0.03585 (QuantReg: 9.29716) QuantErr: 9.29716 batch_time=0.44272 
Train Epoch: 27 [129/500 8256/32000 (26%)] Loss: 0.03771 (QuantReg: 9.48598) QuantErr: 9.48598 batch_time=0.75255 
Train Epoch: 27 [137/500 8768/32000 (27%)] Loss: 0.02809 (QuantReg: 9.55843) QuantErr: 9.55843 batch_time=0.48206 
Train Epoch: 27 [145/500 9280/32000 (29%)] Loss: 0.02652 (QuantReg: 9.23047) QuantErr: 9.23047 batch_time=1.69649 
Train Epoch: 27 [153/500 9792/32000 (31%)] Loss: 0.02296 (QuantReg: 9.66642) QuantErr: 9.66642 batch_time=0.44454 
Train Epoch: 27 [161/500 10304/32000 (32%)] Loss: 0.02755 (QuantReg: 9.26942) QuantErr: 9.26942 batch_time=0.44416 
Train Epoch: 27 [169/500 10816/32000 (34%)] Loss: 0.02950 (QuantReg: 9.49102) QuantErr: 9.49102 batch_time=0.43876 
Train Epoch: 27 [177/500 11328/32000 (35%)] Loss: 0.07131 (QuantReg: 9.35253) QuantErr: 9.35253 batch_time=0.44120 
Train Epoch: 27 [185/500 11840/32000 (37%)] Loss: 0.03940 (QuantReg: 9.28598) QuantErr: 9.28598 batch_time=0.44050 
Train Epoch: 27 [193/500 12352/32000 (39%)] Loss: 0.01743 (QuantReg: 9.27460) QuantErr: 9.27460 batch_time=0.76436 
Train Epoch: 27 [201/500 12864/32000 (40%)] Loss: 0.05378 (QuantReg: 9.47388) QuantErr: 9.47388 batch_time=0.43993 
Train Epoch: 27 [209/500 13376/32000 (42%)] Loss: 0.02351 (QuantReg: 9.32319) QuantErr: 9.32319 batch_time=1.37625 
Train Epoch: 27 [217/500 13888/32000 (43%)] Loss: 0.02258 (QuantReg: 9.46789) QuantErr: 9.46789 batch_time=0.46992 
Train Epoch: 27 [225/500 14400/32000 (45%)] Loss: 0.03237 (QuantReg: 9.35988) QuantErr: 9.35988 batch_time=0.43963 
Train Epoch: 27 [233/500 14912/32000 (47%)] Loss: 0.04606 (QuantReg: 9.46061) QuantErr: 9.46061 batch_time=0.43794 
Train Epoch: 27 [241/500 15424/32000 (48%)] Loss: 0.05711 (QuantReg: 9.55480) QuantErr: 9.55480 batch_time=0.44079 
Train Epoch: 27 [249/500 15936/32000 (50%)] Loss: 0.03866 (QuantReg: 9.30041) QuantErr: 9.30041 batch_time=0.44467 
Train Epoch: 27 [257/500 16448/32000 (51%)] Loss: 0.03396 (QuantReg: 9.46328) QuantErr: 9.46328 batch_time=0.76605 
Train Epoch: 27 [265/500 16960/32000 (53%)] Loss: 0.07544 (QuantReg: 9.42389) QuantErr: 9.42389 batch_time=0.44362 
Train Epoch: 27 [273/500 17472/32000 (55%)] Loss: 0.02839 (QuantReg: 9.20379) QuantErr: 9.20379 batch_time=1.51671 
Train Epoch: 27 [281/500 17984/32000 (56%)] Loss: 0.01340 (QuantReg: 9.51692) QuantErr: 9.51692 batch_time=0.47129 
Train Epoch: 27 [289/500 18496/32000 (58%)] Loss: 0.02318 (QuantReg: 9.46454) QuantErr: 9.46454 batch_time=0.44603 
Train Epoch: 27 [297/500 19008/32000 (59%)] Loss: 0.03118 (QuantReg: 9.31830) QuantErr: 9.31830 batch_time=0.47133 
Train Epoch: 27 [305/500 19520/32000 (61%)] Loss: 0.01858 (QuantReg: 9.43418) QuantErr: 9.43418 batch_time=0.47857 
Train Epoch: 27 [313/500 20032/32000 (63%)] Loss: 0.02690 (QuantReg: 9.51865) QuantErr: 9.51865 batch_time=0.44697 
Train Epoch: 27 [321/500 20544/32000 (64%)] Loss: 0.07664 (QuantReg: 9.42127) QuantErr: 9.42127 batch_time=0.73975 
Train Epoch: 27 [329/500 21056/32000 (66%)] Loss: 0.07456 (QuantReg: 9.34842) QuantErr: 9.34842 batch_time=0.44044 
Train Epoch: 27 [337/500 21568/32000 (67%)] Loss: 0.02309 (QuantReg: 9.43354) QuantErr: 9.43354 batch_time=1.39133 
Train Epoch: 27 [345/500 22080/32000 (69%)] Loss: 0.03221 (QuantReg: 9.32550) QuantErr: 9.32550 batch_time=0.45560 
Train Epoch: 27 [353/500 22592/32000 (71%)] Loss: 0.02884 (QuantReg: 9.20915) QuantErr: 9.20915 batch_time=0.44141 
Train Epoch: 27 [361/500 23104/32000 (72%)] Loss: 0.02661 (QuantReg: 9.52284) QuantErr: 9.52284 batch_time=0.44968 
Train Epoch: 27 [369/500 23616/32000 (74%)] Loss: 0.01870 (QuantReg: 9.29226) QuantErr: 9.29226 batch_time=0.45139 
Train Epoch: 27 [377/500 24128/32000 (75%)] Loss: 0.02108 (QuantReg: 9.03250) QuantErr: 9.03250 batch_time=0.44295 
Train Epoch: 27 [385/500 24640/32000 (77%)] Loss: 0.03186 (QuantReg: 9.47525) QuantErr: 9.47525 batch_time=0.80813 
Train Epoch: 27 [393/500 25152/32000 (79%)] Loss: 0.03519 (QuantReg: 9.48112) QuantErr: 9.48112 batch_time=0.44437 
Train Epoch: 27 [401/500 25664/32000 (80%)] Loss: 0.04272 (QuantReg: 9.25699) QuantErr: 9.25699 batch_time=1.50589 
Train Epoch: 27 [409/500 26176/32000 (82%)] Loss: 0.01642 (QuantReg: 9.48429) QuantErr: 9.48429 batch_time=0.44602 
Train Epoch: 27 [417/500 26688/32000 (83%)] Loss: 0.01974 (QuantReg: 9.41070) QuantErr: 9.41070 batch_time=0.44532 
Train Epoch: 27 [425/500 27200/32000 (85%)] Loss: 0.02170 (QuantReg: 9.38819) QuantErr: 9.38819 batch_time=0.44370 
Train Epoch: 27 [433/500 27712/32000 (87%)] Loss: 0.03415 (QuantReg: 9.42263) QuantErr: 9.42263 batch_time=0.44497 
Train Epoch: 27 [441/500 28224/32000 (88%)] Loss: 0.03303 (QuantReg: 9.36686) QuantErr: 9.36686 batch_time=0.43760 
Train Epoch: 27 [449/500 28736/32000 (90%)] Loss: 0.03192 (QuantReg: 9.31719) QuantErr: 9.31719 batch_time=0.74508 
Train Epoch: 27 [457/500 29248/32000 (91%)] Loss: 0.03067 (QuantReg: 9.25461) QuantErr: 9.25461 batch_time=0.44505 
Train Epoch: 27 [465/500 29760/32000 (93%)] Loss: 0.01999 (QuantReg: 9.42589) QuantErr: 9.42589 batch_time=1.43212 
Train Epoch: 27 [473/500 30272/32000 (95%)] Loss: 0.03106 (QuantReg: 9.31979) QuantErr: 9.31979 batch_time=0.44779 
Train Epoch: 27 [481/500 30784/32000 (96%)] Loss: 0.06253 (QuantReg: 9.48134) QuantErr: 9.48134 batch_time=0.44387 
Train Epoch: 27 [489/500 31296/32000 (98%)] Loss: 0.03073 (QuantReg: 9.30383) QuantErr: 9.30383 batch_time=0.44581 
Train Epoch: 27 [497/500 31808/32000 (99%)] Loss: 0.03711 (QuantReg: 9.42068) QuantErr: 9.42068 batch_time=0.45055 
Train Epoch: 27 codebook_update_time=1.69243
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_ActivityNet_bs64/checkpoint-epoch27.pth ...
Done in 13.033s
removing stale ckpt [epoch 26] [took 0.00s]
 epoch          : 27
 loss           : 0.04065724963136017
 quant_reg      : 9.383152013778686
 quant_err      : 9.383152013778686
 learning_rate  : 6.045274678287313e-06
 n_samples      : 864000
 n_steps        : 13500
 ActivityNet_val1_test/t2v_metrics/R1: 20.154565792149686
 ActivityNet_val1_test/t2v_metrics/R5: 51.169412243237744
 ActivityNet_val1_test/t2v_metrics/R10: 66.76835468781778
 ActivityNet_val1_test/t2v_metrics/R50: 90.01423632296115
 ActivityNet_val1_test/t2v_metrics/MedR: 5.0
 ActivityNet_val1_test/t2v_metrics/MeanR: 31.12100874516982
 ActivityNet_val1_test/t2v_metrics/geometric_mean_R1-R5-R10: 40.98750818203581
 ActivityNet_val1_test/v2t_metrics/R1: 20.96806996135855
 ActivityNet_val1_test/v2t_metrics/R5: 51.82021557860484
 ActivityNet_val1_test/v2t_metrics/R10: 67.94793573317064
 ActivityNet_val1_test/v2t_metrics/R50: 90.50233882448647
 ActivityNet_val1_test/v2t_metrics/MedR: 5.0
 ActivityNet_val1_test/v2t_metrics/MeanR: 29.332926581248728
 ActivityNet_val1_test/v2t_metrics/geometric_mean_R1-R5-R10: 41.951224958647536
 mnt_best       : 41.251529009943695
 not_improved_count: 4
Train Epoch: 28 [1/500 64/32000 (0%)] Loss: 0.04329 (QuantReg: 9.41817) QuantErr: 9.41817 batch_time=24.48102 
Train Epoch: 28 [9/500 576/32000 (2%)] Loss: 0.02809 (QuantReg: 9.41124) QuantErr: 9.41124 batch_time=0.44407 
Train Epoch: 28 [17/500 1088/32000 (3%)] Loss: 0.03078 (QuantReg: 9.11340) QuantErr: 9.11340 batch_time=0.43401 
Train Epoch: 28 [25/500 1600/32000 (5%)] Loss: 0.07849 (QuantReg: 9.16319) QuantErr: 9.16319 batch_time=0.44373 
Train Epoch: 28 [33/500 2112/32000 (7%)] Loss: 0.02110 (QuantReg: 9.25263) QuantErr: 9.25263 batch_time=0.44512 
Train Epoch: 28 [41/500 2624/32000 (8%)] Loss: 0.06975 (QuantReg: 9.22658) QuantErr: 9.22658 batch_time=0.44313 
Train Epoch: 28 [49/500 3136/32000 (10%)] Loss: 0.03898 (QuantReg: 9.20604) QuantErr: 9.20604 batch_time=0.44405 
Train Epoch: 28 [57/500 3648/32000 (11%)] Loss: 0.03643 (QuantReg: 9.36666) QuantErr: 9.36666 batch_time=0.51185 
Train Epoch: 28 [65/500 4160/32000 (13%)] Loss: 0.03806 (QuantReg: 9.50017) QuantErr: 9.50017 batch_time=0.44620 
Train Epoch: 28 [73/500 4672/32000 (15%)] Loss: 0.03214 (QuantReg: 9.49094) QuantErr: 9.49094 batch_time=0.44243 
Train Epoch: 28 [81/500 5184/32000 (16%)] Loss: 0.04485 (QuantReg: 9.41974) QuantErr: 9.41974 batch_time=0.45052 
Train Epoch: 28 [89/500 5696/32000 (18%)] Loss: 0.09599 (QuantReg: 9.36787) QuantErr: 9.36787 batch_time=0.44388 
Train Epoch: 28 [97/500 6208/32000 (19%)] Loss: 0.05215 (QuantReg: 9.20353) QuantErr: 9.20353 batch_time=0.45542 
Train Epoch: 28 [105/500 6720/32000 (21%)] Loss: 0.02717 (QuantReg: 9.15659) QuantErr: 9.15659 batch_time=0.43999 
Train Epoch: 28 [113/500 7232/32000 (23%)] Loss: 0.03822 (QuantReg: 9.41918) QuantErr: 9.41918 batch_time=0.44451 
Train Epoch: 28 [121/500 7744/32000 (24%)] Loss: 0.06246 (QuantReg: 9.39788) QuantErr: 9.39788 batch_time=0.47264 
Train Epoch: 28 [129/500 8256/32000 (26%)] Loss: 0.02735 (QuantReg: 9.51568) QuantErr: 9.51568 batch_time=0.45000 
Train Epoch: 28 [137/500 8768/32000 (27%)] Loss: 0.04056 (QuantReg: 9.37503) QuantErr: 9.37503 batch_time=0.43883 
Train Epoch: 28 [145/500 9280/32000 (29%)] Loss: 0.03787 (QuantReg: 9.10349) QuantErr: 9.10349 batch_time=0.44150 
Train Epoch: 28 [153/500 9792/32000 (31%)] Loss: 0.01916 (QuantReg: 9.52696) QuantErr: 9.52696 batch_time=0.44063 
Train Epoch: 28 [161/500 10304/32000 (32%)] Loss: 0.02758 (QuantReg: 9.43316) QuantErr: 9.43316 batch_time=0.43843 
Train Epoch: 28 [169/500 10816/32000 (34%)] Loss: 0.07395 (QuantReg: 9.54334) QuantErr: 9.54334 batch_time=0.45593 
Train Epoch: 28 [177/500 11328/32000 (35%)] Loss: 0.02805 (QuantReg: 9.27245) QuantErr: 9.27245 batch_time=0.44335 
Train Epoch: 28 [185/500 11840/32000 (37%)] Loss: 0.05996 (QuantReg: 9.22579) QuantErr: 9.22579 batch_time=0.47999 
Train Epoch: 28 [193/500 12352/32000 (39%)] Loss: 0.04003 (QuantReg: 9.28335) QuantErr: 9.28335 batch_time=0.46001 
Train Epoch: 28 [201/500 12864/32000 (40%)] Loss: 0.05345 (QuantReg: 9.33712) QuantErr: 9.33712 batch_time=0.45011 
Train Epoch: 28 [209/500 13376/32000 (42%)] Loss: 0.02428 (QuantReg: 9.38847) QuantErr: 9.38847 batch_time=0.45105 
Train Epoch: 28 [217/500 13888/32000 (43%)] Loss: 0.02865 (QuantReg: 9.32100) QuantErr: 9.32100 batch_time=0.44181 
Train Epoch: 28 [225/500 14400/32000 (45%)] Loss: 0.03036 (QuantReg: 9.33669) QuantErr: 9.33669 batch_time=0.44316 
Train Epoch: 28 [233/500 14912/32000 (47%)] Loss: 0.02182 (QuantReg: 9.26818) QuantErr: 9.26818 batch_time=0.44497 
Train Epoch: 28 [241/500 15424/32000 (48%)] Loss: 0.02235 (QuantReg: 9.31899) QuantErr: 9.31899 batch_time=0.45355 
Train Epoch: 28 [249/500 15936/32000 (50%)] Loss: 0.06450 (QuantReg: 9.36129) QuantErr: 9.36129 batch_time=0.49456 
Train Epoch: 28 [257/500 16448/32000 (51%)] Loss: 0.06018 (QuantReg: 9.18761) QuantErr: 9.18761 batch_time=0.44059 
Train Epoch: 28 [265/500 16960/32000 (53%)] Loss: 0.06933 (QuantReg: 9.47333) QuantErr: 9.47333 batch_time=0.70170 
Train Epoch: 28 [273/500 17472/32000 (55%)] Loss: 0.01563 (QuantReg: 9.31353) QuantErr: 9.31353 batch_time=0.43925 
Train Epoch: 28 [281/500 17984/32000 (56%)] Loss: 0.03418 (QuantReg: 9.21729) QuantErr: 9.21729 batch_time=0.44179 
Train Epoch: 28 [289/500 18496/32000 (58%)] Loss: 0.03352 (QuantReg: 9.34985) QuantErr: 9.34985 batch_time=0.46451 
Train Epoch: 28 [297/500 19008/32000 (59%)] Loss: 0.02616 (QuantReg: 9.46393) QuantErr: 9.46393 batch_time=0.44369 
Train Epoch: 28 [305/500 19520/32000 (61%)] Loss: 0.04628 (QuantReg: 9.01335) QuantErr: 9.01335 batch_time=0.44716 
Train Epoch: 28 [313/500 20032/32000 (63%)] Loss: 0.09092 (QuantReg: 9.18443) QuantErr: 9.18443 batch_time=0.47497 
Train Epoch: 28 [321/500 20544/32000 (64%)] Loss: 0.02584 (QuantReg: 9.42329) QuantErr: 9.42329 batch_time=0.44079 
Train Epoch: 28 [329/500 21056/32000 (66%)] Loss: 0.02626 (QuantReg: 9.41357) QuantErr: 9.41357 batch_time=0.44279 
Train Epoch: 28 [337/500 21568/32000 (67%)] Loss: 0.06402 (QuantReg: 9.16658) QuantErr: 9.16658 batch_time=0.44327 
Train Epoch: 28 [345/500 22080/32000 (69%)] Loss: 0.02692 (QuantReg: 9.39228) QuantErr: 9.39228 batch_time=0.44965 
Train Epoch: 28 [353/500 22592/32000 (71%)] Loss: 0.07457 (QuantReg: 9.07671) QuantErr: 9.07671 batch_time=0.44179 
Train Epoch: 28 [361/500 23104/32000 (72%)] Loss: 0.07427 (QuantReg: 9.54017) QuantErr: 9.54017 batch_time=0.45028 
Train Epoch: 28 [369/500 23616/32000 (74%)] Loss: 0.01948 (QuantReg: 9.50114) QuantErr: 9.50114 batch_time=0.44444 
Train Epoch: 28 [377/500 24128/32000 (75%)] Loss: 0.02556 (QuantReg: 9.47640) QuantErr: 9.47640 batch_time=0.48108 
Train Epoch: 28 [385/500 24640/32000 (77%)] Loss: 0.04549 (QuantReg: 9.08442) QuantErr: 9.08442 batch_time=0.44505 
Train Epoch: 28 [393/500 25152/32000 (79%)] Loss: 0.08426 (QuantReg: 9.35082) QuantErr: 9.35082 batch_time=0.43526 
Train Epoch: 28 [401/500 25664/32000 (80%)] Loss: 0.02098 (QuantReg: 9.25195) QuantErr: 9.25195 batch_time=0.44269 
Train Epoch: 28 [409/500 26176/32000 (82%)] Loss: 0.02697 (QuantReg: 9.32573) QuantErr: 9.32573 batch_time=0.43940 
Train Epoch: 28 [417/500 26688/32000 (83%)] Loss: 0.02262 (QuantReg: 9.15270) QuantErr: 9.15270 batch_time=0.45058 
Train Epoch: 28 [425/500 27200/32000 (85%)] Loss: 0.02278 (QuantReg: 9.35877) QuantErr: 9.35877 batch_time=0.45085 
Train Epoch: 28 [433/500 27712/32000 (87%)] Loss: 0.04711 (QuantReg: 9.36408) QuantErr: 9.36408 batch_time=0.44495 
Train Epoch: 28 [441/500 28224/32000 (88%)] Loss: 0.07650 (QuantReg: 9.42234) QuantErr: 9.42234 batch_time=0.48804 
Train Epoch: 28 [449/500 28736/32000 (90%)] Loss: 0.05889 (QuantReg: 9.42555) QuantErr: 9.42555 batch_time=0.44337 
Train Epoch: 28 [457/500 29248/32000 (91%)] Loss: 0.01891 (QuantReg: 9.40093) QuantErr: 9.40093 batch_time=0.44259 
Train Epoch: 28 [465/500 29760/32000 (93%)] Loss: 0.08873 (QuantReg: 9.42901) QuantErr: 9.42901 batch_time=0.43944 
Train Epoch: 28 [473/500 30272/32000 (95%)] Loss: 0.01942 (QuantReg: 9.29344) QuantErr: 9.29344 batch_time=0.44948 
Train Epoch: 28 [481/500 30784/32000 (96%)] Loss: 0.06616 (QuantReg: 9.23021) QuantErr: 9.23021 batch_time=0.44484 
Train Epoch: 28 [489/500 31296/32000 (98%)] Loss: 0.03606 (QuantReg: 9.37270) QuantErr: 9.37270 batch_time=0.45205 
Train Epoch: 28 [497/500 31808/32000 (99%)] Loss: 0.13316 (QuantReg: 9.35519) QuantErr: 9.35519 batch_time=0.44463 
Train Epoch: 28 codebook_update_time=1.66638
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_ActivityNet_bs64/checkpoint-epoch28.pth ...
Done in 23.271s
removing stale ckpt [epoch 27] [took 0.01s]
 epoch          : 28
 loss           : 0.04221298444643617
 quant_reg      : 9.326606462478638
 quant_err      : 9.326606462478638
 learning_rate  : 6.045274678287313e-06
 n_samples      : 896000
 n_steps        : 14000
 ActivityNet_val1_test/t2v_metrics/R1: 20.500305064063454
 ActivityNet_val1_test/t2v_metrics/R5: 50.86434817978442
 ActivityNet_val1_test/t2v_metrics/R10: 66.84970510473866
 ActivityNet_val1_test/t2v_metrics/R50: 90.29896278218426
 ActivityNet_val1_test/t2v_metrics/MedR: 5.0
 ActivityNet_val1_test/t2v_metrics/MeanR: 30.667683546878177
 ActivityNet_val1_test/t2v_metrics/geometric_mean_R1-R5-R10: 41.155173257808556
 ActivityNet_val1_test/v2t_metrics/R1: 20.70368110636567
 ActivityNet_val1_test/v2t_metrics/R5: 51.57616432784218
 ActivityNet_val1_test/v2t_metrics/R10: 67.56152125279642
 ActivityNet_val1_test/v2t_metrics/R50: 90.38031319910515
 ActivityNet_val1_test/v2t_metrics/MedR: 5.0
 ActivityNet_val1_test/v2t_metrics/MeanR: 28.934716290420987
 ActivityNet_val1_test/v2t_metrics/geometric_mean_R1-R5-R10: 41.62925864497163
 mnt_best       : 41.251529009943695
 not_improved_count: 5
Train Epoch: 29 [1/500 64/32000 (0%)] Loss: 0.01868 (QuantReg: 9.30645) QuantErr: 9.30645 batch_time=23.71957 
Train Epoch: 29 [9/500 576/32000 (2%)] Loss: 0.07183 (QuantReg: 9.49521) QuantErr: 9.49521 batch_time=0.44229 
Train Epoch: 29 [17/500 1088/32000 (3%)] Loss: 0.03329 (QuantReg: 9.17064) QuantErr: 9.17064 batch_time=0.86802 
Train Epoch: 29 [25/500 1600/32000 (5%)] Loss: 0.02600 (QuantReg: 9.42608) QuantErr: 9.42608 batch_time=0.43981 
Train Epoch: 29 [33/500 2112/32000 (7%)] Loss: 0.02060 (QuantReg: 9.22391) QuantErr: 9.22391 batch_time=0.44246 
Train Epoch: 29 [41/500 2624/32000 (8%)] Loss: 0.09031 (QuantReg: 9.18622) QuantErr: 9.18622 batch_time=0.44978 
Train Epoch: 29 [49/500 3136/32000 (10%)] Loss: 0.02474 (QuantReg: 9.23857) QuantErr: 9.23857 batch_time=0.44568 
Train Epoch: 29 [57/500 3648/32000 (11%)] Loss: 0.03135 (QuantReg: 9.24881) QuantErr: 9.24881 batch_time=0.57697 
Train Epoch: 29 [65/500 4160/32000 (13%)] Loss: 0.11187 (QuantReg: 9.34259) QuantErr: 9.34259 batch_time=0.53291 
Train Epoch: 29 [73/500 4672/32000 (15%)] Loss: 0.03418 (QuantReg: 9.40721) QuantErr: 9.40721 batch_time=0.44068 
Train Epoch: 29 [81/500 5184/32000 (16%)] Loss: 0.01930 (QuantReg: 9.15129) QuantErr: 9.15129 batch_time=0.88251 
Train Epoch: 29 [89/500 5696/32000 (18%)] Loss: 0.02116 (QuantReg: 9.24539) QuantErr: 9.24539 batch_time=0.46901 
Train Epoch: 29 [97/500 6208/32000 (19%)] Loss: 0.03238 (QuantReg: 9.29806) QuantErr: 9.29806 batch_time=0.46993 
Train Epoch: 29 [105/500 6720/32000 (21%)] Loss: 0.05029 (QuantReg: 8.97790) QuantErr: 8.97790 batch_time=0.44392 
Train Epoch: 29 [113/500 7232/32000 (23%)] Loss: 0.03030 (QuantReg: 9.06217) QuantErr: 9.06217 batch_time=0.44426 
Train Epoch: 29 [121/500 7744/32000 (24%)] Loss: 0.04573 (QuantReg: 9.24881) QuantErr: 9.24881 batch_time=0.54671 
Train Epoch: 29 [129/500 8256/32000 (26%)] Loss: 0.05184 (QuantReg: 9.15750) QuantErr: 9.15750 batch_time=0.53743 
Train Epoch: 29 [137/500 8768/32000 (27%)] Loss: 0.02281 (QuantReg: 9.19531) QuantErr: 9.19531 batch_time=0.43815 
Train Epoch: 29 [145/500 9280/32000 (29%)] Loss: 0.01955 (QuantReg: 9.28501) QuantErr: 9.28501 batch_time=0.91061 
Train Epoch: 29 [153/500 9792/32000 (31%)] Loss: 0.03433 (QuantReg: 9.27855) QuantErr: 9.27855 batch_time=0.44400 
Train Epoch: 29 [161/500 10304/32000 (32%)] Loss: 0.03501 (QuantReg: 9.37392) QuantErr: 9.37392 batch_time=0.44224 
Train Epoch: 29 [169/500 10816/32000 (34%)] Loss: 0.03912 (QuantReg: 9.40086) QuantErr: 9.40086 batch_time=0.44279 
Train Epoch: 29 [177/500 11328/32000 (35%)] Loss: 0.02597 (QuantReg: 9.28901) QuantErr: 9.28901 batch_time=0.43974 
Train Epoch: 29 [185/500 11840/32000 (37%)] Loss: 0.03184 (QuantReg: 9.24293) QuantErr: 9.24293 batch_time=0.54225 
Train Epoch: 29 [193/500 12352/32000 (39%)] Loss: 0.04593 (QuantReg: 9.31610) QuantErr: 9.31610 batch_time=0.53983 
Train Epoch: 29 [201/500 12864/32000 (40%)] Loss: 0.02724 (QuantReg: 9.19065) QuantErr: 9.19065 batch_time=0.43473 
Train Epoch: 29 [209/500 13376/32000 (42%)] Loss: 0.04267 (QuantReg: 9.27719) QuantErr: 9.27719 batch_time=0.44743 
Train Epoch: 29 [217/500 13888/32000 (43%)] Loss: 0.04837 (QuantReg: 9.25496) QuantErr: 9.25496 batch_time=0.44959 
Train Epoch: 29 [225/500 14400/32000 (45%)] Loss: 0.02915 (QuantReg: 9.39617) QuantErr: 9.39617 batch_time=0.44519 
Train Epoch: 29 [233/500 14912/32000 (47%)] Loss: 0.03211 (QuantReg: 9.22087) QuantErr: 9.22087 batch_time=0.44337 
Train Epoch: 29 [241/500 15424/32000 (48%)] Loss: 0.03830 (QuantReg: 9.07280) QuantErr: 9.07280 batch_time=0.44472 
Train Epoch: 29 [249/500 15936/32000 (50%)] Loss: 0.08277 (QuantReg: 9.15178) QuantErr: 9.15178 batch_time=0.57828 
Train Epoch: 29 [257/500 16448/32000 (51%)] Loss: 0.02914 (QuantReg: 9.24831) QuantErr: 9.24831 batch_time=0.55136 
Train Epoch: 29 [265/500 16960/32000 (53%)] Loss: 0.02441 (QuantReg: 9.22037) QuantErr: 9.22037 batch_time=0.44146 
Train Epoch: 29 [273/500 17472/32000 (55%)] Loss: 0.08743 (QuantReg: 9.27657) QuantErr: 9.27657 batch_time=0.43937 
Train Epoch: 29 [281/500 17984/32000 (56%)] Loss: 0.03719 (QuantReg: 9.11417) QuantErr: 9.11417 batch_time=0.44074 
Train Epoch: 29 [289/500 18496/32000 (58%)] Loss: 0.11551 (QuantReg: 9.32121) QuantErr: 9.32121 batch_time=0.44316 
Train Epoch: 29 [297/500 19008/32000 (59%)] Loss: 0.01965 (QuantReg: 9.30944) QuantErr: 9.30944 batch_time=0.44212 
Train Epoch: 29 [305/500 19520/32000 (61%)] Loss: 0.03475 (QuantReg: 9.20253) QuantErr: 9.20253 batch_time=0.43459 
Train Epoch: 29 [313/500 20032/32000 (63%)] Loss: 0.02996 (QuantReg: 9.07607) QuantErr: 9.07607 batch_time=0.56573 
Train Epoch: 29 [321/500 20544/32000 (64%)] Loss: 0.03886 (QuantReg: 9.37571) QuantErr: 9.37571 batch_time=0.56448 
Train Epoch: 29 [329/500 21056/32000 (66%)] Loss: 0.06016 (QuantReg: 9.14090) QuantErr: 9.14090 batch_time=0.46907 
Train Epoch: 29 [337/500 21568/32000 (67%)] Loss: 0.02976 (QuantReg: 9.23654) QuantErr: 9.23654 batch_time=0.46773 
Train Epoch: 29 [345/500 22080/32000 (69%)] Loss: 0.06928 (QuantReg: 9.04013) QuantErr: 9.04013 batch_time=0.65925 
Train Epoch: 29 [353/500 22592/32000 (71%)] Loss: 0.04097 (QuantReg: 9.37158) QuantErr: 9.37158 batch_time=0.47440 
Train Epoch: 29 [361/500 23104/32000 (72%)] Loss: 0.01885 (QuantReg: 9.27008) QuantErr: 9.27008 batch_time=0.44361 
Train Epoch: 29 [369/500 23616/32000 (74%)] Loss: 0.03415 (QuantReg: 9.33847) QuantErr: 9.33847 batch_time=0.44127 
Train Epoch: 29 [377/500 24128/32000 (75%)] Loss: 0.05493 (QuantReg: 9.04517) QuantErr: 9.04517 batch_time=0.60099 
Train Epoch: 29 [385/500 24640/32000 (77%)] Loss: 0.02633 (QuantReg: 9.40012) QuantErr: 9.40012 batch_time=0.53876 
Train Epoch: 29 [393/500 25152/32000 (79%)] Loss: 0.02130 (QuantReg: 9.27535) QuantErr: 9.27535 batch_time=0.44013 
Train Epoch: 29 [401/500 25664/32000 (80%)] Loss: 0.01976 (QuantReg: 9.06445) QuantErr: 9.06445 batch_time=0.44771 
Train Epoch: 29 [409/500 26176/32000 (82%)] Loss: 0.01478 (QuantReg: 9.21867) QuantErr: 9.21867 batch_time=0.45310 
Train Epoch: 29 [417/500 26688/32000 (83%)] Loss: 0.02836 (QuantReg: 9.43271) QuantErr: 9.43271 batch_time=0.45289 
Train Epoch: 29 [425/500 27200/32000 (85%)] Loss: 0.03304 (QuantReg: 9.22292) QuantErr: 9.22292 batch_time=0.45170 
Train Epoch: 29 [433/500 27712/32000 (87%)] Loss: 0.03122 (QuantReg: 9.36632) QuantErr: 9.36632 batch_time=0.44846 
Train Epoch: 29 [441/500 28224/32000 (88%)] Loss: 0.02551 (QuantReg: 9.32190) QuantErr: 9.32190 batch_time=0.57982 
Train Epoch: 29 [449/500 28736/32000 (90%)] Loss: 0.05989 (QuantReg: 9.27953) QuantErr: 9.27953 batch_time=0.54560 
Train Epoch: 29 [457/500 29248/32000 (91%)] Loss: 0.03182 (QuantReg: 9.31841) QuantErr: 9.31841 batch_time=0.44337 
Train Epoch: 29 [465/500 29760/32000 (93%)] Loss: 0.05746 (QuantReg: 9.25247) QuantErr: 9.25247 batch_time=0.44190 
Train Epoch: 29 [473/500 30272/32000 (95%)] Loss: 0.06142 (QuantReg: 9.12818) QuantErr: 9.12818 batch_time=0.44222 
Train Epoch: 29 [481/500 30784/32000 (96%)] Loss: 0.01826 (QuantReg: 9.32226) QuantErr: 9.32226 batch_time=0.45157 
Train Epoch: 29 [489/500 31296/32000 (98%)] Loss: 0.05015 (QuantReg: 9.18783) QuantErr: 9.18783 batch_time=0.48036 
Train Epoch: 29 [497/500 31808/32000 (99%)] Loss: 0.03291 (QuantReg: 9.30312) QuantErr: 9.30312 batch_time=0.48344 
Train Epoch: 29 codebook_update_time=1.79221
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_ActivityNet_bs64/checkpoint-epoch29.pth ...
Done in 5.067s
removing stale ckpt [epoch 28] [took 0.00s]
 epoch          : 29
 loss           : 0.04086174067109823
 quant_reg      : 9.25413324546814
 quant_err      : 9.25413324546814
 learning_rate  : 5.138483476544216e-06
 n_samples      : 928000
 n_steps        : 14500
 ActivityNet_val1_test/t2v_metrics/R1: 19.625788082163922
 ActivityNet_val1_test/t2v_metrics/R5: 50.76266015863331
 ActivityNet_val1_test/t2v_metrics/R10: 66.09721374822045
 ActivityNet_val1_test/t2v_metrics/R50: 89.52613382143583
 ActivityNet_val1_test/t2v_metrics/MedR: 5.0
 ActivityNet_val1_test/t2v_metrics/MeanR: 33.47813707545251
 ActivityNet_val1_test/t2v_metrics/geometric_mean_R1-R5-R10: 40.381725921511894
 ActivityNet_val1_test/v2t_metrics/R1: 20.33760423022168
 ActivityNet_val1_test/v2t_metrics/R5: 51.65751474476307
 ActivityNet_val1_test/v2t_metrics/R10: 67.43949562741508
 ActivityNet_val1_test/v2t_metrics/R50: 90.09558673988204
 ActivityNet_val1_test/v2t_metrics/MedR: 5.0
 ActivityNet_val1_test/v2t_metrics/MeanR: 30.380109823062842
 ActivityNet_val1_test/v2t_metrics/geometric_mean_R1-R5-R10: 41.37924267053132
 mnt_best       : 41.251529009943695
 not_improved_count: 6
Train Epoch: 30 [1/500 64/32000 (0%)] Loss: 0.01888 (QuantReg: 9.29462) QuantErr: 9.29462 batch_time=23.30461 
Train Epoch: 30 [9/500 576/32000 (2%)] Loss: 0.02600 (QuantReg: 9.18068) QuantErr: 9.18068 batch_time=0.51644 
Train Epoch: 30 [17/500 1088/32000 (3%)] Loss: 0.02900 (QuantReg: 9.23656) QuantErr: 9.23656 batch_time=0.44200 
Train Epoch: 30 [25/500 1600/32000 (5%)] Loss: 0.07436 (QuantReg: 9.14721) QuantErr: 9.14721 batch_time=0.43343 
Train Epoch: 30 [33/500 2112/32000 (7%)] Loss: 0.03936 (QuantReg: 9.24399) QuantErr: 9.24399 batch_time=0.43610 
Train Epoch: 30 [41/500 2624/32000 (8%)] Loss: 0.02649 (QuantReg: 9.21143) QuantErr: 9.21143 batch_time=0.43940 
Train Epoch: 30 [49/500 3136/32000 (10%)] Loss: 0.02841 (QuantReg: 9.13965) QuantErr: 9.13965 batch_time=0.46004 
Train Epoch: 30 [57/500 3648/32000 (11%)] Loss: 0.09341 (QuantReg: 9.37928) QuantErr: 9.37928 batch_time=0.45081 
Train Epoch: 30 [65/500 4160/32000 (13%)] Loss: 0.08679 (QuantReg: 9.39436) QuantErr: 9.39436 batch_time=0.47758 
Train Epoch: 30 [73/500 4672/32000 (15%)] Loss: 0.02954 (QuantReg: 9.18908) QuantErr: 9.18908 batch_time=0.44294 
Train Epoch: 30 [81/500 5184/32000 (16%)] Loss: 0.02846 (QuantReg: 9.33012) QuantErr: 9.33012 batch_time=0.49211 
Train Epoch: 30 [89/500 5696/32000 (18%)] Loss: 0.02601 (QuantReg: 9.18131) QuantErr: 9.18131 batch_time=0.48328 
Train Epoch: 30 [97/500 6208/32000 (19%)] Loss: 0.02048 (QuantReg: 9.31826) QuantErr: 9.31826 batch_time=0.44084 
Train Epoch: 30 [105/500 6720/32000 (21%)] Loss: 0.02400 (QuantReg: 9.27864) QuantErr: 9.27864 batch_time=0.44357 
Train Epoch: 30 [113/500 7232/32000 (23%)] Loss: 0.03976 (QuantReg: 9.25208) QuantErr: 9.25208 batch_time=0.44167 
Train Epoch: 30 [121/500 7744/32000 (24%)] Loss: 0.03509 (QuantReg: 9.19027) QuantErr: 9.19027 batch_time=0.44762 
Train Epoch: 30 [129/500 8256/32000 (26%)] Loss: 0.03093 (QuantReg: 9.27637) QuantErr: 9.27637 batch_time=0.48127 
Train Epoch: 30 [137/500 8768/32000 (27%)] Loss: 0.03618 (QuantReg: 9.23184) QuantErr: 9.23184 batch_time=0.44698 
Train Epoch: 30 [145/500 9280/32000 (29%)] Loss: 0.03232 (QuantReg: 9.20324) QuantErr: 9.20324 batch_time=0.44453 
Train Epoch: 30 [153/500 9792/32000 (31%)] Loss: 0.03209 (QuantReg: 9.22199) QuantErr: 9.22199 batch_time=0.45110 
Train Epoch: 30 [161/500 10304/32000 (32%)] Loss: 0.05192 (QuantReg: 9.30947) QuantErr: 9.30947 batch_time=0.44649 
Train Epoch: 30 [169/500 10816/32000 (34%)] Loss: 0.03091 (QuantReg: 9.07186) QuantErr: 9.07186 batch_time=0.46027 
Train Epoch: 30 [177/500 11328/32000 (35%)] Loss: 0.03385 (QuantReg: 9.36465) QuantErr: 9.36465 batch_time=0.44373 
Train Epoch: 30 [185/500 11840/32000 (37%)] Loss: 0.04237 (QuantReg: 9.26534) QuantErr: 9.26534 batch_time=0.45039 
Train Epoch: 30 [193/500 12352/32000 (39%)] Loss: 0.03071 (QuantReg: 9.28043) QuantErr: 9.28043 batch_time=0.47510 
Train Epoch: 30 [201/500 12864/32000 (40%)] Loss: 0.07197 (QuantReg: 8.94313) QuantErr: 8.94313 batch_time=0.44414 
Train Epoch: 30 [209/500 13376/32000 (42%)] Loss: 0.03126 (QuantReg: 9.17346) QuantErr: 9.17346 batch_time=0.46166 
Train Epoch: 30 [217/500 13888/32000 (43%)] Loss: 0.02789 (QuantReg: 9.11283) QuantErr: 9.11283 batch_time=0.44982 
Train Epoch: 30 [225/500 14400/32000 (45%)] Loss: 0.03401 (QuantReg: 9.01591) QuantErr: 9.01591 batch_time=0.44515 
Train Epoch: 30 [233/500 14912/32000 (47%)] Loss: 0.02046 (QuantReg: 9.13070) QuantErr: 9.13070 batch_time=0.44858 
Train Epoch: 30 [241/500 15424/32000 (48%)] Loss: 0.01737 (QuantReg: 9.28892) QuantErr: 9.28892 batch_time=0.47543 
Train Epoch: 30 [249/500 15936/32000 (50%)] Loss: 0.05058 (QuantReg: 9.41388) QuantErr: 9.41388 batch_time=0.44938 
Train Epoch: 30 [257/500 16448/32000 (51%)] Loss: 0.04795 (QuantReg: 9.08471) QuantErr: 9.08471 batch_time=0.48106 
Train Epoch: 30 [265/500 16960/32000 (53%)] Loss: 0.03705 (QuantReg: 9.16805) QuantErr: 9.16805 batch_time=0.44315 
Train Epoch: 30 [273/500 17472/32000 (55%)] Loss: 0.03593 (QuantReg: 9.28175) QuantErr: 9.28175 batch_time=0.44934 
Train Epoch: 30 [281/500 17984/32000 (56%)] Loss: 0.02828 (QuantReg: 9.36926) QuantErr: 9.36926 batch_time=0.44362 
Train Epoch: 30 [289/500 18496/32000 (58%)] Loss: 0.01873 (QuantReg: 9.19540) QuantErr: 9.19540 batch_time=0.45472 
Train Epoch: 30 [297/500 19008/32000 (59%)] Loss: 0.06286 (QuantReg: 9.20558) QuantErr: 9.20558 batch_time=0.45126 
Train Epoch: 30 [305/500 19520/32000 (61%)] Loss: 0.03874 (QuantReg: 9.20796) QuantErr: 9.20796 batch_time=0.44573 
Train Epoch: 30 [313/500 20032/32000 (63%)] Loss: 0.03338 (QuantReg: 9.16827) QuantErr: 9.16827 batch_time=0.45515 
Train Epoch: 30 [321/500 20544/32000 (64%)] Loss: 0.02247 (QuantReg: 9.19702) QuantErr: 9.19702 batch_time=0.48239 
Train Epoch: 30 [329/500 21056/32000 (66%)] Loss: 0.02342 (QuantReg: 9.20528) QuantErr: 9.20528 batch_time=0.44684 
Train Epoch: 30 [337/500 21568/32000 (67%)] Loss: 0.08202 (QuantReg: 9.09144) QuantErr: 9.09144 batch_time=0.45523 
Train Epoch: 30 [345/500 22080/32000 (69%)] Loss: 0.02129 (QuantReg: 9.05356) QuantErr: 9.05356 batch_time=0.45183 
Train Epoch: 30 [353/500 22592/32000 (71%)] Loss: 0.02258 (QuantReg: 9.34321) QuantErr: 9.34321 batch_time=0.45039 
Train Epoch: 30 [361/500 23104/32000 (72%)] Loss: 0.02499 (QuantReg: 9.08493) QuantErr: 9.08493 batch_time=0.44384 
Train Epoch: 30 [369/500 23616/32000 (74%)] Loss: 0.03103 (QuantReg: 9.12165) QuantErr: 9.12165 batch_time=0.44572 
Train Epoch: 30 [377/500 24128/32000 (75%)] Loss: 0.06428 (QuantReg: 8.91022) QuantErr: 8.91022 batch_time=0.45062 
Train Epoch: 30 [385/500 24640/32000 (77%)] Loss: 0.03612 (QuantReg: 9.09262) QuantErr: 9.09262 batch_time=0.48176 
Train Epoch: 30 [393/500 25152/32000 (79%)] Loss: 0.07662 (QuantReg: 9.42110) QuantErr: 9.42110 batch_time=0.45168 
Train Epoch: 30 [401/500 25664/32000 (80%)] Loss: 0.01818 (QuantReg: 9.43506) QuantErr: 9.43506 batch_time=0.44640 
Train Epoch: 30 [409/500 26176/32000 (82%)] Loss: 0.03008 (QuantReg: 9.34379) QuantErr: 9.34379 batch_time=0.47020 
Train Epoch: 30 [417/500 26688/32000 (83%)] Loss: 0.02389 (QuantReg: 8.99455) QuantErr: 8.99455 batch_time=0.43947 
Train Epoch: 30 [425/500 27200/32000 (85%)] Loss: 0.02201 (QuantReg: 9.12878) QuantErr: 9.12878 batch_time=0.43808 
Train Epoch: 30 [433/500 27712/32000 (87%)] Loss: 0.02706 (QuantReg: 9.10004) QuantErr: 9.10004 batch_time=0.44261 
Train Epoch: 30 [441/500 28224/32000 (88%)] Loss: 0.03584 (QuantReg: 9.28461) QuantErr: 9.28461 batch_time=0.44903 
Train Epoch: 30 [449/500 28736/32000 (90%)] Loss: 0.05214 (QuantReg: 9.27247) QuantErr: 9.27247 batch_time=0.48029 
Train Epoch: 30 [457/500 29248/32000 (91%)] Loss: 0.02176 (QuantReg: 9.18999) QuantErr: 9.18999 batch_time=0.44693 
Train Epoch: 30 [465/500 29760/32000 (93%)] Loss: 0.03066 (QuantReg: 9.18966) QuantErr: 9.18966 batch_time=0.44777 
Train Epoch: 30 [473/500 30272/32000 (95%)] Loss: 0.01550 (QuantReg: 9.19422) QuantErr: 9.19422 batch_time=0.45866 
Train Epoch: 30 [481/500 30784/32000 (96%)] Loss: 0.03427 (QuantReg: 9.12527) QuantErr: 9.12527 batch_time=0.45153 
Train Epoch: 30 [489/500 31296/32000 (98%)] Loss: 0.02082 (QuantReg: 9.04660) QuantErr: 9.04660 batch_time=0.47501 
Train Epoch: 30 [497/500 31808/32000 (99%)] Loss: 0.03430 (QuantReg: 9.11939) QuantErr: 9.11939 batch_time=0.44307 
Train Epoch: 30 codebook_update_time=1.71634
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_ActivityNet_bs64/checkpoint-epoch30.pth ...
Done in 4.352s
removing stale ckpt [epoch 29] [took 0.01s]
 epoch          : 30
 loss           : 0.04182535557635129
 quant_reg      : 9.204248615264893
 quant_err      : 9.204248615264893
 learning_rate  : 5.138483476544216e-06
 n_samples      : 960000
 n_steps        : 15000
 ActivityNet_val1_test/t2v_metrics/R1: 20.418954647142566
 ActivityNet_val1_test/t2v_metrics/R5: 51.14907463900752
 ActivityNet_val1_test/t2v_metrics/R10: 66.60565385397601
 ActivityNet_val1_test/t2v_metrics/R50: 89.79052267642872
 ActivityNet_val1_test/t2v_metrics/MedR: 5.0
 ActivityNet_val1_test/t2v_metrics/MeanR: 31.996949359365466
 ActivityNet_val1_test/t2v_metrics/geometric_mean_R1-R5-R10: 41.12704066389859
 ActivityNet_val1_test/v2t_metrics/R1: 20.866381940207443
 ActivityNet_val1_test/v2t_metrics/R5: 51.57616432784218
 ActivityNet_val1_test/v2t_metrics/R10: 67.84624771201952
 ActivityNet_val1_test/v2t_metrics/R50: 90.17693715680294
 ActivityNet_val1_test/v2t_metrics/MedR: 5.0
 ActivityNet_val1_test/v2t_metrics/MeanR: 29.992068334350215
 ActivityNet_val1_test/v2t_metrics/geometric_mean_R1-R5-R10: 41.796573124325455
 mnt_best       : 41.251529009943695
 not_improved_count: 7
Train Epoch: 31 [1/500 64/32000 (0%)] Loss: 0.01923 (QuantReg: 9.11837) QuantErr: 9.11837 batch_time=23.35329 
Train Epoch: 31 [9/500 576/32000 (2%)] Loss: 0.02327 (QuantReg: 9.10669) QuantErr: 9.10669 batch_time=0.48002 
Train Epoch: 31 [17/500 1088/32000 (3%)] Loss: 0.04514 (QuantReg: 9.12870) QuantErr: 9.12870 batch_time=0.55686 
Train Epoch: 31 [25/500 1600/32000 (5%)] Loss: 0.03099 (QuantReg: 9.09914) QuantErr: 9.09914 batch_time=0.44359 
Train Epoch: 31 [33/500 2112/32000 (7%)] Loss: 0.06316 (QuantReg: 8.95293) QuantErr: 8.95293 batch_time=0.49307 
Train Epoch: 31 [41/500 2624/32000 (8%)] Loss: 0.02681 (QuantReg: 9.20978) QuantErr: 9.20978 batch_time=0.57970 
Train Epoch: 31 [49/500 3136/32000 (10%)] Loss: 0.07519 (QuantReg: 9.06835) QuantErr: 9.06835 batch_time=0.48144 
Train Epoch: 31 [57/500 3648/32000 (11%)] Loss: 0.03427 (QuantReg: 9.17997) QuantErr: 9.17997 batch_time=0.54238 
Train Epoch: 31 [65/500 4160/32000 (13%)] Loss: 0.02557 (QuantReg: 9.04894) QuantErr: 9.04894 batch_time=0.44020 
Train Epoch: 31 [73/500 4672/32000 (15%)] Loss: 0.03592 (QuantReg: 9.18878) QuantErr: 9.18878 batch_time=0.46988 
Train Epoch: 31 [81/500 5184/32000 (16%)] Loss: 0.02492 (QuantReg: 9.10987) QuantErr: 9.10987 batch_time=0.53527 
Train Epoch: 31 [89/500 5696/32000 (18%)] Loss: 0.07187 (QuantReg: 9.13381) QuantErr: 9.13381 batch_time=0.43864 
Train Epoch: 31 [97/500 6208/32000 (19%)] Loss: 0.11050 (QuantReg: 9.05166) QuantErr: 9.05166 batch_time=0.43806 
Train Epoch: 31 [105/500 6720/32000 (21%)] Loss: 0.02658 (QuantReg: 9.20058) QuantErr: 9.20058 batch_time=0.60263 
Train Epoch: 31 [113/500 7232/32000 (23%)] Loss: 0.07518 (QuantReg: 9.13224) QuantErr: 9.13224 batch_time=0.47796 
Train Epoch: 31 [121/500 7744/32000 (24%)] Loss: 0.03337 (QuantReg: 9.15656) QuantErr: 9.15656 batch_time=0.54027 
Train Epoch: 31 [129/500 8256/32000 (26%)] Loss: 0.02146 (QuantReg: 9.02519) QuantErr: 9.02519 batch_time=0.43700 
Train Epoch: 31 [137/500 8768/32000 (27%)] Loss: 0.02057 (QuantReg: 9.21584) QuantErr: 9.21584 batch_time=0.47740 
Train Epoch: 31 [145/500 9280/32000 (29%)] Loss: 0.02187 (QuantReg: 9.09265) QuantErr: 9.09265 batch_time=0.54408 
Train Epoch: 31 [153/500 9792/32000 (31%)] Loss: 0.07462 (QuantReg: 9.03412) QuantErr: 9.03412 batch_time=0.44372 
Train Epoch: 31 [161/500 10304/32000 (32%)] Loss: 0.03878 (QuantReg: 9.25137) QuantErr: 9.25137 batch_time=0.44004 
Train Epoch: 31 [169/500 10816/32000 (34%)] Loss: 0.02427 (QuantReg: 9.41898) QuantErr: 9.41898 batch_time=0.64523 
Train Epoch: 31 [177/500 11328/32000 (35%)] Loss: 0.08494 (QuantReg: 9.11617) QuantErr: 9.11617 batch_time=0.52071 
Train Epoch: 31 [185/500 11840/32000 (37%)] Loss: 0.02678 (QuantReg: 9.12814) QuantErr: 9.12814 batch_time=0.54529 
Train Epoch: 31 [193/500 12352/32000 (39%)] Loss: 0.03896 (QuantReg: 9.21233) QuantErr: 9.21233 batch_time=0.46052 
Train Epoch: 31 [201/500 12864/32000 (40%)] Loss: 0.02907 (QuantReg: 9.10433) QuantErr: 9.10433 batch_time=0.52183 
Train Epoch: 31 [209/500 13376/32000 (42%)] Loss: 0.02945 (QuantReg: 9.17982) QuantErr: 9.17982 batch_time=0.54053 
Train Epoch: 31 [217/500 13888/32000 (43%)] Loss: 0.03213 (QuantReg: 9.06171) QuantErr: 9.06171 batch_time=0.44155 
Train Epoch: 31 [225/500 14400/32000 (45%)] Loss: 0.04050 (QuantReg: 8.98217) QuantErr: 8.98217 batch_time=0.44137 
Train Epoch: 31 [233/500 14912/32000 (47%)] Loss: 0.04296 (QuantReg: 9.35033) QuantErr: 9.35033 batch_time=0.57077 
Train Epoch: 31 [241/500 15424/32000 (48%)] Loss: 0.02894 (QuantReg: 9.30713) QuantErr: 9.30713 batch_time=0.47017 
Train Epoch: 31 [249/500 15936/32000 (50%)] Loss: 0.02559 (QuantReg: 9.12394) QuantErr: 9.12394 batch_time=0.53409 
Train Epoch: 31 [257/500 16448/32000 (51%)] Loss: 0.02305 (QuantReg: 9.12313) QuantErr: 9.12313 batch_time=0.44980 
Train Epoch: 31 [265/500 16960/32000 (53%)] Loss: 0.07031 (QuantReg: 9.08451) QuantErr: 9.08451 batch_time=0.47525 
Train Epoch: 31 [273/500 17472/32000 (55%)] Loss: 0.03788 (QuantReg: 9.18303) QuantErr: 9.18303 batch_time=0.54077 
Train Epoch: 31 [281/500 17984/32000 (56%)] Loss: 0.02796 (QuantReg: 9.22911) QuantErr: 9.22911 batch_time=0.44458 
Train Epoch: 31 [289/500 18496/32000 (58%)] Loss: 0.04336 (QuantReg: 9.05342) QuantErr: 9.05342 batch_time=0.44248 
Train Epoch: 31 [297/500 19008/32000 (59%)] Loss: 0.11376 (QuantReg: 9.12498) QuantErr: 9.12498 batch_time=0.56522 
Train Epoch: 31 [305/500 19520/32000 (61%)] Loss: 0.02702 (QuantReg: 9.08795) QuantErr: 9.08795 batch_time=0.47623 
Train Epoch: 31 [313/500 20032/32000 (63%)] Loss: 0.01642 (QuantReg: 9.29040) QuantErr: 9.29040 batch_time=0.54110 
Train Epoch: 31 [321/500 20544/32000 (64%)] Loss: 0.06858 (QuantReg: 9.13612) QuantErr: 9.13612 batch_time=0.44768 
Train Epoch: 31 [329/500 21056/32000 (66%)] Loss: 0.04580 (QuantReg: 9.15678) QuantErr: 9.15678 batch_time=0.47700 
Train Epoch: 31 [337/500 21568/32000 (67%)] Loss: 0.02106 (QuantReg: 9.32088) QuantErr: 9.32088 batch_time=0.53980 
Train Epoch: 31 [345/500 22080/32000 (69%)] Loss: 0.03414 (QuantReg: 9.03831) QuantErr: 9.03831 batch_time=0.45343 
Train Epoch: 31 [353/500 22592/32000 (71%)] Loss: 0.02137 (QuantReg: 9.13765) QuantErr: 9.13765 batch_time=0.44432 
Train Epoch: 31 [361/500 23104/32000 (72%)] Loss: 0.03851 (QuantReg: 9.18514) QuantErr: 9.18514 batch_time=0.58065 
Train Epoch: 31 [369/500 23616/32000 (74%)] Loss: 0.08060 (QuantReg: 8.83959) QuantErr: 8.83959 batch_time=0.47235 
Train Epoch: 31 [377/500 24128/32000 (75%)] Loss: 0.09277 (QuantReg: 9.07482) QuantErr: 9.07482 batch_time=0.54020 
Train Epoch: 31 [385/500 24640/32000 (77%)] Loss: 0.02062 (QuantReg: 9.09855) QuantErr: 9.09855 batch_time=0.47455 
Train Epoch: 31 [393/500 25152/32000 (79%)] Loss: 0.02524 (QuantReg: 9.06714) QuantErr: 9.06714 batch_time=0.50376 
Train Epoch: 31 [401/500 25664/32000 (80%)] Loss: 0.02176 (QuantReg: 8.89928) QuantErr: 8.89928 batch_time=0.56972 
Train Epoch: 31 [409/500 26176/32000 (82%)] Loss: 0.04151 (QuantReg: 9.09476) QuantErr: 9.09476 batch_time=0.44582 
Train Epoch: 31 [417/500 26688/32000 (83%)] Loss: 0.04113 (QuantReg: 9.21457) QuantErr: 9.21457 batch_time=0.44214 
Train Epoch: 31 [425/500 27200/32000 (85%)] Loss: 0.04692 (QuantReg: 9.02708) QuantErr: 9.02708 batch_time=0.57521 
Train Epoch: 31 [433/500 27712/32000 (87%)] Loss: 0.02274 (QuantReg: 9.17707) QuantErr: 9.17707 batch_time=0.47460 
Train Epoch: 31 [441/500 28224/32000 (88%)] Loss: 0.03614 (QuantReg: 8.91538) QuantErr: 8.91538 batch_time=0.54337 
Train Epoch: 31 [449/500 28736/32000 (90%)] Loss: 0.02470 (QuantReg: 8.97629) QuantErr: 8.97629 batch_time=0.44187 
Train Epoch: 31 [457/500 29248/32000 (91%)] Loss: 0.01688 (QuantReg: 9.01375) QuantErr: 9.01375 batch_time=0.47783 
Train Epoch: 31 [465/500 29760/32000 (93%)] Loss: 0.02722 (QuantReg: 8.88139) QuantErr: 8.88139 batch_time=0.54023 
Train Epoch: 31 [473/500 30272/32000 (95%)] Loss: 0.05212 (QuantReg: 9.16371) QuantErr: 9.16371 batch_time=0.45102 
Train Epoch: 31 [481/500 30784/32000 (96%)] Loss: 0.02734 (QuantReg: 9.07783) QuantErr: 9.07783 batch_time=0.44619 
Train Epoch: 31 [489/500 31296/32000 (98%)] Loss: 0.03034 (QuantReg: 8.93811) QuantErr: 8.93811 batch_time=0.57388 
Train Epoch: 31 [497/500 31808/32000 (99%)] Loss: 0.02984 (QuantReg: 8.97050) QuantErr: 8.97050 batch_time=0.48179 
Train Epoch: 31 codebook_update_time=1.94755
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_ActivityNet_bs64/checkpoint-epoch31.pth ...
Done in 4.783s
removing stale ckpt [epoch 30] [took 0.00s]
 epoch          : 31
 loss           : 0.039136748317629096
 quant_reg      : 9.121144884109498
 quant_err      : 9.121144884109498
 learning_rate  : 4.367710955062584e-06
 n_samples      : 992000
 n_steps        : 15500
 ActivityNet_val1_test/t2v_metrics/R1: 20.33760423022168
 ActivityNet_val1_test/t2v_metrics/R5: 51.04738661785642
 ActivityNet_val1_test/t2v_metrics/R10: 66.64632906243645
 ActivityNet_val1_test/t2v_metrics/R50: 89.66849705104738
 ActivityNet_val1_test/t2v_metrics/MedR: 5.0
 ActivityNet_val1_test/t2v_metrics/MeanR: 32.3213341468375
 ActivityNet_val1_test/t2v_metrics/geometric_mean_R1-R5-R10: 41.05346761039418
 ActivityNet_val1_test/v2t_metrics/R1: 21.04942037827944
 ActivityNet_val1_test/v2t_metrics/R5: 51.92190359975595
 ActivityNet_val1_test/v2t_metrics/R10: 67.72422208663819
 ActivityNet_val1_test/v2t_metrics/R50: 90.21761236526338
 ActivityNet_val1_test/v2t_metrics/MedR: 5.0
 ActivityNet_val1_test/v2t_metrics/MeanR: 30.055216595485053
 ActivityNet_val1_test/v2t_metrics/geometric_mean_R1-R5-R10: 41.98668540601656
 mnt_best       : 41.251529009943695
 not_improved_count: 8
Train Epoch: 32 [1/500 64/32000 (0%)] Loss: 0.12616 (QuantReg: 8.90060) QuantErr: 8.90060 batch_time=24.01675 
Train Epoch: 32 [9/500 576/32000 (2%)] Loss: 0.01919 (QuantReg: 8.98014) QuantErr: 8.98014 batch_time=0.45163 
Train Epoch: 32 [17/500 1088/32000 (3%)] Loss: 0.03258 (QuantReg: 9.03910) QuantErr: 9.03910 batch_time=0.70331 
Train Epoch: 32 [25/500 1600/32000 (5%)] Loss: 0.01919 (QuantReg: 9.01996) QuantErr: 9.01996 batch_time=0.94439 
Train Epoch: 32 [33/500 2112/32000 (7%)] Loss: 0.03981 (QuantReg: 9.01263) QuantErr: 9.01263 batch_time=0.70096 
Train Epoch: 32 [41/500 2624/32000 (8%)] Loss: 0.07097 (QuantReg: 8.99644) QuantErr: 8.99644 batch_time=0.44114 
Train Epoch: 32 [49/500 3136/32000 (10%)] Loss: 0.02752 (QuantReg: 9.07605) QuantErr: 9.07605 batch_time=0.45164 
Train Epoch: 32 [57/500 3648/32000 (11%)] Loss: 0.02869 (QuantReg: 9.02451) QuantErr: 9.02451 batch_time=0.44191 
Train Epoch: 32 [65/500 4160/32000 (13%)] Loss: 0.03438 (QuantReg: 9.14679) QuantErr: 9.14679 batch_time=0.46625 
Train Epoch: 32 [73/500 4672/32000 (15%)] Loss: 0.04433 (QuantReg: 9.21634) QuantErr: 9.21634 batch_time=0.44264 
Train Epoch: 32 [81/500 5184/32000 (16%)] Loss: 0.08668 (QuantReg: 9.02954) QuantErr: 9.02954 batch_time=0.69665 
Train Epoch: 32 [89/500 5696/32000 (18%)] Loss: 0.04571 (QuantReg: 9.02228) QuantErr: 9.02228 batch_time=0.87363 
Train Epoch: 32 [97/500 6208/32000 (19%)] Loss: 0.06603 (QuantReg: 9.04010) QuantErr: 9.04010 batch_time=0.72823 
Train Epoch: 32 [105/500 6720/32000 (21%)] Loss: 0.04502 (QuantReg: 8.95108) QuantErr: 8.95108 batch_time=0.45320 
Train Epoch: 32 [113/500 7232/32000 (23%)] Loss: 0.03842 (QuantReg: 8.99648) QuantErr: 8.99648 batch_time=0.44525 
Train Epoch: 32 [121/500 7744/32000 (24%)] Loss: 0.02775 (QuantReg: 9.01312) QuantErr: 9.01312 batch_time=0.44382 
Train Epoch: 32 [129/500 8256/32000 (26%)] Loss: 0.06641 (QuantReg: 9.06499) QuantErr: 9.06499 batch_time=0.47988 
Train Epoch: 32 [137/500 8768/32000 (27%)] Loss: 0.07101 (QuantReg: 9.08466) QuantErr: 9.08466 batch_time=0.44236 
Train Epoch: 32 [145/500 9280/32000 (29%)] Loss: 0.06490 (QuantReg: 8.94865) QuantErr: 8.94865 batch_time=0.69601 
Train Epoch: 32 [153/500 9792/32000 (31%)] Loss: 0.03697 (QuantReg: 9.01923) QuantErr: 9.01923 batch_time=0.84058 
Train Epoch: 32 [161/500 10304/32000 (32%)] Loss: 0.02628 (QuantReg: 8.90920) QuantErr: 8.90920 batch_time=0.68992 
Train Epoch: 32 [169/500 10816/32000 (34%)] Loss: 0.05948 (QuantReg: 9.08936) QuantErr: 9.08936 batch_time=0.45188 
Train Epoch: 32 [177/500 11328/32000 (35%)] Loss: 0.03550 (QuantReg: 8.97537) QuantErr: 8.97537 batch_time=0.44067 
Train Epoch: 32 [185/500 11840/32000 (37%)] Loss: 0.01537 (QuantReg: 9.05948) QuantErr: 9.05948 batch_time=0.43744 
Train Epoch: 32 [193/500 12352/32000 (39%)] Loss: 0.04072 (QuantReg: 9.08842) QuantErr: 9.08842 batch_time=0.46932 
Train Epoch: 32 [201/500 12864/32000 (40%)] Loss: 0.07288 (QuantReg: 9.11225) QuantErr: 9.11225 batch_time=0.43929 
Train Epoch: 32 [209/500 13376/32000 (42%)] Loss: 0.02292 (QuantReg: 9.05087) QuantErr: 9.05087 batch_time=0.68534 
Train Epoch: 32 [217/500 13888/32000 (43%)] Loss: 0.01870 (QuantReg: 9.08222) QuantErr: 9.08222 batch_time=0.84078 
Train Epoch: 32 [225/500 14400/32000 (45%)] Loss: 0.09020 (QuantReg: 9.10280) QuantErr: 9.10280 batch_time=0.75115 
Train Epoch: 32 [233/500 14912/32000 (47%)] Loss: 0.03170 (QuantReg: 8.98265) QuantErr: 8.98265 batch_time=0.44117 
Train Epoch: 32 [241/500 15424/32000 (48%)] Loss: 0.03131 (QuantReg: 9.27711) QuantErr: 9.27711 batch_time=0.45115 
Train Epoch: 32 [249/500 15936/32000 (50%)] Loss: 0.02410 (QuantReg: 9.19191) QuantErr: 9.19191 batch_time=0.45596 
Train Epoch: 32 [257/500 16448/32000 (51%)] Loss: 0.02346 (QuantReg: 9.17146) QuantErr: 9.17146 batch_time=0.48669 
Train Epoch: 32 [265/500 16960/32000 (53%)] Loss: 0.03149 (QuantReg: 9.11428) QuantErr: 9.11428 batch_time=0.45024 
Train Epoch: 32 [273/500 17472/32000 (55%)] Loss: 0.03610 (QuantReg: 8.91034) QuantErr: 8.91034 batch_time=0.71375 
Train Epoch: 32 [281/500 17984/32000 (56%)] Loss: 0.06126 (QuantReg: 9.18032) QuantErr: 9.18032 batch_time=0.84458 
Train Epoch: 32 [289/500 18496/32000 (58%)] Loss: 0.03129 (QuantReg: 9.15413) QuantErr: 9.15413 batch_time=0.69265 
Train Epoch: 32 [297/500 19008/32000 (59%)] Loss: 0.04670 (QuantReg: 9.17346) QuantErr: 9.17346 batch_time=0.45054 
Train Epoch: 32 [305/500 19520/32000 (61%)] Loss: 0.02762 (QuantReg: 8.94988) QuantErr: 8.94988 batch_time=0.45372 
Train Epoch: 32 [313/500 20032/32000 (63%)] Loss: 0.02521 (QuantReg: 9.08752) QuantErr: 9.08752 batch_time=0.44549 
Train Epoch: 32 [321/500 20544/32000 (64%)] Loss: 0.06798 (QuantReg: 8.96952) QuantErr: 8.96952 batch_time=0.47625 
Train Epoch: 32 [329/500 21056/32000 (66%)] Loss: 0.03615 (QuantReg: 9.17586) QuantErr: 9.17586 batch_time=0.44089 
Train Epoch: 32 [337/500 21568/32000 (67%)] Loss: 0.03332 (QuantReg: 9.03636) QuantErr: 9.03636 batch_time=0.69120 
Train Epoch: 32 [345/500 22080/32000 (69%)] Loss: 0.06489 (QuantReg: 8.98934) QuantErr: 8.98934 batch_time=0.84235 
Train Epoch: 32 [353/500 22592/32000 (71%)] Loss: 0.01598 (QuantReg: 8.96877) QuantErr: 8.96877 batch_time=0.69682 
Train Epoch: 32 [361/500 23104/32000 (72%)] Loss: 0.02976 (QuantReg: 9.00028) QuantErr: 9.00028 batch_time=0.44444 
Train Epoch: 32 [369/500 23616/32000 (74%)] Loss: 0.02951 (QuantReg: 9.04766) QuantErr: 9.04766 batch_time=0.44284 
Train Epoch: 32 [377/500 24128/32000 (75%)] Loss: 0.06185 (QuantReg: 9.23238) QuantErr: 9.23238 batch_time=0.44225 
Train Epoch: 32 [385/500 24640/32000 (77%)] Loss: 0.04189 (QuantReg: 8.79974) QuantErr: 8.79974 batch_time=0.48427 
Train Epoch: 32 [393/500 25152/32000 (79%)] Loss: 0.02565 (QuantReg: 9.19218) QuantErr: 9.19218 batch_time=0.44308 
Train Epoch: 32 [401/500 25664/32000 (80%)] Loss: 0.02490 (QuantReg: 9.04922) QuantErr: 9.04922 batch_time=0.69813 
Train Epoch: 32 [409/500 26176/32000 (82%)] Loss: 0.07321 (QuantReg: 9.13789) QuantErr: 9.13789 batch_time=0.84462 
Train Epoch: 32 [417/500 26688/32000 (83%)] Loss: 0.03426 (QuantReg: 9.09608) QuantErr: 9.09608 batch_time=0.68127 
Train Epoch: 32 [425/500 27200/32000 (85%)] Loss: 0.11194 (QuantReg: 9.03729) QuantErr: 9.03729 batch_time=0.44747 
Train Epoch: 32 [433/500 27712/32000 (87%)] Loss: 0.03071 (QuantReg: 9.08892) QuantErr: 9.08892 batch_time=0.44582 
Train Epoch: 32 [441/500 28224/32000 (88%)] Loss: 0.02568 (QuantReg: 9.02088) QuantErr: 9.02088 batch_time=0.44259 
Train Epoch: 32 [449/500 28736/32000 (90%)] Loss: 0.04384 (QuantReg: 9.04303) QuantErr: 9.04303 batch_time=0.47445 
Train Epoch: 32 [457/500 29248/32000 (91%)] Loss: 0.07614 (QuantReg: 9.06530) QuantErr: 9.06530 batch_time=0.44027 
Train Epoch: 32 [465/500 29760/32000 (93%)] Loss: 0.01729 (QuantReg: 8.91176) QuantErr: 8.91176 batch_time=0.72545 
Train Epoch: 32 [473/500 30272/32000 (95%)] Loss: 0.01870 (QuantReg: 9.00204) QuantErr: 9.00204 batch_time=0.81114 
Train Epoch: 32 [481/500 30784/32000 (96%)] Loss: 0.03917 (QuantReg: 9.02347) QuantErr: 9.02347 batch_time=0.69353 
Train Epoch: 32 [489/500 31296/32000 (98%)] Loss: 0.02726 (QuantReg: 9.08809) QuantErr: 9.08809 batch_time=0.44808 
Train Epoch: 32 [497/500 31808/32000 (99%)] Loss: 0.02202 (QuantReg: 9.25613) QuantErr: 9.25613 batch_time=0.44263 
Train Epoch: 32 codebook_update_time=1.85963
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_ActivityNet_bs64/checkpoint-epoch32.pth ...
Done in 4.930s
removing stale ckpt [epoch 31] [took 0.00s]
 epoch          : 32
 loss           : 0.04006254716217518
 quant_reg      : 9.068337202072144
 quant_err      : 9.068337202072144
 learning_rate  : 4.367710955062584e-06
 n_samples      : 1024000
 n_steps        : 16000
 ActivityNet_val1_test/t2v_metrics/R1: 20.276591417531016
 ActivityNet_val1_test/t2v_metrics/R5: 50.88468578401464
 ActivityNet_val1_test/t2v_metrics/R10: 66.84970510473866
 ActivityNet_val1_test/t2v_metrics/R50: 89.66849705104738
 ActivityNet_val1_test/t2v_metrics/MedR: 5.0
 ActivityNet_val1_test/t2v_metrics/MeanR: 33.06853772625585
 ActivityNet_val1_test/t2v_metrics/geometric_mean_R1-R5-R10: 41.01038511536486
 ActivityNet_val1_test/v2t_metrics/R1: 20.520642668293675
 ActivityNet_val1_test/v2t_metrics/R5: 52.043929225137276
 ActivityNet_val1_test/v2t_metrics/R10: 67.64287166971731
 ActivityNet_val1_test/v2t_metrics/R50: 89.79052267642872
 ActivityNet_val1_test/v2t_metrics/MedR: 5.0
 ActivityNet_val1_test/v2t_metrics/MeanR: 30.65324384787472
 ActivityNet_val1_test/v2t_metrics/geometric_mean_R1-R5-R10: 41.64801981387547
 mnt_best       : 41.251529009943695
 not_improved_count: 9
Train Epoch: 33 [1/500 64/32000 (0%)] Loss: 0.02608 (QuantReg: 9.01312) QuantErr: 9.01312 batch_time=23.52771 
Train Epoch: 33 [9/500 576/32000 (2%)] Loss: 0.04737 (QuantReg: 9.08475) QuantErr: 9.08475 batch_time=0.43955 
Train Epoch: 33 [17/500 1088/32000 (3%)] Loss: 0.03366 (QuantReg: 9.08657) QuantErr: 9.08657 batch_time=0.56645 
Train Epoch: 33 [25/500 1600/32000 (5%)] Loss: 0.02811 (QuantReg: 9.00911) QuantErr: 9.00911 batch_time=0.43582 
Train Epoch: 33 [33/500 2112/32000 (7%)] Loss: 0.02567 (QuantReg: 9.13597) QuantErr: 9.13597 batch_time=0.43511 
Train Epoch: 33 [41/500 2624/32000 (8%)] Loss: 0.03384 (QuantReg: 9.13557) QuantErr: 9.13557 batch_time=0.44439 
Train Epoch: 33 [49/500 3136/32000 (10%)] Loss: 0.02623 (QuantReg: 9.03946) QuantErr: 9.03946 batch_time=0.44502 
Train Epoch: 33 [57/500 3648/32000 (11%)] Loss: 0.02981 (QuantReg: 8.87694) QuantErr: 8.87694 batch_time=0.44611 
Train Epoch: 33 [65/500 4160/32000 (13%)] Loss: 0.06532 (QuantReg: 9.08815) QuantErr: 9.08815 batch_time=0.45785 
Train Epoch: 33 [73/500 4672/32000 (15%)] Loss: 0.06635 (QuantReg: 9.11481) QuantErr: 9.11481 batch_time=0.47891 
Train Epoch: 33 [81/500 5184/32000 (16%)] Loss: 0.03149 (QuantReg: 9.02434) QuantErr: 9.02434 batch_time=0.58326 
Train Epoch: 33 [89/500 5696/32000 (18%)] Loss: 0.08370 (QuantReg: 9.07763) QuantErr: 9.07763 batch_time=0.48749 
Train Epoch: 33 [97/500 6208/32000 (19%)] Loss: 0.10184 (QuantReg: 9.12205) QuantErr: 9.12205 batch_time=0.46051 
Train Epoch: 33 [105/500 6720/32000 (21%)] Loss: 0.04181 (QuantReg: 9.03716) QuantErr: 9.03716 batch_time=0.44262 
Train Epoch: 33 [113/500 7232/32000 (23%)] Loss: 0.03396 (QuantReg: 9.03322) QuantErr: 9.03322 batch_time=0.45021 
Train Epoch: 33 [121/500 7744/32000 (24%)] Loss: 0.04053 (QuantReg: 8.98574) QuantErr: 8.98574 batch_time=0.47657 
Train Epoch: 33 [129/500 8256/32000 (26%)] Loss: 0.02610 (QuantReg: 8.95784) QuantErr: 8.95784 batch_time=0.44395 
Train Epoch: 33 [137/500 8768/32000 (27%)] Loss: 0.02300 (QuantReg: 8.88333) QuantErr: 8.88333 batch_time=0.43756 
Train Epoch: 33 [145/500 9280/32000 (29%)] Loss: 0.03633 (QuantReg: 8.87813) QuantErr: 8.87813 batch_time=0.52825 
Train Epoch: 33 [153/500 9792/32000 (31%)] Loss: 0.03287 (QuantReg: 8.93643) QuantErr: 8.93643 batch_time=0.44636 
Train Epoch: 33 [161/500 10304/32000 (32%)] Loss: 0.02548 (QuantReg: 9.06464) QuantErr: 9.06464 batch_time=0.44675 
Train Epoch: 33 [169/500 10816/32000 (34%)] Loss: 0.02468 (QuantReg: 9.06016) QuantErr: 9.06016 batch_time=0.44750 
Train Epoch: 33 [177/500 11328/32000 (35%)] Loss: 0.02923 (QuantReg: 9.13721) QuantErr: 9.13721 batch_time=0.44991 
Train Epoch: 33 [185/500 11840/32000 (37%)] Loss: 0.02577 (QuantReg: 8.90152) QuantErr: 8.90152 batch_time=0.44476 
Train Epoch: 33 [193/500 12352/32000 (39%)] Loss: 0.03179 (QuantReg: 9.18816) QuantErr: 9.18816 batch_time=0.44649 
Train Epoch: 33 [201/500 12864/32000 (40%)] Loss: 0.03607 (QuantReg: 8.97429) QuantErr: 8.97429 batch_time=0.45457 
Train Epoch: 33 [209/500 13376/32000 (42%)] Loss: 0.11525 (QuantReg: 8.77955) QuantErr: 8.77955 batch_time=0.54907 
Train Epoch: 33 [217/500 13888/32000 (43%)] Loss: 0.06807 (QuantReg: 8.93011) QuantErr: 8.93011 batch_time=0.44317 
Train Epoch: 33 [225/500 14400/32000 (45%)] Loss: 0.02862 (QuantReg: 9.08807) QuantErr: 9.08807 batch_time=0.45512 
Train Epoch: 33 [233/500 14912/32000 (47%)] Loss: 0.03709 (QuantReg: 8.91835) QuantErr: 8.91835 batch_time=0.44440 
Train Epoch: 33 [241/500 15424/32000 (48%)] Loss: 0.02038 (QuantReg: 8.92287) QuantErr: 8.92287 batch_time=0.44972 
Train Epoch: 33 [249/500 15936/32000 (50%)] Loss: 0.01588 (QuantReg: 8.80240) QuantErr: 8.80240 batch_time=0.44164 
Train Epoch: 33 [257/500 16448/32000 (51%)] Loss: 0.02506 (QuantReg: 8.98340) QuantErr: 8.98340 batch_time=0.44312 
Train Epoch: 33 [265/500 16960/32000 (53%)] Loss: 0.02224 (QuantReg: 8.79259) QuantErr: 8.79259 batch_time=0.44220 
Train Epoch: 33 [273/500 17472/32000 (55%)] Loss: 0.06843 (QuantReg: 9.08386) QuantErr: 9.08386 batch_time=0.54035 
Train Epoch: 33 [281/500 17984/32000 (56%)] Loss: 0.02606 (QuantReg: 8.92885) QuantErr: 8.92885 batch_time=0.43858 
Train Epoch: 33 [289/500 18496/32000 (58%)] Loss: 0.04606 (QuantReg: 9.03921) QuantErr: 9.03921 batch_time=0.44041 
Train Epoch: 33 [297/500 19008/32000 (59%)] Loss: 0.10786 (QuantReg: 9.04931) QuantErr: 9.04931 batch_time=0.45667 
Train Epoch: 33 [305/500 19520/32000 (61%)] Loss: 0.12389 (QuantReg: 9.13411) QuantErr: 9.13411 batch_time=0.44558 
Train Epoch: 33 [313/500 20032/32000 (63%)] Loss: 0.02888 (QuantReg: 9.02237) QuantErr: 9.02237 batch_time=0.44467 
Train Epoch: 33 [321/500 20544/32000 (64%)] Loss: 0.01373 (QuantReg: 9.19133) QuantErr: 9.19133 batch_time=0.44597 
Train Epoch: 33 [329/500 21056/32000 (66%)] Loss: 0.07614 (QuantReg: 8.88403) QuantErr: 8.88403 batch_time=0.44911 
Train Epoch: 33 [337/500 21568/32000 (67%)] Loss: 0.03509 (QuantReg: 9.01070) QuantErr: 9.01070 batch_time=0.53414 
Train Epoch: 33 [345/500 22080/32000 (69%)] Loss: 0.02585 (QuantReg: 8.90061) QuantErr: 8.90061 batch_time=0.44435 
Train Epoch: 33 [353/500 22592/32000 (71%)] Loss: 0.04117 (QuantReg: 9.03969) QuantErr: 9.03969 batch_time=0.45144 
Train Epoch: 33 [361/500 23104/32000 (72%)] Loss: 0.07326 (QuantReg: 9.20202) QuantErr: 9.20202 batch_time=0.44364 
Train Epoch: 33 [369/500 23616/32000 (74%)] Loss: 0.02419 (QuantReg: 8.92190) QuantErr: 8.92190 batch_time=0.44500 
Train Epoch: 33 [377/500 24128/32000 (75%)] Loss: 0.05814 (QuantReg: 8.97815) QuantErr: 8.97815 batch_time=0.44991 
Train Epoch: 33 [385/500 24640/32000 (77%)] Loss: 0.03672 (QuantReg: 8.94178) QuantErr: 8.94178 batch_time=0.44797 
Train Epoch: 33 [393/500 25152/32000 (79%)] Loss: 0.01573 (QuantReg: 9.12919) QuantErr: 9.12919 batch_time=0.44335 
Train Epoch: 33 [401/500 25664/32000 (80%)] Loss: 0.02813 (QuantReg: 9.00979) QuantErr: 9.00979 batch_time=0.53706 
Train Epoch: 33 [409/500 26176/32000 (82%)] Loss: 0.02305 (QuantReg: 9.02975) QuantErr: 9.02975 batch_time=0.47434 
Train Epoch: 33 [417/500 26688/32000 (83%)] Loss: 0.02423 (QuantReg: 8.80505) QuantErr: 8.80505 batch_time=0.47832 
Train Epoch: 33 [425/500 27200/32000 (85%)] Loss: 0.02432 (QuantReg: 9.00523) QuantErr: 9.00523 batch_time=0.47972 
Train Epoch: 33 [433/500 27712/32000 (87%)] Loss: 0.15803 (QuantReg: 9.02851) QuantErr: 9.02851 batch_time=0.47489 
Train Epoch: 33 [441/500 28224/32000 (88%)] Loss: 0.02330 (QuantReg: 9.14566) QuantErr: 9.14566 batch_time=0.47706 
Train Epoch: 33 [449/500 28736/32000 (90%)] Loss: 0.02943 (QuantReg: 8.88035) QuantErr: 8.88035 batch_time=0.46292 
Train Epoch: 33 [457/500 29248/32000 (91%)] Loss: 0.01771 (QuantReg: 9.03078) QuantErr: 9.03078 batch_time=0.45181 
Train Epoch: 33 [465/500 29760/32000 (93%)] Loss: 0.02404 (QuantReg: 8.82129) QuantErr: 8.82129 batch_time=0.54346 
Train Epoch: 33 [473/500 30272/32000 (95%)] Loss: 0.07288 (QuantReg: 9.02069) QuantErr: 9.02069 batch_time=0.44874 
Train Epoch: 33 [481/500 30784/32000 (96%)] Loss: 0.02653 (QuantReg: 8.84555) QuantErr: 8.84555 batch_time=0.44873 
Train Epoch: 33 [489/500 31296/32000 (98%)] Loss: 0.02843 (QuantReg: 9.08748) QuantErr: 9.08748 batch_time=0.45025 
Train Epoch: 33 [497/500 31808/32000 (99%)] Loss: 0.02433 (QuantReg: 9.11406) QuantErr: 9.11406 batch_time=0.43929 
Train Epoch: 33 codebook_update_time=1.70170
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_ActivityNet_bs64/checkpoint-epoch33.pth ...
Done in 5.718s
removing stale ckpt [epoch 32] [took 0.01s]
 epoch          : 33
 loss           : 0.040453588850796224
 quant_reg      : 9.003306999206544
 quant_err      : 9.003306999206544
 learning_rate  : 3.712554311803196e-06
 n_samples      : 1056000
 n_steps        : 16500
 ActivityNet_val1_test/t2v_metrics/R1: 20.256253813300795
 ActivityNet_val1_test/t2v_metrics/R5: 50.945698596705306
 ActivityNet_val1_test/t2v_metrics/R10: 66.54464104128533
 ActivityNet_val1_test/t2v_metrics/R50: 89.52613382143583
 ActivityNet_val1_test/t2v_metrics/MedR: 5.0
 ActivityNet_val1_test/t2v_metrics/MeanR: 33.200528777709984
 ActivityNet_val1_test/t2v_metrics/geometric_mean_R1-R5-R10: 40.95056639234073
 ActivityNet_val1_test/v2t_metrics/R1: 20.500305064063454
 ActivityNet_val1_test/v2t_metrics/R5: 52.0642668293675
 ActivityNet_val1_test/v2t_metrics/R10: 68.15131177547285
 ActivityNet_val1_test/v2t_metrics/R50: 89.85153548911939
 ActivityNet_val1_test/v2t_metrics/MedR: 5.0
 ActivityNet_val1_test/v2t_metrics/MeanR: 30.699511897498475
 ActivityNet_val1_test/v2t_metrics/geometric_mean_R1-R5-R10: 41.74374737146933
 mnt_best       : 41.251529009943695
 not_improved_count: 10
Train Epoch: 34 [1/500 64/32000 (0%)] Loss: 0.03596 (QuantReg: 8.95284) QuantErr: 8.95284 batch_time=24.29015 
Train Epoch: 34 [9/500 576/32000 (2%)] Loss: 0.03889 (QuantReg: 9.11819) QuantErr: 9.11819 batch_time=0.49440 
Train Epoch: 34 [17/500 1088/32000 (3%)] Loss: 0.03087 (QuantReg: 8.98196) QuantErr: 8.98196 batch_time=0.54451 
Train Epoch: 34 [25/500 1600/32000 (5%)] Loss: 0.05565 (QuantReg: 9.01452) QuantErr: 9.01452 batch_time=0.44282 
Train Epoch: 34 [33/500 2112/32000 (7%)] Loss: 0.07483 (QuantReg: 8.98872) QuantErr: 8.98872 batch_time=0.44543 
Train Epoch: 34 [41/500 2624/32000 (8%)] Loss: 0.02125 (QuantReg: 8.76582) QuantErr: 8.76582 batch_time=0.44420 
Train Epoch: 34 [49/500 3136/32000 (10%)] Loss: 0.02700 (QuantReg: 9.06821) QuantErr: 9.06821 batch_time=0.44760 
Train Epoch: 34 [57/500 3648/32000 (11%)] Loss: 0.02321 (QuantReg: 9.00743) QuantErr: 9.00743 batch_time=0.44386 
Train Epoch: 34 [65/500 4160/32000 (13%)] Loss: 0.02394 (QuantReg: 8.94203) QuantErr: 8.94203 batch_time=0.48606 
Train Epoch: 34 [73/500 4672/32000 (15%)] Loss: 0.02990 (QuantReg: 8.77573) QuantErr: 8.77573 batch_time=0.44997 
Train Epoch: 34 [81/500 5184/32000 (16%)] Loss: 0.05790 (QuantReg: 8.85552) QuantErr: 8.85552 batch_time=0.56936 
Train Epoch: 34 [89/500 5696/32000 (18%)] Loss: 0.01790 (QuantReg: 8.94322) QuantErr: 8.94322 batch_time=0.44264 
Train Epoch: 34 [97/500 6208/32000 (19%)] Loss: 0.02355 (QuantReg: 9.05120) QuantErr: 9.05120 batch_time=0.44108 
Train Epoch: 34 [105/500 6720/32000 (21%)] Loss: 0.02189 (QuantReg: 8.83404) QuantErr: 8.83404 batch_time=0.43789 
Train Epoch: 34 [113/500 7232/32000 (23%)] Loss: 0.02354 (QuantReg: 9.04518) QuantErr: 9.04518 batch_time=0.43793 
Train Epoch: 34 [121/500 7744/32000 (24%)] Loss: 0.02801 (QuantReg: 8.90463) QuantErr: 8.90463 batch_time=0.43964 
Train Epoch: 34 [129/500 8256/32000 (26%)] Loss: 0.02782 (QuantReg: 9.08661) QuantErr: 9.08661 batch_time=0.47060 
Train Epoch: 34 [137/500 8768/32000 (27%)] Loss: 0.06516 (QuantReg: 9.08148) QuantErr: 9.08148 batch_time=0.43856 
Train Epoch: 34 [145/500 9280/32000 (29%)] Loss: 0.05865 (QuantReg: 9.07857) QuantErr: 9.07857 batch_time=0.54388 
Train Epoch: 34 [153/500 9792/32000 (31%)] Loss: 0.07270 (QuantReg: 8.89562) QuantErr: 8.89562 batch_time=0.44400 
Train Epoch: 34 [161/500 10304/32000 (32%)] Loss: 0.02651 (QuantReg: 9.13086) QuantErr: 9.13086 batch_time=0.44360 
Train Epoch: 34 [169/500 10816/32000 (34%)] Loss: 0.02308 (QuantReg: 9.03184) QuantErr: 9.03184 batch_time=0.44311 
Train Epoch: 34 [177/500 11328/32000 (35%)] Loss: 0.02601 (QuantReg: 9.06471) QuantErr: 9.06471 batch_time=0.44246 
Train Epoch: 34 [185/500 11840/32000 (37%)] Loss: 0.04093 (QuantReg: 8.86591) QuantErr: 8.86591 batch_time=0.44029 
Train Epoch: 34 [193/500 12352/32000 (39%)] Loss: 0.02550 (QuantReg: 8.90936) QuantErr: 8.90936 batch_time=0.47203 
Train Epoch: 34 [201/500 12864/32000 (40%)] Loss: 0.02190 (QuantReg: 8.90398) QuantErr: 8.90398 batch_time=0.44626 
Train Epoch: 34 [209/500 13376/32000 (42%)] Loss: 0.05697 (QuantReg: 8.92251) QuantErr: 8.92251 batch_time=0.55398 
Train Epoch: 34 [217/500 13888/32000 (43%)] Loss: 0.03967 (QuantReg: 8.70351) QuantErr: 8.70351 batch_time=0.44654 
Train Epoch: 34 [225/500 14400/32000 (45%)] Loss: 0.06790 (QuantReg: 8.78035) QuantErr: 8.78035 batch_time=0.44305 
Train Epoch: 34 [233/500 14912/32000 (47%)] Loss: 0.04924 (QuantReg: 8.85882) QuantErr: 8.85882 batch_time=0.44468 
Train Epoch: 34 [241/500 15424/32000 (48%)] Loss: 0.02973 (QuantReg: 8.76364) QuantErr: 8.76364 batch_time=0.44887 
Train Epoch: 34 [249/500 15936/32000 (50%)] Loss: 0.03154 (QuantReg: 8.71514) QuantErr: 8.71514 batch_time=0.44267 
Train Epoch: 34 [257/500 16448/32000 (51%)] Loss: 0.02166 (QuantReg: 8.93242) QuantErr: 8.93242 batch_time=0.48906 
Train Epoch: 34 [265/500 16960/32000 (53%)] Loss: 0.06451 (QuantReg: 8.88251) QuantErr: 8.88251 batch_time=0.43731 
Train Epoch: 34 [273/500 17472/32000 (55%)] Loss: 0.02510 (QuantReg: 8.81991) QuantErr: 8.81991 batch_time=0.53990 
Train Epoch: 34 [281/500 17984/32000 (56%)] Loss: 0.02550 (QuantReg: 8.92317) QuantErr: 8.92317 batch_time=0.44429 
Train Epoch: 34 [289/500 18496/32000 (58%)] Loss: 0.01780 (QuantReg: 8.80378) QuantErr: 8.80378 batch_time=0.44204 
Train Epoch: 34 [297/500 19008/32000 (59%)] Loss: 0.02629 (QuantReg: 8.98367) QuantErr: 8.98367 batch_time=0.48300 
Train Epoch: 34 [305/500 19520/32000 (61%)] Loss: 0.03352 (QuantReg: 9.04484) QuantErr: 9.04484 batch_time=0.44231 
Train Epoch: 34 [313/500 20032/32000 (63%)] Loss: 0.01746 (QuantReg: 8.98853) QuantErr: 8.98853 batch_time=0.44657 
Train Epoch: 34 [321/500 20544/32000 (64%)] Loss: 0.01870 (QuantReg: 8.86283) QuantErr: 8.86283 batch_time=0.48512 
Train Epoch: 34 [329/500 21056/32000 (66%)] Loss: 0.03429 (QuantReg: 8.96170) QuantErr: 8.96170 batch_time=0.46920 
Train Epoch: 34 [337/500 21568/32000 (67%)] Loss: 0.04348 (QuantReg: 9.12290) QuantErr: 9.12290 batch_time=0.55744 
Train Epoch: 34 [345/500 22080/32000 (69%)] Loss: 0.09004 (QuantReg: 9.04018) QuantErr: 9.04018 batch_time=0.46386 
Train Epoch: 34 [353/500 22592/32000 (71%)] Loss: 0.03190 (QuantReg: 8.85375) QuantErr: 8.85375 batch_time=0.43743 
Train Epoch: 34 [361/500 23104/32000 (72%)] Loss: 0.02020 (QuantReg: 9.19564) QuantErr: 9.19564 batch_time=0.45648 
Train Epoch: 34 [369/500 23616/32000 (74%)] Loss: 0.02152 (QuantReg: 8.94617) QuantErr: 8.94617 batch_time=0.44113 
Train Epoch: 34 [377/500 24128/32000 (75%)] Loss: 0.08776 (QuantReg: 9.01351) QuantErr: 9.01351 batch_time=0.43791 
Train Epoch: 34 [385/500 24640/32000 (77%)] Loss: 0.02993 (QuantReg: 8.87818) QuantErr: 8.87818 batch_time=0.48842 
Train Epoch: 34 [393/500 25152/32000 (79%)] Loss: 0.04173 (QuantReg: 9.12440) QuantErr: 9.12440 batch_time=0.45079 
Train Epoch: 34 [401/500 25664/32000 (80%)] Loss: 0.02877 (QuantReg: 8.96365) QuantErr: 8.96365 batch_time=0.45711 
Train Epoch: 34 [409/500 26176/32000 (82%)] Loss: 0.02508 (QuantReg: 9.00749) QuantErr: 9.00749 batch_time=0.45057 
Train Epoch: 34 [417/500 26688/32000 (83%)] Loss: 0.04339 (QuantReg: 8.91097) QuantErr: 8.91097 batch_time=0.44467 
Train Epoch: 34 [425/500 27200/32000 (85%)] Loss: 0.09114 (QuantReg: 8.91992) QuantErr: 8.91992 batch_time=0.44253 
Train Epoch: 34 [433/500 27712/32000 (87%)] Loss: 0.02399 (QuantReg: 8.88886) QuantErr: 8.88886 batch_time=0.45051 
Train Epoch: 34 [441/500 28224/32000 (88%)] Loss: 0.06835 (QuantReg: 8.89093) QuantErr: 8.89093 batch_time=0.44510 
Train Epoch: 34 [449/500 28736/32000 (90%)] Loss: 0.06341 (QuantReg: 8.82266) QuantErr: 8.82266 batch_time=0.44560 
Train Epoch: 34 [457/500 29248/32000 (91%)] Loss: 0.02844 (QuantReg: 9.19446) QuantErr: 9.19446 batch_time=0.44851 
Train Epoch: 34 [465/500 29760/32000 (93%)] Loss: 0.02500 (QuantReg: 8.87217) QuantErr: 8.87217 batch_time=0.44751 
Train Epoch: 34 [473/500 30272/32000 (95%)] Loss: 0.02642 (QuantReg: 8.92051) QuantErr: 8.92051 batch_time=0.43684 
Train Epoch: 34 [481/500 30784/32000 (96%)] Loss: 0.02363 (QuantReg: 8.79572) QuantErr: 8.79572 batch_time=0.44508 
Train Epoch: 34 [489/500 31296/32000 (98%)] Loss: 0.03233 (QuantReg: 8.77058) QuantErr: 8.77058 batch_time=0.44480 
Train Epoch: 34 [497/500 31808/32000 (99%)] Loss: 0.07470 (QuantReg: 9.12385) QuantErr: 9.12385 batch_time=0.44144 
Train Epoch: 34 codebook_update_time=1.87394
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_ActivityNet_bs64/checkpoint-epoch34.pth ...
Done in 3.991s
removing stale ckpt [epoch 33] [took 0.09s]
 epoch          : 34
 loss           : 0.038484198777005076
 quant_reg      : 8.954861640930176
 quant_err      : 8.954861640930176
 learning_rate  : 3.712554311803196e-06
 n_samples      : 1088000
 n_steps        : 17000
 ActivityNet_val1_test/t2v_metrics/R1: 20.58165548098434
 ActivityNet_val1_test/t2v_metrics/R5: 50.986373805165755
 ActivityNet_val1_test/t2v_metrics/R10: 66.38194020744356
 ActivityNet_val1_test/t2v_metrics/R50: 89.52613382143583
 ActivityNet_val1_test/t2v_metrics/MedR: 5.0
 ActivityNet_val1_test/t2v_metrics/MeanR: 33.33699410209477
 ActivityNet_val1_test/t2v_metrics/geometric_mean_R1-R5-R10: 41.14604757388363
 ActivityNet_val1_test/v2t_metrics/R1: 20.622330689444784
 ActivityNet_val1_test/v2t_metrics/R5: 52.104942037827946
 ActivityNet_val1_test/v2t_metrics/R10: 68.15131177547285
 ActivityNet_val1_test/v2t_metrics/R50: 89.89221069757983
 ActivityNet_val1_test/v2t_metrics/MedR: 5.0
 ActivityNet_val1_test/v2t_metrics/MeanR: 31.102298149278013
 ActivityNet_val1_test/v2t_metrics/geometric_mean_R1-R5-R10: 41.837297931795334
 mnt_best       : 41.251529009943695
 not_improved_count: 11
Train Epoch: 35 [1/500 64/32000 (0%)] Loss: 0.01917 (QuantReg: 8.95267) QuantErr: 8.95267 batch_time=23.56189 
Train Epoch: 35 [9/500 576/32000 (2%)] Loss: 0.04147 (QuantReg: 9.00165) QuantErr: 9.00165 batch_time=0.44728 
Train Epoch: 35 [17/500 1088/32000 (3%)] Loss: 0.02227 (QuantReg: 8.80432) QuantErr: 8.80432 batch_time=0.48064 
Train Epoch: 35 [25/500 1600/32000 (5%)] Loss: 0.02561 (QuantReg: 9.00173) QuantErr: 9.00173 batch_time=0.44801 
Train Epoch: 35 [33/500 2112/32000 (7%)] Loss: 0.02550 (QuantReg: 8.91014) QuantErr: 8.91014 batch_time=0.46645 
Train Epoch: 35 [41/500 2624/32000 (8%)] Loss: 0.01779 (QuantReg: 8.87260) QuantErr: 8.87260 batch_time=0.50045 
Train Epoch: 35 [49/500 3136/32000 (10%)] Loss: 0.06872 (QuantReg: 8.95815) QuantErr: 8.95815 batch_time=0.44599 
Train Epoch: 35 [57/500 3648/32000 (11%)] Loss: 0.06982 (QuantReg: 8.86851) QuantErr: 8.86851 batch_time=0.44118 
Train Epoch: 35 [65/500 4160/32000 (13%)] Loss: 0.02251 (QuantReg: 9.06120) QuantErr: 9.06120 batch_time=0.44295 
Train Epoch: 35 [73/500 4672/32000 (15%)] Loss: 0.06372 (QuantReg: 8.84883) QuantErr: 8.84883 batch_time=0.43674 
Train Epoch: 35 [81/500 5184/32000 (16%)] Loss: 0.02498 (QuantReg: 8.96001) QuantErr: 8.96001 batch_time=0.47224 
Train Epoch: 35 [89/500 5696/32000 (18%)] Loss: 0.06378 (QuantReg: 9.03671) QuantErr: 9.03671 batch_time=0.44540 
Train Epoch: 35 [97/500 6208/32000 (19%)] Loss: 0.02449 (QuantReg: 9.01764) QuantErr: 9.01764 batch_time=0.44375 
Train Epoch: 35 [105/500 6720/32000 (21%)] Loss: 0.03647 (QuantReg: 8.85681) QuantErr: 8.85681 batch_time=0.43784 
Train Epoch: 35 [113/500 7232/32000 (23%)] Loss: 0.06737 (QuantReg: 8.82004) QuantErr: 8.82004 batch_time=0.44003 
Train Epoch: 35 [121/500 7744/32000 (24%)] Loss: 0.07207 (QuantReg: 8.91094) QuantErr: 8.91094 batch_time=0.44143 
Train Epoch: 35 [129/500 8256/32000 (26%)] Loss: 0.03676 (QuantReg: 8.82809) QuantErr: 8.82809 batch_time=0.43702 
Train Epoch: 35 [137/500 8768/32000 (27%)] Loss: 0.04050 (QuantReg: 8.89762) QuantErr: 8.89762 batch_time=0.44345 
Train Epoch: 35 [145/500 9280/32000 (29%)] Loss: 0.02837 (QuantReg: 8.98011) QuantErr: 8.98011 batch_time=0.47249 
Train Epoch: 35 [153/500 9792/32000 (31%)] Loss: 0.07438 (QuantReg: 8.98366) QuantErr: 8.98366 batch_time=0.43837 
Train Epoch: 35 [161/500 10304/32000 (32%)] Loss: 0.02488 (QuantReg: 8.79153) QuantErr: 8.79153 batch_time=0.45075 
Train Epoch: 35 [169/500 10816/32000 (34%)] Loss: 0.01864 (QuantReg: 8.99304) QuantErr: 8.99304 batch_time=0.44567 
Train Epoch: 35 [177/500 11328/32000 (35%)] Loss: 0.03344 (QuantReg: 8.80848) QuantErr: 8.80848 batch_time=0.44570 
Train Epoch: 35 [185/500 11840/32000 (37%)] Loss: 0.02353 (QuantReg: 8.89265) QuantErr: 8.89265 batch_time=0.44192 
Train Epoch: 35 [193/500 12352/32000 (39%)] Loss: 0.02688 (QuantReg: 8.91985) QuantErr: 8.91985 batch_time=0.43993 
Train Epoch: 35 [201/500 12864/32000 (40%)] Loss: 0.02048 (QuantReg: 8.82305) QuantErr: 8.82305 batch_time=0.44294 
Train Epoch: 35 [209/500 13376/32000 (42%)] Loss: 0.05438 (QuantReg: 8.91681) QuantErr: 8.91681 batch_time=0.43975 
Train Epoch: 35 [217/500 13888/32000 (43%)] Loss: 0.02933 (QuantReg: 9.11007) QuantErr: 9.11007 batch_time=0.44288 
Train Epoch: 35 [225/500 14400/32000 (45%)] Loss: 0.04510 (QuantReg: 8.98340) QuantErr: 8.98340 batch_time=0.44549 
Train Epoch: 35 [233/500 14912/32000 (47%)] Loss: 0.02239 (QuantReg: 8.88121) QuantErr: 8.88121 batch_time=0.45859 
Train Epoch: 35 [241/500 15424/32000 (48%)] Loss: 0.01995 (QuantReg: 8.95740) QuantErr: 8.95740 batch_time=0.44915 
Train Epoch: 35 [249/500 15936/32000 (50%)] Loss: 0.07263 (QuantReg: 9.00077) QuantErr: 9.00077 batch_time=0.45604 
Train Epoch: 35 [257/500 16448/32000 (51%)] Loss: 0.02974 (QuantReg: 8.84297) QuantErr: 8.84297 batch_time=0.44783 
Train Epoch: 35 [265/500 16960/32000 (53%)] Loss: 0.06681 (QuantReg: 8.91426) QuantErr: 8.91426 batch_time=0.44231 
Train Epoch: 35 [273/500 17472/32000 (55%)] Loss: 0.01964 (QuantReg: 8.95483) QuantErr: 8.95483 batch_time=0.44438 
Train Epoch: 35 [281/500 17984/32000 (56%)] Loss: 0.06620 (QuantReg: 8.93799) QuantErr: 8.93799 batch_time=0.45438 
Train Epoch: 35 [289/500 18496/32000 (58%)] Loss: 0.01899 (QuantReg: 8.70301) QuantErr: 8.70301 batch_time=0.45236 
Train Epoch: 35 [297/500 19008/32000 (59%)] Loss: 0.02189 (QuantReg: 8.91113) QuantErr: 8.91113 batch_time=0.45394 
Train Epoch: 35 [305/500 19520/32000 (61%)] Loss: 0.02522 (QuantReg: 8.88114) QuantErr: 8.88114 batch_time=0.44960 
Train Epoch: 35 [313/500 20032/32000 (63%)] Loss: 0.02116 (QuantReg: 8.92684) QuantErr: 8.92684 batch_time=0.44676 
Train Epoch: 35 [321/500 20544/32000 (64%)] Loss: 0.06628 (QuantReg: 8.81707) QuantErr: 8.81707 batch_time=0.45306 
Train Epoch: 35 [329/500 21056/32000 (66%)] Loss: 0.02627 (QuantReg: 8.85883) QuantErr: 8.85883 batch_time=0.47068 
Train Epoch: 35 [337/500 21568/32000 (67%)] Loss: 0.07216 (QuantReg: 8.80547) QuantErr: 8.80547 batch_time=0.47230 
Train Epoch: 35 [345/500 22080/32000 (69%)] Loss: 0.07453 (QuantReg: 8.91600) QuantErr: 8.91600 batch_time=0.49890 
Train Epoch: 35 [353/500 22592/32000 (71%)] Loss: 0.03677 (QuantReg: 9.01328) QuantErr: 9.01328 batch_time=0.44841 
Train Epoch: 35 [361/500 23104/32000 (72%)] Loss: 0.03198 (QuantReg: 8.88050) QuantErr: 8.88050 batch_time=0.45044 
Train Epoch: 35 [369/500 23616/32000 (74%)] Loss: 0.04136 (QuantReg: 9.04310) QuantErr: 9.04310 batch_time=0.47285 
Train Epoch: 35 [377/500 24128/32000 (75%)] Loss: 0.02688 (QuantReg: 8.68797) QuantErr: 8.68797 batch_time=0.44948 
Train Epoch: 35 [385/500 24640/32000 (77%)] Loss: 0.02251 (QuantReg: 8.94697) QuantErr: 8.94697 batch_time=0.46997 
Train Epoch: 35 [393/500 25152/32000 (79%)] Loss: 0.02358 (QuantReg: 8.92648) QuantErr: 8.92648 batch_time=0.47324 
Train Epoch: 35 [401/500 25664/32000 (80%)] Loss: 0.03378 (QuantReg: 9.11765) QuantErr: 9.11765 batch_time=0.47240 
Train Epoch: 35 [409/500 26176/32000 (82%)] Loss: 0.02093 (QuantReg: 8.90551) QuantErr: 8.90551 batch_time=0.44677 
Train Epoch: 35 [417/500 26688/32000 (83%)] Loss: 0.03884 (QuantReg: 8.86612) QuantErr: 8.86612 batch_time=0.45429 
Train Epoch: 35 [425/500 27200/32000 (85%)] Loss: 0.02987 (QuantReg: 9.08866) QuantErr: 9.08866 batch_time=0.46378 
Train Epoch: 35 [433/500 27712/32000 (87%)] Loss: 0.02341 (QuantReg: 8.89884) QuantErr: 8.89884 batch_time=0.44884 
Train Epoch: 35 [441/500 28224/32000 (88%)] Loss: 0.02594 (QuantReg: 8.95940) QuantErr: 8.95940 batch_time=0.45089 
Train Epoch: 35 [449/500 28736/32000 (90%)] Loss: 0.04362 (QuantReg: 9.08444) QuantErr: 9.08444 batch_time=0.43951 
Train Epoch: 35 [457/500 29248/32000 (91%)] Loss: 0.01884 (QuantReg: 8.92916) QuantErr: 8.92916 batch_time=0.45309 
Train Epoch: 35 [465/500 29760/32000 (93%)] Loss: 0.02458 (QuantReg: 8.89373) QuantErr: 8.89373 batch_time=0.44824 
Train Epoch: 35 [473/500 30272/32000 (95%)] Loss: 0.02253 (QuantReg: 9.01552) QuantErr: 9.01552 batch_time=0.45094 
Train Epoch: 35 [481/500 30784/32000 (96%)] Loss: 0.03229 (QuantReg: 8.91805) QuantErr: 8.91805 batch_time=0.45206 
Train Epoch: 35 [489/500 31296/32000 (98%)] Loss: 0.02067 (QuantReg: 8.95269) QuantErr: 8.95269 batch_time=0.45048 
Train Epoch: 35 [497/500 31808/32000 (99%)] Loss: 0.02816 (QuantReg: 8.80758) QuantErr: 8.80758 batch_time=0.45407 
Train Epoch: 35 codebook_update_time=1.67579
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_ActivityNet_bs64/checkpoint-epoch35.pth ...
Done in 4.125s
removing stale ckpt [epoch 34] [took 0.00s]
 epoch          : 35
 loss           : 0.03835045850649476
 quant_reg      : 8.910557914733888
 quant_err      : 8.910557914733888
 learning_rate  : 3.1556711650327163e-06
 n_samples      : 1120000
 n_steps        : 17500
 ActivityNet_val1_test/t2v_metrics/R1: 20.195241000610128
 ActivityNet_val1_test/t2v_metrics/R5: 51.169412243237744
 ActivityNet_val1_test/t2v_metrics/R10: 66.3209273947529
 ActivityNet_val1_test/t2v_metrics/R50: 89.3024201749034
 ActivityNet_val1_test/t2v_metrics/MedR: 5.0
 ActivityNet_val1_test/t2v_metrics/MeanR: 33.71079926784625
 ActivityNet_val1_test/t2v_metrics/geometric_mean_R1-R5-R10: 40.923240857745085
 ActivityNet_val1_test/v2t_metrics/R1: 20.622330689444784
 ActivityNet_val1_test/v2t_metrics/R5: 51.61683953630262
 ActivityNet_val1_test/v2t_metrics/R10: 67.66320927394753
 ActivityNet_val1_test/v2t_metrics/R50: 89.62782184258694
 ActivityNet_val1_test/v2t_metrics/MedR: 5.0
 ActivityNet_val1_test/v2t_metrics/MeanR: 31.5779947122229
 ActivityNet_val1_test/v2t_metrics/geometric_mean_R1-R5-R10: 41.6064424303465
 mnt_best       : 41.251529009943695
 not_improved_count: 12
Train Epoch: 36 [1/500 64/32000 (0%)] Loss: 0.07952 (QuantReg: 8.94410) QuantErr: 8.94410 batch_time=23.57232 
Train Epoch: 36 [9/500 576/32000 (2%)] Loss: 0.09284 (QuantReg: 8.77147) QuantErr: 8.77147 batch_time=0.44115 
Train Epoch: 36 [17/500 1088/32000 (3%)] Loss: 0.03443 (QuantReg: 9.00332) QuantErr: 9.00332 batch_time=0.43434 
Train Epoch: 36 [25/500 1600/32000 (5%)] Loss: 0.06786 (QuantReg: 9.02945) QuantErr: 9.02945 batch_time=0.47738 
Train Epoch: 36 [33/500 2112/32000 (7%)] Loss: 0.03938 (QuantReg: 8.72280) QuantErr: 8.72280 batch_time=0.44940 
Train Epoch: 36 [41/500 2624/32000 (8%)] Loss: 0.02558 (QuantReg: 8.79379) QuantErr: 8.79379 batch_time=0.44969 
Train Epoch: 36 [49/500 3136/32000 (10%)] Loss: 0.02266 (QuantReg: 9.00834) QuantErr: 9.00834 batch_time=0.44822 
Train Epoch: 36 [57/500 3648/32000 (11%)] Loss: 0.07665 (QuantReg: 8.79639) QuantErr: 8.79639 batch_time=0.44982 
Train Epoch: 36 [65/500 4160/32000 (13%)] Loss: 0.02575 (QuantReg: 8.83865) QuantErr: 8.83865 batch_time=0.44065 
Train Epoch: 36 [73/500 4672/32000 (15%)] Loss: 0.02630 (QuantReg: 8.75676) QuantErr: 8.75676 batch_time=0.44560 
Train Epoch: 36 [81/500 5184/32000 (16%)] Loss: 0.03799 (QuantReg: 8.83562) QuantErr: 8.83562 batch_time=0.44163 
Train Epoch: 36 [89/500 5696/32000 (18%)] Loss: 0.02041 (QuantReg: 8.93891) QuantErr: 8.93891 batch_time=0.43915 
Train Epoch: 36 [97/500 6208/32000 (19%)] Loss: 0.06784 (QuantReg: 8.81209) QuantErr: 8.81209 batch_time=0.45431 
Train Epoch: 36 [105/500 6720/32000 (21%)] Loss: 0.02032 (QuantReg: 8.95399) QuantErr: 8.95399 batch_time=0.44328 
Train Epoch: 36 [113/500 7232/32000 (23%)] Loss: 0.01846 (QuantReg: 8.97673) QuantErr: 8.97673 batch_time=0.47240 
Train Epoch: 36 [121/500 7744/32000 (24%)] Loss: 0.03143 (QuantReg: 8.94210) QuantErr: 8.94210 batch_time=0.47812 
Train Epoch: 36 [129/500 8256/32000 (26%)] Loss: 0.02945 (QuantReg: 9.05570) QuantErr: 9.05570 batch_time=0.46971 
Train Epoch: 36 [137/500 8768/32000 (27%)] Loss: 0.07235 (QuantReg: 8.98956) QuantErr: 8.98956 batch_time=0.48243 
Train Epoch: 36 [145/500 9280/32000 (29%)] Loss: 0.02493 (QuantReg: 8.82501) QuantErr: 8.82501 batch_time=0.44793 
Train Epoch: 36 [153/500 9792/32000 (31%)] Loss: 0.02302 (QuantReg: 8.90339) QuantErr: 8.90339 batch_time=0.44406 
Train Epoch: 36 [161/500 10304/32000 (32%)] Loss: 0.03345 (QuantReg: 8.92550) QuantErr: 8.92550 batch_time=0.44856 
Train Epoch: 36 [169/500 10816/32000 (34%)] Loss: 0.01965 (QuantReg: 8.82429) QuantErr: 8.82429 batch_time=0.50355 
Train Epoch: 36 [177/500 11328/32000 (35%)] Loss: 0.02809 (QuantReg: 9.01569) QuantErr: 9.01569 batch_time=0.44609 
Train Epoch: 36 [185/500 11840/32000 (37%)] Loss: 0.02110 (QuantReg: 8.91054) QuantErr: 8.91054 batch_time=0.44798 
Train Epoch: 36 [193/500 12352/32000 (39%)] Loss: 0.07297 (QuantReg: 8.89065) QuantErr: 8.89065 batch_time=0.44894 
Train Epoch: 36 [201/500 12864/32000 (40%)] Loss: 0.06569 (QuantReg: 8.89890) QuantErr: 8.89890 batch_time=0.46037 
Train Epoch: 36 [209/500 13376/32000 (42%)] Loss: 0.05148 (QuantReg: 8.87709) QuantErr: 8.87709 batch_time=0.46031 
Train Epoch: 36 [217/500 13888/32000 (43%)] Loss: 0.03501 (QuantReg: 8.81906) QuantErr: 8.81906 batch_time=0.43941 
Train Epoch: 36 [225/500 14400/32000 (45%)] Loss: 0.01698 (QuantReg: 8.83257) QuantErr: 8.83257 batch_time=0.44180 
Train Epoch: 36 [233/500 14912/32000 (47%)] Loss: 0.02387 (QuantReg: 8.93926) QuantErr: 8.93926 batch_time=0.44192 
Train Epoch: 36 [241/500 15424/32000 (48%)] Loss: 0.03442 (QuantReg: 8.86738) QuantErr: 8.86738 batch_time=0.44730 
Train Epoch: 36 [249/500 15936/32000 (50%)] Loss: 0.02102 (QuantReg: 8.90839) QuantErr: 8.90839 batch_time=0.46430 
Train Epoch: 36 [257/500 16448/32000 (51%)] Loss: 0.02733 (QuantReg: 9.00796) QuantErr: 9.00796 batch_time=0.45250 
Train Epoch: 36 [265/500 16960/32000 (53%)] Loss: 0.02029 (QuantReg: 8.82471) QuantErr: 8.82471 batch_time=0.43913 
Train Epoch: 36 [273/500 17472/32000 (55%)] Loss: 0.02519 (QuantReg: 8.74919) QuantErr: 8.74919 batch_time=0.43694 
Train Epoch: 36 [281/500 17984/32000 (56%)] Loss: 0.04134 (QuantReg: 8.84702) QuantErr: 8.84702 batch_time=0.44187 
Train Epoch: 36 [289/500 18496/32000 (58%)] Loss: 0.01922 (QuantReg: 8.92235) QuantErr: 8.92235 batch_time=0.44492 
Train Epoch: 36 [297/500 19008/32000 (59%)] Loss: 0.02390 (QuantReg: 8.84630) QuantErr: 8.84630 batch_time=0.45012 
Train Epoch: 36 [305/500 19520/32000 (61%)] Loss: 0.03205 (QuantReg: 8.91430) QuantErr: 8.91430 batch_time=0.44446 
Train Epoch: 36 [313/500 20032/32000 (63%)] Loss: 0.01946 (QuantReg: 8.83481) QuantErr: 8.83481 batch_time=0.44690 
Train Epoch: 36 [321/500 20544/32000 (64%)] Loss: 0.01818 (QuantReg: 8.76495) QuantErr: 8.76495 batch_time=0.44804 
Train Epoch: 36 [329/500 21056/32000 (66%)] Loss: 0.02731 (QuantReg: 9.00303) QuantErr: 9.00303 batch_time=0.44628 
Train Epoch: 36 [337/500 21568/32000 (67%)] Loss: 0.02548 (QuantReg: 8.80438) QuantErr: 8.80438 batch_time=0.44738 
Train Epoch: 36 [345/500 22080/32000 (69%)] Loss: 0.02180 (QuantReg: 8.87177) QuantErr: 8.87177 batch_time=0.46187 
Train Epoch: 36 [353/500 22592/32000 (71%)] Loss: 0.04575 (QuantReg: 8.73974) QuantErr: 8.73974 batch_time=0.44272 
Train Epoch: 36 [361/500 23104/32000 (72%)] Loss: 0.02606 (QuantReg: 8.83074) QuantErr: 8.83074 batch_time=0.44221 
Train Epoch: 36 [369/500 23616/32000 (74%)] Loss: 0.04550 (QuantReg: 8.84563) QuantErr: 8.84563 batch_time=0.46731 
Train Epoch: 36 [377/500 24128/32000 (75%)] Loss: 0.04431 (QuantReg: 8.86850) QuantErr: 8.86850 batch_time=0.47330 
Train Epoch: 36 [385/500 24640/32000 (77%)] Loss: 0.02121 (QuantReg: 8.91433) QuantErr: 8.91433 batch_time=0.44274 
Train Epoch: 36 [393/500 25152/32000 (79%)] Loss: 0.03304 (QuantReg: 8.97874) QuantErr: 8.97874 batch_time=0.43971 
Train Epoch: 36 [401/500 25664/32000 (80%)] Loss: 0.01889 (QuantReg: 8.90403) QuantErr: 8.90403 batch_time=0.44674 
Train Epoch: 36 [409/500 26176/32000 (82%)] Loss: 0.02963 (QuantReg: 8.87897) QuantErr: 8.87897 batch_time=0.69260 
Train Epoch: 36 [417/500 26688/32000 (83%)] Loss: 0.04090 (QuantReg: 8.76709) QuantErr: 8.76709 batch_time=0.45514 
Train Epoch: 36 [425/500 27200/32000 (85%)] Loss: 0.03602 (QuantReg: 8.77946) QuantErr: 8.77946 batch_time=0.44795 
Train Epoch: 36 [433/500 27712/32000 (87%)] Loss: 0.03242 (QuantReg: 8.86716) QuantErr: 8.86716 batch_time=0.49382 
Train Epoch: 36 [441/500 28224/32000 (88%)] Loss: 0.03680 (QuantReg: 8.80912) QuantErr: 8.80912 batch_time=0.44489 
Train Epoch: 36 [449/500 28736/32000 (90%)] Loss: 0.06536 (QuantReg: 8.90703) QuantErr: 8.90703 batch_time=0.44553 
Train Epoch: 36 [457/500 29248/32000 (91%)] Loss: 0.07093 (QuantReg: 8.95559) QuantErr: 8.95559 batch_time=0.44591 
Train Epoch: 36 [465/500 29760/32000 (93%)] Loss: 0.02230 (QuantReg: 8.79620) QuantErr: 8.79620 batch_time=0.44267 
Train Epoch: 36 [473/500 30272/32000 (95%)] Loss: 0.07223 (QuantReg: 8.81104) QuantErr: 8.81104 batch_time=0.44465 
Train Epoch: 36 [481/500 30784/32000 (96%)] Loss: 0.03555 (QuantReg: 8.65901) QuantErr: 8.65901 batch_time=0.44415 
Train Epoch: 36 [489/500 31296/32000 (98%)] Loss: 0.02834 (QuantReg: 8.89727) QuantErr: 8.89727 batch_time=0.44124 
Train Epoch: 36 [497/500 31808/32000 (99%)] Loss: 0.03744 (QuantReg: 8.87236) QuantErr: 8.87236 batch_time=0.44529 
Train Epoch: 36 codebook_update_time=1.73642
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_ActivityNet_bs64/checkpoint-epoch36.pth ...
Done in 4.117s
removing stale ckpt [epoch 35] [took 0.00s]
 epoch          : 36
 loss           : 0.04061323875933886
 quant_reg      : 8.855099615097046
 quant_err      : 8.855099615097046
 learning_rate  : 3.1556711650327163e-06
 n_samples      : 1152000
 n_steps        : 18000
 ActivityNet_val1_test/t2v_metrics/R1: 20.174903396379907
 ActivityNet_val1_test/t2v_metrics/R5: 51.14907463900752
 ActivityNet_val1_test/t2v_metrics/R10: 66.56497864551555
 ActivityNet_val1_test/t2v_metrics/R50: 89.48545861297539
 ActivityNet_val1_test/t2v_metrics/MedR: 5.0
 ActivityNet_val1_test/t2v_metrics/MeanR: 33.08846857840147
 ActivityNet_val1_test/t2v_metrics/geometric_mean_R1-R5-R10: 40.95419061632131
 ActivityNet_val1_test/v2t_metrics/R1: 20.988407565588773
 ActivityNet_val1_test/v2t_metrics/R5: 51.39312588977018
 ActivityNet_val1_test/v2t_metrics/R10: 67.76489729509863
 ActivityNet_val1_test/v2t_metrics/R50: 89.83119788488916
 ActivityNet_val1_test/v2t_metrics/MedR: 5.0
 ActivityNet_val1_test/v2t_metrics/MeanR: 30.444783404514947
 ActivityNet_val1_test/v2t_metrics/geometric_mean_R1-R5-R10: 41.81156618091785
 mnt_best       : 41.251529009943695
 not_improved_count: 13
Train Epoch: 37 [1/500 64/32000 (0%)] Loss: 0.06421 (QuantReg: 8.81079) QuantErr: 8.81079 batch_time=23.98401 
Train Epoch: 37 [9/500 576/32000 (2%)] Loss: 0.08458 (QuantReg: 8.78228) QuantErr: 8.78228 batch_time=0.43887 
Train Epoch: 37 [17/500 1088/32000 (3%)] Loss: 0.02540 (QuantReg: 8.81218) QuantErr: 8.81218 batch_time=0.47998 
Train Epoch: 37 [25/500 1600/32000 (5%)] Loss: 0.05101 (QuantReg: 8.77052) QuantErr: 8.77052 batch_time=0.44868 
Train Epoch: 37 [33/500 2112/32000 (7%)] Loss: 0.02281 (QuantReg: 8.96720) QuantErr: 8.96720 batch_time=0.44888 
Train Epoch: 37 [41/500 2624/32000 (8%)] Loss: 0.04381 (QuantReg: 9.01490) QuantErr: 9.01490 batch_time=0.45662 
Train Epoch: 37 [49/500 3136/32000 (10%)] Loss: 0.06489 (QuantReg: 8.77506) QuantErr: 8.77506 batch_time=0.44989 
Train Epoch: 37 [57/500 3648/32000 (11%)] Loss: 0.01919 (QuantReg: 8.83119) QuantErr: 8.83119 batch_time=0.44597 
Train Epoch: 37 [65/500 4160/32000 (13%)] Loss: 0.02220 (QuantReg: 8.82878) QuantErr: 8.82878 batch_time=0.44640 
Train Epoch: 37 [73/500 4672/32000 (15%)] Loss: 0.02692 (QuantReg: 8.97302) QuantErr: 8.97302 batch_time=0.45130 
Train Epoch: 37 [81/500 5184/32000 (16%)] Loss: 0.08123 (QuantReg: 8.70305) QuantErr: 8.70305 batch_time=0.48234 
Train Epoch: 37 [89/500 5696/32000 (18%)] Loss: 0.06923 (QuantReg: 8.71001) QuantErr: 8.71001 batch_time=0.46989 
Train Epoch: 37 [97/500 6208/32000 (19%)] Loss: 0.02460 (QuantReg: 8.75037) QuantErr: 8.75037 batch_time=0.43924 
Train Epoch: 37 [105/500 6720/32000 (21%)] Loss: 0.03517 (QuantReg: 8.78628) QuantErr: 8.78628 batch_time=0.44361 
Train Epoch: 37 [113/500 7232/32000 (23%)] Loss: 0.04747 (QuantReg: 8.75399) QuantErr: 8.75399 batch_time=0.44164 
Train Epoch: 37 [121/500 7744/32000 (24%)] Loss: 0.04916 (QuantReg: 8.79432) QuantErr: 8.79432 batch_time=0.44761 
Train Epoch: 37 [129/500 8256/32000 (26%)] Loss: 0.02459 (QuantReg: 8.86811) QuantErr: 8.86811 batch_time=0.44362 
Train Epoch: 37 [137/500 8768/32000 (27%)] Loss: 0.02109 (QuantReg: 8.97644) QuantErr: 8.97644 batch_time=0.44049 
Train Epoch: 37 [145/500 9280/32000 (29%)] Loss: 0.03430 (QuantReg: 8.83574) QuantErr: 8.83574 batch_time=0.47584 
Train Epoch: 37 [153/500 9792/32000 (31%)] Loss: 0.02461 (QuantReg: 8.82366) QuantErr: 8.82366 batch_time=0.43738 
Train Epoch: 37 [161/500 10304/32000 (32%)] Loss: 0.01723 (QuantReg: 8.71197) QuantErr: 8.71197 batch_time=0.44282 
Train Epoch: 37 [169/500 10816/32000 (34%)] Loss: 0.03183 (QuantReg: 8.73806) QuantErr: 8.73806 batch_time=0.44981 
Train Epoch: 37 [177/500 11328/32000 (35%)] Loss: 0.02110 (QuantReg: 8.84392) QuantErr: 8.84392 batch_time=0.44610 
Train Epoch: 37 [185/500 11840/32000 (37%)] Loss: 0.03443 (QuantReg: 8.88541) QuantErr: 8.88541 batch_time=0.43835 
Train Epoch: 37 [193/500 12352/32000 (39%)] Loss: 0.02788 (QuantReg: 8.81817) QuantErr: 8.81817 batch_time=0.44170 
Train Epoch: 37 [201/500 12864/32000 (40%)] Loss: 0.01619 (QuantReg: 8.87282) QuantErr: 8.87282 batch_time=0.44464 
Train Epoch: 37 [209/500 13376/32000 (42%)] Loss: 0.01819 (QuantReg: 8.75363) QuantErr: 8.75363 batch_time=0.47340 
Train Epoch: 37 [217/500 13888/32000 (43%)] Loss: 0.03101 (QuantReg: 8.74173) QuantErr: 8.74173 batch_time=0.44540 
Train Epoch: 37 [225/500 14400/32000 (45%)] Loss: 0.05117 (QuantReg: 8.60194) QuantErr: 8.60194 batch_time=0.43754 
Train Epoch: 37 [233/500 14912/32000 (47%)] Loss: 0.01995 (QuantReg: 8.67309) QuantErr: 8.67309 batch_time=0.44099 
Train Epoch: 37 [241/500 15424/32000 (48%)] Loss: 0.04276 (QuantReg: 8.78793) QuantErr: 8.78793 batch_time=0.44082 
Train Epoch: 37 [249/500 15936/32000 (50%)] Loss: 0.03418 (QuantReg: 8.85528) QuantErr: 8.85528 batch_time=0.50637 
Train Epoch: 37 [257/500 16448/32000 (51%)] Loss: 0.08297 (QuantReg: 8.67049) QuantErr: 8.67049 batch_time=0.44529 
Train Epoch: 37 [265/500 16960/32000 (53%)] Loss: 0.03354 (QuantReg: 8.86096) QuantErr: 8.86096 batch_time=0.47239 
Train Epoch: 37 [273/500 17472/32000 (55%)] Loss: 0.02349 (QuantReg: 8.89461) QuantErr: 8.89461 batch_time=0.47883 
Train Epoch: 37 [281/500 17984/32000 (56%)] Loss: 0.03687 (QuantReg: 8.79169) QuantErr: 8.79169 batch_time=0.44568 
Train Epoch: 37 [289/500 18496/32000 (58%)] Loss: 0.02542 (QuantReg: 9.00600) QuantErr: 9.00600 batch_time=0.47823 
Train Epoch: 37 [297/500 19008/32000 (59%)] Loss: 0.02392 (QuantReg: 8.87109) QuantErr: 8.87109 batch_time=0.44689 
Train Epoch: 37 [305/500 19520/32000 (61%)] Loss: 0.05894 (QuantReg: 8.78070) QuantErr: 8.78070 batch_time=0.44705 
Train Epoch: 37 [313/500 20032/32000 (63%)] Loss: 0.03560 (QuantReg: 8.78136) QuantErr: 8.78136 batch_time=0.44054 
Train Epoch: 37 [321/500 20544/32000 (64%)] Loss: 0.06802 (QuantReg: 8.79397) QuantErr: 8.79397 batch_time=0.45310 
Train Epoch: 37 [329/500 21056/32000 (66%)] Loss: 0.03530 (QuantReg: 8.85332) QuantErr: 8.85332 batch_time=0.44546 
Train Epoch: 37 [337/500 21568/32000 (67%)] Loss: 0.03292 (QuantReg: 8.81561) QuantErr: 8.81561 batch_time=0.47119 
Train Epoch: 37 [345/500 22080/32000 (69%)] Loss: 0.06230 (QuantReg: 8.77038) QuantErr: 8.77038 batch_time=0.43687 
Train Epoch: 37 [353/500 22592/32000 (71%)] Loss: 0.03374 (QuantReg: 8.84184) QuantErr: 8.84184 batch_time=0.42941 
Train Epoch: 37 [361/500 23104/32000 (72%)] Loss: 0.02225 (QuantReg: 8.94089) QuantErr: 8.94089 batch_time=0.43822 
Train Epoch: 37 [369/500 23616/32000 (74%)] Loss: 0.06997 (QuantReg: 8.76755) QuantErr: 8.76755 batch_time=0.43776 
Train Epoch: 37 [377/500 24128/32000 (75%)] Loss: 0.02610 (QuantReg: 8.71383) QuantErr: 8.71383 batch_time=0.47295 
Train Epoch: 37 [385/500 24640/32000 (77%)] Loss: 0.02563 (QuantReg: 8.80851) QuantErr: 8.80851 batch_time=0.44721 
Train Epoch: 37 [393/500 25152/32000 (79%)] Loss: 0.06145 (QuantReg: 8.84668) QuantErr: 8.84668 batch_time=0.44250 
Train Epoch: 37 [401/500 25664/32000 (80%)] Loss: 0.03160 (QuantReg: 8.81606) QuantErr: 8.81606 batch_time=0.48016 
Train Epoch: 37 [409/500 26176/32000 (82%)] Loss: 0.05759 (QuantReg: 8.90372) QuantErr: 8.90372 batch_time=0.44145 
Train Epoch: 37 [417/500 26688/32000 (83%)] Loss: 0.04356 (QuantReg: 8.89103) QuantErr: 8.89103 batch_time=0.44794 
Train Epoch: 37 [425/500 27200/32000 (85%)] Loss: 0.07243 (QuantReg: 8.69313) QuantErr: 8.69313 batch_time=0.44320 
Train Epoch: 37 [433/500 27712/32000 (87%)] Loss: 0.06546 (QuantReg: 8.64116) QuantErr: 8.64116 batch_time=0.48217 
Train Epoch: 37 [441/500 28224/32000 (88%)] Loss: 0.04411 (QuantReg: 8.63960) QuantErr: 8.63960 batch_time=0.44321 
Train Epoch: 37 [449/500 28736/32000 (90%)] Loss: 0.02881 (QuantReg: 8.63595) QuantErr: 8.63595 batch_time=0.43843 
Train Epoch: 37 [457/500 29248/32000 (91%)] Loss: 0.08017 (QuantReg: 8.88011) QuantErr: 8.88011 batch_time=0.44636 
Train Epoch: 37 [465/500 29760/32000 (93%)] Loss: 0.06039 (QuantReg: 8.80794) QuantErr: 8.80794 batch_time=0.46970 
Train Epoch: 37 [473/500 30272/32000 (95%)] Loss: 0.03751 (QuantReg: 8.89123) QuantErr: 8.89123 batch_time=0.43353 
Train Epoch: 37 [481/500 30784/32000 (96%)] Loss: 0.04724 (QuantReg: 8.82484) QuantErr: 8.82484 batch_time=0.43148 
Train Epoch: 37 [489/500 31296/32000 (98%)] Loss: 0.03138 (QuantReg: 8.79121) QuantErr: 8.79121 batch_time=0.44383 
Train Epoch: 37 [497/500 31808/32000 (99%)] Loss: 0.06814 (QuantReg: 8.72939) QuantErr: 8.72939 batch_time=0.46939 
Train Epoch: 37 codebook_update_time=1.68819
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_ActivityNet_bs64/checkpoint-epoch37.pth ...
Done in 3.792s
removing stale ckpt [epoch 36] [took 0.00s]
 epoch          : 37
 loss           : 0.03974585169367492
 quant_reg      : 8.816583986282348
 quant_err      : 8.816583986282348
 learning_rate  : 2.6823204902778087e-06
 n_samples      : 1184000
 n_steps        : 18500
 ActivityNet_val1_test/t2v_metrics/R1: 20.174903396379907
 ActivityNet_val1_test/t2v_metrics/R5: 51.08806182631686
 ActivityNet_val1_test/t2v_metrics/R10: 66.25991458206224
 ActivityNet_val1_test/t2v_metrics/R50: 89.28208257067317
 ActivityNet_val1_test/t2v_metrics/MedR: 5.0
 ActivityNet_val1_test/t2v_metrics/MeanR: 33.59934919666463
 ActivityNet_val1_test/t2v_metrics/geometric_mean_R1-R5-R10: 40.875265580877276
 ActivityNet_val1_test/v2t_metrics/R1: 20.866381940207443
 ActivityNet_val1_test/v2t_metrics/R5: 51.271100264388856
 ActivityNet_val1_test/v2t_metrics/R10: 67.41915802318486
 ActivityNet_val1_test/v2t_metrics/R50: 89.60748423835672
 ActivityNet_val1_test/v2t_metrics/MedR: 5.0
 ActivityNet_val1_test/v2t_metrics/MeanR: 31.239170225747408
 ActivityNet_val1_test/v2t_metrics/geometric_mean_R1-R5-R10: 41.62628992830413
 mnt_best       : 41.251529009943695
 not_improved_count: 14
Train Epoch: 38 [1/500 64/32000 (0%)] Loss: 0.04658 (QuantReg: 8.69862) QuantErr: 8.69862 batch_time=24.38353 
Train Epoch: 38 [9/500 576/32000 (2%)] Loss: 0.02786 (QuantReg: 8.92515) QuantErr: 8.92515 batch_time=0.43576 
Train Epoch: 38 [17/500 1088/32000 (3%)] Loss: 0.04783 (QuantReg: 8.70433) QuantErr: 8.70433 batch_time=0.44640 
Train Epoch: 38 [25/500 1600/32000 (5%)] Loss: 0.03167 (QuantReg: 8.82502) QuantErr: 8.82502 batch_time=0.43991 
Train Epoch: 38 [33/500 2112/32000 (7%)] Loss: 0.03850 (QuantReg: 8.62582) QuantErr: 8.62582 batch_time=0.47363 
Train Epoch: 38 [41/500 2624/32000 (8%)] Loss: 0.01892 (QuantReg: 8.95713) QuantErr: 8.95713 batch_time=0.44076 
Train Epoch: 38 [49/500 3136/32000 (10%)] Loss: 0.04760 (QuantReg: 8.81468) QuantErr: 8.81468 batch_time=0.44378 
Train Epoch: 38 [57/500 3648/32000 (11%)] Loss: 0.02724 (QuantReg: 8.93704) QuantErr: 8.93704 batch_time=0.43752 
Train Epoch: 38 [65/500 4160/32000 (13%)] Loss: 0.01956 (QuantReg: 8.77761) QuantErr: 8.77761 batch_time=0.62443 
Train Epoch: 38 [73/500 4672/32000 (15%)] Loss: 0.02737 (QuantReg: 8.47252) QuantErr: 8.47252 batch_time=0.44025 
Train Epoch: 38 [81/500 5184/32000 (16%)] Loss: 0.03510 (QuantReg: 8.75370) QuantErr: 8.75370 batch_time=0.43651 
Train Epoch: 38 [89/500 5696/32000 (18%)] Loss: 0.02274 (QuantReg: 8.89396) QuantErr: 8.89396 batch_time=0.44733 
Train Epoch: 38 [97/500 6208/32000 (19%)] Loss: 0.02902 (QuantReg: 8.76425) QuantErr: 8.76425 batch_time=0.44196 
Train Epoch: 38 [105/500 6720/32000 (21%)] Loss: 0.03126 (QuantReg: 8.85345) QuantErr: 8.85345 batch_time=0.44057 
Train Epoch: 38 [113/500 7232/32000 (23%)] Loss: 0.02608 (QuantReg: 8.71311) QuantErr: 8.71311 batch_time=0.43780 
Train Epoch: 38 [121/500 7744/32000 (24%)] Loss: 0.07311 (QuantReg: 8.77513) QuantErr: 8.77513 batch_time=0.44251 
Train Epoch: 38 [129/500 8256/32000 (26%)] Loss: 0.02426 (QuantReg: 8.90671) QuantErr: 8.90671 batch_time=0.64208 
Train Epoch: 38 [137/500 8768/32000 (27%)] Loss: 0.03942 (QuantReg: 8.77130) QuantErr: 8.77130 batch_time=0.45862 
Train Epoch: 38 [145/500 9280/32000 (29%)] Loss: 0.02703 (QuantReg: 8.70203) QuantErr: 8.70203 batch_time=0.44813 
Train Epoch: 38 [153/500 9792/32000 (31%)] Loss: 0.03924 (QuantReg: 8.74081) QuantErr: 8.74081 batch_time=0.43542 
Train Epoch: 38 [161/500 10304/32000 (32%)] Loss: 0.03431 (QuantReg: 8.61782) QuantErr: 8.61782 batch_time=0.44326 
Train Epoch: 38 [169/500 10816/32000 (34%)] Loss: 0.07201 (QuantReg: 8.71842) QuantErr: 8.71842 batch_time=0.44471 
Train Epoch: 38 [177/500 11328/32000 (35%)] Loss: 0.03588 (QuantReg: 8.98850) QuantErr: 8.98850 batch_time=0.43665 
Train Epoch: 38 [185/500 11840/32000 (37%)] Loss: 0.04534 (QuantReg: 8.79741) QuantErr: 8.79741 batch_time=0.43496 
Train Epoch: 38 [193/500 12352/32000 (39%)] Loss: 0.03326 (QuantReg: 8.83489) QuantErr: 8.83489 batch_time=0.62443 
Train Epoch: 38 [201/500 12864/32000 (40%)] Loss: 0.05408 (QuantReg: 8.64747) QuantErr: 8.64747 batch_time=0.43689 
Train Epoch: 38 [209/500 13376/32000 (42%)] Loss: 0.03333 (QuantReg: 8.63975) QuantErr: 8.63975 batch_time=0.43875 
Train Epoch: 38 [217/500 13888/32000 (43%)] Loss: 0.07137 (QuantReg: 8.78367) QuantErr: 8.78367 batch_time=0.44031 
Train Epoch: 38 [225/500 14400/32000 (45%)] Loss: 0.02038 (QuantReg: 8.84188) QuantErr: 8.84188 batch_time=0.43548 
Train Epoch: 38 [233/500 14912/32000 (47%)] Loss: 0.04791 (QuantReg: 8.67090) QuantErr: 8.67090 batch_time=0.43800 
Train Epoch: 38 [241/500 15424/32000 (48%)] Loss: 0.07637 (QuantReg: 8.99428) QuantErr: 8.99428 batch_time=0.44351 
Train Epoch: 38 [249/500 15936/32000 (50%)] Loss: 0.02689 (QuantReg: 8.77966) QuantErr: 8.77966 batch_time=0.46104 
Train Epoch: 38 [257/500 16448/32000 (51%)] Loss: 0.02883 (QuantReg: 8.71678) QuantErr: 8.71678 batch_time=0.63296 
Train Epoch: 38 [265/500 16960/32000 (53%)] Loss: 0.02750 (QuantReg: 8.77567) QuantErr: 8.77567 batch_time=0.43576 
Train Epoch: 38 [273/500 17472/32000 (55%)] Loss: 0.06902 (QuantReg: 8.75542) QuantErr: 8.75542 batch_time=0.44887 
Train Epoch: 38 [281/500 17984/32000 (56%)] Loss: 0.06696 (QuantReg: 8.75097) QuantErr: 8.75097 batch_time=0.44070 
Train Epoch: 38 [289/500 18496/32000 (58%)] Loss: 0.02988 (QuantReg: 8.86958) QuantErr: 8.86958 batch_time=0.43732 
Train Epoch: 38 [297/500 19008/32000 (59%)] Loss: 0.07988 (QuantReg: 8.79188) QuantErr: 8.79188 batch_time=0.47463 
Train Epoch: 38 [305/500 19520/32000 (61%)] Loss: 0.03461 (QuantReg: 8.70045) QuantErr: 8.70045 batch_time=0.44371 
Train Epoch: 38 [313/500 20032/32000 (63%)] Loss: 0.03566 (QuantReg: 8.69195) QuantErr: 8.69195 batch_time=0.44651 
Train Epoch: 38 [321/500 20544/32000 (64%)] Loss: 0.02519 (QuantReg: 8.95153) QuantErr: 8.95153 batch_time=0.63141 
Train Epoch: 38 [329/500 21056/32000 (66%)] Loss: 0.02790 (QuantReg: 8.90690) QuantErr: 8.90690 batch_time=0.44674 
Train Epoch: 38 [337/500 21568/32000 (67%)] Loss: 0.04862 (QuantReg: 8.56469) QuantErr: 8.56469 batch_time=0.47609 
Train Epoch: 38 [345/500 22080/32000 (69%)] Loss: 0.08163 (QuantReg: 8.81134) QuantErr: 8.81134 batch_time=0.44308 
Train Epoch: 38 [353/500 22592/32000 (71%)] Loss: 0.13285 (QuantReg: 8.81548) QuantErr: 8.81548 batch_time=0.45310 
Train Epoch: 38 [361/500 23104/32000 (72%)] Loss: 0.02296 (QuantReg: 8.84139) QuantErr: 8.84139 batch_time=0.44316 
Train Epoch: 38 [369/500 23616/32000 (74%)] Loss: 0.03103 (QuantReg: 8.82520) QuantErr: 8.82520 batch_time=0.47058 
Train Epoch: 38 [377/500 24128/32000 (75%)] Loss: 0.02350 (QuantReg: 8.65100) QuantErr: 8.65100 batch_time=0.44501 
Train Epoch: 38 [385/500 24640/32000 (77%)] Loss: 0.04128 (QuantReg: 8.76102) QuantErr: 8.76102 batch_time=0.64115 
Train Epoch: 38 [393/500 25152/32000 (79%)] Loss: 0.03155 (QuantReg: 8.88539) QuantErr: 8.88539 batch_time=0.43892 
Train Epoch: 38 [401/500 25664/32000 (80%)] Loss: 0.05456 (QuantReg: 8.90726) QuantErr: 8.90726 batch_time=0.43765 
Train Epoch: 38 [409/500 26176/32000 (82%)] Loss: 0.07043 (QuantReg: 8.92428) QuantErr: 8.92428 batch_time=0.44332 
Train Epoch: 38 [417/500 26688/32000 (83%)] Loss: 0.02809 (QuantReg: 8.71655) QuantErr: 8.71655 batch_time=0.44660 
Train Epoch: 38 [425/500 27200/32000 (85%)] Loss: 0.11052 (QuantReg: 8.67847) QuantErr: 8.67847 batch_time=0.44078 
Train Epoch: 38 [433/500 27712/32000 (87%)] Loss: 0.03833 (QuantReg: 8.98452) QuantErr: 8.98452 batch_time=0.43918 
Train Epoch: 38 [441/500 28224/32000 (88%)] Loss: 0.02849 (QuantReg: 8.93483) QuantErr: 8.93483 batch_time=0.44285 
Train Epoch: 38 [449/500 28736/32000 (90%)] Loss: 0.02463 (QuantReg: 8.67435) QuantErr: 8.67435 batch_time=0.62779 
Train Epoch: 38 [457/500 29248/32000 (91%)] Loss: 0.02079 (QuantReg: 8.86040) QuantErr: 8.86040 batch_time=0.43657 
Train Epoch: 38 [465/500 29760/32000 (93%)] Loss: 0.02250 (QuantReg: 8.88710) QuantErr: 8.88710 batch_time=0.44264 
Train Epoch: 38 [473/500 30272/32000 (95%)] Loss: 0.02699 (QuantReg: 8.91700) QuantErr: 8.91700 batch_time=0.44234 
Train Epoch: 38 [481/500 30784/32000 (96%)] Loss: 0.06935 (QuantReg: 8.86378) QuantErr: 8.86378 batch_time=0.44247 
Train Epoch: 38 [489/500 31296/32000 (98%)] Loss: 0.02674 (QuantReg: 8.80971) QuantErr: 8.80971 batch_time=0.49503 
Train Epoch: 38 [497/500 31808/32000 (99%)] Loss: 0.01618 (QuantReg: 8.68768) QuantErr: 8.68768 batch_time=0.45124 
Train Epoch: 38 codebook_update_time=1.66432
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_ActivityNet_bs64/checkpoint-epoch38.pth ...
Done in 4.631s
removing stale ckpt [epoch 37] [took 0.02s]
 epoch          : 38
 loss           : 0.03875807701051235
 quant_reg      : 8.780093112945556
 quant_err      : 8.780093112945556
 learning_rate  : 2.6823204902778087e-06
 n_samples      : 1216000
 n_steps        : 19000
 ActivityNet_val1_test/t2v_metrics/R1: 20.012202562538132
 ActivityNet_val1_test/t2v_metrics/R5: 50.945698596705306
 ActivityNet_val1_test/t2v_metrics/R10: 66.52430343705511
 ActivityNet_val1_test/t2v_metrics/R50: 89.20073215375228
 ActivityNet_val1_test/t2v_metrics/MedR: 5.0
 ActivityNet_val1_test/t2v_metrics/MeanR: 33.81106365670124
 ActivityNet_val1_test/t2v_metrics/geometric_mean_R1-R5-R10: 40.781285927846504
 ActivityNet_val1_test/v2t_metrics/R1: 21.008745169818994
 ActivityNet_val1_test/v2t_metrics/R5: 51.63717714053284
 ActivityNet_val1_test/v2t_metrics/R10: 68.0089485458613
 ActivityNet_val1_test/v2t_metrics/R50: 89.6888346552776
 ActivityNet_val1_test/v2t_metrics/MedR: 5.0
 ActivityNet_val1_test/v2t_metrics/MeanR: 31.292454748830586
 ActivityNet_val1_test/v2t_metrics/geometric_mean_R1-R5-R10: 41.94139668587359
 mnt_best       : 41.251529009943695
 not_improved_count: 15
Train Epoch: 39 [1/500 64/32000 (0%)] Loss: 0.02418 (QuantReg: 8.86753) QuantErr: 8.86753 batch_time=24.62038 
Train Epoch: 39 [9/500 576/32000 (2%)] Loss: 0.02822 (QuantReg: 8.76124) QuantErr: 8.76124 batch_time=0.45105 
Train Epoch: 39 [17/500 1088/32000 (3%)] Loss: 0.01765 (QuantReg: 8.78625) QuantErr: 8.78625 batch_time=0.47427 
Train Epoch: 39 [25/500 1600/32000 (5%)] Loss: 0.03951 (QuantReg: 8.78885) QuantErr: 8.78885 batch_time=1.29299 
Train Epoch: 39 [33/500 2112/32000 (7%)] Loss: 0.05573 (QuantReg: 8.70609) QuantErr: 8.70609 batch_time=0.44742 
Train Epoch: 39 [41/500 2624/32000 (8%)] Loss: 0.02730 (QuantReg: 8.78454) QuantErr: 8.78454 batch_time=0.46034 
Train Epoch: 39 [49/500 3136/32000 (10%)] Loss: 0.06413 (QuantReg: 8.85617) QuantErr: 8.85617 batch_time=0.45505 
Train Epoch: 39 [57/500 3648/32000 (11%)] Loss: 0.01955 (QuantReg: 8.78029) QuantErr: 8.78029 batch_time=0.44454 
Train Epoch: 39 [65/500 4160/32000 (13%)] Loss: 0.02931 (QuantReg: 8.90660) QuantErr: 8.90660 batch_time=0.81264 
Train Epoch: 39 [73/500 4672/32000 (15%)] Loss: 0.01820 (QuantReg: 8.64717) QuantErr: 8.64717 batch_time=0.44514 
Train Epoch: 39 [81/500 5184/32000 (16%)] Loss: 0.02523 (QuantReg: 8.64936) QuantErr: 8.64936 batch_time=0.44660 
Train Epoch: 39 [89/500 5696/32000 (18%)] Loss: 0.02509 (QuantReg: 8.87580) QuantErr: 8.87580 batch_time=1.10295 
Train Epoch: 39 [97/500 6208/32000 (19%)] Loss: 0.03397 (QuantReg: 8.74122) QuantErr: 8.74122 batch_time=0.44835 
Train Epoch: 39 [105/500 6720/32000 (21%)] Loss: 0.02731 (QuantReg: 8.85670) QuantErr: 8.85670 batch_time=0.44252 
Train Epoch: 39 [113/500 7232/32000 (23%)] Loss: 0.07449 (QuantReg: 8.92939) QuantErr: 8.92939 batch_time=0.44054 
Train Epoch: 39 [121/500 7744/32000 (24%)] Loss: 0.04678 (QuantReg: 8.74239) QuantErr: 8.74239 batch_time=0.43658 
Train Epoch: 39 [129/500 8256/32000 (26%)] Loss: 0.03062 (QuantReg: 8.65210) QuantErr: 8.65210 batch_time=0.79695 
Train Epoch: 39 [137/500 8768/32000 (27%)] Loss: 0.03343 (QuantReg: 8.80491) QuantErr: 8.80491 batch_time=0.43736 
Train Epoch: 39 [145/500 9280/32000 (29%)] Loss: 0.02933 (QuantReg: 8.76732) QuantErr: 8.76732 batch_time=0.44181 
Train Epoch: 39 [153/500 9792/32000 (31%)] Loss: 0.04158 (QuantReg: 8.69064) QuantErr: 8.69064 batch_time=1.07722 
Train Epoch: 39 [161/500 10304/32000 (32%)] Loss: 0.03174 (QuantReg: 8.74231) QuantErr: 8.74231 batch_time=0.44099 
Train Epoch: 39 [169/500 10816/32000 (34%)] Loss: 0.07833 (QuantReg: 8.66695) QuantErr: 8.66695 batch_time=0.44268 
Train Epoch: 39 [177/500 11328/32000 (35%)] Loss: 0.02232 (QuantReg: 8.82351) QuantErr: 8.82351 batch_time=0.44580 
Train Epoch: 39 [185/500 11840/32000 (37%)] Loss: 0.02227 (QuantReg: 8.86458) QuantErr: 8.86458 batch_time=0.44332 
Train Epoch: 39 [193/500 12352/32000 (39%)] Loss: 0.02059 (QuantReg: 8.76319) QuantErr: 8.76319 batch_time=0.84753 
Train Epoch: 39 [201/500 12864/32000 (40%)] Loss: 0.02065 (QuantReg: 8.73686) QuantErr: 8.73686 batch_time=0.44038 
Train Epoch: 39 [209/500 13376/32000 (42%)] Loss: 0.02088 (QuantReg: 8.74005) QuantErr: 8.74005 batch_time=0.44735 
Train Epoch: 39 [217/500 13888/32000 (43%)] Loss: 0.02152 (QuantReg: 8.87032) QuantErr: 8.87032 batch_time=1.13972 
Train Epoch: 39 [225/500 14400/32000 (45%)] Loss: 0.02559 (QuantReg: 8.71042) QuantErr: 8.71042 batch_time=0.44222 
Train Epoch: 39 [233/500 14912/32000 (47%)] Loss: 0.03338 (QuantReg: 8.81579) QuantErr: 8.81579 batch_time=0.43970 
Train Epoch: 39 [241/500 15424/32000 (48%)] Loss: 0.02715 (QuantReg: 8.82513) QuantErr: 8.82513 batch_time=0.48856 
Train Epoch: 39 [249/500 15936/32000 (50%)] Loss: 0.03189 (QuantReg: 8.94519) QuantErr: 8.94519 batch_time=0.44200 
Train Epoch: 39 [257/500 16448/32000 (51%)] Loss: 0.01816 (QuantReg: 8.71982) QuantErr: 8.71982 batch_time=0.79314 
Train Epoch: 39 [265/500 16960/32000 (53%)] Loss: 0.02858 (QuantReg: 8.70408) QuantErr: 8.70408 batch_time=0.44348 
Train Epoch: 39 [273/500 17472/32000 (55%)] Loss: 0.06781 (QuantReg: 8.53068) QuantErr: 8.53068 batch_time=0.44454 
Train Epoch: 39 [281/500 17984/32000 (56%)] Loss: 0.02586 (QuantReg: 8.86699) QuantErr: 8.86699 batch_time=1.10590 
Train Epoch: 39 [289/500 18496/32000 (58%)] Loss: 0.04118 (QuantReg: 8.71217) QuantErr: 8.71217 batch_time=0.44124 
Train Epoch: 39 [297/500 19008/32000 (59%)] Loss: 0.02114 (QuantReg: 8.71340) QuantErr: 8.71340 batch_time=0.45201 
Train Epoch: 39 [305/500 19520/32000 (61%)] Loss: 0.05316 (QuantReg: 8.83826) QuantErr: 8.83826 batch_time=0.44866 
Train Epoch: 39 [313/500 20032/32000 (63%)] Loss: 0.02541 (QuantReg: 8.55484) QuantErr: 8.55484 batch_time=0.44791 
Train Epoch: 39 [321/500 20544/32000 (64%)] Loss: 0.06851 (QuantReg: 8.81461) QuantErr: 8.81461 batch_time=0.81416 
Train Epoch: 39 [329/500 21056/32000 (66%)] Loss: 0.05320 (QuantReg: 8.82259) QuantErr: 8.82259 batch_time=0.44800 
Train Epoch: 39 [337/500 21568/32000 (67%)] Loss: 0.03860 (QuantReg: 8.78431) QuantErr: 8.78431 batch_time=0.44892 
Train Epoch: 39 [345/500 22080/32000 (69%)] Loss: 0.03751 (QuantReg: 8.77074) QuantErr: 8.77074 batch_time=1.10289 
Train Epoch: 39 [353/500 22592/32000 (71%)] Loss: 0.02289 (QuantReg: 8.61909) QuantErr: 8.61909 batch_time=0.44838 
Train Epoch: 39 [361/500 23104/32000 (72%)] Loss: 0.03694 (QuantReg: 8.78700) QuantErr: 8.78700 batch_time=0.44601 
Train Epoch: 39 [369/500 23616/32000 (74%)] Loss: 0.03676 (QuantReg: 8.61306) QuantErr: 8.61306 batch_time=0.45017 
Train Epoch: 39 [377/500 24128/32000 (75%)] Loss: 0.01886 (QuantReg: 8.74108) QuantErr: 8.74108 batch_time=0.44585 
Train Epoch: 39 [385/500 24640/32000 (77%)] Loss: 0.01953 (QuantReg: 8.75548) QuantErr: 8.75548 batch_time=0.85231 
Train Epoch: 39 [393/500 25152/32000 (79%)] Loss: 0.06237 (QuantReg: 8.62185) QuantErr: 8.62185 batch_time=0.48090 
Train Epoch: 39 [401/500 25664/32000 (80%)] Loss: 0.03414 (QuantReg: 8.82422) QuantErr: 8.82422 batch_time=0.47963 
Train Epoch: 39 [409/500 26176/32000 (82%)] Loss: 0.02576 (QuantReg: 8.89809) QuantErr: 8.89809 batch_time=1.08561 
Train Epoch: 39 [417/500 26688/32000 (83%)] Loss: 0.03839 (QuantReg: 8.53611) QuantErr: 8.53611 batch_time=0.46050 
Train Epoch: 39 [425/500 27200/32000 (85%)] Loss: 0.05337 (QuantReg: 8.89406) QuantErr: 8.89406 batch_time=0.44903 
Train Epoch: 39 [433/500 27712/32000 (87%)] Loss: 0.02137 (QuantReg: 8.59835) QuantErr: 8.59835 batch_time=0.44349 
Train Epoch: 39 [441/500 28224/32000 (88%)] Loss: 0.03708 (QuantReg: 8.89218) QuantErr: 8.89218 batch_time=0.44355 
Train Epoch: 39 [449/500 28736/32000 (90%)] Loss: 0.07102 (QuantReg: 8.74284) QuantErr: 8.74284 batch_time=0.80191 
Train Epoch: 39 [457/500 29248/32000 (91%)] Loss: 0.06772 (QuantReg: 8.71934) QuantErr: 8.71934 batch_time=0.44451 
Train Epoch: 39 [465/500 29760/32000 (93%)] Loss: 0.02814 (QuantReg: 8.74009) QuantErr: 8.74009 batch_time=0.47876 
Train Epoch: 39 [473/500 30272/32000 (95%)] Loss: 0.03101 (QuantReg: 8.71725) QuantErr: 8.71725 batch_time=1.09535 
Train Epoch: 39 [481/500 30784/32000 (96%)] Loss: 0.03642 (QuantReg: 8.67624) QuantErr: 8.67624 batch_time=0.50870 
Train Epoch: 39 [489/500 31296/32000 (98%)] Loss: 0.04617 (QuantReg: 8.79429) QuantErr: 8.79429 batch_time=0.44044 
Train Epoch: 39 [497/500 31808/32000 (99%)] Loss: 0.01334 (QuantReg: 8.71782) QuantErr: 8.71782 batch_time=0.45069 
Train Epoch: 39 codebook_update_time=1.69815
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_ActivityNet_bs64/checkpoint-epoch39.pth ...
Done in 4.430s
removing stale ckpt [epoch 38] [took 0.01s]
 epoch          : 39
 loss           : 0.038110997125506405
 quant_reg      : 8.746129657745362
 quant_err      : 8.746129657745362
 learning_rate  : 2.2799724167361374e-06
 n_samples      : 1248000
 n_steps        : 19500
 ActivityNet_val1_test/t2v_metrics/R1: 20.11389058368924
 ActivityNet_val1_test/t2v_metrics/R5: 51.10839943054708
 ActivityNet_val1_test/t2v_metrics/R10: 66.19890176937157
 ActivityNet_val1_test/t2v_metrics/R50: 89.60748423835672
 ActivityNet_val1_test/t2v_metrics/MedR: 5.0
 ActivityNet_val1_test/t2v_metrics/MeanR: 33.4767134431564
 ActivityNet_val1_test/t2v_metrics/geometric_mean_R1-R5-R10: 40.82689790266826
 ActivityNet_val1_test/v2t_metrics/R1: 20.96806996135855
 ActivityNet_val1_test/v2t_metrics/R5: 51.43380109823063
 ActivityNet_val1_test/v2t_metrics/R10: 67.70388448240797
 ActivityNet_val1_test/v2t_metrics/R50: 89.72950986373804
 ActivityNet_val1_test/v2t_metrics/MedR: 5.0
 ActivityNet_val1_test/v2t_metrics/MeanR: 31.16331096196868
 ActivityNet_val1_test/v2t_metrics/geometric_mean_R1-R5-R10: 41.79652942596815
 mnt_best       : 41.251529009943695
 not_improved_count: 16
Train Epoch: 40 [1/500 64/32000 (0%)] Loss: 0.06572 (QuantReg: 8.75006) QuantErr: 8.75006 batch_time=23.70911 
Train Epoch: 40 [9/500 576/32000 (2%)] Loss: 0.06651 (QuantReg: 8.71014) QuantErr: 8.71014 batch_time=0.46091 
Train Epoch: 40 [17/500 1088/32000 (3%)] Loss: 0.04496 (QuantReg: 8.63795) QuantErr: 8.63795 batch_time=0.44147 
Train Epoch: 40 [25/500 1600/32000 (5%)] Loss: 0.02368 (QuantReg: 8.84902) QuantErr: 8.84902 batch_time=0.84167 
Train Epoch: 40 [33/500 2112/32000 (7%)] Loss: 0.07212 (QuantReg: 8.76887) QuantErr: 8.76887 batch_time=0.44655 
Train Epoch: 40 [41/500 2624/32000 (8%)] Loss: 0.03716 (QuantReg: 8.58804) QuantErr: 8.58804 batch_time=0.44938 
Train Epoch: 40 [49/500 3136/32000 (10%)] Loss: 0.08974 (QuantReg: 8.62644) QuantErr: 8.62644 batch_time=0.44545 
Train Epoch: 40 [57/500 3648/32000 (11%)] Loss: 0.05210 (QuantReg: 8.65394) QuantErr: 8.65394 batch_time=0.44153 
Train Epoch: 40 [65/500 4160/32000 (13%)] Loss: 0.04735 (QuantReg: 8.59237) QuantErr: 8.59237 batch_time=0.88613 
Train Epoch: 40 [73/500 4672/32000 (15%)] Loss: 0.02095 (QuantReg: 8.78229) QuantErr: 8.78229 batch_time=0.44148 
Train Epoch: 40 [81/500 5184/32000 (16%)] Loss: 0.04900 (QuantReg: 8.62914) QuantErr: 8.62914 batch_time=0.44173 
Train Epoch: 40 [89/500 5696/32000 (18%)] Loss: 0.02685 (QuantReg: 8.67383) QuantErr: 8.67383 batch_time=0.74660 
Train Epoch: 40 [97/500 6208/32000 (19%)] Loss: 0.02813 (QuantReg: 8.71967) QuantErr: 8.71967 batch_time=0.44614 
Train Epoch: 40 [105/500 6720/32000 (21%)] Loss: 0.02848 (QuantReg: 8.68008) QuantErr: 8.68008 batch_time=0.45520 
Train Epoch: 40 [113/500 7232/32000 (23%)] Loss: 0.04238 (QuantReg: 8.81862) QuantErr: 8.81862 batch_time=0.43936 
Train Epoch: 40 [121/500 7744/32000 (24%)] Loss: 0.02671 (QuantReg: 8.78962) QuantErr: 8.78962 batch_time=0.44138 
Train Epoch: 40 [129/500 8256/32000 (26%)] Loss: 0.03292 (QuantReg: 8.75992) QuantErr: 8.75992 batch_time=0.84167 
Train Epoch: 40 [137/500 8768/32000 (27%)] Loss: 0.06215 (QuantReg: 8.72721) QuantErr: 8.72721 batch_time=0.44932 
Train Epoch: 40 [145/500 9280/32000 (29%)] Loss: 0.01708 (QuantReg: 8.73980) QuantErr: 8.73980 batch_time=0.44483 
Train Epoch: 40 [153/500 9792/32000 (31%)] Loss: 0.01948 (QuantReg: 8.79744) QuantErr: 8.79744 batch_time=0.75239 
Train Epoch: 40 [161/500 10304/32000 (32%)] Loss: 0.02662 (QuantReg: 8.47419) QuantErr: 8.47419 batch_time=0.46601 
Train Epoch: 40 [169/500 10816/32000 (34%)] Loss: 0.06928 (QuantReg: 8.69132) QuantErr: 8.69132 batch_time=0.44870 
Train Epoch: 40 [177/500 11328/32000 (35%)] Loss: 0.02531 (QuantReg: 8.58812) QuantErr: 8.58812 batch_time=0.43956 
Train Epoch: 40 [185/500 11840/32000 (37%)] Loss: 0.01839 (QuantReg: 8.69156) QuantErr: 8.69156 batch_time=0.44996 
Train Epoch: 40 [193/500 12352/32000 (39%)] Loss: 0.03548 (QuantReg: 8.67608) QuantErr: 8.67608 batch_time=0.92683 
Train Epoch: 40 [201/500 12864/32000 (40%)] Loss: 0.04375 (QuantReg: 8.67580) QuantErr: 8.67580 batch_time=0.43825 
Train Epoch: 40 [209/500 13376/32000 (42%)] Loss: 0.02998 (QuantReg: 8.68435) QuantErr: 8.68435 batch_time=0.44982 
Train Epoch: 40 [217/500 13888/32000 (43%)] Loss: 0.06831 (QuantReg: 8.69460) QuantErr: 8.69460 batch_time=0.74026 
Train Epoch: 40 [225/500 14400/32000 (45%)] Loss: 0.02217 (QuantReg: 8.59341) QuantErr: 8.59341 batch_time=0.44470 
Train Epoch: 40 [233/500 14912/32000 (47%)] Loss: 0.06226 (QuantReg: 8.49962) QuantErr: 8.49962 batch_time=0.43484 
Train Epoch: 40 [241/500 15424/32000 (48%)] Loss: 0.02700 (QuantReg: 8.55959) QuantErr: 8.55959 batch_time=0.43985 
Train Epoch: 40 [249/500 15936/32000 (50%)] Loss: 0.02639 (QuantReg: 8.71756) QuantErr: 8.71756 batch_time=0.44061 
Train Epoch: 40 [257/500 16448/32000 (51%)] Loss: 0.02677 (QuantReg: 8.77862) QuantErr: 8.77862 batch_time=0.83973 
Train Epoch: 40 [265/500 16960/32000 (53%)] Loss: 0.07215 (QuantReg: 8.61963) QuantErr: 8.61963 batch_time=0.44506 
Train Epoch: 40 [273/500 17472/32000 (55%)] Loss: 0.02761 (QuantReg: 8.80852) QuantErr: 8.80852 batch_time=0.44778 
Train Epoch: 40 [281/500 17984/32000 (56%)] Loss: 0.02193 (QuantReg: 8.62011) QuantErr: 8.62011 batch_time=0.75703 
Train Epoch: 40 [289/500 18496/32000 (58%)] Loss: 0.09647 (QuantReg: 8.59917) QuantErr: 8.59917 batch_time=0.44542 
Train Epoch: 40 [297/500 19008/32000 (59%)] Loss: 0.02446 (QuantReg: 8.70192) QuantErr: 8.70192 batch_time=0.44514 
Train Epoch: 40 [305/500 19520/32000 (61%)] Loss: 0.01942 (QuantReg: 8.90973) QuantErr: 8.90973 batch_time=0.44828 
Train Epoch: 40 [313/500 20032/32000 (63%)] Loss: 0.02303 (QuantReg: 8.83899) QuantErr: 8.83899 batch_time=0.44157 
Train Epoch: 40 [321/500 20544/32000 (64%)] Loss: 0.02435 (QuantReg: 8.94009) QuantErr: 8.94009 batch_time=0.86683 
Train Epoch: 40 [329/500 21056/32000 (66%)] Loss: 0.01986 (QuantReg: 8.83862) QuantErr: 8.83862 batch_time=0.44664 
Train Epoch: 40 [337/500 21568/32000 (67%)] Loss: 0.06319 (QuantReg: 8.66214) QuantErr: 8.66214 batch_time=0.44538 
Train Epoch: 40 [345/500 22080/32000 (69%)] Loss: 0.08625 (QuantReg: 8.72816) QuantErr: 8.72816 batch_time=0.76869 
Train Epoch: 40 [353/500 22592/32000 (71%)] Loss: 0.04368 (QuantReg: 8.65646) QuantErr: 8.65646 batch_time=0.45072 
Train Epoch: 40 [361/500 23104/32000 (72%)] Loss: 0.02657 (QuantReg: 8.67322) QuantErr: 8.67322 batch_time=0.44922 
Train Epoch: 40 [369/500 23616/32000 (74%)] Loss: 0.08317 (QuantReg: 8.59353) QuantErr: 8.59353 batch_time=0.45032 
Train Epoch: 40 [377/500 24128/32000 (75%)] Loss: 0.04117 (QuantReg: 8.71161) QuantErr: 8.71161 batch_time=0.44619 
Train Epoch: 40 [385/500 24640/32000 (77%)] Loss: 0.03769 (QuantReg: 8.55347) QuantErr: 8.55347 batch_time=0.96898 
Train Epoch: 40 [393/500 25152/32000 (79%)] Loss: 0.02434 (QuantReg: 8.79062) QuantErr: 8.79062 batch_time=0.44960 
Train Epoch: 40 [401/500 25664/32000 (80%)] Loss: 0.01610 (QuantReg: 8.58291) QuantErr: 8.58291 batch_time=0.45458 
Train Epoch: 40 [409/500 26176/32000 (82%)] Loss: 0.02265 (QuantReg: 8.58191) QuantErr: 8.58191 batch_time=0.74323 
Train Epoch: 40 [417/500 26688/32000 (83%)] Loss: 0.02808 (QuantReg: 8.71353) QuantErr: 8.71353 batch_time=0.46471 
Train Epoch: 40 [425/500 27200/32000 (85%)] Loss: 0.06379 (QuantReg: 8.56329) QuantErr: 8.56329 batch_time=0.45870 
Train Epoch: 40 [433/500 27712/32000 (87%)] Loss: 0.11393 (QuantReg: 8.91472) QuantErr: 8.91472 batch_time=0.44531 
Train Epoch: 40 [441/500 28224/32000 (88%)] Loss: 0.02538 (QuantReg: 8.70847) QuantErr: 8.70847 batch_time=0.44792 
Train Epoch: 40 [449/500 28736/32000 (90%)] Loss: 0.03768 (QuantReg: 8.61616) QuantErr: 8.61616 batch_time=0.85898 
Train Epoch: 40 [457/500 29248/32000 (91%)] Loss: 0.15123 (QuantReg: 8.57722) QuantErr: 8.57722 batch_time=0.44336 
Train Epoch: 40 [465/500 29760/32000 (93%)] Loss: 0.06918 (QuantReg: 8.51275) QuantErr: 8.51275 batch_time=0.45892 
Train Epoch: 40 [473/500 30272/32000 (95%)] Loss: 0.02540 (QuantReg: 8.71941) QuantErr: 8.71941 batch_time=0.73194 
Train Epoch: 40 [481/500 30784/32000 (96%)] Loss: 0.02532 (QuantReg: 8.77306) QuantErr: 8.77306 batch_time=0.43951 
Train Epoch: 40 [489/500 31296/32000 (98%)] Loss: 0.02874 (QuantReg: 8.72357) QuantErr: 8.72357 batch_time=0.44174 
Train Epoch: 40 [497/500 31808/32000 (99%)] Loss: 0.02649 (QuantReg: 8.64667) QuantErr: 8.64667 batch_time=0.44086 
Train Epoch: 40 codebook_update_time=1.64657
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_ActivityNet_bs64/checkpoint-epoch40.pth ...
Done in 4.966s
removing stale ckpt [epoch 39] [took 0.00s]
 epoch          : 40
 loss           : 0.039320216689258815
 quant_reg      : 8.70195009994507
 quant_err      : 8.70195009994507
 learning_rate  : 2.2799724167361374e-06
 n_samples      : 1280000
 n_steps        : 20000
 ActivityNet_val1_test/t2v_metrics/R1: 20.561317876754117
 ActivityNet_val1_test/t2v_metrics/R5: 50.78299776286354
 ActivityNet_val1_test/t2v_metrics/R10: 66.38194020744356
 ActivityNet_val1_test/t2v_metrics/R50: 89.18039454952206
 ActivityNet_val1_test/t2v_metrics/MedR: 5.0
 ActivityNet_val1_test/t2v_metrics/MeanR: 33.97722188326215
 ActivityNet_val1_test/t2v_metrics/geometric_mean_R1-R5-R10: 41.07772732462516
 ActivityNet_val1_test/v2t_metrics/R1: 20.561317876754117
 ActivityNet_val1_test/v2t_metrics/R5: 51.96257880821639
 ActivityNet_val1_test/v2t_metrics/R10: 68.13097417124263
 ActivityNet_val1_test/v2t_metrics/R50: 89.48545861297539
 ActivityNet_val1_test/v2t_metrics/MedR: 5.0
 ActivityNet_val1_test/v2t_metrics/MeanR: 31.10168802115111
 ActivityNet_val1_test/v2t_metrics/geometric_mean_R1-R5-R10: 41.753743031831775
 mnt_best       : 41.251529009943695
 not_improved_count: 17
Train Epoch: 41 [1/500 64/32000 (0%)] Loss: 0.03295 (QuantReg: 8.66200) QuantErr: 8.66200 batch_time=23.40927 
Train Epoch: 41 [9/500 576/32000 (2%)] Loss: 0.02813 (QuantReg: 8.63001) QuantErr: 8.63001 batch_time=0.50406 
Train Epoch: 41 [17/500 1088/32000 (3%)] Loss: 0.08250 (QuantReg: 8.78231) QuantErr: 8.78231 batch_time=0.43553 
Train Epoch: 41 [25/500 1600/32000 (5%)] Loss: 0.04202 (QuantReg: 8.57575) QuantErr: 8.57575 batch_time=0.45091 
Train Epoch: 41 [33/500 2112/32000 (7%)] Loss: 0.07135 (QuantReg: 8.67660) QuantErr: 8.67660 batch_time=0.43910 
Train Epoch: 41 [41/500 2624/32000 (8%)] Loss: 0.03204 (QuantReg: 8.71497) QuantErr: 8.71497 batch_time=0.44142 
Train Epoch: 41 [49/500 3136/32000 (10%)] Loss: 0.02381 (QuantReg: 8.63220) QuantErr: 8.63220 batch_time=0.44071 
Train Epoch: 41 [57/500 3648/32000 (11%)] Loss: 0.03675 (QuantReg: 8.79002) QuantErr: 8.79002 batch_time=0.44398 
Train Epoch: 41 [65/500 4160/32000 (13%)] Loss: 0.03095 (QuantReg: 8.67005) QuantErr: 8.67005 batch_time=0.44384 
Train Epoch: 41 [73/500 4672/32000 (15%)] Loss: 0.02496 (QuantReg: 8.58502) QuantErr: 8.58502 batch_time=0.50411 
Train Epoch: 41 [81/500 5184/32000 (16%)] Loss: 0.11742 (QuantReg: 8.52681) QuantErr: 8.52681 batch_time=0.43710 
Train Epoch: 41 [89/500 5696/32000 (18%)] Loss: 0.02264 (QuantReg: 8.76474) QuantErr: 8.76474 batch_time=0.43515 
Train Epoch: 41 [97/500 6208/32000 (19%)] Loss: 0.02919 (QuantReg: 8.63014) QuantErr: 8.63014 batch_time=0.46006 
Train Epoch: 41 [105/500 6720/32000 (21%)] Loss: 0.02859 (QuantReg: 8.61288) QuantErr: 8.61288 batch_time=0.43747 
Train Epoch: 41 [113/500 7232/32000 (23%)] Loss: 0.06808 (QuantReg: 8.84124) QuantErr: 8.84124 batch_time=0.44094 
Train Epoch: 41 [121/500 7744/32000 (24%)] Loss: 0.02956 (QuantReg: 8.68784) QuantErr: 8.68784 batch_time=0.43892 
Train Epoch: 41 [129/500 8256/32000 (26%)] Loss: 0.02845 (QuantReg: 8.77496) QuantErr: 8.77496 batch_time=0.43423 
Train Epoch: 41 [137/500 8768/32000 (27%)] Loss: 0.08352 (QuantReg: 8.46912) QuantErr: 8.46912 batch_time=0.50400 
Train Epoch: 41 [145/500 9280/32000 (29%)] Loss: 0.03352 (QuantReg: 8.58606) QuantErr: 8.58606 batch_time=0.44005 
Train Epoch: 41 [153/500 9792/32000 (31%)] Loss: 0.03045 (QuantReg: 8.46974) QuantErr: 8.46974 batch_time=0.44378 
Train Epoch: 41 [161/500 10304/32000 (32%)] Loss: 0.02317 (QuantReg: 8.66543) QuantErr: 8.66543 batch_time=0.45402 
Train Epoch: 41 [169/500 10816/32000 (34%)] Loss: 0.05382 (QuantReg: 8.66918) QuantErr: 8.66918 batch_time=0.43994 
Train Epoch: 41 [177/500 11328/32000 (35%)] Loss: 0.01885 (QuantReg: 8.69375) QuantErr: 8.69375 batch_time=0.43559 
Train Epoch: 41 [185/500 11840/32000 (37%)] Loss: 0.06792 (QuantReg: 8.66195) QuantErr: 8.66195 batch_time=0.43851 
Train Epoch: 41 [193/500 12352/32000 (39%)] Loss: 0.01935 (QuantReg: 8.69473) QuantErr: 8.69473 batch_time=0.43193 
Train Epoch: 41 [201/500 12864/32000 (40%)] Loss: 0.08158 (QuantReg: 8.36185) QuantErr: 8.36185 batch_time=0.50069 
Train Epoch: 41 [209/500 13376/32000 (42%)] Loss: 0.03207 (QuantReg: 8.82409) QuantErr: 8.82409 batch_time=0.44017 
Train Epoch: 41 [217/500 13888/32000 (43%)] Loss: 0.02818 (QuantReg: 8.68423) QuantErr: 8.68423 batch_time=0.43789 
Train Epoch: 41 [225/500 14400/32000 (45%)] Loss: 0.02607 (QuantReg: 8.60073) QuantErr: 8.60073 batch_time=0.44363 
Train Epoch: 41 [233/500 14912/32000 (47%)] Loss: 0.06337 (QuantReg: 8.54733) QuantErr: 8.54733 batch_time=0.44001 
Train Epoch: 41 [241/500 15424/32000 (48%)] Loss: 0.03844 (QuantReg: 8.79922) QuantErr: 8.79922 batch_time=0.43612 
Train Epoch: 41 [249/500 15936/32000 (50%)] Loss: 0.06725 (QuantReg: 8.71564) QuantErr: 8.71564 batch_time=0.44448 
Train Epoch: 41 [257/500 16448/32000 (51%)] Loss: 0.11643 (QuantReg: 8.65691) QuantErr: 8.65691 batch_time=0.44717 
Train Epoch: 41 [265/500 16960/32000 (53%)] Loss: 0.03348 (QuantReg: 8.83405) QuantErr: 8.83405 batch_time=0.51237 
Train Epoch: 41 [273/500 17472/32000 (55%)] Loss: 0.03008 (QuantReg: 8.68678) QuantErr: 8.68678 batch_time=0.46041 
Train Epoch: 41 [281/500 17984/32000 (56%)] Loss: 0.02041 (QuantReg: 8.69310) QuantErr: 8.69310 batch_time=0.71963 
Train Epoch: 41 [289/500 18496/32000 (58%)] Loss: 0.03698 (QuantReg: 8.67684) QuantErr: 8.67684 batch_time=0.44803 
Train Epoch: 41 [297/500 19008/32000 (59%)] Loss: 0.02872 (QuantReg: 8.69444) QuantErr: 8.69444 batch_time=0.44741 
Train Epoch: 41 [305/500 19520/32000 (61%)] Loss: 0.02149 (QuantReg: 8.72277) QuantErr: 8.72277 batch_time=0.43761 
Train Epoch: 41 [313/500 20032/32000 (63%)] Loss: 0.03190 (QuantReg: 8.63529) QuantErr: 8.63529 batch_time=0.44037 
Train Epoch: 41 [321/500 20544/32000 (64%)] Loss: 0.01971 (QuantReg: 8.76966) QuantErr: 8.76966 batch_time=0.43462 
Train Epoch: 41 [329/500 21056/32000 (66%)] Loss: 0.04902 (QuantReg: 8.67448) QuantErr: 8.67448 batch_time=0.50165 
Train Epoch: 41 [337/500 21568/32000 (67%)] Loss: 0.03761 (QuantReg: 8.73454) QuantErr: 8.73454 batch_time=0.43639 
Train Epoch: 41 [345/500 22080/32000 (69%)] Loss: 0.04457 (QuantReg: 8.70577) QuantErr: 8.70577 batch_time=0.44893 
Train Epoch: 41 [353/500 22592/32000 (71%)] Loss: 0.06901 (QuantReg: 8.60636) QuantErr: 8.60636 batch_time=0.44139 
Train Epoch: 41 [361/500 23104/32000 (72%)] Loss: 0.07277 (QuantReg: 8.61989) QuantErr: 8.61989 batch_time=0.44476 
Train Epoch: 41 [369/500 23616/32000 (74%)] Loss: 0.02613 (QuantReg: 8.77894) QuantErr: 8.77894 batch_time=0.46333 
Train Epoch: 41 [377/500 24128/32000 (75%)] Loss: 0.03840 (QuantReg: 8.76319) QuantErr: 8.76319 batch_time=0.46718 
Train Epoch: 41 [385/500 24640/32000 (77%)] Loss: 0.03045 (QuantReg: 8.46109) QuantErr: 8.46109 batch_time=0.43595 
Train Epoch: 41 [393/500 25152/32000 (79%)] Loss: 0.02495 (QuantReg: 8.65774) QuantErr: 8.65774 batch_time=0.50973 
Train Epoch: 41 [401/500 25664/32000 (80%)] Loss: 0.02947 (QuantReg: 8.70938) QuantErr: 8.70938 batch_time=0.44181 
Train Epoch: 41 [409/500 26176/32000 (82%)] Loss: 0.02024 (QuantReg: 8.69520) QuantErr: 8.69520 batch_time=0.44303 
Train Epoch: 41 [417/500 26688/32000 (83%)] Loss: 0.02937 (QuantReg: 8.68584) QuantErr: 8.68584 batch_time=0.43970 
Train Epoch: 41 [425/500 27200/32000 (85%)] Loss: 0.08090 (QuantReg: 8.53596) QuantErr: 8.53596 batch_time=0.44126 
Train Epoch: 41 [433/500 27712/32000 (87%)] Loss: 0.01878 (QuantReg: 8.56002) QuantErr: 8.56002 batch_time=0.44212 
Train Epoch: 41 [441/500 28224/32000 (88%)] Loss: 0.05172 (QuantReg: 8.77084) QuantErr: 8.77084 batch_time=0.45002 
Train Epoch: 41 [449/500 28736/32000 (90%)] Loss: 0.06080 (QuantReg: 8.62379) QuantErr: 8.62379 batch_time=0.43752 
Train Epoch: 41 [457/500 29248/32000 (91%)] Loss: 0.04538 (QuantReg: 8.79216) QuantErr: 8.79216 batch_time=0.52704 
Train Epoch: 41 [465/500 29760/32000 (93%)] Loss: 0.04376 (QuantReg: 8.71037) QuantErr: 8.71037 batch_time=0.43995 
Train Epoch: 41 [473/500 30272/32000 (95%)] Loss: 0.03062 (QuantReg: 8.64847) QuantErr: 8.64847 batch_time=0.46920 
Train Epoch: 41 [481/500 30784/32000 (96%)] Loss: 0.05202 (QuantReg: 8.75059) QuantErr: 8.75059 batch_time=0.45274 
Train Epoch: 41 [489/500 31296/32000 (98%)] Loss: 0.01458 (QuantReg: 8.63357) QuantErr: 8.63357 batch_time=0.44611 
Train Epoch: 41 [497/500 31808/32000 (99%)] Loss: 0.02323 (QuantReg: 8.74908) QuantErr: 8.74908 batch_time=0.44461 
Train Epoch: 41 codebook_update_time=2.10402
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_ActivityNet_bs64/checkpoint-epoch41.pth ...
Done in 5.248s
Updating 'best' checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_ActivityNet_bs64/checkpoint-epoch41.pth ...
Done in 10.431s
removing stale ckpt [epoch 40] [took 0.01s]
 epoch          : 41
 loss           : 0.03956118554994464
 quant_reg      : 8.666942464828491
 quant_err      : 8.666942464828491
 learning_rate  : 1.9379765542257167e-06
 n_samples      : 1312000
 n_steps        : 20500
 ActivityNet_val1_test/t2v_metrics/R1: 20.622330689444784
 ActivityNet_val1_test/t2v_metrics/R5: 51.5965019320724
 ActivityNet_val1_test/t2v_metrics/R10: 66.91071791742932
 ActivityNet_val1_test/t2v_metrics/R50: 88.93634329875941
 ActivityNet_val1_test/t2v_metrics/MedR: 5.0
 ActivityNet_val1_test/t2v_metrics/MeanR: 33.60626398210291
 ActivityNet_val1_test/t2v_metrics/geometric_mean_R1-R5-R10: 41.446185373070655
 ActivityNet_val1_test/v2t_metrics/R1: 20.58165548098434
 ActivityNet_val1_test/v2t_metrics/R5: 51.63717714053284
 ActivityNet_val1_test/v2t_metrics/R10: 67.76489729509863
 ActivityNet_val1_test/v2t_metrics/R50: 89.40410819605451
 ActivityNet_val1_test/v2t_metrics/MedR: 5.0
 ActivityNet_val1_test/v2t_metrics/MeanR: 31.520642668293675
 ActivityNet_val1_test/v2t_metrics/geometric_mean_R1-R5-R10: 41.60535133504599
 mnt_best       : 41.446185373070655
 not_improved_count: 0
Train Epoch: 42 [1/500 64/32000 (0%)] Loss: 0.02482 (QuantReg: 8.57644) QuantErr: 8.57644 batch_time=23.43299 
Train Epoch: 42 [9/500 576/32000 (2%)] Loss: 0.02453 (QuantReg: 8.72655) QuantErr: 8.72655 batch_time=0.44173 
Train Epoch: 42 [17/500 1088/32000 (3%)] Loss: 0.12983 (QuantReg: 8.81234) QuantErr: 8.81234 batch_time=0.44187 
Train Epoch: 42 [25/500 1600/32000 (5%)] Loss: 0.02873 (QuantReg: 8.43718) QuantErr: 8.43718 batch_time=0.51018 
Train Epoch: 42 [33/500 2112/32000 (7%)] Loss: 0.01791 (QuantReg: 8.73232) QuantErr: 8.73232 batch_time=0.44552 
Train Epoch: 42 [41/500 2624/32000 (8%)] Loss: 0.03989 (QuantReg: 8.65741) QuantErr: 8.65741 batch_time=0.44480 
Train Epoch: 42 [49/500 3136/32000 (10%)] Loss: 0.02521 (QuantReg: 8.57427) QuantErr: 8.57427 batch_time=0.45884 
Train Epoch: 42 [57/500 3648/32000 (11%)] Loss: 0.06628 (QuantReg: 8.62370) QuantErr: 8.62370 batch_time=0.43920 
Train Epoch: 42 [65/500 4160/32000 (13%)] Loss: 0.01808 (QuantReg: 8.71466) QuantErr: 8.71466 batch_time=0.43681 
Train Epoch: 42 [73/500 4672/32000 (15%)] Loss: 0.02564 (QuantReg: 8.67995) QuantErr: 8.67995 batch_time=0.44368 
Train Epoch: 42 [81/500 5184/32000 (16%)] Loss: 0.01880 (QuantReg: 8.50327) QuantErr: 8.50327 batch_time=0.44495 
Train Epoch: 42 [89/500 5696/32000 (18%)] Loss: 0.07025 (QuantReg: 8.45910) QuantErr: 8.45910 batch_time=0.51380 
Train Epoch: 42 [97/500 6208/32000 (19%)] Loss: 0.03038 (QuantReg: 8.52254) QuantErr: 8.52254 batch_time=0.44449 
Train Epoch: 42 [105/500 6720/32000 (21%)] Loss: 0.03244 (QuantReg: 8.73805) QuantErr: 8.73805 batch_time=0.44451 
Train Epoch: 42 [113/500 7232/32000 (23%)] Loss: 0.03581 (QuantReg: 8.62457) QuantErr: 8.62457 batch_time=0.44189 
Train Epoch: 42 [121/500 7744/32000 (24%)] Loss: 0.03385 (QuantReg: 8.59134) QuantErr: 8.59134 batch_time=0.44322 
Train Epoch: 42 [129/500 8256/32000 (26%)] Loss: 0.05073 (QuantReg: 8.80350) QuantErr: 8.80350 batch_time=0.47838 
Train Epoch: 42 [137/500 8768/32000 (27%)] Loss: 0.02654 (QuantReg: 8.75294) QuantErr: 8.75294 batch_time=0.44448 
Train Epoch: 42 [145/500 9280/32000 (29%)] Loss: 0.07657 (QuantReg: 8.57463) QuantErr: 8.57463 batch_time=0.43837 
Train Epoch: 42 [153/500 9792/32000 (31%)] Loss: 0.06711 (QuantReg: 8.78777) QuantErr: 8.78777 batch_time=0.51134 
Train Epoch: 42 [161/500 10304/32000 (32%)] Loss: 0.04423 (QuantReg: 8.56254) QuantErr: 8.56254 batch_time=0.43973 
Train Epoch: 42 [169/500 10816/32000 (34%)] Loss: 0.03436 (QuantReg: 8.55885) QuantErr: 8.55885 batch_time=0.45812 
Train Epoch: 42 [177/500 11328/32000 (35%)] Loss: 0.03253 (QuantReg: 8.73807) QuantErr: 8.73807 batch_time=0.47699 
Train Epoch: 42 [185/500 11840/32000 (37%)] Loss: 0.02427 (QuantReg: 8.57697) QuantErr: 8.57697 batch_time=0.44450 
Train Epoch: 42 [193/500 12352/32000 (39%)] Loss: 0.03627 (QuantReg: 8.69179) QuantErr: 8.69179 batch_time=0.43845 
Train Epoch: 42 [201/500 12864/32000 (40%)] Loss: 0.02777 (QuantReg: 8.54302) QuantErr: 8.54302 batch_time=0.43928 
Train Epoch: 42 [209/500 13376/32000 (42%)] Loss: 0.03005 (QuantReg: 8.60443) QuantErr: 8.60443 batch_time=0.43960 
Train Epoch: 42 [217/500 13888/32000 (43%)] Loss: 0.07817 (QuantReg: 8.76067) QuantErr: 8.76067 batch_time=0.52760 
Train Epoch: 42 [225/500 14400/32000 (45%)] Loss: 0.03990 (QuantReg: 8.72421) QuantErr: 8.72421 batch_time=0.46940 
Train Epoch: 42 [233/500 14912/32000 (47%)] Loss: 0.03262 (QuantReg: 8.55141) QuantErr: 8.55141 batch_time=0.44045 
Train Epoch: 42 [241/500 15424/32000 (48%)] Loss: 0.05568 (QuantReg: 8.61391) QuantErr: 8.61391 batch_time=0.43922 
Train Epoch: 42 [249/500 15936/32000 (50%)] Loss: 0.11658 (QuantReg: 8.56244) QuantErr: 8.56244 batch_time=0.44389 
Train Epoch: 42 [257/500 16448/32000 (51%)] Loss: 0.02314 (QuantReg: 8.64506) QuantErr: 8.64506 batch_time=0.44255 
Train Epoch: 42 [265/500 16960/32000 (53%)] Loss: 0.07635 (QuantReg: 8.77135) QuantErr: 8.77135 batch_time=0.47908 
Train Epoch: 42 [273/500 17472/32000 (55%)] Loss: 0.02331 (QuantReg: 8.67349) QuantErr: 8.67349 batch_time=0.47602 
Train Epoch: 42 [281/500 17984/32000 (56%)] Loss: 0.03166 (QuantReg: 8.54957) QuantErr: 8.54957 batch_time=0.53675 
Train Epoch: 42 [289/500 18496/32000 (58%)] Loss: 0.07185 (QuantReg: 8.70289) QuantErr: 8.70289 batch_time=0.47472 
Train Epoch: 42 [297/500 19008/32000 (59%)] Loss: 0.02750 (QuantReg: 8.61633) QuantErr: 8.61633 batch_time=0.44547 
Train Epoch: 42 [305/500 19520/32000 (61%)] Loss: 0.03282 (QuantReg: 8.63893) QuantErr: 8.63893 batch_time=0.44189 
Train Epoch: 42 [313/500 20032/32000 (63%)] Loss: 0.06964 (QuantReg: 8.52397) QuantErr: 8.52397 batch_time=0.44633 
Train Epoch: 42 [321/500 20544/32000 (64%)] Loss: 0.03395 (QuantReg: 8.69312) QuantErr: 8.69312 batch_time=0.44386 
Train Epoch: 42 [329/500 21056/32000 (66%)] Loss: 0.10379 (QuantReg: 8.37328) QuantErr: 8.37328 batch_time=0.44339 
Train Epoch: 42 [337/500 21568/32000 (67%)] Loss: 0.02746 (QuantReg: 8.47877) QuantErr: 8.47877 batch_time=0.46079 
Train Epoch: 42 [345/500 22080/32000 (69%)] Loss: 0.04929 (QuantReg: 8.75509) QuantErr: 8.75509 batch_time=0.51494 
Train Epoch: 42 [353/500 22592/32000 (71%)] Loss: 0.04852 (QuantReg: 8.47801) QuantErr: 8.47801 batch_time=0.44720 
Train Epoch: 42 [361/500 23104/32000 (72%)] Loss: 0.03596 (QuantReg: 8.62283) QuantErr: 8.62283 batch_time=0.43932 
Train Epoch: 42 [369/500 23616/32000 (74%)] Loss: 0.01694 (QuantReg: 8.56024) QuantErr: 8.56024 batch_time=0.45197 
Train Epoch: 42 [377/500 24128/32000 (75%)] Loss: 0.06726 (QuantReg: 8.64987) QuantErr: 8.64987 batch_time=0.44591 
Train Epoch: 42 [385/500 24640/32000 (77%)] Loss: 0.02542 (QuantReg: 8.67064) QuantErr: 8.67064 batch_time=0.44554 
Train Epoch: 42 [393/500 25152/32000 (79%)] Loss: 0.01454 (QuantReg: 8.58501) QuantErr: 8.58501 batch_time=0.44453 
Train Epoch: 42 [401/500 25664/32000 (80%)] Loss: 0.02504 (QuantReg: 8.48757) QuantErr: 8.48757 batch_time=0.44526 
Train Epoch: 42 [409/500 26176/32000 (82%)] Loss: 0.02452 (QuantReg: 8.62911) QuantErr: 8.62911 batch_time=0.50232 
Train Epoch: 42 [417/500 26688/32000 (83%)] Loss: 0.06732 (QuantReg: 8.69232) QuantErr: 8.69232 batch_time=0.50831 
Train Epoch: 42 [425/500 27200/32000 (85%)] Loss: 0.01629 (QuantReg: 8.59808) QuantErr: 8.59808 batch_time=0.44361 
Train Epoch: 42 [433/500 27712/32000 (87%)] Loss: 0.02871 (QuantReg: 8.61488) QuantErr: 8.61488 batch_time=0.44951 
Train Epoch: 42 [441/500 28224/32000 (88%)] Loss: 0.02418 (QuantReg: 8.52586) QuantErr: 8.52586 batch_time=0.44279 
Train Epoch: 42 [449/500 28736/32000 (90%)] Loss: 0.03270 (QuantReg: 8.45929) QuantErr: 8.45929 batch_time=0.43093 
Train Epoch: 42 [457/500 29248/32000 (91%)] Loss: 0.03360 (QuantReg: 8.74453) QuantErr: 8.74453 batch_time=0.44344 
Train Epoch: 42 [465/500 29760/32000 (93%)] Loss: 0.02550 (QuantReg: 8.57109) QuantErr: 8.57109 batch_time=0.44656 
Train Epoch: 42 [473/500 30272/32000 (95%)] Loss: 0.02247 (QuantReg: 8.70152) QuantErr: 8.70152 batch_time=0.54127 
Train Epoch: 42 [481/500 30784/32000 (96%)] Loss: 0.02784 (QuantReg: 8.65801) QuantErr: 8.65801 batch_time=0.44706 
Train Epoch: 42 [489/500 31296/32000 (98%)] Loss: 0.02388 (QuantReg: 8.71016) QuantErr: 8.71016 batch_time=0.45923 
Train Epoch: 42 [497/500 31808/32000 (99%)] Loss: 0.02074 (QuantReg: 8.76510) QuantErr: 8.76510 batch_time=0.44629 
Train Epoch: 42 codebook_update_time=1.69041
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_ActivityNet_bs64/checkpoint-epoch42.pth ...
Done in 3.966s
removing stale ckpt [epoch 41] [took 0.00s]
 epoch          : 42
 loss           : 0.03940428459830582
 quant_reg      : 8.636842449188233
 quant_err      : 8.636842449188233
 learning_rate  : 1.9379765542257167e-06
 n_samples      : 1344000
 n_steps        : 21000
 ActivityNet_val1_test/t2v_metrics/R1: 20.479967459833233
 ActivityNet_val1_test/t2v_metrics/R5: 51.21008745169819
 ActivityNet_val1_test/t2v_metrics/R10: 67.09375635550133
 ActivityNet_val1_test/t2v_metrics/R50: 89.26174496644295
 ActivityNet_val1_test/t2v_metrics/MedR: 5.0
 ActivityNet_val1_test/t2v_metrics/MeanR: 33.339637990644704
 ActivityNet_val1_test/t2v_metrics/geometric_mean_R1-R5-R10: 41.28468376735507
 ActivityNet_val1_test/v2t_metrics/R1: 20.90705714866789
 ActivityNet_val1_test/v2t_metrics/R5: 52.16595485051861
 ActivityNet_val1_test/v2t_metrics/R10: 67.68354687817775
 ActivityNet_val1_test/v2t_metrics/R50: 89.5871466341265
 ActivityNet_val1_test/v2t_metrics/MedR: 5.0
 ActivityNet_val1_test/v2t_metrics/MeanR: 31.054504779336995
 ActivityNet_val1_test/v2t_metrics/geometric_mean_R1-R5-R10: 41.94894654455013
 mnt_best       : 41.446185373070655
 not_improved_count: 1
Train Epoch: 43 [1/500 64/32000 (0%)] Loss: 0.06106 (QuantReg: 8.77618) QuantErr: 8.77618 batch_time=22.53292 
Train Epoch: 43 [9/500 576/32000 (2%)] Loss: 0.02034 (QuantReg: 8.72289) QuantErr: 8.72289 batch_time=0.44006 
Train Epoch: 43 [17/500 1088/32000 (3%)] Loss: 0.02316 (QuantReg: 8.65815) QuantErr: 8.65815 batch_time=1.41062 
Train Epoch: 43 [25/500 1600/32000 (5%)] Loss: 0.04479 (QuantReg: 8.60222) QuantErr: 8.60222 batch_time=0.44100 
Train Epoch: 43 [33/500 2112/32000 (7%)] Loss: 0.02813 (QuantReg: 8.60031) QuantErr: 8.60031 batch_time=0.45697 
Train Epoch: 43 [41/500 2624/32000 (8%)] Loss: 0.02682 (QuantReg: 8.48935) QuantErr: 8.48935 batch_time=0.43842 
Train Epoch: 43 [49/500 3136/32000 (10%)] Loss: 0.03328 (QuantReg: 8.66420) QuantErr: 8.66420 batch_time=0.44304 
Train Epoch: 43 [57/500 3648/32000 (11%)] Loss: 0.02506 (QuantReg: 8.62412) QuantErr: 8.62412 batch_time=0.44903 
Train Epoch: 43 [65/500 4160/32000 (13%)] Loss: 0.03241 (QuantReg: 8.74682) QuantErr: 8.74682 batch_time=0.44911 
Train Epoch: 43 [73/500 4672/32000 (15%)] Loss: 0.02483 (QuantReg: 8.64710) QuantErr: 8.64710 batch_time=0.45091 
Train Epoch: 43 [81/500 5184/32000 (16%)] Loss: 0.08568 (QuantReg: 8.69601) QuantErr: 8.69601 batch_time=1.20107 
Train Epoch: 43 [89/500 5696/32000 (18%)] Loss: 0.05111 (QuantReg: 8.69661) QuantErr: 8.69661 batch_time=0.44054 
Train Epoch: 43 [97/500 6208/32000 (19%)] Loss: 0.09229 (QuantReg: 8.53217) QuantErr: 8.53217 batch_time=0.45326 
Train Epoch: 43 [105/500 6720/32000 (21%)] Loss: 0.04258 (QuantReg: 8.55475) QuantErr: 8.55475 batch_time=0.43825 
Train Epoch: 43 [113/500 7232/32000 (23%)] Loss: 0.07860 (QuantReg: 8.53081) QuantErr: 8.53081 batch_time=0.43723 
Train Epoch: 43 [121/500 7744/32000 (24%)] Loss: 0.07289 (QuantReg: 8.43710) QuantErr: 8.43710 batch_time=0.44368 
Train Epoch: 43 [129/500 8256/32000 (26%)] Loss: 0.02000 (QuantReg: 8.36984) QuantErr: 8.36984 batch_time=0.43601 
Train Epoch: 43 [137/500 8768/32000 (27%)] Loss: 0.03572 (QuantReg: 8.72921) QuantErr: 8.72921 batch_time=0.44329 
Train Epoch: 43 [145/500 9280/32000 (29%)] Loss: 0.02368 (QuantReg: 8.67787) QuantErr: 8.67787 batch_time=1.46124 
Train Epoch: 43 [153/500 9792/32000 (31%)] Loss: 0.03736 (QuantReg: 8.50899) QuantErr: 8.50899 batch_time=0.43721 
Train Epoch: 43 [161/500 10304/32000 (32%)] Loss: 0.02532 (QuantReg: 8.51300) QuantErr: 8.51300 batch_time=0.44321 
Train Epoch: 43 [169/500 10816/32000 (34%)] Loss: 0.05413 (QuantReg: 8.54246) QuantErr: 8.54246 batch_time=0.43877 
Train Epoch: 43 [177/500 11328/32000 (35%)] Loss: 0.02505 (QuantReg: 8.63460) QuantErr: 8.63460 batch_time=0.44818 
Train Epoch: 43 [185/500 11840/32000 (37%)] Loss: 0.03279 (QuantReg: 8.52151) QuantErr: 8.52151 batch_time=0.44243 
Train Epoch: 43 [193/500 12352/32000 (39%)] Loss: 0.02711 (QuantReg: 8.50359) QuantErr: 8.50359 batch_time=0.43966 
Train Epoch: 43 [201/500 12864/32000 (40%)] Loss: 0.02493 (QuantReg: 8.48420) QuantErr: 8.48420 batch_time=0.44591 
Train Epoch: 43 [209/500 13376/32000 (42%)] Loss: 0.02164 (QuantReg: 8.55822) QuantErr: 8.55822 batch_time=1.22072 
Train Epoch: 43 [217/500 13888/32000 (43%)] Loss: 0.03111 (QuantReg: 8.41590) QuantErr: 8.41590 batch_time=0.44049 
Train Epoch: 43 [225/500 14400/32000 (45%)] Loss: 0.05969 (QuantReg: 8.52638) QuantErr: 8.52638 batch_time=0.44171 
Train Epoch: 43 [233/500 14912/32000 (47%)] Loss: 0.02524 (QuantReg: 8.69357) QuantErr: 8.69357 batch_time=0.43792 
Train Epoch: 43 [241/500 15424/32000 (48%)] Loss: 0.05008 (QuantReg: 8.78302) QuantErr: 8.78302 batch_time=0.43845 
Train Epoch: 43 [249/500 15936/32000 (50%)] Loss: 0.01739 (QuantReg: 8.44411) QuantErr: 8.44411 batch_time=0.43918 
Train Epoch: 43 [257/500 16448/32000 (51%)] Loss: 0.04238 (QuantReg: 8.62848) QuantErr: 8.62848 batch_time=0.43834 
Train Epoch: 43 [265/500 16960/32000 (53%)] Loss: 0.02115 (QuantReg: 8.59912) QuantErr: 8.59912 batch_time=0.44400 
Train Epoch: 43 [273/500 17472/32000 (55%)] Loss: 0.11785 (QuantReg: 8.50647) QuantErr: 8.50647 batch_time=1.25901 
Train Epoch: 43 [281/500 17984/32000 (56%)] Loss: 0.02406 (QuantReg: 8.72530) QuantErr: 8.72530 batch_time=0.43994 
Train Epoch: 43 [289/500 18496/32000 (58%)] Loss: 0.02599 (QuantReg: 8.68817) QuantErr: 8.68817 batch_time=0.44161 
Train Epoch: 43 [297/500 19008/32000 (59%)] Loss: 0.04756 (QuantReg: 8.54309) QuantErr: 8.54309 batch_time=0.44278 
Train Epoch: 43 [305/500 19520/32000 (61%)] Loss: 0.02933 (QuantReg: 8.48120) QuantErr: 8.48120 batch_time=0.44163 
Train Epoch: 43 [313/500 20032/32000 (63%)] Loss: 0.09222 (QuantReg: 8.48795) QuantErr: 8.48795 batch_time=0.44398 
Train Epoch: 43 [321/500 20544/32000 (64%)] Loss: 0.06351 (QuantReg: 8.50472) QuantErr: 8.50472 batch_time=0.44219 
Train Epoch: 43 [329/500 21056/32000 (66%)] Loss: 0.02652 (QuantReg: 8.48720) QuantErr: 8.48720 batch_time=0.43953 
Train Epoch: 43 [337/500 21568/32000 (67%)] Loss: 0.06297 (QuantReg: 8.71031) QuantErr: 8.71031 batch_time=1.19955 
Train Epoch: 43 [345/500 22080/32000 (69%)] Loss: 0.06942 (QuantReg: 8.56262) QuantErr: 8.56262 batch_time=0.44582 
Train Epoch: 43 [353/500 22592/32000 (71%)] Loss: 0.08454 (QuantReg: 8.68893) QuantErr: 8.68893 batch_time=0.44575 
Train Epoch: 43 [361/500 23104/32000 (72%)] Loss: 0.02953 (QuantReg: 8.67890) QuantErr: 8.67890 batch_time=0.43950 
Train Epoch: 43 [369/500 23616/32000 (74%)] Loss: 0.07068 (QuantReg: 8.65521) QuantErr: 8.65521 batch_time=0.45281 
Train Epoch: 43 [377/500 24128/32000 (75%)] Loss: 0.02998 (QuantReg: 8.83472) QuantErr: 8.83472 batch_time=0.44268 
Train Epoch: 43 [385/500 24640/32000 (77%)] Loss: 0.04738 (QuantReg: 8.52212) QuantErr: 8.52212 batch_time=0.45992 
Train Epoch: 43 [393/500 25152/32000 (79%)] Loss: 0.04292 (QuantReg: 8.38177) QuantErr: 8.38177 batch_time=0.44632 
Train Epoch: 43 [401/500 25664/32000 (80%)] Loss: 0.02711 (QuantReg: 8.64798) QuantErr: 8.64798 batch_time=1.17446 
Train Epoch: 43 [409/500 26176/32000 (82%)] Loss: 0.01914 (QuantReg: 8.56514) QuantErr: 8.56514 batch_time=0.46218 
Train Epoch: 43 [417/500 26688/32000 (83%)] Loss: 0.02557 (QuantReg: 8.76920) QuantErr: 8.76920 batch_time=0.44641 
Train Epoch: 43 [425/500 27200/32000 (85%)] Loss: 0.04492 (QuantReg: 8.52690) QuantErr: 8.52690 batch_time=0.44030 
Train Epoch: 43 [433/500 27712/32000 (87%)] Loss: 0.02619 (QuantReg: 8.56270) QuantErr: 8.56270 batch_time=0.44862 
Train Epoch: 43 [441/500 28224/32000 (88%)] Loss: 0.02995 (QuantReg: 8.66969) QuantErr: 8.66969 batch_time=0.44721 
Train Epoch: 43 [449/500 28736/32000 (90%)] Loss: 0.03079 (QuantReg: 8.77139) QuantErr: 8.77139 batch_time=0.45256 
Train Epoch: 43 [457/500 29248/32000 (91%)] Loss: 0.02853 (QuantReg: 8.62454) QuantErr: 8.62454 batch_time=0.45709 
Train Epoch: 43 [465/500 29760/32000 (93%)] Loss: 0.02280 (QuantReg: 8.73866) QuantErr: 8.73866 batch_time=1.26775 
Train Epoch: 43 [473/500 30272/32000 (95%)] Loss: 0.01965 (QuantReg: 8.57011) QuantErr: 8.57011 batch_time=0.47153 
Train Epoch: 43 [481/500 30784/32000 (96%)] Loss: 0.02436 (QuantReg: 8.53384) QuantErr: 8.53384 batch_time=0.48002 
Train Epoch: 43 [489/500 31296/32000 (98%)] Loss: 0.05568 (QuantReg: 8.45798) QuantErr: 8.45798 batch_time=0.44548 
Train Epoch: 43 [497/500 31808/32000 (99%)] Loss: 0.01779 (QuantReg: 8.63353) QuantErr: 8.63353 batch_time=0.44089 
Train Epoch: 43 codebook_update_time=1.63715
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_ActivityNet_bs64/checkpoint-epoch43.pth ...
Done in 5.897s
removing stale ckpt [epoch 42] [took 0.06s]
 epoch          : 43
 loss           : 0.03911736840009689
 quant_reg      : 8.598767278671264
 quant_err      : 8.598767278671264
 learning_rate  : 1.6472800710918591e-06
 n_samples      : 1376000
 n_steps        : 21500
 ActivityNet_val1_test/t2v_metrics/R1: 20.520642668293675
 ActivityNet_val1_test/t2v_metrics/R5: 51.08806182631686
 ActivityNet_val1_test/t2v_metrics/R10: 66.38194020744356
 ActivityNet_val1_test/t2v_metrics/R50: 89.2210697579825
 ActivityNet_val1_test/t2v_metrics/MedR: 5.0
 ActivityNet_val1_test/t2v_metrics/MeanR: 33.77323571283303
 ActivityNet_val1_test/t2v_metrics/geometric_mean_R1-R5-R10: 41.13265808508984
 ActivityNet_val1_test/v2t_metrics/R1: 20.561317876754117
 ActivityNet_val1_test/v2t_metrics/R5: 52.003254016676834
 ActivityNet_val1_test/v2t_metrics/R10: 67.94793573317064
 ActivityNet_val1_test/v2t_metrics/R50: 89.64815944681716
 ActivityNet_val1_test/v2t_metrics/MedR: 5.0
 ActivityNet_val1_test/v2t_metrics/MeanR: 31.141549725442342
 ActivityNet_val1_test/v2t_metrics/geometric_mean_R1-R5-R10: 41.7272001303707
 mnt_best       : 41.446185373070655
 not_improved_count: 2
Train Epoch: 44 [1/500 64/32000 (0%)] Loss: 0.02947 (QuantReg: 8.55124) QuantErr: 8.55124 batch_time=24.16764 
Train Epoch: 44 [9/500 576/32000 (2%)] Loss: 0.02720 (QuantReg: 8.69082) QuantErr: 8.69082 batch_time=0.97628 
Train Epoch: 44 [17/500 1088/32000 (3%)] Loss: 0.02619 (QuantReg: 8.68761) QuantErr: 8.68761 batch_time=0.44248 
Train Epoch: 44 [25/500 1600/32000 (5%)] Loss: 0.02370 (QuantReg: 8.67173) QuantErr: 8.67173 batch_time=0.44431 
Train Epoch: 44 [33/500 2112/32000 (7%)] Loss: 0.02965 (QuantReg: 8.63079) QuantErr: 8.63079 batch_time=0.44176 
Train Epoch: 44 [41/500 2624/32000 (8%)] Loss: 0.02206 (QuantReg: 8.62421) QuantErr: 8.62421 batch_time=0.44313 
Train Epoch: 44 [49/500 3136/32000 (10%)] Loss: 0.03994 (QuantReg: 8.60433) QuantErr: 8.60433 batch_time=0.54220 
Train Epoch: 44 [57/500 3648/32000 (11%)] Loss: 0.03627 (QuantReg: 8.46539) QuantErr: 8.46539 batch_time=0.44084 
Train Epoch: 44 [65/500 4160/32000 (13%)] Loss: 0.02160 (QuantReg: 8.48298) QuantErr: 8.48298 batch_time=0.69310 
Train Epoch: 44 [73/500 4672/32000 (15%)] Loss: 0.07168 (QuantReg: 8.50796) QuantErr: 8.50796 batch_time=0.86965 
Train Epoch: 44 [81/500 5184/32000 (16%)] Loss: 0.04611 (QuantReg: 8.60020) QuantErr: 8.60020 batch_time=0.44200 
Train Epoch: 44 [89/500 5696/32000 (18%)] Loss: 0.06330 (QuantReg: 8.74888) QuantErr: 8.74888 batch_time=0.44009 
Train Epoch: 44 [97/500 6208/32000 (19%)] Loss: 0.03648 (QuantReg: 8.65918) QuantErr: 8.65918 batch_time=0.43982 
Train Epoch: 44 [105/500 6720/32000 (21%)] Loss: 0.02888 (QuantReg: 8.53971) QuantErr: 8.53971 batch_time=0.44455 
Train Epoch: 44 [113/500 7232/32000 (23%)] Loss: 0.05428 (QuantReg: 8.55618) QuantErr: 8.55618 batch_time=0.54101 
Train Epoch: 44 [121/500 7744/32000 (24%)] Loss: 0.02885 (QuantReg: 8.57174) QuantErr: 8.57174 batch_time=0.48082 
Train Epoch: 44 [129/500 8256/32000 (26%)] Loss: 0.02434 (QuantReg: 8.68823) QuantErr: 8.68823 batch_time=0.70148 
Train Epoch: 44 [137/500 8768/32000 (27%)] Loss: 0.02940 (QuantReg: 8.63022) QuantErr: 8.63022 batch_time=0.88253 
Train Epoch: 44 [145/500 9280/32000 (29%)] Loss: 0.02056 (QuantReg: 8.49002) QuantErr: 8.49002 batch_time=0.44104 
Train Epoch: 44 [153/500 9792/32000 (31%)] Loss: 0.01748 (QuantReg: 8.57592) QuantErr: 8.57592 batch_time=0.43829 
Train Epoch: 44 [161/500 10304/32000 (32%)] Loss: 0.07088 (QuantReg: 8.58410) QuantErr: 8.58410 batch_time=0.44465 
Train Epoch: 44 [169/500 10816/32000 (34%)] Loss: 0.03217 (QuantReg: 8.34386) QuantErr: 8.34386 batch_time=0.45081 
Train Epoch: 44 [177/500 11328/32000 (35%)] Loss: 0.02186 (QuantReg: 8.61576) QuantErr: 8.61576 batch_time=0.54418 
Train Epoch: 44 [185/500 11840/32000 (37%)] Loss: 0.04084 (QuantReg: 8.38716) QuantErr: 8.38716 batch_time=0.44549 
Train Epoch: 44 [193/500 12352/32000 (39%)] Loss: 0.04162 (QuantReg: 8.67187) QuantErr: 8.67187 batch_time=0.69124 
Train Epoch: 44 [201/500 12864/32000 (40%)] Loss: 0.04814 (QuantReg: 8.64680) QuantErr: 8.64680 batch_time=0.86641 
Train Epoch: 44 [209/500 13376/32000 (42%)] Loss: 0.05535 (QuantReg: 8.37687) QuantErr: 8.37687 batch_time=0.44103 
Train Epoch: 44 [217/500 13888/32000 (43%)] Loss: 0.02149 (QuantReg: 8.40324) QuantErr: 8.40324 batch_time=0.45011 
Train Epoch: 44 [225/500 14400/32000 (45%)] Loss: 0.07330 (QuantReg: 8.74589) QuantErr: 8.74589 batch_time=0.43990 
Train Epoch: 44 [233/500 14912/32000 (47%)] Loss: 0.03010 (QuantReg: 8.58134) QuantErr: 8.58134 batch_time=0.44437 
Train Epoch: 44 [241/500 15424/32000 (48%)] Loss: 0.05520 (QuantReg: 8.46132) QuantErr: 8.46132 batch_time=0.54018 
Train Epoch: 44 [249/500 15936/32000 (50%)] Loss: 0.02213 (QuantReg: 8.44759) QuantErr: 8.44759 batch_time=0.44345 
Train Epoch: 44 [257/500 16448/32000 (51%)] Loss: 0.02142 (QuantReg: 8.65811) QuantErr: 8.65811 batch_time=0.69341 
Train Epoch: 44 [265/500 16960/32000 (53%)] Loss: 0.01700 (QuantReg: 8.64075) QuantErr: 8.64075 batch_time=0.88123 
Train Epoch: 44 [273/500 17472/32000 (55%)] Loss: 0.02106 (QuantReg: 8.65165) QuantErr: 8.65165 batch_time=0.44634 
Train Epoch: 44 [281/500 17984/32000 (56%)] Loss: 0.02979 (QuantReg: 8.52890) QuantErr: 8.52890 batch_time=0.43821 
Train Epoch: 44 [289/500 18496/32000 (58%)] Loss: 0.02690 (QuantReg: 8.63418) QuantErr: 8.63418 batch_time=0.45622 
Train Epoch: 44 [297/500 19008/32000 (59%)] Loss: 0.03359 (QuantReg: 8.51614) QuantErr: 8.51614 batch_time=0.44240 
Train Epoch: 44 [305/500 19520/32000 (61%)] Loss: 0.07197 (QuantReg: 8.63752) QuantErr: 8.63752 batch_time=0.54115 
Train Epoch: 44 [313/500 20032/32000 (63%)] Loss: 0.03899 (QuantReg: 8.36130) QuantErr: 8.36130 batch_time=0.43652 
Train Epoch: 44 [321/500 20544/32000 (64%)] Loss: 0.02362 (QuantReg: 8.61037) QuantErr: 8.61037 batch_time=0.68545 
Train Epoch: 44 [329/500 21056/32000 (66%)] Loss: 0.03001 (QuantReg: 8.66087) QuantErr: 8.66087 batch_time=0.85809 
Train Epoch: 44 [337/500 21568/32000 (67%)] Loss: 0.02797 (QuantReg: 8.53240) QuantErr: 8.53240 batch_time=0.43660 
Train Epoch: 44 [345/500 22080/32000 (69%)] Loss: 0.02057 (QuantReg: 8.69438) QuantErr: 8.69438 batch_time=0.45132 
Train Epoch: 44 [353/500 22592/32000 (71%)] Loss: 0.03789 (QuantReg: 8.40233) QuantErr: 8.40233 batch_time=0.44577 
Train Epoch: 44 [361/500 23104/32000 (72%)] Loss: 0.01897 (QuantReg: 8.72640) QuantErr: 8.72640 batch_time=0.44130 
Train Epoch: 44 [369/500 23616/32000 (74%)] Loss: 0.02916 (QuantReg: 8.54301) QuantErr: 8.54301 batch_time=0.54276 
Train Epoch: 44 [377/500 24128/32000 (75%)] Loss: 0.02948 (QuantReg: 8.66157) QuantErr: 8.66157 batch_time=0.46353 
Train Epoch: 44 [385/500 24640/32000 (77%)] Loss: 0.07901 (QuantReg: 8.50805) QuantErr: 8.50805 batch_time=0.70895 
Train Epoch: 44 [393/500 25152/32000 (79%)] Loss: 0.02682 (QuantReg: 8.60847) QuantErr: 8.60847 batch_time=0.87279 
Train Epoch: 44 [401/500 25664/32000 (80%)] Loss: 0.04010 (QuantReg: 8.56661) QuantErr: 8.56661 batch_time=0.44353 
Train Epoch: 44 [409/500 26176/32000 (82%)] Loss: 0.03107 (QuantReg: 8.52556) QuantErr: 8.52556 batch_time=0.45130 
Train Epoch: 44 [417/500 26688/32000 (83%)] Loss: 0.02313 (QuantReg: 8.59056) QuantErr: 8.59056 batch_time=0.44583 
Train Epoch: 44 [425/500 27200/32000 (85%)] Loss: 0.02033 (QuantReg: 8.61866) QuantErr: 8.61866 batch_time=0.44998 
Train Epoch: 44 [433/500 27712/32000 (87%)] Loss: 0.02946 (QuantReg: 8.54251) QuantErr: 8.54251 batch_time=0.54030 
Train Epoch: 44 [441/500 28224/32000 (88%)] Loss: 0.02016 (QuantReg: 8.59239) QuantErr: 8.59239 batch_time=0.44199 
Train Epoch: 44 [449/500 28736/32000 (90%)] Loss: 0.02357 (QuantReg: 8.63287) QuantErr: 8.63287 batch_time=0.73096 
Train Epoch: 44 [457/500 29248/32000 (91%)] Loss: 0.07946 (QuantReg: 8.63192) QuantErr: 8.63192 batch_time=0.86530 
Train Epoch: 44 [465/500 29760/32000 (93%)] Loss: 0.01725 (QuantReg: 8.39563) QuantErr: 8.39563 batch_time=0.44659 
Train Epoch: 44 [473/500 30272/32000 (95%)] Loss: 0.02263 (QuantReg: 8.53139) QuantErr: 8.53139 batch_time=0.45420 
Train Epoch: 44 [481/500 30784/32000 (96%)] Loss: 0.02586 (QuantReg: 8.37328) QuantErr: 8.37328 batch_time=0.44909 
Train Epoch: 44 [489/500 31296/32000 (98%)] Loss: 0.02562 (QuantReg: 8.56586) QuantErr: 8.56586 batch_time=0.45180 
Train Epoch: 44 [497/500 31808/32000 (99%)] Loss: 0.04016 (QuantReg: 8.68298) QuantErr: 8.68298 batch_time=0.54434 
Train Epoch: 44 codebook_update_time=1.74259
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_ActivityNet_bs64/checkpoint-epoch44.pth ...
Done in 4.727s
removing stale ckpt [epoch 43] [took 1.16s]
 epoch          : 44
 loss           : 0.03905698674544692
 quant_reg      : 8.572203746795655
 quant_err      : 8.572203746795655
 learning_rate  : 1.6472800710918591e-06
 n_samples      : 1408000
 n_steps        : 22000
 ActivityNet_val1_test/t2v_metrics/R1: 20.70368110636567
 ActivityNet_val1_test/t2v_metrics/R5: 51.29143786861908
 ActivityNet_val1_test/t2v_metrics/R10: 66.70734187512711
 ActivityNet_val1_test/t2v_metrics/R50: 89.16005694529184
 ActivityNet_val1_test/t2v_metrics/MedR: 5.0
 ActivityNet_val1_test/t2v_metrics/MeanR: 33.561928004881025
 ActivityNet_val1_test/t2v_metrics/geometric_mean_R1-R5-R10: 41.37665323528891
 ActivityNet_val1_test/v2t_metrics/R1: 20.988407565588773
 ActivityNet_val1_test/v2t_metrics/R5: 51.96257880821639
 ActivityNet_val1_test/v2t_metrics/R10: 67.4598332316453
 ActivityNet_val1_test/v2t_metrics/R50: 89.52613382143583
 ActivityNet_val1_test/v2t_metrics/MedR: 5.0
 ActivityNet_val1_test/v2t_metrics/MeanR: 31.09334960341672
 ActivityNet_val1_test/v2t_metrics/geometric_mean_R1-R5-R10: 41.90235991035741
 mnt_best       : 41.446185373070655
 not_improved_count: 3
Train Epoch: 45 [1/500 64/32000 (0%)] Loss: 0.03800 (QuantReg: 8.59040) QuantErr: 8.59040 batch_time=24.18669 
Train Epoch: 45 [9/500 576/32000 (2%)] Loss: 0.04568 (QuantReg: 8.50535) QuantErr: 8.50535 batch_time=0.44077 
Train Epoch: 45 [17/500 1088/32000 (3%)] Loss: 0.06570 (QuantReg: 8.52655) QuantErr: 8.52655 batch_time=0.43829 
Train Epoch: 45 [25/500 1600/32000 (5%)] Loss: 0.05275 (QuantReg: 8.55367) QuantErr: 8.55367 batch_time=0.94633 
Train Epoch: 45 [33/500 2112/32000 (7%)] Loss: 0.03363 (QuantReg: 8.55585) QuantErr: 8.55585 batch_time=0.44721 
Train Epoch: 45 [41/500 2624/32000 (8%)] Loss: 0.10173 (QuantReg: 8.61783) QuantErr: 8.61783 batch_time=0.44440 
Train Epoch: 45 [49/500 3136/32000 (10%)] Loss: 0.07323 (QuantReg: 8.44234) QuantErr: 8.44234 batch_time=0.47437 
Train Epoch: 45 [57/500 3648/32000 (11%)] Loss: 0.02733 (QuantReg: 8.64114) QuantErr: 8.64114 batch_time=0.44499 
Train Epoch: 45 [65/500 4160/32000 (13%)] Loss: 0.03713 (QuantReg: 8.47897) QuantErr: 8.47897 batch_time=0.56924 
Train Epoch: 45 [73/500 4672/32000 (15%)] Loss: 0.03288 (QuantReg: 8.57974) QuantErr: 8.57974 batch_time=0.44167 
Train Epoch: 45 [81/500 5184/32000 (16%)] Loss: 0.04214 (QuantReg: 8.54264) QuantErr: 8.54264 batch_time=0.44188 
Train Epoch: 45 [89/500 5696/32000 (18%)] Loss: 0.06419 (QuantReg: 8.50859) QuantErr: 8.50859 batch_time=0.89791 
Train Epoch: 45 [97/500 6208/32000 (19%)] Loss: 0.02502 (QuantReg: 8.59956) QuantErr: 8.59956 batch_time=0.44354 
Train Epoch: 45 [105/500 6720/32000 (21%)] Loss: 0.02322 (QuantReg: 8.55889) QuantErr: 8.55889 batch_time=0.44148 
Train Epoch: 45 [113/500 7232/32000 (23%)] Loss: 0.02816 (QuantReg: 8.60864) QuantErr: 8.60864 batch_time=0.47606 
Train Epoch: 45 [121/500 7744/32000 (24%)] Loss: 0.04917 (QuantReg: 8.58705) QuantErr: 8.58705 batch_time=0.44670 
Train Epoch: 45 [129/500 8256/32000 (26%)] Loss: 0.02876 (QuantReg: 8.42759) QuantErr: 8.42759 batch_time=0.58292 
Train Epoch: 45 [137/500 8768/32000 (27%)] Loss: 0.09239 (QuantReg: 8.41794) QuantErr: 8.41794 batch_time=0.47934 
Train Epoch: 45 [145/500 9280/32000 (29%)] Loss: 0.07180 (QuantReg: 8.63650) QuantErr: 8.63650 batch_time=0.47713 
Train Epoch: 45 [153/500 9792/32000 (31%)] Loss: 0.03964 (QuantReg: 8.42651) QuantErr: 8.42651 batch_time=0.88011 
Train Epoch: 45 [161/500 10304/32000 (32%)] Loss: 0.03442 (QuantReg: 8.56315) QuantErr: 8.56315 batch_time=0.44859 
Train Epoch: 45 [169/500 10816/32000 (34%)] Loss: 0.04035 (QuantReg: 8.54786) QuantErr: 8.54786 batch_time=0.44004 
Train Epoch: 45 [177/500 11328/32000 (35%)] Loss: 0.03096 (QuantReg: 8.61805) QuantErr: 8.61805 batch_time=0.46996 
Train Epoch: 45 [185/500 11840/32000 (37%)] Loss: 0.02846 (QuantReg: 8.48614) QuantErr: 8.48614 batch_time=0.44589 
Train Epoch: 45 [193/500 12352/32000 (39%)] Loss: 0.03644 (QuantReg: 8.61724) QuantErr: 8.61724 batch_time=0.56977 
Train Epoch: 45 [201/500 12864/32000 (40%)] Loss: 0.03901 (QuantReg: 8.61665) QuantErr: 8.61665 batch_time=0.44266 
Train Epoch: 45 [209/500 13376/32000 (42%)] Loss: 0.05934 (QuantReg: 8.61717) QuantErr: 8.61717 batch_time=0.43595 
Train Epoch: 45 [217/500 13888/32000 (43%)] Loss: 0.06044 (QuantReg: 8.50239) QuantErr: 8.50239 batch_time=0.87590 
Train Epoch: 45 [225/500 14400/32000 (45%)] Loss: 0.06426 (QuantReg: 8.38943) QuantErr: 8.38943 batch_time=0.43575 
Train Epoch: 45 [233/500 14912/32000 (47%)] Loss: 0.07642 (QuantReg: 8.58446) QuantErr: 8.58446 batch_time=0.44398 
Train Epoch: 45 [241/500 15424/32000 (48%)] Loss: 0.06922 (QuantReg: 8.48415) QuantErr: 8.48415 batch_time=0.47140 
Train Epoch: 45 [249/500 15936/32000 (50%)] Loss: 0.02090 (QuantReg: 8.65734) QuantErr: 8.65734 batch_time=0.44136 
Train Epoch: 45 [257/500 16448/32000 (51%)] Loss: 0.02983 (QuantReg: 8.63101) QuantErr: 8.63101 batch_time=0.57432 
Train Epoch: 45 [265/500 16960/32000 (53%)] Loss: 0.04040 (QuantReg: 8.43957) QuantErr: 8.43957 batch_time=0.43674 
Train Epoch: 45 [273/500 17472/32000 (55%)] Loss: 0.06383 (QuantReg: 8.42116) QuantErr: 8.42116 batch_time=0.42899 
Train Epoch: 45 [281/500 17984/32000 (56%)] Loss: 0.04298 (QuantReg: 8.61054) QuantErr: 8.61054 batch_time=0.86428 
Train Epoch: 45 [289/500 18496/32000 (58%)] Loss: 0.03216 (QuantReg: 8.65159) QuantErr: 8.65159 batch_time=0.43082 
Train Epoch: 45 [297/500 19008/32000 (59%)] Loss: 0.01754 (QuantReg: 8.39162) QuantErr: 8.39162 batch_time=0.43565 
Train Epoch: 45 [305/500 19520/32000 (61%)] Loss: 0.01858 (QuantReg: 8.39670) QuantErr: 8.39670 batch_time=0.47156 
Train Epoch: 45 [313/500 20032/32000 (63%)] Loss: 0.06517 (QuantReg: 8.66822) QuantErr: 8.66822 batch_time=0.43920 
Train Epoch: 45 [321/500 20544/32000 (64%)] Loss: 0.09462 (QuantReg: 8.57064) QuantErr: 8.57064 batch_time=0.56793 
Train Epoch: 45 [329/500 21056/32000 (66%)] Loss: 0.02483 (QuantReg: 8.63032) QuantErr: 8.63032 batch_time=0.44211 
Train Epoch: 45 [337/500 21568/32000 (67%)] Loss: 0.04003 (QuantReg: 8.64926) QuantErr: 8.64926 batch_time=0.44836 
Train Epoch: 45 [345/500 22080/32000 (69%)] Loss: 0.06363 (QuantReg: 8.53297) QuantErr: 8.53297 batch_time=0.87310 
Train Epoch: 45 [353/500 22592/32000 (71%)] Loss: 0.07945 (QuantReg: 8.55576) QuantErr: 8.55576 batch_time=0.44231 
Train Epoch: 45 [361/500 23104/32000 (72%)] Loss: 0.03432 (QuantReg: 8.64884) QuantErr: 8.64884 batch_time=0.44815 
Train Epoch: 45 [369/500 23616/32000 (74%)] Loss: 0.02189 (QuantReg: 8.47172) QuantErr: 8.47172 batch_time=0.47222 
Train Epoch: 45 [377/500 24128/32000 (75%)] Loss: 0.02884 (QuantReg: 8.52463) QuantErr: 8.52463 batch_time=0.43985 
Train Epoch: 45 [385/500 24640/32000 (77%)] Loss: 0.02170 (QuantReg: 8.68314) QuantErr: 8.68314 batch_time=0.58020 
Train Epoch: 45 [393/500 25152/32000 (79%)] Loss: 0.02526 (QuantReg: 8.62871) QuantErr: 8.62871 batch_time=0.44570 
Train Epoch: 45 [401/500 25664/32000 (80%)] Loss: 0.03392 (QuantReg: 8.54668) QuantErr: 8.54668 batch_time=0.44198 
Train Epoch: 45 [409/500 26176/32000 (82%)] Loss: 0.01861 (QuantReg: 8.44117) QuantErr: 8.44117 batch_time=0.84985 
Train Epoch: 45 [417/500 26688/32000 (83%)] Loss: 0.08683 (QuantReg: 8.33395) QuantErr: 8.33395 batch_time=0.43840 
Train Epoch: 45 [425/500 27200/32000 (85%)] Loss: 0.03013 (QuantReg: 8.46537) QuantErr: 8.46537 batch_time=0.49191 
Train Epoch: 45 [433/500 27712/32000 (87%)] Loss: 0.02765 (QuantReg: 8.45322) QuantErr: 8.45322 batch_time=0.51820 
Train Epoch: 45 [441/500 28224/32000 (88%)] Loss: 0.04573 (QuantReg: 8.55647) QuantErr: 8.55647 batch_time=0.47520 
Train Epoch: 45 [449/500 28736/32000 (90%)] Loss: 0.02455 (QuantReg: 8.56485) QuantErr: 8.56485 batch_time=0.61072 
Train Epoch: 45 [457/500 29248/32000 (91%)] Loss: 0.03129 (QuantReg: 8.66018) QuantErr: 8.66018 batch_time=0.44191 
Train Epoch: 45 [465/500 29760/32000 (93%)] Loss: 0.03553 (QuantReg: 8.39926) QuantErr: 8.39926 batch_time=0.44570 
Train Epoch: 45 [473/500 30272/32000 (95%)] Loss: 0.03451 (QuantReg: 8.57149) QuantErr: 8.57149 batch_time=0.86630 
Train Epoch: 45 [481/500 30784/32000 (96%)] Loss: 0.02259 (QuantReg: 8.54656) QuantErr: 8.54656 batch_time=0.44476 
Train Epoch: 45 [489/500 31296/32000 (98%)] Loss: 0.01851 (QuantReg: 8.40831) QuantErr: 8.40831 batch_time=0.44089 
Train Epoch: 45 [497/500 31808/32000 (99%)] Loss: 0.02028 (QuantReg: 8.50900) QuantErr: 8.50900 batch_time=0.48640 
Train Epoch: 45 codebook_update_time=1.79164
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_ActivityNet_bs64/checkpoint-epoch45.pth ...
Done in 4.505s
removing stale ckpt [epoch 44] [took 0.00s]
 epoch          : 45
 loss           : 0.04157151598110795
 quant_reg      : 8.553437913894653
 quant_err      : 8.553437913894653
 learning_rate  : 1.4001880604280803e-06
 n_samples      : 1440000
 n_steps        : 22500
 ActivityNet_val1_test/t2v_metrics/R1: 20.825706731747
 ActivityNet_val1_test/t2v_metrics/R5: 51.006711409395976
 ActivityNet_val1_test/t2v_metrics/R10: 66.17856416514135
 ActivityNet_val1_test/t2v_metrics/R50: 89.20073215375228
 ActivityNet_val1_test/t2v_metrics/MedR: 5.0
 ActivityNet_val1_test/t2v_metrics/MeanR: 33.70510473866179
 ActivityNet_val1_test/t2v_metrics/geometric_mean_R1-R5-R10: 41.271298918939934
 ActivityNet_val1_test/v2t_metrics/R1: 21.2934716290421
 ActivityNet_val1_test/v2t_metrics/R5: 51.94224120398617
 ActivityNet_val1_test/v2t_metrics/R10: 67.66320927394753
 ActivityNet_val1_test/v2t_metrics/R50: 89.24140736221273
 ActivityNet_val1_test/v2t_metrics/MedR: 5.0
 ActivityNet_val1_test/v2t_metrics/MeanR: 31.070978238763473
 ActivityNet_val1_test/v2t_metrics/geometric_mean_R1-R5-R10: 42.141169458562985
 mnt_best       : 41.446185373070655
 not_improved_count: 4
Train Epoch: 46 [1/500 64/32000 (0%)] Loss: 0.02446 (QuantReg: 8.53253) QuantErr: 8.53253 batch_time=22.57495 
Train Epoch: 46 [9/500 576/32000 (2%)] Loss: 0.02309 (QuantReg: 8.47437) QuantErr: 8.47437 batch_time=0.43669 
Train Epoch: 46 [17/500 1088/32000 (3%)] Loss: 0.03032 (QuantReg: 8.53577) QuantErr: 8.53577 batch_time=0.44620 
Train Epoch: 46 [25/500 1600/32000 (5%)] Loss: 0.04615 (QuantReg: 8.61823) QuantErr: 8.61823 batch_time=0.44221 
Train Epoch: 46 [33/500 2112/32000 (7%)] Loss: 0.06593 (QuantReg: 8.59921) QuantErr: 8.59921 batch_time=0.44874 
Train Epoch: 46 [41/500 2624/32000 (8%)] Loss: 0.03021 (QuantReg: 8.50135) QuantErr: 8.50135 batch_time=0.44520 
Train Epoch: 46 [49/500 3136/32000 (10%)] Loss: 0.03155 (QuantReg: 8.59895) QuantErr: 8.59895 batch_time=0.44493 
Train Epoch: 46 [57/500 3648/32000 (11%)] Loss: 0.02347 (QuantReg: 8.54489) QuantErr: 8.54489 batch_time=0.44782 
Train Epoch: 46 [65/500 4160/32000 (13%)] Loss: 0.06477 (QuantReg: 8.55023) QuantErr: 8.55023 batch_time=0.43883 
Train Epoch: 46 [73/500 4672/32000 (15%)] Loss: 0.07630 (QuantReg: 8.45264) QuantErr: 8.45264 batch_time=0.45762 
Train Epoch: 46 [81/500 5184/32000 (16%)] Loss: 0.03745 (QuantReg: 8.59962) QuantErr: 8.59962 batch_time=0.47113 
Train Epoch: 46 [89/500 5696/32000 (18%)] Loss: 0.02069 (QuantReg: 8.43332) QuantErr: 8.43332 batch_time=0.45236 
Train Epoch: 46 [97/500 6208/32000 (19%)] Loss: 0.06193 (QuantReg: 8.63295) QuantErr: 8.63295 batch_time=0.44497 
Train Epoch: 46 [105/500 6720/32000 (21%)] Loss: 0.07741 (QuantReg: 8.49175) QuantErr: 8.49175 batch_time=0.44880 
Train Epoch: 46 [113/500 7232/32000 (23%)] Loss: 0.01813 (QuantReg: 8.63013) QuantErr: 8.63013 batch_time=0.44923 
Train Epoch: 46 [121/500 7744/32000 (24%)] Loss: 0.02449 (QuantReg: 8.50587) QuantErr: 8.50587 batch_time=0.44927 
Train Epoch: 46 [129/500 8256/32000 (26%)] Loss: 0.04054 (QuantReg: 8.70009) QuantErr: 8.70009 batch_time=0.44876 
Train Epoch: 46 [137/500 8768/32000 (27%)] Loss: 0.03342 (QuantReg: 8.47735) QuantErr: 8.47735 batch_time=0.45440 
Train Epoch: 46 [145/500 9280/32000 (29%)] Loss: 0.03138 (QuantReg: 8.43082) QuantErr: 8.43082 batch_time=0.45062 
Train Epoch: 46 [153/500 9792/32000 (31%)] Loss: 0.04369 (QuantReg: 8.69855) QuantErr: 8.69855 batch_time=0.46826 
Train Epoch: 46 [161/500 10304/32000 (32%)] Loss: 0.03798 (QuantReg: 8.57610) QuantErr: 8.57610 batch_time=0.44034 
Train Epoch: 46 [169/500 10816/32000 (34%)] Loss: 0.06364 (QuantReg: 8.52342) QuantErr: 8.52342 batch_time=0.45881 
Train Epoch: 46 [177/500 11328/32000 (35%)] Loss: 0.11609 (QuantReg: 8.30180) QuantErr: 8.30180 batch_time=0.45260 
Train Epoch: 46 [185/500 11840/32000 (37%)] Loss: 0.03335 (QuantReg: 8.68669) QuantErr: 8.68669 batch_time=0.45807 
Train Epoch: 46 [193/500 12352/32000 (39%)] Loss: 0.02197 (QuantReg: 8.60398) QuantErr: 8.60398 batch_time=0.44147 
Train Epoch: 46 [201/500 12864/32000 (40%)] Loss: 0.06719 (QuantReg: 8.55587) QuantErr: 8.55587 batch_time=0.45138 
Train Epoch: 46 [209/500 13376/32000 (42%)] Loss: 0.08086 (QuantReg: 8.40028) QuantErr: 8.40028 batch_time=0.44925 
Train Epoch: 46 [217/500 13888/32000 (43%)] Loss: 0.03224 (QuantReg: 8.56914) QuantErr: 8.56914 batch_time=0.44870 
Train Epoch: 46 [225/500 14400/32000 (45%)] Loss: 0.01984 (QuantReg: 8.44488) QuantErr: 8.44488 batch_time=0.45090 
Train Epoch: 46 [233/500 14912/32000 (47%)] Loss: 0.02221 (QuantReg: 8.70117) QuantErr: 8.70117 batch_time=0.44036 
Train Epoch: 46 [241/500 15424/32000 (48%)] Loss: 0.02525 (QuantReg: 8.44454) QuantErr: 8.44454 batch_time=0.44046 
Train Epoch: 46 [249/500 15936/32000 (50%)] Loss: 0.07291 (QuantReg: 8.39156) QuantErr: 8.39156 batch_time=0.44168 
Train Epoch: 46 [257/500 16448/32000 (51%)] Loss: 0.02273 (QuantReg: 8.65878) QuantErr: 8.65878 batch_time=0.43573 
Train Epoch: 46 [265/500 16960/32000 (53%)] Loss: 0.03321 (QuantReg: 8.36327) QuantErr: 8.36327 batch_time=0.47656 
Train Epoch: 46 [273/500 17472/32000 (55%)] Loss: 0.02734 (QuantReg: 8.56298) QuantErr: 8.56298 batch_time=0.43934 
Train Epoch: 46 [281/500 17984/32000 (56%)] Loss: 0.04682 (QuantReg: 8.51652) QuantErr: 8.51652 batch_time=0.47454 
Train Epoch: 46 [289/500 18496/32000 (58%)] Loss: 0.04163 (QuantReg: 8.56113) QuantErr: 8.56113 batch_time=0.44727 
Train Epoch: 46 [297/500 19008/32000 (59%)] Loss: 0.03493 (QuantReg: 8.64231) QuantErr: 8.64231 batch_time=0.47005 
Train Epoch: 46 [305/500 19520/32000 (61%)] Loss: 0.04401 (QuantReg: 8.33935) QuantErr: 8.33935 batch_time=0.44673 
Train Epoch: 46 [313/500 20032/32000 (63%)] Loss: 0.03516 (QuantReg: 8.61329) QuantErr: 8.61329 batch_time=0.44401 
Train Epoch: 46 [321/500 20544/32000 (64%)] Loss: 0.02732 (QuantReg: 8.70193) QuantErr: 8.70193 batch_time=0.43937 
Train Epoch: 46 [329/500 21056/32000 (66%)] Loss: 0.02611 (QuantReg: 8.45164) QuantErr: 8.45164 batch_time=0.44557 
Train Epoch: 46 [337/500 21568/32000 (67%)] Loss: 0.02243 (QuantReg: 8.48417) QuantErr: 8.48417 batch_time=0.46550 
Train Epoch: 46 [345/500 22080/32000 (69%)] Loss: 0.07779 (QuantReg: 8.38266) QuantErr: 8.38266 batch_time=0.45499 
Train Epoch: 46 [353/500 22592/32000 (71%)] Loss: 0.02267 (QuantReg: 8.49093) QuantErr: 8.49093 batch_time=0.47779 
Train Epoch: 46 [361/500 23104/32000 (72%)] Loss: 0.03638 (QuantReg: 8.45496) QuantErr: 8.45496 batch_time=0.43808 
Train Epoch: 46 [369/500 23616/32000 (74%)] Loss: 0.03710 (QuantReg: 8.60017) QuantErr: 8.60017 batch_time=0.45700 
Train Epoch: 46 [377/500 24128/32000 (75%)] Loss: 0.03133 (QuantReg: 8.52830) QuantErr: 8.52830 batch_time=0.44753 
Train Epoch: 46 [385/500 24640/32000 (77%)] Loss: 0.03187 (QuantReg: 8.54954) QuantErr: 8.54954 batch_time=0.44408 
Train Epoch: 46 [393/500 25152/32000 (79%)] Loss: 0.06814 (QuantReg: 8.43148) QuantErr: 8.43148 batch_time=0.44466 
Train Epoch: 46 [401/500 25664/32000 (80%)] Loss: 0.03578 (QuantReg: 8.53291) QuantErr: 8.53291 batch_time=0.45210 
Train Epoch: 46 [409/500 26176/32000 (82%)] Loss: 0.02035 (QuantReg: 8.50132) QuantErr: 8.50132 batch_time=0.44849 
Train Epoch: 46 [417/500 26688/32000 (83%)] Loss: 0.06220 (QuantReg: 8.49394) QuantErr: 8.49394 batch_time=0.46116 
Train Epoch: 46 [425/500 27200/32000 (85%)] Loss: 0.02962 (QuantReg: 8.62181) QuantErr: 8.62181 batch_time=0.45266 
Train Epoch: 46 [433/500 27712/32000 (87%)] Loss: 0.03245 (QuantReg: 8.55626) QuantErr: 8.55626 batch_time=0.48357 
Train Epoch: 46 [441/500 28224/32000 (88%)] Loss: 0.05122 (QuantReg: 8.58956) QuantErr: 8.58956 batch_time=0.44894 
Train Epoch: 46 [449/500 28736/32000 (90%)] Loss: 0.02182 (QuantReg: 8.51446) QuantErr: 8.51446 batch_time=0.44115 
Train Epoch: 46 [457/500 29248/32000 (91%)] Loss: 0.02564 (QuantReg: 8.68516) QuantErr: 8.68516 batch_time=0.44342 
Train Epoch: 46 [465/500 29760/32000 (93%)] Loss: 0.04380 (QuantReg: 8.47482) QuantErr: 8.47482 batch_time=0.44363 
Train Epoch: 46 [473/500 30272/32000 (95%)] Loss: 0.07379 (QuantReg: 8.60748) QuantErr: 8.60748 batch_time=0.44773 
Train Epoch: 46 [481/500 30784/32000 (96%)] Loss: 0.08605 (QuantReg: 8.65113) QuantErr: 8.65113 batch_time=0.44030 
Train Epoch: 46 [489/500 31296/32000 (98%)] Loss: 0.02175 (QuantReg: 8.69474) QuantErr: 8.69474 batch_time=0.47397 
Train Epoch: 46 [497/500 31808/32000 (99%)] Loss: 0.02821 (QuantReg: 8.64362) QuantErr: 8.64362 batch_time=0.47630 
Train Epoch: 46 codebook_update_time=1.67945
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_ActivityNet_bs64/checkpoint-epoch46.pth ...
Done in 19.479s
removing stale ckpt [epoch 45] [took 0.03s]
 epoch          : 46
 loss           : 0.03923844689875841
 quant_reg      : 8.526251842498779
 quant_err      : 8.526251842498779
 learning_rate  : 1.4001880604280803e-06
 n_samples      : 1472000
 n_steps        : 23000
 ActivityNet_val1_test/t2v_metrics/R1: 20.540980272523896
 ActivityNet_val1_test/t2v_metrics/R5: 50.925360992475085
 ActivityNet_val1_test/t2v_metrics/R10: 66.40227781167378
 ActivityNet_val1_test/t2v_metrics/R50: 89.26174496644295
 ActivityNet_val1_test/t2v_metrics/MedR: 5.0
 ActivityNet_val1_test/t2v_metrics/MeanR: 34.00081350416921
 ActivityNet_val1_test/t2v_metrics/geometric_mean_R1-R5-R10: 41.10671320553388
 ActivityNet_val1_test/v2t_metrics/R1: 20.866381940207443
 ActivityNet_val1_test/v2t_metrics/R5: 51.65751474476307
 ActivityNet_val1_test/v2t_metrics/R10: 67.84624771201952
 ActivityNet_val1_test/v2t_metrics/R50: 89.2210697579825
 ActivityNet_val1_test/v2t_metrics/MedR: 5.0
 ActivityNet_val1_test/v2t_metrics/MeanR: 32.043115720968075
 ActivityNet_val1_test/v2t_metrics/geometric_mean_R1-R5-R10: 41.81853664551132
 mnt_best       : 41.446185373070655
 not_improved_count: 5
Train Epoch: 47 [1/500 64/32000 (0%)] Loss: 0.02206 (QuantReg: 8.73318) QuantErr: 8.73318 batch_time=23.17801 
Train Epoch: 47 [9/500 576/32000 (2%)] Loss: 0.02812 (QuantReg: 8.46679) QuantErr: 8.46679 batch_time=0.44532 
Train Epoch: 47 [17/500 1088/32000 (3%)] Loss: 0.02728 (QuantReg: 8.51003) QuantErr: 8.51003 batch_time=0.79180 
Train Epoch: 47 [25/500 1600/32000 (5%)] Loss: 0.03039 (QuantReg: 8.61696) QuantErr: 8.61696 batch_time=0.43397 
Train Epoch: 47 [33/500 2112/32000 (7%)] Loss: 0.04603 (QuantReg: 8.64098) QuantErr: 8.64098 batch_time=0.43791 
Train Epoch: 47 [41/500 2624/32000 (8%)] Loss: 0.02594 (QuantReg: 8.49739) QuantErr: 8.49739 batch_time=0.44349 
Train Epoch: 47 [49/500 3136/32000 (10%)] Loss: 0.08525 (QuantReg: 8.59302) QuantErr: 8.59302 batch_time=0.44316 
Train Epoch: 47 [57/500 3648/32000 (11%)] Loss: 0.04357 (QuantReg: 8.60772) QuantErr: 8.60772 batch_time=0.56993 
Train Epoch: 47 [65/500 4160/32000 (13%)] Loss: 0.03195 (QuantReg: 8.56410) QuantErr: 8.56410 batch_time=0.49575 
Train Epoch: 47 [73/500 4672/32000 (15%)] Loss: 0.02343 (QuantReg: 8.62434) QuantErr: 8.62434 batch_time=0.44031 
Train Epoch: 47 [81/500 5184/32000 (16%)] Loss: 0.03656 (QuantReg: 8.42683) QuantErr: 8.42683 batch_time=0.79105 
Train Epoch: 47 [89/500 5696/32000 (18%)] Loss: 0.02462 (QuantReg: 8.45374) QuantErr: 8.45374 batch_time=0.45815 
Train Epoch: 47 [97/500 6208/32000 (19%)] Loss: 0.02104 (QuantReg: 8.60293) QuantErr: 8.60293 batch_time=0.44403 
Train Epoch: 47 [105/500 6720/32000 (21%)] Loss: 0.05022 (QuantReg: 8.42159) QuantErr: 8.42159 batch_time=0.44458 
Train Epoch: 47 [113/500 7232/32000 (23%)] Loss: 0.04212 (QuantReg: 8.59145) QuantErr: 8.59145 batch_time=0.43881 
Train Epoch: 47 [121/500 7744/32000 (24%)] Loss: 0.02351 (QuantReg: 8.65724) QuantErr: 8.65724 batch_time=0.52011 
Train Epoch: 47 [129/500 8256/32000 (26%)] Loss: 0.06293 (QuantReg: 8.47871) QuantErr: 8.47871 batch_time=0.46444 
Train Epoch: 47 [137/500 8768/32000 (27%)] Loss: 0.04098 (QuantReg: 8.67093) QuantErr: 8.67093 batch_time=0.43926 
Train Epoch: 47 [145/500 9280/32000 (29%)] Loss: 0.02417 (QuantReg: 8.64133) QuantErr: 8.64133 batch_time=0.79199 
Train Epoch: 47 [153/500 9792/32000 (31%)] Loss: 0.08295 (QuantReg: 8.56211) QuantErr: 8.56211 batch_time=0.44631 
Train Epoch: 47 [161/500 10304/32000 (32%)] Loss: 0.01897 (QuantReg: 8.71108) QuantErr: 8.71108 batch_time=0.44258 
Train Epoch: 47 [169/500 10816/32000 (34%)] Loss: 0.02148 (QuantReg: 8.42986) QuantErr: 8.42986 batch_time=0.44445 
Train Epoch: 47 [177/500 11328/32000 (35%)] Loss: 0.02627 (QuantReg: 8.48991) QuantErr: 8.48991 batch_time=0.44065 
Train Epoch: 47 [185/500 11840/32000 (37%)] Loss: 0.02950 (QuantReg: 8.60859) QuantErr: 8.60859 batch_time=0.58512 
Train Epoch: 47 [193/500 12352/32000 (39%)] Loss: 0.04159 (QuantReg: 8.47892) QuantErr: 8.47892 batch_time=0.47984 
Train Epoch: 47 [201/500 12864/32000 (40%)] Loss: 0.03826 (QuantReg: 8.41157) QuantErr: 8.41157 batch_time=0.44779 
Train Epoch: 47 [209/500 13376/32000 (42%)] Loss: 0.02529 (QuantReg: 8.62284) QuantErr: 8.62284 batch_time=0.80044 
Train Epoch: 47 [217/500 13888/32000 (43%)] Loss: 0.05731 (QuantReg: 8.43867) QuantErr: 8.43867 batch_time=0.49088 
Train Epoch: 47 [225/500 14400/32000 (45%)] Loss: 0.03834 (QuantReg: 8.56188) QuantErr: 8.56188 batch_time=0.44779 
Train Epoch: 47 [233/500 14912/32000 (47%)] Loss: 0.07578 (QuantReg: 8.47460) QuantErr: 8.47460 batch_time=0.43445 
Train Epoch: 47 [241/500 15424/32000 (48%)] Loss: 0.07729 (QuantReg: 8.54152) QuantErr: 8.54152 batch_time=0.43865 
Train Epoch: 47 [249/500 15936/32000 (50%)] Loss: 0.03829 (QuantReg: 8.38960) QuantErr: 8.38960 batch_time=0.54066 
Train Epoch: 47 [257/500 16448/32000 (51%)] Loss: 0.02667 (QuantReg: 8.60710) QuantErr: 8.60710 batch_time=0.45569 
Train Epoch: 47 [265/500 16960/32000 (53%)] Loss: 0.02100 (QuantReg: 8.42055) QuantErr: 8.42055 batch_time=0.44563 
Train Epoch: 47 [273/500 17472/32000 (55%)] Loss: 0.02686 (QuantReg: 8.55840) QuantErr: 8.55840 batch_time=0.77657 
Train Epoch: 47 [281/500 17984/32000 (56%)] Loss: 0.02577 (QuantReg: 8.34647) QuantErr: 8.34647 batch_time=0.45019 
Train Epoch: 47 [289/500 18496/32000 (58%)] Loss: 0.02943 (QuantReg: 8.62177) QuantErr: 8.62177 batch_time=0.43646 
Train Epoch: 47 [297/500 19008/32000 (59%)] Loss: 0.07887 (QuantReg: 8.41002) QuantErr: 8.41002 batch_time=0.45175 
Train Epoch: 47 [305/500 19520/32000 (61%)] Loss: 0.03468 (QuantReg: 8.61524) QuantErr: 8.61524 batch_time=0.43879 
Train Epoch: 47 [313/500 20032/32000 (63%)] Loss: 0.02354 (QuantReg: 8.63111) QuantErr: 8.63111 batch_time=0.54226 
Train Epoch: 47 [321/500 20544/32000 (64%)] Loss: 0.07210 (QuantReg: 8.56214) QuantErr: 8.56214 batch_time=0.44087 
Train Epoch: 47 [329/500 21056/32000 (66%)] Loss: 0.03246 (QuantReg: 8.61482) QuantErr: 8.61482 batch_time=0.44782 
Train Epoch: 47 [337/500 21568/32000 (67%)] Loss: 0.03200 (QuantReg: 8.59662) QuantErr: 8.59662 batch_time=0.77656 
Train Epoch: 47 [345/500 22080/32000 (69%)] Loss: 0.06488 (QuantReg: 8.44663) QuantErr: 8.44663 batch_time=0.44035 
Train Epoch: 47 [353/500 22592/32000 (71%)] Loss: 0.02331 (QuantReg: 8.61606) QuantErr: 8.61606 batch_time=0.45109 
Train Epoch: 47 [361/500 23104/32000 (72%)] Loss: 0.03857 (QuantReg: 8.51323) QuantErr: 8.51323 batch_time=0.43642 
Train Epoch: 47 [369/500 23616/32000 (74%)] Loss: 0.02309 (QuantReg: 8.48961) QuantErr: 8.48961 batch_time=0.43991 
Train Epoch: 47 [377/500 24128/32000 (75%)] Loss: 0.02590 (QuantReg: 8.52379) QuantErr: 8.52379 batch_time=0.53938 
Train Epoch: 47 [385/500 24640/32000 (77%)] Loss: 0.07702 (QuantReg: 8.38852) QuantErr: 8.38852 batch_time=0.44730 
Train Epoch: 47 [393/500 25152/32000 (79%)] Loss: 0.06733 (QuantReg: 8.43401) QuantErr: 8.43401 batch_time=0.44537 
Train Epoch: 47 [401/500 25664/32000 (80%)] Loss: 0.02419 (QuantReg: 8.41604) QuantErr: 8.41604 batch_time=0.76076 
Train Epoch: 47 [409/500 26176/32000 (82%)] Loss: 0.05981 (QuantReg: 8.34214) QuantErr: 8.34214 batch_time=0.43477 
Train Epoch: 47 [417/500 26688/32000 (83%)] Loss: 0.04587 (QuantReg: 8.44994) QuantErr: 8.44994 batch_time=0.43828 
Train Epoch: 47 [425/500 27200/32000 (85%)] Loss: 0.02928 (QuantReg: 8.45177) QuantErr: 8.45177 batch_time=0.44297 
Train Epoch: 47 [433/500 27712/32000 (87%)] Loss: 0.03651 (QuantReg: 8.51776) QuantErr: 8.51776 batch_time=0.44428 
Train Epoch: 47 [441/500 28224/32000 (88%)] Loss: 0.02391 (QuantReg: 8.53716) QuantErr: 8.53716 batch_time=0.54952 
Train Epoch: 47 [449/500 28736/32000 (90%)] Loss: 0.06020 (QuantReg: 8.43609) QuantErr: 8.43609 batch_time=0.43953 
Train Epoch: 47 [457/500 29248/32000 (91%)] Loss: 0.13208 (QuantReg: 8.54301) QuantErr: 8.54301 batch_time=0.44566 
Train Epoch: 47 [465/500 29760/32000 (93%)] Loss: 0.03651 (QuantReg: 8.60372) QuantErr: 8.60372 batch_time=0.78828 
Train Epoch: 47 [473/500 30272/32000 (95%)] Loss: 0.03575 (QuantReg: 8.41336) QuantErr: 8.41336 batch_time=0.44586 
Train Epoch: 47 [481/500 30784/32000 (96%)] Loss: 0.01701 (QuantReg: 8.34921) QuantErr: 8.34921 batch_time=0.43615 
Train Epoch: 47 [489/500 31296/32000 (98%)] Loss: 0.03716 (QuantReg: 8.60792) QuantErr: 8.60792 batch_time=0.43532 
Train Epoch: 47 [497/500 31808/32000 (99%)] Loss: 0.03187 (QuantReg: 8.50527) QuantErr: 8.50527 batch_time=0.44553 
Train Epoch: 47 codebook_update_time=1.73165
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_ActivityNet_bs64/checkpoint-epoch47.pth ...
Done in 22.181s
removing stale ckpt [epoch 46] [took 0.01s]
 epoch          : 47
 loss           : 0.03921082929894328
 quant_reg      : 8.513441236495972
 quant_err      : 8.513441236495972
 learning_rate  : 1.1901598513638682e-06
 n_samples      : 1504000
 n_steps        : 23500
 ActivityNet_val1_test/t2v_metrics/R1: 20.663005897905226
 ActivityNet_val1_test/t2v_metrics/R5: 50.8440105755542
 ActivityNet_val1_test/t2v_metrics/R10: 66.50396583282489
 ActivityNet_val1_test/t2v_metrics/R50: 89.38377059182429
 ActivityNet_val1_test/t2v_metrics/MedR: 5.0
 ActivityNet_val1_test/t2v_metrics/MeanR: 33.61724628838723
 ActivityNet_val1_test/t2v_metrics/geometric_mean_R1-R5-R10: 41.187011544219935
 ActivityNet_val1_test/v2t_metrics/R1: 20.94773235712833
 ActivityNet_val1_test/v2t_metrics/R5: 52.14561724628839
 ActivityNet_val1_test/v2t_metrics/R10: 67.15476916819199
 ActivityNet_val1_test/v2t_metrics/R50: 89.46512100874517
 ActivityNet_val1_test/v2t_metrics/MedR: 5.0
 ActivityNet_val1_test/v2t_metrics/MeanR: 31.174293268253
 ActivityNet_val1_test/v2t_metrics/geometric_mean_R1-R5-R10: 41.861092956810914
 mnt_best       : 41.446185373070655
 not_improved_count: 6
Train Epoch: 48 [1/500 64/32000 (0%)] Loss: 0.02881 (QuantReg: 8.42737) QuantErr: 8.42737 batch_time=22.63028 
Train Epoch: 48 [9/500 576/32000 (2%)] Loss: 0.05702 (QuantReg: 8.54757) QuantErr: 8.54757 batch_time=0.47385 
Train Epoch: 48 [17/500 1088/32000 (3%)] Loss: 0.07473 (QuantReg: 8.51693) QuantErr: 8.51693 batch_time=0.57044 
Train Epoch: 48 [25/500 1600/32000 (5%)] Loss: 0.02232 (QuantReg: 8.47219) QuantErr: 8.47219 batch_time=0.43781 
Train Epoch: 48 [33/500 2112/32000 (7%)] Loss: 0.02642 (QuantReg: 8.49052) QuantErr: 8.49052 batch_time=0.44050 
Train Epoch: 48 [41/500 2624/32000 (8%)] Loss: 0.03772 (QuantReg: 8.64005) QuantErr: 8.64005 batch_time=0.44618 
Train Epoch: 48 [49/500 3136/32000 (10%)] Loss: 0.06415 (QuantReg: 8.50436) QuantErr: 8.50436 batch_time=0.44839 
Train Epoch: 48 [57/500 3648/32000 (11%)] Loss: 0.08756 (QuantReg: 8.42361) QuantErr: 8.42361 batch_time=0.45190 
Train Epoch: 48 [65/500 4160/32000 (13%)] Loss: 0.03920 (QuantReg: 8.55100) QuantErr: 8.55100 batch_time=0.44761 
Train Epoch: 48 [73/500 4672/32000 (15%)] Loss: 0.03563 (QuantReg: 8.57442) QuantErr: 8.57442 batch_time=0.47688 
Train Epoch: 48 [81/500 5184/32000 (16%)] Loss: 0.07761 (QuantReg: 8.69810) QuantErr: 8.69810 batch_time=0.56742 
Train Epoch: 48 [89/500 5696/32000 (18%)] Loss: 0.05159 (QuantReg: 8.53615) QuantErr: 8.53615 batch_time=0.43315 
Train Epoch: 48 [97/500 6208/32000 (19%)] Loss: 0.02738 (QuantReg: 8.62145) QuantErr: 8.62145 batch_time=0.43381 
Train Epoch: 48 [105/500 6720/32000 (21%)] Loss: 0.01814 (QuantReg: 8.55110) QuantErr: 8.55110 batch_time=0.43271 
Train Epoch: 48 [113/500 7232/32000 (23%)] Loss: 0.04915 (QuantReg: 8.46626) QuantErr: 8.46626 batch_time=0.46894 
Train Epoch: 48 [121/500 7744/32000 (24%)] Loss: 0.04168 (QuantReg: 8.41877) QuantErr: 8.41877 batch_time=0.48408 
Train Epoch: 48 [129/500 8256/32000 (26%)] Loss: 0.02435 (QuantReg: 8.36958) QuantErr: 8.36958 batch_time=0.45131 
Train Epoch: 48 [137/500 8768/32000 (27%)] Loss: 0.03503 (QuantReg: 8.50210) QuantErr: 8.50210 batch_time=0.47862 
Train Epoch: 48 [145/500 9280/32000 (29%)] Loss: 0.03828 (QuantReg: 8.58898) QuantErr: 8.58898 batch_time=0.57128 
Train Epoch: 48 [153/500 9792/32000 (31%)] Loss: 0.11280 (QuantReg: 8.61668) QuantErr: 8.61668 batch_time=0.45732 
Train Epoch: 48 [161/500 10304/32000 (32%)] Loss: 0.02348 (QuantReg: 8.57428) QuantErr: 8.57428 batch_time=0.44283 
Train Epoch: 48 [169/500 10816/32000 (34%)] Loss: 0.04120 (QuantReg: 8.49929) QuantErr: 8.49929 batch_time=0.44354 
Train Epoch: 48 [177/500 11328/32000 (35%)] Loss: 0.04845 (QuantReg: 8.59650) QuantErr: 8.59650 batch_time=0.44962 
Train Epoch: 48 [185/500 11840/32000 (37%)] Loss: 0.02741 (QuantReg: 8.44771) QuantErr: 8.44771 batch_time=0.44349 
Train Epoch: 48 [193/500 12352/32000 (39%)] Loss: 0.07439 (QuantReg: 8.43679) QuantErr: 8.43679 batch_time=0.44184 
Train Epoch: 48 [201/500 12864/32000 (40%)] Loss: 0.04979 (QuantReg: 8.43880) QuantErr: 8.43880 batch_time=0.48611 
Train Epoch: 48 [209/500 13376/32000 (42%)] Loss: 0.03789 (QuantReg: 8.51571) QuantErr: 8.51571 batch_time=0.58373 
Train Epoch: 48 [217/500 13888/32000 (43%)] Loss: 0.02397 (QuantReg: 8.50279) QuantErr: 8.50279 batch_time=0.43968 
Train Epoch: 48 [225/500 14400/32000 (45%)] Loss: 0.03253 (QuantReg: 8.50625) QuantErr: 8.50625 batch_time=0.44357 
Train Epoch: 48 [233/500 14912/32000 (47%)] Loss: 0.03263 (QuantReg: 8.56424) QuantErr: 8.56424 batch_time=0.45187 
Train Epoch: 48 [241/500 15424/32000 (48%)] Loss: 0.06877 (QuantReg: 8.46599) QuantErr: 8.46599 batch_time=0.44590 
Train Epoch: 48 [249/500 15936/32000 (50%)] Loss: 0.03307 (QuantReg: 8.47190) QuantErr: 8.47190 batch_time=0.44711 
Train Epoch: 48 [257/500 16448/32000 (51%)] Loss: 0.04375 (QuantReg: 8.49002) QuantErr: 8.49002 batch_time=0.43896 
Train Epoch: 48 [265/500 16960/32000 (53%)] Loss: 0.06830 (QuantReg: 8.45367) QuantErr: 8.45367 batch_time=0.48475 
Train Epoch: 48 [273/500 17472/32000 (55%)] Loss: 0.02034 (QuantReg: 8.50948) QuantErr: 8.50948 batch_time=0.58946 
Train Epoch: 48 [281/500 17984/32000 (56%)] Loss: 0.02108 (QuantReg: 8.54718) QuantErr: 8.54718 batch_time=0.44583 
Train Epoch: 48 [289/500 18496/32000 (58%)] Loss: 0.06827 (QuantReg: 8.55263) QuantErr: 8.55263 batch_time=0.44231 
Train Epoch: 48 [297/500 19008/32000 (59%)] Loss: 0.02904 (QuantReg: 8.50995) QuantErr: 8.50995 batch_time=0.45501 
Train Epoch: 48 [305/500 19520/32000 (61%)] Loss: 0.07171 (QuantReg: 8.42722) QuantErr: 8.42722 batch_time=0.44264 
Train Epoch: 48 [313/500 20032/32000 (63%)] Loss: 0.02913 (QuantReg: 8.56215) QuantErr: 8.56215 batch_time=0.45158 
Train Epoch: 48 [321/500 20544/32000 (64%)] Loss: 0.02202 (QuantReg: 8.55146) QuantErr: 8.55146 batch_time=0.45531 
Train Epoch: 48 [329/500 21056/32000 (66%)] Loss: 0.03030 (QuantReg: 8.53670) QuantErr: 8.53670 batch_time=0.48445 
Train Epoch: 48 [337/500 21568/32000 (67%)] Loss: 0.03177 (QuantReg: 8.54746) QuantErr: 8.54746 batch_time=0.57811 
Train Epoch: 48 [345/500 22080/32000 (69%)] Loss: 0.02866 (QuantReg: 8.48585) QuantErr: 8.48585 batch_time=0.43757 
Train Epoch: 48 [353/500 22592/32000 (71%)] Loss: 0.04612 (QuantReg: 8.59888) QuantErr: 8.59888 batch_time=0.44121 
Train Epoch: 48 [361/500 23104/32000 (72%)] Loss: 0.02488 (QuantReg: 8.54011) QuantErr: 8.54011 batch_time=0.44420 
Train Epoch: 48 [369/500 23616/32000 (74%)] Loss: 0.07613 (QuantReg: 8.69857) QuantErr: 8.69857 batch_time=0.45258 
Train Epoch: 48 [377/500 24128/32000 (75%)] Loss: 0.02755 (QuantReg: 8.50006) QuantErr: 8.50006 batch_time=0.44757 
Train Epoch: 48 [385/500 24640/32000 (77%)] Loss: 0.04652 (QuantReg: 8.51251) QuantErr: 8.51251 batch_time=0.44351 
Train Epoch: 48 [393/500 25152/32000 (79%)] Loss: 0.04074 (QuantReg: 8.50189) QuantErr: 8.50189 batch_time=0.47717 
Train Epoch: 48 [401/500 25664/32000 (80%)] Loss: 0.07265 (QuantReg: 8.66380) QuantErr: 8.66380 batch_time=0.57821 
Train Epoch: 48 [409/500 26176/32000 (82%)] Loss: 0.04161 (QuantReg: 8.46768) QuantErr: 8.46768 batch_time=0.45756 
Train Epoch: 48 [417/500 26688/32000 (83%)] Loss: 0.03046 (QuantReg: 8.33389) QuantErr: 8.33389 batch_time=0.46399 
Train Epoch: 48 [425/500 27200/32000 (85%)] Loss: 0.02784 (QuantReg: 8.45663) QuantErr: 8.45663 batch_time=0.44826 
Train Epoch: 48 [433/500 27712/32000 (87%)] Loss: 0.02338 (QuantReg: 8.45099) QuantErr: 8.45099 batch_time=0.44303 
Train Epoch: 48 [441/500 28224/32000 (88%)] Loss: 0.02007 (QuantReg: 8.60548) QuantErr: 8.60548 batch_time=0.44153 
Train Epoch: 48 [449/500 28736/32000 (90%)] Loss: 0.02815 (QuantReg: 8.48315) QuantErr: 8.48315 batch_time=0.44710 
Train Epoch: 48 [457/500 29248/32000 (91%)] Loss: 0.10420 (QuantReg: 8.44091) QuantErr: 8.44091 batch_time=0.47565 
Train Epoch: 48 [465/500 29760/32000 (93%)] Loss: 0.03674 (QuantReg: 8.51334) QuantErr: 8.51334 batch_time=0.56741 
Train Epoch: 48 [473/500 30272/32000 (95%)] Loss: 0.02083 (QuantReg: 8.51775) QuantErr: 8.51775 batch_time=0.43966 
Train Epoch: 48 [481/500 30784/32000 (96%)] Loss: 0.02336 (QuantReg: 8.57664) QuantErr: 8.57664 batch_time=0.46529 
Train Epoch: 48 [489/500 31296/32000 (98%)] Loss: 0.03135 (QuantReg: 8.43832) QuantErr: 8.43832 batch_time=0.44215 
Train Epoch: 48 [497/500 31808/32000 (99%)] Loss: 0.03514 (QuantReg: 8.47958) QuantErr: 8.47958 batch_time=0.45221 
Train Epoch: 48 codebook_update_time=1.69636
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_ActivityNet_bs64/checkpoint-epoch48.pth ...
Done in 4.429s
removing stale ckpt [epoch 47] [took 0.00s]
 epoch          : 48
 loss           : 0.04180480901151896
 quant_reg      : 8.492387470245362
 quant_err      : 8.492387470245362
 learning_rate  : 1.1901598513638682e-06
 n_samples      : 1536000
 n_steps        : 24000
 ActivityNet_val1_test/t2v_metrics/R1: 20.785031523286555
 ActivityNet_val1_test/t2v_metrics/R5: 50.76266015863331
 ActivityNet_val1_test/t2v_metrics/R10: 66.25991458206224
 ActivityNet_val1_test/t2v_metrics/R50: 89.07870652837096
 ActivityNet_val1_test/t2v_metrics/MedR: 5.0
 ActivityNet_val1_test/t2v_metrics/MeanR: 34.19941020947732
 ActivityNet_val1_test/t2v_metrics/geometric_mean_R1-R5-R10: 41.195392395788794
 ActivityNet_val1_test/v2t_metrics/R1: 20.80536912751678
 ActivityNet_val1_test/v2t_metrics/R5: 51.69818995322351
 ActivityNet_val1_test/v2t_metrics/R10: 67.70388448240797
 ActivityNet_val1_test/v2t_metrics/R50: 89.62782184258694
 ActivityNet_val1_test/v2t_metrics/MedR: 5.0
 ActivityNet_val1_test/v2t_metrics/MeanR: 31.56721578198088
 ActivityNet_val1_test/v2t_metrics/geometric_mean_R1-R5-R10: 41.75945128112155
 mnt_best       : 41.446185373070655
 not_improved_count: 7
Train Epoch: 49 [1/500 64/32000 (0%)] Loss: 0.03198 (QuantReg: 8.65815) QuantErr: 8.65815 batch_time=23.45732 
Train Epoch: 49 [9/500 576/32000 (2%)] Loss: 0.02835 (QuantReg: 8.38352) QuantErr: 8.38352 batch_time=0.45141 
Train Epoch: 49 [17/500 1088/32000 (3%)] Loss: 0.04329 (QuantReg: 8.41211) QuantErr: 8.41211 batch_time=0.43996 
Train Epoch: 49 [25/500 1600/32000 (5%)] Loss: 0.03546 (QuantReg: 8.58307) QuantErr: 8.58307 batch_time=0.44075 
Train Epoch: 49 [33/500 2112/32000 (7%)] Loss: 0.02628 (QuantReg: 8.39918) QuantErr: 8.39918 batch_time=0.71001 
Train Epoch: 49 [41/500 2624/32000 (8%)] Loss: 0.03455 (QuantReg: 8.46406) QuantErr: 8.46406 batch_time=0.44853 
Train Epoch: 49 [49/500 3136/32000 (10%)] Loss: 0.02398 (QuantReg: 8.59283) QuantErr: 8.59283 batch_time=0.64221 
Train Epoch: 49 [57/500 3648/32000 (11%)] Loss: 0.03483 (QuantReg: 8.38650) QuantErr: 8.38650 batch_time=0.46368 
Train Epoch: 49 [65/500 4160/32000 (13%)] Loss: 0.02612 (QuantReg: 8.52604) QuantErr: 8.52604 batch_time=0.45288 
Train Epoch: 49 [73/500 4672/32000 (15%)] Loss: 0.07054 (QuantReg: 8.44912) QuantErr: 8.44912 batch_time=0.45099 
Train Epoch: 49 [81/500 5184/32000 (16%)] Loss: 0.07045 (QuantReg: 8.43952) QuantErr: 8.43952 batch_time=0.44646 
Train Epoch: 49 [89/500 5696/32000 (18%)] Loss: 0.02207 (QuantReg: 8.47958) QuantErr: 8.47958 batch_time=0.44788 
Train Epoch: 49 [97/500 6208/32000 (19%)] Loss: 0.02918 (QuantReg: 8.42142) QuantErr: 8.42142 batch_time=0.72291 
Train Epoch: 49 [105/500 6720/32000 (21%)] Loss: 0.02094 (QuantReg: 8.55857) QuantErr: 8.55857 batch_time=0.44883 
Train Epoch: 49 [113/500 7232/32000 (23%)] Loss: 0.01784 (QuantReg: 8.51771) QuantErr: 8.51771 batch_time=0.66503 
Train Epoch: 49 [121/500 7744/32000 (24%)] Loss: 0.01953 (QuantReg: 8.51472) QuantErr: 8.51472 batch_time=0.43902 
Train Epoch: 49 [129/500 8256/32000 (26%)] Loss: 0.02062 (QuantReg: 8.46909) QuantErr: 8.46909 batch_time=0.44682 
Train Epoch: 49 [137/500 8768/32000 (27%)] Loss: 0.02374 (QuantReg: 8.50918) QuantErr: 8.50918 batch_time=0.49394 
Train Epoch: 49 [145/500 9280/32000 (29%)] Loss: 0.01990 (QuantReg: 8.56001) QuantErr: 8.56001 batch_time=0.44709 
Train Epoch: 49 [153/500 9792/32000 (31%)] Loss: 0.02664 (QuantReg: 8.57900) QuantErr: 8.57900 batch_time=0.47023 
Train Epoch: 49 [161/500 10304/32000 (32%)] Loss: 0.02319 (QuantReg: 8.47084) QuantErr: 8.47084 batch_time=0.78698 
Train Epoch: 49 [169/500 10816/32000 (34%)] Loss: 0.04272 (QuantReg: 8.28238) QuantErr: 8.28238 batch_time=0.44734 
Train Epoch: 49 [177/500 11328/32000 (35%)] Loss: 0.02661 (QuantReg: 8.38329) QuantErr: 8.38329 batch_time=0.63932 
Train Epoch: 49 [185/500 11840/32000 (37%)] Loss: 0.05064 (QuantReg: 8.49832) QuantErr: 8.49832 batch_time=0.44836 
Train Epoch: 49 [193/500 12352/32000 (39%)] Loss: 0.07465 (QuantReg: 8.25128) QuantErr: 8.25128 batch_time=0.44417 
Train Epoch: 49 [201/500 12864/32000 (40%)] Loss: 0.03444 (QuantReg: 8.46363) QuantErr: 8.46363 batch_time=0.45206 
Train Epoch: 49 [209/500 13376/32000 (42%)] Loss: 0.03021 (QuantReg: 8.59442) QuantErr: 8.59442 batch_time=0.44000 
Train Epoch: 49 [217/500 13888/32000 (43%)] Loss: 0.04901 (QuantReg: 8.46872) QuantErr: 8.46872 batch_time=0.44264 
Train Epoch: 49 [225/500 14400/32000 (45%)] Loss: 0.03648 (QuantReg: 8.52400) QuantErr: 8.52400 batch_time=0.70532 
Train Epoch: 49 [233/500 14912/32000 (47%)] Loss: 0.04018 (QuantReg: 8.69135) QuantErr: 8.69135 batch_time=0.45006 
Train Epoch: 49 [241/500 15424/32000 (48%)] Loss: 0.02672 (QuantReg: 8.62832) QuantErr: 8.62832 batch_time=0.66180 
Train Epoch: 49 [249/500 15936/32000 (50%)] Loss: 0.02203 (QuantReg: 8.53037) QuantErr: 8.53037 batch_time=0.45349 
Train Epoch: 49 [257/500 16448/32000 (51%)] Loss: 0.04001 (QuantReg: 8.51464) QuantErr: 8.51464 batch_time=0.44501 
Train Epoch: 49 [265/500 16960/32000 (53%)] Loss: 0.03168 (QuantReg: 8.35410) QuantErr: 8.35410 batch_time=0.45711 
Train Epoch: 49 [273/500 17472/32000 (55%)] Loss: 0.01952 (QuantReg: 8.51881) QuantErr: 8.51881 batch_time=0.44511 
Train Epoch: 49 [281/500 17984/32000 (56%)] Loss: 0.03564 (QuantReg: 8.44959) QuantErr: 8.44959 batch_time=0.45642 
Train Epoch: 49 [289/500 18496/32000 (58%)] Loss: 0.02407 (QuantReg: 8.47223) QuantErr: 8.47223 batch_time=0.70333 
Train Epoch: 49 [297/500 19008/32000 (59%)] Loss: 0.02872 (QuantReg: 8.62212) QuantErr: 8.62212 batch_time=0.43674 
Train Epoch: 49 [305/500 19520/32000 (61%)] Loss: 0.04259 (QuantReg: 8.47889) QuantErr: 8.47889 batch_time=0.63496 
Train Epoch: 49 [313/500 20032/32000 (63%)] Loss: 0.02152 (QuantReg: 8.57299) QuantErr: 8.57299 batch_time=0.45098 
Train Epoch: 49 [321/500 20544/32000 (64%)] Loss: 0.03239 (QuantReg: 8.49143) QuantErr: 8.49143 batch_time=0.44426 
Train Epoch: 49 [329/500 21056/32000 (66%)] Loss: 0.01891 (QuantReg: 8.36684) QuantErr: 8.36684 batch_time=0.45170 
Train Epoch: 49 [337/500 21568/32000 (67%)] Loss: 0.02071 (QuantReg: 8.53600) QuantErr: 8.53600 batch_time=0.44550 
Train Epoch: 49 [345/500 22080/32000 (69%)] Loss: 0.02604 (QuantReg: 8.47395) QuantErr: 8.47395 batch_time=0.44107 
Train Epoch: 49 [353/500 22592/32000 (71%)] Loss: 0.03314 (QuantReg: 8.48127) QuantErr: 8.48127 batch_time=0.71008 
Train Epoch: 49 [361/500 23104/32000 (72%)] Loss: 0.04068 (QuantReg: 8.45215) QuantErr: 8.45215 batch_time=0.44876 
Train Epoch: 49 [369/500 23616/32000 (74%)] Loss: 0.02587 (QuantReg: 8.43954) QuantErr: 8.43954 batch_time=0.63425 
Train Epoch: 49 [377/500 24128/32000 (75%)] Loss: 0.02529 (QuantReg: 8.52309) QuantErr: 8.52309 batch_time=0.44420 
Train Epoch: 49 [385/500 24640/32000 (77%)] Loss: 0.02450 (QuantReg: 8.34465) QuantErr: 8.34465 batch_time=0.44477 
Train Epoch: 49 [393/500 25152/32000 (79%)] Loss: 0.03168 (QuantReg: 8.63791) QuantErr: 8.63791 batch_time=0.44985 
Train Epoch: 49 [401/500 25664/32000 (80%)] Loss: 0.04841 (QuantReg: 8.36758) QuantErr: 8.36758 batch_time=0.44733 
Train Epoch: 49 [409/500 26176/32000 (82%)] Loss: 0.02352 (QuantReg: 8.38559) QuantErr: 8.38559 batch_time=0.44684 
Train Epoch: 49 [417/500 26688/32000 (83%)] Loss: 0.03222 (QuantReg: 8.51671) QuantErr: 8.51671 batch_time=0.73301 
Train Epoch: 49 [425/500 27200/32000 (85%)] Loss: 0.06699 (QuantReg: 8.43254) QuantErr: 8.43254 batch_time=0.44061 
Train Epoch: 49 [433/500 27712/32000 (87%)] Loss: 0.01866 (QuantReg: 8.45918) QuantErr: 8.45918 batch_time=0.62988 
Train Epoch: 49 [441/500 28224/32000 (88%)] Loss: 0.02212 (QuantReg: 8.37353) QuantErr: 8.37353 batch_time=0.43733 
Train Epoch: 49 [449/500 28736/32000 (90%)] Loss: 0.01850 (QuantReg: 8.41924) QuantErr: 8.41924 batch_time=0.45725 
Train Epoch: 49 [457/500 29248/32000 (91%)] Loss: 0.02296 (QuantReg: 8.30429) QuantErr: 8.30429 batch_time=0.45151 
Train Epoch: 49 [465/500 29760/32000 (93%)] Loss: 0.02322 (QuantReg: 8.60626) QuantErr: 8.60626 batch_time=0.46271 
Train Epoch: 49 [473/500 30272/32000 (95%)] Loss: 0.03298 (QuantReg: 8.54978) QuantErr: 8.54978 batch_time=0.44069 
Train Epoch: 49 [481/500 30784/32000 (96%)] Loss: 0.02320 (QuantReg: 8.51176) QuantErr: 8.51176 batch_time=0.70050 
Train Epoch: 49 [489/500 31296/32000 (98%)] Loss: 0.03439 (QuantReg: 8.42010) QuantErr: 8.42010 batch_time=0.43874 
Train Epoch: 49 [497/500 31808/32000 (99%)] Loss: 0.02735 (QuantReg: 8.57149) QuantErr: 8.57149 batch_time=0.64382 
Train Epoch: 49 codebook_update_time=1.73946
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_ActivityNet_bs64/checkpoint-epoch49.pth ...
Done in 3.866s
removing stale ckpt [epoch 48] [took 0.01s]
 epoch          : 49
 loss           : 0.039182832017540935
 quant_reg      : 8.477739582061767
 quant_err      : 8.477739582061767
 learning_rate  : 1.0116358736592879e-06
 n_samples      : 1568000
 n_steps        : 24500
 ActivityNet_val1_test/t2v_metrics/R1: 20.601993085214563
 ActivityNet_val1_test/t2v_metrics/R5: 50.62029692902176
 ActivityNet_val1_test/t2v_metrics/R10: 66.11755135245068
 ActivityNet_val1_test/t2v_metrics/R50: 89.40410819605451
 ActivityNet_val1_test/t2v_metrics/MedR: 5.0
 ActivityNet_val1_test/t2v_metrics/MeanR: 34.00549115314216
 ActivityNet_val1_test/t2v_metrics/geometric_mean_R1-R5-R10: 41.00626640681555
 ActivityNet_val1_test/v2t_metrics/R1: 20.825706731747
 ActivityNet_val1_test/v2t_metrics/R5: 52.023591620907055
 ActivityNet_val1_test/v2t_metrics/R10: 67.8259101077893
 ActivityNet_val1_test/v2t_metrics/R50: 89.62782184258694
 ActivityNet_val1_test/v2t_metrics/MedR: 5.0
 ActivityNet_val1_test/v2t_metrics/MeanR: 31.562944885092538
 ActivityNet_val1_test/v2t_metrics/geometric_mean_R1-R5-R10: 41.88564781236876
 mnt_best       : 41.446185373070655
 not_improved_count: 8
Train Epoch: 50 [1/500 64/32000 (0%)] Loss: 0.03689 (QuantReg: 8.60123) QuantErr: 8.60123 batch_time=24.68610 
Train Epoch: 50 [9/500 576/32000 (2%)] Loss: 0.04647 (QuantReg: 8.35637) QuantErr: 8.35637 batch_time=0.43422 
Train Epoch: 50 [17/500 1088/32000 (3%)] Loss: 0.02988 (QuantReg: 8.54280) QuantErr: 8.54280 batch_time=0.50380 
Train Epoch: 50 [25/500 1600/32000 (5%)] Loss: 0.08252 (QuantReg: 8.24575) QuantErr: 8.24575 batch_time=0.63288 
Train Epoch: 50 [33/500 2112/32000 (7%)] Loss: 0.03682 (QuantReg: 8.43275) QuantErr: 8.43275 batch_time=0.97631 
Train Epoch: 50 [41/500 2624/32000 (8%)] Loss: 0.10745 (QuantReg: 8.72852) QuantErr: 8.72852 batch_time=0.43964 
Train Epoch: 50 [49/500 3136/32000 (10%)] Loss: 0.08086 (QuantReg: 8.53238) QuantErr: 8.53238 batch_time=0.44196 
Train Epoch: 50 [57/500 3648/32000 (11%)] Loss: 0.02045 (QuantReg: 8.38989) QuantErr: 8.38989 batch_time=0.44171 
Train Epoch: 50 [65/500 4160/32000 (13%)] Loss: 0.03078 (QuantReg: 8.22245) QuantErr: 8.22245 batch_time=1.11826 
Train Epoch: 50 [73/500 4672/32000 (15%)] Loss: 0.03102 (QuantReg: 8.47254) QuantErr: 8.47254 batch_time=0.47846 
Train Epoch: 50 [81/500 5184/32000 (16%)] Loss: 0.02574 (QuantReg: 8.59549) QuantErr: 8.59549 batch_time=0.51146 
Train Epoch: 50 [89/500 5696/32000 (18%)] Loss: 0.04068 (QuantReg: 8.55828) QuantErr: 8.55828 batch_time=0.64809 
Train Epoch: 50 [97/500 6208/32000 (19%)] Loss: 0.06426 (QuantReg: 8.47457) QuantErr: 8.47457 batch_time=0.90678 
Train Epoch: 50 [105/500 6720/32000 (21%)] Loss: 0.04870 (QuantReg: 8.59140) QuantErr: 8.59140 batch_time=0.46452 
Train Epoch: 50 [113/500 7232/32000 (23%)] Loss: 0.04195 (QuantReg: 8.43695) QuantErr: 8.43695 batch_time=0.44659 
Train Epoch: 50 [121/500 7744/32000 (24%)] Loss: 0.03314 (QuantReg: 8.43369) QuantErr: 8.43369 batch_time=0.45270 
Train Epoch: 50 [129/500 8256/32000 (26%)] Loss: 0.04938 (QuantReg: 8.48701) QuantErr: 8.48701 batch_time=1.14957 
Train Epoch: 50 [137/500 8768/32000 (27%)] Loss: 0.02587 (QuantReg: 8.58881) QuantErr: 8.58881 batch_time=0.44171 
Train Epoch: 50 [145/500 9280/32000 (29%)] Loss: 0.03503 (QuantReg: 8.49493) QuantErr: 8.49493 batch_time=0.50908 
Train Epoch: 50 [153/500 9792/32000 (31%)] Loss: 0.04891 (QuantReg: 8.45547) QuantErr: 8.45547 batch_time=0.65350 
Train Epoch: 50 [161/500 10304/32000 (32%)] Loss: 0.02594 (QuantReg: 8.39055) QuantErr: 8.39055 batch_time=0.92148 
Train Epoch: 50 [169/500 10816/32000 (34%)] Loss: 0.02411 (QuantReg: 8.35631) QuantErr: 8.35631 batch_time=0.45713 
Train Epoch: 50 [177/500 11328/32000 (35%)] Loss: 0.08017 (QuantReg: 8.44115) QuantErr: 8.44115 batch_time=0.44610 
Train Epoch: 50 [185/500 11840/32000 (37%)] Loss: 0.08478 (QuantReg: 8.44070) QuantErr: 8.44070 batch_time=0.44429 
Train Epoch: 50 [193/500 12352/32000 (39%)] Loss: 0.02358 (QuantReg: 8.56164) QuantErr: 8.56164 batch_time=1.21020 
Train Epoch: 50 [201/500 12864/32000 (40%)] Loss: 0.02207 (QuantReg: 8.49372) QuantErr: 8.49372 batch_time=3.29444 
Train Epoch: 50 [209/500 13376/32000 (42%)] Loss: 0.03516 (QuantReg: 8.37685) QuantErr: 8.37685 batch_time=0.44325 
Train Epoch: 50 [217/500 13888/32000 (43%)] Loss: 0.04601 (QuantReg: 8.33485) QuantErr: 8.33485 batch_time=0.47620 
Train Epoch: 50 [225/500 14400/32000 (45%)] Loss: 0.06918 (QuantReg: 8.39911) QuantErr: 8.39911 batch_time=0.44120 
Train Epoch: 50 [233/500 14912/32000 (47%)] Loss: 0.03310 (QuantReg: 8.55320) QuantErr: 8.55320 batch_time=0.44185 
Train Epoch: 50 [241/500 15424/32000 (48%)] Loss: 0.02368 (QuantReg: 8.36090) QuantErr: 8.36090 batch_time=0.44725 
Train Epoch: 50 [249/500 15936/32000 (50%)] Loss: 0.03710 (QuantReg: 8.38740) QuantErr: 8.38740 batch_time=0.44586 
Train Epoch: 50 [257/500 16448/32000 (51%)] Loss: 0.03305 (QuantReg: 8.42885) QuantErr: 8.42885 batch_time=0.51121 
Train Epoch: 50 [265/500 16960/32000 (53%)] Loss: 0.03171 (QuantReg: 8.43532) QuantErr: 8.43532 batch_time=2.02287 
Train Epoch: 50 [273/500 17472/32000 (55%)] Loss: 0.06120 (QuantReg: 8.50428) QuantErr: 8.50428 batch_time=0.44726 
Train Epoch: 50 [281/500 17984/32000 (56%)] Loss: 0.04273 (QuantReg: 8.42871) QuantErr: 8.42871 batch_time=0.45673 
Train Epoch: 50 [289/500 18496/32000 (58%)] Loss: 0.01798 (QuantReg: 8.41950) QuantErr: 8.41950 batch_time=0.44681 
Train Epoch: 50 [297/500 19008/32000 (59%)] Loss: 0.07468 (QuantReg: 8.46831) QuantErr: 8.46831 batch_time=0.56720 
Train Epoch: 50 [305/500 19520/32000 (61%)] Loss: 0.02422 (QuantReg: 8.45905) QuantErr: 8.45905 batch_time=0.47359 
Train Epoch: 50 [313/500 20032/32000 (63%)] Loss: 0.02107 (QuantReg: 8.47310) QuantErr: 8.47310 batch_time=0.45161 
Train Epoch: 50 [321/500 20544/32000 (64%)] Loss: 0.02049 (QuantReg: 8.66556) QuantErr: 8.66556 batch_time=0.98039 
Train Epoch: 50 [329/500 21056/32000 (66%)] Loss: 0.02748 (QuantReg: 8.41613) QuantErr: 8.41613 batch_time=2.36300 
Train Epoch: 50 [337/500 21568/32000 (67%)] Loss: 0.03657 (QuantReg: 8.39446) QuantErr: 8.39446 batch_time=0.44436 
Train Epoch: 50 [345/500 22080/32000 (69%)] Loss: 0.02819 (QuantReg: 8.65262) QuantErr: 8.65262 batch_time=0.44113 
Train Epoch: 50 [353/500 22592/32000 (71%)] Loss: 0.06468 (QuantReg: 8.53369) QuantErr: 8.53369 batch_time=0.44316 
Train Epoch: 50 [361/500 23104/32000 (72%)] Loss: 0.06539 (QuantReg: 8.49342) QuantErr: 8.49342 batch_time=0.45210 
Train Epoch: 50 [369/500 23616/32000 (74%)] Loss: 0.04827 (QuantReg: 8.44913) QuantErr: 8.44913 batch_time=0.46775 
Train Epoch: 50 [377/500 24128/32000 (75%)] Loss: 0.01919 (QuantReg: 8.43241) QuantErr: 8.43241 batch_time=0.44739 
Train Epoch: 50 [385/500 24640/32000 (77%)] Loss: 0.03223 (QuantReg: 8.57723) QuantErr: 8.57723 batch_time=0.89838 
Train Epoch: 50 [393/500 25152/32000 (79%)] Loss: 0.01882 (QuantReg: 8.47156) QuantErr: 8.47156 batch_time=1.94610 
Train Epoch: 50 [401/500 25664/32000 (80%)] Loss: 0.02053 (QuantReg: 8.63302) QuantErr: 8.63302 batch_time=0.43645 
Train Epoch: 50 [409/500 26176/32000 (82%)] Loss: 0.02822 (QuantReg: 8.47730) QuantErr: 8.47730 batch_time=0.45233 
Train Epoch: 50 [417/500 26688/32000 (83%)] Loss: 0.04494 (QuantReg: 8.37339) QuantErr: 8.37339 batch_time=0.45349 
Train Epoch: 50 [425/500 27200/32000 (85%)] Loss: 0.02420 (QuantReg: 8.48375) QuantErr: 8.48375 batch_time=0.44091 
Train Epoch: 50 [433/500 27712/32000 (87%)] Loss: 0.03358 (QuantReg: 8.50722) QuantErr: 8.50722 batch_time=0.44252 
Train Epoch: 50 [441/500 28224/32000 (88%)] Loss: 0.02517 (QuantReg: 8.43539) QuantErr: 8.43539 batch_time=0.45154 
Train Epoch: 50 [449/500 28736/32000 (90%)] Loss: 0.11104 (QuantReg: 8.46522) QuantErr: 8.46522 batch_time=0.94592 
Train Epoch: 50 [457/500 29248/32000 (91%)] Loss: 0.02021 (QuantReg: 8.44879) QuantErr: 8.44879 batch_time=1.97627 
Train Epoch: 50 [465/500 29760/32000 (93%)] Loss: 0.05944 (QuantReg: 8.44698) QuantErr: 8.44698 batch_time=0.44539 
Train Epoch: 50 [473/500 30272/32000 (95%)] Loss: 0.05201 (QuantReg: 8.53335) QuantErr: 8.53335 batch_time=0.48729 
Train Epoch: 50 [481/500 30784/32000 (96%)] Loss: 0.03757 (QuantReg: 8.50264) QuantErr: 8.50264 batch_time=0.47608 
Train Epoch: 50 [489/500 31296/32000 (98%)] Loss: 0.02822 (QuantReg: 8.37788) QuantErr: 8.37788 batch_time=0.47490 
Train Epoch: 50 [497/500 31808/32000 (99%)] Loss: 0.02220 (QuantReg: 8.36563) QuantErr: 8.36563 batch_time=0.47165 
Train Epoch: 50 codebook_update_time=1.65988
Saving checkpoint: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_ActivityNet_bs64/checkpoint-epoch50.pth ...
Done in 4.554s
removing stale ckpt [epoch 49] [took 0.00s]
 epoch          : 50
 loss           : 0.04177122515439987
 quant_reg      : 8.451394638061524
 quant_err      : 8.451394638061524
 learning_rate  : 1.0116358736592879e-06
 n_samples      : 1600000
 n_steps        : 25000
 ActivityNet_val1_test/t2v_metrics/R1: 20.70368110636567
 ActivityNet_val1_test/t2v_metrics/R5: 50.76266015863331
 ActivityNet_val1_test/t2v_metrics/R10: 66.09721374822045
 ActivityNet_val1_test/t2v_metrics/R50: 89.09904413260118
 ActivityNet_val1_test/t2v_metrics/MedR: 5.0
 ActivityNet_val1_test/t2v_metrics/MeanR: 34.52918446207037
 ActivityNet_val1_test/t2v_metrics/geometric_mean_R1-R5-R10: 41.10787542052498
 ActivityNet_val1_test/v2t_metrics/R1: 21.06975798250966
 ActivityNet_val1_test/v2t_metrics/R5: 51.71852755745373
 ActivityNet_val1_test/v2t_metrics/R10: 67.48017083587554
 ActivityNet_val1_test/v2t_metrics/R50: 89.54647142566606
 ActivityNet_val1_test/v2t_metrics/MedR: 5.0
 ActivityNet_val1_test/v2t_metrics/MeanR: 32.4405125076266
 ActivityNet_val1_test/v2t_metrics/geometric_mean_R1-R5-R10: 41.89484848735064
 mnt_best       : 41.446185373070655
 not_improved_count: 9
Final evaluation ...
Loading checkpoint from: /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_ActivityNet_bs64/trained_model.pth ...
Ckpt loaded at epoch 41.
Saved similarity matrix (quantize videos) to /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_ActivityNet_bs64/ActivityNet-test-qv-sims.npy
Saved v2t similarity matrix (quantize texts) to /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_ActivityNet_bs64/ActivityNet-test-qt-sims.npy
ActivityNet_val1_test:
 t2v_metrics/R1/final_eval: 20.622330689444784
 t2v_metrics/R5/final_eval: 51.5965019320724
 t2v_metrics/R10/final_eval: 66.91071791742932
 t2v_metrics/R50/final_eval: 88.93634329875941
 t2v_metrics/MedR/final_eval: 5.0
 t2v_metrics/MeanR/final_eval: 33.60626398210291
 t2v_metrics/geometric_mean_R1-R5-R10/final_eval: 41.446185373070655
 v2t_metrics/R1/final_eval: 20.58165548098434
 v2t_metrics/R5/final_eval: 51.63717714053284
 v2t_metrics/R10/final_eval: 67.76489729509863
 v2t_metrics/R50/final_eval: 89.40410819605451
 v2t_metrics/MedR/final_eval: 5.0
 v2t_metrics/MeanR/final_eval: 31.520642668293675
 v2t_metrics/geometric_mean_R1-R5-R10/final_eval: 41.60535133504599
Best epoch for the monitored metric: 41
Script took 04h51m39s
The best performing ckpt can be found at /apdcephfs/share_47076/gimwang/HCQ/exps/HCQ_ActivityNet_bs64/trained_model.pth
